  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 228502.35it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183335.15it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████      | 4347/10556 [00:00<00:00, 42993.80it/s] 86%|████████▋ | 9129/10556 [00:00<00:00, 42071.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 41768.58it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7520/10556 [00:00<00:00, 75199.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 79755.65it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158898.76it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120417.08it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7151/10556 [00:00<00:00, 71509.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 78461.28it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183130.41it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|███▎      | 3456/10556 [00:00<00:00, 29537.35it/s] 76%|███████▌  | 8014/10556 [00:00<00:00, 32043.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 32012.82it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5274/10556 [00:00<00:00, 52737.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 57274.57it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128468.72it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 57952.24it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.03553295135498047 seconds.
Run epoch 1
Epoch 1 ends in 0.040018320083618164 seconds.
5416 sentences created
mode 1: time used = 0.1288907527923584
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 78618.79it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.03869509696960449 seconds.
Run epoch 1
Epoch 1 ends in 0.03947710990905762 seconds.
5416 sentences created
mode 1: time used = 0.09067821502685547
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 176790.57it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.02399754524230957 seconds.
Run epoch 1
Epoch 1 ends in 0.019620418548583984 seconds.
5416 sentences created
mode 1: time used = 0.03860044479370117
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 73986.43it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.028513193130493164 seconds.
Run epoch 1
Epoch 1 ends in 0.03549766540527344 seconds.
5416 sentences created
mode 1: time used = 0.08724308013916016
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 63982.33it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.1154632568359375 seconds.
Run epoch 1
Epoch 1 ends in 0.15457963943481445 seconds.
5416 sentences created
mode 1: time used = 0.10643911361694336
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 115415.71it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.06374406814575195 seconds.
Run epoch 1
Epoch 1 ends in 0.042034149169921875 seconds.
5416 sentences created
mode 1: time used = 0.0587000846862793
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
  0%|          | 0/5416 [00:00<?, ?it/s] 49%|████▉     | 2679/5416 [00:00<00:00, 25221.29it/s]100%|██████████| 5416/5416 [00:00<00:00, 26089.01it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.3610572814941406 seconds.
Run epoch 1
Epoch 1 ends in 0.24588680267333984 seconds.
5416 sentences created
mode 1: time used = 0.28389859199523926
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
  0%|          | 0/5416 [00:00<?, ?it/s] 65%|██████▌   | 3525/5416 [00:00<00:00, 35249.03it/s]100%|██████████| 5416/5416 [00:00<00:00, 31664.96it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.14958882331848145 seconds.
Run epoch 1
Epoch 1 ends in 0.07268929481506348 seconds.
5416 sentences created
mode 1: time used = 0.23645496368408203
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 10.76 GiB total capacity; 0 bytes already allocated; 14.44 MiB free; 0 bytes reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 55721.99it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|▊         | 6231/75824 [00:00<00:01, 61755.13it/s] 16%|█▌        | 11851/75824 [00:00<00:01, 59975.52it/s] 22%|██▏       | 17016/75824 [00:00<00:01, 56732.95it/s] 28%|██▊       | 21523/75824 [00:00<00:01, 52644.85it/s] 35%|███▌      | 26556/75824 [00:00<00:00, 51066.97it/s] 40%|████      | 30698/75824 [00:00<00:00, 46230.40it/s] 46%|████▌     | 34734/75824 [00:00<00:00, 43482.94it/s] 51%|█████     | 38705/75824 [00:00<00:00, 40186.31it/s] 56%|█████▌    | 42509/75824 [00:00<00:00, 39021.01it/s] 63%|██████▎   | 47421/75824 [00:01<00:00, 41585.55it/s] 69%|██████▉   | 52412/75824 [00:01<00:00, 43775.25it/s] 76%|███████▌  | 57532/75824 [00:01<00:00, 45765.68it/s] 83%|████████▎ | 62901/75824 [00:01<00:00, 47236.94it/s] 90%|████████▉ | 68160/75824 [00:01<00:00, 48606.56it/s] 97%|█████████▋| 73508/75824 [00:01<00:00, 49972.53it/s]100%|██████████| 75824/75824 [00:01<00:00, 47568.77it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 222, in forward
    self.to(self._device)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 607, in to
    return self._apply(convert)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 376, in _apply
    param_applied = fn(param)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 605, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.76 GiB total capacity; 14.80 MiB already allocated; 16.44 MiB free; 16.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.11343789100646973 seconds.
Run epoch 1
Epoch 1 ends in 0.09688615798950195 seconds.
5416 sentences created
mode 1: time used = 0.13624835014343262
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 65467.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17564/75824 [00:00<00:00, 175631.37it/s] 40%|████      | 30511/75824 [00:00<00:00, 158658.63it/s] 54%|█████▍    | 40880/75824 [00:00<00:00, 136280.04it/s] 70%|███████   | 53123/75824 [00:00<00:00, 131806.64it/s] 86%|████████▌ | 64991/75824 [00:00<00:00, 126384.40it/s] 99%|█████████▉| 75410/75824 [00:00<00:00, 118791.85it/s]100%|██████████| 75824/75824 [00:00<00:00, 124736.34it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 222, in forward
    self.to(self._device)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 607, in to
    return self._apply(convert)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 376, in _apply
    param_applied = fn(param)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 605, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.76 GiB total capacity; 14.80 MiB already allocated; 15.44 MiB free; 16.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.02742457389831543 seconds.
Run epoch 1
Epoch 1 ends in 0.026137828826904297 seconds.
5416 sentences created
mode 1: time used = 0.0985267162322998
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
  0%|          | 0/5416 [00:00<?, ?it/s] 85%|████████▌ | 4620/5416 [00:00<00:00, 46198.61it/s]100%|██████████| 5416/5416 [00:00<00:00, 38609.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|█▏        | 9203/75824 [00:00<00:00, 92029.87it/s] 23%|██▎       | 17170/75824 [00:00<00:00, 87935.64it/s] 34%|███▍      | 25959/75824 [00:00<00:00, 87649.91it/s] 49%|████▊     | 36798/75824 [00:00<00:00, 92987.64it/s] 67%|██████▋   | 50626/75824 [00:00<00:00, 103119.31it/s] 88%|████████▊ | 66872/75824 [00:00<00:00, 115808.75it/s]100%|██████████| 75824/75824 [00:00<00:00, 103831.66it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.03305530548095703 seconds.
Run epoch 1
Epoch 1 ends in 0.031081438064575195 seconds.
5416 sentences created
mode 1: time used = 0.20770645141601562
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 62111.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|█         | 7863/75824 [00:00<00:00, 78627.83it/s] 26%|██▋       | 19935/75824 [00:00<00:00, 87811.81it/s] 41%|████▏     | 31447/75824 [00:00<00:00, 94538.65it/s] 57%|█████▋    | 43506/75824 [00:00<00:00, 101088.73it/s] 73%|███████▎  | 55323/75824 [00:00<00:00, 105670.73it/s] 89%|████████▉ | 67759/75824 [00:00<00:00, 110657.40it/s]100%|██████████| 75824/75824 [00:00<00:00, 112506.71it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 222, in forward
    self.to(self._device)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 607, in to
    return self._apply(convert)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 376, in _apply
    param_applied = fn(param)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 605, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.76 GiB total capacity; 14.80 MiB already allocated; 15.44 MiB free; 16.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.0662851333618164 seconds.
Run epoch 1
Epoch 1 ends in 0.07682418823242188 seconds.
5416 sentences created
mode 1: time used = 0.12642121315002441
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s] 74%|███████▍  | 4001/5416 [00:00<00:00, 40008.89it/s]100%|██████████| 5416/5416 [00:00<00:00, 45669.54it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▌        | 11695/75824 [00:00<00:00, 116945.65it/s] 32%|███▏      | 24181/75824 [00:00<00:00, 119212.35it/s] 48%|████▊     | 36705/75824 [00:00<00:00, 120957.11it/s] 65%|██████▌   | 49445/75824 [00:00<00:00, 122819.43it/s] 78%|███████▊  | 58936/75824 [00:00<00:00, 104691.93it/s] 90%|████████▉ | 67916/75824 [00:00<00:00, 99288.99it/s] 100%|██████████| 75824/75824 [00:00<00:00, 110093.21it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 55, in _forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 43, in embed
    return self.features[x]
RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 10.76 GiB total capacity; 17.47 MiB already allocated; 19.44 MiB free; 20.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.10978150367736816 seconds.
Run epoch 1
Epoch 1 ends in 0.0421910285949707 seconds.
5416 sentences created
mode 1: time used = 0.1456892490386963
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 140682.04it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|▉         | 7544/75824 [00:00<00:00, 75433.96it/s] 28%|██▊       | 21466/75824 [00:00<00:00, 87454.55it/s] 51%|█████     | 38546/75824 [00:00<00:00, 102452.18it/s] 69%|██████▉   | 52472/75824 [00:00<00:00, 111274.82it/s] 83%|████████▎ | 63060/75824 [00:00<00:00, 96061.75it/s]  99%|█████████▉| 75199/75824 [00:00<00:00, 102474.60it/s]100%|██████████| 75824/75824 [00:00<00:00, 116496.45it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.03573966026306152 seconds.
Run epoch 1
Epoch 1 ends in 0.042922258377075195 seconds.
5416 sentences created
mode 1: time used = 0.04673576354980469
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 135384.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 13014/75824 [00:00<00:00, 130131.75it/s] 29%|██▉       | 21985/75824 [00:00<00:00, 114632.67it/s] 36%|███▌      | 27409/75824 [00:00<00:00, 84327.92it/s]  52%|█████▏    | 39577/75824 [00:00<00:00, 92880.22it/s] 69%|██████▊   | 52048/75824 [00:00<00:00, 100580.24it/s] 86%|████████▌ | 64834/75824 [00:00<00:00, 107456.73it/s]100%|██████████| 75824/75824 [00:00<00:00, 110841.40it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 222, in forward
    self.to(self._device)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 607, in to
    return self._apply(convert)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 376, in _apply
    param_applied = fn(param)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 605, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.76 GiB total capacity; 14.80 MiB already allocated; 16.44 MiB free; 16.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.027324914932250977 seconds.
Run epoch 1
Epoch 1 ends in 0.02568674087524414 seconds.
5416 sentences created
mode 1: time used = 0.05023670196533203
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 125384.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|██        | 15432/75824 [00:00<00:00, 154305.43it/s] 35%|███▌      | 26550/75824 [00:00<00:00, 138218.10it/s] 52%|█████▏    | 39288/75824 [00:00<00:00, 134776.96it/s] 67%|██████▋   | 50625/75824 [00:00<00:00, 127550.03it/s] 81%|████████  | 61526/75824 [00:00<00:00, 121357.64it/s] 94%|█████████▍| 71305/75824 [00:00<00:00, 111083.29it/s]100%|██████████| 75824/75824 [00:00<00:00, 111827.93it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 222, in forward
    self.to(self._device)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 607, in to
    return self._apply(convert)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 376, in _apply
    param_applied = fn(param)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 605, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.76 GiB total capacity; 14.80 MiB already allocated; 16.44 MiB free; 16.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.020818710327148438 seconds.
Run epoch 1
Epoch 1 ends in 0.020635128021240234 seconds.
5416 sentences created
mode 1: time used = 0.05135512351989746
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 82208.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|▉         | 7295/75824 [00:00<00:01, 61123.26it/s] 25%|██▌       | 19036/75824 [00:00<00:00, 71390.20it/s] 41%|████▏     | 31367/75824 [00:00<00:00, 81711.14it/s] 54%|█████▎    | 40643/75824 [00:00<00:00, 82034.50it/s] 67%|██████▋   | 51083/75824 [00:00<00:00, 87667.99it/s] 84%|████████▎ | 63495/75824 [00:00<00:00, 96136.73it/s]100%|█████████▉| 75455/75824 [00:00<00:00, 102147.09it/s]100%|██████████| 75824/75824 [00:00<00:00, 102674.93it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 222, in forward
    self.to(self._device)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 607, in to
    return self._apply(convert)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 376, in _apply
    param_applied = fn(param)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 605, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 14.80 MiB already allocated; 16.44 MiB free; 16.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.0436856746673584 seconds.
Run epoch 1
Epoch 1 ends in 0.03707242012023926 seconds.
5416 sentences created
mode 1: time used = 0.08781242370605469
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 81011.20it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|█▏        | 8996/75824 [00:00<00:00, 89958.58it/s] 19%|█▉        | 14625/75824 [00:00<00:00, 76272.06it/s] 35%|███▍      | 26163/75824 [00:00<00:00, 84905.11it/s] 52%|█████▏    | 39484/75824 [00:00<00:00, 95268.21it/s] 72%|███████▏  | 54881/75824 [00:00<00:00, 107571.17it/s] 86%|████████▌ | 65221/75824 [00:00<00:00, 97869.99it/s] 100%|██████████| 75824/75824 [00:00<00:00, 107579.29it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.02970576286315918 seconds.
Run epoch 1
Epoch 1 ends in 0.03379034996032715 seconds.
5416 sentences created
mode 1: time used = 0.12158203125
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s] 93%|█████████▎| 5047/5416 [00:00<00:00, 50442.63it/s]100%|██████████| 5416/5416 [00:00<00:00, 47991.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 11885/75824 [00:00<00:00, 118845.58it/s] 27%|██▋       | 20185/75824 [00:00<00:00, 105212.44it/s] 41%|████      | 30970/75824 [00:00<00:00, 105989.12it/s] 54%|█████▍    | 40929/75824 [00:00<00:00, 102258.24it/s] 67%|██████▋   | 50453/75824 [00:00<00:00, 100044.96it/s] 78%|███████▊  | 59107/75824 [00:00<00:00, 91633.15it/s]  88%|████████▊ | 67101/75824 [00:00<00:00, 65089.83it/s] 97%|█████████▋| 73862/75824 [00:00<00:00, 55899.67it/s]100%|██████████| 75824/75824 [00:01<00:00, 72925.01it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/graph_isomorphism.py", line 37, in forward
    y = self.mlp((1 + self.eps) * x + torch.mm(self.adj, x))
RuntimeError: !t.is_cuda() INTERNAL ASSERT FAILED at "/pytorch/aten/src/ATen/native/sparse/SparseTensorMath.cpp":822, please report a bug to PyTorch. 
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = gin
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.04746818542480469 seconds.
Run epoch 1
Epoch 1 ends in 0.03483128547668457 seconds.
5416 sentences created
mode 1: time used = 0.1481938362121582
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 10.76 GiB total capacity; 0 bytes already allocated; 15.44 MiB free; 0 bytes reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 10.76 GiB total capacity; 0 bytes already allocated; 16.44 MiB free; 0 bytes reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 222, in forward
    self.to(self._device)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 607, in to
    return self._apply(convert)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 376, in _apply
    param_applied = fn(param)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 605, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 14.80 MiB already allocated; 16.44 MiB free; 16.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.38590'}; time used = 0.10105013847351074s
epoch 10: {'train_loss': '1.37945'}; time used = 0.053670406341552734s
epoch 15: {'train_loss': '1.34941'}; time used = 0.06485319137573242s
epoch 20: {'train_loss': '1.28666'}; time used = 0.07160687446594238s
epoch 25: {'train_loss': '1.25648'}; time used = 0.06032967567443848s
epoch 30: {'train_loss': '1.21383'}; time used = 0.04688096046447754s
epoch 35: {'train_loss': '1.19931'}; time used = 0.04796552658081055s
epoch 40: {'train_loss': '1.18497'}; time used = 0.05437612533569336s
epoch 45: {'train_loss': '1.16934'}; time used = 0.0697181224822998s
epoch 50: {'train_loss': '1.15957'}; time used = 0.03714466094970703s
epoch 55: {'train_loss': '1.13873'}; time used = 0.048223257064819336s
epoch 60: {'train_loss': '1.13048'}; time used = 0.036560773849487305s
epoch 65: {'train_loss': '1.13126'}; time used = 0.049459218978881836s
epoch 70: {'train_loss': '1.11231'}; time used = 0.04427456855773926s
epoch 75: {'train_loss': '1.11006'}; time used = 0.043283700942993164s
epoch 80: {'train_loss': '1.10845'}; time used = 0.048787593841552734s
epoch 85: {'train_loss': '1.09461'}; time used = 0.04493093490600586s
epoch 90: {'train_loss': '1.08908'}; time used = 0.042755126953125s
epoch 95: {'train_loss': '1.08312'}; time used = 0.03474259376525879s
epoch 100: {'train_loss': '1.08122'}; time used = 0.04332447052001953s
epoch 105: {'train_loss': '1.07281'}; time used = 0.06369757652282715s
epoch 110: {'train_loss': '1.05670'}; time used = 0.05898261070251465s
epoch 115: {'train_loss': '1.04499'}; time used = 0.047330379486083984s
epoch 120: {'train_loss': '1.04565'}; time used = 0.03419232368469238s
epoch 125: {'train_loss': '1.02974'}; time used = 0.04294228553771973s
epoch 130: {'train_loss': '1.02235'}; time used = 0.043416738510131836s
epoch 135: {'train_loss': '1.01236'}; time used = 0.04673290252685547s
epoch 140: {'train_loss': '1.02366'}; time used = 0.03966641426086426s
epoch 145: {'train_loss': '1.00634'}; time used = 0.055963754653930664s
epoch 150: {'train_loss': '0.99654'}; time used = 0.05087637901306152s
epoch 155: {'train_loss': '0.99394'}; time used = 0.04345846176147461s
epoch 160: {'train_loss': '0.98979'}; time used = 0.05054354667663574s
epoch 165: {'train_loss': '0.96787'}; time used = 0.03576850891113281s
epoch 170: {'train_loss': '0.98610'}; time used = 0.029648780822753906s
epoch 175: {'train_loss': '0.97470'}; time used = 0.02703404426574707s
epoch 180: {'train_loss': '0.97482'}; time used = 0.024288177490234375s
epoch 185: {'train_loss': '0.96792'}; time used = 0.049068450927734375s
epoch 190: {'train_loss': '0.96284'}; time used = 0.02219223976135254s
epoch 195: {'train_loss': '0.95585'}; time used = 0.027301311492919922s
epoch 200: {'train_loss': '0.94493'}; time used = 0.03830695152282715s
epoch 205: {'train_loss': '0.94941'}; time used = 0.03789687156677246s
epoch 210: {'train_loss': '0.93784'}; time used = 0.035315752029418945s
epoch 215: {'train_loss': '0.93482'}; time used = 0.022641420364379883s
epoch 220: {'train_loss': '0.94517'}; time used = 0.022222518920898438s
epoch 225: {'train_loss': '0.93483'}; time used = 0.022212505340576172s
epoch 230: {'train_loss': '0.93140'}; time used = 0.03699541091918945s
epoch 235: {'train_loss': '0.93572'}; time used = 0.03895831108093262s
epoch 240: {'train_loss': '0.93287'}; time used = 0.040035247802734375s
epoch 245: {'train_loss': '0.93273'}; time used = 0.03168058395385742s
epoch 250: {'train_loss': '0.92086'}; time used = 0.03796219825744629s
epoch 255: {'train_loss': '0.92153'}; time used = 0.05985212326049805s
epoch 260: {'train_loss': '0.92653'}; time used = 0.04737353324890137s
epoch 265: {'train_loss': '0.91568'}; time used = 0.05199265480041504s
epoch 270: {'train_loss': '0.91116'}; time used = 0.04844474792480469s
epoch 275: {'train_loss': '0.91531'}; time used = 0.04001736640930176s
epoch 280: {'train_loss': '0.92108'}; time used = 0.05630755424499512s
epoch 285: {'train_loss': '0.90636'}; time used = 0.048415422439575195s
epoch 290: {'train_loss': '0.92271'}; time used = 0.0403289794921875s
epoch 295: {'train_loss': '0.91213'}; time used = 0.06514644622802734s
epoch 300: {'train_loss': '0.90658'}; time used = 0.05198502540588379s
epoch 305: {'train_loss': '0.91242'}; time used = 0.02220630645751953s
epoch 310: {'train_loss': '0.91315'}; time used = 0.022141218185424805s
epoch 315: {'train_loss': '0.90803'}; time used = 0.02219676971435547s
epoch 320: {'train_loss': '0.90494'}; time used = 0.03412365913391113s
epoch 325: {'train_loss': '0.89500'}; time used = 0.12129592895507812s
epoch 330: {'train_loss': '0.88994'}; time used = 0.030186176300048828s
epoch 335: {'train_loss': '0.90673'}; time used = 0.028318405151367188s
epoch 340: {'train_loss': '0.89850'}; time used = 0.03855133056640625s
epoch 345: {'train_loss': '0.89922'}; time used = 0.03889298439025879s
epoch 350: {'train_loss': '0.89842'}; time used = 0.029618501663208008s
epoch 355: {'train_loss': '0.89859'}; time used = 0.022731304168701172s
epoch 360: {'train_loss': '0.89521'}; time used = 0.02203226089477539s
epoch 365: {'train_loss': '0.88379'}; time used = 0.021973133087158203s
epoch 370: {'train_loss': '0.89785'}; time used = 0.02244877815246582s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.313823461532593.
Training classifier using 20.00% nodes...
{'micro': 0.683894785417628, 'macro': 0.5804409926390504, 'samples': 0.683894785417628, 'weighted': 0.6603114407461781}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146769.50it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 47, in forward
    loss = self.estimator(self.decoder(hx, hpos), self.decoder(hx, hneg))
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_decoder.py", line 15, in forward
    score = self.layer(x, y)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_decoder.py", line 25, in forward
    score = torch.sum((x * y), dim=-1)
RuntimeError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 10.76 GiB total capacity; 65.04 MiB already allocated; 17.44 MiB free; 74.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9661/10556 [00:00<00:00, 95740.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 91280.53it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/linear.py", line 46, in forward
    pre_sup = torch.mm(x, self.weight)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153301.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144733.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148806.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145813.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144153.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148840.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151419.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151812.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149686.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147058.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147319.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148284.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151417.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10337/10556 [00:00<00:00, 103366.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 102818.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154228.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151970.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146503.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150661.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141953.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150325.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108882.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5969/10556 [00:00<00:00, 59688.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 67676.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145801.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141715.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201053.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178696.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179196.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194286.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184564.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 102940.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118863.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181871.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125632.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128204.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7426/10556 [00:00<00:00, 72215.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 68939.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197638.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121568.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9598/10556 [00:00<00:00, 84846.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 59748.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165916.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158958.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|███▎      | 3540/10556 [00:00<00:00, 35397.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 56968.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7369/10556 [00:00<00:00, 65300.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 64535.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194165.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190555.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164232.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|████      | 4274/10556 [00:00<00:00, 42736.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 63792.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5095/10556 [00:00<00:00, 50946.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 71431.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7424/10556 [00:00<00:00, 74239.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 80032.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190137.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181298.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178985.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177919.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169675.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117975.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160479.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180837.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180919.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177042.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177579.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179023.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166881.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184636.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187314.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175137.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177904.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174557.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176461.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173665.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176325.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165941.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175464.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179004.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180931.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111528.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145331.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128220.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9914/10556 [00:00<00:00, 99139.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 99418.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147500.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149720.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170762.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176260.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177117.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175278.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174989.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121344.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158128.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114997.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152139.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142872.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151492.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206619.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134203.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195456.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165163.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211787.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192426.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127217.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165948.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172064.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157957.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171037.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168549.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138298.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127434.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187630.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168627.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132595.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168218.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186731.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176526.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147082.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122142.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6887/10556 [00:00<00:00, 68866.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 81585.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113031.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144868.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189660.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175625.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190631.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189677.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184948.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182013.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180727.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187193.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184550.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186979.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190292.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196041.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180682.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181339.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179791.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182701.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184145.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143682.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148687.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190795.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193948.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190593.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211189.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194114.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141417.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127481.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9792/10556 [00:00<00:00, 94364.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 78631.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8956/10556 [00:00<00:00, 84391.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 78743.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138255.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182199.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124881.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8761/10556 [00:00<00:00, 87028.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 65678.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|███████▉  | 8411/10556 [00:00<00:00, 78886.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 66522.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114342.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▊      | 4070/10556 [00:00<00:00, 40697.32it/s] 77%|███████▋  | 8082/10556 [00:00<00:00, 40149.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 41813.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196604.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203030.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5209/10556 [00:00<00:00, 52087.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 80729.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173609.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6335/10556 [00:00<00:00, 59614.41it/s] 95%|█████████▌| 10078/10556 [00:00<00:00, 49893.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 47879.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4459/10556 [00:00<00:00, 43055.10it/s] 71%|███████   | 7513/10556 [00:00<00:00, 38138.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 44781.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123618.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138359.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153864.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196169.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186864.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186355.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188535.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136750.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120003.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209429.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183359.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195352.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189495.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148507.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155301.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184288.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187576.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187402.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189935.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179480.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179852.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183858.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194720.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126897.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140313.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193603.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195064.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176497.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196916.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206278.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202800.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184537.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140427.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154664.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149662.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141700.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150215.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150517.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148486.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145917.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140696.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141749.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140272.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137178.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8163/10556 [00:00<00:00, 81627.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 91032.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136608.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134553.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135691.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142138.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144749.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9786/10556 [00:00<00:00, 97857.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 97867.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137984.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170523.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167049.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121405.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109114.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127856.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129281.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147311.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146660.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137392.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8370/10556 [00:00<00:00, 83695.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 92233.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149723.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146421.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145777.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10244/10556 [00:00<00:00, 102433.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 102212.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137650.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146904.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148537.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148393.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150035.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148964.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146438.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107957.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117978.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150779.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159976.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190034.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188636.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179258.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189317.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192204.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187768.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189178.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193416.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187276.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183392.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171295.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165479.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182928.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179749.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187688.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181827.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119917.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167278.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199497.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140559.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134654.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183481.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196317.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189814.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179015.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122502.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10535/10556 [00:00<00:00, 105349.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 104963.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9967/10556 [00:00<00:00, 99663.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 89433.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130168.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199091.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10385/10556 [00:00<00:00, 103844.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 103742.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144886.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130497.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7120/10556 [00:00<00:00, 71192.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 67610.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125508.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117824.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114639.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117492.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5451/10556 [00:00<00:00, 54507.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 83138.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196969.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157816.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5743/10556 [00:00<00:00, 56003.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 67785.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9731/10556 [00:00<00:00, 97305.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 96714.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7722/10556 [00:00<00:00, 77219.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 92518.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175116.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6187/10556 [00:00<00:00, 61865.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 78354.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108090.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7452/10556 [00:00<00:00, 73657.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 87202.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128138.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196107.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186416.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180207.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184801.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174564.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120105.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149209.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192767.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191806.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192986.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190847.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183794.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188033.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191177.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194265.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193053.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198876.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194487.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204739.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192447.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199752.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204452.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197517.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199011.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183544.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187755.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189515.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203868.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189753.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7862/10556 [00:00<00:00, 78615.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 89046.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203354.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222110.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207041.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136734.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150771.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152922.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150346.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10549/10556 [00:00<00:00, 105482.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 105033.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134147.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138293.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148582.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149509.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150159.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10278/10556 [00:00<00:00, 95006.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 94567.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110423.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150219.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147874.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149251.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148375.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147092.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142660.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9738/10556 [00:00<00:00, 97378.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 74178.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142564.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192074.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196879.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207162.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197527.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189616.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174699.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160243.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187284.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145031.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136440.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187135.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182455.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199381.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186690.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190762.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185464.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188461.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182610.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185056.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176281.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181015.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193915.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181929.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183672.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164546.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179051.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172408.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182938.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183069.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142846.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129472.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180785.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186167.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183939.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139192.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151858.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149846.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132775.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107887.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138908.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4557/10556 [00:00<00:00, 45568.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 66927.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|███▋      | 3847/10556 [00:00<00:00, 37781.92it/s]100%|█████████▉| 10537/10556 [00:00<00:00, 43455.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 52176.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9710/10556 [00:00<00:00, 97097.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 101028.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6867/10556 [00:00<00:00, 59242.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 60786.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7394/10556 [00:00<00:00, 73934.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 74509.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111762.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████      | 4343/10556 [00:00<00:00, 43427.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 62340.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▊     | 5139/10556 [00:00<00:00, 47305.43it/s] 75%|███████▍  | 7905/10556 [00:00<00:00, 38993.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 38325.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6941/10556 [00:00<00:00, 64251.47it/s] 88%|████████▊ | 9284/10556 [00:00<00:00, 39656.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 45717.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9227/10556 [00:00<00:00, 92269.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 94781.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188094.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193227.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182247.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180643.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184579.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182207.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177350.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8284/10556 [00:00<00:00, 82836.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 81155.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215519.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209721.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197486.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196008.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213228.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199553.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213127.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203658.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144606.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212575.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180551.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191276.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194882.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194991.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199090.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204888.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207132.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208362.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205695.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209942.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210713.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195789.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194350.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208562.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208156.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137098.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9297/10556 [00:00<00:00, 92966.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 97369.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131254.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142892.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151281.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150041.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147997.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7222/10556 [00:00<00:00, 72216.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 72971.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147726.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149098.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141778.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7645/10556 [00:00<00:00, 76439.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 78178.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9165/10556 [00:00<00:00, 91647.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 93605.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140436.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142807.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147619.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151106.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150501.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146466.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148353.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144481.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138861.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9233/10556 [00:00<00:00, 92325.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 76102.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143577.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133940.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148027.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146721.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143769.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136190.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9591/10556 [00:00<00:00, 95909.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 100169.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171954.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174863.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181113.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170059.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175981.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184392.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178815.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172600.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175228.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182565.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179377.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178549.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183050.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182327.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172581.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185535.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175368.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8192/10556 [00:00<00:00, 80094.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 78677.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178110.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179618.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171319.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185276.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182683.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183961.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187593.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182594.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179309.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7996/10556 [00:00<00:00, 79954.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 79632.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185859.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176042.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184079.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186753.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211743.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10428/10556 [00:00<00:00, 104273.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 97853.68it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122582.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185786.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184801.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187192.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186576.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168861.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182500.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188662.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152514.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124924.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183691.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145789.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143949.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9406/10556 [00:00<00:00, 94055.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 89474.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126119.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156072.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8269/10556 [00:00<00:00, 82686.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 78601.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 7018/10556 [00:00<00:00, 70177.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 75166.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7807/10556 [00:00<00:00, 78059.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 63654.13it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.38552'}; time used = 0.41515016555786133s
epoch 10: {'train_loss': '1.37980'}; time used = 0.3988800048828125s
epoch 15: {'train_loss': '1.35109'}; time used = 0.42000555992126465s
epoch 20: {'train_loss': '1.28727'}; time used = 0.4230380058288574s
epoch 25: {'train_loss': '1.24456'}; time used = 0.4770643711090088s
epoch 30: {'train_loss': '1.21010'}; time used = 0.41011762619018555s
epoch 35: {'train_loss': '1.16833'}; time used = 0.4705357551574707s
epoch 40: {'train_loss': '1.13492'}; time used = 0.6279230117797852s
epoch 45: {'train_loss': '1.09794'}; time used = 0.5357785224914551s
epoch 50: {'train_loss': '1.05579'}; time used = 0.49745702743530273s
epoch 55: {'train_loss': '1.02980'}; time used = 0.3695075511932373s
epoch 60: {'train_loss': '1.02119'}; time used = 0.32877159118652344s
epoch 65: {'train_loss': '0.99876'}; time used = 0.32564640045166016s
epoch 70: {'train_loss': '0.98772'}; time used = 0.33342790603637695s
epoch 75: {'train_loss': '0.97971'}; time used = 0.3974630832672119s
epoch 80: {'train_loss': '0.97612'}; time used = 0.40187740325927734s
epoch 85: {'train_loss': '0.95987'}; time used = 0.3683469295501709s
epoch 90: {'train_loss': '0.94638'}; time used = 0.3936734199523926s
epoch 95: {'train_loss': '0.94729'}; time used = 0.33922338485717773s
epoch 100: {'train_loss': '0.94242'}; time used = 0.37479591369628906s
epoch 105: {'train_loss': '0.94146'}; time used = 0.3717982769012451s
epoch 110: {'train_loss': '0.94620'}; time used = 0.36767578125s
epoch 115: {'train_loss': '0.93173'}; time used = 0.5006487369537354s
epoch 120: {'train_loss': '0.93216'}; time used = 0.3209340572357178s
epoch 125: {'train_loss': '0.92868'}; time used = 0.31694936752319336s
epoch 130: {'train_loss': '0.92798'}; time used = 0.31625819206237793s
epoch 135: {'train_loss': '0.91990'}; time used = 0.3596913814544678s
epoch 140: {'train_loss': '0.91487'}; time used = 0.3417224884033203s
epoch 145: {'train_loss': '0.91017'}; time used = 0.5253782272338867s
epoch 150: {'train_loss': '0.91158'}; time used = 0.7768313884735107s
epoch 155: {'train_loss': '0.90721'}; time used = 0.7706387042999268s
epoch 160: {'train_loss': '0.90101'}; time used = 0.3947458267211914s
epoch 165: {'train_loss': '0.90645'}; time used = 0.35488009452819824s
epoch 170: {'train_loss': '0.90935'}; time used = 0.33177852630615234s
epoch 175: {'train_loss': '0.89436'}; time used = 0.31029558181762695s
epoch 180: {'train_loss': '0.90541'}; time used = 0.3712613582611084s
epoch 185: {'train_loss': '0.90195'}; time used = 0.31225085258483887s
epoch 190: {'train_loss': '0.89764'}; time used = 0.36930227279663086s
epoch 195: {'train_loss': '0.89130'}; time used = 0.3868272304534912s
epoch 200: {'train_loss': '0.88628'}; time used = 0.46459341049194336s
epoch 205: {'train_loss': '0.89075'}; time used = 0.41115713119506836s
epoch 210: {'train_loss': '0.88362'}; time used = 0.44722652435302734s
epoch 215: {'train_loss': '0.89258'}; time used = 0.44429922103881836s
epoch 220: {'train_loss': '0.88776'}; time used = 0.4445970058441162s
epoch 225: {'train_loss': '0.87807'}; time used = 0.4310944080352783s
epoch 230: {'train_loss': '0.88151'}; time used = 0.4392375946044922s
epoch 235: {'train_loss': '0.87843'}; time used = 0.3384876251220703s
epoch 240: {'train_loss': '0.88148'}; time used = 0.30501508712768555s
epoch 245: {'train_loss': '0.86439'}; time used = 0.32816171646118164s
epoch 250: {'train_loss': '0.86477'}; time used = 0.3595905303955078s
epoch 255: {'train_loss': '0.86190'}; time used = 0.34015750885009766s
epoch 260: {'train_loss': '0.86070'}; time used = 0.44595885276794434s
epoch 265: {'train_loss': '0.86754'}; time used = 0.42997097969055176s
epoch 270: {'train_loss': '0.86990'}; time used = 0.5625035762786865s
epoch 275: {'train_loss': '0.86768'}; time used = 0.5610616207122803s
epoch 280: {'train_loss': '0.85950'}; time used = 0.5848090648651123s
epoch 285: {'train_loss': '0.86124'}; time used = 0.3341939449310303s
epoch 290: {'train_loss': '0.86064'}; time used = 0.36368823051452637s
epoch 295: {'train_loss': '0.86122'}; time used = 0.30753278732299805s
epoch 300: {'train_loss': '0.86309'}; time used = 0.30202341079711914s
epoch 305: {'train_loss': '0.85378'}; time used = 0.2920210361480713s
epoch 310: {'train_loss': '0.84235'}; time used = 0.3037750720977783s
epoch 315: {'train_loss': '0.85395'}; time used = 0.42669034004211426s
epoch 320: {'train_loss': '0.84058'}; time used = 0.41872310638427734s
epoch 325: {'train_loss': '0.85810'}; time used = 0.4315762519836426s
epoch 330: {'train_loss': '0.84803'}; time used = 0.42163896560668945s
epoch 335: {'train_loss': '0.84890'}; time used = 0.45500898361206055s
epoch 340: {'train_loss': '0.85034'}; time used = 0.308121919631958s
epoch 345: {'train_loss': '0.84234'}; time used = 0.3600804805755615s
epoch 350: {'train_loss': '0.83634'}; time used = 0.31940698623657227s
epoch 355: {'train_loss': '0.84955'}; time used = 0.3225748538970947s
epoch 360: {'train_loss': '0.85332'}; time used = 0.32132983207702637s
epoch 365: {'train_loss': '0.83618'}; time used = 0.357576847076416s
epoch 370: {'train_loss': '0.82922'}; time used = 0.34064579010009766s
epoch 375: {'train_loss': '0.84155'}; time used = 0.5164666175842285s
epoch 380: {'train_loss': '0.83450'}; time used = 0.7440581321716309s
epoch 385: {'train_loss': '0.83361'}; time used = 0.9128224849700928s
epoch 390: {'train_loss': '0.84479'}; time used = 0.3124103546142578s
epoch 395: {'train_loss': '0.83075'}; time used = 0.36836910247802734s
epoch 400: {'train_loss': '0.85318'}; time used = 0.2801046371459961s
epoch 405: {'train_loss': '0.84472'}; time used = 0.3171811103820801s
epoch 410: {'train_loss': '0.83763'}; time used = 0.2866780757904053s
epoch 415: {'train_loss': '0.82058'}; time used = 0.2831413745880127s
epoch 420: {'train_loss': '0.83640'}; time used = 0.3990514278411865s
epoch 425: {'train_loss': '0.83499'}; time used = 0.4643561840057373s
epoch 430: {'train_loss': '0.83091'}; time used = 0.4977078437805176s
epoch 435: {'train_loss': '0.83595'}; time used = 0.3966858386993408s
epoch 440: {'train_loss': '0.83998'}; time used = 0.46059346199035645s
epoch 445: {'train_loss': '0.83188'}; time used = 0.4057650566101074s
epoch 450: {'train_loss': '0.83097'}; time used = 0.41109633445739746s
epoch 455: {'train_loss': '0.83223'}; time used = 0.33190274238586426s
epoch 460: {'train_loss': '0.81637'}; time used = 0.3340122699737549s
epoch 465: {'train_loss': '0.83345'}; time used = 0.40376734733581543s
epoch 470: {'train_loss': '0.83357'}; time used = 0.3253660202026367s
epoch 475: {'train_loss': '0.82819'}; time used = 0.3922154903411865s
epoch 480: {'train_loss': '0.82260'}; time used = 0.30594682693481445s
epoch 485: {'train_loss': '0.82328'}; time used = 0.3980698585510254s
epoch 490: {'train_loss': '0.83268'}; time used = 0.32903575897216797s
epoch 495: {'train_loss': '0.82800'}; time used = 0.44758081436157227s
epoch 500: {'train_loss': '0.83294'}; time used = 0.6413004398345947s
Finished training. Time used = 46.431962728500366.
Training classifier using 20.00% nodes...
{'micro': 0.733271804337794, 'macro': 0.7133120613081978, 'samples': 0.7332718043377942, 'weighted': 0.72946086042342}

  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162021.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144686.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160822.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191570.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206619.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149197.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174503.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166998.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114296.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124943.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154450.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174239.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181441.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154399.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174626.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186400.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174323.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8338/10556 [00:00<00:00, 80331.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 84184.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9480/10556 [00:00<00:00, 94795.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 97007.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145000.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140030.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148600.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149917.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150579.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148193.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121310.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128689.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116678.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121711.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122281.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123404.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122506.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148934.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150784.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5983/10556 [00:00<00:00, 57731.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 78180.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152223.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146375.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114489.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107479.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112875.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138798.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6547/10556 [00:00<00:00, 65466.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 63815.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146722.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▊     | 5141/10556 [00:00<00:00, 51409.68it/s] 92%|█████████▏| 9763/10556 [00:00<00:00, 49279.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 47763.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142258.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184517.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7307/10556 [00:00<00:00, 69421.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 86770.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|███▍      | 3577/10556 [00:00<00:00, 35607.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 59304.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170676.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9824/10556 [00:00<00:00, 98236.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 85546.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5109/10556 [00:00<00:00, 48649.95it/s] 98%|█████████▊| 10309/10556 [00:00<00:00, 49608.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 50914.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177810.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190486.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194203.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8245/10556 [00:00<00:00, 77388.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 54268.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127798.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109729.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159138.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184566.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198850.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204978.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197800.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185335.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187997.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118778.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140201.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189798.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202516.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205079.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200240.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191944.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165691.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201835.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203233.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198303.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203657.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207028.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205273.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209176.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192061.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114997.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6857/10556 [00:00<00:00, 68564.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 72381.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140863.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168029.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178715.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177983.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178653.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168301.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119768.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135877.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156092.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185706.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188149.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184039.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180901.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141443.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152392.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151116.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149180.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122558.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140469.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143438.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9714/10556 [00:00<00:00, 97134.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 97450.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████      | 4280/10556 [00:00<00:00, 42205.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 65743.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145895.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183447.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182954.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181638.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185349.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172853.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159229.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201123.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10276/10556 [00:00<00:00, 96417.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 94390.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162138.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184594.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178638.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191762.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169524.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183739.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193274.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187557.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183355.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189360.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180304.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178371.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4436/10556 [00:00<00:00, 38431.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 60575.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9559/10556 [00:00<00:00, 95589.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 100332.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210467.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5753/10556 [00:00<00:00, 56761.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 65403.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5755/10556 [00:00<00:00, 57544.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 61010.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7472/10556 [00:00<00:00, 74716.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 66840.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 25%|██▍       | 2635/10556 [00:00<00:00, 23730.77it/s] 46%|████▌     | 4865/10556 [00:00<00:00, 23281.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 33988.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|███▊      | 4014/10556 [00:00<00:00, 40002.32it/s] 73%|███████▎  | 7726/10556 [00:00<00:00, 38027.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 38830.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10385/10556 [00:00<00:00, 100952.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 97659.00it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7562/10556 [00:00<00:00, 75619.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 78560.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148975.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|████      | 4264/10556 [00:00<00:00, 42109.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 68063.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119527.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154800.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176865.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184498.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181746.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184451.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188853.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187662.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190981.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190087.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194845.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191439.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191685.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179552.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187022.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185224.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180139.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176571.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123979.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141094.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127901.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105751.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154950.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150146.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151903.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151579.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145206.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150483.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151278.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126147.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114175.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154693.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150779.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150428.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151589.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144518.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151698.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144157.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143543.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127480.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154653.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143629.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130735.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108961.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9572/10556 [00:00<00:00, 92902.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 97281.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124233.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136813.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154909.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153546.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151086.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129327.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8531/10556 [00:00<00:00, 85309.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 92951.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150424.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149572.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140337.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147344.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142041.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6471/10556 [00:00<00:00, 64696.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 65130.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6898/10556 [00:00<00:00, 68974.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 70628.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7401/10556 [00:00<00:00, 74009.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 72237.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142239.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142425.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164393.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177741.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174638.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180163.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178905.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167863.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10151/10556 [00:00<00:00, 91577.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 89593.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140926.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144078.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175875.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180040.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183943.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174573.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187839.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181221.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159352.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10093/10556 [00:00<00:00, 100926.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 102314.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148501.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142424.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183405.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191506.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7024/10556 [00:00<00:00, 70234.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 74561.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181809.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124507.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144575.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5602/10556 [00:00<00:00, 48614.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 57169.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174261.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6204/10556 [00:00<00:00, 62035.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 83045.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154373.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9247/10556 [00:00<00:00, 92467.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 84428.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150707.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105718.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105908.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5706/10556 [00:00<00:00, 57055.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 74642.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|███▋      | 3942/10556 [00:00<00:00, 39419.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 68811.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116119.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113232.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143514.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128418.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182071.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168944.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185799.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141122.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170532.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181167.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180423.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186229.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188358.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168649.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156045.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179920.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173697.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168726.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180278.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182738.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187439.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169939.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179078.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176359.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175339.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166600.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177135.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140105.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140355.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115741.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116801.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127080.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154596.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182215.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164677.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173783.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172959.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174960.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151055.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9756/10556 [00:00<00:00, 97556.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 99469.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141807.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175790.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176039.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177692.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168979.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169923.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147083.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150400.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149262.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149799.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149086.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149425.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132245.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127133.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 7017/10556 [00:00<00:00, 66304.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 71330.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154029.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150932.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148437.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153407.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140251.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151478.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121474.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115165.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132866.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150089.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148801.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129929.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142604.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119876.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149526.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147090.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147621.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151601.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149964.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129077.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186650.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187568.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191016.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185803.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186998.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179124.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145387.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144921.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139699.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8928/10556 [00:00<00:00, 83884.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 68956.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10524/10556 [00:00<00:00, 105233.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 99992.03it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119449.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6525/10556 [00:00<00:00, 65249.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 65048.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10000/10556 [00:00<00:00, 99996.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 98890.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10223/10556 [00:00<00:00, 102226.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 103459.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157515.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105428.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 94266.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|████      | 4271/10556 [00:00<00:00, 42512.80it/s] 90%|████████▉ | 9476/10556 [00:00<00:00, 44984.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 46807.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120989.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8567/10556 [00:00<00:00, 85667.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 83450.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186035.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167966.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178379.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185093.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178216.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169780.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186507.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178348.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125043.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192948.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178432.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179590.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184577.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187402.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183013.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175768.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127518.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141863.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187192.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189136.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182957.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167608.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177443.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177974.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178323.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118616.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143005.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151423.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176544.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179950.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182288.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147303.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125091.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146525.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145753.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153539.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174052.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174591.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175453.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141127.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133412.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182830.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176388.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171333.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170242.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167835.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132531.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138549.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130257.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130176.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128787.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162196.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 163130.45it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.38580'}; time used = 0.3583645820617676s
epoch 10: {'train_loss': '1.37174'}; time used = 0.411456823348999s
epoch 15: {'train_loss': '1.36226'}; time used = 0.33714818954467773s
epoch 20: {'train_loss': '1.35692'}; time used = 0.48285508155822754s
epoch 25: {'train_loss': '1.34784'}; time used = 0.40878963470458984s
epoch 30: {'train_loss': '1.34464'}; time used = 0.470613956451416s
epoch 35: {'train_loss': '1.34650'}; time used = 0.46445775032043457s
epoch 40: {'train_loss': '1.34225'}; time used = 0.4659388065338135s
epoch 45: {'train_loss': '1.33700'}; time used = 0.649127721786499s
epoch 50: {'train_loss': '1.33018'}; time used = 0.7292890548706055s
epoch 55: {'train_loss': '1.30291'}; time used = 0.48796868324279785s
epoch 60: {'train_loss': '1.27690'}; time used = 0.35126495361328125s
epoch 65: {'train_loss': '1.26315'}; time used = 0.3688662052154541s
epoch 70: {'train_loss': '1.25309'}; time used = 0.2927513122558594s
epoch 75: {'train_loss': '1.24417'}; time used = 0.2984802722930908s
epoch 80: {'train_loss': '1.23461'}; time used = 0.32533836364746094s
epoch 85: {'train_loss': '1.22980'}; time used = 0.44949841499328613s
epoch 90: {'train_loss': '1.22939'}; time used = 0.3831930160522461s
epoch 95: {'train_loss': '1.22109'}; time used = 0.3382086753845215s
epoch 100: {'train_loss': '1.22585'}; time used = 0.4052572250366211s
epoch 105: {'train_loss': '1.22469'}; time used = 0.5183038711547852s
epoch 110: {'train_loss': '1.22121'}; time used = 0.33697938919067383s
epoch 115: {'train_loss': '1.21498'}; time used = 0.38075971603393555s
epoch 120: {'train_loss': '1.20505'}; time used = 0.3148472309112549s
epoch 125: {'train_loss': '1.21355'}; time used = 0.4334874153137207s
epoch 130: {'train_loss': '1.21290'}; time used = 0.7143425941467285s
epoch 135: {'train_loss': '1.20856'}; time used = 0.9552934169769287s
epoch 140: {'train_loss': '1.20351'}; time used = 0.48093533515930176s
epoch 145: {'train_loss': '1.19807'}; time used = 0.30897951126098633s
epoch 150: {'train_loss': '1.20071'}; time used = 0.30571746826171875s
epoch 155: {'train_loss': '1.20049'}; time used = 0.3466475009918213s
epoch 160: {'train_loss': '1.19090'}; time used = 0.42962050437927246s
epoch 165: {'train_loss': '1.20342'}; time used = 0.38013410568237305s
epoch 170: {'train_loss': '1.19584'}; time used = 0.415372371673584s
epoch 175: {'train_loss': '1.18888'}; time used = 0.3869185447692871s
epoch 180: {'train_loss': '1.19575'}; time used = 0.43218159675598145s
epoch 185: {'train_loss': '1.19068'}; time used = 0.4598221778869629s
epoch 190: {'train_loss': '1.17853'}; time used = 0.46312928199768066s
epoch 195: {'train_loss': '1.18700'}; time used = 0.5701093673706055s
epoch 200: {'train_loss': '1.18035'}; time used = 0.468203067779541s
epoch 205: {'train_loss': '1.17534'}; time used = 0.39234495162963867s
epoch 210: {'train_loss': '1.18679'}; time used = 0.3727717399597168s
epoch 215: {'train_loss': '1.18050'}; time used = 0.3887064456939697s
epoch 220: {'train_loss': '1.17774'}; time used = 0.4399869441986084s
epoch 225: {'train_loss': '1.18440'}; time used = 0.48891496658325195s
epoch 230: {'train_loss': '1.17960'}; time used = 0.5362634658813477s
epoch 235: {'train_loss': '1.17352'}; time used = 0.6633603572845459s
epoch 240: {'train_loss': '1.17767'}; time used = 0.3827040195465088s
epoch 245: {'train_loss': '1.17024'}; time used = 0.33736228942871094s
epoch 250: {'train_loss': '1.17447'}; time used = 0.3354933261871338s
epoch 255: {'train_loss': '1.18014'}; time used = 0.3230624198913574s
epoch 260: {'train_loss': '1.17745'}; time used = 0.33066344261169434s
epoch 265: {'train_loss': '1.18271'}; time used = 0.4824378490447998s
epoch 270: {'train_loss': '1.17346'}; time used = 0.3588738441467285s
epoch 275: {'train_loss': '1.18166'}; time used = 0.41442131996154785s
epoch 280: {'train_loss': '1.17543'}; time used = 0.350186824798584s
epoch 285: {'train_loss': '1.17998'}; time used = 0.38245201110839844s
epoch 290: {'train_loss': '1.16960'}; time used = 0.4820706844329834s
epoch 295: {'train_loss': '1.17732'}; time used = 0.40581202507019043s
epoch 300: {'train_loss': '1.18514'}; time used = 0.4248621463775635s
epoch 305: {'train_loss': '1.17337'}; time used = 0.4110279083251953s
epoch 310: {'train_loss': '1.17090'}; time used = 0.37568092346191406s
epoch 315: {'train_loss': '1.17669'}; time used = 0.3270909786224365s
epoch 320: {'train_loss': '1.16746'}; time used = 0.5875730514526367s
epoch 325: {'train_loss': '1.17778'}; time used = 0.6080582141876221s
epoch 330: {'train_loss': '1.17783'}; time used = 0.6617183685302734s
epoch 335: {'train_loss': '1.17121'}; time used = 0.32283616065979004s
epoch 340: {'train_loss': '1.16393'}; time used = 0.3508470058441162s
epoch 345: {'train_loss': '1.17326'}; time used = 0.31423354148864746s
epoch 350: {'train_loss': '1.17103'}; time used = 0.3616201877593994s
epoch 355: {'train_loss': '1.17673'}; time used = 0.3563053607940674s
epoch 360: {'train_loss': '1.16881'}; time used = 0.35820508003234863s
epoch 365: {'train_loss': '1.16935'}; time used = 0.3996753692626953s
epoch 370: {'train_loss': '1.16765'}; time used = 0.36331868171691895s
epoch 375: {'train_loss': '1.16802'}; time used = 0.33471202850341797s
epoch 380: {'train_loss': '1.16651'}; time used = 0.43602514266967773s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.84582328796387.
Training classifier using 20.00% nodes...
{'micro': 0.43239501615136133, 'macro': 0.2109051616517177, 'samples': 0.43239501615136133, 'weighted': 0.3090883749294171}
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10354/10556 [00:00<00:00, 98157.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 88313.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6100/10556 [00:00<00:00, 60999.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 75167.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8865/10556 [00:00<00:00, 88649.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 88249.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5792/10556 [00:00<00:00, 57719.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 56395.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████▏| 9642/10556 [00:00<00:00, 96412.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 97760.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6709/10556 [00:00<00:00, 60058.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 72779.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7819/10556 [00:00<00:00, 71326.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 73279.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120235.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7374/10556 [00:00<00:00, 71243.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 70293.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107653.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6672/10556 [00:00<00:00, 61793.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 72748.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127095.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10371/10556 [00:00<00:00, 103709.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 103594.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6299/10556 [00:00<00:00, 62986.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 61718.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6211/10556 [00:00<00:00, 62106.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 76160.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117976.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6297/10556 [00:00<00:00, 62966.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 73350.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|███▍      | 3686/10556 [00:00<00:00, 36529.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 50899.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|███▏      | 3397/10556 [00:00<00:00, 33969.71it/s] 83%|████████▎ | 8719/10556 [00:00<00:00, 38104.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 49021.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|████▍     | 4641/10556 [00:00<00:00, 33302.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 45237.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114143.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|███▍      | 3660/10556 [00:00<00:00, 36596.37it/s] 63%|██████▎   | 6685/10556 [00:00<00:00, 34225.94it/s] 93%|█████████▎| 9861/10556 [00:00<00:00, 32722.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 31722.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|███▌      | 3711/10556 [00:00<00:00, 36815.72it/s] 94%|█████████▍| 9971/10556 [00:00<00:00, 41824.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 47342.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|██▉       | 3072/10556 [00:00<00:00, 30718.78it/s] 76%|███████▋  | 8075/10556 [00:00<00:00, 34740.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 43453.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110932.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7787/10556 [00:00<00:00, 77090.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 64395.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110652.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▊   | 7253/10556 [00:00<00:00, 70579.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 73977.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118560.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5745/10556 [00:00<00:00, 57449.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 71842.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5793/10556 [00:00<00:00, 53952.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 58126.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120687.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10413/10556 [00:00<00:00, 104128.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 104006.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9592/10556 [00:00<00:00, 92820.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 88242.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6152/10556 [00:00<00:00, 60162.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 74433.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115045.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110838.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9817/10556 [00:00<00:00, 98162.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 98234.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5218/10556 [00:00<00:00, 52147.72it/s] 93%|█████████▎| 9834/10556 [00:00<00:00, 50193.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 51091.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7368/10556 [00:00<00:00, 73675.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 68046.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114455.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115207.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6411/10556 [00:00<00:00, 63840.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 75610.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5743/10556 [00:00<00:00, 57425.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 69912.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7401/10556 [00:00<00:00, 74007.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 82864.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8368/10556 [00:00<00:00, 77735.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 82239.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9320/10556 [00:00<00:00, 93192.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 89547.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107558.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7090/10556 [00:00<00:00, 70899.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 79275.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4824/10556 [00:00<00:00, 47979.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 54618.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|███████▉  | 8424/10556 [00:00<00:00, 84234.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 89012.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7227/10556 [00:00<00:00, 72268.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 81381.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109274.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8495/10556 [00:00<00:00, 84947.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 88590.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106861.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110741.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6887/10556 [00:00<00:00, 68869.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 73030.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6695/10556 [00:00<00:00, 66949.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 60099.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 102820.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9131/10556 [00:00<00:00, 90504.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 88694.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118203.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7083/10556 [00:00<00:00, 70828.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 81900.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9759/10556 [00:00<00:00, 94572.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 52015.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6448/10556 [00:00<00:00, 64479.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 66380.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4957/10556 [00:00<00:00, 49567.21it/s] 93%|█████████▎| 9820/10556 [00:00<00:00, 49281.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 47462.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107646.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10465/10556 [00:00<00:00, 104642.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 104312.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6149/10556 [00:00<00:00, 61485.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 61363.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119755.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4525/10556 [00:00<00:00, 45249.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 57352.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119497.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119969.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9523/10556 [00:00<00:00, 95226.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 75762.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6519/10556 [00:00<00:00, 65189.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 69900.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105446.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 101763.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8679/10556 [00:00<00:00, 86788.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 87815.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▊  | 8292/10556 [00:00<00:00, 82914.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 88504.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115546.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114117.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114502.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10547/10556 [00:00<00:00, 105465.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 105093.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8606/10556 [00:00<00:00, 86055.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 80966.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119142.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6284/10556 [00:00<00:00, 62839.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 75351.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▊  | 8296/10556 [00:00<00:00, 74707.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 76833.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10365/10556 [00:00<00:00, 103644.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 103418.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116676.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6615/10556 [00:00<00:00, 66143.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 77984.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112498.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████▏| 9635/10556 [00:00<00:00, 96346.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 93382.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9050/10556 [00:00<00:00, 90492.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 93526.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7436/10556 [00:00<00:00, 74356.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 63785.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116686.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111614.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119117.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5711/10556 [00:00<00:00, 44959.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 47478.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114317.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9382/10556 [00:00<00:00, 93812.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 84384.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5100/10556 [00:00<00:00, 50998.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 70356.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5807/10556 [00:00<00:00, 56612.07it/s] 93%|█████████▎| 9803/10556 [00:00<00:00, 50321.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 49289.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5188/10556 [00:00<00:00, 51879.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 54922.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9604/10556 [00:00<00:00, 96033.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 96694.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10447/10556 [00:00<00:00, 104465.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 104228.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110586.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10014/10556 [00:00<00:00, 100139.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 92783.68it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|█████     | 5315/10556 [00:00<00:00, 53146.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 69303.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6353/10556 [00:00<00:00, 56070.92it/s]100%|█████████▉| 10551/10556 [00:00<00:00, 50940.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 49395.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5147/10556 [00:00<00:00, 46059.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 51592.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5641/10556 [00:00<00:00, 51651.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 52881.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 100436.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6322/10556 [00:00<00:00, 63216.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 61378.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8704/10556 [00:00<00:00, 87036.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 91633.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110534.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6634/10556 [00:00<00:00, 66336.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 75821.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8108/10556 [00:00<00:00, 81075.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 84716.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4413/10556 [00:00<00:00, 42659.15it/s] 85%|████████▍ | 8952/10556 [00:00<00:00, 42161.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 45848.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5773/10556 [00:00<00:00, 47855.18it/s] 94%|█████████▍| 9900/10556 [00:00<00:00, 45667.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 46491.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|███▌      | 3709/10556 [00:00<00:00, 37089.06it/s] 96%|█████████▌| 10081/10556 [00:00<00:00, 42004.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 48443.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6414/10556 [00:00<00:00, 64137.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 76898.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7837/10556 [00:00<00:00, 78369.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 86237.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7186/10556 [00:00<00:00, 68382.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 75444.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|███▋      | 3944/10556 [00:00<00:00, 39435.71it/s] 57%|█████▋    | 5995/10556 [00:00<00:00, 30661.79it/s] 77%|███████▋  | 8115/10556 [00:00<00:00, 26748.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 27162.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 17%|█▋        | 1783/10556 [00:00<00:00, 15709.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 54840.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|████▍     | 4691/10556 [00:00<00:00, 46906.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 66584.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7189/10556 [00:00<00:00, 69496.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 66039.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115047.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|███▏      | 3397/10556 [00:00<00:00, 28505.57it/s] 75%|███████▌  | 7922/10556 [00:00<00:00, 32064.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 43657.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6299/10556 [00:00<00:00, 62984.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 77646.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6142/10556 [00:00<00:00, 61416.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 67739.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10226/10556 [00:00<00:00, 102258.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 101309.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7176/10556 [00:00<00:00, 71758.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 62509.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8501/10556 [00:00<00:00, 85009.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 89262.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6012/10556 [00:00<00:00, 55082.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 57290.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6490/10556 [00:00<00:00, 63274.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 56578.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6105/10556 [00:00<00:00, 61049.77it/s] 98%|█████████▊| 10363/10556 [00:00<00:00, 53770.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 51074.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▉      | 4100/10556 [00:00<00:00, 40999.94it/s] 93%|█████████▎| 9810/10556 [00:00<00:00, 44787.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 50953.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9963/10556 [00:00<00:00, 99625.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 100285.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9107/10556 [00:00<00:00, 91064.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 94115.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4546/10556 [00:00<00:00, 45459.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 62721.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5594/10556 [00:00<00:00, 55936.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 72601.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████▏     | 4369/10556 [00:00<00:00, 41299.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 61380.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10365/10556 [00:00<00:00, 103645.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 103306.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108023.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4976/10556 [00:00<00:00, 49756.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 59546.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6393/10556 [00:00<00:00, 63927.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 77570.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 7019/10556 [00:00<00:00, 70184.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 78273.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10212/10556 [00:00<00:00, 102113.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 102237.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9255/10556 [00:00<00:00, 92545.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 91499.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9176/10556 [00:00<00:00, 91752.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 94488.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120668.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119022.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120117.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6716/10556 [00:00<00:00, 67156.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 75905.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119690.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118270.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120006.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122602.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122341.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5990/10556 [00:00<00:00, 59898.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 65587.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 95394.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7492/10556 [00:00<00:00, 74915.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 83335.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111734.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▊   | 7257/10556 [00:00<00:00, 72565.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 79847.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8703/10556 [00:00<00:00, 72383.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 73120.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7968/10556 [00:00<00:00, 76873.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 79807.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7401/10556 [00:00<00:00, 74009.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 76993.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5249/10556 [00:00<00:00, 52486.80it/s] 96%|█████████▋| 10175/10556 [00:00<00:00, 51473.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 51818.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8994/10556 [00:00<00:00, 89938.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 92724.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7707/10556 [00:00<00:00, 77065.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 84935.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109561.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|█████     | 5321/10556 [00:00<00:00, 53208.02it/s] 97%|█████████▋| 10288/10556 [00:00<00:00, 51532.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 51065.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8745/10556 [00:00<00:00, 87449.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 91777.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8698/10556 [00:00<00:00, 86974.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 90535.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5238/10556 [00:00<00:00, 52376.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 61874.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5448/10556 [00:00<00:00, 54476.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 61788.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5913/10556 [00:00<00:00, 59128.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 75519.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 97038.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117605.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120469.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114575.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119882.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10378/10556 [00:00<00:00, 103651.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 101477.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10230/10556 [00:00<00:00, 102293.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 102462.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108051.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111228.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105468.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5943/10556 [00:00<00:00, 59426.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 72195.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9168/10556 [00:00<00:00, 91675.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 86531.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118594.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9310/10556 [00:00<00:00, 93099.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 80750.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111523.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111144.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106788.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116749.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113497.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8804/10556 [00:00<00:00, 88039.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 67286.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117079.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8164/10556 [00:00<00:00, 81567.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 71955.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4563/10556 [00:00<00:00, 43958.60it/s] 89%|████████▉ | 9444/10556 [00:00<00:00, 45309.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 48973.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4878/10556 [00:00<00:00, 48779.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 50815.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6039/10556 [00:00<00:00, 60387.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 55182.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5797/10556 [00:00<00:00, 52255.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 66690.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6756/10556 [00:00<00:00, 64936.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 73628.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7394/10556 [00:00<00:00, 63710.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 58754.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|██▉       | 3097/10556 [00:00<00:00, 30965.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 64211.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7388/10556 [00:00<00:00, 73879.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 83439.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117105.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6271/10556 [00:00<00:00, 62706.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 77723.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120017.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 27%|██▋       | 2833/10556 [00:00<00:00, 24212.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 50239.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5915/10556 [00:00<00:00, 59148.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 57351.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▋     | 4900/10556 [00:00<00:00, 47298.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 58738.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7466/10556 [00:00<00:00, 64977.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 56005.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109083.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112150.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6249/10556 [00:00<00:00, 62487.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 71537.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9252/10556 [00:00<00:00, 92517.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 95147.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120595.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117325.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118340.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117283.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▎ | 8833/10556 [00:00<00:00, 88322.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 92113.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119182.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115793.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9803/10556 [00:00<00:00, 98022.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 98634.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112248.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119524.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6488/10556 [00:00<00:00, 64875.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 63790.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9816/10556 [00:00<00:00, 98153.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 98996.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7115/10556 [00:00<00:00, 71147.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 73256.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6517/10556 [00:00<00:00, 60762.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 60338.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7025/10556 [00:00<00:00, 70247.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 69691.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7171/10556 [00:00<00:00, 71699.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 70214.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████▏  | 7530/10556 [00:00<00:00, 75100.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 69277.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8045/10556 [00:00<00:00, 80448.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 85822.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120118.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6489/10556 [00:00<00:00, 64886.81it/s] 92%|█████████▏| 9752/10556 [00:00<00:00, 48677.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 46267.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6442/10556 [00:00<00:00, 64416.07it/s] 87%|████████▋ | 9190/10556 [00:00<00:00, 45732.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 44857.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9461/10556 [00:00<00:00, 94605.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 86157.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|███▍      | 3624/10556 [00:00<00:00, 33814.35it/s] 95%|█████████▌| 10055/10556 [00:00<00:00, 39422.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 49272.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7871/10556 [00:00<00:00, 73641.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 78547.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7397/10556 [00:00<00:00, 73969.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 74701.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8483/10556 [00:00<00:00, 84825.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 77454.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████▏    | 5413/10556 [00:00<00:00, 54122.83it/s] 99%|█████████▉| 10442/10556 [00:00<00:00, 52910.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 52223.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6755/10556 [00:00<00:00, 67547.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 67414.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110633.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4823/10556 [00:00<00:00, 48209.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 59719.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10246/10556 [00:00<00:00, 102454.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 102621.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9236/10556 [00:00<00:00, 68719.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 67812.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8978/10556 [00:00<00:00, 89777.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 92724.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109965.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6982/10556 [00:00<00:00, 69818.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 65820.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9566/10556 [00:00<00:00, 95653.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 97416.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9145/10556 [00:00<00:00, 91443.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 94233.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6620/10556 [00:00<00:00, 66195.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 68301.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7829/10556 [00:00<00:00, 78283.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 84408.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115821.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6628/10556 [00:00<00:00, 61627.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 72879.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6119/10556 [00:00<00:00, 60701.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 61020.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5363/10556 [00:00<00:00, 53623.15it/s] 72%|███████▏  | 7585/10556 [00:00<00:00, 37193.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 37298.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4918/10556 [00:00<00:00, 49177.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 57967.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117003.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9740/10556 [00:00<00:00, 97388.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 94062.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5955/10556 [00:00<00:00, 56412.62it/s] 85%|████████▌ | 9019/10556 [00:00<00:00, 43570.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 40574.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10383/10556 [00:00<00:00, 101276.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 101293.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|████▍     | 4664/10556 [00:00<00:00, 44842.31it/s] 99%|█████████▉| 10439/10556 [00:00<00:00, 45666.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 46369.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5480/10556 [00:00<00:00, 54799.40it/s] 85%|████████▌ | 9013/10556 [00:00<00:00, 47024.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 45065.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113873.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6263/10556 [00:00<00:00, 59883.80it/s] 98%|█████████▊| 10379/10556 [00:00<00:00, 52631.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 49384.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4958/10556 [00:00<00:00, 46456.68it/s] 71%|███████   | 7503/10556 [00:00<00:00, 37033.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 42121.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10235/10556 [00:00<00:00, 102346.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 101985.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 26%|██▋       | 2792/10556 [00:00<00:00, 27692.11it/s] 76%|███████▌  | 8046/10556 [00:00<00:00, 32224.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 43357.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6026/10556 [00:00<00:00, 60259.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 74468.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113992.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6513/10556 [00:00<00:00, 64048.16it/s] 96%|█████████▌| 10123/10556 [00:00<00:00, 51975.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 51362.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6448/10556 [00:00<00:00, 64476.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 75266.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114823.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▎ | 8815/10556 [00:00<00:00, 88144.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 91668.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|███▏      | 3352/10556 [00:00<00:00, 33515.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 53563.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6150/10556 [00:00<00:00, 61499.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 65907.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▎| 9891/10556 [00:00<00:00, 98908.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 99853.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|███████▉  | 8444/10556 [00:00<00:00, 76784.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 52717.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118226.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6222/10556 [00:00<00:00, 62217.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 63900.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5696/10556 [00:00<00:00, 56746.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 56775.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6280/10556 [00:00<00:00, 59358.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 72820.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6592/10556 [00:00<00:00, 65917.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 78337.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7853/10556 [00:00<00:00, 77050.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 70217.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8491/10556 [00:00<00:00, 84904.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 85530.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9363/10556 [00:00<00:00, 93628.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 95958.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6886/10556 [00:00<00:00, 68856.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 73928.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 97436.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|███▋      | 3838/10556 [00:00<00:00, 37131.00it/s] 93%|█████████▎| 9818/10556 [00:00<00:00, 41895.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 48454.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110021.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5078/10556 [00:00<00:00, 47260.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 57288.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5485/10556 [00:00<00:00, 54843.25it/s] 72%|███████▏  | 7630/10556 [00:00<00:00, 34565.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 40038.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6934/10556 [00:00<00:00, 69334.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 68115.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 101822.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9555/10556 [00:00<00:00, 95546.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 68316.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6936/10556 [00:00<00:00, 69358.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 74569.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 23%|██▎       | 2430/10556 [00:00<00:00, 24297.65it/s] 49%|████▉     | 5159/10556 [00:00<00:00, 25123.72it/s] 97%|█████████▋| 10225/10556 [00:00<00:00, 29549.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 34713.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9093/10556 [00:00<00:00, 90926.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 93138.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6677/10556 [00:00<00:00, 62732.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 60921.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9265/10556 [00:00<00:00, 92647.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 95418.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107722.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117286.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6394/10556 [00:00<00:00, 63936.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 75171.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6035/10556 [00:00<00:00, 58783.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 69476.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106876.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7980/10556 [00:00<00:00, 79799.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 86957.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120766.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121888.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6239/10556 [00:00<00:00, 62387.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 75490.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10546/10556 [00:00<00:00, 105453.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 105020.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7463/10556 [00:00<00:00, 74627.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 82834.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6488/10556 [00:00<00:00, 64875.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 62425.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8218/10556 [00:00<00:00, 82178.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 89181.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 104107.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6924/10556 [00:00<00:00, 66756.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 64474.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9601/10556 [00:00<00:00, 86051.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 77835.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▌| 10057/10556 [00:00<00:00, 100566.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 100942.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6401/10556 [00:00<00:00, 64009.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 63443.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6253/10556 [00:00<00:00, 62529.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 61162.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9062/10556 [00:00<00:00, 90617.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 85454.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8487/10556 [00:00<00:00, 84867.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 76534.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10500/10556 [00:00<00:00, 104999.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 104711.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10206/10556 [00:00<00:00, 102052.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 102336.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10307/10556 [00:00<00:00, 103067.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 103134.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10410/10556 [00:00<00:00, 85807.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 86041.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9080/10556 [00:00<00:00, 90793.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 93785.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8370/10556 [00:00<00:00, 83698.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 89029.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119462.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152459.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172158.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174527.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169324.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179053.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179367.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175178.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177670.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182306.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144440.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186013.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187406.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140457.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107468.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115074.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132938.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159087.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194910.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195658.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197244.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198043.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▋  | 8060/10556 [00:00<00:00, 79435.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 62334.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6856/10556 [00:00<00:00, 68558.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 60264.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118842.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186324.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6792/10556 [00:00<00:00, 62435.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 63354.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191613.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175864.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 163167.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|███▍      | 3682/10556 [00:00<00:00, 36819.95it/s] 76%|███████▌  | 7982/10556 [00:00<00:00, 38478.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 48274.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215902.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123994.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8198/10556 [00:00<00:00, 80726.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 66151.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▋| 10164/10556 [00:00<00:00, 101635.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 103539.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200783.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189988.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9947/10556 [00:00<00:00, 99464.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 94201.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6979/10556 [00:00<00:00, 69781.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 69941.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112718.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160930.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173727.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176156.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194005.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191839.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116587.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190908.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204195.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203010.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185272.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194198.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199205.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197742.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199696.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202980.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181121.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205771.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207501.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202772.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208284.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209074.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136940.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200594.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181129.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171110.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146673.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126244.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184735.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131844.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187650.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178297.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217159.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202704.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209891.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191509.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183386.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176527.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118744.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205722.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196126.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202327.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158853.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190106.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191134.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181232.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189525.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178980.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159734.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197043.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197358.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204790.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192951.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196749.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166119.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9463/10556 [00:00<00:00, 94622.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 85522.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156848.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193658.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169858.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154721.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167373.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182302.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185848.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181110.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183076.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6717/10556 [00:00<00:00, 65593.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 76521.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137965.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144418.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143999.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138809.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142779.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149271.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132515.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108113.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123461.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148602.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172952.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 163825.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123243.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121884.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115295.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174183.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5687/10556 [00:00<00:00, 53098.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 64869.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5819/10556 [00:00<00:00, 51684.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 52092.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5590/10556 [00:00<00:00, 55898.05it/s] 80%|███████▉  | 8439/10556 [00:00<00:00, 43377.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 44593.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141334.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|███▋      | 3958/10556 [00:00<00:00, 36561.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 61549.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124246.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7422/10556 [00:00<00:00, 74217.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 63684.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▉      | 4153/10556 [00:00<00:00, 37586.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 56841.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123161.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 31%|███       | 3288/10556 [00:00<00:00, 30466.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 58952.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 94931.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7177/10556 [00:00<00:00, 71764.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 84879.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137234.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143110.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137100.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138570.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134378.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140525.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135815.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138948.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139333.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136467.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129137.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148538.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147495.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136374.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142490.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167013.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171492.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9413/10556 [00:00<00:00, 94122.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 84444.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▌| 10057/10556 [00:00<00:00, 100568.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 100829.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115968.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8852/10556 [00:00<00:00, 88512.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 88128.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10129/10556 [00:00<00:00, 101285.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 101199.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110580.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10408/10556 [00:00<00:00, 99627.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 97047.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████      | 4317/10556 [00:00<00:00, 39924.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 55984.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10509/10556 [00:00<00:00, 105086.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 104742.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170521.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108806.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111540.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7622/10556 [00:00<00:00, 74671.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 72607.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6769/10556 [00:00<00:00, 66453.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 67524.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117271.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121166.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120506.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121392.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6367/10556 [00:00<00:00, 63403.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 76448.11it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 0.92498779296875s
epoch 10: {'train_loss': '1.38629'}; time used = 0.6686875820159912s
epoch 15: {'train_loss': '1.38629'}; time used = 0.6485025882720947s
epoch 20: {'train_loss': '1.38629'}; time used = 0.9451932907104492s
epoch 25: {'train_loss': '1.38629'}; time used = 1.126044750213623s
epoch 30: {'train_loss': '1.38629'}; time used = 0.7289752960205078s
epoch 35: {'train_loss': '1.38629'}; time used = 0.6187796592712402s
epoch 40: {'train_loss': '1.38629'}; time used = 0.7313282489776611s
epoch 45: {'train_loss': '1.38629'}; time used = 0.7117533683776855s
epoch 50: {'train_loss': '1.38629'}; time used = 0.7561414241790771s
epoch 55: {'train_loss': '1.38629'}; time used = 0.6016926765441895s
epoch 60: {'train_loss': '1.38629'}; time used = 0.7390496730804443s
epoch 65: {'train_loss': '1.38629'}; time used = 0.9207658767700195s
epoch 70: {'train_loss': '1.38629'}; time used = 0.659837007522583s
epoch 75: {'train_loss': '1.38629'}; time used = 0.6377997398376465s
epoch 80: {'train_loss': '1.38629'}; time used = 0.5529685020446777s
epoch 85: {'train_loss': '1.38629'}; time used = 0.6413314342498779s
epoch 90: {'train_loss': '1.38629'}; time used = 0.587843656539917s
epoch 95: {'train_loss': '1.38629'}; time used = 0.6134016513824463s
epoch 100: {'train_loss': '1.38629'}; time used = 0.8559694290161133s
epoch 105: {'train_loss': '1.38629'}; time used = 0.6516017913818359s
epoch 110: {'train_loss': '1.38629'}; time used = 1.0005507469177246s
epoch 115: {'train_loss': '1.38629'}; time used = 0.7139925956726074s
epoch 120: {'train_loss': '1.38629'}; time used = 1.0503368377685547s
epoch 125: {'train_loss': '1.38629'}; time used = 1.1120707988739014s
epoch 130: {'train_loss': '1.38629'}; time used = 0.7906901836395264s
epoch 135: {'train_loss': '1.38629'}; time used = 0.9289097785949707s
epoch 140: {'train_loss': '1.38629'}; time used = 0.8257129192352295s
epoch 145: {'train_loss': '1.38629'}; time used = 0.7507274150848389s
epoch 150: {'train_loss': '1.38629'}; time used = 0.6219213008880615s
epoch 155: {'train_loss': '1.38629'}; time used = 0.5237834453582764s
epoch 160: {'train_loss': '1.38629'}; time used = 0.5897963047027588s
epoch 165: {'train_loss': '1.38629'}; time used = 0.6885707378387451s
epoch 170: {'train_loss': '1.38629'}; time used = 0.7793912887573242s
epoch 175: {'train_loss': '1.38629'}; time used = 0.8792009353637695s
epoch 180: {'train_loss': '1.38629'}; time used = 0.5903050899505615s
epoch 185: {'train_loss': '1.38629'}; time used = 0.5419731140136719s
epoch 190: {'train_loss': '1.38629'}; time used = 0.6670732498168945s
epoch 195: {'train_loss': '1.38629'}; time used = 0.5320360660552979s
epoch 200: {'train_loss': '1.38629'}; time used = 0.8854706287384033s
epoch 205: {'train_loss': '1.38629'}; time used = 0.9089531898498535s
epoch 210: {'train_loss': '1.38629'}; time used = 0.695594310760498s
epoch 215: {'train_loss': '1.38629'}; time used = 0.822070837020874s
epoch 220: {'train_loss': '1.38629'}; time used = 0.5790605545043945s
epoch 225: {'train_loss': '1.38629'}; time used = 0.5492560863494873s
epoch 230: {'train_loss': '1.38629'}; time used = 0.6733689308166504s
epoch 235: {'train_loss': '1.38629'}; time used = 0.8187925815582275s
epoch 240: {'train_loss': '1.38629'}; time used = 0.9379169940948486s
epoch 245: {'train_loss': '1.38629'}; time used = 0.8564715385437012s
epoch 250: {'train_loss': '1.38629'}; time used = 0.7284016609191895s
epoch 255: {'train_loss': '1.38629'}; time used = 0.7179667949676514s
epoch 260: {'train_loss': '1.38629'}; time used = 0.8684067726135254s
epoch 265: {'train_loss': '1.38629'}; time used = 0.8106503486633301s
epoch 270: {'train_loss': '1.38629'}; time used = 1.0935406684875488s
epoch 275: {'train_loss': '1.38629'}; time used = 0.8478374481201172s
epoch 280: {'train_loss': '1.38629'}; time used = 0.7797820568084717s
epoch 285: {'train_loss': '1.38629'}; time used = 0.8090038299560547s
epoch 290: {'train_loss': '1.38629'}; time used = 0.7288801670074463s
epoch 295: {'train_loss': '1.38629'}; time used = 0.8344345092773438s
epoch 300: {'train_loss': '1.38629'}; time used = 0.9291119575500488s
epoch 305: {'train_loss': '1.38629'}; time used = 0.8822762966156006s
epoch 310: {'train_loss': '1.38629'}; time used = 0.6619269847869873s
epoch 315: {'train_loss': '1.38629'}; time used = 0.6023483276367188s
epoch 320: {'train_loss': '1.38629'}; time used = 0.7795140743255615s
epoch 325: {'train_loss': '1.38629'}; time used = 0.7888119220733643s
epoch 330: {'train_loss': '1.38629'}; time used = 0.5947835445404053s
epoch 335: {'train_loss': '1.38629'}; time used = 0.4501230716705322s
epoch 340: {'train_loss': '1.38629'}; time used = 0.34351634979248047s
epoch 345: {'train_loss': '1.38629'}; time used = 0.34916210174560547s
epoch 350: {'train_loss': '1.38629'}; time used = 0.4370393753051758s
epoch 355: {'train_loss': '1.38629'}; time used = 0.5440943241119385s
epoch 360: {'train_loss': '1.38629'}; time used = 0.47721052169799805s
epoch 365: {'train_loss': '1.38629'}; time used = 0.6278171539306641s
epoch 370: {'train_loss': '1.38629'}; time used = 0.5260903835296631s
epoch 375: {'train_loss': '1.38629'}; time used = 0.37482428550720215s
epoch 380: {'train_loss': '1.38629'}; time used = 0.3284270763397217s
epoch 385: {'train_loss': '1.38629'}; time used = 0.30112504959106445s
epoch 390: {'train_loss': '1.38629'}; time used = 0.2905433177947998s
epoch 395: {'train_loss': '1.38629'}; time used = 0.31479716300964355s
epoch 400: {'train_loss': '1.38629'}; time used = 0.3828856945037842s
epoch 405: {'train_loss': '1.38629'}; time used = 0.2956852912902832s
epoch 410: {'train_loss': '1.38629'}; time used = 0.3782691955566406s
epoch 415: {'train_loss': '1.38629'}; time used = 0.31350088119506836s
epoch 420: {'train_loss': '1.38629'}; time used = 0.3268556594848633s
epoch 425: {'train_loss': '1.38629'}; time used = 0.30901122093200684s
epoch 430: {'train_loss': '1.38629'}; time used = 0.41666603088378906s
epoch 435: {'train_loss': '1.38629'}; time used = 0.3334927558898926s
epoch 440: {'train_loss': '1.38629'}; time used = 0.46776366233825684s
epoch 445: {'train_loss': '1.38629'}; time used = 0.44916677474975586s
epoch 450: {'train_loss': '1.38629'}; time used = 0.41108250617980957s
epoch 455: {'train_loss': '1.38629'}; time used = 0.8050928115844727s
epoch 460: {'train_loss': '1.38629'}; time used = 0.7323887348175049s
epoch 465: {'train_loss': '1.38629'}; time used = 0.6319377422332764s
epoch 470: {'train_loss': '1.38629'}; time used = 0.4100456237792969s
epoch 475: {'train_loss': '1.38629'}; time used = 0.4207580089569092s
epoch 480: {'train_loss': '1.38629'}; time used = 0.390669584274292s
epoch 485: {'train_loss': '1.38629'}; time used = 0.5461781024932861s
epoch 490: {'train_loss': '1.38629'}; time used = 0.6467247009277344s
epoch 495: {'train_loss': '1.38629'}; time used = 0.5964536666870117s
epoch 500: {'train_loss': '1.38629'}; time used = 0.5249414443969727s
Finished training. Time used = 76.18733954429626.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}

Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198818.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172380.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179186.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173130.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128022.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147940.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147281.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129866.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146471.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122468.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10332/10556 [00:00<00:00, 103316.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 103771.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150840.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140863.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146042.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|███▉      | 4198/10556 [00:00<00:00, 41653.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 61068.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150301.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7295/10556 [00:00<00:00, 72943.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 78945.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10523/10556 [00:00<00:00, 105229.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 104780.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|███▋      | 3956/10556 [00:00<00:00, 38615.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 60383.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9800/10556 [00:00<00:00, 97993.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 87220.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 30%|██▉       | 3158/10556 [00:00<00:00, 29294.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 58048.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179947.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175076.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178288.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6936/10556 [00:00<00:00, 69357.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 64716.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6598/10556 [00:00<00:00, 62545.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 62946.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168242.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106832.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132852.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203189.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185939.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184325.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171985.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4464/10556 [00:00<00:00, 38856.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 65091.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193114.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201838.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179813.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125097.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202632.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155691.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166387.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174698.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173992.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175252.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141435.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111019.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180381.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172553.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170618.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174639.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164980.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176338.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165049.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160831.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158122.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168711.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179301.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176205.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177058.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140432.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151104.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152935.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148463.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147736.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147591.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107315.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139904.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151802.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148176.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143234.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142000.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148463.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147513.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111888.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7726/10556 [00:00<00:00, 77258.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 77033.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9175/10556 [00:00<00:00, 91743.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 90035.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9152/10556 [00:00<00:00, 91513.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 91389.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10382/10556 [00:00<00:00, 103819.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 104246.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175100.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108126.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127407.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118655.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155031.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152275.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177287.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176474.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150580.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122236.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10132/10556 [00:00<00:00, 95065.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 95097.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169882.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183132.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8270/10556 [00:00<00:00, 82696.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 83589.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4982/10556 [00:00<00:00, 49815.77it/s] 66%|██████▌   | 6931/10556 [00:00<00:00, 33962.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 36114.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8769/10556 [00:00<00:00, 87685.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 80497.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117095.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10005/10556 [00:00<00:00, 99802.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 96339.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121345.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119945.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122323.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115448.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10456/10556 [00:00<00:00, 104556.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 93319.72it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6512/10556 [00:00<00:00, 65119.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 87313.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7906/10556 [00:00<00:00, 79057.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 79441.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173353.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187420.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165002.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158881.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179673.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164184.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131178.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115874.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9720/10556 [00:00<00:00, 97199.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 99315.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189532.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175074.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 163255.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179396.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191243.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177275.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153961.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120223.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117415.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137674.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142218.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174790.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162399.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172483.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171797.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132159.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108422.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123450.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152833.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164924.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169851.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168049.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137582.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7616/10556 [00:00<00:00, 76157.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 84593.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133379.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131604.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145712.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157302.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162666.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10398/10556 [00:00<00:00, 103971.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 99818.90it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136893.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174942.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181338.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164859.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179806.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166069.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162339.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151379.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187693.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169849.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182756.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174688.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169689.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166859.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176165.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175554.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174825.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112482.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105830.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179886.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166700.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180235.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171789.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172176.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162322.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174915.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122343.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141627.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169937.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179787.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 161938.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132493.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8496/10556 [00:00<00:00, 84954.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 84769.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9495/10556 [00:00<00:00, 94942.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 95680.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110578.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7983/10556 [00:00<00:00, 68953.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 62001.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176831.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127787.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7926/10556 [00:00<00:00, 76835.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 58043.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9379/10556 [00:00<00:00, 93785.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 95777.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7716/10556 [00:00<00:00, 77157.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 86027.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178276.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185287.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████      | 4327/10556 [00:00<00:00, 42239.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 59798.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184501.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 100026.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8505/10556 [00:00<00:00, 71477.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 67203.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113748.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174410.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164358.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140017.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|███████▉  | 8401/10556 [00:00<00:00, 84006.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 94714.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179719.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122653.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127831.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168287.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171591.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175816.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144781.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179190.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164312.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176467.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170421.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187798.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151431.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164376.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164761.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150345.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10315/10556 [00:00<00:00, 103145.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 103436.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113291.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127349.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151846.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175143.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173996.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170178.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162238.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 9983/10556 [00:00<00:00, 99822.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 99270.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110535.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165094.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159510.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144005.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173102.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174494.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173603.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175312.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169707.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172707.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145819.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141221.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138911.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129713.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145132.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9141/10556 [00:00<00:00, 88833.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 93370.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142468.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147698.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▌| 10047/10556 [00:00<00:00, 100467.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 99909.23it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122055.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134231.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10401/10556 [00:00<00:00, 104009.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 101738.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6589/10556 [00:00<00:00, 65888.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 68840.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4877/10556 [00:00<00:00, 48764.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 65202.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9596/10556 [00:00<00:00, 95952.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 96111.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106332.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136821.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167477.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176161.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171841.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171017.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176446.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168702.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172973.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181190.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167311.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165372.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172403.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165477.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175104.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139718.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146445.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119408.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9839/10556 [00:00<00:00, 98389.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 90849.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111985.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8847/10556 [00:00<00:00, 88468.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 93068.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130877.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114314.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124611.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159372.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5018/10556 [00:00<00:00, 50176.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 64561.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156155.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141354.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9613/10556 [00:00<00:00, 96126.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 97407.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123006.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|███▉      | 4184/10556 [00:00<00:00, 41839.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 56388.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129292.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7094/10556 [00:00<00:00, 70938.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 78337.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108906.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9326/10556 [00:00<00:00, 93252.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 95644.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126876.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146642.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188585.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170316.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182735.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173433.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142309.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111674.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183367.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190677.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188709.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145125.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173831.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176348.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9111/10556 [00:00<00:00, 91102.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 94171.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139000.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147013.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131452.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173751.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174425.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142131.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160746.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126254.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160783.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 161750.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165849.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175028.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175423.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133290.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149203.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150400.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116534.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129683.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144585.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148407.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149613.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143254.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148226.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129583.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111969.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151241.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146535.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147171.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162783.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168188.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162998.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10474/10556 [00:00<00:00, 104739.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 104757.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169793.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188128.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152505.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118522.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9961/10556 [00:00<00:00, 99609.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 98851.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144686.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143926.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149254.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105721.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151173.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120904.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146576.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144496.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130534.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112123.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9744/10556 [00:00<00:00, 97434.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 97497.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135698.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147779.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10485/10556 [00:00<00:00, 104848.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 104328.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121602.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140614.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6979/10556 [00:00<00:00, 69789.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 86865.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126056.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136042.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9494/10556 [00:00<00:00, 94933.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 84070.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151249.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6798/10556 [00:00<00:00, 67976.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 55219.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8245/10556 [00:00<00:00, 79348.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 85954.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122236.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133316.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10547/10556 [00:00<00:00, 105468.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 105161.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8680/10556 [00:00<00:00, 80782.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 71108.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116756.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7159/10556 [00:00<00:00, 71587.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 82755.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|█████     | 5286/10556 [00:00<00:00, 52856.14it/s] 97%|█████████▋| 10274/10556 [00:00<00:00, 51605.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 50808.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8250/10556 [00:00<00:00, 82494.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 88508.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7190/10556 [00:00<00:00, 71895.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 82328.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119685.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5172/10556 [00:00<00:00, 51354.57it/s] 97%|█████████▋| 10281/10556 [00:00<00:00, 51273.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 51119.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113118.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7666/10556 [00:00<00:00, 76659.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 85065.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7023/10556 [00:00<00:00, 70227.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 81773.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120676.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6587/10556 [00:00<00:00, 65867.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 71541.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110699.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7716/10556 [00:00<00:00, 74375.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 64451.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6530/10556 [00:00<00:00, 65297.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 55986.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5770/10556 [00:00<00:00, 52179.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 53900.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5855/10556 [00:00<00:00, 57627.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 57009.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6630/10556 [00:00<00:00, 62130.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 59636.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105799.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5683/10556 [00:00<00:00, 56825.58it/s]100%|█████████▉| 10553/10556 [00:00<00:00, 54017.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 52498.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6502/10556 [00:00<00:00, 60271.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 58038.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5980/10556 [00:00<00:00, 59795.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 57370.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115878.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6439/10556 [00:00<00:00, 60899.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 66736.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6199/10556 [00:00<00:00, 61319.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 62537.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5681/10556 [00:00<00:00, 56805.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 61262.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9738/10556 [00:00<00:00, 97372.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 97652.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6271/10556 [00:00<00:00, 59330.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 55655.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5894/10556 [00:00<00:00, 58939.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 69078.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6345/10556 [00:00<00:00, 58457.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 61241.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116942.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6363/10556 [00:00<00:00, 63625.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 76971.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▋  | 8069/10556 [00:00<00:00, 80684.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 81553.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10013/10556 [00:00<00:00, 100127.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 100720.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6932/10556 [00:00<00:00, 69318.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 80405.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118086.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6429/10556 [00:00<00:00, 59007.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 56048.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10382/10556 [00:00<00:00, 103817.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 98968.57it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108671.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9379/10556 [00:00<00:00, 93788.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 95157.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105419.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6754/10556 [00:00<00:00, 60596.91it/s] 99%|█████████▉| 10433/10556 [00:00<00:00, 50743.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 48351.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10533/10556 [00:00<00:00, 105323.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 104873.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5609/10556 [00:00<00:00, 56087.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 65356.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9805/10556 [00:00<00:00, 98045.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 99296.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113599.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120114.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105807.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10240/10556 [00:00<00:00, 102033.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 102246.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6605/10556 [00:00<00:00, 66049.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 58755.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8639/10556 [00:00<00:00, 80968.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 65347.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10390/10556 [00:00<00:00, 103894.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 103905.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|███▌      | 3719/10556 [00:00<00:00, 37029.71it/s] 67%|██████▋   | 7068/10556 [00:00<00:00, 34841.17it/s] 96%|█████████▌| 10091/10556 [00:00<00:00, 33315.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 33209.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6069/10556 [00:00<00:00, 60536.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 59899.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6359/10556 [00:00<00:00, 62318.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 60582.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6709/10556 [00:00<00:00, 63405.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 58625.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119657.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107266.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108954.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9558/10556 [00:00<00:00, 95574.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 89355.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 103914.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5453/10556 [00:00<00:00, 50199.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 54543.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8084/10556 [00:00<00:00, 80838.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 87597.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9676/10556 [00:00<00:00, 96757.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 94145.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▊     | 5125/10556 [00:00<00:00, 51249.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 64162.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10097/10556 [00:00<00:00, 100969.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 98135.86it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5066/10556 [00:00<00:00, 50657.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 72964.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5445/10556 [00:00<00:00, 54445.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 66900.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5644/10556 [00:00<00:00, 56436.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 59587.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7353/10556 [00:00<00:00, 73529.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 81856.72it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 0.38496947288513184s
epoch 10: {'train_loss': '1.38629'}; time used = 0.44520044326782227s
epoch 15: {'train_loss': '1.38629'}; time used = 0.5004398822784424s
epoch 20: {'train_loss': '1.38629'}; time used = 0.7492620944976807s
epoch 25: {'train_loss': '1.38629'}; time used = 0.5476400852203369s
epoch 30: {'train_loss': '1.38629'}; time used = 0.40283775329589844s
epoch 35: {'train_loss': '1.38629'}; time used = 0.4176514148712158s
epoch 40: {'train_loss': '1.38629'}; time used = 0.3718242645263672s
epoch 45: {'train_loss': '1.38629'}; time used = 0.3844456672668457s
epoch 50: {'train_loss': '1.38629'}; time used = 0.3456430435180664s
epoch 55: {'train_loss': '1.38629'}; time used = 0.3490462303161621s
epoch 60: {'train_loss': '1.38629'}; time used = 0.35430431365966797s
epoch 65: {'train_loss': '1.38629'}; time used = 0.41633009910583496s
epoch 70: {'train_loss': '1.38629'}; time used = 0.40016794204711914s
epoch 75: {'train_loss': '1.38629'}; time used = 0.5459942817687988s
epoch 80: {'train_loss': '1.38629'}; time used = 0.5153388977050781s
epoch 85: {'train_loss': '1.38629'}; time used = 0.376234769821167s
epoch 90: {'train_loss': '1.38629'}; time used = 0.4221932888031006s
epoch 95: {'train_loss': '1.38629'}; time used = 0.8385913372039795s
epoch 100: {'train_loss': '1.38629'}; time used = 0.5217549800872803s
epoch 105: {'train_loss': '1.38629'}; time used = 0.4764218330383301s
epoch 110: {'train_loss': '1.38629'}; time used = 0.3993046283721924s
epoch 115: {'train_loss': '1.38629'}; time used = 0.3884766101837158s
epoch 120: {'train_loss': '1.38629'}; time used = 0.41183900833129883s
epoch 125: {'train_loss': '1.38629'}; time used = 0.36804914474487305s
epoch 130: {'train_loss': '1.38629'}; time used = 0.44628310203552246s
epoch 135: {'train_loss': '1.38629'}; time used = 0.43260765075683594s
epoch 140: {'train_loss': '1.38629'}; time used = 0.39745283126831055s
epoch 145: {'train_loss': '1.38629'}; time used = 0.4095633029937744s
epoch 150: {'train_loss': '1.38629'}; time used = 0.3570270538330078s
epoch 155: {'train_loss': '1.38629'}; time used = 0.3396306037902832s
epoch 160: {'train_loss': '1.38629'}; time used = 0.4066624641418457s
epoch 165: {'train_loss': '1.38629'}; time used = 0.332902193069458s
epoch 170: {'train_loss': '1.38629'}; time used = 0.37373924255371094s
epoch 175: {'train_loss': '1.38629'}; time used = 0.48429179191589355s
epoch 180: {'train_loss': '1.38629'}; time used = 0.6339864730834961s
epoch 185: {'train_loss': '1.38629'}; time used = 0.5867226123809814s
epoch 190: {'train_loss': '1.38629'}; time used = 0.530057430267334s
epoch 195: {'train_loss': '1.38629'}; time used = 0.42844605445861816s
epoch 200: {'train_loss': '1.38629'}; time used = 0.3648355007171631s
epoch 205: {'train_loss': '1.38629'}; time used = 0.3282601833343506s
epoch 210: {'train_loss': '1.38629'}; time used = 0.4151420593261719s
epoch 215: {'train_loss': '1.38629'}; time used = 0.3988010883331299s
epoch 220: {'train_loss': '1.38629'}; time used = 0.4322831630706787s
epoch 225: {'train_loss': '1.38629'}; time used = 0.35769152641296387s
epoch 230: {'train_loss': '1.38629'}; time used = 0.3652820587158203s
epoch 235: {'train_loss': '1.38629'}; time used = 0.4601278305053711s
epoch 240: {'train_loss': '1.38629'}; time used = 0.48782801628112793s
epoch 245: {'train_loss': '1.38629'}; time used = 0.6690511703491211s
epoch 250: {'train_loss': '1.38629'}; time used = 0.3432281017303467s
epoch 255: {'train_loss': '1.38629'}; time used = 0.34329700469970703s
epoch 260: {'train_loss': '1.38629'}; time used = 0.35985779762268066s
epoch 265: {'train_loss': '1.38629'}; time used = 0.5223922729492188s
epoch 270: {'train_loss': '1.38629'}; time used = 0.5302019119262695s
epoch 275: {'train_loss': '1.38629'}; time used = 0.6080067157745361s
epoch 280: {'train_loss': '1.38629'}; time used = 0.577667236328125s
epoch 285: {'train_loss': '1.38629'}; time used = 0.3399999141693115s
epoch 290: {'train_loss': '1.38629'}; time used = 0.3710193634033203s
epoch 295: {'train_loss': '1.38629'}; time used = 0.40912723541259766s
epoch 300: {'train_loss': '1.38629'}; time used = 0.3693222999572754s
epoch 305: {'train_loss': '1.38616'}; time used = 0.3622920513153076s
epoch 310: {'train_loss': '1.38616'}; time used = 0.40371179580688477s
epoch 315: {'train_loss': '1.38616'}; time used = 0.42758798599243164s
epoch 320: {'train_loss': '1.38616'}; time used = 0.43408703804016113s
epoch 325: {'train_loss': '1.38616'}; time used = 0.3974454402923584s
epoch 330: {'train_loss': '1.38616'}; time used = 0.42413997650146484s
epoch 335: {'train_loss': '1.38616'}; time used = 0.4449598789215088s
epoch 340: {'train_loss': '1.38616'}; time used = 0.44834232330322266s
epoch 345: {'train_loss': '1.38616'}; time used = 0.4856705665588379s
epoch 350: {'train_loss': '1.38636'}; time used = 0.5519073009490967s
epoch 355: {'train_loss': '1.38619'}; time used = 0.6047477722167969s
epoch 360: {'train_loss': '1.38616'}; time used = 0.7255463600158691s
epoch 365: {'train_loss': '1.38616'}; time used = 0.6937301158905029s
epoch 370: {'train_loss': '1.38616'}; time used = 0.6545314788818359s
epoch 375: {'train_loss': '1.38616'}; time used = 1.0052564144134521s
epoch 380: {'train_loss': '1.38616'}; time used = 0.8341178894042969s
epoch 385: {'train_loss': '1.38616'}; time used = 0.8845784664154053s
epoch 390: {'train_loss': '1.38616'}; time used = 0.7448415756225586s
epoch 395: {'train_loss': '1.38616'}; time used = 0.7311956882476807s
epoch 400: {'train_loss': '1.38616'}; time used = 0.7288198471069336s
epoch 405: {'train_loss': '1.38616'}; time used = 0.5951848030090332s
epoch 410: {'train_loss': '1.38616'}; time used = 0.9335672855377197s
epoch 415: {'train_loss': '1.38616'}; time used = 0.8055565357208252s
epoch 420: {'train_loss': '1.38616'}; time used = 0.6869328022003174s
epoch 425: {'train_loss': '1.38624'}; time used = 0.7637555599212646s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 58.0143084526062.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9208/10556 [00:00<00:00, 92075.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 90028.23it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 42, in forward
    hneg = self.embed(neg)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 72, in forward
    hx = self.full_embeddings[x]
RuntimeError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 10.76 GiB total capacity; 79.39 MiB already allocated; 17.44 MiB free; 102.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210830.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185345.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202498.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7895/10556 [00:00<00:00, 78943.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 85397.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9337/10556 [00:00<00:00, 93359.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 89728.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10294/10556 [00:00<00:00, 102928.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 102777.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119833.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118677.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9334/10556 [00:00<00:00, 93328.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 88958.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7827/10556 [00:00<00:00, 78264.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 86974.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|███▌      | 3784/10556 [00:00<00:00, 37838.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 75915.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194323.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185180.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173800.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156482.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155570.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|█████     | 5284/10556 [00:00<00:00, 52405.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 58313.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128115.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5465/10556 [00:00<00:00, 54649.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 78965.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126368.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111254.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143651.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6850/10556 [00:00<00:00, 67428.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 76595.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132500.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|███▍      | 3676/10556 [00:00<00:00, 34921.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 64663.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112351.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121162.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194430.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185055.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187375.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184234.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124847.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158919.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179644.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162822.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151646.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139487.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147335.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 161201.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179976.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142730.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192479.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176379.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176411.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169147.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137182.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154433.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145646.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155942.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151211.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138459.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129237.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116122.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156978.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150118.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164789.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190615.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191288.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192834.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196813.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8279/10556 [00:00<00:00, 82788.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 81320.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188345.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180016.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194243.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192698.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193917.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194975.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190433.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185659.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191050.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176139.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185998.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183915.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193625.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202915.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187713.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197840.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195520.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198034.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183621.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201443.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190138.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201060.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201030.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196376.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193378.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171435.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126313.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193651.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199760.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192802.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193366.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195292.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147155.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158779.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190252.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195213.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191607.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188850.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135754.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132547.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205540.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203552.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196971.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208576.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201266.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189941.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195933.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195834.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192367.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190553.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200846.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203512.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207946.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219256.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221931.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213938.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149000.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125373.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130502.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6050/10556 [00:00<00:00, 52440.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 64786.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8614/10556 [00:00<00:00, 80664.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 65623.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113925.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7297/10556 [00:00<00:00, 65953.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 53937.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7412/10556 [00:00<00:00, 74114.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 52432.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174774.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143866.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|███▌      | 3761/10556 [00:00<00:00, 34077.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 60767.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220679.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6823/10556 [00:00<00:00, 68226.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 72759.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143414.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10292/10556 [00:00<00:00, 102914.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 94496.23it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135267.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9833/10556 [00:00<00:00, 97049.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 78297.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110842.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194644.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135050.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147943.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201533.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203263.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206466.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189276.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191186.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202792.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211756.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203825.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208701.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211280.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208750.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212196.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212827.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212962.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213619.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217626.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217551.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209256.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189823.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188630.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193968.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185531.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186132.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186122.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182291.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154551.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170434.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195945.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 161884.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130656.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200705.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196240.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190381.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189250.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194569.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193225.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196355.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7364/10556 [00:00<00:00, 70139.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 83758.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214351.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211264.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194402.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188350.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191258.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198516.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190775.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189482.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197187.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197760.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196709.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189276.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189078.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181721.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136773.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126886.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 161794.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155598.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193297.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185146.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191585.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180504.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185228.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179424.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10348/10556 [00:00<00:00, 102428.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 102488.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157133.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152823.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158059.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8901/10556 [00:00<00:00, 89007.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 88196.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136173.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179276.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181939.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181570.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130541.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181978.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184708.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196966.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200562.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196336.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188191.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193525.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181801.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186134.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196144.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193754.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144432.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8445/10556 [00:00<00:00, 84449.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 95762.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189015.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195677.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190936.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191979.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182180.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186612.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197962.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 101503.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153167.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 234837.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212669.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8226/10556 [00:00<00:00, 82256.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 83848.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193929.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189410.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197440.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7629/10556 [00:00<00:00, 66350.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 56870.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203216.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209187.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8896/10556 [00:00<00:00, 88957.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 94136.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|███▊      | 3971/10556 [00:00<00:00, 38163.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 60294.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141799.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121017.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4576/10556 [00:00<00:00, 45759.83it/s] 89%|████████▉ | 9423/10556 [00:00<00:00, 44782.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 44766.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132874.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196925.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122550.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|████▌     | 4801/10556 [00:00<00:00, 38380.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 59626.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122049.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154151.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152962.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125826.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181994.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190005.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7189/10556 [00:00<00:00, 71880.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 73014.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10099/10556 [00:00<00:00, 100982.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 97780.64it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109034.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195372.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204826.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221396.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210567.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199154.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206035.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187135.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220490.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207114.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211096.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211393.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207139.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218141.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212028.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203555.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198610.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200395.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203876.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211497.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180713.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6742/10556 [00:00<00:00, 67419.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 88478.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222446.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211406.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155326.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107619.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153530.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111988.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116560.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118914.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125998.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138158.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155597.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158667.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156149.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153779.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155949.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154978.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154528.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153602.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152862.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117541.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118781.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158463.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154358.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146991.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154133.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151888.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152831.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156991.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140811.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138877.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6962/10556 [00:00<00:00, 69616.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 85299.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159229.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154786.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140796.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154774.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148201.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141150.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155393.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156849.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148071.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156738.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157766.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152222.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158737.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157046.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153834.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154667.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152614.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149466.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7404/10556 [00:00<00:00, 74037.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 88131.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154697.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154641.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157274.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150774.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157370.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9166/10556 [00:00<00:00, 91658.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 64442.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6629/10556 [00:00<00:00, 66287.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 79623.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121813.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192252.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203794.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▌| 10052/10556 [00:00<00:00, 90838.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 78875.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179176.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221645.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9231/10556 [00:00<00:00, 80801.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 73436.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|███▍      | 3691/10556 [00:00<00:00, 31813.82it/s] 59%|█████▊    | 6184/10556 [00:00<00:00, 29379.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 43967.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190766.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146288.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186832.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8472/10556 [00:00<00:00, 84716.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 89936.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144213.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125845.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 163478.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9416/10556 [00:00<00:00, 85750.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 58080.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159211.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158609.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185214.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191035.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183357.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123443.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188970.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188022.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191678.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193985.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197467.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189975.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199449.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203287.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208706.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215843.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199889.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192358.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201337.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211350.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209254.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198939.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205024.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195396.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141453.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187196.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169941.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8360/10556 [00:00<00:00, 83597.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 95478.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204733.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194925.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219193.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215146.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211913.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204884.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192005.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169168.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106987.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191778.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196017.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178504.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197646.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191250.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187892.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183501.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184916.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185484.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186351.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182807.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193503.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177433.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193059.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180004.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7388/10556 [00:00<00:00, 73876.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 82452.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186331.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186950.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193453.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172703.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184546.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185823.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181850.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178397.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8258/10556 [00:00<00:00, 82576.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 86565.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194017.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210520.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192774.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188779.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185016.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210183.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210865.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194597.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190241.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117918.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111741.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106851.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8762/10556 [00:00<00:00, 87619.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 86600.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8512/10556 [00:00<00:00, 85115.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 82701.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189602.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186212.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193593.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193397.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195171.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186791.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197379.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187162.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7910/10556 [00:00<00:00, 77629.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 90297.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193247.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194013.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193387.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193022.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197596.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197277.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189297.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192731.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188389.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190009.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128540.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 163848.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190343.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196980.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201814.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193648.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196557.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127577.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127245.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107666.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 227301.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10528/10556 [00:00<00:00, 99945.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 92350.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9613/10556 [00:00<00:00, 96128.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 98143.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122279.81it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.37522'}; time used = 0.5269525051116943s
epoch 10: {'train_loss': '1.35109'}; time used = 0.6071248054504395s
epoch 15: {'train_loss': '1.30317'}; time used = 0.3354766368865967s
epoch 20: {'train_loss': '1.17771'}; time used = 0.6281704902648926s
epoch 25: {'train_loss': '1.05204'}; time used = 0.6194908618927002s
epoch 30: {'train_loss': '0.99280'}; time used = 0.35977649688720703s
epoch 35: {'train_loss': '0.95609'}; time used = 0.38437676429748535s
epoch 40: {'train_loss': '0.92201'}; time used = 0.3813893795013428s
epoch 45: {'train_loss': '0.91230'}; time used = 0.35259175300598145s
epoch 50: {'train_loss': '0.87420'}; time used = 0.39307117462158203s
epoch 55: {'train_loss': '0.87084'}; time used = 0.4176297187805176s
epoch 60: {'train_loss': '0.85048'}; time used = 0.3895418643951416s
epoch 65: {'train_loss': '0.83616'}; time used = 0.31420087814331055s
epoch 70: {'train_loss': '0.84272'}; time used = 0.31661295890808105s
epoch 75: {'train_loss': '0.82377'}; time used = 0.3086836338043213s
epoch 80: {'train_loss': '0.82935'}; time used = 0.3059420585632324s
epoch 85: {'train_loss': '0.82587'}; time used = 0.3128533363342285s
epoch 90: {'train_loss': '0.81339'}; time used = 0.36051082611083984s
epoch 95: {'train_loss': '0.80980'}; time used = 0.3428914546966553s
epoch 100: {'train_loss': '0.80995'}; time used = 0.36962056159973145s
epoch 105: {'train_loss': '0.80389'}; time used = 0.2950894832611084s
epoch 110: {'train_loss': '0.79941'}; time used = 0.31548452377319336s
epoch 115: {'train_loss': '0.79438'}; time used = 0.27807140350341797s
epoch 120: {'train_loss': '0.80550'}; time used = 0.47611021995544434s
epoch 125: {'train_loss': '0.79340'}; time used = 0.7619223594665527s
epoch 130: {'train_loss': '0.79364'}; time used = 0.5489463806152344s
epoch 135: {'train_loss': '0.78339'}; time used = 0.5241332054138184s
epoch 140: {'train_loss': '0.78785'}; time used = 0.34519124031066895s
epoch 145: {'train_loss': '0.78045'}; time used = 0.296170711517334s
epoch 150: {'train_loss': '0.78462'}; time used = 0.2850768566131592s
epoch 155: {'train_loss': '0.78333'}; time used = 0.2800252437591553s
epoch 160: {'train_loss': '0.77895'}; time used = 0.31973910331726074s
epoch 165: {'train_loss': '0.77054'}; time used = 0.33022236824035645s
epoch 170: {'train_loss': '0.78287'}; time used = 0.365386962890625s
epoch 175: {'train_loss': '0.77106'}; time used = 0.38808417320251465s
epoch 180: {'train_loss': '0.78111'}; time used = 0.3037528991699219s
epoch 185: {'train_loss': '0.77543'}; time used = 0.305203914642334s
epoch 190: {'train_loss': '0.77303'}; time used = 0.3376297950744629s
epoch 195: {'train_loss': '0.77671'}; time used = 0.38483715057373047s
epoch 200: {'train_loss': '0.76235'}; time used = 0.3721895217895508s
epoch 205: {'train_loss': '0.78090'}; time used = 0.4538233280181885s
epoch 210: {'train_loss': '0.77001'}; time used = 0.3607769012451172s
epoch 215: {'train_loss': '0.77421'}; time used = 0.31098008155822754s
epoch 220: {'train_loss': '0.76440'}; time used = 0.3322312831878662s
epoch 225: {'train_loss': '0.76924'}; time used = 0.38193607330322266s
epoch 230: {'train_loss': '0.76335'}; time used = 0.35629820823669434s
epoch 235: {'train_loss': '0.76450'}; time used = 0.3771378993988037s
epoch 240: {'train_loss': '0.76123'}; time used = 0.4236876964569092s
epoch 245: {'train_loss': '0.75713'}; time used = 0.7771453857421875s
epoch 250: {'train_loss': '0.75880'}; time used = 0.5260124206542969s
epoch 255: {'train_loss': '0.75252'}; time used = 0.379971981048584s
epoch 260: {'train_loss': '0.75846'}; time used = 0.49779510498046875s
epoch 265: {'train_loss': '0.75703'}; time used = 0.29485034942626953s
epoch 270: {'train_loss': '0.75258'}; time used = 0.28321266174316406s
epoch 275: {'train_loss': '0.75533'}; time used = 0.28699660301208496s
epoch 280: {'train_loss': '0.76323'}; time used = 0.36709094047546387s
epoch 285: {'train_loss': '0.75668'}; time used = 0.4165220260620117s
epoch 290: {'train_loss': '0.75944'}; time used = 0.46399641036987305s
epoch 295: {'train_loss': '0.75133'}; time used = 0.375382661819458s
epoch 300: {'train_loss': '0.75604'}; time used = 0.4426443576812744s
epoch 305: {'train_loss': '0.75415'}; time used = 0.3816721439361572s
epoch 310: {'train_loss': '0.75924'}; time used = 0.45341992378234863s
epoch 315: {'train_loss': '0.75909'}; time used = 0.38585901260375977s
epoch 320: {'train_loss': '0.75339'}; time used = 0.3873097896575928s
epoch 325: {'train_loss': '0.75990'}; time used = 0.3722960948944092s
epoch 330: {'train_loss': '0.74648'}; time used = 0.4385945796966553s
epoch 335: {'train_loss': '0.75445'}; time used = 0.4636824131011963s
epoch 340: {'train_loss': '0.75434'}; time used = 0.5243353843688965s
epoch 345: {'train_loss': '0.75642'}; time used = 0.5887119770050049s
epoch 350: {'train_loss': '0.75507'}; time used = 0.44945240020751953s
epoch 355: {'train_loss': '0.75102'}; time used = 0.47742605209350586s
epoch 360: {'train_loss': '0.75092'}; time used = 0.3610703945159912s
epoch 365: {'train_loss': '0.74768'}; time used = 0.3031337261199951s
epoch 370: {'train_loss': '0.75433'}; time used = 0.2908661365509033s
epoch 375: {'train_loss': '0.75458'}; time used = 0.28945112228393555s
epoch 380: {'train_loss': '0.74596'}; time used = 0.4076535701751709s
epoch 385: {'train_loss': '0.74417'}; time used = 0.2837338447570801s
epoch 390: {'train_loss': '0.74988'}; time used = 0.379763126373291s
epoch 395: {'train_loss': '0.74652'}; time used = 0.3181178569793701s
epoch 400: {'train_loss': '0.75159'}; time used = 0.3269007205963135s
epoch 405: {'train_loss': '0.75080'}; time used = 0.3950636386871338s
epoch 410: {'train_loss': '0.74624'}; time used = 0.328155517578125s
epoch 415: {'train_loss': '0.74506'}; time used = 0.3973879814147949s
epoch 420: {'train_loss': '0.74711'}; time used = 0.3146500587463379s
epoch 425: {'train_loss': '0.74700'}; time used = 0.3822641372680664s
epoch 430: {'train_loss': '0.75183'}; time used = 0.5072813034057617s
epoch 435: {'train_loss': '0.74913'}; time used = 0.321669340133667s
epoch 440: {'train_loss': '0.74826'}; time used = 0.377596378326416s
epoch 445: {'train_loss': '0.75286'}; time used = 0.30983471870422363s
epoch 450: {'train_loss': '0.74276'}; time used = 0.36546778678894043s
epoch 455: {'train_loss': '0.74000'}; time used = 0.32245755195617676s
epoch 460: {'train_loss': '0.74698'}; time used = 0.5097208023071289s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.768529415130615.
Training classifier using 20.00% nodes...
{'micro': 0.8167974157821873, 'macro': 0.8061702557277305, 'samples': 0.8167974157821873, 'weighted': 0.8156267309582337}
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 233921.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172691.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125470.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111403.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9096/10556 [00:00<00:00, 90950.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 88517.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7630/10556 [00:00<00:00, 76291.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 76553.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110547.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182555.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179657.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186242.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187726.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181593.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176636.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186668.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168798.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160011.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185818.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132271.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126869.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107814.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119921.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129750.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126229.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125297.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137425.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146530.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113719.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156465.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168072.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138098.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144834.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106925.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5547/10556 [00:00<00:00, 55465.29it/s] 86%|████████▌ | 9057/10556 [00:00<00:00, 47241.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 44075.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6329/10556 [00:00<00:00, 63284.63it/s] 84%|████████▍ | 8907/10556 [00:00<00:00, 44054.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 48294.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7928/10556 [00:00<00:00, 79277.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 67923.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121455.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9229/10556 [00:00<00:00, 78480.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 70393.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6984/10556 [00:00<00:00, 69837.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 62960.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125191.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144632.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131683.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110311.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7062/10556 [00:00<00:00, 70616.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 80390.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5682/10556 [00:00<00:00, 54934.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 69934.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135505.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146932.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141298.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150132.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125563.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 98634.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164292.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143078.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151414.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160394.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175125.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167325.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160491.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170425.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165333.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167492.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137554.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118719.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124841.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127086.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121762.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128193.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7613/10556 [00:00<00:00, 76128.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 83345.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110029.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143248.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145908.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130239.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151213.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156061.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138981.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123447.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105649.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9623/10556 [00:00<00:00, 96228.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 95950.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118952.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120527.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143805.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147545.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129334.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123792.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127743.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124399.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166633.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126917.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125243.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120807.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9617/10556 [00:00<00:00, 94338.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 88227.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119869.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108927.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120886.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128625.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129274.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128274.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8925/10556 [00:00<00:00, 89248.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 80984.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106894.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110184.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6178/10556 [00:00<00:00, 59824.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 56111.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9175/10556 [00:00<00:00, 91740.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 94863.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6619/10556 [00:00<00:00, 65982.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 63511.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|█████     | 5330/10556 [00:00<00:00, 53299.54it/s] 85%|████████▍ | 8927/10556 [00:00<00:00, 44688.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 41393.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8106/10556 [00:00<00:00, 81055.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 84994.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6988/10556 [00:00<00:00, 69222.06it/s] 92%|█████████▏| 9759/10556 [00:00<00:00, 47021.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 45559.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5401/10556 [00:00<00:00, 47705.40it/s] 94%|█████████▍| 9937/10556 [00:00<00:00, 46975.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 48358.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125781.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4842/10556 [00:00<00:00, 42996.46it/s] 66%|██████▋   | 7010/10556 [00:00<00:00, 33179.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 38794.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6784/10556 [00:00<00:00, 64034.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 69278.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5465/10556 [00:00<00:00, 53868.03it/s] 89%|████████▊ | 9364/10556 [00:00<00:00, 48322.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 46098.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6371/10556 [00:00<00:00, 63704.74it/s] 89%|████████▉ | 9385/10556 [00:00<00:00, 45588.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 48105.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5478/10556 [00:00<00:00, 52856.97it/s] 88%|████████▊ | 9341/10556 [00:00<00:00, 47383.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 45827.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6053/10556 [00:00<00:00, 60525.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 70736.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5150/10556 [00:00<00:00, 44969.53it/s] 78%|███████▊  | 8221/10556 [00:00<00:00, 39470.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 41623.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7128/10556 [00:00<00:00, 71274.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 66514.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110549.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7649/10556 [00:00<00:00, 76489.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 85929.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 6995/10556 [00:00<00:00, 69945.06it/s] 99%|█████████▉| 10440/10556 [00:00<00:00, 52200.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 50605.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5794/10556 [00:00<00:00, 57939.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 57447.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6448/10556 [00:00<00:00, 64477.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 68556.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8077/10556 [00:00<00:00, 74166.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 75055.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|███▊      | 4018/10556 [00:00<00:00, 40113.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 64827.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|█████     | 5316/10556 [00:00<00:00, 53158.28it/s] 87%|████████▋ | 9187/10556 [00:00<00:00, 46853.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 43867.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7508/10556 [00:00<00:00, 75078.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 79994.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10400/10556 [00:00<00:00, 103992.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 103906.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6557/10556 [00:00<00:00, 65568.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 79788.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125597.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6221/10556 [00:00<00:00, 56877.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 52355.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125707.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7442/10556 [00:00<00:00, 70174.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 65019.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10223/10556 [00:00<00:00, 102225.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 97285.62it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6807/10556 [00:00<00:00, 68068.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 80771.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7294/10556 [00:00<00:00, 72774.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 69402.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7829/10556 [00:00<00:00, 78286.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 79980.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113821.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5935/10556 [00:00<00:00, 57966.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 68747.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7283/10556 [00:00<00:00, 72824.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 66416.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7505/10556 [00:00<00:00, 73541.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 83160.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10457/10556 [00:00<00:00, 104563.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 104365.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|███▌      | 3797/10556 [00:00<00:00, 36774.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 56492.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9834/10556 [00:00<00:00, 98332.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 99429.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6758/10556 [00:00<00:00, 67577.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 81031.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|███▋      | 3952/10556 [00:00<00:00, 39333.42it/s] 86%|████████▌ | 9081/10556 [00:00<00:00, 42290.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 44916.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108306.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9549/10556 [00:00<00:00, 95484.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 83092.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7331/10556 [00:00<00:00, 68740.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 66807.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6879/10556 [00:00<00:00, 68789.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 81656.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6244/10556 [00:00<00:00, 62436.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 78018.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9707/10556 [00:00<00:00, 97062.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 94787.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▋  | 8072/10556 [00:00<00:00, 80715.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 87907.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125443.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7382/10556 [00:00<00:00, 73814.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 81563.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113444.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 6997/10556 [00:00<00:00, 69968.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 61322.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8486/10556 [00:00<00:00, 84854.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 90420.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108872.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9735/10556 [00:00<00:00, 97348.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 94070.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5613/10556 [00:00<00:00, 53753.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 70700.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8468/10556 [00:00<00:00, 83568.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 88450.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7402/10556 [00:00<00:00, 74018.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 69872.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10439/10556 [00:00<00:00, 104382.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 104015.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112715.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108671.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116222.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8984/10556 [00:00<00:00, 89839.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 93792.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|████▍     | 4731/10556 [00:00<00:00, 47309.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 71133.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9144/10556 [00:00<00:00, 91436.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 85925.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8875/10556 [00:00<00:00, 88749.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 92477.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6140/10556 [00:00<00:00, 61397.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 71649.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6097/10556 [00:00<00:00, 60968.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 76656.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118289.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6687/10556 [00:00<00:00, 66865.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 79485.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9666/10556 [00:00<00:00, 88216.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 86823.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9240/10556 [00:00<00:00, 92397.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 94303.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113866.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115789.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114355.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117912.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9031/10556 [00:00<00:00, 90306.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 93470.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114506.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119584.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117366.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112892.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121920.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5495/10556 [00:00<00:00, 54946.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 67187.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114126.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110813.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9119/10556 [00:00<00:00, 91189.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 89130.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 103646.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108822.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116139.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109120.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6560/10556 [00:00<00:00, 65596.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 58580.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4910/10556 [00:00<00:00, 44431.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 52188.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 7007/10556 [00:00<00:00, 65047.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 62889.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6142/10556 [00:00<00:00, 61415.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 70855.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119917.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9125/10556 [00:00<00:00, 91248.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 94395.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10446/10556 [00:00<00:00, 104458.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 104126.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9391/10556 [00:00<00:00, 93909.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 95887.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118430.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114756.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▊  | 8287/10556 [00:00<00:00, 77982.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 51475.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5370/10556 [00:00<00:00, 49357.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 55194.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114665.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▉      | 4154/10556 [00:00<00:00, 38494.31it/s] 87%|████████▋ | 9139/10556 [00:00<00:00, 39635.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 40833.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|██▉       | 3105/10556 [00:00<00:00, 30726.96it/s] 69%|██████▉   | 7292/10556 [00:00<00:00, 33392.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 39249.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████▏    | 5436/10556 [00:00<00:00, 54358.76it/s] 85%|████████▍ | 8966/10556 [00:00<00:00, 45953.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 43878.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5074/10556 [00:00<00:00, 50737.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 65870.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6406/10556 [00:00<00:00, 59486.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 74227.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9110/10556 [00:00<00:00, 91093.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 81858.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8809/10556 [00:00<00:00, 62459.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 58903.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9356/10556 [00:00<00:00, 93554.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 96010.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8994/10556 [00:00<00:00, 89939.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 92628.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|████▍     | 4667/10556 [00:00<00:00, 46666.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 63062.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5807/10556 [00:00<00:00, 58067.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 75202.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8363/10556 [00:00<00:00, 83628.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 89071.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114329.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109938.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|████▍     | 4748/10556 [00:00<00:00, 43096.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 61060.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████▏| 9645/10556 [00:00<00:00, 96447.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 97629.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10423/10556 [00:00<00:00, 104226.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 97383.41it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8994/10556 [00:00<00:00, 89937.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 93350.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120092.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119628.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7582/10556 [00:00<00:00, 75816.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 84606.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8753/10556 [00:00<00:00, 87527.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 91577.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|████▍     | 4652/10556 [00:00<00:00, 45311.29it/s] 95%|█████████▍| 10009/10556 [00:00<00:00, 47508.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 48697.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████▏  | 7541/10556 [00:00<00:00, 75406.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 84108.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9034/10556 [00:00<00:00, 90332.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 93268.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6864/10556 [00:00<00:00, 68639.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 80614.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119799.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8992/10556 [00:00<00:00, 89916.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 94441.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115764.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5798/10556 [00:00<00:00, 57979.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 58804.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7087/10556 [00:00<00:00, 70868.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 68235.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▉      | 4151/10556 [00:00<00:00, 41509.64it/s] 84%|████████▎ | 8829/10556 [00:00<00:00, 42817.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 44670.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106302.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116061.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6041/10556 [00:00<00:00, 55078.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 70390.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6522/10556 [00:00<00:00, 61656.06it/s]100%|█████████▉| 10549/10556 [00:00<00:00, 53181.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 46736.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▊     | 5142/10556 [00:00<00:00, 44441.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 49054.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109106.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8545/10556 [00:00<00:00, 85445.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 89242.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6557/10556 [00:00<00:00, 62216.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 59092.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5276/10556 [00:00<00:00, 51718.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 56233.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10458/10556 [00:00<00:00, 104577.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 104282.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7227/10556 [00:00<00:00, 66970.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 75567.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112496.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6299/10556 [00:00<00:00, 62988.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 75094.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113256.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6415/10556 [00:00<00:00, 63016.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 76838.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112405.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6876/10556 [00:00<00:00, 68756.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 75709.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9173/10556 [00:00<00:00, 91727.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 94236.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6042/10556 [00:00<00:00, 60415.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 74563.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8858/10556 [00:00<00:00, 88576.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 91822.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9092/10556 [00:00<00:00, 90916.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 88494.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9836/10556 [00:00<00:00, 98357.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 99291.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▊   | 7253/10556 [00:00<00:00, 72526.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 64090.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6722/10556 [00:00<00:00, 67216.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 72403.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5821/10556 [00:00<00:00, 58208.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 73952.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8945/10556 [00:00<00:00, 84454.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 81466.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▋  | 8061/10556 [00:00<00:00, 80608.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 86223.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6669/10556 [00:00<00:00, 66685.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 76681.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121762.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7436/10556 [00:00<00:00, 74355.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 83747.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5692/10556 [00:00<00:00, 47627.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 64935.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8334/10556 [00:00<00:00, 83335.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 74213.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6661/10556 [00:00<00:00, 59458.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 67475.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9204/10556 [00:00<00:00, 92038.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 94820.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9426/10556 [00:00<00:00, 94259.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 95436.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9858/10556 [00:00<00:00, 98572.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 98834.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8868/10556 [00:00<00:00, 88674.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 82936.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8623/10556 [00:00<00:00, 86229.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 75189.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10024/10556 [00:00<00:00, 100236.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 100888.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118763.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118482.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9302/10556 [00:00<00:00, 93018.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 88771.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8704/10556 [00:00<00:00, 87033.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 87727.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6655/10556 [00:00<00:00, 66549.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 78059.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5796/10556 [00:00<00:00, 57956.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 60652.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 102937.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5506/10556 [00:00<00:00, 53344.72it/s] 97%|█████████▋| 10285/10556 [00:00<00:00, 51546.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 49649.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113889.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9363/10556 [00:00<00:00, 93628.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 89951.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6890/10556 [00:00<00:00, 67661.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 79283.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118988.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5976/10556 [00:00<00:00, 59495.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 65783.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6255/10556 [00:00<00:00, 62547.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 54630.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▎  | 7784/10556 [00:00<00:00, 68083.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 76550.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106191.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6355/10556 [00:00<00:00, 63549.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 60367.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8949/10556 [00:00<00:00, 89487.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 92813.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7438/10556 [00:00<00:00, 74376.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 83120.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7661/10556 [00:00<00:00, 76608.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 57401.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6109/10556 [00:00<00:00, 57665.96it/s] 98%|█████████▊| 10321/10556 [00:00<00:00, 50694.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 48806.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8969/10556 [00:00<00:00, 89685.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 93928.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109953.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 31%|███▏      | 3325/10556 [00:00<00:00, 30707.71it/s] 79%|███████▉  | 8373/10556 [00:00<00:00, 34796.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 45997.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6051/10556 [00:00<00:00, 60508.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 76340.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▋  | 8067/10556 [00:00<00:00, 72918.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 56427.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6767/10556 [00:00<00:00, 66391.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 59422.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7690/10556 [00:00<00:00, 76899.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 71554.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9906/10556 [00:00<00:00, 99053.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 100046.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106162.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6294/10556 [00:00<00:00, 62939.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 77591.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 30%|███       | 3188/10556 [00:00<00:00, 31354.43it/s] 72%|███████▏  | 7549/10556 [00:00<00:00, 33781.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 31436.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106618.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164054.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192469.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131583.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10288/10556 [00:00<00:00, 102874.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 100621.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123245.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185589.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182062.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186626.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192272.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189329.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186775.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183059.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122479.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166378.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196010.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193596.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191603.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184196.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181397.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190152.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9792/10556 [00:00<00:00, 94155.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 90693.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183085.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187599.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151771.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203429.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187300.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153555.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174365.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122254.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106029.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166701.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168142.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191410.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181572.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164392.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173657.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121693.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140388.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172791.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172747.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178013.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156316.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189025.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184543.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175104.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176830.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174824.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172366.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 163831.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168559.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168132.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179260.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9902/10556 [00:00<00:00, 99013.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 99255.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137343.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172969.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165611.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176374.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176664.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166597.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174938.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143155.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131520.54it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.38590'}; time used = 0.5902667045593262s
epoch 10: {'train_loss': '1.37945'}; time used = 0.3798959255218506s
epoch 15: {'train_loss': '1.34941'}; time used = 0.3535621166229248s
epoch 20: {'train_loss': '1.28666'}; time used = 0.473543643951416s
epoch 25: {'train_loss': '1.25648'}; time used = 0.4570317268371582s
epoch 30: {'train_loss': '1.21383'}; time used = 0.4326145648956299s
epoch 35: {'train_loss': '1.19931'}; time used = 0.8596696853637695s
epoch 40: {'train_loss': '1.18497'}; time used = 0.6284658908843994s
epoch 45: {'train_loss': '1.16934'}; time used = 0.5875158309936523s
epoch 50: {'train_loss': '1.15957'}; time used = 0.46446824073791504s
epoch 55: {'train_loss': '1.13873'}; time used = 0.38431763648986816s
epoch 60: {'train_loss': '1.13048'}; time used = 0.3889129161834717s
epoch 65: {'train_loss': '1.13126'}; time used = 0.48274946212768555s
epoch 70: {'train_loss': '1.11231'}; time used = 0.4945068359375s
epoch 75: {'train_loss': '1.11006'}; time used = 0.47334909439086914s
epoch 80: {'train_loss': '1.10845'}; time used = 0.49330830574035645s
epoch 85: {'train_loss': '1.09461'}; time used = 0.45699381828308105s
epoch 90: {'train_loss': '1.08908'}; time used = 0.5499744415283203s
epoch 95: {'train_loss': '1.08312'}; time used = 0.49398183822631836s
epoch 100: {'train_loss': '1.08122'}; time used = 0.7249305248260498s
epoch 105: {'train_loss': '1.07281'}; time used = 1.0549499988555908s
epoch 110: {'train_loss': '1.05670'}; time used = 1.0395870208740234s
epoch 115: {'train_loss': '1.04499'}; time used = 0.9816262722015381s
epoch 120: {'train_loss': '1.04565'}; time used = 0.885941743850708s
epoch 125: {'train_loss': '1.02974'}; time used = 0.8630542755126953s
epoch 130: {'train_loss': '1.02235'}; time used = 0.7300412654876709s
epoch 135: {'train_loss': '1.01236'}; time used = 0.7548742294311523s
epoch 140: {'train_loss': '1.02366'}; time used = 0.7598068714141846s
epoch 145: {'train_loss': '1.00634'}; time used = 0.8175921440124512s
epoch 150: {'train_loss': '0.99654'}; time used = 0.6689276695251465s
epoch 155: {'train_loss': '0.99394'}; time used = 0.6748330593109131s
epoch 160: {'train_loss': '0.98979'}; time used = 0.7018907070159912s
epoch 165: {'train_loss': '0.96787'}; time used = 0.6136691570281982s
epoch 170: {'train_loss': '0.98610'}; time used = 0.7068626880645752s
epoch 175: {'train_loss': '0.97470'}; time used = 0.6393001079559326s
epoch 180: {'train_loss': '0.97482'}; time used = 0.5221467018127441s
epoch 185: {'train_loss': '0.96792'}; time used = 0.5989067554473877s
epoch 190: {'train_loss': '0.96284'}; time used = 0.5799500942230225s
epoch 195: {'train_loss': '0.95585'}; time used = 0.8663644790649414s
epoch 200: {'train_loss': '0.94493'}; time used = 0.577113151550293s
epoch 205: {'train_loss': '0.94941'}; time used = 0.9133422374725342s
epoch 210: {'train_loss': '0.93784'}; time used = 1.0273363590240479s
epoch 215: {'train_loss': '0.93482'}; time used = 0.7959284782409668s
epoch 220: {'train_loss': '0.94517'}; time used = 0.6906440258026123s
epoch 225: {'train_loss': '0.93483'}; time used = 0.5991010665893555s
epoch 230: {'train_loss': '0.93140'}; time used = 0.7834467887878418s
epoch 235: {'train_loss': '0.93572'}; time used = 0.698087215423584s
epoch 240: {'train_loss': '0.93287'}; time used = 0.9066617488861084s
epoch 245: {'train_loss': '0.93273'}; time used = 0.8819336891174316s
epoch 250: {'train_loss': '0.92086'}; time used = 0.6340405941009521s
epoch 255: {'train_loss': '0.92153'}; time used = 0.6968204975128174s
epoch 260: {'train_loss': '0.92653'}; time used = 0.7426769733428955s
epoch 265: {'train_loss': '0.91568'}; time used = 0.7046771049499512s
epoch 270: {'train_loss': '0.91116'}; time used = 0.7583870887756348s
epoch 275: {'train_loss': '0.91531'}; time used = 0.6546175479888916s
epoch 280: {'train_loss': '0.92108'}; time used = 0.6019694805145264s
epoch 285: {'train_loss': '0.90636'}; time used = 0.7798092365264893s
epoch 290: {'train_loss': '0.92271'}; time used = 0.7842833995819092s
epoch 295: {'train_loss': '0.91213'}; time used = 0.773033857345581s
epoch 300: {'train_loss': '0.90658'}; time used = 0.8546476364135742s
epoch 305: {'train_loss': '0.91242'}; time used = 0.8003425598144531s
epoch 310: {'train_loss': '0.91315'}; time used = 0.7552039623260498s
epoch 315: {'train_loss': '0.90803'}; time used = 0.43831729888916016s
epoch 320: {'train_loss': '0.90494'}; time used = 0.31116271018981934s
epoch 325: {'train_loss': '0.89500'}; time used = 0.3524456024169922s
epoch 330: {'train_loss': '0.88994'}; time used = 0.37978482246398926s
epoch 335: {'train_loss': '0.90673'}; time used = 0.33368706703186035s
epoch 340: {'train_loss': '0.89850'}; time used = 0.4082603454589844s
epoch 345: {'train_loss': '0.89922'}; time used = 0.36343908309936523s
epoch 350: {'train_loss': '0.89842'}; time used = 0.36739015579223633s
epoch 355: {'train_loss': '0.89859'}; time used = 0.33605051040649414s
epoch 360: {'train_loss': '0.89521'}; time used = 0.3533334732055664s
epoch 365: {'train_loss': '0.88379'}; time used = 0.4174165725708008s
epoch 370: {'train_loss': '0.89785'}; time used = 0.38829660415649414s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 51.41909337043762.
Training classifier using 20.00% nodes...
{'micro': 0.683894785417628, 'macro': 0.5804409926390504, 'samples': 0.683894785417628, 'weighted': 0.6603114407461781}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 158127.99it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 147, in evaluate
    neg = neg.to(self._device)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.76 GiB total capacity; 16.53 MiB already allocated; 15.44 MiB free; 18.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.021213531494140625 seconds.
Run epoch 1
Epoch 1 ends in 0.020460844039916992 seconds.
5416 sentences created
mode 1: time used = 0.043365478515625
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 186434.93it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.021090984344482422 seconds.
Run epoch 1
Epoch 1 ends in 0.01963973045349121 seconds.
5416 sentences created
mode 1: time used = 0.03625011444091797
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '1.35210'}; time used = 0.12195062637329102s
epoch 10: {'train_loss': '1.26879'}; time used = 0.07686185836791992s
epoch 15: {'train_loss': '1.13640'}; time used = 0.03381180763244629s
epoch 20: {'train_loss': '1.05936'}; time used = 0.03309178352355957s
epoch 25: {'train_loss': '1.01226'}; time used = 0.03786134719848633s
epoch 30: {'train_loss': '0.98021'}; time used = 0.052481889724731445s
epoch 35: {'train_loss': '0.94660'}; time used = 0.03891611099243164s
epoch 40: {'train_loss': '0.93269'}; time used = 0.03858017921447754s
epoch 45: {'train_loss': '0.91700'}; time used = 0.03899836540222168s
epoch 50: {'train_loss': '0.90840'}; time used = 0.03396725654602051s
epoch 55: {'train_loss': '0.90204'}; time used = 0.16369390487670898s
epoch 60: {'train_loss': '0.88940'}; time used = 0.034731149673461914s
epoch 65: {'train_loss': '0.88425'}; time used = 0.034331321716308594s
epoch 70: {'train_loss': '0.88020'}; time used = 0.031198501586914062s
epoch 75: {'train_loss': '0.87585'}; time used = 0.03088545799255371s
epoch 80: {'train_loss': '0.87823'}; time used = 0.03036022186279297s
epoch 85: {'train_loss': '0.86946'}; time used = 0.03071427345275879s
epoch 90: {'train_loss': '0.86629'}; time used = 0.033104896545410156s
epoch 95: {'train_loss': '0.86757'}; time used = 0.03619718551635742s
epoch 100: {'train_loss': '0.86476'}; time used = 0.14163875579833984s
epoch 105: {'train_loss': '0.86388'}; time used = 0.04017305374145508s
epoch 110: {'train_loss': '0.85630'}; time used = 0.034375667572021484s
epoch 115: {'train_loss': '0.86250'}; time used = 0.03365588188171387s
epoch 120: {'train_loss': '0.86288'}; time used = 0.032633304595947266s
epoch 125: {'train_loss': '0.85758'}; time used = 0.03302431106567383s
epoch 130: {'train_loss': '0.85706'}; time used = 0.20107102394104004s
epoch 135: {'train_loss': '0.85409'}; time used = 0.037339210510253906s
epoch 140: {'train_loss': '0.85076'}; time used = 0.21799349784851074s
epoch 145: {'train_loss': '0.85369'}; time used = 0.3914792537689209s
epoch 150: {'train_loss': '0.85105'}; time used = 0.12482094764709473s
epoch 155: {'train_loss': '0.85212'}; time used = 0.03318190574645996s
epoch 160: {'train_loss': '0.84667'}; time used = 0.24049830436706543s
epoch 165: {'train_loss': '0.84807'}; time used = 0.19248151779174805s
epoch 170: {'train_loss': '0.84799'}; time used = 0.036185503005981445s
epoch 175: {'train_loss': '0.84674'}; time used = 0.03453850746154785s
epoch 180: {'train_loss': '0.84653'}; time used = 0.17511320114135742s
epoch 185: {'train_loss': '0.84561'}; time used = 0.206834077835083s
epoch 190: {'train_loss': '0.85072'}; time used = 0.03913617134094238s
epoch 195: {'train_loss': '0.84672'}; time used = 0.04121279716491699s
epoch 200: {'train_loss': '0.84281'}; time used = 0.03672027587890625s
epoch 205: {'train_loss': '0.84631'}; time used = 0.12324142456054688s
epoch 210: {'train_loss': '0.84034'}; time used = 0.05718374252319336s
epoch 215: {'train_loss': '0.84423'}; time used = 0.036225080490112305s
epoch 220: {'train_loss': '0.84205'}; time used = 0.03423142433166504s
epoch 225: {'train_loss': '0.84420'}; time used = 0.03679919242858887s
epoch 230: {'train_loss': '0.84240'}; time used = 0.03419923782348633s
epoch 235: {'train_loss': '0.83999'}; time used = 0.034775495529174805s
epoch 240: {'train_loss': '0.84149'}; time used = 0.03448295593261719s
epoch 245: {'train_loss': '0.83511'}; time used = 0.031064510345458984s
epoch 250: {'train_loss': '0.83863'}; time used = 0.0320734977722168s
epoch 255: {'train_loss': '0.83947'}; time used = 0.03397941589355469s
epoch 260: {'train_loss': '0.83774'}; time used = 0.032593727111816406s
epoch 265: {'train_loss': '0.83689'}; time used = 0.03269243240356445s
epoch 270: {'train_loss': '0.83823'}; time used = 0.03205418586730957s
epoch 275: {'train_loss': '0.84228'}; time used = 0.03266310691833496s
epoch 280: {'train_loss': '0.83303'}; time used = 0.031951189041137695s
epoch 285: {'train_loss': '0.83686'}; time used = 0.033312082290649414s
epoch 290: {'train_loss': '0.84065'}; time used = 0.1309041976928711s
epoch 295: {'train_loss': '0.83504'}; time used = 0.03948616981506348s
epoch 300: {'train_loss': '0.83591'}; time used = 0.032858848571777344s
epoch 305: {'train_loss': '0.83807'}; time used = 0.03608298301696777s
epoch 310: {'train_loss': '0.83490'}; time used = 0.03566169738769531s
epoch 315: {'train_loss': '0.83328'}; time used = 0.035926103591918945s
epoch 320: {'train_loss': '0.83419'}; time used = 0.03424715995788574s
epoch 325: {'train_loss': '0.83695'}; time used = 0.03365039825439453s
epoch 330: {'train_loss': '0.83499'}; time used = 0.036496877670288086s
epoch 335: {'train_loss': '0.83717'}; time used = 0.032979488372802734s
epoch 340: {'train_loss': '0.83536'}; time used = 0.03235912322998047s
epoch 345: {'train_loss': '0.83203'}; time used = 0.03283047676086426s
epoch 350: {'train_loss': '0.83427'}; time used = 0.03777909278869629s
epoch 355: {'train_loss': '0.83093'}; time used = 0.0374140739440918s
epoch 360: {'train_loss': '0.83175'}; time used = 0.03815650939941406s
epoch 365: {'train_loss': '0.83439'}; time used = 0.03886914253234863s
epoch 370: {'train_loss': '0.83337'}; time used = 0.036341190338134766s
epoch 375: {'train_loss': '0.83445'}; time used = 0.03319883346557617s
epoch 380: {'train_loss': '0.83385'}; time used = 0.03484511375427246s
epoch 385: {'train_loss': '0.83232'}; time used = 0.03573012351989746s
epoch 390: {'train_loss': '0.83929'}; time used = 0.03812813758850098s
epoch 395: {'train_loss': '0.82813'}; time used = 0.0338747501373291s
epoch 400: {'train_loss': '0.83276'}; time used = 0.036043643951416016s
epoch 405: {'train_loss': '0.82815'}; time used = 0.04280686378479004s
epoch 410: {'train_loss': '0.83116'}; time used = 0.038177490234375s
epoch 415: {'train_loss': '0.83202'}; time used = 0.03720498085021973s
epoch 420: {'train_loss': '0.83273'}; time used = 0.035193443298339844s
epoch 425: {'train_loss': '0.83115'}; time used = 0.03535127639770508s
epoch 430: {'train_loss': '0.82740'}; time used = 0.07713866233825684s
epoch 435: {'train_loss': '0.83024'}; time used = 0.052701711654663086s
epoch 440: {'train_loss': '0.83174'}; time used = 0.039186716079711914s
epoch 445: {'train_loss': '0.82717'}; time used = 0.05082368850708008s
epoch 450: {'train_loss': '0.82379'}; time used = 0.042653799057006836s
epoch 455: {'train_loss': '0.82823'}; time used = 0.046063899993896484s
epoch 460: {'train_loss': '0.82914'}; time used = 0.050200700759887695s
epoch 465: {'train_loss': '0.82669'}; time used = 0.043854713439941406s
epoch 470: {'train_loss': '0.82861'}; time used = 0.04335165023803711s
epoch 475: {'train_loss': '0.82840'}; time used = 0.04229140281677246s
epoch 480: {'train_loss': '0.82787'}; time used = 0.04196476936340332s
epoch 485: {'train_loss': '0.82784'}; time used = 0.04263782501220703s

epoch 490: {'train_loss': '0.82848'}; time used = 0.042183637619018555s
epoch 495: {'train_loss': '0.82759'}; time used = 0.05111813545227051s
epoch 500: {'train_loss': '0.82664'}; time used = 0.1257340908050537s
Finished training. Time used = 11.222009420394897.
Training classifier using 20.00% nodes...
{'micro': 0.7180433779418552, 'macro': 0.7086930594823889, 'samples': 0.7180433779418551, 'weighted': 0.7197080817976513}
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 59464.40it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.03658437728881836 seconds.
Run epoch 1
Epoch 1 ends in 0.036742448806762695 seconds.
5416 sentences created
mode 1: time used = 0.11303043365478516
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '1.38599'}; time used = 0.6404268741607666s
epoch 10: {'train_loss': '1.38611'}; time used = 0.41436767578125s
epoch 15: {'train_loss': '1.38528'}; time used = 0.5353057384490967s
epoch 20: {'train_loss': '1.38423'}; time used = 0.5599818229675293s
epoch 25: {'train_loss': '1.38304'}; time used = 0.5964856147766113s
epoch 30: {'train_loss': '1.37955'}; time used = 0.521949052810669s
epoch 35: {'train_loss': '1.37849'}; time used = 0.5090415477752686s
epoch 40: {'train_loss': '1.37970'}; time used = 0.5702841281890869s
epoch 45: {'train_loss': '1.37721'}; time used = 0.4944450855255127s
epoch 50: {'train_loss': '1.37606'}; time used = 0.6638791561126709s
epoch 55: {'train_loss': '1.37336'}; time used = 1.0102241039276123s
epoch 60: {'train_loss': '1.37204'}; time used = 1.0040416717529297s
epoch 65: {'train_loss': '1.36925'}; time used = 0.7027988433837891s
epoch 70: {'train_loss': '1.36244'}; time used = 0.645153284072876s
epoch 75: {'train_loss': '1.35580'}; time used = 0.5817060470581055s
epoch 80: {'train_loss': '1.35137'}; time used = 0.9861247539520264s
epoch 85: {'train_loss': '1.34590'}; time used = 0.8565847873687744s
epoch 90: {'train_loss': '1.34337'}; time used = 0.8069443702697754s
epoch 95: {'train_loss': '1.34000'}; time used = 0.6661896705627441s
epoch 100: {'train_loss': '1.33853'}; time used = 0.6984741687774658s
epoch 105: {'train_loss': '1.33714'}; time used = 0.5311472415924072s
epoch 110: {'train_loss': '1.33413'}; time used = 0.4868464469909668s
epoch 115: {'train_loss': '1.32852'}; time used = 0.5443439483642578s
epoch 120: {'train_loss': '1.30078'}; time used = 0.5403432846069336s
epoch 125: {'train_loss': '1.28050'}; time used = 0.46406984329223633s
epoch 130: {'train_loss': '1.25603'}; time used = 0.5504393577575684s
epoch 135: {'train_loss': '1.22919'}; time used = 0.47208690643310547s
epoch 140: {'train_loss': '1.20647'}; time used = 0.7477412223815918s
epoch 145: {'train_loss': '1.18665'}; time used = 0.573150634765625s
epoch 150: {'train_loss': '1.17246'}; time used = 0.48198676109313965s
epoch 155: {'train_loss': '1.15678'}; time used = 0.4915034770965576s
epoch 160: {'train_loss': '1.15006'}; time used = 0.5453112125396729s
epoch 165: {'train_loss': '1.14202'}; time used = 0.7208070755004883s
epoch 170: {'train_loss': '1.13846'}; time used = 0.7038848400115967s
epoch 175: {'train_loss': '1.13590'}; time used = 1.2402348518371582s
epoch 180: {'train_loss': '1.12759'}; time used = 1.0047328472137451s
epoch 185: {'train_loss': '1.12765'}; time used = 1.21309232711792s
epoch 190: {'train_loss': '1.12553'}; time used = 0.7890219688415527s
epoch 195: {'train_loss': '1.12269'}; time used = 0.7840080261230469s
epoch 200: {'train_loss': '1.12054'}; time used = 0.551095724105835s
epoch 205: {'train_loss': '1.12132'}; time used = 0.5359468460083008s
epoch 210: {'train_loss': '1.11722'}; time used = 0.5448813438415527s
epoch 215: {'train_loss': '1.11727'}; time used = 0.680056095123291s
epoch 220: {'train_loss': '1.11514'}; time used = 0.7684788703918457s
epoch 225: {'train_loss': '1.11402'}; time used = 0.674598217010498s
epoch 230: {'train_loss': '1.10929'}; time used = 0.4767765998840332s
epoch 235: {'train_loss': '1.11429'}; time used = 0.5647614002227783s
epoch 240: {'train_loss': '1.11175'}; time used = 0.4511988162994385s
epoch 245: {'train_loss': '1.11291'}; time used = 0.520240068435669s
epoch 250: {'train_loss': '1.10765'}; time used = 0.42052769660949707s
epoch 255: {'train_loss': '1.10594'}; time used = 0.559119462966919s
epoch 260: {'train_loss': '1.10599'}; time used = 0.4061276912689209s
epoch 265: {'train_loss': '1.10521'}; time used = 0.4952394962310791s
epoch 270: {'train_loss': '1.10585'}; time used = 0.3959999084472656s
epoch 275: {'train_loss': '1.10812'}; time used = 0.562281608581543s
epoch 280: {'train_loss': '1.10511'}; time used = 0.569225549697876s
epoch 285: {'train_loss': '1.10157'}; time used = 0.8364393711090088s
epoch 290: {'train_loss': '1.10594'}; time used = 1.0696070194244385s
epoch 295: {'train_loss': '1.10514'}; time used = 0.8089754581451416s
epoch 300: {'train_loss': '1.10666'}; time used = 0.6879711151123047s
epoch 305: {'train_loss': '1.10338'}; time used = 0.5279271602630615s
epoch 310: {'train_loss': '1.10154'}; time used = 0.7055690288543701s
epoch 315: {'train_loss': '1.10534'}; time used = 0.8854942321777344s
epoch 320: {'train_loss': '1.10232'}; time used = 0.6490466594696045s
epoch 325: {'train_loss': '1.10070'}; time used = 0.6919028759002686s
epoch 330: {'train_loss': '1.09831'}; time used = 0.6000256538391113s
epoch 335: {'train_loss': '1.09997'}; time used = 0.6112227439880371s
epoch 340: {'train_loss': '1.10296'}; time used = 0.5066559314727783s
epoch 345: {'train_loss': '1.09740'}; time used = 0.8210420608520508s
epoch 350: {'train_loss': '1.09729'}; time used = 0.9332270622253418s
epoch 355: {'train_loss': '1.09963'}; time used = 0.5715034008026123s
epoch 360: {'train_loss': '1.09838'}; time used = 0.6381938457489014s
epoch 365: {'train_loss': '1.09562'}; time used = 0.441051721572876s
epoch 370: {'train_loss': '1.09843'}; time used = 0.42881202697753906s
epoch 375: {'train_loss': '1.10136'}; time used = 0.4306986331939697s
epoch 380: {'train_loss': '1.09927'}; time used = 0.49665188789367676s
epoch 385: {'train_loss': '1.09904'}; time used = 0.4489166736602783s
epoch 390: {'train_loss': '1.09929'}; time used = 0.5467672348022461s
epoch 395: {'train_loss': '1.09636'}; time used = 0.4363124370574951s
epoch 400: {'train_loss': '1.09960'}; time used = 0.46375536918640137s
epoch 405: {'train_loss': '1.09419'}; time used = 0.5150158405303955s
epoch 410: {'train_loss': '1.10067'}; time used = 0.4394547939300537s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 61.1900417804718.
Training classifier using 20.00% nodes...
{'micro': 0.4388555606829718, 'macro': 0.22802811320083533, 'samples': 0.4388555606829718, 'weighted': 0.3324809502056365}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 138299.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16630/75824 [00:00<00:00, 166293.02it/s] 47%|████▋     | 35303/75824 [00:00<00:00, 171309.84it/s] 62%|██████▏   | 47225/75824 [00:00<00:00, 151454.91it/s] 85%|████████▍ | 64407/75824 [00:00<00:00, 157037.86it/s]100%|██████████| 75824/75824 [00:00<00:00, 165273.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19111/75824 [00:00<00:00, 191107.45it/s] 45%|████▍     | 34107/75824 [00:00<00:00, 176571.12it/s] 57%|█████▋    | 43279/75824 [00:00<00:00, 138207.56it/s] 70%|██████▉   | 52703/75824 [00:00<00:00, 121236.94it/s] 98%|█████████▊| 73979/75824 [00:00<00:00, 139200.10it/s]100%|██████████| 75824/75824 [00:00<00:00, 148927.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  4%|▍         | 3053/75824 [00:00<00:02, 30525.52it/s] 14%|█▍        | 10523/75824 [00:00<00:01, 36701.98it/s] 24%|██▍       | 18109/75824 [00:00<00:01, 43426.53it/s] 40%|███▉      | 30263/75824 [00:00<00:00, 53799.18it/s] 56%|█████▌    | 42236/75824 [00:00<00:00, 64445.48it/s] 67%|██████▋   | 50431/75824 [00:00<00:00, 64383.34it/s] 92%|█████████▏| 69745/75824 [00:00<00:00, 80478.20it/s]100%|██████████| 75824/75824 [00:00<00:00, 98959.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|█         | 7742/75824 [00:00<00:00, 73258.74it/s] 15%|█▌        | 11489/75824 [00:00<00:01, 54442.69it/s] 30%|███       | 22975/75824 [00:00<00:00, 64643.60it/s] 46%|████▌     | 34664/75824 [00:00<00:00, 74653.21it/s] 62%|██████▏   | 47104/75824 [00:00<00:00, 84829.85it/s] 89%|████████▉ | 67734/75824 [00:00<00:00, 103028.90it/s]100%|██████████| 75824/75824 [00:00<00:00, 116312.56it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17775/75824 [00:00<00:00, 177741.27it/s] 46%|████▋     | 35243/75824 [00:00<00:00, 176809.30it/s] 68%|██████▊   | 51620/75824 [00:00<00:00, 172681.90it/s] 95%|█████████▍| 71780/75824 [00:00<00:00, 180446.29it/s]100%|██████████| 75824/75824 [00:00<00:00, 180506.97it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19369/75824 [00:00<00:00, 193682.33it/s] 50%|████▉     | 37906/75824 [00:00<00:00, 191111.17it/s] 78%|███████▊  | 58809/75824 [00:00<00:00, 196154.47it/s]100%|██████████| 75824/75824 [00:00<00:00, 196160.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18763/75824 [00:00<00:00, 187620.34it/s] 52%|█████▏    | 39615/75824 [00:00<00:00, 193435.60it/s] 79%|███████▉  | 59906/75824 [00:00<00:00, 196182.26it/s]100%|██████████| 75824/75824 [00:00<00:00, 192902.27it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18048/75824 [00:00<00:00, 177902.59it/s] 52%|█████▏    | 39142/75824 [00:00<00:00, 186672.50it/s] 78%|███████▊  | 58780/75824 [00:00<00:00, 189481.34it/s]100%|██████████| 75824/75824 [00:00<00:00, 196119.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|█▍        | 10908/75824 [00:00<00:00, 105740.47it/s] 30%|██▉       | 22522/75824 [00:00<00:00, 108656.28it/s] 47%|████▋     | 35762/75824 [00:00<00:00, 114833.18it/s] 71%|███████   | 53732/75824 [00:00<00:00, 128777.59it/s] 95%|█████████▍| 71796/75824 [00:00<00:00, 140912.96it/s]100%|██████████| 75824/75824 [00:00<00:00, 144239.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14625/75824 [00:00<00:00, 146247.70it/s] 38%|███▊      | 28442/75824 [00:00<00:00, 142579.27it/s] 51%|█████     | 38605/75824 [00:00<00:00, 127200.91it/s] 72%|███████▏  | 54886/75824 [00:00<00:00, 136132.31it/s] 96%|█████████▌| 72506/75824 [00:00<00:00, 146099.01it/s]100%|██████████| 75824/75824 [00:00<00:00, 145219.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▌        | 11749/75824 [00:00<00:00, 117446.71it/s] 28%|██▊       | 21190/75824 [00:00<00:00, 109433.55it/s] 44%|████▎     | 32991/75824 [00:00<00:00, 111870.65it/s] 61%|██████    | 46293/75824 [00:00<00:00, 117473.90it/s] 81%|████████  | 61298/75824 [00:00<00:00, 125656.59it/s]100%|██████████| 75824/75824 [00:00<00:00, 130467.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▊        | 14081/75824 [00:00<00:00, 140808.46it/s] 38%|███▊      | 28676/75824 [00:00<00:00, 142310.23it/s] 62%|██████▏   | 47349/75824 [00:00<00:00, 153245.95it/s] 87%|████████▋ | 65671/75824 [00:00<00:00, 161153.98it/s]100%|██████████| 75824/75824 [00:00<00:00, 166729.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17357/75824 [00:00<00:00, 173566.44it/s] 39%|███▉      | 29906/75824 [00:00<00:00, 155673.84it/s] 56%|█████▌    | 42259/75824 [00:00<00:00, 144400.00it/s] 67%|██████▋   | 51152/75824 [00:00<00:00, 101288.91it/s] 78%|███████▊  | 59168/75824 [00:00<00:00, 89300.61it/s]  88%|████████▊ | 66879/75824 [00:00<00:00, 78925.31it/s]100%|██████████| 75824/75824 [00:00<00:00, 102374.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13773/75824 [00:00<00:00, 137726.19it/s] 35%|███▌      | 26720/75824 [00:00<00:00, 135135.34it/s] 44%|████▍     | 33730/75824 [00:00<00:00, 103847.16it/s] 56%|█████▋    | 42756/75824 [00:00<00:00, 99357.74it/s]  66%|██████▌   | 50200/75824 [00:00<00:00, 74861.48it/s] 78%|███████▊  | 59457/75824 [00:00<00:00, 78354.80it/s] 96%|█████████▌| 72950/75824 [00:00<00:00, 89628.09it/s]100%|██████████| 75824/75824 [00:00<00:00, 95855.70it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12533/75824 [00:00<00:00, 118703.14it/s] 26%|██▋       | 20008/75824 [00:00<00:00, 100903.33it/s] 47%|████▋     | 35993/75824 [00:00<00:00, 113453.95it/s] 66%|██████▌   | 49918/75824 [00:00<00:00, 120128.80it/s] 89%|████████▉ | 67429/75824 [00:00<00:00, 132620.82it/s]100%|██████████| 75824/75824 [00:00<00:00, 137533.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18214/75824 [00:00<00:00, 182132.36it/s] 50%|████▉     | 37800/75824 [00:00<00:00, 186043.30it/s] 76%|███████▌  | 57324/75824 [00:00<00:00, 188709.30it/s]100%|██████████| 75824/75824 [00:00<00:00, 194489.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20113/75824 [00:00<00:00, 201120.60it/s] 54%|█████▍    | 41007/75824 [00:00<00:00, 203403.19it/s] 82%|████████▏ | 62411/75824 [00:00<00:00, 206481.46it/s]100%|██████████| 75824/75824 [00:00<00:00, 211918.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|██▊       | 21564/75824 [00:00<00:00, 215634.04it/s] 59%|█████▊    | 44454/75824 [00:00<00:00, 219448.82it/s] 87%|████████▋ | 66069/75824 [00:00<00:00, 218447.29it/s]100%|██████████| 75824/75824 [00:00<00:00, 219406.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18709/75824 [00:00<00:00, 187087.95it/s] 44%|████▍     | 33260/75824 [00:00<00:00, 172313.93it/s] 55%|█████▌    | 41793/75824 [00:00<00:00, 131955.49it/s] 75%|███████▌  | 57213/75824 [00:00<00:00, 137922.75it/s]100%|██████████| 75824/75824 [00:00<00:00, 151979.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16658/75824 [00:00<00:00, 166579.76it/s] 43%|████▎     | 32564/75824 [00:00<00:00, 164249.42it/s] 71%|███████   | 53693/75824 [00:00<00:00, 176003.88it/s] 96%|█████████▌| 72827/75824 [00:00<00:00, 180336.99it/s]100%|██████████| 75824/75824 [00:00<00:00, 178707.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19792/75824 [00:00<00:00, 197919.24it/s] 55%|█████▌    | 41851/75824 [00:00<00:00, 204213.24it/s] 81%|████████  | 61369/75824 [00:00<00:00, 201415.69it/s]100%|██████████| 75824/75824 [00:00<00:00, 203166.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18662/75824 [00:00<00:00, 186618.40it/s] 51%|█████     | 38423/75824 [00:00<00:00, 189783.54it/s] 77%|███████▋  | 58195/75824 [00:00<00:00, 192094.95it/s]100%|██████████| 75824/75824 [00:00<00:00, 195431.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18729/75824 [00:00<00:00, 187284.37it/s] 50%|████▉     | 37698/75824 [00:00<00:00, 187999.28it/s] 72%|███████▏  | 54953/75824 [00:00<00:00, 183077.92it/s] 89%|████████▊ | 67120/75824 [00:00<00:00, 158999.66it/s]100%|██████████| 75824/75824 [00:00<00:00, 169813.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18472/75824 [00:00<00:00, 184714.45it/s] 51%|█████     | 38365/75824 [00:00<00:00, 188758.99it/s] 69%|██████▊   | 52016/75824 [00:00<00:00, 169316.83it/s] 94%|█████████▍| 71201/75824 [00:00<00:00, 175499.83it/s]100%|██████████| 75824/75824 [00:00<00:00, 178821.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13631/75824 [00:00<00:00, 136299.73it/s] 39%|███▉      | 29431/75824 [00:00<00:00, 142155.79it/s] 66%|██████▌   | 49768/75824 [00:00<00:00, 156265.72it/s] 92%|█████████▏| 69861/75824 [00:00<00:00, 167431.02it/s]100%|██████████| 75824/75824 [00:00<00:00, 176828.90it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▊        | 14183/75824 [00:00<00:00, 141825.74it/s] 37%|███▋      | 28210/75824 [00:00<00:00, 141349.23it/s] 47%|████▋     | 35396/75824 [00:00<00:00, 96898.61it/s]  69%|██████▊   | 52006/75824 [00:00<00:00, 109866.29it/s] 81%|████████  | 61494/75824 [00:00<00:00, 91994.22it/s] 100%|██████████| 75824/75824 [00:00<00:00, 112945.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 11878/75824 [00:00<00:00, 118773.32it/s] 32%|███▏      | 24509/75824 [00:00<00:00, 120936.46it/s] 49%|████▉     | 37167/75824 [00:00<00:00, 122573.03it/s] 67%|██████▋   | 50651/75824 [00:00<00:00, 126011.80it/s] 80%|███████▉  | 60433/75824 [00:00<00:00, 79472.65it/s]  93%|█████████▎| 70547/75824 [00:00<00:00, 84930.88it/s]100%|██████████| 75824/75824 [00:00<00:00, 98417.91it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12967/75824 [00:00<00:00, 129659.92it/s] 39%|███▊      | 29330/75824 [00:00<00:00, 138270.97it/s] 62%|██████▏   | 47098/75824 [00:00<00:00, 148126.14it/s] 78%|███████▊  | 59518/75824 [00:00<00:00, 140032.06it/s] 93%|█████████▎| 70715/75824 [00:00<00:00, 130079.14it/s]100%|██████████| 75824/75824 [00:00<00:00, 144354.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20348/75824 [00:00<00:00, 203479.71it/s] 55%|█████▌    | 41966/75824 [00:00<00:00, 207129.36it/s] 85%|████████▌ | 64483/75824 [00:00<00:00, 212230.03it/s]100%|██████████| 75824/75824 [00:00<00:00, 216786.55it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19322/75824 [00:00<00:00, 193215.58it/s] 54%|█████▍    | 41073/75824 [00:00<00:00, 199905.16it/s] 82%|████████▏ | 62154/75824 [00:00<00:00, 203055.78it/s]100%|██████████| 75824/75824 [00:00<00:00, 210022.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|██▉       | 21857/75824 [00:00<00:00, 218559.27it/s] 60%|██████    | 45703/75824 [00:00<00:00, 224170.91it/s] 91%|█████████ | 68661/75824 [00:00<00:00, 225765.00it/s]100%|██████████| 75824/75824 [00:00<00:00, 220239.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 14843/75824 [00:00<00:00, 148429.08it/s] 44%|████▎     | 33037/75824 [00:00<00:00, 157108.47it/s] 69%|██████▉   | 52235/75824 [00:00<00:00, 166161.70it/s] 93%|█████████▎| 70485/75824 [00:00<00:00, 170747.25it/s]100%|██████████| 75824/75824 [00:00<00:00, 177933.00it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|█▎        | 9867/75824 [00:00<00:00, 98666.33it/s] 32%|███▏      | 24021/75824 [00:00<00:00, 108527.85it/s] 57%|█████▋    | 43395/75824 [00:00<00:00, 125023.73it/s] 84%|████████▍ | 63765/75824 [00:00<00:00, 141408.07it/s]100%|██████████| 75824/75824 [00:00<00:00, 165245.53it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 14831/75824 [00:00<00:00, 148306.61it/s] 38%|███▊      | 29174/75824 [00:00<00:00, 146808.23it/s] 52%|█████▏    | 39712/75824 [00:00<00:00, 131315.97it/s] 69%|██████▊   | 52023/75824 [00:00<00:00, 128739.97it/s] 89%|████████▊ | 67230/75824 [00:00<00:00, 134948.97it/s]100%|██████████| 75824/75824 [00:00<00:00, 136207.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▊        | 14171/75824 [00:00<00:00, 141707.77it/s] 38%|███▊      | 29061/75824 [00:00<00:00, 143789.76it/s] 60%|██████    | 45779/75824 [00:00<00:00, 150087.70it/s] 74%|███████▍  | 56005/75824 [00:00<00:00, 123878.79it/s] 87%|████████▋ | 65804/75824 [00:00<00:00, 108240.84it/s]100%|██████████| 75824/75824 [00:00<00:00, 121252.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  4%|▍         | 3100/75824 [00:00<00:02, 30999.14it/s] 26%|██▌       | 19561/75824 [00:00<00:01, 40977.27it/s] 39%|███▉      | 29798/75824 [00:00<00:00, 49967.01it/s] 49%|████▊     | 36813/75824 [00:00<00:00, 54685.26it/s] 66%|██████▋   | 50353/75824 [00:00<00:00, 66594.67it/s] 97%|█████████▋| 73639/75824 [00:00<00:00, 84748.01it/s]100%|██████████| 75824/75824 [00:00<00:00, 124462.00it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▍        | 11300/75824 [00:00<00:00, 112993.10it/s] 30%|██▉       | 22745/75824 [00:00<00:00, 113426.21it/s] 54%|█████▍    | 40924/75824 [00:00<00:00, 127849.40it/s] 78%|███████▊  | 59199/75824 [00:00<00:00, 140512.81it/s]100%|██████████| 75824/75824 [00:00<00:00, 154714.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▎       | 17992/75824 [00:00<00:00, 179912.88it/s] 47%|████▋     | 35878/75824 [00:00<00:00, 179595.38it/s] 75%|███████▌  | 56940/75824 [00:00<00:00, 187896.83it/s] 92%|█████████▏| 69660/75824 [00:00<00:00, 142373.17it/s]100%|██████████| 75824/75824 [00:00<00:00, 149808.57it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 14863/75824 [00:00<00:00, 148624.47it/s] 34%|███▍      | 25741/75824 [00:00<00:00, 133906.60it/s] 42%|████▏     | 32126/75824 [00:00<00:00, 78256.81it/s]  56%|█████▌    | 42613/75824 [00:00<00:00, 84705.44it/s] 66%|██████▌   | 50048/75824 [00:00<00:00, 81303.90it/s] 76%|███████▌  | 57416/75824 [00:00<00:00, 78822.59it/s] 90%|█████████ | 68493/75824 [00:00<00:00, 86288.37it/s]100%|██████████| 75824/75824 [00:00<00:00, 94988.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|██        | 15375/75824 [00:00<00:00, 153745.38it/s] 39%|███▉      | 29626/75824 [00:00<00:00, 150190.49it/s] 49%|████▉     | 37130/75824 [00:00<00:00, 95727.12it/s]  72%|███████▏  | 54687/75824 [00:00<00:00, 110040.45it/s] 85%|████████▌ | 64523/75824 [00:00<00:00, 94455.14it/s] 100%|██████████| 75824/75824 [00:00<00:00, 117936.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12735/75824 [00:00<00:00, 127343.75it/s] 38%|███▊      | 28979/75824 [00:00<00:00, 136168.92it/s] 61%|██████▏   | 46532/75824 [00:00<00:00, 145988.58it/s] 88%|████████▊ | 66409/75824 [00:00<00:00, 158624.55it/s]100%|██████████| 75824/75824 [00:00<00:00, 169570.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19427/75824 [00:00<00:00, 194264.63it/s] 49%|████▉     | 37405/75824 [00:00<00:00, 189678.58it/s] 66%|██████▌   | 49927/75824 [00:00<00:00, 164304.12it/s] 90%|█████████ | 68499/75824 [00:00<00:00, 170190.63it/s]100%|██████████| 75824/75824 [00:00<00:00, 173937.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19022/75824 [00:00<00:00, 190213.38it/s] 53%|█████▎    | 40324/75824 [00:00<00:00, 196524.34it/s] 79%|███████▉  | 60201/75824 [00:00<00:00, 197190.51it/s]100%|██████████| 75824/75824 [00:00<00:00, 199776.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18471/75824 [00:00<00:00, 184707.97it/s] 50%|████▉     | 37909/75824 [00:00<00:00, 187506.52it/s] 75%|███████▍  | 56784/75824 [00:00<00:00, 187877.09it/s]100%|██████████| 75824/75824 [00:00<00:00, 192780.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18537/75824 [00:00<00:00, 185362.66it/s] 47%|████▋     | 35486/75824 [00:00<00:00, 180297.02it/s] 59%|█████▊    | 44464/75824 [00:00<00:00, 120795.98it/s] 70%|██████▉   | 52796/75824 [00:00<00:00, 92204.72it/s]  93%|█████████▎| 70201/75824 [00:00<00:00, 107348.53it/s]100%|██████████| 75824/75824 [00:00<00:00, 126424.19it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18840/75824 [00:00<00:00, 188397.93it/s] 45%|████▍     | 33910/75824 [00:00<00:00, 175243.16it/s] 65%|██████▌   | 49377/75824 [00:00<00:00, 168515.89it/s] 90%|█████████ | 68387/75824 [00:00<00:00, 174456.55it/s]100%|██████████| 75824/75824 [00:00<00:00, 170387.20it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17679/75824 [00:00<00:00, 176786.38it/s] 51%|█████     | 38474/75824 [00:00<00:00, 185107.54it/s] 79%|███████▉  | 59823/75824 [00:00<00:00, 192795.89it/s]100%|██████████| 75824/75824 [00:00<00:00, 198111.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19042/75824 [00:00<00:00, 190412.46it/s] 52%|█████▏    | 39314/75824 [00:00<00:00, 193944.16it/s] 73%|███████▎  | 55186/75824 [00:00<00:00, 181834.71it/s] 91%|█████████ | 69063/75824 [00:00<00:00, 166342.02it/s]100%|██████████| 75824/75824 [00:00<00:00, 163696.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  4%|▍         | 3383/75824 [00:00<00:02, 30535.18it/s] 11%|█         | 7979/75824 [00:00<00:01, 33953.35it/s] 21%|██▏       | 16290/75824 [00:00<00:01, 41277.22it/s] 27%|██▋       | 20198/75824 [00:00<00:01, 39357.51it/s] 43%|████▎     | 32427/75824 [00:00<00:00, 49409.68it/s] 61%|██████    | 46009/75824 [00:00<00:00, 61064.46it/s] 77%|███████▋  | 58194/75824 [00:00<00:00, 71607.56it/s]100%|██████████| 75824/75824 [00:00<00:00, 93238.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 14922/75824 [00:00<00:00, 144648.89it/s] 25%|██▌       | 19262/75824 [00:00<00:00, 68198.96it/s]  36%|███▌      | 26920/75824 [00:00<00:00, 70169.89it/s] 42%|████▏     | 31945/75824 [00:00<00:00, 58394.35it/s] 58%|█████▊    | 43923/75824 [00:00<00:00, 69002.95it/s] 73%|███████▎  | 55709/75824 [00:00<00:00, 78456.20it/s] 88%|████████▊ | 66761/75824 [00:00<00:00, 85934.65it/s]100%|██████████| 75824/75824 [00:00<00:00, 92284.74it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19392/75824 [00:00<00:00, 193918.80it/s] 47%|████▋     | 35791/75824 [00:00<00:00, 183480.33it/s] 59%|█████▉    | 44754/75824 [00:00<00:00, 135467.85it/s] 88%|████████▊ | 66452/75824 [00:00<00:00, 152673.26it/s]100%|██████████| 75824/75824 [00:00<00:00, 169083.91it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19891/75824 [00:00<00:00, 198909.72it/s] 57%|█████▋    | 43367/75824 [00:00<00:00, 208458.11it/s] 87%|████████▋ | 65906/75824 [00:00<00:00, 213262.15it/s]100%|██████████| 75824/75824 [00:00<00:00, 222811.83it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|██▉       | 22322/75824 [00:00<00:00, 223218.62it/s] 56%|█████▌    | 42177/75824 [00:00<00:00, 215196.59it/s] 83%|████████▎ | 62620/75824 [00:00<00:00, 211848.67it/s]100%|██████████| 75824/75824 [00:00<00:00, 208822.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18826/75824 [00:00<00:00, 188251.65it/s] 51%|█████▏    | 38987/75824 [00:00<00:00, 191755.71it/s] 80%|███████▉  | 60456/75824 [00:00<00:00, 198102.83it/s]100%|██████████| 75824/75824 [00:00<00:00, 205915.52it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|██▊       | 21564/75824 [00:00<00:00, 215636.09it/s] 52%|█████▏    | 39558/75824 [00:00<00:00, 203523.29it/s] 78%|███████▊  | 59133/75824 [00:00<00:00, 201126.27it/s]100%|██████████| 75824/75824 [00:00<00:00, 206584.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|██▊       | 21622/75824 [00:00<00:00, 216214.54it/s] 60%|█████▉    | 45445/75824 [00:00<00:00, 222379.51it/s] 75%|███████▌  | 57133/75824 [00:00<00:00, 143854.79it/s] 96%|█████████▌| 72649/75824 [00:00<00:00, 147069.15it/s]100%|██████████| 75824/75824 [00:00<00:00, 162178.14it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|██▊       | 21625/75824 [00:00<00:00, 216247.11it/s] 59%|█████▉    | 44946/75824 [00:00<00:00, 221068.91it/s] 89%|████████▉ | 67707/75824 [00:00<00:00, 222989.14it/s]100%|██████████| 75824/75824 [00:00<00:00, 226869.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|▉         | 7266/75824 [00:00<00:00, 72658.51it/s] 33%|███▎      | 25087/75824 [00:00<00:00, 88358.44it/s] 64%|██████▍   | 48761/75824 [00:00<00:00, 108819.55it/s] 96%|█████████▌| 72532/75824 [00:00<00:00, 129958.98it/s]100%|██████████| 75824/75824 [00:00<00:00, 183187.09it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 30%|██▉       | 22457/75824 [00:00<00:00, 224566.47it/s] 59%|█████▊    | 44397/75824 [00:00<00:00, 222989.76it/s] 88%|████████▊ | 67050/75824 [00:00<00:00, 224039.59it/s]100%|██████████| 75824/75824 [00:00<00:00, 225573.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 14009/75824 [00:00<00:00, 140087.13it/s] 33%|███▎      | 25358/75824 [00:00<00:00, 130884.83it/s] 52%|█████▏    | 39129/75824 [00:00<00:00, 132860.22it/s] 79%|███████▉  | 60242/75824 [00:00<00:00, 149484.73it/s]100%|██████████| 75824/75824 [00:00<00:00, 161931.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14723/75824 [00:00<00:00, 141721.51it/s] 27%|██▋       | 20597/75824 [00:00<00:00, 99533.54it/s]  47%|████▋     | 35499/75824 [00:00<00:00, 110507.70it/s] 57%|█████▋    | 43280/75824 [00:00<00:00, 84256.39it/s]  66%|██████▋   | 50353/75824 [00:00<00:00, 79143.56it/s] 76%|███████▌  | 57596/75824 [00:00<00:00, 76999.85it/s] 87%|████████▋ | 66168/75824 [00:00<00:00, 79422.55it/s] 99%|█████████▊| 74854/75824 [00:00<00:00, 81513.70it/s]100%|██████████| 75824/75824 [00:00<00:00, 88055.11it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|█▍        | 10819/75824 [00:00<00:00, 108181.33it/s] 32%|███▏      | 24145/75824 [00:00<00:00, 114652.06it/s] 40%|████      | 30415/75824 [00:00<00:00, 90096.00it/s]  48%|████▊     | 36606/75824 [00:00<00:00, 74714.08it/s] 61%|██████▏   | 46500/75824 [00:00<00:00, 80636.73it/s] 75%|███████▌  | 56956/75824 [00:00<00:00, 85725.58it/s] 86%|████████▌ | 64959/75824 [00:00<00:00, 80497.86it/s]100%|██████████| 75824/75824 [00:00<00:00, 91409.10it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17070/75824 [00:00<00:00, 170697.31it/s] 48%|████▊     | 36364/75824 [00:00<00:00, 176809.84it/s] 74%|███████▍  | 55972/75824 [00:00<00:00, 182180.43it/s] 93%|█████████▎| 70466/75824 [00:00<00:00, 169141.66it/s]100%|██████████| 75824/75824 [00:00<00:00, 171070.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19837/75824 [00:00<00:00, 198359.78it/s] 55%|█████▍    | 41335/75824 [00:00<00:00, 203068.02it/s] 83%|████████▎ | 63312/75824 [00:00<00:00, 207804.63it/s]100%|██████████| 75824/75824 [00:00<00:00, 206800.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▎       | 17822/75824 [00:00<00:00, 178217.62it/s] 40%|███▉      | 30221/75824 [00:00<00:00, 157545.27it/s] 66%|██████▌   | 49980/75824 [00:00<00:00, 167743.19it/s] 92%|█████████▏| 69800/75824 [00:00<00:00, 175848.15it/s]100%|██████████| 75824/75824 [00:00<00:00, 176368.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20719/75824 [00:00<00:00, 207186.74it/s] 56%|█████▌    | 42393/75824 [00:00<00:00, 209960.40it/s] 78%|███████▊  | 59430/75824 [00:00<00:00, 196273.86it/s]100%|██████████| 75824/75824 [00:00<00:00, 200380.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18229/75824 [00:00<00:00, 182283.22it/s] 50%|████▉     | 37555/75824 [00:00<00:00, 185441.96it/s] 75%|███████▌  | 56871/75824 [00:00<00:00, 187689.92it/s]100%|██████████| 75824/75824 [00:00<00:00, 192288.78it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20192/75824 [00:00<00:00, 201907.68it/s] 54%|█████▍    | 40923/75824 [00:00<00:00, 203496.92it/s] 81%|████████  | 61059/75824 [00:00<00:00, 202849.11it/s]100%|██████████| 75824/75824 [00:00<00:00, 202755.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19244/75824 [00:00<00:00, 192434.68it/s] 49%|████▉     | 37466/75824 [00:00<00:00, 189250.53it/s] 72%|███████▏  | 54704/75824 [00:00<00:00, 183851.04it/s] 88%|████████▊ | 66531/75824 [00:00<00:00, 117679.93it/s]100%|██████████| 75824/75824 [00:00<00:00, 120600.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20596/75824 [00:00<00:00, 205948.90it/s] 43%|████▎     | 32425/75824 [00:00<00:00, 168489.00it/s] 69%|██████▊   | 52001/75824 [00:00<00:00, 175836.28it/s] 95%|█████████▌| 72082/75824 [00:00<00:00, 182649.03it/s]100%|██████████| 75824/75824 [00:00<00:00, 180912.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20417/75824 [00:00<00:00, 204163.87it/s] 54%|█████▎    | 40620/75824 [00:00<00:00, 203517.43it/s] 79%|███████▊  | 59659/75824 [00:00<00:00, 199390.20it/s]100%|██████████| 75824/75824 [00:00<00:00, 199066.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13404/75824 [00:00<00:00, 134037.25it/s] 34%|███▎      | 25414/75824 [00:00<00:00, 127484.93it/s] 44%|████▍     | 33442/75824 [00:00<00:00, 108368.11it/s] 60%|█████▉    | 45181/75824 [00:00<00:00, 110925.06it/s] 70%|███████   | 53450/75824 [00:00<00:00, 92016.64it/s]  88%|████████▊ | 66488/75824 [00:00<00:00, 100924.59it/s]100%|██████████| 75824/75824 [00:00<00:00, 98306.26it/s] 
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19649/75824 [00:00<00:00, 196487.85it/s] 47%|████▋     | 35893/75824 [00:00<00:00, 184858.58it/s] 60%|█████▉    | 45319/75824 [00:00<00:00, 143483.29it/s] 72%|███████▏  | 54447/75824 [00:00<00:00, 105344.21it/s] 83%|████████▎ | 62787/75824 [00:00<00:00, 83122.71it/s]  93%|█████████▎| 70296/75824 [00:00<00:00, 76689.72it/s]100%|██████████| 75824/75824 [00:00<00:00, 101814.15it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|█         | 7874/75824 [00:00<00:00, 78735.57it/s] 27%|██▋       | 20705/75824 [00:00<00:00, 89057.48it/s] 51%|█████     | 38365/75824 [00:00<00:00, 104614.71it/s] 75%|███████▌  | 56946/75824 [00:00<00:00, 120398.05it/s] 95%|█████████▍| 71681/75824 [00:00<00:00, 127387.67it/s]100%|██████████| 75824/75824 [00:00<00:00, 142197.79it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19725/75824 [00:00<00:00, 197249.25it/s] 53%|█████▎    | 39920/75824 [00:00<00:00, 198635.41it/s] 80%|████████  | 60902/75824 [00:00<00:00, 201863.33it/s]100%|██████████| 75824/75824 [00:00<00:00, 207037.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18750/75824 [00:00<00:00, 187498.84it/s] 53%|█████▎    | 40442/75824 [00:00<00:00, 195450.19it/s] 81%|████████  | 61520/75824 [00:00<00:00, 199807.66it/s]100%|██████████| 75824/75824 [00:00<00:00, 211588.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 31%|███       | 23200/75824 [00:00<00:00, 231995.80it/s] 57%|█████▋    | 43575/75824 [00:00<00:00, 222732.14it/s] 87%|████████▋ | 65650/75824 [00:00<00:00, 222132.24it/s]100%|██████████| 75824/75824 [00:00<00:00, 221205.65it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20782/75824 [00:00<00:00, 207815.24it/s] 57%|█████▋    | 42918/75824 [00:00<00:00, 211700.56it/s] 83%|████████▎ | 62942/75824 [00:00<00:00, 208125.18it/s]100%|██████████| 75824/75824 [00:00<00:00, 209828.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14420/75824 [00:00<00:00, 144198.42it/s] 38%|███▊      | 28815/75824 [00:00<00:00, 144123.33it/s] 51%|█████     | 38837/75824 [00:00<00:00, 127380.56it/s] 73%|███████▎  | 55612/75824 [00:00<00:00, 137291.16it/s]100%|█████████▉| 75576/75824 [00:00<00:00, 151482.94it/s]100%|██████████| 75824/75824 [00:00<00:00, 151214.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18808/75824 [00:00<00:00, 188076.14it/s] 51%|█████     | 38794/75824 [00:00<00:00, 191461.90it/s] 78%|███████▊  | 59319/75824 [00:00<00:00, 195398.54it/s]100%|██████████| 75824/75824 [00:00<00:00, 199302.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▌        | 11510/75824 [00:00<00:00, 115098.74it/s] 42%|████▏     | 32018/75824 [00:00<00:00, 132545.47it/s] 69%|██████▉   | 52299/75824 [00:00<00:00, 147918.37it/s] 96%|█████████▌| 72782/75824 [00:00<00:00, 161367.52it/s]100%|██████████| 75824/75824 [00:00<00:00, 182809.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|██▊       | 21613/75824 [00:00<00:00, 216128.14it/s] 54%|█████▍    | 41044/75824 [00:00<00:00, 209082.00it/s] 81%|████████  | 61440/75824 [00:00<00:00, 207517.14it/s]100%|██████████| 75824/75824 [00:00<00:00, 204470.10it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18256/75824 [00:00<00:00, 182558.87it/s] 49%|████▊     | 36878/75824 [00:00<00:00, 183636.48it/s] 61%|██████    | 46298/75824 [00:00<00:00, 123377.28it/s] 76%|███████▋  | 57862/75824 [00:00<00:00, 120947.20it/s] 98%|█████████▊| 74443/75824 [00:00<00:00, 131631.07it/s]100%|██████████| 75824/75824 [00:00<00:00, 139639.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|▉         | 6976/75824 [00:00<00:01, 66606.87it/s] 17%|█▋        | 12575/75824 [00:00<00:01, 63019.63it/s] 26%|██▌       | 19540/75824 [00:00<00:00, 64871.15it/s] 37%|███▋      | 27730/75824 [00:00<00:00, 69186.31it/s] 44%|████▎     | 33158/75824 [00:00<00:00, 52534.09it/s] 53%|█████▎    | 39947/75824 [00:00<00:00, 56356.81it/s] 62%|██████▏   | 47078/75824 [00:00<00:00, 60139.74it/s] 70%|██████▉   | 53000/75824 [00:00<00:00, 51283.41it/s] 82%|████████▏ | 62399/75824 [00:01<00:00, 59375.57it/s] 91%|█████████ | 68922/75824 [00:01<00:00, 51515.33it/s] 98%|█████████▊| 74669/75824 [00:01<00:00, 51097.97it/s]100%|██████████| 75824/75824 [00:01<00:00, 57266.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▌        | 11576/75824 [00:00<00:00, 115759.01it/s] 40%|███▉      | 30256/75824 [00:00<00:00, 130665.53it/s] 65%|██████▍   | 48998/75824 [00:00<00:00, 143721.18it/s] 92%|█████████▏| 70011/75824 [00:00<00:00, 158773.87it/s]100%|██████████| 75824/75824 [00:00<00:00, 177296.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20488/75824 [00:00<00:00, 204870.43it/s] 53%|█████▎    | 40110/75824 [00:00<00:00, 202196.02it/s] 82%|████████▏ | 61849/75824 [00:00<00:00, 206525.36it/s]100%|██████████| 75824/75824 [00:00<00:00, 210150.89it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|██▉       | 22184/75824 [00:00<00:00, 221835.45it/s] 58%|█████▊    | 43853/75824 [00:00<00:00, 220263.68it/s] 78%|███████▊  | 59073/75824 [00:00<00:00, 194204.87it/s] 99%|█████████▉| 75162/75824 [00:00<00:00, 182844.31it/s]100%|██████████| 75824/75824 [00:00<00:00, 187877.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19867/75824 [00:00<00:00, 198665.45it/s] 55%|█████▌    | 41995/75824 [00:00<00:00, 204947.81it/s] 79%|███████▊  | 59649/75824 [00:00<00:00, 195506.69it/s]100%|██████████| 75824/75824 [00:00<00:00, 198849.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 13042/75824 [00:00<00:00, 130418.57it/s] 35%|███▍      | 26346/75824 [00:00<00:00, 131193.75it/s] 49%|████▊     | 36851/75824 [00:00<00:00, 122078.34it/s] 69%|██████▉   | 52602/75824 [00:00<00:00, 130912.12it/s] 99%|█████████▉| 75402/75824 [00:00<00:00, 150084.60it/s]100%|██████████| 75824/75824 [00:00<00:00, 150975.75it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|██▊       | 21370/75824 [00:00<00:00, 213692.56it/s] 58%|█████▊    | 43706/75824 [00:00<00:00, 216501.88it/s] 84%|████████▎ | 63384/75824 [00:00<00:00, 210180.64it/s]100%|██████████| 75824/75824 [00:00<00:00, 214787.60it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19548/75824 [00:00<00:00, 195477.39it/s] 55%|█████▍    | 41546/75824 [00:00<00:00, 202233.94it/s] 84%|████████▍ | 63713/75824 [00:00<00:00, 207694.91it/s]100%|██████████| 75824/75824 [00:00<00:00, 210429.55it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19360/75824 [00:00<00:00, 193593.26it/s] 52%|█████▏    | 39465/75824 [00:00<00:00, 195769.56it/s] 73%|███████▎  | 55558/75824 [00:00<00:00, 183827.29it/s] 92%|█████████▏| 69880/75824 [00:00<00:00, 169416.02it/s]100%|██████████| 75824/75824 [00:00<00:00, 176096.81it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18220/75824 [00:00<00:00, 182194.09it/s] 47%|████▋     | 35923/75824 [00:00<00:00, 180611.45it/s] 71%|███████   | 53947/75824 [00:00<00:00, 180498.87it/s] 98%|█████████▊| 74057/75824 [00:00<00:00, 186221.89it/s]100%|██████████| 75824/75824 [00:00<00:00, 185393.65it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19299/75824 [00:00<00:00, 192981.90it/s] 51%|█████▏    | 38932/75824 [00:00<00:00, 193972.42it/s] 68%|██████▊   | 51440/75824 [00:00<00:00, 166462.30it/s] 93%|█████████▎| 70309/75824 [00:00<00:00, 172559.40it/s]100%|██████████| 75824/75824 [00:00<00:00, 171246.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██        | 15962/75824 [00:00<00:00, 159616.35it/s] 33%|███▎      | 24785/75824 [00:00<00:00, 128436.32it/s] 49%|████▉     | 37087/75824 [00:00<00:00, 125605.71it/s] 59%|█████▉    | 44870/75824 [00:00<00:00, 97207.19it/s]  73%|███████▎  | 55021/75824 [00:00<00:00, 98456.46it/s] 83%|████████▎ | 63216/75824 [00:00<00:00, 90630.51it/s] 98%|█████████▊| 74485/75824 [00:00<00:00, 96284.15it/s]100%|██████████| 75824/75824 [00:00<00:00, 102015.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|▊         | 6608/75824 [00:00<00:01, 65403.00it/s] 15%|█▌        | 11681/75824 [00:00<00:01, 60180.69it/s] 24%|██▍       | 18279/75824 [00:00<00:00, 61808.36it/s] 31%|███▏      | 23822/75824 [00:00<00:00, 59743.40it/s] 37%|███▋      | 28289/75824 [00:00<00:00, 52115.59it/s] 49%|████▉     | 37254/75824 [00:00<00:00, 59601.17it/s] 57%|█████▋    | 42976/75824 [00:00<00:00, 47679.22it/s] 67%|██████▋   | 50594/75824 [00:00<00:00, 53706.39it/s] 82%|████████▏ | 62551/75824 [00:00<00:00, 64338.20it/s] 98%|█████████▊| 74088/75824 [00:01<00:00, 74181.90it/s]100%|██████████| 75824/75824 [00:01<00:00, 68664.15it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|█▎        | 10413/75824 [00:00<00:00, 104127.86it/s] 27%|██▋       | 20692/75824 [00:00<00:00, 103720.57it/s] 37%|███▋      | 27807/75824 [00:00<00:00, 91194.25it/s]  53%|█████▎    | 39872/75824 [00:00<00:00, 98401.28it/s] 70%|██████▉   | 52795/75824 [00:00<00:00, 105986.38it/s] 87%|████████▋ | 65889/75824 [00:00<00:00, 112411.91it/s]100%|██████████| 75824/75824 [00:00<00:00, 110166.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 13024/75824 [00:00<00:00, 130230.81it/s] 35%|███▍      | 26473/75824 [00:00<00:00, 131477.98it/s] 52%|█████▏    | 39172/75824 [00:00<00:00, 130095.62it/s] 66%|██████▌   | 49673/75824 [00:00<00:00, 121393.97it/s] 78%|███████▊  | 58807/75824 [00:00<00:00, 107647.82it/s] 93%|█████████▎| 70205/75824 [00:00<00:00, 109470.27it/s]100%|██████████| 75824/75824 [00:00<00:00, 114538.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16478/75824 [00:00<00:00, 164772.30it/s] 48%|████▊     | 36086/75824 [00:00<00:00, 173060.12it/s] 70%|██████▉   | 52786/75824 [00:00<00:00, 171194.82it/s] 88%|████████▊ | 66617/75824 [00:00<00:00, 159794.03it/s]100%|██████████| 75824/75824 [00:00<00:00, 170141.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18837/75824 [00:00<00:00, 188359.40it/s] 49%|████▉     | 37253/75824 [00:00<00:00, 187077.76it/s] 75%|███████▍  | 56551/75824 [00:00<00:00, 188810.09it/s]100%|██████████| 75824/75824 [00:00<00:00, 191652.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18229/75824 [00:00<00:00, 182285.83it/s] 43%|████▎     | 32412/75824 [00:00<00:00, 165701.07it/s] 62%|██████▏   | 46689/75824 [00:00<00:00, 158081.15it/s] 88%|████████▊ | 66749/75824 [00:00<00:00, 168815.66it/s]100%|██████████| 75824/75824 [00:00<00:00, 169180.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|█▍        | 10939/75824 [00:00<00:00, 109383.85it/s] 29%|██▉       | 22325/75824 [00:00<00:00, 110686.48it/s] 44%|████▍     | 33725/75824 [00:00<00:00, 111658.21it/s] 60%|█████▉    | 45363/75824 [00:00<00:00, 113031.85it/s] 75%|███████▌  | 57032/75824 [00:00<00:00, 114102.54it/s] 90%|█████████ | 68520/75824 [00:00<00:00, 114333.97it/s]100%|██████████| 75824/75824 [00:00<00:00, 113614.09it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12695/75824 [00:00<00:00, 126945.58it/s] 24%|██▍       | 18555/75824 [00:00<00:00, 92705.23it/s]  32%|███▏      | 23949/75824 [00:00<00:00, 76258.99it/s] 38%|███▊      | 28628/75824 [00:00<00:00, 62610.51it/s] 51%|█████     | 38463/75824 [00:00<00:00, 67081.98it/s] 60%|█████▉    | 45266/75824 [00:00<00:00, 67362.76it/s] 69%|██████▊   | 52099/75824 [00:00<00:00, 64716.16it/s] 90%|█████████ | 68324/75824 [00:00<00:00, 78954.39it/s]100%|██████████| 75824/75824 [00:00<00:00, 85795.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|█▎        | 9605/75824 [00:00<00:00, 96048.72it/s] 26%|██▋       | 19937/75824 [00:00<00:00, 98118.42it/s] 37%|███▋      | 27772/75824 [00:00<00:00, 91211.77it/s] 46%|████▌     | 34545/75824 [00:00<00:00, 82618.13it/s] 54%|█████▎    | 40730/75824 [00:00<00:00, 70294.93it/s] 61%|██████▏   | 46624/75824 [00:00<00:00, 61796.61it/s] 69%|██████▉   | 52196/75824 [00:00<00:00, 51848.78it/s] 75%|███████▌  | 57227/75824 [00:00<00:00, 49575.03it/s] 84%|████████▎ | 63384/75824 [00:01<00:00, 52651.56it/s] 96%|█████████▋| 73139/75824 [00:01<00:00, 61086.14it/s]100%|██████████| 75824/75824 [00:01<00:00, 67200.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20247/75824 [00:00<00:00, 202469.23it/s] 53%|█████▎    | 39952/75824 [00:00<00:00, 200811.60it/s] 80%|███████▉  | 60321/75824 [00:00<00:00, 201663.60it/s]100%|██████████| 75824/75824 [00:00<00:00, 202477.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19120/75824 [00:00<00:00, 191188.33it/s] 48%|████▊     | 36452/75824 [00:00<00:00, 185449.95it/s] 64%|██████▍   | 48504/75824 [00:00<00:00, 158443.03it/s] 89%|████████▉ | 67688/75824 [00:00<00:00, 167172.59it/s]100%|██████████| 75824/75824 [00:00<00:00, 171481.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|██▉       | 21881/75824 [00:00<00:00, 218807.08it/s] 51%|█████▏    | 39016/75824 [00:00<00:00, 202021.42it/s] 83%|████████▎ | 62749/75824 [00:00<00:00, 211458.84it/s]100%|██████████| 75824/75824 [00:00<00:00, 207419.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 11883/75824 [00:00<00:00, 118825.01it/s] 44%|████▍     | 33375/75824 [00:00<00:00, 137232.65it/s] 72%|███████▏  | 54744/75824 [00:00<00:00, 153733.13it/s]100%|█████████▉| 75763/75824 [00:00<00:00, 167205.31it/s]100%|██████████| 75824/75824 [00:00<00:00, 189295.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18321/75824 [00:00<00:00, 183204.93it/s] 55%|█████▍    | 41600/75824 [00:00<00:00, 195710.18it/s] 85%|████████▌ | 64816/75824 [00:00<00:00, 205381.92it/s]100%|██████████| 75824/75824 [00:00<00:00, 218896.86it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|██▊       | 21005/75824 [00:00<00:00, 210043.19it/s] 57%|█████▋    | 43533/75824 [00:00<00:00, 214392.52it/s] 88%|████████▊ | 66471/75824 [00:00<00:00, 218676.83it/s]100%|██████████| 75824/75824 [00:00<00:00, 222698.09it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14284/75824 [00:00<00:00, 86815.84it/s] 26%|██▋       | 20069/75824 [00:00<00:00, 75476.82it/s] 35%|███▍      | 26346/75824 [00:00<00:00, 71154.45it/s] 59%|█████▉    | 44970/75824 [00:00<00:00, 87347.04it/s] 86%|████████▌ | 64928/75824 [00:00<00:00, 105072.87it/s]100%|██████████| 75824/75824 [00:00<00:00, 122389.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 18996/75824 [00:00<00:00, 189956.56it/s] 51%|█████     | 38727/75824 [00:00<00:00, 192104.31it/s] 68%|██████▊   | 51934/75824 [00:00<00:00, 168870.12it/s] 84%|████████▎ | 63476/75824 [00:00<00:00, 148270.25it/s]100%|██████████| 75824/75824 [00:00<00:00, 164600.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19802/75824 [00:00<00:00, 198013.58it/s] 53%|█████▎    | 39993/75824 [00:00<00:00, 199164.01it/s] 79%|███████▉  | 59897/75824 [00:00<00:00, 199125.00it/s]100%|██████████| 75824/75824 [00:00<00:00, 202245.68it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|▊         | 6347/75824 [00:00<00:01, 54904.57it/s] 25%|██▍       | 18749/75824 [00:00<00:00, 65926.59it/s] 41%|████      | 31189/75824 [00:00<00:00, 76748.71it/s] 55%|█████▍    | 41556/75824 [00:00<00:00, 83232.16it/s] 66%|██████▌   | 49667/75824 [00:00<00:00, 72108.92it/s] 75%|███████▌  | 57020/75824 [00:00<00:00, 71214.34it/s] 87%|████████▋ | 66177/75824 [00:00<00:00, 76302.46it/s]100%|██████████| 75824/75824 [00:00<00:00, 93196.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 12123/75824 [00:00<00:00, 121222.31it/s] 23%|██▎       | 17606/75824 [00:00<00:00, 84389.76it/s]  30%|███       | 22915/75824 [00:00<00:00, 71704.88it/s] 49%|████▉     | 37485/75824 [00:00<00:00, 84592.65it/s] 62%|██████▏   | 47093/75824 [00:00<00:00, 87300.66it/s] 74%|███████▍  | 56456/75824 [00:00<00:00, 89105.71it/s] 86%|████████▌ | 65342/75824 [00:00<00:00, 89030.99it/s] 98%|█████████▊| 74610/75824 [00:00<00:00, 90081.97it/s]100%|██████████| 75824/75824 [00:00<00:00, 91036.24it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19118/75824 [00:00<00:00, 191176.08it/s] 46%|████▌     | 34549/75824 [00:00<00:00, 178388.49it/s] 64%|██████▍   | 48674/75824 [00:00<00:00, 165345.08it/s] 93%|█████████▎| 70661/75824 [00:00<00:00, 178634.24it/s]100%|██████████| 75824/75824 [00:00<00:00, 178757.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19220/75824 [00:00<00:00, 192197.89it/s] 54%|█████▍    | 40973/75824 [00:00<00:00, 199155.00it/s] 83%|████████▎ | 63165/75824 [00:00<00:00, 205478.16it/s]100%|██████████| 75824/75824 [00:00<00:00, 211475.78it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19766/75824 [00:00<00:00, 197657.36it/s] 55%|█████▌    | 41895/75824 [00:00<00:00, 204199.12it/s] 85%|████████▌ | 64580/75824 [00:00<00:00, 210504.12it/s]100%|██████████| 75824/75824 [00:00<00:00, 217744.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17385/75824 [00:00<00:00, 173846.44it/s] 50%|█████     | 38229/75824 [00:00<00:00, 182955.59it/s] 77%|███████▋  | 58207/75824 [00:00<00:00, 187695.69it/s]100%|██████████| 75824/75824 [00:00<00:00, 194805.00it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18560/75824 [00:00<00:00, 185598.41it/s] 50%|█████     | 38102/75824 [00:00<00:00, 188438.00it/s] 76%|███████▋  | 58003/75824 [00:00<00:00, 191486.77it/s]100%|██████████| 75824/75824 [00:00<00:00, 192706.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▍        | 11115/75824 [00:00<00:00, 111147.19it/s] 33%|███▎      | 25222/75824 [00:00<00:00, 118699.46it/s] 59%|█████▉    | 44911/75824 [00:00<00:00, 134752.92it/s] 86%|████████▌ | 64855/75824 [00:00<00:00, 149277.70it/s]100%|██████████| 75824/75824 [00:00<00:00, 166630.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18947/75824 [00:00<00:00, 189467.47it/s] 51%|█████▏    | 38908/75824 [00:00<00:00, 192397.86it/s] 72%|███████▏  | 54598/75824 [00:00<00:00, 180165.95it/s] 92%|█████████▏| 69873/75824 [00:00<00:00, 170960.26it/s]100%|██████████| 75824/75824 [00:00<00:00, 176639.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18500/75824 [00:00<00:00, 184995.77it/s] 50%|█████     | 38081/75824 [00:00<00:00, 188110.10it/s] 77%|███████▋  | 58144/75824 [00:00<00:00, 191696.30it/s]100%|██████████| 75824/75824 [00:00<00:00, 195830.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18085/75824 [00:00<00:00, 180845.86it/s] 36%|███▋      | 27650/75824 [00:00<00:00, 142706.57it/s] 48%|████▊     | 36724/75824 [00:00<00:00, 121778.59it/s] 60%|██████    | 45633/75824 [00:00<00:00, 109702.88it/s] 85%|████████▍ | 64129/75824 [00:00<00:00, 124955.48it/s]100%|██████████| 75824/75824 [00:00<00:00, 137332.65it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 18985/75824 [00:00<00:00, 189841.13it/s] 52%|█████▏    | 39436/75824 [00:00<00:00, 194015.77it/s] 73%|███████▎  | 55575/75824 [00:00<00:00, 182919.28it/s] 89%|████████▉ | 67502/75824 [00:00<00:00, 127667.64it/s]100%|██████████| 75824/75824 [00:00<00:00, 148443.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18688/75824 [00:00<00:00, 186868.15it/s] 32%|███▏      | 24295/75824 [00:00<00:00, 90088.52it/s]  51%|█████     | 38577/75824 [00:00<00:00, 100433.38it/s] 61%|██████    | 46297/75824 [00:00<00:00, 87881.09it/s]  78%|███████▊  | 58874/75824 [00:00<00:00, 95773.11it/s] 89%|████████▉ | 67721/75824 [00:00<00:00, 87552.97it/s]100%|██████████| 75824/75824 [00:00<00:00, 104551.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17193/75824 [00:00<00:00, 171926.47it/s] 42%|████▏     | 31571/75824 [00:00<00:00, 162383.77it/s] 52%|█████▏    | 39495/75824 [00:00<00:00, 97567.44it/s]  66%|██████▌   | 49909/75824 [00:00<00:00, 98038.36it/s] 82%|████████▏ | 62497/75824 [00:00<00:00, 105005.06it/s]100%|██████████| 75824/75824 [00:00<00:00, 115643.76it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|██▊       | 20942/75824 [00:00<00:00, 209419.20it/s] 55%|█████▍    | 41504/75824 [00:00<00:00, 208263.03it/s] 81%|████████  | 61469/75824 [00:00<00:00, 205599.73it/s]100%|██████████| 75824/75824 [00:00<00:00, 204361.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▋       | 19966/75824 [00:00<00:00, 199650.19it/s] 52%|█████▏    | 39715/75824 [00:00<00:00, 198996.67it/s] 69%|██████▉   | 52377/75824 [00:00<00:00, 169863.51it/s] 92%|█████████▏| 69661/75824 [00:00<00:00, 170744.72it/s]100%|██████████| 75824/75824 [00:00<00:00, 176552.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17678/75824 [00:00<00:00, 176773.85it/s] 50%|█████     | 38206/75824 [00:00<00:00, 184457.25it/s] 76%|███████▌  | 57335/75824 [00:00<00:00, 186450.90it/s] 92%|█████████▏| 69983/75824 [00:00<00:00, 161766.27it/s]100%|██████████| 75824/75824 [00:00<00:00, 176154.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18885/75824 [00:00<00:00, 188820.92it/s] 50%|████▉     | 37664/75824 [00:00<00:00, 188509.70it/s] 78%|███████▊  | 59351/75824 [00:00<00:00, 196206.70it/s]100%|██████████| 75824/75824 [00:00<00:00, 203365.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17387/75824 [00:00<00:00, 173859.80it/s] 35%|███▌      | 26657/75824 [00:00<00:00, 137691.61it/s] 59%|█████▉    | 44735/75824 [00:00<00:00, 148294.16it/s] 80%|████████  | 60848/75824 [00:00<00:00, 151922.91it/s]100%|██████████| 75824/75824 [00:00<00:00, 160240.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 30%|██▉       | 22661/75824 [00:00<00:00, 226609.68it/s] 59%|█████▉    | 44584/75824 [00:00<00:00, 224342.39it/s] 86%|████████▌ | 65253/75824 [00:00<00:00, 218736.23it/s]100%|██████████| 75824/75824 [00:00<00:00, 197573.24it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16567/75824 [00:00<00:00, 165663.05it/s] 52%|█████▏    | 39240/75824 [00:00<00:00, 180225.35it/s] 74%|███████▎  | 55890/75824 [00:00<00:00, 175873.53it/s]100%|██████████| 75824/75824 [00:00<00:00, 190859.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 11764/75824 [00:00<00:00, 117634.78it/s] 29%|██▊       | 21739/75824 [00:00<00:00, 111629.73it/s] 55%|█████▌    | 41965/75824 [00:00<00:00, 128965.62it/s] 82%|████████▏ | 62368/75824 [00:00<00:00, 144965.83it/s]100%|██████████| 75824/75824 [00:00<00:00, 163221.65it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██        | 15800/75824 [00:00<00:00, 157996.38it/s] 47%|████▋     | 35349/75824 [00:00<00:00, 167638.50it/s] 63%|██████▎   | 47477/75824 [00:00<00:00, 150387.65it/s] 82%|████████▏ | 61824/75824 [00:00<00:00, 148242.80it/s] 98%|█████████▊| 74043/75824 [00:00<00:00, 131502.29it/s]100%|██████████| 75824/75824 [00:00<00:00, 138974.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 11933/75824 [00:00<00:00, 119326.13it/s] 21%|██        | 15654/75824 [00:00<00:00, 71789.29it/s]  35%|███▌      | 26741/75824 [00:00<00:00, 80278.38it/s] 45%|████▍     | 33846/75824 [00:00<00:00, 77266.18it/s] 63%|██████▎   | 48144/75824 [00:00<00:00, 89623.12it/s] 83%|████████▎ | 63048/75824 [00:00<00:00, 101796.52it/s] 98%|█████████▊| 74334/75824 [00:00<00:00, 104880.52it/s]100%|██████████| 75824/75824 [00:00<00:00, 106452.34it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|▌         | 4612/75824 [00:00<00:01, 46118.61it/s] 20%|██        | 15491/75824 [00:00<00:01, 55754.05it/s] 36%|███▌      | 27022/75824 [00:00<00:00, 65848.89it/s] 44%|████▍     | 33406/75824 [00:00<00:00, 59100.91it/s] 56%|█████▋    | 42710/75824 [00:00<00:00, 64113.45it/s] 67%|██████▋   | 50862/75824 [00:00<00:00, 68501.38it/s] 93%|█████████▎| 70837/75824 [00:00<00:00, 85319.07it/s]100%|██████████| 75824/75824 [00:00<00:00, 97698.70it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▋        | 12457/75824 [00:00<00:00, 124566.26it/s] 36%|███▌      | 27229/75824 [00:00<00:00, 130712.19it/s] 61%|██████    | 46192/75824 [00:00<00:00, 144147.36it/s] 88%|████████▊ | 66865/75824 [00:00<00:00, 158545.97it/s]100%|██████████| 75824/75824 [00:00<00:00, 171646.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19058/75824 [00:00<00:00, 190573.37it/s] 52%|█████▏    | 39184/75824 [00:00<00:00, 193656.98it/s] 81%|████████  | 61253/75824 [00:00<00:00, 201044.63it/s]100%|██████████| 75824/75824 [00:00<00:00, 210084.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20386/75824 [00:00<00:00, 203859.22it/s] 55%|█████▍    | 41674/75824 [00:00<00:00, 206481.91it/s] 86%|████████▌ | 65379/75824 [00:00<00:00, 214790.19it/s]100%|██████████| 75824/75824 [00:00<00:00, 218785.73it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19702/75824 [00:00<00:00, 197007.04it/s] 53%|█████▎    | 39941/75824 [00:00<00:00, 198589.86it/s] 74%|███████▍  | 56411/75824 [00:00<00:00, 187041.26it/s]100%|██████████| 75824/75824 [00:00<00:00, 194410.71it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18019/75824 [00:00<00:00, 180184.59it/s] 51%|█████     | 38306/75824 [00:00<00:00, 186438.07it/s] 77%|███████▋  | 58390/75824 [00:00<00:00, 190535.90it/s] 94%|█████████▍| 71331/75824 [00:00<00:00, 166887.22it/s]100%|██████████| 75824/75824 [00:00<00:00, 174702.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18257/75824 [00:00<00:00, 182561.90it/s] 50%|█████     | 38090/75824 [00:00<00:00, 187021.30it/s] 77%|███████▋  | 58141/75824 [00:00<00:00, 190873.22it/s]100%|██████████| 75824/75824 [00:00<00:00, 196189.52it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18882/75824 [00:00<00:00, 188816.58it/s] 45%|████▌     | 34378/75824 [00:00<00:00, 177200.80it/s] 62%|██████▏   | 47351/75824 [00:00<00:00, 159671.23it/s] 90%|█████████ | 68384/75824 [00:00<00:00, 172106.65it/s]100%|██████████| 75824/75824 [00:00<00:00, 173965.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|██▊       | 21590/75824 [00:00<00:00, 215894.03it/s] 58%|█████▊    | 43830/75824 [00:00<00:00, 217802.81it/s] 86%|████████▌ | 65145/75824 [00:00<00:00, 216382.39it/s]100%|██████████| 75824/75824 [00:00<00:00, 215523.83it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19463/75824 [00:00<00:00, 194620.44it/s] 53%|█████▎    | 39878/75824 [00:00<00:00, 197383.94it/s] 79%|███████▊  | 59604/75824 [00:00<00:00, 197344.96it/s]100%|██████████| 75824/75824 [00:00<00:00, 200314.75it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▎       | 17931/75824 [00:00<00:00, 179308.03it/s] 41%|████      | 31123/75824 [00:00<00:00, 161862.13it/s] 65%|██████▍   | 49129/75824 [00:00<00:00, 166920.68it/s] 79%|███████▉  | 59937/75824 [00:00<00:00, 127539.88it/s] 92%|█████████▏| 69971/75824 [00:00<00:00, 111898.33it/s]100%|██████████| 75824/75824 [00:00<00:00, 126871.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|█▎        | 9556/75824 [00:00<00:00, 95299.71it/s] 21%|██        | 15791/75824 [00:00<00:00, 82256.61it/s] 30%|███       | 22988/75824 [00:00<00:00, 78873.42it/s] 47%|████▋     | 35261/75824 [00:00<00:00, 88343.61it/s] 60%|██████    | 45573/75824 [00:00<00:00, 92310.57it/s] 71%|███████   | 53630/75824 [00:00<00:00, 78086.99it/s] 80%|████████  | 60993/75824 [00:00<00:00, 73119.21it/s] 90%|████████▉ | 68070/75824 [00:00<00:00, 68435.65it/s] 99%|█████████▊| 74801/75824 [00:01<00:00, 61457.21it/s]100%|██████████| 75824/75824 [00:01<00:00, 74391.70it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17605/75824 [00:00<00:00, 176045.97it/s] 39%|███▉      | 29805/75824 [00:00<00:00, 154643.66it/s] 58%|█████▊    | 44191/75824 [00:00<00:00, 151241.79it/s] 84%|████████▍ | 63937/75824 [00:00<00:00, 162662.51it/s]100%|██████████| 75824/75824 [00:00<00:00, 164154.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18620/75824 [00:00<00:00, 186196.63it/s] 44%|████▎     | 33074/75824 [00:00<00:00, 171378.88it/s] 64%|██████▍   | 48431/75824 [00:00<00:00, 165614.98it/s] 89%|████████▉ | 67819/75824 [00:00<00:00, 173188.29it/s]100%|██████████| 75824/75824 [00:00<00:00, 172433.86it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██        | 15702/75824 [00:00<00:00, 157014.53it/s] 45%|████▌     | 34374/75824 [00:00<00:00, 164882.38it/s] 69%|██████▉   | 52397/75824 [00:00<00:00, 169203.24it/s] 88%|████████▊ | 67045/75824 [00:00<00:00, 161678.60it/s]100%|██████████| 75824/75824 [00:00<00:00, 171425.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19372/75824 [00:00<00:00, 193718.80it/s] 51%|█████     | 38794/75824 [00:00<00:00, 193867.28it/s] 78%|███████▊  | 58925/75824 [00:00<00:00, 196041.31it/s] 99%|█████████▉| 75105/75824 [00:00<00:00, 184337.33it/s]100%|██████████| 75824/75824 [00:00<00:00, 187774.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17355/75824 [00:00<00:00, 173548.51it/s] 48%|████▊     | 36738/75824 [00:00<00:00, 179171.72it/s] 74%|███████▍  | 56159/75824 [00:00<00:00, 183431.17it/s]100%|██████████| 75824/75824 [00:00<00:00, 193866.04it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19818/75824 [00:00<00:00, 198173.57it/s] 54%|█████▍    | 40925/75824 [00:00<00:00, 201871.51it/s] 80%|████████  | 60684/75824 [00:00<00:00, 200567.32it/s]100%|██████████| 75824/75824 [00:00<00:00, 200855.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19786/75824 [00:00<00:00, 197859.25it/s] 53%|█████▎    | 39986/75824 [00:00<00:00, 199081.63it/s] 75%|███████▌  | 56886/75824 [00:00<00:00, 188988.10it/s] 93%|█████████▎| 70705/75824 [00:00<00:00, 170215.80it/s]100%|██████████| 75824/75824 [00:00<00:00, 178309.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19119/75824 [00:00<00:00, 191185.17it/s] 51%|█████     | 38518/75824 [00:00<00:00, 192015.26it/s] 76%|███████▌  | 57579/75824 [00:00<00:00, 191591.43it/s]100%|██████████| 75824/75824 [00:00<00:00, 193074.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17583/75824 [00:00<00:00, 175821.36it/s] 42%|████▏     | 32182/75824 [00:00<00:00, 165665.18it/s] 53%|█████▎    | 40254/75824 [00:00<00:00, 104796.68it/s] 63%|██████▎   | 47598/75824 [00:00<00:00, 81515.44it/s]  85%|████████▌ | 64736/75824 [00:00<00:00, 96731.61it/s]100%|██████████| 75824/75824 [00:00<00:00, 119544.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▋       | 19946/75824 [00:00<00:00, 199459.24it/s] 53%|█████▎    | 39898/75824 [00:00<00:00, 199475.95it/s] 79%|███████▊  | 59659/75824 [00:00<00:00, 198910.53it/s]100%|██████████| 75824/75824 [00:00<00:00, 193502.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|██        | 15534/75824 [00:00<00:00, 155337.93it/s] 42%|████▏     | 31664/75824 [00:00<00:00, 156178.73it/s] 53%|█████▎    | 40496/75824 [00:00<00:00, 126918.11it/s] 64%|██████▍   | 48751/75824 [00:00<00:00, 94281.13it/s]  80%|████████  | 61025/75824 [00:00<00:00, 101327.37it/s] 92%|█████████▏| 69990/75824 [00:00<00:00, 81568.55it/s] 100%|██████████| 75824/75824 [00:00<00:00, 101973.20it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|▉         | 7073/75824 [00:00<00:00, 70729.06it/s] 23%|██▎       | 17306/75824 [00:00<00:00, 77950.50it/s] 41%|████▏     | 31439/75824 [00:00<00:00, 90066.65it/s] 60%|█████▉    | 45294/75824 [00:00<00:00, 100630.40it/s] 77%|███████▋  | 58311/75824 [00:00<00:00, 107980.08it/s] 91%|█████████ | 68766/75824 [00:00<00:00, 86604.87it/s] 100%|██████████| 75824/75824 [00:00<00:00, 93177.45it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|█▏        | 9186/75824 [00:00<00:00, 83858.33it/s] 22%|██▏       | 16375/75824 [00:00<00:00, 79868.45it/s] 42%|████▏     | 31859/75824 [00:00<00:00, 93440.83it/s] 62%|██████▏   | 47387/75824 [00:00<00:00, 106118.34it/s] 89%|████████▉ | 67354/75824 [00:00<00:00, 123473.38it/s]100%|██████████| 75824/75824 [00:00<00:00, 137270.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▋        | 12332/75824 [00:00<00:00, 123315.12it/s] 40%|███▉      | 29997/75824 [00:00<00:00, 135595.89it/s] 63%|██████▎   | 48066/75824 [00:00<00:00, 146568.88it/s] 85%|████████▌ | 64546/75824 [00:00<00:00, 151598.69it/s]100%|██████████| 75824/75824 [00:00<00:00, 169088.49it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|██▊       | 21243/75824 [00:00<00:00, 212421.59it/s] 57%|█████▋    | 43587/75824 [00:00<00:00, 215611.21it/s] 84%|████████▍ | 63722/75824 [00:00<00:00, 211122.51it/s]100%|██████████| 75824/75824 [00:00<00:00, 210120.90it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19253/75824 [00:00<00:00, 192521.46it/s] 52%|█████▏    | 39661/75824 [00:00<00:00, 195848.28it/s] 80%|███████▉  | 60619/75824 [00:00<00:00, 199774.72it/s]100%|██████████| 75824/75824 [00:00<00:00, 203329.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▎       | 17916/75824 [00:00<00:00, 179159.74it/s] 40%|███▉      | 30292/75824 [00:00<00:00, 157946.48it/s] 57%|█████▋    | 43387/75824 [00:00<00:00, 148742.54it/s] 75%|███████▌  | 57179/75824 [00:00<00:00, 145318.52it/s] 94%|█████████▍| 71269/75824 [00:00<00:00, 143962.49it/s]100%|██████████| 75824/75824 [00:00<00:00, 143112.44it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13489/75824 [00:00<00:00, 134889.81it/s] 33%|███▎      | 25025/75824 [00:00<00:00, 128369.84it/s] 55%|█████▍    | 41333/75824 [00:00<00:00, 137124.10it/s] 76%|███████▌  | 57772/75824 [00:00<00:00, 144301.77it/s] 94%|█████████▍| 71104/75824 [00:00<00:00, 140821.05it/s]100%|██████████| 75824/75824 [00:00<00:00, 144807.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16560/75824 [00:00<00:00, 165593.84it/s] 47%|████▋     | 35366/75824 [00:00<00:00, 171747.49it/s] 73%|███████▎  | 55442/75824 [00:00<00:00, 179528.62it/s] 91%|█████████ | 68962/75824 [00:00<00:00, 163448.41it/s]100%|██████████| 75824/75824 [00:00<00:00, 156192.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19093/75824 [00:00<00:00, 190923.35it/s] 52%|█████▏    | 39174/75824 [00:00<00:00, 193783.51it/s] 77%|███████▋  | 58751/75824 [00:00<00:00, 194373.89it/s]100%|██████████| 75824/75824 [00:00<00:00, 197808.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19044/75824 [00:00<00:00, 190439.27it/s] 48%|████▊     | 36439/75824 [00:00<00:00, 185170.98it/s] 63%|██████▎   | 48122/75824 [00:00<00:00, 157522.67it/s] 88%|████████▊ | 67059/75824 [00:00<00:00, 165891.99it/s]100%|██████████| 75824/75824 [00:00<00:00, 172756.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 11978/75824 [00:00<00:00, 119770.69it/s] 31%|███       | 23643/75824 [00:00<00:00, 118814.18it/s] 49%|████▊     | 36876/75824 [00:00<00:00, 122569.57it/s] 60%|█████▉    | 45229/75824 [00:00<00:00, 107491.52it/s] 73%|███████▎  | 55303/75824 [00:00<00:00, 105370.58it/s] 85%|████████▍ | 64088/75824 [00:00<00:00, 95861.67it/s] 100%|██████████| 75824/75824 [00:00<00:00, 108685.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|██        | 15181/75824 [00:00<00:00, 151807.97it/s] 40%|████      | 30431/75824 [00:00<00:00, 152012.25it/s] 50%|█████     | 38194/75824 [00:00<00:00, 112460.59it/s] 63%|██████▎   | 48015/75824 [00:00<00:00, 107767.38it/s] 74%|███████▍  | 56235/75824 [00:00<00:00, 76651.66it/s]  84%|████████▎ | 63377/75824 [00:00<00:00, 75002.76it/s]100%|██████████| 75824/75824 [00:00<00:00, 96507.74it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▌        | 11578/75824 [00:00<00:00, 115776.80it/s] 26%|██▌       | 19805/75824 [00:00<00:00, 103168.91it/s] 43%|████▎     | 32436/75824 [00:00<00:00, 109167.87it/s] 56%|█████▋    | 42836/75824 [00:00<00:00, 105763.24it/s] 67%|██████▋   | 50847/75824 [00:00<00:00, 86514.21it/s]  77%|███████▋  | 58277/75824 [00:00<00:00, 71351.61it/s] 86%|████████▌ | 64997/75824 [00:00<00:00, 62617.46it/s] 98%|█████████▊| 73996/75824 [00:00<00:00, 68904.53it/s]100%|██████████| 75824/75824 [00:00<00:00, 80860.75it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▋        | 12403/75824 [00:00<00:00, 124028.64it/s] 31%|███▏      | 23744/75824 [00:00<00:00, 120636.97it/s] 39%|███▉      | 29751/75824 [00:00<00:00, 77930.85it/s]  52%|█████▏    | 39543/75824 [00:00<00:00, 83013.44it/s] 67%|██████▋   | 51124/75824 [00:00<00:00, 90720.56it/s] 83%|████████▎ | 62897/75824 [00:00<00:00, 97425.57it/s] 98%|█████████▊| 74354/75824 [00:00<00:00, 102004.52it/s]100%|██████████| 75824/75824 [00:00<00:00, 100614.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|█         | 8239/75824 [00:00<00:00, 82388.31it/s] 20%|█▉        | 15061/75824 [00:00<00:00, 77555.90it/s] 37%|███▋      | 28057/75824 [00:00<00:00, 88227.83it/s] 55%|█████▍    | 41441/75824 [00:00<00:00, 98274.54it/s] 72%|███████▏  | 54215/75824 [00:00<00:00, 105579.34it/s] 88%|████████▊ | 66851/75824 [00:00<00:00, 111056.34it/s]100%|██████████| 75824/75824 [00:00<00:00, 113288.90it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12583/75824 [00:00<00:00, 125820.82it/s] 33%|███▎      | 24701/75824 [00:00<00:00, 124388.42it/s] 42%|████▏     | 31878/75824 [00:00<00:00, 101961.14it/s] 59%|█████▉    | 44745/75824 [00:00<00:00, 108732.17it/s] 80%|███████▉  | 60378/75824 [00:00<00:00, 119661.95it/s] 99%|█████████▉| 75065/75824 [00:00<00:00, 126703.32it/s]100%|██████████| 75824/75824 [00:00<00:00, 125658.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20632/75824 [00:00<00:00, 206318.72it/s] 53%|█████▎    | 40221/75824 [00:00<00:00, 203073.30it/s] 78%|███████▊  | 58804/75824 [00:00<00:00, 197570.61it/s] 94%|█████████▍| 71526/75824 [00:00<00:00, 143118.16it/s]100%|██████████| 75824/75824 [00:00<00:00, 161731.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|▉         | 7232/75824 [00:00<00:00, 72318.00it/s] 28%|██▊       | 21596/75824 [00:00<00:00, 84975.67it/s] 55%|█████▍    | 41349/75824 [00:00<00:00, 102496.33it/s] 80%|████████  | 60886/75824 [00:00<00:00, 119544.25it/s]100%|██████████| 75824/75824 [00:00<00:00, 157030.68it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20747/75824 [00:00<00:00, 207469.70it/s] 55%|█████▍    | 41699/75824 [00:00<00:00, 208079.89it/s] 84%|████████▍ | 64030/75824 [00:00<00:00, 212424.12it/s]100%|██████████| 75824/75824 [00:00<00:00, 215466.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19727/75824 [00:00<00:00, 197260.78it/s] 53%|█████▎    | 40169/75824 [00:00<00:00, 199354.83it/s] 70%|██████▉   | 52726/75824 [00:00<00:00, 169477.36it/s] 89%|████████▊ | 67122/75824 [00:00<00:00, 155658.00it/s]100%|██████████| 75824/75824 [00:00<00:00, 147358.81it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██▏       | 16128/75824 [00:00<00:00, 161274.77it/s] 47%|████▋     | 35992/75824 [00:00<00:00, 170918.42it/s] 75%|███████▍  | 56586/75824 [00:00<00:00, 180105.43it/s] 99%|█████████▉| 74894/75824 [00:00<00:00, 180984.07it/s]100%|██████████| 75824/75824 [00:00<00:00, 185998.78it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|▋         | 5148/75824 [00:00<00:01, 42556.34it/s] 11%|█▏        | 8542/75824 [00:00<00:01, 39544.34it/s] 36%|███▋      | 27499/75824 [00:00<00:00, 51855.74it/s] 46%|████▌     | 34993/75824 [00:00<00:00, 57135.10it/s] 56%|█████▋    | 42747/75824 [00:00<00:00, 62032.06it/s] 67%|██████▋   | 50566/75824 [00:00<00:00, 66131.64it/s] 92%|█████████▏| 69912/75824 [00:00<00:00, 82401.61it/s]100%|██████████| 75824/75824 [00:00<00:00, 100912.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|▊         | 5985/75824 [00:00<00:01, 49327.30it/s] 10%|█         | 7777/75824 [00:00<00:02, 32328.54it/s] 25%|██▌       | 19039/75824 [00:00<00:01, 41124.01it/s] 35%|███▍      | 26323/75824 [00:00<00:01, 47145.74it/s] 42%|████▏     | 31608/75824 [00:00<00:00, 48382.68it/s] 52%|█████▏    | 39619/75824 [00:00<00:00, 54904.96it/s] 64%|██████▍   | 48526/75824 [00:00<00:00, 62044.08it/s] 73%|███████▎  | 55451/75824 [00:00<00:00, 63907.60it/s] 84%|████████▎ | 63317/75824 [00:00<00:00, 67717.01it/s] 96%|█████████▌| 72971/75824 [00:01<00:00, 74378.02it/s]100%|██████████| 75824/75824 [00:01<00:00, 72169.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 11843/75824 [00:00<00:00, 118419.10it/s] 31%|███▏      | 23777/75824 [00:00<00:00, 118693.32it/s] 48%|████▊     | 36299/75824 [00:00<00:00, 120574.05it/s] 58%|█████▊    | 44302/75824 [00:00<00:00, 92881.98it/s]  69%|██████▉   | 52331/75824 [00:00<00:00, 88705.26it/s] 86%|████████▌ | 65352/75824 [00:00<00:00, 98084.27it/s]100%|██████████| 75824/75824 [00:00<00:00, 104942.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▋        | 12342/75824 [00:00<00:00, 123413.64it/s] 32%|███▏      | 24217/75824 [00:00<00:00, 121974.87it/s] 49%|████▉     | 37307/75824 [00:00<00:00, 124520.12it/s] 66%|██████▋   | 50338/75824 [00:00<00:00, 126201.23it/s] 82%|████████▏ | 62236/75824 [00:00<00:00, 123944.13it/s] 99%|█████████▉| 74945/75824 [00:00<00:00, 124827.59it/s]100%|██████████| 75824/75824 [00:00<00:00, 124925.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|██▉       | 21898/75824 [00:00<00:00, 218972.38it/s] 60%|██████    | 45727/75824 [00:00<00:00, 224429.30it/s] 90%|████████▉ | 67956/75824 [00:00<00:00, 223781.01it/s]100%|██████████| 75824/75824 [00:00<00:00, 227842.15it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|██▉       | 22025/75824 [00:00<00:00, 220239.71it/s] 60%|█████▉    | 45368/75824 [00:00<00:00, 224036.71it/s] 79%|███████▉  | 60139/75824 [00:00<00:00, 193965.33it/s] 96%|█████████▌| 72710/75824 [00:00<00:00, 152552.27it/s]100%|██████████| 75824/75824 [00:00<00:00, 172491.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14760/75824 [00:00<00:00, 147595.21it/s] 39%|███▉      | 29942/75824 [00:00<00:00, 148836.86it/s] 60%|█████▉    | 45228/75824 [00:00<00:00, 150020.48it/s] 83%|████████▎ | 63183/75824 [00:00<00:00, 157805.18it/s]100%|██████████| 75824/75824 [00:00<00:00, 164520.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18856/75824 [00:00<00:00, 188549.39it/s] 37%|███▋      | 27811/75824 [00:00<00:00, 141588.12it/s] 52%|█████▏    | 39324/75824 [00:00<00:00, 132450.43it/s] 63%|██████▎   | 47430/75824 [00:00<00:00, 108659.88it/s] 81%|████████  | 61553/75824 [00:00<00:00, 116735.24it/s] 96%|█████████▌| 72488/75824 [00:00<00:00, 114413.78it/s]100%|██████████| 75824/75824 [00:00<00:00, 115689.53it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 30%|██▉       | 22655/75824 [00:00<00:00, 226542.11it/s] 61%|██████    | 46081/75824 [00:00<00:00, 228801.86it/s] 91%|█████████ | 68985/75824 [00:00<00:00, 228871.51it/s]100%|██████████| 75824/75824 [00:00<00:00, 228703.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▎       | 17823/75824 [00:00<00:00, 178225.07it/s] 34%|███▍      | 26094/75824 [00:00<00:00, 132362.44it/s] 43%|████▎     | 32732/75824 [00:00<00:00, 101955.53it/s] 54%|█████▍    | 40995/75824 [00:00<00:00, 95270.81it/s]  65%|██████▌   | 49458/75824 [00:00<00:00, 91805.35it/s] 80%|████████  | 60971/75824 [00:00<00:00, 97744.20it/s] 96%|█████████▌| 72721/75824 [00:00<00:00, 102934.17it/s]100%|██████████| 75824/75824 [00:00<00:00, 104392.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|▌         | 4501/75824 [00:00<00:01, 45008.33it/s] 21%|██        | 15956/75824 [00:00<00:01, 55030.83it/s] 37%|███▋      | 27849/75824 [00:00<00:00, 65605.29it/s] 57%|█████▋    | 43401/75824 [00:00<00:00, 79371.63it/s] 85%|████████▍ | 64175/75824 [00:00<00:00, 97433.69it/s]100%|██████████| 75824/75824 [00:00<00:00, 110101.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|█         | 8247/75824 [00:00<00:00, 80468.49it/s] 30%|███       | 23024/75824 [00:00<00:00, 93013.35it/s] 40%|████      | 30625/75824 [00:00<00:00, 87163.63it/s] 55%|█████▌    | 41845/75824 [00:00<00:00, 93416.09it/s] 76%|███████▋  | 57845/75824 [00:00<00:00, 106742.23it/s]100%|██████████| 75824/75824 [00:00<00:00, 128209.65it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19666/75824 [00:00<00:00, 196656.44it/s] 54%|█████▎    | 40597/75824 [00:00<00:00, 200286.62it/s] 79%|███████▉  | 59719/75824 [00:00<00:00, 197476.66it/s]100%|██████████| 75824/75824 [00:00<00:00, 198699.14it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|██▊       | 20965/75824 [00:00<00:00, 209647.20it/s] 57%|█████▋    | 43149/75824 [00:00<00:00, 213161.57it/s] 88%|████████▊ | 66546/75824 [00:00<00:00, 219004.14it/s]100%|██████████| 75824/75824 [00:00<00:00, 223669.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19644/75824 [00:00<00:00, 196435.50it/s] 54%|█████▎    | 40734/75824 [00:00<00:00, 200561.79it/s] 77%|███████▋  | 58051/75824 [00:00<00:00, 191475.35it/s] 95%|█████████▌| 72040/75824 [00:00<00:00, 172402.24it/s]100%|██████████| 75824/75824 [00:00<00:00, 181773.08it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20785/75824 [00:00<00:00, 207832.86it/s] 37%|███▋      | 27775/75824 [00:00<00:00, 125600.50it/s] 47%|████▋     | 35909/75824 [00:00<00:00, 107974.20it/s] 65%|██████▍   | 49067/75824 [00:00<00:00, 114115.12it/s] 88%|████████▊ | 66715/75824 [00:00<00:00, 127646.94it/s]100%|██████████| 75824/75824 [00:00<00:00, 136191.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 11910/75824 [00:00<00:00, 119096.42it/s] 30%|███       | 23059/75824 [00:00<00:00, 116704.42it/s] 44%|████▍     | 33221/75824 [00:00<00:00, 111728.34it/s] 61%|██████▏   | 46490/75824 [00:00<00:00, 117285.47it/s] 82%|████████▏ | 62543/75824 [00:00<00:00, 127596.00it/s] 98%|█████████▊| 74457/75824 [00:00<00:00, 124932.08it/s]100%|██████████| 75824/75824 [00:00<00:00, 123715.75it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 17011/75824 [00:00<00:00, 170100.83it/s] 40%|███▉      | 30074/75824 [00:00<00:00, 155959.79it/s] 61%|██████    | 45973/75824 [00:00<00:00, 156855.48it/s] 85%|████████▌ | 64478/75824 [00:00<00:00, 164367.52it/s]100%|██████████| 75824/75824 [00:00<00:00, 164430.72it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16712/75824 [00:00<00:00, 167113.78it/s] 38%|███▊      | 28975/75824 [00:00<00:00, 150711.44it/s] 62%|██████▏   | 47111/75824 [00:00<00:00, 158758.70it/s] 86%|████████▌ | 64953/75824 [00:00<00:00, 164186.48it/s]100%|██████████| 75824/75824 [00:00<00:00, 165632.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18684/75824 [00:00<00:00, 186832.16it/s] 36%|███▌      | 27085/75824 [00:00<00:00, 134275.88it/s] 54%|█████▍    | 41096/75824 [00:00<00:00, 135972.89it/s] 73%|███████▎  | 55147/75824 [00:00<00:00, 137301.94it/s] 86%|████████▋ | 65419/75824 [00:00<00:00, 117479.41it/s] 99%|█████████▉| 75246/75824 [00:00<00:00, 110181.14it/s]100%|██████████| 75824/75824 [00:00<00:00, 121102.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▌        | 11716/75824 [00:00<00:00, 117153.69it/s] 22%|██▏       | 16552/75824 [00:00<00:00, 82108.66it/s]  41%|████      | 30943/75824 [00:00<00:00, 94250.20it/s] 50%|█████     | 37998/75824 [00:00<00:00, 73112.16it/s] 75%|███████▌  | 57212/75824 [00:00<00:00, 89801.26it/s] 91%|█████████▏| 69225/75824 [00:00<00:00, 97159.55it/s]100%|██████████| 75824/75824 [00:00<00:00, 101262.74it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14537/75824 [00:00<00:00, 145367.37it/s] 34%|███▍      | 25745/75824 [00:00<00:00, 133474.83it/s] 48%|████▊     | 36165/75824 [00:00<00:00, 123097.62it/s] 58%|█████▊    | 43948/75824 [00:00<00:00, 104807.15it/s] 69%|██████▉   | 52302/75824 [00:00<00:00, 97369.45it/s]  89%|████████▉ | 67816/75824 [00:00<00:00, 109613.06it/s]100%|██████████| 75824/75824 [00:00<00:00, 115065.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18117/75824 [00:00<00:00, 181160.67it/s] 49%|████▉     | 37168/75824 [00:00<00:00, 183866.46it/s] 73%|███████▎  | 55062/75824 [00:00<00:00, 182359.79it/s] 89%|████████▉ | 67603/75824 [00:00<00:00, 160492.97it/s]100%|██████████| 75824/75824 [00:00<00:00, 170860.83it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 11882/75824 [00:00<00:00, 118818.70it/s] 40%|███▉      | 30297/75824 [00:00<00:00, 132969.75it/s] 64%|██████▎   | 48154/75824 [00:00<00:00, 144000.44it/s] 90%|█████████ | 68495/75824 [00:00<00:00, 157829.04it/s]100%|██████████| 75824/75824 [00:00<00:00, 173507.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▊        | 14193/75824 [00:00<00:00, 141919.65it/s] 39%|███▉      | 29798/75824 [00:00<00:00, 145882.10it/s] 59%|█████▉    | 44721/75824 [00:00<00:00, 146867.43it/s] 83%|████████▎ | 62762/75824 [00:00<00:00, 155541.70it/s]100%|██████████| 75824/75824 [00:00<00:00, 161432.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18366/75824 [00:00<00:00, 183655.36it/s] 45%|████▍     | 33784/75824 [00:00<00:00, 173689.17it/s] 63%|██████▎   | 47751/75824 [00:00<00:00, 161859.63it/s] 88%|████████▊ | 66847/75824 [00:00<00:00, 169611.53it/s]100%|██████████| 75824/75824 [00:00<00:00, 169818.75it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18051/75824 [00:00<00:00, 180498.55it/s] 40%|████      | 30382/75824 [00:00<00:00, 158449.63it/s] 64%|██████▎   | 48336/75824 [00:00<00:00, 164237.08it/s] 87%|████████▋ | 65767/75824 [00:00<00:00, 167133.92it/s]100%|██████████| 75824/75824 [00:00<00:00, 157652.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18278/75824 [00:00<00:00, 182779.30it/s] 49%|████▉     | 37099/75824 [00:00<00:00, 184374.59it/s] 74%|███████▍  | 56159/75824 [00:00<00:00, 186197.71it/s] 92%|█████████▏| 69985/75824 [00:00<00:00, 168650.92it/s]100%|██████████| 75824/75824 [00:00<00:00, 171072.68it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18317/75824 [00:00<00:00, 183165.37it/s] 49%|████▊     | 36961/75824 [00:00<00:00, 184133.85it/s] 74%|███████▎  | 55810/75824 [00:00<00:00, 185416.46it/s] 98%|█████████▊| 74087/75824 [00:00<00:00, 184613.76it/s]100%|██████████| 75824/75824 [00:00<00:00, 185216.90it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18542/75824 [00:00<00:00, 185419.73it/s] 49%|████▉     | 37456/75824 [00:00<00:00, 186519.22it/s] 74%|███████▍  | 56227/75824 [00:00<00:00, 186870.66it/s] 91%|█████████ | 68900/75824 [00:00<00:00, 163579.30it/s]100%|██████████| 75824/75824 [00:00<00:00, 171705.83it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|██        | 15174/75824 [00:00<00:00, 151736.89it/s] 40%|████      | 30514/75824 [00:00<00:00, 152231.09it/s] 56%|█████▋    | 42795/75824 [00:00<00:00, 142020.04it/s] 79%|███████▊  | 59568/75824 [00:00<00:00, 148864.46it/s] 94%|█████████▎| 70995/75824 [00:00<00:00, 112612.49it/s]100%|██████████| 75824/75824 [00:00<00:00, 126085.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|▊         | 6358/75824 [00:00<00:01, 61148.16it/s] 25%|██▍       | 18728/75824 [00:00<00:00, 72082.32it/s] 37%|███▋      | 28089/75824 [00:00<00:00, 77423.85it/s] 49%|████▊     | 36862/75824 [00:00<00:00, 80250.76it/s] 61%|██████▏   | 46525/75824 [00:00<00:00, 84548.90it/s] 76%|███████▌  | 57775/75824 [00:00<00:00, 91357.75it/s] 93%|█████████▎| 70544/75824 [00:00<00:00, 99883.62it/s]100%|██████████| 75824/75824 [00:00<00:00, 101438.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██        | 15761/75824 [00:00<00:00, 136761.54it/s] 29%|██▉       | 22180/75824 [00:00<00:00, 102121.55it/s] 45%|████▍     | 34011/75824 [00:00<00:00, 106491.39it/s] 67%|██████▋   | 50952/75824 [00:00<00:00, 119843.75it/s] 80%|████████  | 60870/75824 [00:00<00:00, 103872.90it/s]100%|██████████| 75824/75824 [00:00<00:00, 118589.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18395/75824 [00:00<00:00, 183947.54it/s] 49%|████▉     | 37039/75824 [00:00<00:00, 184686.34it/s] 74%|███████▍  | 56453/75824 [00:00<00:00, 187424.00it/s]100%|██████████| 75824/75824 [00:00<00:00, 189918.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|█▎        | 9602/75824 [00:00<00:00, 96016.20it/s] 27%|██▋       | 20395/75824 [00:00<00:00, 99303.36it/s] 53%|█████▎    | 40278/75824 [00:00<00:00, 116850.32it/s] 79%|███████▉  | 60086/75824 [00:00<00:00, 133241.50it/s]100%|██████████| 75824/75824 [00:00<00:00, 156835.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18110/75824 [00:00<00:00, 181099.74it/s] 40%|███▉      | 30091/75824 [00:00<00:00, 156999.56it/s] 62%|██████▏   | 47272/75824 [00:00<00:00, 161166.65it/s] 83%|████████▎ | 63043/75824 [00:00<00:00, 160112.03it/s]100%|██████████| 75824/75824 [00:00<00:00, 160299.90it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17571/75824 [00:00<00:00, 175700.11it/s] 47%|████▋     | 35440/75824 [00:00<00:00, 176585.57it/s] 66%|██████▌   | 49986/75824 [00:00<00:00, 165930.29it/s] 80%|████████  | 60685/75824 [00:00<00:00, 118274.05it/s] 98%|█████████▊| 74680/75824 [00:00<00:00, 124037.10it/s]100%|██████████| 75824/75824 [00:00<00:00, 136121.83it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17116/75824 [00:00<00:00, 171147.92it/s] 38%|███▊      | 28903/75824 [00:00<00:00, 150708.79it/s] 62%|██████▏   | 46897/75824 [00:00<00:00, 158428.20it/s] 85%|████████▍ | 64353/75824 [00:00<00:00, 162435.63it/s]100%|██████████| 75824/75824 [00:00<00:00, 163622.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13418/75824 [00:00<00:00, 134179.81it/s] 34%|███▍      | 26157/75824 [00:00<00:00, 132065.46it/s] 54%|█████▎    | 40711/75824 [00:00<00:00, 135837.31it/s] 73%|███████▎  | 55559/75824 [00:00<00:00, 139396.38it/s] 98%|█████████▊| 74459/75824 [00:00<00:00, 151308.73it/s]100%|██████████| 75824/75824 [00:00<00:00, 149392.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17273/75824 [00:00<00:00, 172726.46it/s] 45%|████▍     | 33775/75824 [00:00<00:00, 170338.15it/s] 62%|██████▏   | 46662/75824 [00:00<00:00, 155339.46it/s] 86%|████████▌ | 65171/75824 [00:00<00:00, 163207.41it/s]100%|██████████| 75824/75824 [00:00<00:00, 166317.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16851/75824 [00:00<00:00, 168505.34it/s] 41%|████      | 31250/75824 [00:00<00:00, 160313.29it/s] 61%|██████▏   | 46609/75824 [00:00<00:00, 150118.55it/s] 77%|███████▋  | 58402/75824 [00:00<00:00, 138756.32it/s] 94%|█████████▍| 71501/75824 [00:00<00:00, 134389.14it/s]100%|██████████| 75824/75824 [00:00<00:00, 126516.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12996/75824 [00:00<00:00, 129951.14it/s] 24%|██▎       | 17851/75824 [00:00<00:00, 86459.49it/s]  35%|███▌      | 26547/75824 [00:00<00:00, 86608.38it/s] 51%|█████     | 38527/75824 [00:00<00:00, 94458.27it/s] 64%|██████▍   | 48649/75824 [00:00<00:00, 96389.30it/s] 77%|███████▋  | 58132/75824 [00:00<00:00, 95915.21it/s] 88%|████████▊ | 66764/75824 [00:00<00:00, 76470.95it/s]100%|██████████| 75824/75824 [00:00<00:00, 90251.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13291/75824 [00:00<00:00, 132906.32it/s] 29%|██▉       | 22042/75824 [00:00<00:00, 112235.14it/s] 45%|████▍     | 33879/75824 [00:00<00:00, 111216.58it/s] 54%|█████▍    | 40830/75824 [00:00<00:00, 81623.23it/s]  68%|██████▊   | 51411/75824 [00:00<00:00, 87630.89it/s] 78%|███████▊  | 59049/75824 [00:00<00:00, 81831.87it/s] 94%|█████████▎| 70983/75824 [00:00<00:00, 90350.01it/s]100%|██████████| 75824/75824 [00:00<00:00, 96076.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▎       | 17977/75824 [00:00<00:00, 179760.31it/s] 50%|████▉     | 37899/75824 [00:00<00:00, 185185.69it/s] 63%|██████▎   | 47657/75824 [00:00<00:00, 143709.70it/s] 82%|████████▏ | 62424/75824 [00:00<00:00, 144874.43it/s]100%|██████████| 75824/75824 [00:00<00:00, 161262.21it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|██        | 15335/75824 [00:00<00:00, 153345.39it/s] 43%|████▎     | 32878/75824 [00:00<00:00, 159362.71it/s] 67%|██████▋   | 50948/75824 [00:00<00:00, 165211.95it/s] 84%|████████▍ | 63686/75824 [00:00<00:00, 151693.42it/s]100%|██████████| 75824/75824 [00:00<00:00, 155715.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▊        | 14141/75824 [00:00<00:00, 139869.15it/s] 39%|███▊      | 29229/75824 [00:00<00:00, 142998.47it/s] 63%|██████▎   | 47967/75824 [00:00<00:00, 153935.16it/s] 85%|████████▌ | 64607/75824 [00:00<00:00, 157471.51it/s]100%|██████████| 75824/75824 [00:00<00:00, 155082.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18804/75824 [00:00<00:00, 188037.94it/s] 49%|████▉     | 37258/75824 [00:00<00:00, 186973.95it/s] 73%|███████▎  | 54973/75824 [00:00<00:00, 183913.88it/s] 96%|█████████▌| 72900/75824 [00:00<00:00, 182494.77it/s]100%|██████████| 75824/75824 [00:00<00:00, 182348.91it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18029/75824 [00:00<00:00, 180282.44it/s] 48%|████▊     | 36118/75824 [00:00<00:00, 180461.49it/s] 72%|███████▏  | 54594/75824 [00:00<00:00, 181729.82it/s] 90%|████████▉ | 68188/75824 [00:00<00:00, 165050.20it/s]100%|██████████| 75824/75824 [00:00<00:00, 167393.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17774/75824 [00:00<00:00, 177738.47it/s] 48%|████▊     | 36038/75824 [00:00<00:00, 179178.62it/s] 72%|███████▏  | 54707/75824 [00:00<00:00, 181365.32it/s] 91%|█████████▏| 69371/75824 [00:00<00:00, 169332.38it/s]100%|██████████| 75824/75824 [00:00<00:00, 168368.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 11902/75824 [00:00<00:00, 119014.15it/s] 31%|███       | 23345/75824 [00:00<00:00, 117600.06it/s] 51%|█████     | 38295/75824 [00:00<00:00, 125641.46it/s] 70%|███████   | 53372/75824 [00:00<00:00, 132253.68it/s] 90%|█████████ | 68518/75824 [00:00<00:00, 137482.77it/s]100%|██████████| 75824/75824 [00:00<00:00, 136725.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14259/75824 [00:00<00:00, 142588.44it/s] 38%|███▊      | 28984/75824 [00:00<00:00, 143953.64it/s] 58%|█████▊    | 44281/75824 [00:00<00:00, 146542.07it/s] 78%|███████▊  | 59464/75824 [00:00<00:00, 148087.96it/s]100%|██████████| 75824/75824 [00:00<00:00, 151662.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14388/75824 [00:00<00:00, 143874.65it/s] 40%|███▉      | 29972/75824 [00:00<00:00, 147265.53it/s] 58%|█████▊    | 43847/75824 [00:00<00:00, 144600.66it/s] 76%|███████▋  | 57914/75824 [00:00<00:00, 141818.92it/s] 91%|█████████ | 68671/75824 [00:00<00:00, 124686.07it/s]100%|██████████| 75824/75824 [00:00<00:00, 133262.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|▋         | 5192/75824 [00:00<00:01, 51917.33it/s] 17%|█▋        | 12729/75824 [00:00<00:01, 56199.55it/s] 27%|██▋       | 20803/75824 [00:00<00:00, 61837.22it/s] 43%|████▎     | 32982/75824 [00:00<00:00, 72550.93it/s] 58%|█████▊    | 44319/75824 [00:00<00:00, 81335.52it/s] 78%|███████▊  | 59478/75824 [00:00<00:00, 93633.64it/s] 92%|█████████▏| 69583/75824 [00:00<00:00, 76404.70it/s]100%|██████████| 75824/75824 [00:00<00:00, 87834.10it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|█▍        | 10776/75824 [00:00<00:00, 107753.94it/s] 23%|██▎       | 17164/75824 [00:00<00:00, 89344.34it/s]  46%|████▋     | 35069/75824 [00:00<00:00, 105147.79it/s] 67%|██████▋   | 50654/75824 [00:00<00:00, 116518.13it/s] 83%|████████▎ | 63231/75824 [00:00<00:00, 119144.75it/s] 99%|█████████▉| 74988/75824 [00:00<00:00, 118666.75it/s]100%|██████████| 75824/75824 [00:00<00:00, 124025.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19160/75824 [00:00<00:00, 191593.79it/s] 45%|████▌     | 34435/75824 [00:00<00:00, 178010.87it/s] 66%|██████▌   | 50067/75824 [00:00<00:00, 170894.46it/s] 90%|█████████ | 68529/75824 [00:00<00:00, 174792.52it/s]100%|██████████| 75824/75824 [00:00<00:00, 173156.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19273/75824 [00:00<00:00, 192726.51it/s] 51%|█████     | 38636/75824 [00:00<00:00, 192993.70it/s] 71%|███████   | 53706/75824 [00:00<00:00, 178002.53it/s] 88%|████████▊ | 66649/75824 [00:00<00:00, 159987.97it/s]100%|██████████| 75824/75824 [00:00<00:00, 168323.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██        | 15808/75824 [00:00<00:00, 158073.74it/s] 45%|████▌     | 34321/75824 [00:00<00:00, 165322.10it/s] 65%|██████▌   | 49500/75824 [00:00<00:00, 161014.43it/s] 80%|███████▉  | 60568/75824 [00:00<00:00, 141682.37it/s] 94%|█████████▍| 71424/75824 [00:00<00:00, 109382.51it/s]100%|██████████| 75824/75824 [00:00<00:00, 124225.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17470/75824 [00:00<00:00, 174691.00it/s] 47%|████▋     | 35736/75824 [00:00<00:00, 177006.79it/s] 71%|███████▏  | 54140/75824 [00:00<00:00, 179057.34it/s] 87%|████████▋ | 66065/75824 [00:00<00:00, 154883.96it/s]100%|██████████| 75824/75824 [00:00<00:00, 152348.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18337/75824 [00:00<00:00, 183364.93it/s] 50%|████▉     | 37791/75824 [00:00<00:00, 186578.67it/s] 69%|██████▉   | 52554/75824 [00:00<00:00, 172894.21it/s] 90%|█████████ | 68299/75824 [00:00<00:00, 167947.35it/s]100%|██████████| 75824/75824 [00:00<00:00, 172589.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18031/75824 [00:00<00:00, 180308.02it/s] 50%|█████     | 37920/75824 [00:00<00:00, 185505.84it/s] 77%|███████▋  | 58112/75824 [00:00<00:00, 190141.52it/s]100%|██████████| 75824/75824 [00:00<00:00, 194924.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18549/75824 [00:00<00:00, 185478.68it/s] 41%|████      | 30832/75824 [00:00<00:00, 160863.48it/s] 66%|██████▌   | 49867/75824 [00:00<00:00, 168702.56it/s] 82%|████████▏ | 62528/75824 [00:00<00:00, 153401.42it/s]100%|██████████| 75824/75824 [00:00<00:00, 157961.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18176/75824 [00:00<00:00, 181754.97it/s] 49%|████▉     | 37455/75824 [00:00<00:00, 184929.05it/s] 74%|███████▍  | 56146/75824 [00:00<00:00, 185517.78it/s] 98%|█████████▊| 74112/75824 [00:00<00:00, 183719.70it/s]100%|██████████| 75824/75824 [00:00<00:00, 183303.65it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▋        | 12382/75824 [00:00<00:00, 123813.03it/s] 29%|██▉       | 22086/75824 [00:00<00:00, 114347.49it/s] 45%|████▌     | 34271/75824 [00:00<00:00, 116496.97it/s] 55%|█████▌    | 41785/75824 [00:00<00:00, 87561.51it/s]  72%|███████▏  | 54914/75824 [00:00<00:00, 97280.74it/s] 89%|████████▊ | 67133/75824 [00:00<00:00, 103617.03it/s]100%|██████████| 75824/75824 [00:00<00:00, 104053.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13515/75824 [00:00<00:00, 135141.11it/s] 34%|███▎      | 25439/75824 [00:00<00:00, 129939.71it/s] 47%|████▋     | 35648/75824 [00:00<00:00, 120108.08it/s] 58%|█████▊    | 43905/75824 [00:00<00:00, 105692.74it/s] 68%|██████▊   | 51670/75824 [00:00<00:00, 83288.77it/s]  78%|███████▊  | 59036/75824 [00:00<00:00, 77404.53it/s] 95%|█████████▌| 72181/75824 [00:00<00:00, 88294.74it/s]100%|██████████| 75824/75824 [00:00<00:00, 97849.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|▋         | 5609/75824 [00:00<00:01, 56089.79it/s] 31%|███       | 23568/75824 [00:00<00:00, 70668.66it/s] 56%|█████▌    | 42398/75824 [00:00<00:00, 86966.73it/s] 81%|████████  | 61457/75824 [00:00<00:00, 103915.83it/s] 98%|█████████▊| 74346/75824 [00:00<00:00, 109976.62it/s]100%|██████████| 75824/75824 [00:00<00:00, 147668.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18866/75824 [00:00<00:00, 188657.03it/s] 41%|████      | 31198/75824 [00:00<00:00, 162244.73it/s] 60%|██████    | 45806/75824 [00:00<00:00, 157030.95it/s] 86%|████████▌ | 65183/75824 [00:00<00:00, 166500.44it/s]100%|██████████| 75824/75824 [00:00<00:00, 166582.55it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18584/75824 [00:00<00:00, 185833.09it/s] 49%|████▊     | 36885/75824 [00:00<00:00, 184974.17it/s] 75%|███████▍  | 56622/75824 [00:00<00:00, 188524.54it/s]100%|██████████| 75824/75824 [00:00<00:00, 190146.24it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 18959/75824 [00:00<00:00, 189582.50it/s] 51%|█████     | 38301/75824 [00:00<00:00, 190715.16it/s] 74%|███████▍  | 56474/75824 [00:00<00:00, 187927.46it/s] 99%|█████████▉| 75305/75824 [00:00<00:00, 188039.56it/s]100%|██████████| 75824/75824 [00:00<00:00, 188106.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 17009/75824 [00:00<00:00, 170087.32it/s] 45%|████▍     | 33812/75824 [00:00<00:00, 169463.19it/s] 69%|██████▊   | 52083/75824 [00:00<00:00, 173230.52it/s] 93%|█████████▎| 70287/75824 [00:00<00:00, 175781.36it/s]100%|██████████| 75824/75824 [00:00<00:00, 176303.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|▉         | 6644/75824 [00:00<00:01, 66438.16it/s] 20%|█▉        | 14938/75824 [00:00<00:00, 70654.93it/s] 39%|███▉      | 29398/75824 [00:00<00:00, 83457.71it/s] 63%|██████▎   | 47747/75824 [00:00<00:00, 99776.00it/s] 88%|████████▊ | 66726/75824 [00:00<00:00, 116326.74it/s]100%|██████████| 75824/75824 [00:00<00:00, 138560.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18602/75824 [00:00<00:00, 186010.86it/s] 42%|████▏     | 31895/75824 [00:00<00:00, 156658.60it/s] 57%|█████▋    | 43202/75824 [00:00<00:00, 140417.27it/s] 83%|████████▎ | 63096/75824 [00:00<00:00, 154008.61it/s]100%|██████████| 75824/75824 [00:00<00:00, 158048.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19785/75824 [00:00<00:00, 197842.17it/s] 52%|█████▏    | 39544/75824 [00:00<00:00, 197765.52it/s] 78%|███████▊  | 59508/75824 [00:00<00:00, 198323.23it/s]100%|██████████| 75824/75824 [00:00<00:00, 199803.55it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18395/75824 [00:00<00:00, 183946.67it/s] 50%|████▉     | 37665/75824 [00:00<00:00, 186486.39it/s] 75%|███████▌  | 57213/75824 [00:00<00:00, 189095.63it/s]100%|██████████| 75824/75824 [00:00<00:00, 191752.91it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|█▏        | 8927/75824 [00:00<00:00, 87609.10it/s] 27%|██▋       | 20392/75824 [00:00<00:00, 94279.14it/s] 41%|████▏     | 31342/75824 [00:00<00:00, 95416.10it/s] 60%|█████▉    | 45355/75824 [00:00<00:00, 103205.63it/s] 71%|███████   | 53829/75824 [00:00<00:00, 90464.05it/s]  88%|████████▊ | 66414/75824 [00:00<00:00, 98795.95it/s]100%|█████████▉| 75816/75824 [00:00<00:00, 84004.53it/s]100%|██████████| 75824/75824 [00:00<00:00, 95325.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12977/75824 [00:00<00:00, 129759.30it/s] 27%|██▋       | 20318/75824 [00:00<00:00, 100670.82it/s] 34%|███▎      | 25475/75824 [00:00<00:00, 78302.89it/s]  58%|█████▊    | 43765/75824 [00:00<00:00, 94518.51it/s] 71%|███████   | 53644/75824 [00:00<00:00, 92464.83it/s] 82%|████████▏ | 62498/75824 [00:00<00:00, 76128.98it/s] 95%|█████████▍| 72000/75824 [00:00<00:00, 79635.71it/s]100%|██████████| 75824/75824 [00:00<00:00, 86676.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|▉         | 6765/75824 [00:00<00:01, 67643.77it/s] 32%|███▏      | 24352/75824 [00:00<00:00, 82958.82it/s] 57%|█████▋    | 43556/75824 [00:00<00:00, 99998.72it/s] 82%|████████▏ | 61798/75824 [00:00<00:00, 115677.56it/s]100%|██████████| 75824/75824 [00:00<00:00, 160249.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19343/75824 [00:00<00:00, 193428.34it/s] 52%|█████▏    | 39068/75824 [00:00<00:00, 194558.02it/s] 77%|███████▋  | 58150/75824 [00:00<00:00, 193421.10it/s]100%|██████████| 75824/75824 [00:00<00:00, 191002.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 13154/75824 [00:00<00:00, 131539.50it/s] 43%|████▎     | 32377/75824 [00:00<00:00, 145298.32it/s] 69%|██████▉   | 52587/75824 [00:00<00:00, 158675.64it/s] 92%|█████████▏| 69501/75824 [00:00<00:00, 161673.15it/s]100%|██████████| 75824/75824 [00:00<00:00, 167188.99it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19009/75824 [00:00<00:00, 190086.10it/s] 52%|█████▏    | 39065/75824 [00:00<00:00, 193105.91it/s] 78%|███████▊  | 59177/75824 [00:00<00:00, 195441.51it/s]100%|██████████| 75824/75824 [00:00<00:00, 196789.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 12194/75824 [00:00<00:00, 121931.10it/s] 30%|██▉       | 22653/75824 [00:00<00:00, 116151.60it/s] 44%|████▍     | 33289/75824 [00:00<00:00, 113029.86it/s] 60%|█████▉    | 45377/75824 [00:00<00:00, 115274.49it/s] 81%|████████▏ | 61611/75824 [00:00<00:00, 126255.57it/s]100%|██████████| 75824/75824 [00:00<00:00, 131213.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▎       | 17942/75824 [00:00<00:00, 179418.03it/s] 47%|████▋     | 35675/75824 [00:00<00:00, 178783.56it/s] 63%|██████▎   | 47900/75824 [00:00<00:00, 157000.26it/s] 87%|████████▋ | 66221/75824 [00:00<00:00, 164038.73it/s]100%|██████████| 75824/75824 [00:00<00:00, 168801.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19028/75824 [00:00<00:00, 190277.46it/s] 52%|█████▏    | 39072/75824 [00:00<00:00, 193214.80it/s] 76%|███████▌  | 57382/75824 [00:00<00:00, 190063.72it/s] 94%|█████████▍| 71459/75824 [00:00<00:00, 171991.49it/s]100%|██████████| 75824/75824 [00:00<00:00, 166088.15it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19289/75824 [00:00<00:00, 192887.42it/s] 52%|█████▏    | 39237/75824 [00:00<00:00, 194818.90it/s] 78%|███████▊  | 59277/75824 [00:00<00:00, 196457.20it/s]100%|██████████| 75824/75824 [00:00<00:00, 199078.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17476/75824 [00:00<00:00, 174750.17it/s] 39%|███▊      | 29222/75824 [00:00<00:00, 152442.36it/s] 54%|█████▍    | 40946/75824 [00:00<00:00, 139844.86it/s] 66%|██████▌   | 49798/75824 [00:00<00:00, 119123.97it/s] 80%|████████  | 60900/75824 [00:00<00:00, 116570.72it/s]100%|██████████| 75824/75824 [00:00<00:00, 130584.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17759/75824 [00:00<00:00, 177582.12it/s] 35%|███▌      | 26668/75824 [00:00<00:00, 136812.67it/s] 54%|█████▍    | 41066/75824 [00:00<00:00, 138885.51it/s] 66%|██████▌   | 49867/75824 [00:00<00:00, 103867.94it/s] 82%|████████▏ | 62509/75824 [00:00<00:00, 105447.06it/s] 94%|█████████▍| 71475/75824 [00:00<00:00, 94869.69it/s] 100%|██████████| 75824/75824 [00:00<00:00, 109647.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▌        | 11392/75824 [00:00<00:00, 113915.49it/s] 31%|███       | 23365/75824 [00:00<00:00, 115597.31it/s] 51%|█████▏    | 38912/75824 [00:00<00:00, 124931.10it/s] 69%|██████▉   | 52287/75824 [00:00<00:00, 127449.89it/s] 83%|████████▎ | 63137/75824 [00:00<00:00, 121101.73it/s]100%|█████████▉| 75597/75824 [00:00<00:00, 122129.16it/s]100%|██████████| 75824/75824 [00:00<00:00, 125698.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14286/75824 [00:00<00:00, 142851.96it/s] 30%|██▉       | 22677/75824 [00:00<00:00, 117986.05it/s] 47%|████▋     | 35271/75824 [00:00<00:00, 120264.08it/s] 67%|██████▋   | 51002/75824 [00:00<00:00, 129405.39it/s] 92%|█████████▏| 69844/75824 [00:00<00:00, 142824.41it/s]100%|██████████| 75824/75824 [00:00<00:00, 142756.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██▏       | 16150/75824 [00:00<00:00, 161499.00it/s] 31%|███       | 23290/75824 [00:00<00:00, 117149.12it/s] 49%|████▉     | 37501/75824 [00:00<00:00, 121410.69it/s] 68%|██████▊   | 51199/75824 [00:00<00:00, 125696.03it/s] 94%|█████████▍| 71437/75824 [00:00<00:00, 141816.27it/s]100%|██████████| 75824/75824 [00:00<00:00, 143285.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19184/75824 [00:00<00:00, 191831.95it/s] 46%|████▋     | 35257/75824 [00:00<00:00, 181306.76it/s] 64%|██████▍   | 48415/75824 [00:00<00:00, 162841.74it/s] 85%|████████▌ | 64743/75824 [00:00<00:00, 162971.15it/s]100%|██████████| 75824/75824 [00:00<00:00, 159915.10it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 13068/75824 [00:00<00:00, 130674.83it/s] 40%|████      | 30457/75824 [00:00<00:00, 141202.10it/s] 61%|██████▏   | 46555/75824 [00:00<00:00, 146604.37it/s] 79%|███████▉  | 60223/75824 [00:00<00:00, 143478.57it/s]100%|██████████| 75824/75824 [00:00<00:00, 155557.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12863/75824 [00:00<00:00, 128621.84it/s] 36%|███▌      | 27052/75824 [00:00<00:00, 132333.37it/s] 49%|████▉     | 37178/75824 [00:00<00:00, 121174.56it/s] 69%|██████▊   | 51996/75824 [00:00<00:00, 128182.66it/s] 88%|████████▊ | 66909/75824 [00:00<00:00, 133820.79it/s]100%|██████████| 75824/75824 [00:00<00:00, 135451.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▊        | 14092/75824 [00:00<00:00, 140919.13it/s] 41%|████      | 31187/75824 [00:00<00:00, 148757.08it/s] 52%|█████▏    | 39275/75824 [00:00<00:00, 103783.53it/s] 76%|███████▌  | 57559/75824 [00:00<00:00, 119251.15it/s]100%|██████████| 75824/75824 [00:00<00:00, 142502.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18381/75824 [00:00<00:00, 183807.55it/s] 49%|████▊     | 36812/75824 [00:00<00:00, 183955.29it/s] 69%|██████▉   | 52343/75824 [00:00<00:00, 174307.91it/s] 88%|████████▊ | 66780/75824 [00:00<00:00, 164098.56it/s]100%|██████████| 75824/75824 [00:00<00:00, 153817.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▍        | 11355/75824 [00:00<00:00, 113548.48it/s] 31%|███       | 23201/75824 [00:00<00:00, 114976.03it/s] 46%|████▋     | 35108/75824 [00:00<00:00, 112966.44it/s] 59%|█████▉    | 45093/75824 [00:00<00:00, 108681.65it/s] 76%|███████▌  | 57375/75824 [00:00<00:00, 112568.96it/s] 92%|█████████▏| 69894/75824 [00:00<00:00, 116077.07it/s]100%|██████████| 75824/75824 [00:00<00:00, 104884.71it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|█▏        | 9361/75824 [00:00<00:00, 93603.84it/s] 21%|██        | 15574/75824 [00:00<00:00, 81253.37it/s] 31%|███       | 23366/75824 [00:00<00:00, 78060.18it/s] 45%|████▍     | 34083/75824 [00:00<00:00, 84984.81it/s] 54%|█████▎    | 40677/75824 [00:00<00:00, 72810.36it/s] 62%|██████▏   | 46930/75824 [00:00<00:00, 64562.96it/s] 84%|████████▍ | 63568/75824 [00:00<00:00, 79080.91it/s] 97%|█████████▋| 73385/75824 [00:00<00:00, 83978.54it/s]100%|██████████| 75824/75824 [00:00<00:00, 84594.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16525/75824 [00:00<00:00, 165248.58it/s] 47%|████▋     | 35599/75824 [00:00<00:00, 172148.30it/s] 62%|██████▏   | 47315/75824 [00:00<00:00, 150898.67it/s] 76%|███████▌  | 57265/75824 [00:00<00:00, 124494.90it/s] 97%|█████████▋| 73409/75824 [00:00<00:00, 133670.65it/s]100%|██████████| 75824/75824 [00:00<00:00, 144469.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|██        | 15402/75824 [00:00<00:00, 154016.84it/s] 45%|████▌     | 34313/75824 [00:00<00:00, 163096.03it/s] 71%|███████   | 53575/75824 [00:00<00:00, 170954.54it/s] 95%|█████████▍| 71972/75824 [00:00<00:00, 174660.60it/s]100%|██████████| 75824/75824 [00:00<00:00, 180415.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██▏       | 16256/75824 [00:00<00:00, 162559.77it/s] 46%|████▋     | 35237/75824 [00:00<00:00, 169875.80it/s] 70%|███████   | 53337/75824 [00:00<00:00, 173064.58it/s] 95%|█████████▍| 71670/75824 [00:00<00:00, 176021.37it/s]100%|██████████| 75824/75824 [00:00<00:00, 179685.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14467/75824 [00:00<00:00, 144662.21it/s] 42%|████▏     | 31919/75824 [00:00<00:00, 152488.24it/s] 66%|██████▌   | 50228/75824 [00:00<00:00, 160535.89it/s] 89%|████████▉ | 67832/75824 [00:00<00:00, 164891.09it/s]100%|██████████| 75824/75824 [00:00<00:00, 171404.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▌        | 11385/75824 [00:00<00:00, 113842.78it/s] 34%|███▍      | 25764/75824 [00:00<00:00, 121427.54it/s] 54%|█████▍    | 40833/75824 [00:00<00:00, 128937.91it/s] 71%|███████   | 53955/75824 [00:00<00:00, 129612.82it/s] 85%|████████▍ | 64341/75824 [00:00<00:00, 106867.27it/s]100%|██████████| 75824/75824 [00:00<00:00, 124864.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18166/75824 [00:00<00:00, 181655.84it/s] 48%|████▊     | 36707/75824 [00:00<00:00, 182765.05it/s] 73%|███████▎  | 55381/75824 [00:00<00:00, 183938.93it/s] 98%|█████████▊| 74049/75824 [00:00<00:00, 184751.63it/s]100%|██████████| 75824/75824 [00:00<00:00, 184893.97it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|█         | 7755/75824 [00:00<00:00, 75223.41it/s] 21%|██▏       | 16264/75824 [00:00<00:00, 77933.93it/s] 41%|████      | 30712/75824 [00:00<00:00, 90428.82it/s] 64%|██████▍   | 48833/75824 [00:00<00:00, 106423.34it/s] 89%|████████▉ | 67302/75824 [00:00<00:00, 121922.61it/s]100%|██████████| 75824/75824 [00:00<00:00, 138212.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 15047/75824 [00:00<00:00, 150464.76it/s] 39%|███▉      | 29835/75824 [00:00<00:00, 149679.61it/s] 61%|██████    | 46008/75824 [00:00<00:00, 153099.73it/s] 86%|████████▌ | 65385/75824 [00:00<00:00, 163386.79it/s]100%|██████████| 75824/75824 [00:00<00:00, 166997.17it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 13108/75824 [00:00<00:00, 131073.56it/s] 40%|███▉      | 30325/75824 [00:00<00:00, 141181.05it/s] 50%|█████     | 38243/75824 [00:00<00:00, 109417.01it/s] 65%|██████▌   | 49307/75824 [00:00<00:00, 109780.07it/s] 81%|████████  | 61495/75824 [00:00<00:00, 109871.73it/s] 93%|█████████▎| 70892/75824 [00:00<00:00, 95010.58it/s] 100%|██████████| 75824/75824 [00:00<00:00, 111363.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 12204/75824 [00:00<00:00, 122037.21it/s] 24%|██▍       | 18318/75824 [00:00<00:00, 91764.40it/s]  34%|███▍      | 25767/75824 [00:00<00:00, 85794.30it/s] 44%|████▍     | 33523/75824 [00:00<00:00, 83144.33it/s] 63%|██████▎   | 47938/75824 [00:00<00:00, 95235.35it/s] 80%|███████▉  | 60557/75824 [00:00<00:00, 102800.04it/s] 94%|█████████▍| 71294/75824 [00:00<00:00, 99329.17it/s] 100%|██████████| 75824/75824 [00:00<00:00, 94442.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|█▎        | 10397/75824 [00:00<00:00, 87412.51it/s] 22%|██▏       | 16663/75824 [00:00<00:00, 75827.92it/s] 30%|███       | 22751/75824 [00:00<00:00, 70358.67it/s] 38%|███▊      | 29102/75824 [00:00<00:00, 68153.76it/s] 56%|█████▌    | 42431/75824 [00:00<00:00, 79860.96it/s] 74%|███████▍  | 56393/75824 [00:00<00:00, 91625.97it/s] 97%|█████████▋| 73893/75824 [00:00<00:00, 106904.47it/s]100%|██████████| 75824/75824 [00:00<00:00, 102582.86it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|█▍        | 10702/75824 [00:00<00:00, 107015.00it/s] 24%|██▍       | 18485/75824 [00:00<00:00, 96193.20it/s]  41%|████      | 31126/75824 [00:00<00:00, 103623.96it/s] 65%|██████▍   | 49109/75824 [00:00<00:00, 118715.52it/s] 81%|████████  | 61302/75824 [00:00<00:00, 119659.18it/s] 96%|█████████▌| 72793/75824 [00:00<00:00, 118193.49it/s]100%|██████████| 75824/75824 [00:00<00:00, 116582.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18723/75824 [00:00<00:00, 187226.16it/s] 47%|████▋     | 35733/75824 [00:00<00:00, 181735.35it/s] 72%|███████▏  | 54717/75824 [00:00<00:00, 184091.41it/s] 90%|█████████ | 68538/75824 [00:00<00:00, 167417.75it/s]100%|██████████| 75824/75824 [00:00<00:00, 166807.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13277/75824 [00:00<00:00, 132769.18it/s] 43%|████▎     | 32251/75824 [00:00<00:00, 145911.96it/s] 67%|██████▋   | 50877/75824 [00:00<00:00, 156051.98it/s] 92%|█████████▏| 69431/75824 [00:00<00:00, 163864.46it/s]100%|██████████| 75824/75824 [00:00<00:00, 174726.56it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13648/75824 [00:00<00:00, 136478.50it/s] 39%|███▉      | 29461/75824 [00:00<00:00, 142323.39it/s] 64%|██████▎   | 48216/75824 [00:00<00:00, 153422.24it/s] 90%|████████▉ | 67953/75824 [00:00<00:00, 164402.16it/s]100%|██████████| 75824/75824 [00:00<00:00, 171890.89it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██        | 15851/75824 [00:00<00:00, 158499.57it/s] 43%|████▎     | 32472/75824 [00:00<00:00, 160735.57it/s] 64%|██████▍   | 48462/75824 [00:00<00:00, 160481.26it/s] 85%|████████▌ | 64451/75824 [00:00<00:00, 160300.02it/s]100%|██████████| 75824/75824 [00:00<00:00, 161556.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|█▎        | 10213/75824 [00:00<00:00, 102123.77it/s] 28%|██▊       | 21562/75824 [00:00<00:00, 105286.79it/s] 43%|████▎     | 32641/75824 [00:00<00:00, 106878.99it/s] 63%|██████▎   | 47723/75824 [00:00<00:00, 117115.33it/s] 83%|████████▎ | 62952/75824 [00:00<00:00, 125833.21it/s]100%|██████████| 75824/75824 [00:00<00:00, 129812.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14589/75824 [00:00<00:00, 145884.57it/s] 37%|███▋      | 28215/75824 [00:00<00:00, 142856.80it/s] 51%|█████     | 38556/75824 [00:00<00:00, 128183.82it/s] 67%|██████▋   | 50948/75824 [00:00<00:00, 126871.34it/s] 94%|█████████▎| 70896/75824 [00:00<00:00, 142422.48it/s]100%|██████████| 75824/75824 [00:00<00:00, 144465.81it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19519/75824 [00:00<00:00, 195185.53it/s] 50%|█████     | 38191/75824 [00:00<00:00, 192564.42it/s] 75%|███████▌  | 57073/75824 [00:00<00:00, 191422.60it/s] 92%|█████████▏| 69528/75824 [00:00<00:00, 148213.65it/s]100%|██████████| 75824/75824 [00:00<00:00, 148596.99it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  4%|▍         | 3298/75824 [00:00<00:02, 32979.09it/s] 18%|█▊        | 13855/75824 [00:00<00:01, 41550.00it/s] 30%|███       | 22960/75824 [00:00<00:01, 49646.87it/s] 41%|████      | 31205/75824 [00:00<00:00, 55718.55it/s] 57%|█████▋    | 43576/75824 [00:00<00:00, 66719.08it/s] 80%|███████▉  | 60423/75824 [00:00<00:00, 81482.71it/s] 95%|█████████▍| 71873/75824 [00:00<00:00, 89197.10it/s]100%|██████████| 75824/75824 [00:00<00:00, 96664.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▍        | 11023/75824 [00:00<00:00, 110226.95it/s] 28%|██▊       | 20964/75824 [00:00<00:00, 106742.05it/s] 43%|████▎     | 32926/75824 [00:00<00:00, 105738.02it/s] 52%|█████▏    | 39738/75824 [00:00<00:00, 89877.06it/s]  73%|███████▎  | 54981/75824 [00:00<00:00, 102494.71it/s] 91%|█████████ | 68803/75824 [00:00<00:00, 111108.95it/s]100%|██████████| 75824/75824 [00:00<00:00, 107235.55it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18415/75824 [00:00<00:00, 184144.03it/s] 50%|█████     | 37943/75824 [00:00<00:00, 187347.14it/s] 75%|███████▌  | 57048/75824 [00:00<00:00, 188440.50it/s]100%|██████████| 75824/75824 [00:00<00:00, 194323.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 17050/75824 [00:00<00:00, 170491.22it/s] 29%|██▉       | 22165/75824 [00:00<00:00, 98215.33it/s]  46%|████▌     | 34932/75824 [00:00<00:00, 105517.60it/s] 70%|██████▉   | 52773/75824 [00:00<00:00, 120256.84it/s] 93%|█████████▎| 70787/75824 [00:00<00:00, 133577.83it/s]100%|██████████| 75824/75824 [00:00<00:00, 142635.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17667/75824 [00:00<00:00, 176668.06it/s] 46%|████▋     | 35181/75824 [00:00<00:00, 176205.00it/s] 71%|███████   | 53817/75824 [00:00<00:00, 179130.83it/s] 96%|█████████▌| 72634/75824 [00:00<00:00, 181749.48it/s]100%|██████████| 75824/75824 [00:00<00:00, 181790.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 14979/75824 [00:00<00:00, 149783.00it/s] 44%|████▎     | 33015/75824 [00:00<00:00, 157808.81it/s] 68%|██████▊   | 51566/75824 [00:00<00:00, 165207.81it/s] 92%|█████████▏| 70137/75824 [00:00<00:00, 170864.44it/s]100%|██████████| 75824/75824 [00:00<00:00, 176024.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16843/75824 [00:00<00:00, 168427.35it/s] 46%|████▌     | 35045/75824 [00:00<00:00, 172285.63it/s] 70%|██████▉   | 53063/75824 [00:00<00:00, 174577.36it/s] 94%|█████████▍| 71322/75824 [00:00<00:00, 176906.01it/s]100%|██████████| 75824/75824 [00:00<00:00, 176757.55it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|█▍        | 10854/75824 [00:00<00:00, 108537.77it/s] 29%|██▉       | 22219/75824 [00:00<00:00, 110020.54it/s] 46%|████▌     | 34695/75824 [00:00<00:00, 114061.87it/s] 70%|███████   | 53145/75824 [00:00<00:00, 128814.31it/s] 94%|█████████▍| 71391/75824 [00:00<00:00, 141274.62it/s]100%|██████████| 75824/75824 [00:00<00:00, 144766.73it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██▏       | 16235/75824 [00:00<00:00, 162347.06it/s] 34%|███▍      | 26002/75824 [00:00<00:00, 135437.02it/s] 51%|█████     | 38436/75824 [00:00<00:00, 131904.80it/s] 73%|███████▎  | 55138/75824 [00:00<00:00, 140783.27it/s] 91%|█████████▏| 69241/75824 [00:00<00:00, 140854.32it/s]100%|██████████| 75824/75824 [00:00<00:00, 134081.02it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19523/75824 [00:00<00:00, 195220.41it/s] 41%|████      | 30874/75824 [00:00<00:00, 158959.39it/s] 51%|█████     | 38301/75824 [00:00<00:00, 115788.60it/s] 75%|███████▌  | 57097/75824 [00:00<00:00, 130860.85it/s] 92%|█████████▏| 69657/75824 [00:00<00:00, 129234.08it/s]100%|██████████| 75824/75824 [00:00<00:00, 132896.89it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|██        | 15212/75824 [00:00<00:00, 152116.52it/s] 40%|████      | 30530/75824 [00:00<00:00, 152433.18it/s] 51%|█████     | 38320/75824 [00:00<00:00, 86573.36it/s]  71%|███████   | 53964/75824 [00:00<00:00, 99966.38it/s] 84%|████████▎ | 63380/75824 [00:00<00:00, 94035.76it/s] 98%|█████████▊| 74021/75824 [00:00<00:00, 97433.99it/s]100%|██████████| 75824/75824 [00:00<00:00, 104738.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 13085/75824 [00:00<00:00, 130843.89it/s] 42%|████▏     | 31958/75824 [00:00<00:00, 144103.00it/s] 68%|██████▊   | 51368/75824 [00:00<00:00, 156170.19it/s] 83%|████████▎ | 63078/75824 [00:00<00:00, 124274.55it/s] 97%|█████████▋| 73800/75824 [00:00<00:00, 116949.64it/s]100%|██████████| 75824/75824 [00:00<00:00, 136940.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|██▊       | 20894/75824 [00:00<00:00, 208936.71it/s] 55%|█████▍    | 41531/75824 [00:00<00:00, 208157.98it/s] 82%|████████▏ | 62295/75824 [00:00<00:00, 208001.93it/s]100%|██████████| 75824/75824 [00:00<00:00, 203892.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|██▊       | 21252/75824 [00:00<00:00, 212510.58it/s] 55%|█████▍    | 41638/75824 [00:00<00:00, 209838.42it/s] 80%|███████▉  | 60464/75824 [00:00<00:00, 202861.57it/s]100%|██████████| 75824/75824 [00:00<00:00, 200049.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18466/75824 [00:00<00:00, 184654.89it/s] 49%|████▊     | 36962/75824 [00:00<00:00, 184745.45it/s] 70%|███████   | 53371/75824 [00:00<00:00, 178019.41it/s] 94%|█████████▍| 71272/75824 [00:00<00:00, 178313.45it/s]100%|██████████| 75824/75824 [00:00<00:00, 178481.52it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18817/75824 [00:00<00:00, 188162.55it/s] 49%|████▉     | 37282/75824 [00:00<00:00, 187091.77it/s] 74%|███████▍  | 56066/75824 [00:00<00:00, 187313.80it/s] 97%|█████████▋| 73896/75824 [00:00<00:00, 184515.31it/s]100%|██████████| 75824/75824 [00:00<00:00, 185013.04it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14756/75824 [00:00<00:00, 147551.70it/s] 39%|███▉      | 29805/75824 [00:00<00:00, 148416.19it/s] 49%|████▉     | 37418/75824 [00:00<00:00, 108530.94it/s] 75%|███████▍  | 56780/75824 [00:00<00:00, 125011.36it/s]100%|█████████▉| 75763/75824 [00:00<00:00, 139277.20it/s]100%|██████████| 75824/75824 [00:00<00:00, 147279.17it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19515/75824 [00:00<00:00, 195140.88it/s] 51%|█████▏    | 38987/75824 [00:00<00:00, 195013.08it/s] 78%|███████▊  | 58825/75824 [00:00<00:00, 196010.60it/s] 95%|█████████▍| 71734/75824 [00:00<00:00, 137428.03it/s]100%|██████████| 75824/75824 [00:00<00:00, 157657.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19171/75824 [00:00<00:00, 191709.27it/s] 50%|█████     | 37995/75824 [00:00<00:00, 190653.39it/s] 75%|███████▌  | 57242/75824 [00:00<00:00, 191193.33it/s]100%|██████████| 75824/75824 [00:00<00:00, 191282.81it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17632/75824 [00:00<00:00, 176313.86it/s] 49%|████▉     | 37340/75824 [00:00<00:00, 182068.89it/s] 74%|███████▍  | 55959/75824 [00:00<00:00, 183284.05it/s] 99%|█████████▊| 74824/75824 [00:00<00:00, 184858.71it/s]100%|██████████| 75824/75824 [00:00<00:00, 186940.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16987/75824 [00:00<00:00, 169868.95it/s] 39%|███▉      | 29860/75824 [00:00<00:00, 155002.78it/s] 52%|█████▏    | 39630/75824 [00:00<00:00, 131807.98it/s] 70%|██████▉   | 53066/75824 [00:00<00:00, 132563.01it/s] 83%|████████▎ | 62789/75824 [00:00<00:00, 100791.61it/s]100%|██████████| 75824/75824 [00:00<00:00, 117416.45it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14701/75824 [00:00<00:00, 146997.87it/s] 25%|██▌       | 19111/75824 [00:00<00:00, 82039.85it/s]  42%|████▏     | 31702/75824 [00:00<00:00, 91616.08it/s] 57%|█████▋    | 43427/75824 [00:00<00:00, 98046.72it/s] 68%|██████▊   | 51695/75824 [00:00<00:00, 88081.37it/s] 80%|████████  | 60756/75824 [00:00<00:00, 87805.32it/s] 91%|█████████ | 68918/75824 [00:00<00:00, 68738.28it/s]100%|██████████| 75824/75824 [00:00<00:00, 81187.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|█         | 8352/75824 [00:00<00:00, 83513.11it/s] 20%|██        | 15534/75824 [00:00<00:00, 79622.70it/s] 31%|███▏      | 23839/75824 [00:00<00:00, 80620.17it/s] 47%|████▋     | 35816/75824 [00:00<00:00, 89385.46it/s] 68%|██████▊   | 51517/75824 [00:00<00:00, 102648.51it/s] 94%|█████████▎| 70978/75824 [00:00<00:00, 119603.43it/s]100%|██████████| 75824/75824 [00:00<00:00, 121335.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19098/75824 [00:00<00:00, 190977.91it/s] 52%|█████▏    | 39256/75824 [00:00<00:00, 194037.21it/s] 78%|███████▊  | 58869/75824 [00:00<00:00, 194659.84it/s] 99%|█████████▉| 75077/75824 [00:00<00:00, 183588.45it/s]100%|██████████| 75824/75824 [00:00<00:00, 187540.49it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19028/75824 [00:00<00:00, 190272.92it/s] 49%|████▉     | 37461/75824 [00:00<00:00, 188448.60it/s] 69%|██████▉   | 52696/75824 [00:00<00:00, 175937.42it/s] 89%|████████▉ | 67493/75824 [00:00<00:00, 166493.80it/s]100%|██████████| 75824/75824 [00:00<00:00, 170635.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 17023/75824 [00:00<00:00, 170218.39it/s] 40%|███▉      | 29988/75824 [00:00<00:00, 155609.72it/s] 64%|██████▍   | 48566/75824 [00:00<00:00, 163578.83it/s] 88%|████████▊ | 66870/75824 [00:00<00:00, 168967.05it/s]100%|██████████| 75824/75824 [00:00<00:00, 161109.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17498/75824 [00:00<00:00, 174974.33it/s] 44%|████▍     | 33701/75824 [00:00<00:00, 170874.23it/s] 62%|██████▏   | 47375/75824 [00:00<00:00, 158967.18it/s] 87%|████████▋ | 65756/75824 [00:00<00:00, 165685.06it/s]100%|██████████| 75824/75824 [00:00<00:00, 166611.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17676/75824 [00:00<00:00, 176748.79it/s] 41%|████      | 30817/75824 [00:00<00:00, 160168.27it/s] 60%|█████▉    | 45281/75824 [00:00<00:00, 155169.84it/s] 73%|███████▎  | 54978/75824 [00:00<00:00, 118620.21it/s] 90%|█████████ | 68352/75824 [00:00<00:00, 122783.97it/s]100%|██████████| 75824/75824 [00:00<00:00, 132955.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14752/75824 [00:00<00:00, 147510.64it/s] 39%|███▉      | 29524/75824 [00:00<00:00, 147570.69it/s] 59%|█████▊    | 44535/75824 [00:00<00:00, 148320.52it/s] 73%|███████▎  | 55328/75824 [00:00<00:00, 133345.12it/s] 94%|█████████▍| 71545/75824 [00:00<00:00, 140854.51it/s]100%|██████████| 75824/75824 [00:00<00:00, 140946.52it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 14913/75824 [00:00<00:00, 149126.94it/s] 41%|████      | 30895/75824 [00:00<00:00, 152181.37it/s] 67%|██████▋   | 50867/75824 [00:00<00:00, 163882.10it/s] 93%|█████████▎| 70824/75824 [00:00<00:00, 173172.14it/s]100%|██████████| 75824/75824 [00:00<00:00, 172308.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14582/75824 [00:00<00:00, 145813.88it/s] 39%|███▉      | 29861/75824 [00:00<00:00, 147836.59it/s] 63%|██████▎   | 47752/75824 [00:00<00:00, 155960.96it/s] 82%|████████▏ | 61887/75824 [00:00<00:00, 139896.08it/s] 96%|█████████▌| 72774/75824 [00:00<00:00, 119493.42it/s]100%|██████████| 75824/75824 [00:00<00:00, 133526.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12619/75824 [00:00<00:00, 126188.62it/s] 27%|██▋       | 20568/75824 [00:00<00:00, 107280.67it/s] 42%|████▏     | 31963/75824 [00:00<00:00, 109197.76it/s] 65%|██████▍   | 49164/75824 [00:00<00:00, 122630.93it/s] 78%|███████▊  | 59184/75824 [00:00<00:00, 88995.42it/s]  94%|█████████▎| 71013/75824 [00:00<00:00, 96137.08it/s]100%|██████████| 75824/75824 [00:00<00:00, 104197.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 12173/75824 [00:00<00:00, 121723.15it/s] 28%|██▊       | 21289/75824 [00:00<00:00, 110597.80it/s] 41%|████▏     | 31303/75824 [00:00<00:00, 102282.41it/s] 57%|█████▋    | 43263/75824 [00:00<00:00, 106927.15it/s] 83%|████████▎ | 63058/75824 [00:00<00:00, 124037.61it/s]100%|██████████| 75824/75824 [00:00<00:00, 131181.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18240/75824 [00:00<00:00, 182396.26it/s] 43%|████▎     | 32460/75824 [00:00<00:00, 168133.87it/s] 59%|█████▉    | 44807/75824 [00:00<00:00, 151670.56it/s] 76%|███████▌  | 57589/75824 [00:00<00:00, 143628.44it/s] 98%|█████████▊| 74178/75824 [00:00<00:00, 149651.83it/s]100%|██████████| 75824/75824 [00:00<00:00, 148816.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19809/75824 [00:00<00:00, 198085.94it/s] 51%|█████     | 38584/75824 [00:00<00:00, 194867.37it/s] 76%|███████▌  | 57374/75824 [00:00<00:00, 192721.16it/s]100%|██████████| 75824/75824 [00:00<00:00, 192230.20it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|██        | 15220/75824 [00:00<00:00, 151524.94it/s] 45%|████▍     | 33896/75824 [00:00<00:00, 160614.46it/s] 70%|███████   | 53278/75824 [00:00<00:00, 169316.04it/s] 94%|█████████▍| 71143/75824 [00:00<00:00, 172011.05it/s]100%|██████████| 75824/75824 [00:00<00:00, 178236.65it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18815/75824 [00:00<00:00, 188144.35it/s] 50%|█████     | 38175/75824 [00:00<00:00, 189746.01it/s] 78%|███████▊  | 58782/75824 [00:00<00:00, 194363.78it/s]100%|██████████| 75824/75824 [00:00<00:00, 196029.90it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 15134/75824 [00:00<00:00, 151332.21it/s] 40%|████      | 30462/75824 [00:00<00:00, 151909.43it/s] 55%|█████▍    | 41535/75824 [00:00<00:00, 136660.88it/s] 72%|███████▏  | 54885/75824 [00:00<00:00, 135694.29it/s] 93%|█████████▎| 70289/75824 [00:00<00:00, 140721.65it/s]100%|██████████| 75824/75824 [00:00<00:00, 141438.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19106/75824 [00:00<00:00, 191059.73it/s] 51%|█████▏    | 39010/75824 [00:00<00:00, 193385.18it/s] 78%|███████▊  | 59444/75824 [00:00<00:00, 194946.43it/s]100%|█████████▉| 75615/75824 [00:00<00:00, 183620.76it/s]100%|██████████| 75824/75824 [00:00<00:00, 187292.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 15069/75824 [00:00<00:00, 150689.43it/s] 41%|████▏     | 31364/75824 [00:00<00:00, 154167.77it/s] 65%|██████▍   | 49120/75824 [00:00<00:00, 160509.71it/s] 89%|████████▉ | 67449/75824 [00:00<00:00, 166724.40it/s]100%|██████████| 75824/75824 [00:00<00:00, 170655.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▋        | 12338/75824 [00:00<00:00, 123374.53it/s] 40%|████      | 30340/75824 [00:00<00:00, 136234.58it/s] 53%|█████▎    | 40178/75824 [00:00<00:00, 122135.90it/s] 65%|██████▍   | 49264/75824 [00:00<00:00, 110703.29it/s] 76%|███████▋  | 57972/75824 [00:00<00:00, 101995.31it/s] 93%|█████████▎| 70705/75824 [00:00<00:00, 108468.99it/s]100%|██████████| 75824/75824 [00:00<00:00, 118141.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14293/75824 [00:00<00:00, 142920.60it/s] 35%|███▍      | 26507/75824 [00:00<00:00, 135979.29it/s] 48%|████▊     | 36173/75824 [00:00<00:00, 121186.25it/s] 63%|██████▎   | 47844/75824 [00:00<00:00, 119806.80it/s] 75%|███████▍  | 56641/75824 [00:00<00:00, 92891.29it/s]  95%|█████████▌| 72258/75824 [00:00<00:00, 105744.01it/s]100%|██████████| 75824/75824 [00:00<00:00, 112601.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 11912/75824 [00:00<00:00, 119114.15it/s] 22%|██▏       | 16368/75824 [00:00<00:00, 78931.45it/s]  31%|███       | 23554/75824 [00:00<00:00, 71445.83it/s] 38%|███▊      | 28965/75824 [00:00<00:00, 65178.78it/s] 55%|█████▌    | 41819/75824 [00:00<00:00, 76489.54it/s] 74%|███████▍  | 56343/75824 [00:00<00:00, 88366.84it/s] 86%|████████▋ | 65516/75824 [00:00<00:00, 86498.00it/s]100%|██████████| 75824/75824 [00:00<00:00, 92140.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|██        | 15203/75824 [00:00<00:00, 152024.71it/s] 39%|███▊      | 29258/75824 [00:00<00:00, 148387.85it/s] 57%|█████▋    | 43191/75824 [00:00<00:00, 145548.81it/s] 83%|████████▎ | 63272/75824 [00:00<00:00, 158645.19it/s]100%|██████████| 75824/75824 [00:00<00:00, 163855.65it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20277/75824 [00:00<00:00, 202769.23it/s] 53%|█████▎    | 40237/75824 [00:00<00:00, 201807.12it/s] 79%|███████▊  | 59592/75824 [00:00<00:00, 199255.83it/s]100%|██████████| 75824/75824 [00:00<00:00, 197749.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19183/75824 [00:00<00:00, 191822.41it/s] 49%|████▉     | 37235/75824 [00:00<00:00, 188283.49it/s] 74%|███████▍  | 56169/75824 [00:00<00:00, 188597.78it/s] 93%|█████████▎| 70771/75824 [00:00<00:00, 173419.52it/s]100%|██████████| 75824/75824 [00:00<00:00, 156026.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12871/75824 [00:00<00:00, 128705.52it/s] 41%|████      | 30729/75824 [00:00<00:00, 140472.76it/s] 62%|██████▏   | 47174/75824 [00:00<00:00, 146898.05it/s] 79%|███████▉  | 60187/75824 [00:00<00:00, 141427.75it/s] 95%|█████████▌| 72080/75824 [00:00<00:00, 133832.63it/s]100%|██████████| 75824/75824 [00:00<00:00, 142012.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19026/75824 [00:00<00:00, 190254.28it/s] 50%|█████     | 38070/75824 [00:00<00:00, 190308.66it/s] 76%|███████▌  | 57290/75824 [00:00<00:00, 190870.16it/s]100%|██████████| 75824/75824 [00:00<00:00, 192812.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▋        | 12503/75824 [00:00<00:00, 125024.16it/s] 32%|███▏      | 24171/75824 [00:00<00:00, 122396.16it/s] 48%|████▊     | 36367/75824 [00:00<00:00, 122264.58it/s] 71%|███████   | 53743/75824 [00:00<00:00, 134195.43it/s] 94%|█████████▍| 71272/75824 [00:00<00:00, 144345.74it/s]100%|██████████| 75824/75824 [00:00<00:00, 144266.52it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18217/75824 [00:00<00:00, 182161.92it/s] 48%|████▊     | 36605/75824 [00:00<00:00, 182671.16it/s] 74%|███████▎  | 55806/75824 [00:00<00:00, 185374.15it/s]100%|█████████▉| 75734/75824 [00:00<00:00, 189336.02it/s]100%|██████████| 75824/75824 [00:00<00:00, 189142.71it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20356/75824 [00:00<00:00, 203559.71it/s] 51%|█████     | 38661/75824 [00:00<00:00, 196937.70it/s] 76%|███████▌  | 57762/75824 [00:00<00:00, 195120.46it/s]100%|██████████| 75824/75824 [00:00<00:00, 192882.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|▋         | 5006/75824 [00:00<00:01, 49150.81it/s] 22%|██▏       | 16969/75824 [00:00<00:00, 59702.82it/s] 28%|██▊       | 21591/75824 [00:00<00:01, 49041.42it/s] 45%|████▍     | 33773/75824 [00:00<00:00, 59749.86it/s] 60%|█████▉    | 45176/75824 [00:00<00:00, 69703.62it/s] 70%|███████   | 53249/75824 [00:00<00:00, 64544.75it/s] 96%|█████████▌| 72508/75824 [00:00<00:00, 80626.04it/s]100%|██████████| 75824/75824 [00:00<00:00, 94932.76it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12525/75824 [00:00<00:00, 125248.63it/s] 33%|███▎      | 24789/75824 [00:00<00:00, 124453.05it/s] 44%|████▍     | 33200/75824 [00:00<00:00, 107489.42it/s] 55%|█████▌    | 41905/75824 [00:00<00:00, 94991.95it/s]  76%|███████▋  | 57966/75824 [00:00<00:00, 108261.11it/s] 89%|████████▉ | 67717/75824 [00:00<00:00, 99326.49it/s] 100%|██████████| 75824/75824 [00:00<00:00, 104379.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17212/75824 [00:00<00:00, 172115.65it/s] 48%|████▊     | 36081/75824 [00:00<00:00, 176773.88it/s] 73%|███████▎  | 55437/75824 [00:00<00:00, 181493.82it/s] 92%|█████████▏| 69710/75824 [00:00<00:00, 167819.89it/s]100%|██████████| 75824/75824 [00:00<00:00, 170260.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20560/75824 [00:00<00:00, 205592.35it/s] 52%|█████▏    | 39491/75824 [00:00<00:00, 200418.59it/s] 77%|███████▋  | 58720/75824 [00:00<00:00, 197906.05it/s]100%|██████████| 75824/75824 [00:00<00:00, 196642.24it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20446/75824 [00:00<00:00, 204451.42it/s] 53%|█████▎    | 40461/75824 [00:00<00:00, 203139.55it/s] 80%|███████▉  | 60305/75824 [00:00<00:00, 201704.34it/s]100%|██████████| 75824/75824 [00:00<00:00, 199679.60it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18756/75824 [00:00<00:00, 187557.50it/s] 49%|████▉     | 37105/75824 [00:00<00:00, 186315.51it/s] 73%|███████▎  | 55206/75824 [00:00<00:00, 184690.60it/s] 92%|█████████▏| 69397/75824 [00:00<00:00, 169368.30it/s]100%|██████████| 75824/75824 [00:00<00:00, 168089.70it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19506/75824 [00:00<00:00, 195059.72it/s] 52%|█████▏    | 39581/75824 [00:00<00:00, 196730.08it/s] 78%|███████▊  | 59402/75824 [00:00<00:00, 197168.00it/s] 96%|█████████▌| 72431/75824 [00:00<00:00, 167023.97it/s]100%|██████████| 75824/75824 [00:00<00:00, 179020.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18590/75824 [00:00<00:00, 185888.21it/s] 33%|███▎      | 25141/75824 [00:00<00:00, 119823.29it/s] 50%|████▉     | 37870/75824 [00:00<00:00, 121969.63it/s] 69%|██████▉   | 52183/75824 [00:00<00:00, 127629.11it/s] 93%|█████████▎| 70555/75824 [00:00<00:00, 140496.43it/s]100%|██████████| 75824/75824 [00:00<00:00, 140505.83it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 18961/75824 [00:00<00:00, 189606.56it/s] 50%|████▉     | 37817/75824 [00:00<00:00, 189289.39it/s] 76%|███████▌  | 57537/75824 [00:00<00:00, 191592.78it/s]100%|██████████| 75824/75824 [00:00<00:00, 193866.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▋       | 19989/75824 [00:00<00:00, 199887.81it/s] 53%|█████▎    | 40092/75824 [00:00<00:00, 200228.73it/s] 79%|███████▉  | 60254/75824 [00:00<00:00, 200643.58it/s]100%|██████████| 75824/75824 [00:00<00:00, 201149.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14610/75824 [00:00<00:00, 146095.96it/s] 36%|███▌      | 27103/75824 [00:00<00:00, 136782.28it/s] 49%|████▉     | 36975/75824 [00:00<00:00, 122600.04it/s] 75%|███████▌  | 57047/75824 [00:00<00:00, 138805.62it/s]100%|██████████| 75824/75824 [00:00<00:00, 151803.19it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19843/75824 [00:00<00:00, 198423.57it/s] 46%|████▌     | 34843/75824 [00:00<00:00, 180902.54it/s] 57%|█████▋    | 43510/75824 [00:00<00:00, 135669.60it/s] 73%|███████▎  | 55156/75824 [00:00<00:00, 129270.28it/s] 85%|████████▌ | 64696/75824 [00:00<00:00, 112772.60it/s]100%|██████████| 75824/75824 [00:00<00:00, 127728.20it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▍        | 11134/75824 [00:00<00:00, 111339.31it/s] 23%|██▎       | 17064/75824 [00:00<00:00, 86476.27it/s]  35%|███▍      | 26242/75824 [00:00<00:00, 88001.80it/s] 54%|█████▎    | 40622/75824 [00:00<00:00, 99594.73it/s] 72%|███████▏  | 54765/75824 [00:00<00:00, 108114.08it/s] 85%|████████▌ | 64574/75824 [00:00<00:00, 97265.08it/s] 100%|█████████▉| 75590/75824 [00:00<00:00, 100803.28it/s]100%|██████████| 75824/75824 [00:00<00:00, 101588.15it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|█▍        | 10472/75824 [00:00<00:00, 95361.10it/s] 18%|█▊        | 13551/75824 [00:00<00:01, 58533.02it/s] 32%|███▏      | 24082/75824 [00:00<00:00, 67531.18it/s] 47%|████▋     | 35433/75824 [00:00<00:00, 76871.99it/s] 63%|██████▎   | 47890/75824 [00:00<00:00, 86847.14it/s] 78%|███████▊  | 59444/75824 [00:00<00:00, 93807.31it/s] 91%|█████████ | 68977/75824 [00:00<00:00, 92366.01it/s]100%|██████████| 75824/75824 [00:00<00:00, 100825.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12796/75824 [00:00<00:00, 127958.90it/s] 37%|███▋      | 27894/75824 [00:00<00:00, 134091.42it/s] 64%|██████▍   | 48667/75824 [00:00<00:00, 150048.38it/s] 84%|████████▎ | 63341/75824 [00:00<00:00, 149039.16it/s]100%|█████████▉| 75642/75824 [00:00<00:00, 128478.27it/s]100%|██████████| 75824/75824 [00:00<00:00, 143520.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 15011/75824 [00:00<00:00, 150109.07it/s] 47%|████▋     | 35869/75824 [00:00<00:00, 163891.47it/s] 77%|███████▋  | 58615/75824 [00:00<00:00, 178888.37it/s]100%|██████████| 75824/75824 [00:00<00:00, 200338.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16650/75824 [00:00<00:00, 164892.63it/s] 48%|████▊     | 36201/75824 [00:00<00:00, 173019.27it/s] 73%|███████▎  | 55289/75824 [00:00<00:00, 178014.06it/s] 97%|█████████▋| 73186/75824 [00:00<00:00, 178297.79it/s]100%|██████████| 75824/75824 [00:00<00:00, 182914.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██▏       | 16302/75824 [00:00<00:00, 163014.33it/s] 47%|████▋     | 35822/75824 [00:00<00:00, 171495.46it/s] 73%|███████▎  | 55326/75824 [00:00<00:00, 177938.88it/s] 99%|█████████▊| 74734/75824 [00:00<00:00, 182491.90it/s]100%|██████████| 75824/75824 [00:00<00:00, 186800.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17462/75824 [00:00<00:00, 174618.92it/s] 41%|████      | 31178/75824 [00:00<00:00, 161391.57it/s] 61%|██████    | 46438/75824 [00:00<00:00, 158649.24it/s] 78%|███████▊  | 59081/75824 [00:00<00:00, 147380.37it/s]100%|██████████| 75824/75824 [00:00<00:00, 155772.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19888/75824 [00:00<00:00, 198875.45it/s] 53%|█████▎    | 40185/75824 [00:00<00:00, 200083.60it/s] 81%|████████  | 61047/75824 [00:00<00:00, 202567.64it/s]100%|██████████| 75824/75824 [00:00<00:00, 205422.74it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14683/75824 [00:00<00:00, 146818.59it/s] 35%|███▍      | 26474/75824 [00:00<00:00, 133725.45it/s] 43%|████▎     | 32878/75824 [00:00<00:00, 97912.67it/s]  64%|██████▍   | 48508/75824 [00:00<00:00, 110269.96it/s] 76%|███████▌  | 57601/75824 [00:00<00:00, 99283.32it/s]  98%|█████████▊| 74024/75824 [00:00<00:00, 112646.53it/s]100%|██████████| 75824/75824 [00:00<00:00, 118860.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18912/75824 [00:00<00:00, 189114.32it/s] 49%|████▊     | 36909/75824 [00:00<00:00, 186273.87it/s] 73%|███████▎  | 55711/75824 [00:00<00:00, 186792.49it/s] 99%|█████████▉| 74999/75824 [00:00<00:00, 188575.29it/s]100%|██████████| 75824/75824 [00:00<00:00, 187487.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19118/75824 [00:00<00:00, 191176.54it/s] 51%|█████     | 38819/75824 [00:00<00:00, 192887.33it/s] 75%|███████▌  | 57140/75824 [00:00<00:00, 189875.70it/s] 96%|█████████▌| 72781/75824 [00:00<00:00, 178421.03it/s]100%|██████████| 75824/75824 [00:00<00:00, 178597.49it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|█▏        | 8598/75824 [00:00<00:00, 84028.18it/s] 23%|██▎       | 17404/75824 [00:00<00:00, 85197.80it/s] 39%|███▉      | 29748/75824 [00:00<00:00, 91960.56it/s] 54%|█████▍    | 41299/75824 [00:00<00:00, 97946.09it/s] 67%|██████▋   | 50871/75824 [00:00<00:00, 93355.91it/s] 78%|███████▊  | 58992/75824 [00:00<00:00, 80669.00it/s] 96%|█████████▌| 72841/75824 [00:00<00:00, 92159.04it/s]100%|██████████| 75824/75824 [00:00<00:00, 89527.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12968/75824 [00:00<00:00, 128726.56it/s] 27%|██▋       | 20362/75824 [00:00<00:00, 105315.26it/s] 47%|████▋     | 35607/75824 [00:00<00:00, 116080.30it/s] 64%|██████▍   | 48771/75824 [00:00<00:00, 120347.11it/s] 77%|███████▋  | 58333/75824 [00:00<00:00, 90342.82it/s]  88%|████████▊ | 66968/75824 [00:00<00:00, 88902.23it/s] 99%|█████████▉| 75425/75824 [00:00<00:00, 69277.90it/s]100%|██████████| 75824/75824 [00:00<00:00, 87670.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|██▊       | 20906/75824 [00:00<00:00, 209053.72it/s] 55%|█████▍    | 41627/75824 [00:00<00:00, 208495.73it/s] 81%|████████  | 61595/75824 [00:00<00:00, 205769.80it/s]100%|██████████| 75824/75824 [00:00<00:00, 203792.57it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13787/75824 [00:00<00:00, 137867.17it/s] 45%|████▍     | 33809/75824 [00:00<00:00, 152074.38it/s] 70%|███████   | 53383/75824 [00:00<00:00, 162981.40it/s] 87%|████████▋ | 65651/75824 [00:00<00:00, 148355.96it/s]100%|██████████| 75824/75824 [00:00<00:00, 164019.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▋       | 20085/75824 [00:00<00:00, 200843.01it/s] 52%|█████▏    | 39479/75824 [00:00<00:00, 198719.95it/s] 75%|███████▌  | 57125/75824 [00:00<00:00, 191470.72it/s]100%|██████████| 75824/75824 [00:00<00:00, 192335.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|█▏        | 8587/75824 [00:00<00:00, 83066.92it/s] 24%|██▍       | 18446/75824 [00:00<00:00, 87185.10it/s] 46%|████▌     | 34583/75824 [00:00<00:00, 101132.81it/s] 66%|██████▋   | 50261/75824 [00:00<00:00, 113184.69it/s] 88%|████████▊ | 66765/75824 [00:00<00:00, 124962.65it/s]100%|██████████| 75824/75824 [00:00<00:00, 137637.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17286/75824 [00:00<00:00, 172853.57it/s] 39%|███▊      | 29290/75824 [00:00<00:00, 152696.97it/s] 58%|█████▊    | 44147/75824 [00:00<00:00, 151434.83it/s] 80%|███████▉  | 60521/75824 [00:00<00:00, 154926.38it/s]100%|██████████| 75824/75824 [00:00<00:00, 156892.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18172/75824 [00:00<00:00, 181711.94it/s] 48%|████▊     | 36112/75824 [00:00<00:00, 181011.79it/s] 69%|██████▉   | 52302/75824 [00:00<00:00, 174819.52it/s] 85%|████████▌ | 64743/75824 [00:00<00:00, 155871.16it/s]100%|██████████| 75824/75824 [00:00<00:00, 159302.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17661/75824 [00:00<00:00, 176608.48it/s] 47%|████▋     | 35781/75824 [00:00<00:00, 177959.99it/s] 71%|███████▏  | 54159/75824 [00:00<00:00, 179664.33it/s] 89%|████████▉ | 67413/75824 [00:00<00:00, 162345.12it/s]100%|██████████| 75824/75824 [00:00<00:00, 165587.02it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12540/75824 [00:00<00:00, 125392.35it/s] 32%|███▏      | 24019/75824 [00:00<00:00, 122009.82it/s] 40%|███▉      | 30096/75824 [00:00<00:00, 86472.50it/s]  47%|████▋     | 35895/75824 [00:00<00:00, 73429.92it/s] 61%|██████    | 46023/75824 [00:00<00:00, 80030.68it/s] 75%|███████▍  | 56628/75824 [00:00<00:00, 86387.77it/s] 87%|████████▋ | 66027/75824 [00:00<00:00, 88534.15it/s]100%|█████████▉| 75623/75824 [00:00<00:00, 90636.61it/s]100%|██████████| 75824/75824 [00:00<00:00, 91103.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 11851/75824 [00:00<00:00, 118503.90it/s] 25%|██▌       | 19093/75824 [00:00<00:00, 99503.46it/s]  41%|████      | 31018/75824 [00:00<00:00, 104703.64it/s] 66%|██████▌   | 49960/75824 [00:00<00:00, 120928.87it/s] 92%|█████████▏| 69787/75824 [00:00<00:00, 136955.15it/s]100%|██████████| 75824/75824 [00:00<00:00, 143156.76it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19527/75824 [00:00<00:00, 195266.46it/s] 52%|█████▏    | 39613/75824 [00:00<00:00, 196910.90it/s] 77%|███████▋  | 58477/75824 [00:00<00:00, 194353.38it/s] 96%|█████████▌| 72489/75824 [00:00<00:00, 174131.75it/s]100%|██████████| 75824/75824 [00:00<00:00, 177434.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██        | 15915/75824 [00:00<00:00, 159144.08it/s] 43%|████▎     | 32811/75824 [00:00<00:00, 161172.25it/s] 62%|██████▏   | 46723/75824 [00:00<00:00, 153852.84it/s] 81%|████████  | 61574/75824 [00:00<00:00, 152206.97it/s] 99%|█████████▉| 75398/75824 [00:00<00:00, 147726.93it/s]100%|██████████| 75824/75824 [00:00<00:00, 149933.08it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16308/75824 [00:00<00:00, 163067.71it/s] 31%|███       | 23574/75824 [00:00<00:00, 118737.99it/s] 39%|███▉      | 29721/75824 [00:00<00:00, 92797.89it/s]  50%|████▉     | 37539/75824 [00:00<00:00, 83081.93it/s] 60%|██████    | 45849/75824 [00:00<00:00, 83086.54it/s] 78%|███████▊  | 59305/75824 [00:00<00:00, 93857.14it/s]100%|██████████| 75824/75824 [00:00<00:00, 107616.97it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13589/75824 [00:00<00:00, 135884.62it/s] 38%|███▊      | 28450/75824 [00:00<00:00, 139466.01it/s] 55%|█████▍    | 41627/75824 [00:00<00:00, 137063.56it/s] 71%|███████   | 53844/75824 [00:00<00:00, 132224.83it/s] 84%|████████▍ | 63859/75824 [00:00<00:00, 109078.19it/s]100%|██████████| 75824/75824 [00:00<00:00, 124478.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18381/75824 [00:00<00:00, 183808.86it/s] 48%|████▊     | 36043/75824 [00:00<00:00, 181587.81it/s] 63%|██████▎   | 47667/75824 [00:00<00:00, 155380.58it/s] 87%|████████▋ | 65605/75824 [00:00<00:00, 161877.23it/s]100%|██████████| 75824/75824 [00:00<00:00, 166565.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18469/75824 [00:00<00:00, 184681.37it/s] 47%|████▋     | 35757/75824 [00:00<00:00, 180969.27it/s] 59%|█████▉    | 44822/75824 [00:00<00:00, 120145.87it/s] 81%|████████  | 61420/75824 [00:00<00:00, 130997.78it/s] 97%|█████████▋| 73918/75824 [00:00<00:00, 129129.64it/s]100%|██████████| 75824/75824 [00:00<00:00, 137659.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19637/75824 [00:00<00:00, 196360.36it/s] 52%|█████▏    | 39570/75824 [00:00<00:00, 197239.46it/s] 72%|███████▏  | 54781/75824 [00:00<00:00, 180502.58it/s] 88%|████████▊ | 66374/75824 [00:00<00:00, 145563.30it/s]100%|██████████| 75824/75824 [00:00<00:00, 155326.00it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14522/75824 [00:00<00:00, 145217.37it/s] 44%|████▍     | 33193/75824 [00:00<00:00, 155588.72it/s] 68%|██████▊   | 51595/75824 [00:00<00:00, 163148.89it/s] 93%|█████████▎| 70298/75824 [00:00<00:00, 169647.08it/s]100%|██████████| 75824/75824 [00:00<00:00, 176844.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20146/75824 [00:00<00:00, 201459.71it/s] 52%|█████▏    | 39769/75824 [00:00<00:00, 199860.51it/s] 79%|███████▊  | 59550/75824 [00:00<00:00, 199239.39it/s]100%|██████████| 75824/75824 [00:00<00:00, 198920.99it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 14942/75824 [00:00<00:00, 149417.65it/s] 37%|███▋      | 28410/75824 [00:00<00:00, 144665.05it/s] 51%|█████     | 38606/75824 [00:00<00:00, 128516.21it/s] 65%|██████▌   | 49493/75824 [00:00<00:00, 121912.80it/s] 90%|█████████ | 68257/75824 [00:00<00:00, 136227.19it/s]100%|██████████| 75824/75824 [00:00<00:00, 140428.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13901/75824 [00:00<00:00, 139006.82it/s] 45%|████▍     | 34036/75824 [00:00<00:00, 153239.82it/s] 57%|█████▋    | 42996/75824 [00:00<00:00, 116866.35it/s] 74%|███████▍  | 56330/75824 [00:00<00:00, 121364.54it/s] 87%|████████▋ | 66300/75824 [00:00<00:00, 96657.24it/s] 100%|██████████| 75824/75824 [00:00<00:00, 116851.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██        | 15971/75824 [00:00<00:00, 159697.21it/s] 27%|██▋       | 20847/75824 [00:00<00:00, 94910.65it/s]  50%|█████     | 38100/75824 [00:00<00:00, 109718.19it/s] 76%|███████▋  | 57856/75824 [00:00<00:00, 126605.36it/s] 92%|█████████▏| 69766/75824 [00:00<00:00, 96008.61it/s] 100%|██████████| 75824/75824 [00:00<00:00, 118184.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██▏       | 16126/75824 [00:00<00:00, 161258.62it/s] 41%|████      | 30727/75824 [00:00<00:00, 156353.83it/s] 51%|█████     | 38494/75824 [00:00<00:00, 101635.84it/s] 73%|███████▎  | 55602/75824 [00:00<00:00, 115728.04it/s] 90%|████████▉ | 68042/75824 [00:00<00:00, 118197.67it/s]100%|██████████| 75824/75824 [00:00<00:00, 129626.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 12105/75824 [00:00<00:00, 121040.88it/s] 35%|███▍      | 26366/75824 [00:00<00:00, 126792.33it/s] 61%|██████    | 45979/75824 [00:00<00:00, 141834.04it/s] 88%|████████▊ | 66742/75824 [00:00<00:00, 156733.85it/s]100%|██████████| 75824/75824 [00:00<00:00, 171357.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|██        | 15213/75824 [00:00<00:00, 152128.33it/s] 39%|███▊      | 29239/75824 [00:00<00:00, 148362.09it/s] 56%|█████▌    | 42582/75824 [00:00<00:00, 143541.88it/s] 81%|████████  | 61362/75824 [00:00<00:00, 154462.02it/s]100%|██████████| 75824/75824 [00:00<00:00, 159498.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18338/75824 [00:00<00:00, 183377.99it/s] 47%|████▋     | 35732/75824 [00:00<00:00, 180438.15it/s] 70%|███████   | 53248/75824 [00:00<00:00, 178820.35it/s] 92%|█████████▏| 69745/75824 [00:00<00:00, 174424.86it/s]100%|██████████| 75824/75824 [00:00<00:00, 175952.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 12310/75824 [00:00<00:00, 123086.32it/s] 38%|███▊      | 29044/75824 [00:00<00:00, 133691.43it/s] 63%|██████▎   | 47775/75824 [00:00<00:00, 146250.12it/s] 88%|████████▊ | 66592/75824 [00:00<00:00, 156724.34it/s]100%|██████████| 75824/75824 [00:00<00:00, 169602.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13803/75824 [00:00<00:00, 138025.20it/s] 37%|███▋      | 27949/75824 [00:00<00:00, 139034.22it/s] 46%|████▋     | 35091/75824 [00:00<00:00, 102495.34it/s] 66%|██████▋   | 50260/75824 [00:00<00:00, 113537.81it/s] 89%|████████▉ | 67734/75824 [00:00<00:00, 126867.83it/s]100%|██████████| 75824/75824 [00:00<00:00, 136248.02it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██        | 15550/75824 [00:00<00:00, 155498.67it/s] 47%|████▋     | 35469/75824 [00:00<00:00, 166449.83it/s] 74%|███████▍  | 56155/75824 [00:00<00:00, 176810.65it/s] 93%|█████████▎| 70391/75824 [00:00<00:00, 158797.21it/s]100%|██████████| 75824/75824 [00:00<00:00, 152400.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13882/75824 [00:00<00:00, 138819.14it/s] 37%|███▋      | 27880/75824 [00:00<00:00, 139164.32it/s] 54%|█████▍    | 41147/75824 [00:00<00:00, 137149.66it/s] 75%|███████▍  | 56527/75824 [00:00<00:00, 141753.09it/s] 99%|█████████▉| 75142/75824 [00:00<00:00, 152675.06it/s]100%|██████████| 75824/75824 [00:00<00:00, 149999.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▍        | 11299/75824 [00:00<00:00, 112988.22it/s] 34%|███▍      | 25869/75824 [00:00<00:00, 121147.02it/s] 58%|█████▊    | 43929/75824 [00:00<00:00, 134274.66it/s] 84%|████████▍ | 63721/75824 [00:00<00:00, 148610.08it/s]100%|██████████| 75824/75824 [00:00<00:00, 164096.78it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 14931/75824 [00:00<00:00, 149306.23it/s] 39%|███▉      | 29790/75824 [00:00<00:00, 149090.14it/s] 59%|█████▊    | 44506/75824 [00:00<00:00, 148502.85it/s] 78%|███████▊  | 59318/75824 [00:00<00:00, 148385.06it/s] 93%|█████████▎| 70573/75824 [00:00<00:00, 129199.22it/s]100%|██████████| 75824/75824 [00:00<00:00, 116399.49it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|█▍        | 10962/75824 [00:00<00:00, 109619.32it/s] 30%|███       | 22761/75824 [00:00<00:00, 112002.60it/s] 50%|████▉     | 37835/75824 [00:00<00:00, 121357.59it/s] 73%|███████▎  | 55211/75824 [00:00<00:00, 133428.32it/s] 98%|█████████▊| 74041/75824 [00:00<00:00, 146207.78it/s]100%|██████████| 75824/75824 [00:00<00:00, 147394.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|▊         | 5891/75824 [00:00<00:01, 56521.99it/s] 16%|█▌        | 12009/75824 [00:00<00:01, 55224.22it/s] 25%|██▌       | 19286/75824 [00:00<00:00, 59529.28it/s] 42%|████▏     | 31595/75824 [00:00<00:00, 70440.84it/s] 64%|██████▎   | 48247/75824 [00:00<00:00, 85186.10it/s] 88%|████████▊ | 66432/75824 [00:00<00:00, 101347.43it/s]100%|██████████| 75824/75824 [00:00<00:00, 112899.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 15091/75824 [00:00<00:00, 150908.70it/s] 40%|████      | 30359/75824 [00:00<00:00, 151434.95it/s] 55%|█████▍    | 41500/75824 [00:00<00:00, 132208.95it/s] 66%|██████▌   | 49985/75824 [00:00<00:00, 104461.39it/s] 82%|████████▏ | 62538/75824 [00:00<00:00, 109999.01it/s]100%|██████████| 75824/75824 [00:00<00:00, 121501.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19515/75824 [00:00<00:00, 195143.67it/s] 51%|█████     | 38585/75824 [00:00<00:00, 193787.62it/s] 68%|██████▊   | 51883/75824 [00:00<00:00, 170239.94it/s] 83%|████████▎ | 62736/75824 [00:00<00:00, 138413.44it/s]100%|██████████| 75824/75824 [00:00<00:00, 157553.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 18995/75824 [00:00<00:00, 189949.73it/s] 50%|████▉     | 37729/75824 [00:00<00:00, 189158.17it/s] 73%|███████▎  | 55003/75824 [00:00<00:00, 183912.90it/s] 88%|████████▊ | 66912/75824 [00:00<00:00, 147358.79it/s]100%|██████████| 75824/75824 [00:00<00:00, 149235.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20108/75824 [00:00<00:00, 201076.36it/s] 44%|████▎     | 33136/75824 [00:00<00:00, 172889.90it/s] 70%|██████▉   | 53026/75824 [00:00<00:00, 179949.18it/s] 96%|█████████▌| 72547/75824 [00:00<00:00, 184268.68it/s]100%|██████████| 75824/75824 [00:00<00:00, 181841.68it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19637/75824 [00:00<00:00, 196360.82it/s] 52%|█████▏    | 39346/75824 [00:00<00:00, 196577.94it/s] 77%|███████▋  | 58374/75824 [00:00<00:00, 194644.42it/s]100%|██████████| 75824/75824 [00:00<00:00, 194616.17it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19531/75824 [00:00<00:00, 195303.67it/s] 48%|████▊     | 36182/75824 [00:00<00:00, 185671.28it/s] 60%|█████▉    | 45279/75824 [00:00<00:00, 98831.91it/s]  76%|███████▋  | 57861/75824 [00:00<00:00, 105628.65it/s] 94%|█████████▍| 71118/75824 [00:00<00:00, 112485.29it/s]100%|██████████| 75824/75824 [00:00<00:00, 122969.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18617/75824 [00:00<00:00, 186164.85it/s] 43%|████▎     | 32453/75824 [00:00<00:00, 168678.28it/s] 63%|██████▎   | 47778/75824 [00:00<00:00, 163731.10it/s] 78%|███████▊  | 59056/75824 [00:00<00:00, 144186.41it/s] 95%|█████████▌| 72076/75824 [00:00<00:00, 139682.50it/s]100%|██████████| 75824/75824 [00:00<00:00, 141571.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▊        | 14070/75824 [00:00<00:00, 140699.80it/s] 34%|███▍      | 25892/75824 [00:00<00:00, 133105.72it/s] 53%|█████▎    | 40462/75824 [00:00<00:00, 136648.79it/s] 65%|██████▌   | 49384/75824 [00:00<00:00, 112510.75it/s] 85%|████████▍ | 64175/75824 [00:00<00:00, 121213.15it/s]100%|██████████| 75824/75824 [00:00<00:00, 127843.11it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16543/75824 [00:00<00:00, 165422.27it/s] 43%|████▎     | 32694/75824 [00:00<00:00, 164227.57it/s] 59%|█████▉    | 45019/75824 [00:00<00:00, 149329.29it/s] 72%|███████▏  | 54540/75824 [00:00<00:00, 94484.94it/s]  83%|████████▎ | 62731/75824 [00:00<00:00, 76814.41it/s]100%|██████████| 75824/75824 [00:00<00:00, 106512.02it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12636/75824 [00:00<00:00, 126354.70it/s] 32%|███▏      | 24551/75824 [00:00<00:00, 124096.44it/s] 42%|████▏     | 32008/75824 [00:00<00:00, 103477.65it/s] 64%|██████▍   | 48837/75824 [00:00<00:00, 116992.98it/s] 77%|███████▋  | 58503/75824 [00:00<00:00, 92974.22it/s]  96%|█████████▌| 72693/75824 [00:00<00:00, 103700.59it/s]100%|██████████| 75824/75824 [00:00<00:00, 113104.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18488/75824 [00:00<00:00, 184875.33it/s] 38%|███▊      | 28941/75824 [00:00<00:00, 147178.43it/s] 50%|████▉     | 37807/75824 [00:00<00:00, 122850.20it/s] 76%|███████▌  | 57362/75824 [00:00<00:00, 138270.67it/s] 99%|█████████▉| 75043/75824 [00:00<00:00, 147944.81it/s]100%|██████████| 75824/75824 [00:00<00:00, 148915.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19661/75824 [00:00<00:00, 196607.84it/s] 51%|█████     | 38484/75824 [00:00<00:00, 194014.56it/s] 76%|███████▌  | 57251/75824 [00:00<00:00, 192065.95it/s]100%|██████████| 75824/75824 [00:00<00:00, 191346.57it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 14020/75824 [00:00<00:00, 140191.78it/s] 38%|███▊      | 29075/75824 [00:00<00:00, 143144.13it/s] 59%|█████▊    | 44537/75824 [00:00<00:00, 146401.71it/s] 79%|███████▉  | 60107/75824 [00:00<00:00, 149070.26it/s]100%|█████████▉| 75529/75824 [00:00<00:00, 150577.59it/s]100%|██████████| 75824/75824 [00:00<00:00, 150961.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 14999/75824 [00:00<00:00, 149985.85it/s] 40%|███▉      | 30081/75824 [00:00<00:00, 150232.92it/s] 61%|██████▏   | 46565/75824 [00:00<00:00, 154333.57it/s] 86%|████████▌ | 65044/75824 [00:00<00:00, 162361.05it/s]100%|██████████| 75824/75824 [00:00<00:00, 165679.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 18963/75824 [00:00<00:00, 189628.37it/s] 33%|███▎      | 24652/75824 [00:00<00:00, 100424.22it/s] 57%|█████▋    | 43028/75824 [00:00<00:00, 116237.78it/s] 83%|████████▎ | 62652/75824 [00:00<00:00, 132434.11it/s]100%|██████████| 75824/75824 [00:00<00:00, 155890.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12903/75824 [00:00<00:00, 129025.51it/s] 37%|███▋      | 27704/75824 [00:00<00:00, 134187.24it/s] 52%|█████▏    | 39062/75824 [00:00<00:00, 127258.65it/s] 63%|██████▎   | 47750/75824 [00:00<00:00, 111683.29it/s] 80%|████████  | 60984/75824 [00:00<00:00, 117169.38it/s]100%|██████████| 75824/75824 [00:00<00:00, 128390.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19356/75824 [00:00<00:00, 193552.80it/s] 48%|████▊     | 36127/75824 [00:00<00:00, 185000.42it/s] 68%|██████▊   | 51871/75824 [00:00<00:00, 175765.96it/s] 86%|████████▌ | 65374/75824 [00:00<00:00, 161172.47it/s]100%|██████████| 75824/75824 [00:00<00:00, 137162.24it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|█▏        | 9475/75824 [00:00<00:00, 94736.99it/s] 24%|██▎       | 17958/75824 [00:00<00:00, 91529.05it/s] 36%|███▌      | 26963/75824 [00:00<00:00, 91079.95it/s] 53%|█████▎    | 40197/75824 [00:00<00:00, 100477.75it/s] 73%|███████▎  | 55389/75824 [00:00<00:00, 111837.24it/s] 87%|████████▋ | 65605/75824 [00:00<00:00, 98186.10it/s] 100%|██████████| 75824/75824 [00:00<00:00, 108787.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19700/75824 [00:00<00:00, 196998.31it/s] 41%|████▏     | 31394/75824 [00:00<00:00, 162182.07it/s] 56%|█████▌    | 42189/75824 [00:00<00:00, 140939.46it/s] 81%|████████  | 61147/75824 [00:00<00:00, 152691.24it/s]100%|█████████▉| 75534/75824 [00:00<00:00, 149930.81it/s]100%|██████████| 75824/75824 [00:00<00:00, 150272.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12578/75824 [00:00<00:00, 125776.22it/s] 32%|███▏      | 24225/75824 [00:00<00:00, 122830.50it/s] 40%|████      | 30361/75824 [00:00<00:00, 84508.78it/s]  56%|█████▋    | 42695/75824 [00:00<00:00, 92697.71it/s] 66%|██████▋   | 50322/75824 [00:00<00:00, 83604.25it/s] 85%|████████▌ | 64635/75824 [00:00<00:00, 95521.66it/s]100%|██████████| 75824/75824 [00:00<00:00, 106295.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▌        | 11728/75824 [00:00<00:00, 117272.00it/s] 28%|██▊       | 21494/75824 [00:00<00:00, 110548.00it/s] 35%|███▌      | 26882/75824 [00:00<00:00, 81295.70it/s]  58%|█████▊    | 43991/75824 [00:00<00:00, 96487.59it/s] 80%|████████  | 60759/75824 [00:00<00:00, 110570.71it/s] 97%|█████████▋| 73467/75824 [00:00<00:00, 115053.29it/s]100%|██████████| 75824/75824 [00:00<00:00, 122345.49it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19450/75824 [00:00<00:00, 194490.91it/s] 50%|████▉     | 37766/75824 [00:00<00:00, 190944.33it/s] 69%|██████▉   | 52402/75824 [00:00<00:00, 174951.34it/s] 89%|████████▊ | 67234/75824 [00:00<00:00, 166007.82it/s]100%|██████████| 75824/75824 [00:00<00:00, 170518.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19736/75824 [00:00<00:00, 197356.42it/s] 52%|█████▏    | 39277/75824 [00:00<00:00, 196221.99it/s] 77%|███████▋  | 58751/75824 [00:00<00:00, 195774.10it/s] 97%|█████████▋| 73541/75824 [00:00<00:00, 178443.71it/s]100%|██████████| 75824/75824 [00:00<00:00, 179932.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 12933/75824 [00:00<00:00, 129324.57it/s] 38%|███▊      | 29021/75824 [00:00<00:00, 137409.03it/s] 62%|██████▏   | 47388/75824 [00:00<00:00, 148640.31it/s] 81%|████████  | 61183/75824 [00:00<00:00, 145262.92it/s]100%|██████████| 75824/75824 [00:00<00:00, 153251.21it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▊        | 14205/75824 [00:00<00:00, 142046.75it/s] 38%|███▊      | 28507/75824 [00:00<00:00, 142335.65it/s] 61%|██████▏   | 46582/75824 [00:00<00:00, 152027.58it/s] 85%|████████▍ | 64450/75824 [00:00<00:00, 159148.97it/s]100%|██████████| 75824/75824 [00:00<00:00, 163360.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▊        | 14034/75824 [00:00<00:00, 140333.11it/s] 38%|███▊      | 28480/75824 [00:00<00:00, 141545.15it/s] 58%|█████▊    | 43731/75824 [00:00<00:00, 144663.68it/s] 82%|████████▏ | 62301/75824 [00:00<00:00, 154934.23it/s]100%|██████████| 75824/75824 [00:00<00:00, 160636.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16769/75824 [00:00<00:00, 167685.76it/s] 49%|████▊     | 36806/75824 [00:00<00:00, 176313.76it/s] 73%|███████▎  | 55379/75824 [00:00<00:00, 179034.16it/s] 90%|█████████ | 68332/75824 [00:00<00:00, 160615.82it/s]100%|██████████| 75824/75824 [00:00<00:00, 173721.74it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19678/75824 [00:00<00:00, 196775.97it/s] 51%|█████▏    | 38886/75824 [00:00<00:00, 195341.17it/s] 77%|███████▋  | 58319/75824 [00:00<00:00, 195033.97it/s]100%|██████████| 75824/75824 [00:00<00:00, 195197.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|█▍        | 10476/75824 [00:00<00:00, 104758.85it/s] 30%|██▉       | 22554/75824 [00:00<00:00, 109098.54it/s] 37%|███▋      | 28378/75824 [00:00<00:00, 79573.64it/s]  60%|█████▉    | 45165/75824 [00:00<00:00, 94482.40it/s] 71%|███████▏  | 54079/75824 [00:00<00:00, 80612.33it/s] 92%|█████████▏| 69591/75824 [00:00<00:00, 94182.85it/s]100%|██████████| 75824/75824 [00:00<00:00, 97603.89it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 11851/75824 [00:00<00:00, 118509.27it/s] 35%|███▌      | 26582/75824 [00:00<00:00, 125891.36it/s] 44%|████▍     | 33578/75824 [00:00<00:00, 96791.73it/s]  53%|█████▎    | 40300/75824 [00:00<00:00, 83398.58it/s] 62%|██████▏   | 46897/75824 [00:00<00:00, 69714.80it/s] 71%|███████   | 53887/75824 [00:00<00:00, 69770.23it/s] 85%|████████▌ | 64475/75824 [00:00<00:00, 77721.77it/s]100%|██████████| 75824/75824 [00:00<00:00, 91101.17it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13566/75824 [00:00<00:00, 135656.57it/s] 43%|████▎     | 32689/75824 [00:00<00:00, 148611.18it/s] 69%|██████▉   | 52132/75824 [00:00<00:00, 159915.00it/s] 88%|████████▊ | 66733/75824 [00:00<00:00, 155470.34it/s]100%|██████████| 75824/75824 [00:00<00:00, 163265.65it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18285/75824 [00:00<00:00, 182842.76it/s] 49%|████▉     | 37067/75824 [00:00<00:00, 184307.94it/s] 74%|███████▎  | 55829/75824 [00:00<00:00, 185287.69it/s] 99%|█████████▉| 74920/75824 [00:00<00:00, 186937.79it/s]100%|██████████| 75824/75824 [00:00<00:00, 187350.02it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|█▉        | 14996/75824 [00:00<00:00, 149955.14it/s] 44%|████▍     | 33606/75824 [00:00<00:00, 159232.02it/s] 69%|██████▊   | 52110/75824 [00:00<00:00, 166184.48it/s] 93%|█████████▎| 70503/75824 [00:00<00:00, 171134.97it/s]100%|██████████| 75824/75824 [00:00<00:00, 175842.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14507/75824 [00:00<00:00, 145063.22it/s] 38%|███▊      | 28946/75824 [00:00<00:00, 144857.83it/s] 57%|█████▋    | 43277/75824 [00:00<00:00, 144389.50it/s] 76%|███████▋  | 57988/75824 [00:00<00:00, 145192.30it/s] 96%|█████████▋| 73088/75824 [00:00<00:00, 146885.56it/s]100%|██████████| 75824/75824 [00:00<00:00, 146219.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██▏       | 16184/75824 [00:00<00:00, 161833.98it/s] 42%|████▏     | 31953/75824 [00:00<00:00, 160564.05it/s] 58%|█████▊    | 44204/75824 [00:00<00:00, 146874.06it/s] 82%|████████▏ | 62248/75824 [00:00<00:00, 155553.60it/s]100%|██████████| 75824/75824 [00:00<00:00, 160885.15it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17356/75824 [00:00<00:00, 173556.03it/s] 48%|████▊     | 36414/75824 [00:00<00:00, 178334.65it/s] 73%|███████▎  | 55712/75824 [00:00<00:00, 182487.98it/s] 94%|█████████▍| 71378/75824 [00:00<00:00, 173582.74it/s]100%|██████████| 75824/75824 [00:00<00:00, 160455.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19522/75824 [00:00<00:00, 195211.34it/s] 51%|█████     | 38704/75824 [00:00<00:00, 194180.07it/s] 77%|███████▋  | 58476/75824 [00:00<00:00, 195227.07it/s]100%|██████████| 75824/75824 [00:00<00:00, 194668.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18781/75824 [00:00<00:00, 187808.39it/s] 50%|█████     | 38065/75824 [00:00<00:00, 189288.81it/s] 76%|███████▋  | 57826/75824 [00:00<00:00, 191710.29it/s]100%|██████████| 75824/75824 [00:00<00:00, 191664.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19304/75824 [00:00<00:00, 193038.80it/s] 50%|█████     | 38144/75824 [00:00<00:00, 191621.32it/s] 63%|██████▎   | 47850/75824 [00:00<00:00, 145267.43it/s] 80%|███████▉  | 60453/75824 [00:00<00:00, 138905.50it/s] 94%|█████████▎| 70940/75824 [00:00<00:00, 121993.64it/s]100%|██████████| 75824/75824 [00:00<00:00, 129304.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|█▋        | 13003/75824 [00:00<00:00, 130026.71it/s] 27%|██▋       | 20851/75824 [00:00<00:00, 108622.89it/s] 49%|████▉     | 37482/75824 [00:00<00:00, 121238.41it/s] 71%|███████▏  | 54188/75824 [00:00<00:00, 132105.02it/s] 86%|████████▌ | 65184/75824 [00:00<00:00, 96194.45it/s]  99%|█████████▉| 75035/75824 [00:00<00:00, 96877.09it/s]100%|██████████| 75824/75824 [00:00<00:00, 108867.89it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▍        | 11174/75824 [00:00<00:00, 111735.05it/s] 31%|███       | 23144/75824 [00:00<00:00, 114008.51it/s] 44%|████▍     | 33442/75824 [00:00<00:00, 103504.17it/s] 58%|█████▊    | 43876/75824 [00:00<00:00, 103752.95it/s] 74%|███████▍  | 56375/75824 [00:00<00:00, 108612.70it/s] 87%|████████▋ | 66135/75824 [00:00<00:00, 103564.84it/s]100%|██████████| 75824/75824 [00:00<00:00, 107719.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▎       | 17877/75824 [00:00<00:00, 178753.12it/s] 31%|███       | 23240/75824 [00:00<00:00, 96415.14it/s]  48%|████▊     | 36385/75824 [00:00<00:00, 104793.75it/s] 60%|█████▉    | 45178/75824 [00:00<00:00, 99090.18it/s]  73%|███████▎  | 55620/75824 [00:00<00:00, 100630.17it/s] 98%|█████████▊| 74418/75824 [00:00<00:00, 116930.08it/s]100%|██████████| 75824/75824 [00:00<00:00, 121670.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18213/75824 [00:00<00:00, 182116.28it/s] 40%|████      | 30489/75824 [00:00<00:00, 159043.36it/s] 64%|██████▍   | 48821/75824 [00:00<00:00, 165621.20it/s] 87%|████████▋ | 65865/75824 [00:00<00:00, 167034.05it/s]100%|██████████| 75824/75824 [00:00<00:00, 155113.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|██▋       | 20174/75824 [00:00<00:00, 201737.31it/s] 52%|█████▏    | 39581/75824 [00:00<00:00, 199374.01it/s] 70%|██████▉   | 52707/75824 [00:00<00:00, 172513.04it/s] 85%|████████▌ | 64488/75824 [00:00<00:00, 151420.14it/s]100%|██████████| 75824/75824 [00:00<00:00, 162867.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18906/75824 [00:00<00:00, 189051.17it/s] 52%|█████▏    | 39334/75824 [00:00<00:00, 193374.04it/s] 76%|███████▌  | 57583/75824 [00:00<00:00, 189971.99it/s]100%|██████████| 75824/75824 [00:00<00:00, 192061.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██        | 15808/75824 [00:00<00:00, 158072.61it/s] 41%|████      | 30915/75824 [00:00<00:00, 155902.46it/s] 61%|██████    | 46096/75824 [00:00<00:00, 154650.09it/s] 81%|████████  | 61144/75824 [00:00<00:00, 153374.71it/s]100%|██████████| 75824/75824 [00:00<00:00, 152389.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▉        | 14769/75824 [00:00<00:00, 147686.62it/s] 39%|███▉      | 29740/75824 [00:00<00:00, 148282.45it/s] 49%|████▉     | 37333/75824 [00:00<00:00, 109356.68it/s] 59%|█████▉    | 44683/75824 [00:00<00:00, 93503.08it/s]  78%|███████▊  | 59492/75824 [00:00<00:00, 105127.12it/s] 91%|█████████ | 69003/75824 [00:00<00:00, 92733.39it/s] 100%|██████████| 75824/75824 [00:00<00:00, 101692.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▌        | 11647/75824 [00:00<00:00, 116461.50it/s] 27%|██▋       | 20595/75824 [00:00<00:00, 106798.55it/s] 41%|████      | 31001/75824 [00:00<00:00, 105959.61it/s] 51%|█████     | 38426/75824 [00:00<00:00, 93924.37it/s]  73%|███████▎  | 55707/75824 [00:00<00:00, 108827.68it/s] 93%|█████████▎| 70398/75824 [00:00<00:00, 118002.48it/s]100%|██████████| 75824/75824 [00:00<00:00, 117950.99it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|▉         | 7013/75824 [00:00<00:00, 69940.47it/s] 25%|██▌       | 19116/75824 [00:00<00:00, 80081.22it/s] 40%|███▉      | 30212/75824 [00:00<00:00, 87374.40it/s] 49%|████▉     | 37464/75824 [00:00<00:00, 82315.81it/s] 63%|██████▎   | 47901/75824 [00:00<00:00, 87041.79it/s] 74%|███████▎  | 55820/75824 [00:00<00:00, 78491.02it/s] 91%|█████████▏| 69261/75824 [00:00<00:00, 89683.95it/s]100%|██████████| 75824/75824 [00:00<00:00, 97862.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▊        | 14080/75824 [00:00<00:00, 140793.42it/s] 39%|███▉      | 29655/75824 [00:00<00:00, 144969.58it/s] 64%|██████▍   | 48501/75824 [00:00<00:00, 155751.83it/s] 81%|████████  | 61221/75824 [00:00<00:00, 145921.91it/s]100%|██████████| 75824/75824 [00:00<00:00, 159067.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19647/75824 [00:00<00:00, 196464.57it/s] 51%|█████     | 38629/75824 [00:00<00:00, 194422.06it/s] 76%|███████▌  | 57416/75824 [00:00<00:00, 192407.88it/s] 98%|█████████▊| 74579/75824 [00:00<00:00, 185664.13it/s]100%|██████████| 75824/75824 [00:00<00:00, 184716.24it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19042/75824 [00:00<00:00, 190418.37it/s] 49%|████▉     | 37493/75824 [00:00<00:00, 188606.42it/s] 74%|███████▍  | 56001/75824 [00:00<00:00, 187533.57it/s] 97%|█████████▋| 73749/75824 [00:00<00:00, 184397.35it/s]100%|██████████| 75824/75824 [00:00<00:00, 184134.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18310/75824 [00:00<00:00, 183093.63it/s] 48%|████▊     | 36122/75824 [00:00<00:00, 181571.35it/s] 72%|███████▏  | 54437/75824 [00:00<00:00, 182041.35it/s] 96%|█████████▌| 72597/75824 [00:00<00:00, 181907.73it/s]100%|██████████| 75824/75824 [00:00<00:00, 181514.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▊        | 14073/75824 [00:00<00:00, 140728.79it/s] 43%|████▎     | 32788/75824 [00:00<00:00, 152040.90it/s] 67%|██████▋   | 50861/75824 [00:00<00:00, 159640.26it/s] 84%|████████▍ | 63866/75824 [00:00<00:00, 149438.36it/s]100%|██████████| 75824/75824 [00:00<00:00, 160791.11it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 12089/75824 [00:00<00:00, 120874.27it/s] 40%|███▉      | 30120/75824 [00:00<00:00, 134138.15it/s] 65%|██████▌   | 49336/75824 [00:00<00:00, 147499.03it/s] 88%|████████▊ | 66476/75824 [00:00<00:00, 153936.72it/s]100%|██████████| 75824/75824 [00:00<00:00, 159679.60it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▋       | 19934/75824 [00:00<00:00, 199332.11it/s] 52%|█████▏    | 39638/75824 [00:00<00:00, 198638.53it/s] 78%|███████▊  | 59293/75824 [00:00<00:00, 198005.95it/s]100%|██████████| 75824/75824 [00:00<00:00, 198425.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17323/75824 [00:00<00:00, 173226.04it/s] 49%|████▉     | 37425/75824 [00:00<00:00, 180720.24it/s] 75%|███████▌  | 57198/75824 [00:00<00:00, 185505.80it/s]100%|██████████| 75824/75824 [00:00<00:00, 192267.97it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 19281/75824 [00:00<00:00, 192807.89it/s] 43%|████▎     | 32463/75824 [00:00<00:00, 169303.00it/s] 60%|█████▉    | 45165/75824 [00:00<00:00, 150889.07it/s] 75%|███████▍  | 56692/75824 [00:00<00:00, 138086.70it/s] 96%|█████████▌| 72616/75824 [00:00<00:00, 143814.70it/s]100%|██████████| 75824/75824 [00:00<00:00, 142740.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16629/75824 [00:00<00:00, 166278.27it/s] 42%|████▏     | 31884/75824 [00:00<00:00, 161905.00it/s] 53%|█████▎    | 39953/75824 [00:00<00:00, 106292.02it/s] 78%|███████▊  | 58946/75824 [00:00<00:00, 122471.20it/s] 92%|█████████▏| 69837/75824 [00:00<00:00, 111852.55it/s]100%|██████████| 75824/75824 [00:00<00:00, 125928.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 12070/75824 [00:00<00:00, 120692.35it/s] 32%|███▏      | 23908/75824 [00:00<00:00, 119987.25it/s] 50%|████▉     | 37668/75824 [00:00<00:00, 124778.61it/s] 63%|██████▎   | 47792/75824 [00:00<00:00, 116637.91it/s] 75%|███████▍  | 56701/75824 [00:00<00:00, 100717.89it/s]100%|█████████▉| 75804/75824 [00:00<00:00, 117362.50it/s]100%|██████████| 75824/75824 [00:00<00:00, 122884.08it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 12163/75824 [00:00<00:00, 121620.55it/s] 40%|███▉      | 29992/75824 [00:00<00:00, 134439.02it/s] 64%|██████▍   | 48749/75824 [00:00<00:00, 146922.22it/s] 83%|████████▎ | 63001/75824 [00:00<00:00, 140814.36it/s]100%|██████████| 75824/75824 [00:00<00:00, 151173.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16844/75824 [00:00<00:00, 168435.34it/s] 49%|████▊     | 36963/75824 [00:00<00:00, 177082.76it/s] 72%|███████▏  | 54594/75824 [00:00<00:00, 176849.38it/s] 97%|█████████▋| 73236/75824 [00:00<00:00, 179613.72it/s]100%|██████████| 75824/75824 [00:00<00:00, 176890.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16659/75824 [00:00<00:00, 166586.58it/s] 45%|████▌     | 34259/75824 [00:00<00:00, 169300.99it/s] 69%|██████▉   | 52148/75824 [00:00<00:00, 172065.43it/s] 93%|█████████▎| 70738/75824 [00:00<00:00, 175992.56it/s]100%|██████████| 75824/75824 [00:00<00:00, 177376.76it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18761/75824 [00:00<00:00, 187593.18it/s] 43%|████▎     | 32457/75824 [00:00<00:00, 168864.50it/s] 63%|██████▎   | 47769/75824 [00:00<00:00, 163809.52it/s] 83%|████████▎ | 62601/75824 [00:00<00:00, 158832.24it/s]100%|██████████| 75824/75824 [00:00<00:00, 156338.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|██▌       | 19546/75824 [00:00<00:00, 195452.26it/s] 52%|█████▏    | 39503/75824 [00:00<00:00, 196668.44it/s] 76%|███████▌  | 57512/75824 [00:00<00:00, 191379.60it/s] 93%|█████████▎| 70226/75824 [00:00<00:00, 166186.29it/s]100%|██████████| 75824/75824 [00:00<00:00, 175460.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16714/75824 [00:00<00:00, 167133.39it/s] 44%|████▍     | 33305/75824 [00:00<00:00, 166763.45it/s] 63%|██████▎   | 48018/75824 [00:00<00:00, 160341.33it/s] 87%|████████▋ | 65657/75824 [00:00<00:00, 164838.75it/s]100%|██████████| 75824/75824 [00:00<00:00, 165175.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|█▍        | 10819/75824 [00:00<00:00, 108185.20it/s] 20%|██        | 15429/75824 [00:00<00:00, 77053.09it/s]  36%|███▌      | 27014/75824 [00:00<00:00, 85658.67it/s] 55%|█████▌    | 41840/75824 [00:00<00:00, 98081.86it/s] 71%|███████   | 53994/75824 [00:00<00:00, 104110.03it/s] 84%|████████▍ | 63711/75824 [00:00<00:00, 85087.49it/s] 100%|██████████| 75824/75824 [00:00<00:00, 103772.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|█▊        | 14175/75824 [00:00<00:00, 141741.35it/s] 35%|███▌      | 26749/75824 [00:00<00:00, 136525.91it/s] 44%|████▍     | 33498/75824 [00:00<00:00, 87423.79it/s]  60%|██████    | 45755/75824 [00:00<00:00, 95650.67it/s] 73%|███████▎  | 55118/75824 [00:00<00:00, 94677.08it/s] 85%|████████▍ | 64328/75824 [00:00<00:00, 93888.76it/s] 99%|█████████▉| 74923/75824 [00:00<00:00, 94726.92it/s]100%|██████████| 75824/75824 [00:00<00:00, 98709.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|██        | 15165/75824 [00:00<00:00, 151649.42it/s] 36%|███▌      | 27465/75824 [00:00<00:00, 141744.00it/s] 58%|█████▊    | 44085/75824 [00:00<00:00, 148288.61it/s] 84%|████████▍ | 63857/75824 [00:00<00:00, 160310.65it/s]100%|██████████| 75824/75824 [00:00<00:00, 164192.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▌       | 18995/75824 [00:00<00:00, 189944.75it/s] 46%|████▌     | 34817/75824 [00:00<00:00, 179162.84it/s] 63%|██████▎   | 48022/75824 [00:00<00:00, 161838.19it/s] 84%|████████▍ | 64033/75824 [00:00<00:00, 161311.11it/s]100%|██████████| 75824/75824 [00:00<00:00, 143349.57it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|██▏       | 16875/75824 [00:00<00:00, 168740.91it/s] 46%|████▌     | 34532/75824 [00:00<00:00, 171013.79it/s] 72%|███████▏  | 54407/75824 [00:00<00:00, 178485.08it/s] 98%|█████████▊| 74528/75824 [00:00<00:00, 184743.26it/s]100%|██████████| 75824/75824 [00:00<00:00, 186670.86it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|██        | 15878/75824 [00:00<00:00, 158777.88it/s] 47%|████▋     | 35646/75824 [00:00<00:00, 168738.14it/s] 74%|███████▎  | 55849/75824 [00:00<00:00, 177512.42it/s]100%|█████████▉| 75457/75824 [00:00<00:00, 182702.23it/s]100%|██████████| 75824/75824 [00:00<00:00, 187810.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13667/75824 [00:00<00:00, 136666.22it/s] 36%|███▌      | 27328/75824 [00:00<00:00, 136647.24it/s] 53%|█████▎    | 40077/75824 [00:00<00:00, 133761.88it/s] 71%|███████   | 53517/75824 [00:00<00:00, 133952.05it/s] 94%|█████████▍| 71370/75824 [00:00<00:00, 144797.12it/s]100%|██████████| 75824/75824 [00:00<00:00, 144457.60it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17629/75824 [00:00<00:00, 176283.02it/s] 47%|████▋     | 35437/75824 [00:00<00:00, 176815.84it/s] 71%|███████   | 53464/75824 [00:00<00:00, 177835.65it/s] 91%|█████████ | 69106/75824 [00:00<00:00, 170815.03it/s]100%|██████████| 75824/75824 [00:00<00:00, 166520.79it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|██▎       | 17695/75824 [00:00<00:00, 176945.95it/s] 47%|████▋     | 35962/75824 [00:00<00:00, 178623.69it/s] 72%|███████▏  | 54311/75824 [00:00<00:00, 180053.66it/s] 96%|█████████▌| 72872/75824 [00:00<00:00, 181683.20it/s]100%|██████████| 75824/75824 [00:00<00:00, 182246.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18922/75824 [00:00<00:00, 189218.83it/s] 50%|████▉     | 37563/75824 [00:00<00:00, 188366.57it/s] 75%|███████▍  | 56793/75824 [00:00<00:00, 189529.25it/s] 91%|█████████▏| 69259/75824 [00:00<00:00, 143303.75it/s]100%|██████████| 75824/75824 [00:00<00:00, 146570.00it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 12179/75824 [00:00<00:00, 121783.15it/s] 34%|███▍      | 26135/75824 [00:00<00:00, 126621.25it/s] 56%|█████▌    | 42324/75824 [00:00<00:00, 135474.16it/s] 79%|███████▊  | 59638/75824 [00:00<00:00, 144931.15it/s]100%|██████████| 75824/75824 [00:00<00:00, 155254.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18126/75824 [00:00<00:00, 181251.96it/s] 48%|████▊     | 36268/75824 [00:00<00:00, 181302.13it/s] 64%|██████▍   | 48600/75824 [00:00<00:00, 158886.46it/s] 88%|████████▊ | 67093/75824 [00:00<00:00, 165893.25it/s]100%|██████████| 75824/75824 [00:00<00:00, 161162.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▌        | 11499/75824 [00:00<00:00, 114982.98it/s] 35%|███▌      | 26801/75824 [00:00<00:00, 124247.04it/s] 46%|████▌     | 34588/75824 [00:00<00:00, 99134.85it/s]  55%|█████▍    | 41513/75824 [00:00<00:00, 82594.35it/s] 73%|███████▎  | 55495/75824 [00:00<00:00, 94154.91it/s] 88%|████████▊ | 66970/75824 [00:00<00:00, 99512.87it/s]100%|██████████| 75824/75824 [00:00<00:00, 111821.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|▋         | 4875/75824 [00:00<00:01, 48746.10it/s] 24%|██▎       | 17982/75824 [00:00<00:00, 60063.48it/s] 49%|████▊     | 36919/75824 [00:00<00:00, 75536.69it/s] 61%|██████    | 46432/75824 [00:00<00:00, 78200.67it/s] 73%|███████▎  | 55394/75824 [00:00<00:00, 75496.85it/s] 94%|█████████▍| 71557/75824 [00:00<00:00, 89862.59it/s]100%|██████████| 75824/75824 [00:00<00:00, 109476.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|█▎        | 9537/75824 [00:00<00:00, 95364.63it/s] 24%|██▎       | 17848/75824 [00:00<00:00, 91324.24it/s] 45%|████▍     | 34110/75824 [00:00<00:00, 105153.91it/s] 70%|███████   | 53263/75824 [00:00<00:00, 121606.32it/s] 97%|█████████▋| 73173/75824 [00:00<00:00, 137682.36it/s]100%|██████████| 75824/75824 [00:00<00:00, 147484.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18061/75824 [00:00<00:00, 180597.69it/s] 32%|███▏      | 24540/75824 [00:00<00:00, 117555.00it/s] 59%|█████▉    | 44840/75824 [00:00<00:00, 134543.89it/s] 85%|████████▍ | 64412/75824 [00:00<00:00, 148465.35it/s]100%|██████████| 75824/75824 [00:00<00:00, 165514.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18145/75824 [00:00<00:00, 181448.44it/s] 48%|████▊     | 36542/75824 [00:00<00:00, 182195.22it/s] 73%|███████▎  | 55630/75824 [00:00<00:00, 184715.55it/s] 98%|█████████▊| 74424/75824 [00:00<00:00, 185669.95it/s]100%|██████████| 75824/75824 [00:00<00:00, 185348.27it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18734/75824 [00:00<00:00, 187337.50it/s] 49%|████▉     | 37037/75824 [00:00<00:00, 186021.73it/s] 69%|██████▉   | 52321/75824 [00:00<00:00, 174645.41it/s] 86%|████████▌ | 65107/75824 [00:00<00:00, 157369.98it/s]100%|██████████| 75824/75824 [00:00<00:00, 155530.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18861/75824 [00:00<00:00, 188607.03it/s] 51%|█████     | 38757/75824 [00:00<00:00, 191597.65it/s] 77%|███████▋  | 58448/75824 [00:00<00:00, 193160.12it/s]100%|██████████| 75824/75824 [00:00<00:00, 194459.21it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|█▊        | 13442/75824 [00:00<00:00, 134407.31it/s] 31%|███       | 23186/75824 [00:00<00:00, 120670.12it/s] 44%|████▍     | 33658/75824 [00:00<00:00, 115395.78it/s] 69%|██████▉   | 52175/75824 [00:00<00:00, 130101.94it/s] 94%|█████████▍| 71088/75824 [00:00<00:00, 143541.08it/s]100%|██████████| 75824/75824 [00:00<00:00, 144340.57it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|██▍       | 18727/75824 [00:00<00:00, 187267.95it/s] 50%|████▉     | 37828/75824 [00:00<00:00, 188374.33it/s] 66%|██████▌   | 50220/75824 [00:00<00:00, 162945.90it/s] 84%|████████▍ | 64059/75824 [00:00<00:00, 154708.93it/s]100%|█████████▉| 75548/75824 [00:00<00:00, 134125.37it/s]100%|██████████| 75824/75824 [00:00<00:00, 147531.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|▉         | 7162/75824 [00:00<00:00, 69352.47it/s] 21%|██        | 15700/75824 [00:00<00:00, 73490.49it/s] 34%|███▍      | 25770/75824 [00:00<00:00, 79972.64it/s] 47%|████▋     | 35497/75824 [00:00<00:00, 84479.25it/s] 56%|█████▋    | 42689/75824 [00:00<00:00, 80272.83it/s] 66%|██████▌   | 49748/75824 [00:00<00:00, 71143.31it/s] 75%|███████▌  | 56884/75824 [00:00<00:00, 70322.57it/s] 85%|████████▌ | 64780/75824 [00:00<00:00, 72707.13it/s]100%|██████████| 75824/75824 [00:00<00:00, 81563.55it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|█▏        | 9043/75824 [00:00<00:00, 81903.30it/s] 26%|██▌       | 19472/75824 [00:00<00:00, 87540.56it/s] 44%|████▎     | 33116/75824 [00:00<00:00, 98086.47it/s] 69%|██████▊   | 52108/75824 [00:00<00:00, 114728.68it/s] 91%|█████████ | 69051/75824 [00:00<00:00, 127031.14it/s]100%|██████████| 75824/75824 [00:00<00:00, 126631.19it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|█         | 8402/75824 [00:00<00:00, 84014.67it/s] 25%|██▌       | 18971/75824 [00:00<00:00, 89522.26it/s] 44%|████▎     | 33147/75824 [00:00<00:00, 100648.68it/s] 67%|██████▋   | 50662/75824 [00:00<00:00, 115370.63it/s] 91%|█████████ | 68789/75824 [00:00<00:00, 129493.05it/s]100%|██████████| 75824/75824 [00:00<00:00, 140779.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18457/75824 [00:00<00:00, 184566.22it/s] 51%|█████     | 38401/75824 [00:00<00:00, 188789.36it/s] 75%|███████▌  | 57201/75824 [00:00<00:00, 188550.96it/s]100%|██████████| 75824/75824 [00:00<00:00, 190492.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18456/75824 [00:00<00:00, 184550.50it/s] 49%|████▉     | 36999/75824 [00:00<00:00, 184813.39it/s] 73%|███████▎  | 55274/75824 [00:00<00:00, 184187.16it/s] 98%|█████████▊| 74165/75824 [00:00<00:00, 185578.69it/s]100%|██████████| 75824/75824 [00:00<00:00, 185344.82it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.026213407516479492 seconds.
Run epoch 1
Epoch 1 ends in 0.024939537048339844 seconds.
5416 sentences created
mode 1: time used = 0.048996686935424805
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '1.38627'}; time used = 2.8600571155548096s
epoch 10: {'train_loss': '1.38629'}; time used = 2.468999147415161s
epoch 15: {'train_loss': '1.38629'}; time used = 3.1054794788360596s
epoch 20: {'train_loss': '1.38629'}; time used = 2.1012778282165527s
epoch 25: {'train_loss': '1.38629'}; time used = 2.527881622314453s
epoch 30: {'train_loss': '1.38629'}; time used = 2.5783298015594482s
epoch 35: {'train_loss': '1.38629'}; time used = 2.831235408782959s
epoch 40: {'train_loss': '1.38629'}; time used = 3.0554184913635254s
epoch 45: {'train_loss': '1.38629'}; time used = 2.3044679164886475s
epoch 50: {'train_loss': '1.38629'}; time used = 3.100587844848633s
epoch 55: {'train_loss': '1.38629'}; time used = 1.9563486576080322s
epoch 60: {'train_loss': '1.38629'}; time used = 2.5023250579833984s
epoch 65: {'train_loss': '1.38629'}; time used = 2.4954190254211426s
epoch 70: {'train_loss': '1.38629'}; time used = 2.3894267082214355s
epoch 75: {'train_loss': '1.38629'}; time used = 2.8946802616119385s
epoch 80: {'train_loss': '1.38629'}; time used = 2.0586421489715576s
epoch 85: {'train_loss': '1.38629'}; time used = 3.2423007488250732s
epoch 90: {'train_loss': '1.38629'}; time used = 2.063220977783203s
epoch 95: {'train_loss': '1.38629'}; time used = 3.2375621795654297s
epoch 100: {'train_loss': '1.38629'}; time used = 2.740833044052124s
epoch 105: {'train_loss': '1.38629'}; time used = 3.5756051540374756s
epoch 110: {'train_loss': '1.38629'}; time used = 2.192539691925049s
epoch 115: {'train_loss': '1.38629'}; time used = 3.0056424140930176s
epoch 120: {'train_loss': '1.38629'}; time used = 1.9894964694976807s
epoch 125: {'train_loss': '1.38629'}; time used = 2.739333152770996s
epoch 130: {'train_loss': '1.38629'}; time used = 2.3175368309020996s
epoch 135: {'train_loss': '1.38629'}; time used = 2.4607791900634766s
epoch 140: {'train_loss': '1.38629'}; time used = 2.736867666244507s
epoch 145: {'train_loss': '1.38629'}; time used = 2.0570690631866455s
epoch 150: {'train_loss': '1.38629'}; time used = 3.094961643218994s
epoch 155: {'train_loss': '1.38629'}; time used = 2.0883607864379883s
epoch 160: {'train_loss': '1.38629'}; time used = 3.113947629928589s
epoch 165: {'train_loss': '1.38629'}; time used = 2.3097617626190186s
epoch 170: {'train_loss': '1.38629'}; time used = 2.5845866203308105s
epoch 175: {'train_loss': '1.38629'}; time used = 3.8434293270111084s
epoch 180: {'train_loss': '1.38629'}; time used = 2.414947986602783s
epoch 185: {'train_loss': '1.38629'}; time used = 3.5423061847686768s
epoch 190: {'train_loss': '1.38629'}; time used = 2.943183422088623s
epoch 195: {'train_loss': '1.38629'}; time used = 2.5693862438201904s
epoch 200: {'train_loss': '1.38629'}; time used = 2.9017271995544434s
epoch 205: {'train_loss': '1.38629'}; time used = 2.8961963653564453s
epoch 210: {'train_loss': '1.38629'}; time used = 2.323770761489868s
epoch 215: {'train_loss': '1.38629'}; time used = 3.1936163902282715s
epoch 220: {'train_loss': '1.38629'}; time used = 2.5252866744995117s
epoch 225: {'train_loss': '1.38629'}; time used = 3.272549629211426s
epoch 230: {'train_loss': '1.38629'}; time used = 2.4886717796325684s
epoch 235: {'train_loss': '1.38629'}; time used = 3.3863844871520996s
epoch 240: {'train_loss': '1.38629'}; time used = 2.4615414142608643s
epoch 245: {'train_loss': '1.38629'}; time used = 3.078975200653076s
epoch 250: {'train_loss': '1.38629'}; time used = 2.2949564456939697s
epoch 255: {'train_loss': '1.38629'}; time used = 3.0378665924072266s
epoch 260: {'train_loss': '1.38629'}; time used = 2.397684335708618s
epoch 265: {'train_loss': '1.38629'}; time used = 2.632066011428833s
epoch 270: {'train_loss': '1.38629'}; time used = 2.8407375812530518s
epoch 275: {'train_loss': '1.38629'}; time used = 3.4181571006774902s
epoch 280: {'train_loss': '1.38629'}; time used = 2.4730799198150635s
epoch 285: {'train_loss': '1.38629'}; time used = 2.9702813625335693s
epoch 290: {'train_loss': '1.38629'}; time used = 2.8617753982543945s
epoch 295: {'train_loss': '1.38629'}; time used = 3.0123322010040283s
epoch 300: {'train_loss': '1.38629'}; time used = 2.5286450386047363s
epoch 305: {'train_loss': '1.38629'}; time used = 3.174018621444702s
epoch 310: {'train_loss': '1.38629'}; time used = 2.289269208908081s
epoch 315: {'train_loss': '1.38629'}; time used = 2.6730899810791016s
epoch 320: {'train_loss': '1.38629'}; time used = 3.1252381801605225s
epoch 325: {'train_loss': '1.38629'}; time used = 2.9584949016571045s
epoch 330: {'train_loss': '1.38629'}; time used = 2.914332866668701s
epoch 335: {'train_loss': '1.38629'}; time used = 2.652989149093628s
epoch 340: {'train_loss': '1.38629'}; time used = 3.0213849544525146s
epoch 345: {'train_loss': '1.38629'}; time used = 2.448453903198242s
epoch 350: {'train_loss': '1.38629'}; time used = 2.9860680103302s
epoch 355: {'train_loss': '1.38629'}; time used = 2.425400972366333s
epoch 360: {'train_loss': '1.38629'}; time used = 3.4559481143951416s
epoch 365: {'train_loss': '1.38629'}; time used = 2.189774513244629s
epoch 370: {'train_loss': '1.38629'}; time used = 3.451101541519165s
epoch 375: {'train_loss': '1.38629'}; time used = 2.3269262313842773s
epoch 380: {'train_loss': '1.38629'}; time used = 2.8350465297698975s
epoch 385: {'train_loss': '1.38629'}; time used = 3.0665442943573s
epoch 390: {'train_loss': '1.38629'}; time used = 2.737091064453125s
epoch 395: {'train_loss': '1.38629'}; time used = 2.8334202766418457s
epoch 400: {'train_loss': '1.38629'}; time used = 2.688565969467163s
epoch 405: {'train_loss': '1.38629'}; time used = 3.2485005855560303s
epoch 410: {'train_loss': '1.38629'}; time used = 2.655745029449463s
epoch 415: {'train_loss': '1.38629'}; time used = 3.078242778778076s
epoch 420: {'train_loss': '1.38629'}; time used = 2.7764201164245605s
epoch 425: {'train_loss': '1.38629'}; time used = 3.294701337814331s
epoch 430: {'train_loss': '1.38629'}; time used = 2.516026020050049s
epoch 435: {'train_loss': '1.38629'}; time used = 3.040372610092163s
epoch 440: {'train_loss': '1.38629'}; time used = 2.3948910236358643s
epoch 445: {'train_loss': '1.38629'}; time used = 3.2258071899414062s
epoch 450: {'train_loss': '1.38629'}; time used = 2.8235435485839844s
epoch 455: {'train_loss': '1.38629'}; time used = 3.1452856063842773s
epoch 460: {'train_loss': '1.38629'}; time used = 2.3507866859436035s
epoch 465: {'train_loss': '1.38629'}; time used = 2.9576416015625s
epoch 470: {'train_loss': '1.38629'}; time used = 2.756920576095581s
epoch 475: {'train_loss': '1.38629'}; time used = 2.723666191101074s
epoch 480: {'train_loss': '1.38629'}; time used = 2.5865094661712646s
epoch 485: {'train_loss': '1.38629'}; time used = 2.974238395690918s
epoch 490: {'train_loss': '1.38629'}; time used = 2.5316805839538574s
epoch 495: {'train_loss': '1.38629'}; time used = 3.023836374282837s
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18442/75824 [00:00<00:00, 184413.58it/s] 49%|████▊     | 36895/75824 [00:00<00:00, 184447.36it/s] 72%|███████▏  | 54429/75824 [00:00<00:00, 181614.70it/s] 92%|█████████▏| 69627/75824 [00:00<00:00, 171576.12it/s]100%|██████████| 75824/75824 [00:00<00:00, 172247.45it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18176/75824 [00:00<00:00, 181756.71it/s] 47%|████▋     | 35543/75824 [00:00<00:00, 179250.25it/s] 64%|██████▎   | 48270/75824 [00:00<00:00, 159683.13it/s] 88%|████████▊ | 66562/75824 [00:00<00:00, 166009.03it/s]100%|██████████| 75824/75824 [00:00<00:00, 168505.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|█▌        | 11596/75824 [00:00<00:00, 115952.37it/s] 39%|███▊      | 29246/75824 [00:00<00:00, 129252.98it/s] 51%|█████     | 38577/75824 [00:00<00:00, 115863.40it/s] 62%|██████▏   | 46788/75824 [00:00<00:00, 96857.08it/s]  76%|███████▌  | 57584/75824 [00:00<00:00, 99940.03it/s] 94%|█████████▎| 70972/75824 [00:00<00:00, 108165.45it/s]100%|██████████| 75824/75824 [00:00<00:00, 116769.86it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|██▍       | 18201/75824 [00:00<00:00, 182002.80it/s] 48%|████▊     | 36399/75824 [00:00<00:00, 181995.23it/s] 73%|███████▎  | 55181/75824 [00:00<00:00, 183703.52it/s] 97%|█████████▋| 73857/75824 [00:00<00:00, 184607.48it/s]100%|██████████| 75824/75824 [00:00<00:00, 184415.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|█▌        | 12056/75824 [00:00<00:00, 120554.94it/s] 41%|████      | 30806/75824 [00:00<00:00, 135016.77it/s] 66%|██████▌   | 49829/75824 [00:00<00:00, 147893.73it/s] 91%|█████████ | 68751/75824 [00:00<00:00, 158262.01it/s]100%|██████████| 75824/75824 [00:00<00:00, 166829.50it/s]

epoch 500: {'train_loss': '1.38629'}; time used = 2.494006633758545s
Finished training. Time used = 284.38466358184814.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.21815'}; time used = 0.049127817153930664s
epoch 10: {'train_loss': '0.87742'}; time used = 0.03745317459106445s
epoch 15: {'train_loss': '0.73846'}; time used = 0.034902334213256836s
epoch 20: {'train_loss': '0.51809'}; time used = 0.030905961990356445s
epoch 25: {'train_loss': '0.40898'}; time used = 0.03038477897644043s
epoch 30: {'train_loss': '0.34974'}; time used = 0.03136920928955078s
epoch 35: {'train_loss': '0.31583'}; time used = 0.03142714500427246s
epoch 40: {'train_loss': '0.40443'}; time used = 0.03064250946044922s
epoch 45: {'train_loss': '0.32866'}; time used = 0.030644893646240234s
epoch 50: {'train_loss': '0.29368'}; time used = 0.030549049377441406s
epoch 55: {'train_loss': '0.24103'}; time used = 0.03131580352783203s
epoch 60: {'train_loss': '0.20020'}; time used = 0.030634164810180664s
epoch 65: {'train_loss': '0.18293'}; time used = 0.030830860137939453s
epoch 70: {'train_loss': '0.16066'}; time used = 0.02995920181274414s
epoch 75: {'train_loss': '0.14148'}; time used = 0.031075716018676758s
epoch 80: {'train_loss': '0.13243'}; time used = 0.029322147369384766s
epoch 85: {'train_loss': '0.13909'}; time used = 0.02844548225402832s
epoch 90: {'train_loss': '0.11914'}; time used = 0.029227495193481445s
epoch 95: {'train_loss': '0.12084'}; time used = 0.02987504005432129s
epoch 100: {'train_loss': '0.13076'}; time used = 0.029837369918823242s
epoch 105: {'train_loss': '0.13619'}; time used = 0.03131413459777832s
epoch 110: {'train_loss': '0.12738'}; time used = 0.026585817337036133s
epoch 115: {'train_loss': '0.11929'}; time used = 0.02686333656311035s
epoch 120: {'train_loss': '0.10409'}; time used = 0.026951074600219727s
epoch 125: {'train_loss': '0.10162'}; time used = 0.02525019645690918s
epoch 130: {'train_loss': '0.09881'}; time used = 0.024486303329467773s
epoch 135: {'train_loss': '0.08345'}; time used = 0.03000497817993164s
epoch 140: {'train_loss': '0.09741'}; time used = 0.03032231330871582s
epoch 145: {'train_loss': '0.09556'}; time used = 0.02437448501586914s
epoch 150: {'train_loss': '0.09479'}; time used = 0.05714249610900879s
epoch 155: {'train_loss': '0.09780'}; time used = 0.024276018142700195s
epoch 160: {'train_loss': '0.09371'}; time used = 0.025652647018432617s
epoch 165: {'train_loss': '0.12155'}; time used = 0.02469801902770996s
epoch 170: {'train_loss': '0.09228'}; time used = 0.023925065994262695s
epoch 175: {'train_loss': '0.10644'}; time used = 0.025902986526489258s
epoch 180: {'train_loss': '0.08721'}; time used = 0.026435375213623047s
epoch 185: {'train_loss': '0.08746'}; time used = 0.024045705795288086s
epoch 190: {'train_loss': '0.08892'}; time used = 0.024007081985473633s
epoch 195: {'train_loss': '0.07076'}; time used = 0.023554325103759766s
epoch 200: {'train_loss': '0.07711'}; time used = 0.022447824478149414s
epoch 205: {'train_loss': '0.07811'}; time used = 0.028513669967651367s
epoch 210: {'train_loss': '0.07195'}; time used = 0.03594255447387695s
epoch 215: {'train_loss': '0.08796'}; time used = 0.023182392120361328s
epoch 220: {'train_loss': '0.07332'}; time used = 0.0231778621673584s
epoch 225: {'train_loss': '0.07418'}; time used = 0.03042912483215332s
epoch 230: {'train_loss': '0.08004'}; time used = 0.027632713317871094s
epoch 235: {'train_loss': '0.07775'}; time used = 0.028867244720458984s
epoch 240: {'train_loss': '0.07876'}; time used = 0.029883384704589844s
epoch 245: {'train_loss': '0.07883'}; time used = 0.029082536697387695s
epoch 250: {'train_loss': '0.16394'}; time used = 0.030409574508666992s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 5.487574338912964.
Training classifier using 20.00% nodes...
{'micro': 0.7494231656668204, 'macro': 0.7206045503600672, 'samples': 0.7494231656668204, 'weighted': 0.7443574646916957}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 58, in _forward
    hx = layer(hx)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/layers/linear.py", line 46, in forward
    pre_sup = torch.mm(x, self.weight)
RuntimeError: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 222, in forward
    self.to(self._device)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 607, in to
    return self._apply(convert)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 376, in _apply
    param_applied = fn(param)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 605, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.76 GiB total capacity; 14.80 MiB already allocated; 12.44 MiB free; 16.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.38668'}; time used = 0.04643654823303223s
epoch 10: {'train_loss': '1.38661'}; time used = 0.034479618072509766s
epoch 15: {'train_loss': '1.37388'}; time used = 0.029663801193237305s
epoch 20: {'train_loss': '1.35686'}; time used = 0.03011345863342285s
epoch 25: {'train_loss': '1.33742'}; time used = 0.029550552368164062s
epoch 30: {'train_loss': '1.32527'}; time used = 0.030228614807128906s
epoch 35: {'train_loss': '1.31815'}; time used = 0.03397703170776367s
epoch 40: {'train_loss': '1.30868'}; time used = 0.04278850555419922s
epoch 45: {'train_loss': '1.30609'}; time used = 0.04203009605407715s
epoch 50: {'train_loss': '1.29416'}; time used = 0.040578603744506836s
epoch 55: {'train_loss': '1.28938'}; time used = 0.0413355827331543s
epoch 60: {'train_loss': '1.28510'}; time used = 0.03831338882446289s
epoch 65: {'train_loss': '1.28442'}; time used = 0.04123067855834961s
epoch 70: {'train_loss': '1.28258'}; time used = 0.0351560115814209s
epoch 75: {'train_loss': '1.26576'}; time used = 0.035756587982177734s
epoch 80: {'train_loss': '1.23082'}; time used = 0.0398564338684082s
epoch 85: {'train_loss': '1.17780'}; time used = 0.04118037223815918s
epoch 90: {'train_loss': '1.16381'}; time used = 0.0339360237121582s
epoch 95: {'train_loss': '1.12494'}; time used = 0.03780531883239746s
epoch 100: {'train_loss': '1.10319'}; time used = 0.03560924530029297s
epoch 105: {'train_loss': '1.08010'}; time used = 0.03286314010620117s
epoch 110: {'train_loss': '1.06154'}; time used = 0.04741215705871582s
epoch 115: {'train_loss': '1.06650'}; time used = 0.03142523765563965s
epoch 120: {'train_loss': '1.05453'}; time used = 0.036661624908447266s
epoch 125: {'train_loss': '1.03846'}; time used = 0.03526568412780762s
epoch 130: {'train_loss': '1.02468'}; time used = 0.03835105895996094s
epoch 135: {'train_loss': '1.02519'}; time used = 0.0403141975402832s
epoch 140: {'train_loss': '1.09729'}; time used = 0.04288005828857422s
epoch 145: {'train_loss': '1.04969'}; time used = 0.04201507568359375s
epoch 150: {'train_loss': '1.01548'}; time used = 0.0355076789855957s
epoch 155: {'train_loss': '1.01637'}; time used = 0.03909754753112793s
epoch 160: {'train_loss': '1.03018'}; time used = 0.03552865982055664s
epoch 165: {'train_loss': '1.00307'}; time used = 0.0369417667388916s
epoch 170: {'train_loss': '0.99356'}; time used = 0.028185129165649414s
epoch 175: {'train_loss': '1.13397'}; time used = 0.04294848442077637s
epoch 180: {'train_loss': '1.10788'}; time used = 0.025825977325439453s
epoch 185: {'train_loss': '1.05830'}; time used = 0.027844667434692383s
epoch 190: {'train_loss': '1.02689'}; time used = 0.031975507736206055s
epoch 195: {'train_loss': '1.05811'}; time used = 0.032334089279174805s
epoch 200: {'train_loss': '1.00124'}; time used = 0.0336606502532959s
epoch 205: {'train_loss': '0.98736'}; time used = 0.03233957290649414s
epoch 210: {'train_loss': '0.97889'}; time used = 0.03346133232116699s
epoch 215: {'train_loss': '0.95083'}; time used = 0.03448653221130371s
epoch 220: {'train_loss': '0.93722'}; time used = 0.030089855194091797s
epoch 225: {'train_loss': '0.92047'}; time used = 0.03003835678100586s
epoch 230: {'train_loss': '0.92070'}; time used = 0.03054523468017578s
epoch 235: {'train_loss': '0.95712'}; time used = 0.0345759391784668s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 5.451154470443726.
Training classifier using 20.00% nodes...
{'micro': 0.3913244116289802, 'macro': 0.19521067750711826, 'samples': 0.3913244116289802, 'weighted': 0.27657485316552205}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.38576'}; time used = 0.05370664596557617s
epoch 10: {'train_loss': '1.24877'}; time used = 0.060376644134521484s
epoch 15: {'train_loss': '1.01004'}; time used = 0.04078817367553711s
epoch 20: {'train_loss': '0.82550'}; time used = 0.039194583892822266s
epoch 25: {'train_loss': '0.83632'}; time used = 0.03802204132080078s
epoch 30: {'train_loss': '0.62399'}; time used = 0.03554701805114746s
epoch 35: {'train_loss': '0.54930'}; time used = 0.033867597579956055s
epoch 40: {'train_loss': '0.51758'}; time used = 0.035520315170288086s
epoch 45: {'train_loss': '0.55363'}; time used = 0.03901505470275879s
epoch 50: {'train_loss': '0.48531'}; time used = 0.034000396728515625s
epoch 55: {'train_loss': '0.45206'}; time used = 0.034658193588256836s
epoch 60: {'train_loss': '0.40514'}; time used = 0.03484344482421875s
epoch 65: {'train_loss': '0.36388'}; time used = 0.042200565338134766s
epoch 70: {'train_loss': '0.33472'}; time used = 0.03355693817138672s
epoch 75: {'train_loss': '0.52561'}; time used = 0.031552791595458984s
epoch 80: {'train_loss': '0.45073'}; time used = 0.03350567817687988s
epoch 85: {'train_loss': '0.44127'}; time used = 0.03302502632141113s
epoch 90: {'train_loss': '0.38345'}; time used = 0.032259464263916016s
epoch 95: {'train_loss': '0.36446'}; time used = 0.03331398963928223s
epoch 100: {'train_loss': '0.36962'}; time used = 0.03085017204284668s
epoch 105: {'train_loss': '0.31473'}; time used = 0.03383016586303711s
epoch 110: {'train_loss': '0.29121'}; time used = 0.029840946197509766s
epoch 115: {'train_loss': '0.28343'}; time used = 0.03450632095336914s
epoch 120: {'train_loss': '0.27805'}; time used = 0.03625774383544922s
epoch 125: {'train_loss': '0.32415'}; time used = 0.029644250869750977s
epoch 130: {'train_loss': '0.31111'}; time used = 0.02835679054260254s
epoch 135: {'train_loss': '0.41904'}; time used = 0.02974390983581543s
epoch 140: {'train_loss': '0.36404'}; time used = 0.03377246856689453s
epoch 145: {'train_loss': '0.31817'}; time used = 0.02897953987121582s
epoch 150: {'train_loss': '0.26610'}; time used = 0.02890491485595703s
epoch 155: {'train_loss': '0.27529'}; time used = 0.030712604522705078s
epoch 160: {'train_loss': '0.24866'}; time used = 0.029222965240478516s
epoch 165: {'train_loss': '0.25190'}; time used = 0.027189254760742188s
epoch 170: {'train_loss': '0.22646'}; time used = 0.027755022048950195s
epoch 175: {'train_loss': '0.21570'}; time used = 0.029197216033935547s
epoch 180: {'train_loss': '0.21214'}; time used = 0.027831315994262695s
epoch 185: {'train_loss': '0.20638'}; time used = 0.04005002975463867s
epoch 190: {'train_loss': '0.23139'}; time used = 0.03169393539428711s
epoch 195: {'train_loss': '0.24397'}; time used = 0.034368038177490234s
epoch 200: {'train_loss': '0.31445'}; time used = 0.037827253341674805s
epoch 205: {'train_loss': '0.41064'}; time used = 0.033936262130737305s
epoch 210: {'train_loss': '0.36131'}; time used = 0.025135040283203125s
epoch 215: {'train_loss': '0.28712'}; time used = 0.03212881088256836s
epoch 220: {'train_loss': '0.26412'}; time used = 0.026772737503051758s
epoch 225: {'train_loss': '0.22833'}; time used = 0.026582717895507812s
epoch 230: {'train_loss': '0.20502'}; time used = 0.02659296989440918s
epoch 235: {'train_loss': '0.20788'}; time used = 0.029534578323364258s
epoch 240: {'train_loss': '0.21700'}; time used = 0.045269012451171875s
epoch 245: {'train_loss': '0.23660'}; time used = 0.05551314353942871s
epoch 250: {'train_loss': '0.25132'}; time used = 0.025806427001953125s
epoch 255: {'train_loss': '0.23185'}; time used = 0.03705286979675293s
epoch 260: {'train_loss': '0.20308'}; time used = 0.04909324645996094s
epoch 265: {'train_loss': '0.20035'}; time used = 0.03094625473022461s
epoch 270: {'train_loss': '0.19692'}; time used = 0.027638673782348633s
epoch 275: {'train_loss': '0.20850'}; time used = 0.03278088569641113s
epoch 280: {'train_loss': '0.30781'}; time used = 0.05918288230895996s
epoch 285: {'train_loss': '0.37645'}; time used = 0.04442620277404785s
epoch 290: {'train_loss': '0.35085'}; time used = 0.029451608657836914s
epoch 295: {'train_loss': '0.30838'}; time used = 0.030027389526367188s
epoch 300: {'train_loss': '0.25273'}; time used = 0.029787540435791016s
epoch 305: {'train_loss': '0.22819'}; time used = 0.030590534210205078s
epoch 310: {'train_loss': '0.21115'}; time used = 0.02903580665588379s
epoch 315: {'train_loss': '0.21339'}; time used = 0.024732589721679688s
epoch 320: {'train_loss': '0.24926'}; time used = 0.025562047958374023s
epoch 325: {'train_loss': '0.34588'}; time used = 0.0260770320892334s
epoch 330: {'train_loss': '0.35129'}; time used = 0.027647733688354492s
epoch 335: {'train_loss': '0.31056'}; time used = 0.02979588508605957s
epoch 340: {'train_loss': '0.25444'}; time used = 0.033323049545288086s
epoch 345: {'train_loss': '0.22822'}; time used = 0.028550386428833008s
epoch 350: {'train_loss': '0.20851'}; time used = 0.03247714042663574s
epoch 355: {'train_loss': '0.19212'}; time used = 0.04436540603637695s
epoch 360: {'train_loss': '0.20272'}; time used = 0.03333330154418945s
epoch 365: {'train_loss': '0.18502'}; time used = 0.03281569480895996s
epoch 370: {'train_loss': '0.29559'}; time used = 0.03268313407897949s
epoch 375: {'train_loss': '0.21934'}; time used = 0.03285980224609375s
epoch 380: {'train_loss': '0.19734'}; time used = 0.032213687896728516s
epoch 385: {'train_loss': '0.19561'}; time used = 0.03318166732788086s
epoch 390: {'train_loss': '0.17750'}; time used = 0.03852558135986328s
epoch 395: {'train_loss': '0.17412'}; time used = 0.03209996223449707s
epoch 400: {'train_loss': '0.17733'}; time used = 0.0335392951965332s
epoch 405: {'train_loss': '0.15852'}; time used = 0.03298354148864746s
epoch 410: {'train_loss': '0.15946'}; time used = 0.049604177474975586s
epoch 415: {'train_loss': '0.15558'}; time used = 0.03755307197570801s
epoch 420: {'train_loss': '0.16305'}; time used = 0.031783342361450195s
epoch 425: {'train_loss': '0.17180'}; time used = 0.029877424240112305s
epoch 430: {'train_loss': '0.17678'}; time used = 0.03446245193481445s
epoch 435: {'train_loss': '0.21131'}; time used = 0.03346681594848633s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 6.715673446655273.
Training classifier using 20.00% nodes...
{'micro': 0.7023534840793724, 'macro': 0.6883885010082098, 'samples': 0.7023534840793724, 'weighted': 0.6981735868626483}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.38716'}; time used = 0.04716181755065918s
epoch 10: {'train_loss': '1.38699'}; time used = 0.05371427536010742s
epoch 15: {'train_loss': '1.38384'}; time used = 0.03779172897338867s
epoch 20: {'train_loss': '1.36706'}; time used = 0.0398101806640625s
epoch 25: {'train_loss': '1.37144'}; time used = 0.0498204231262207s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 4.025713920593262.
Training classifier using 20.00% nodes...
{'micro': 0.30733733271804337, 'macro': 0.11861091575033715, 'samples': 0.30733733271804337, 'weighted': 0.18315093863961382}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 83, in forward
    self.full_embeddings = _forward(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 55, in _forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 43, in embed
    return self.features[x]
RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 10.76 GiB total capacity; 16.03 MiB already allocated; 14.44 MiB free; 18.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '3.49291'}; time used = 0.0704038143157959s
epoch 10: {'train_loss': '1.38640'}; time used = 0.0566248893737793s
epoch 15: {'train_loss': '1.38631'}; time used = 0.058472633361816406s
epoch 20: {'train_loss': '1.38629'}; time used = 0.05884575843811035s
epoch 25: {'train_loss': '1.38630'}; time used = 0.06269693374633789s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 4.047616481781006.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 660.00 MiB (GPU 0; 10.76 GiB total capacity; 56.95 MiB already allocated; 401.44 MiB free; 74.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f69a4bba1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f69a4e1064b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f69a4e11464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f69a4e11aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f6743d8290e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f67421bc949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f67421d6777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f677cf72c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f677cf72f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f677d07da1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f677cd0d4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f677cd0f166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f677cd0f65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f677cd0f80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f677ca4ceb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f67421abb40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f677c8df530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f677d0c781c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f677d01882b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f677cb4f952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f677cb50f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f677d1248c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f677d14e08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f677d075337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f677ec83205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f677d14e08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f677d075337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f677ebe2f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f677f1febb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f677f1fa400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f677f1fafa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f677f1f3119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f69a596c4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f69a6ac86df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f69aab236db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f69aae5c71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.38634'}; time used = 0.16898417472839355s
epoch 10: {'train_loss': '1.37943'}; time used = 0.059058189392089844s
epoch 15: {'train_loss': '1.38736'}; time used = 0.05261659622192383s
epoch 20: {'train_loss': '1.37566'}; time used = 0.053652048110961914s
epoch 25: {'train_loss': '1.30542'}; time used = 0.0798349380493164s
epoch 30: {'train_loss': '1.30741'}; time used = 0.15403509140014648s
epoch 35: {'train_loss': '1.20284'}; time used = 0.12756705284118652s
epoch 40: {'train_loss': '1.18198'}; time used = 0.09798717498779297s
epoch 45: {'train_loss': '1.20757'}; time used = 0.0816202163696289s
epoch 50: {'train_loss': '1.11710'}; time used = 0.05738425254821777s
epoch 55: {'train_loss': '1.06472'}; time used = 0.06455802917480469s
epoch 60: {'train_loss': '1.04512'}; time used = 0.06447339057922363s
epoch 65: {'train_loss': '1.01886'}; time used = 0.06475567817687988s
epoch 70: {'train_loss': '1.00108'}; time used = 0.05321168899536133s
epoch 75: {'train_loss': '0.98806'}; time used = 0.04958319664001465s
epoch 80: {'train_loss': '1.02257'}; time used = 0.04768538475036621s
epoch 85: {'train_loss': '1.06880'}; time used = 0.04865097999572754s
epoch 90: {'train_loss': '1.05416'}; time used = 0.05117487907409668s
epoch 95: {'train_loss': '1.01578'}; time used = 0.05939626693725586s
epoch 100: {'train_loss': '0.99641'}; time used = 0.04827141761779785s
epoch 105: {'train_loss': '0.96484'}; time used = 0.05115461349487305s
epoch 110: {'train_loss': '0.95753'}; time used = 0.04875493049621582s
epoch 115: {'train_loss': '0.93940'}; time used = 0.04831576347351074s
epoch 120: {'train_loss': '0.93144'}; time used = 0.0593416690826416s
epoch 125: {'train_loss': '0.91800'}; time used = 0.04983186721801758s
epoch 130: {'train_loss': '0.91190'}; time used = 0.0619966983795166s
epoch 135: {'train_loss': '0.92094'}; time used = 0.05966043472290039s
epoch 140: {'train_loss': '0.91251'}; time used = 0.059038400650024414s
epoch 145: {'train_loss': '0.92786'}; time used = 0.047971248626708984s
epoch 150: {'train_loss': '0.92046'}; time used = 0.05533313751220703s
epoch 155: {'train_loss': '0.88828'}; time used = 0.10431838035583496s
epoch 160: {'train_loss': '0.89606'}; time used = 0.11852884292602539s
epoch 165: {'train_loss': '0.88125'}; time used = 0.08467340469360352s
epoch 170: {'train_loss': '0.86867'}; time used = 0.05516314506530762s
epoch 175: {'train_loss': '0.87826'}; time used = 0.05374288558959961s
epoch 180: {'train_loss': '0.91450'}; time used = 0.04810380935668945s
epoch 185: {'train_loss': '0.88914'}; time used = 0.06869769096374512s
epoch 190: {'train_loss': '0.86436'}; time used = 0.06301140785217285s
epoch 195: {'train_loss': '0.86499'}; time used = 0.05986213684082031s
epoch 200: {'train_loss': '0.86630'}; time used = 0.08983635902404785s
epoch 205: {'train_loss': '0.85943'}; time used = 0.05264449119567871s
epoch 210: {'train_loss': '0.84828'}; time used = 0.07878375053405762s
epoch 215: {'train_loss': '0.84553'}; time used = 0.06408858299255371s
epoch 220: {'train_loss': '0.84283'}; time used = 0.07938671112060547s
epoch 225: {'train_loss': '0.83071'}; time used = 0.05953025817871094s
epoch 230: {'train_loss': '0.86996'}; time used = 0.04858994483947754s
epoch 235: {'train_loss': '0.81984'}; time used = 0.059659719467163086s
epoch 240: {'train_loss': '0.80984'}; time used = 0.11540865898132324s
epoch 245: {'train_loss': '0.79172'}; time used = 0.09807896614074707s
epoch 250: {'train_loss': '0.99909'}; time used = 0.09563589096069336s
epoch 255: {'train_loss': '0.92126'}; time used = 0.04806160926818848s
epoch 260: {'train_loss': '0.86673'}; time used = 0.06768965721130371s
epoch 265: {'train_loss': '0.84488'}; time used = 0.06588506698608398s
epoch 270: {'train_loss': '0.80113'}; time used = 0.07588410377502441s
epoch 275: {'train_loss': '0.78517'}; time used = 0.04754996299743652s
epoch 280: {'train_loss': '0.77846'}; time used = 0.053845882415771484s
epoch 285: {'train_loss': '0.78346'}; time used = 0.06954097747802734s
epoch 290: {'train_loss': '0.88051'}; time used = 0.07213044166564941s
epoch 295: {'train_loss': '0.83985'}; time used = 0.06107950210571289s
epoch 300: {'train_loss': '0.80446'}; time used = 0.06862735748291016s
epoch 305: {'train_loss': '0.76827'}; time used = 0.047926902770996094s
epoch 310: {'train_loss': '0.75098'}; time used = 0.05767178535461426s
epoch 315: {'train_loss': '0.73165'}; time used = 0.06258177757263184s
epoch 320: {'train_loss': '0.76250'}; time used = 0.05783820152282715s
epoch 325: {'train_loss': '0.78058'}; time used = 0.04990243911743164s
epoch 330: {'train_loss': '0.74066'}; time used = 0.07360053062438965s
epoch 335: {'train_loss': '0.72596'}; time used = 0.05283164978027344s
epoch 340: {'train_loss': '0.70907'}; time used = 0.04620099067687988s
epoch 345: {'train_loss': '0.69197'}; time used = 0.046087026596069336s
epoch 350: {'train_loss': '0.75742'}; time used = 0.050744056701660156s
epoch 355: {'train_loss': '0.79494'}; time used = 0.07315659523010254s
epoch 360: {'train_loss': '0.77448'}; time used = 0.062406063079833984s
epoch 365: {'train_loss': '0.72462'}; time used = 0.09141063690185547s
epoch 370: {'train_loss': '0.70846'}; time used = 0.06571245193481445s
epoch 375: {'train_loss': '0.69376'}; time used = 0.06655049324035645s
epoch 380: {'train_loss': '0.66094'}; time used = 0.0485994815826416s
epoch 385: {'train_loss': '0.69501'}; time used = 0.04900026321411133s
epoch 390: {'train_loss': '0.67642'}; time used = 0.04777407646179199s
epoch 395: {'train_loss': '0.65659'}; time used = 0.04766511917114258s
epoch 400: {'train_loss': '0.66624'}; time used = 0.04699826240539551s
epoch 405: {'train_loss': '0.63065'}; time used = 0.06158161163330078s
epoch 410: {'train_loss': '0.62602'}; time used = 0.04894685745239258s
epoch 415: {'train_loss': '0.64759'}; time used = 0.0621185302734375s
epoch 420: {'train_loss': '0.63862'}; time used = 0.04784727096557617s
epoch 425: {'train_loss': '0.62685'}; time used = 0.04829740524291992s
epoch 430: {'train_loss': '0.61444'}; time used = 0.048879146575927734s
epoch 435: {'train_loss': '0.60686'}; time used = 0.07440710067749023s
epoch 440: {'train_loss': '0.59811'}; time used = 0.04899859428405762s
epoch 445: {'train_loss': '0.61077'}; time used = 0.04753255844116211s
epoch 450: {'train_loss': '0.60780'}; time used = 0.04719376564025879s
epoch 455: {'train_loss': '0.59606'}; time used = 0.0588231086730957s
epoch 460: {'train_loss': '0.64347'}; time used = 0.08735823631286621s
epoch 465: {'train_loss': '0.63638'}; time used = 0.058954477310180664s
epoch 470: {'train_loss': '0.66347'}; time used = 0.04885411262512207s
epoch 475: {'train_loss': '0.62062'}; time used = 0.0848689079284668s
epoch 480: {'train_loss': '0.61008'}; time used = 0.07314157485961914s
epoch 485: {'train_loss': '0.59270'}; time used = 0.07781219482421875s
epoch 490: {'train_loss': '0.56921'}; time used = 0.06060314178466797s
epoch 495: {'train_loss': '0.59948'}; time used = 0.06954503059387207s
epoch 500: {'train_loss': '0.58885'}; time used = 0.05922412872314453s
Finished training. Time used = 12.182782173156738.
Training classifier using 20.00% nodes...
{'micro': 0.43147208121827413, 'macro': 0.24202817439022858, 'samples': 0.43147208121827413, 'weighted': 0.30464976255177006}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.38630'}; time used = 0.10000038146972656s
epoch 10: {'train_loss': '1.38550'}; time used = 0.08163619041442871s
epoch 15: {'train_loss': '1.38200'}; time used = 0.11188197135925293s
epoch 20: {'train_loss': '1.36911'}; time used = 0.09072470664978027s
epoch 25: {'train_loss': '1.35575'}; time used = 0.08890080451965332s
epoch 30: {'train_loss': '1.32353'}; time used = 0.09659361839294434s
epoch 35: {'train_loss': '1.28915'}; time used = 0.09090924263000488s
epoch 40: {'train_loss': '1.25313'}; time used = 0.09453153610229492s
epoch 45: {'train_loss': '1.21044'}; time used = 0.08736801147460938s
epoch 50: {'train_loss': '1.18497'}; time used = 0.07853126525878906s
epoch 55: {'train_loss': '1.14879'}; time used = 0.0881657600402832s
epoch 60: {'train_loss': '1.17616'}; time used = 0.10182452201843262s
epoch 65: {'train_loss': '1.16527'}; time used = 0.07214117050170898s
epoch 70: {'train_loss': '1.12721'}; time used = 0.0769500732421875s
epoch 75: {'train_loss': '1.09492'}; time used = 0.07270216941833496s
epoch 80: {'train_loss': '1.08509'}; time used = 0.09070062637329102s
epoch 85: {'train_loss': '1.06554'}; time used = 0.0736076831817627s
epoch 90: {'train_loss': '1.06767'}; time used = 0.06883859634399414s
epoch 95: {'train_loss': '1.24077'}; time used = 0.0833282470703125s
epoch 100: {'train_loss': '1.14092'}; time used = 0.06893086433410645s
epoch 105: {'train_loss': '1.07656'}; time used = 0.08416581153869629s
epoch 110: {'train_loss': '1.07553'}; time used = 0.06752586364746094s
epoch 115: {'train_loss': '1.07360'}; time used = 0.08972883224487305s
epoch 120: {'train_loss': '1.04279'}; time used = 0.07755613327026367s
epoch 125: {'train_loss': '1.03194'}; time used = 0.08978676795959473s
epoch 130: {'train_loss': '1.02590'}; time used = 0.08581686019897461s
epoch 135: {'train_loss': '1.01955'}; time used = 0.06816339492797852s
epoch 140: {'train_loss': '1.03200'}; time used = 0.08676958084106445s
epoch 145: {'train_loss': '1.01822'}; time used = 0.07451963424682617s
epoch 150: {'train_loss': '1.01972'}; time used = 0.08600544929504395s
epoch 155: {'train_loss': '1.01864'}; time used = 0.07786417007446289s
epoch 160: {'train_loss': '1.10680'}; time used = 0.10011768341064453s
epoch 165: {'train_loss': '1.02988'}; time used = 0.08253979682922363s
epoch 170: {'train_loss': '1.02859'}; time used = 0.08978629112243652s
epoch 175: {'train_loss': '1.01477'}; time used = 0.08768367767333984s
epoch 180: {'train_loss': '1.00367'}; time used = 0.10096120834350586s
epoch 185: {'train_loss': '0.99627'}; time used = 0.09682917594909668s
epoch 190: {'train_loss': '0.99384'}; time used = 0.09332013130187988s
epoch 195: {'train_loss': '0.98275'}; time used = 0.10858440399169922s
epoch 200: {'train_loss': '1.03130'}; time used = 0.0855250358581543s
epoch 205: {'train_loss': '0.98361'}; time used = 0.08862471580505371s
epoch 210: {'train_loss': '1.00899'}; time used = 0.07982063293457031s
epoch 215: {'train_loss': '0.97679'}; time used = 0.10014557838439941s
epoch 220: {'train_loss': '0.97556'}; time used = 0.08045339584350586s
epoch 225: {'train_loss': '1.34350'}; time used = 0.10290956497192383s
epoch 230: {'train_loss': '1.13191'}; time used = 0.07747077941894531s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.819705247879028.
Training classifier using 20.00% nodes...
{'micro': 0.2930318412551915, 'macro': 0.06960522347388527, 'samples': 0.2930318412551915, 'weighted': 0.13946548944120768}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 0; 10.76 GiB total capacity; 89.65 MiB already allocated; 793.44 MiB free; 106.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f923cad91e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f923cd2f64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f923cd30464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f923cd30aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f8febe6290e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f8fea29c949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f8fea2b6777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f9204403c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f9204403f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f920450ea1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f920419e4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f92041a0166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f92041a065d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f92041a080a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f9203eddeb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f8fea28bb40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f9203d70530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f920455881c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f92044a982b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f9203fe0952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f9203fe1f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f92045b58c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f92045df08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f9204506337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f9206114205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f92045df08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f9204506337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f9206073f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f920668fbb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f920668b400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f920668bfa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f9206684119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f923d88b4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f923e9e76df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f9242a426db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f9242d7b71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 10.31 GiB (GPU 0; 10.76 GiB total capacity; 128.00 MiB already allocated; 94.44 MiB free; 148.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f458c3641e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f458c5ba64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f458c5bb464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f458c5bbaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f434b8ae90e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f4349ce8949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f4349d02777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f458d8b6c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f458d8b6f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f458d9c1a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f458d6514f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f458d653166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f458d65365d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f458d65380a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f458d390eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f4349cd7b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f458d223530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f458da0b81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f458d95c82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f458d493952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f458d494f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f458da688c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f458da9208b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f458d9b9337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f458f5c7205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f458da9208b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f458d9b9337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f458f526f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f458fb42bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f458fb3e400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f458fb3efa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f458fb37119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f459d2d74ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f459e4336df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f45a248e6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f45a27c771f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 10.76 GiB total capacity; 0 bytes already allocated; 9.44 MiB free; 0 bytes reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189732.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206883.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207258.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168791.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168492.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169096.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168270.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171420.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217689.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204235.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198238.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200985.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199315.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151896.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108893.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221884.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6005/10556 [00:00<00:00, 60047.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 76592.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▌| 10041/10556 [00:00<00:00, 95982.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 95997.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124300.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8147/10556 [00:00<00:00, 81466.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 95099.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216216.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132992.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124354.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4445/10556 [00:00<00:00, 41268.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 77823.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216041.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128551.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165204.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122282.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 161430.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197781.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202045.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202967.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206660.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201862.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200099.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194136.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195452.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181000.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197013.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202996.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204934.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201087.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201350.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182430.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201134.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202314.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198352.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193915.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190726.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196100.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199774.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203640.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196866.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200320.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198287.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203958.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207944.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191855.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200347.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200257.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199324.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197119.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190168.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155030.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199733.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201962.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204876.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204125.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194017.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204732.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197240.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202622.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162227.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 224981.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195987.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217211.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195449.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176668.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195099.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205594.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198722.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172745.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172545.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170771.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168403.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166270.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165068.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212302.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207165.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142617.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183200.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189159.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186416.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179468.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181207.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183341.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126644.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108934.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160764.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7300/10556 [00:00<00:00, 72995.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 77490.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187674.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188688.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198323.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199613.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193054.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5380/10556 [00:00<00:00, 52537.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 53740.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134222.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127840.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209222.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184882.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199552.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203711.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217697.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197584.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205095.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210862.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213998.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210498.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207477.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193254.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160634.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198775.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206614.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208047.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193172.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190079.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190430.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156795.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146427.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162672.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201812.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205463.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199480.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187779.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204218.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8313/10556 [00:00<00:00, 83126.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 92637.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193222.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202024.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202287.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207603.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201147.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206059.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188910.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197089.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214281.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192496.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196743.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200871.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201894.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205813.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201571.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203707.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193275.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209647.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211291.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212158.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213886.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208188.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201983.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206517.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196172.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199167.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189295.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196230.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150900.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140460.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132799.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155312.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145979.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144035.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150308.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144703.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153717.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153429.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153156.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154308.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152568.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150095.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152373.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150162.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152541.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152345.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150509.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151539.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150804.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141395.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122937.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153477.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152539.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151391.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152705.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152707.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153202.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148412.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150878.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154645.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8694/10556 [00:00<00:00, 86933.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 75956.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10485/10556 [00:00<00:00, 104842.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 104573.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127106.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133579.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8939/10556 [00:00<00:00, 89388.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 93052.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182172.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176815.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192074.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7149/10556 [00:00<00:00, 71488.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 90618.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7153/10556 [00:00<00:00, 66069.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 72887.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152271.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5807/10556 [00:00<00:00, 58067.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 84670.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187502.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191331.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191905.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190576.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196897.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187311.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186522.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190492.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188803.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190405.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195929.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188718.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187860.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190099.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190700.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210712.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 226313.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215868.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190736.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188338.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215373.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164707.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156055.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154087.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147928.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152041.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152210.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149807.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152889.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152462.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145544.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150907.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147258.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151169.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150317.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142553.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150764.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150967.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152247.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151824.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150379.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147427.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141729.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149268.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139574.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153064.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141624.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9371/10556 [00:00<00:00, 93707.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 97844.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148756.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133081.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127866.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169601.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177246.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194553.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181624.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189924.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197349.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182924.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192024.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189221.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189842.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203368.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196265.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196261.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202174.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175688.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 161546.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190387.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194193.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209345.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198794.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194294.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220824.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220582.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196365.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193850.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213999.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189002.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190471.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182070.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191834.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198974.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130597.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159596.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211715.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180105.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164214.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169836.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193543.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198884.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194732.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136580.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125849.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191828.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194127.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193093.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193437.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187671.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195130.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193769.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6802/10556 [00:00<00:00, 68013.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 79834.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8186/10556 [00:00<00:00, 81853.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 82688.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9192/10556 [00:00<00:00, 91919.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 89645.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▋| 10174/10556 [00:00<00:00, 101736.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 103459.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178845.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8194/10556 [00:00<00:00, 81927.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 75801.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162307.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178986.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177785.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 163857.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165132.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155500.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148589.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148427.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137217.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141521.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125038.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136030.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107121.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119991.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126270.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111371.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7975/10556 [00:00<00:00, 79748.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 87892.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125059.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126029.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▎  | 7760/10556 [00:00<00:00, 77594.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 69248.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125835.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123154.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111923.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114773.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125179.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118822.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150960.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152184.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126047.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126287.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123495.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126376.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123815.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118047.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124631.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125205.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124447.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116785.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106787.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151841.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150837.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147639.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149015.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148139.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144607.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151615.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151050.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151672.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147071.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149015.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152331.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151400.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151178.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149789.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148972.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145699.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148896.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149682.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138869.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126646.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121167.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123408.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151661.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7324/10556 [00:00<00:00, 71527.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 60311.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9622/10556 [00:00<00:00, 96211.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 95663.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8144/10556 [00:00<00:00, 81433.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 78199.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9631/10556 [00:00<00:00, 96303.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 96739.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5730/10556 [00:00<00:00, 57295.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 57242.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6212/10556 [00:00<00:00, 60277.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 60036.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8966/10556 [00:00<00:00, 89657.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 79035.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106267.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5395/10556 [00:00<00:00, 48467.82it/s] 92%|█████████▏| 9762/10556 [00:00<00:00, 46921.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 48391.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▎  | 7762/10556 [00:00<00:00, 73674.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 75979.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6378/10556 [00:00<00:00, 62348.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 63724.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6896/10556 [00:00<00:00, 65135.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 73058.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5857/10556 [00:00<00:00, 58208.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 64626.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7689/10556 [00:00<00:00, 76887.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 78690.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5524/10556 [00:00<00:00, 54850.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 59146.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|█████     | 5326/10556 [00:00<00:00, 53259.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 53395.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7114/10556 [00:00<00:00, 71138.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 81215.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6198/10556 [00:00<00:00, 61866.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 57289.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6243/10556 [00:00<00:00, 61831.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 59934.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7592/10556 [00:00<00:00, 73327.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 66390.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6600/10556 [00:00<00:00, 64490.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 60686.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4428/10556 [00:00<00:00, 41323.28it/s] 98%|█████████▊| 10301/10556 [00:00<00:00, 44835.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 48520.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5882/10556 [00:00<00:00, 58164.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 56285.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6025/10556 [00:00<00:00, 60247.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 58197.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6304/10556 [00:00<00:00, 59863.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 59406.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8730/10556 [00:00<00:00, 87296.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 91260.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6096/10556 [00:00<00:00, 58543.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 59985.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7655/10556 [00:00<00:00, 74431.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 67295.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7021/10556 [00:00<00:00, 70209.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 73013.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119704.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6783/10556 [00:00<00:00, 67825.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 72475.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9733/10556 [00:00<00:00, 97323.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 98487.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6837/10556 [00:00<00:00, 65909.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 75746.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119118.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112146.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6728/10556 [00:00<00:00, 67275.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 67270.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9110/10556 [00:00<00:00, 91095.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 93887.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111131.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7503/10556 [00:00<00:00, 75029.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 83309.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9157/10556 [00:00<00:00, 91569.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 89366.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116852.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118045.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114787.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119296.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6420/10556 [00:00<00:00, 64196.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 71565.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6704/10556 [00:00<00:00, 67036.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 79767.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7191/10556 [00:00<00:00, 66706.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 61940.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10011/10556 [00:00<00:00, 100104.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 98309.53it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8244/10556 [00:00<00:00, 82438.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 89047.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6825/10556 [00:00<00:00, 68247.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 83020.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127231.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108423.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127011.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170087.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184483.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186375.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194873.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7610/10556 [00:00<00:00, 75562.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 73784.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191061.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8549/10556 [00:00<00:00, 85002.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 81934.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190653.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197794.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182417.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186977.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186283.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188840.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190070.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186018.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105517.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188767.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186104.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192431.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187030.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185198.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190504.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154769.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9612/10556 [00:00<00:00, 96119.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 100695.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180812.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190122.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194213.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192363.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190632.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189864.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189923.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191725.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183601.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190637.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192960.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205027.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171035.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134995.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146965.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150691.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151569.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152901.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141960.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152621.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143629.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147545.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151847.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152120.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149472.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152377.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147844.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157181.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156569.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152947.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143817.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144970.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154162.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151968.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152052.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145160.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155586.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147854.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200701.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207173.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203648.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221702.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200565.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192030.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197324.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207759.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203246.77it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.37444'}; time used = 0.336841344833374s
epoch 10: {'train_loss': '1.34634'}; time used = 0.30927562713623047s
epoch 15: {'train_loss': '1.29060'}; time used = 0.35372114181518555s
epoch 20: {'train_loss': '1.20709'}; time used = 0.5467967987060547s
epoch 25: {'train_loss': '1.09631'}; time used = 0.4776430130004883s
epoch 30: {'train_loss': '0.99207'}; time used = 0.3667576313018799s
epoch 35: {'train_loss': '0.88110'}; time used = 0.2982172966003418s
epoch 40: {'train_loss': '0.79318'}; time used = 0.3046698570251465s
epoch 45: {'train_loss': '0.70458'}; time used = 0.30504631996154785s
epoch 50: {'train_loss': '0.64330'}; time used = 0.307361364364624s
epoch 55: {'train_loss': '0.58330'}; time used = 0.30043792724609375s
epoch 60: {'train_loss': '0.53310'}; time used = 0.3001866340637207s
epoch 65: {'train_loss': '0.49539'}; time used = 0.31826257705688477s
epoch 70: {'train_loss': '0.44576'}; time used = 0.2974855899810791s
epoch 75: {'train_loss': '0.41089'}; time used = 0.310652494430542s
epoch 80: {'train_loss': '0.39445'}; time used = 0.30785036087036133s
epoch 85: {'train_loss': '0.37521'}; time used = 0.3504304885864258s
epoch 90: {'train_loss': '0.34465'}; time used = 0.3402714729309082s
epoch 95: {'train_loss': '0.33099'}; time used = 0.32181644439697266s
epoch 100: {'train_loss': '0.32326'}; time used = 0.49579954147338867s
epoch 105: {'train_loss': '0.29873'}; time used = 0.44858336448669434s
epoch 110: {'train_loss': '0.29434'}; time used = 0.3761107921600342s
epoch 115: {'train_loss': '0.27909'}; time used = 0.2873382568359375s
epoch 120: {'train_loss': '0.26295'}; time used = 0.3000466823577881s
epoch 125: {'train_loss': '0.26068'}; time used = 0.30522990226745605s
epoch 130: {'train_loss': '0.25912'}; time used = 0.348268985748291s
epoch 135: {'train_loss': '0.24397'}; time used = 0.3594777584075928s
epoch 140: {'train_loss': '0.24819'}; time used = 0.30174779891967773s
epoch 145: {'train_loss': '0.23680'}; time used = 0.2927849292755127s
epoch 150: {'train_loss': '0.22064'}; time used = 0.2923004627227783s
epoch 155: {'train_loss': '0.22414'}; time used = 0.2969837188720703s
epoch 160: {'train_loss': '0.19966'}; time used = 0.28740525245666504s
epoch 165: {'train_loss': '0.21289'}; time used = 0.3395369052886963s
epoch 170: {'train_loss': '0.20069'}; time used = 0.39950060844421387s
epoch 175: {'train_loss': '0.19764'}; time used = 0.38237619400024414s
epoch 180: {'train_loss': '0.19557'}; time used = 0.38530898094177246s
epoch 185: {'train_loss': '0.20670'}; time used = 0.38916444778442383s
epoch 190: {'train_loss': '0.18914'}; time used = 0.41144227981567383s
epoch 195: {'train_loss': '0.18246'}; time used = 0.383711576461792s
epoch 200: {'train_loss': '0.18324'}; time used = 0.570744514465332s
epoch 205: {'train_loss': '0.19223'}; time used = 0.47495436668395996s
epoch 210: {'train_loss': '0.17911'}; time used = 0.4081556797027588s
epoch 215: {'train_loss': '0.17878'}; time used = 0.30687713623046875s
epoch 220: {'train_loss': '0.18257'}; time used = 0.3074040412902832s
epoch 225: {'train_loss': '0.17978'}; time used = 0.28942227363586426s
epoch 230: {'train_loss': '0.19018'}; time used = 0.34099316596984863s
epoch 235: {'train_loss': '0.17436'}; time used = 0.38108372688293457s
epoch 240: {'train_loss': '0.16518'}; time used = 0.3840982913970947s
epoch 245: {'train_loss': '0.16176'}; time used = 0.38934993743896484s
epoch 250: {'train_loss': '0.17140'}; time used = 0.38898253440856934s
epoch 255: {'train_loss': '0.16776'}; time used = 0.43995022773742676s
epoch 260: {'train_loss': '0.16047'}; time used = 0.3961617946624756s
epoch 265: {'train_loss': '0.16721'}; time used = 0.31645655632019043s
epoch 270: {'train_loss': '0.15355'}; time used = 0.3163430690765381s
epoch 275: {'train_loss': '0.15264'}; time used = 0.32317686080932617s
epoch 280: {'train_loss': '0.14515'}; time used = 0.29039597511291504s
epoch 285: {'train_loss': '0.14106'}; time used = 0.29457736015319824s
epoch 290: {'train_loss': '0.14571'}; time used = 0.3367486000061035s
epoch 295: {'train_loss': '0.15398'}; time used = 0.3497731685638428s
epoch 300: {'train_loss': '0.14199'}; time used = 0.3582279682159424s
epoch 305: {'train_loss': '0.14267'}; time used = 0.30814313888549805s
epoch 310: {'train_loss': '0.15045'}; time used = 0.5655517578125s
epoch 315: {'train_loss': '0.13112'}; time used = 0.4934577941894531s
epoch 320: {'train_loss': '0.12954'}; time used = 0.37291836738586426s
epoch 325: {'train_loss': '0.13716'}; time used = 0.43427014350891113s
epoch 330: {'train_loss': '0.14108'}; time used = 0.5445601940155029s
epoch 335: {'train_loss': '0.14267'}; time used = 0.5317249298095703s
epoch 340: {'train_loss': '0.13214'}; time used = 0.474057674407959s
epoch 345: {'train_loss': '0.13720'}; time used = 0.4512817859649658s
epoch 350: {'train_loss': '0.13040'}; time used = 0.47798824310302734s
epoch 355: {'train_loss': '0.12578'}; time used = 0.464951753616333s
epoch 360: {'train_loss': '0.13566'}; time used = 0.4006481170654297s
epoch 365: {'train_loss': '0.13056'}; time used = 0.4000222682952881s
epoch 370: {'train_loss': '0.12876'}; time used = 0.398193359375s
epoch 375: {'train_loss': '0.12187'}; time used = 0.4527451992034912s
epoch 380: {'train_loss': '0.13275'}; time used = 0.6459901332855225s
epoch 385: {'train_loss': '0.13455'}; time used = 0.8833646774291992s
epoch 390: {'train_loss': '0.13071'}; time used = 0.8171191215515137s
epoch 395: {'train_loss': '0.11398'}; time used = 0.9558885097503662s
epoch 400: {'train_loss': '0.12175'}; time used = 1.0205507278442383s
epoch 405: {'train_loss': '0.11671'}; time used = 0.8551075458526611s
epoch 410: {'train_loss': '0.12378'}; time used = 0.6302189826965332s
epoch 415: {'train_loss': '0.12742'}; time used = 0.6388704776763916s
epoch 420: {'train_loss': '0.11512'}; time used = 0.550997257232666s
epoch 425: {'train_loss': '0.12592'}; time used = 0.7564871311187744s
epoch 430: {'train_loss': '0.12863'}; time used = 0.509366512298584s
epoch 435: {'train_loss': '0.11681'}; time used = 0.40015602111816406s
epoch 440: {'train_loss': '0.11487'}; time used = 0.3829171657562256s
epoch 445: {'train_loss': '0.11758'}; time used = 0.36684513092041016s
epoch 450: {'train_loss': '0.11691'}; time used = 0.31805896759033203s
epoch 455: {'train_loss': '0.11363'}; time used = 0.3783540725708008s
epoch 460: {'train_loss': '0.11005'}; time used = 0.31075072288513184s
epoch 465: {'train_loss': '0.11488'}; time used = 0.3096017837524414s
epoch 470: {'train_loss': '0.11147'}; time used = 0.40453577041625977s
epoch 475: {'train_loss': '0.11423'}; time used = 0.3954629898071289s
epoch 480: {'train_loss': '0.10530'}; time used = 0.3881106376647949s
epoch 485: {'train_loss': '0.10983'}; time used = 0.3874647617340088s
epoch 490: {'train_loss': '0.10587'}; time used = 0.3912053108215332s
epoch 495: {'train_loss': '0.10343'}; time used = 0.31461191177368164s
epoch 500: {'train_loss': '0.09633'}; time used = 0.29962587356567383s
Finished training. Time used = 44.772972106933594.
Training classifier using 20.00% nodes...
{'micro': 0.7563451776649746, 'macro': 0.7257217902697872, 'samples': 0.7563451776649747, 'weighted': 0.7533134831068132}

  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206437.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185261.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184637.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181053.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177480.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175089.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182116.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184113.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158696.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183975.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10187/10556 [00:00<00:00, 101865.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 101470.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144663.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138358.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143363.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146304.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143916.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145008.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134267.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6849/10556 [00:00<00:00, 68487.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 84266.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147401.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143807.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9292/10556 [00:00<00:00, 92910.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 87097.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7051/10556 [00:00<00:00, 70508.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 71943.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▊   | 7256/10556 [00:00<00:00, 72555.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 65008.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9219/10556 [00:00<00:00, 92183.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 97217.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198237.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185174.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158803.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156308.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196256.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205049.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181795.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204185.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204357.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205575.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135093.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145923.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182584.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195722.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203349.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201831.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136814.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125049.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131959.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111236.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130531.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121576.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7932/10556 [00:00<00:00, 79318.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 75873.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222224.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180640.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 163977.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215295.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209265.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222773.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219012.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208636.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202873.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196574.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201296.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179243.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9684/10556 [00:00<00:00, 96835.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 101408.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110950.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9789/10556 [00:00<00:00, 97885.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 99242.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 161665.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197788.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196189.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199316.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8351/10556 [00:00<00:00, 83507.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 81262.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118075.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109371.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218697.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197859.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208449.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 228815.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198916.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197003.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195741.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198142.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205186.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198529.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188640.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208097.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209769.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203425.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201733.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198410.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210652.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188357.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207077.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207635.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206679.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204464.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171125.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146085.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143933.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149813.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144882.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134189.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130654.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144733.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145421.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129000.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146398.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146528.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146509.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147539.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147648.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142468.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148830.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149157.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147487.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141463.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149339.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150521.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140587.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116140.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114523.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116662.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113657.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133531.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171067.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178319.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200334.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200872.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190266.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182451.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172211.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179486.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176186.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175696.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176229.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154354.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185597.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186440.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185330.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173865.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184143.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190261.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190287.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192081.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197060.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192031.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192471.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182515.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188032.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184261.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7065/10556 [00:00<00:00, 66584.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 77080.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6418/10556 [00:00<00:00, 64179.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 79058.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123733.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9091/10556 [00:00<00:00, 90903.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 91919.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178886.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192011.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191236.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196470.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112440.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135095.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169094.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137534.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150347.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180076.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180282.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181955.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8467/10556 [00:00<00:00, 84665.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 81232.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145227.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183202.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159094.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188999.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181113.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171684.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176931.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179841.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182985.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177418.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168206.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177027.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180107.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183058.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184020.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185875.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181884.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183112.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184641.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190954.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190514.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192291.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184674.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189173.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191192.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195736.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190221.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191351.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188161.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191729.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181233.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187627.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183247.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187018.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194454.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197040.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189770.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195728.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189818.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189305.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186598.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189391.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185656.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178076.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181271.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164933.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182063.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176008.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171371.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184869.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182483.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186423.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182115.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182584.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197285.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186078.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184089.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177676.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182695.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182459.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185606.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186090.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181753.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184415.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186436.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185662.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187441.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187103.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123019.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 161101.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186077.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181153.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183563.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182442.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179648.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182941.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148969.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107919.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121407.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149814.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198215.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186070.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169723.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179243.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185230.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116519.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7741/10556 [00:00<00:00, 75691.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 62406.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120156.30it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.21815'}; time used = 0.3425898551940918s
epoch 10: {'train_loss': '0.87742'}; time used = 0.3810763359069824s
epoch 15: {'train_loss': '0.73846'}; time used = 0.4231147766113281s
epoch 20: {'train_loss': '0.51809'}; time used = 0.46338868141174316s
epoch 25: {'train_loss': '0.40898'}; time used = 0.6936314105987549s
epoch 30: {'train_loss': '0.34974'}; time used = 0.34479832649230957s
epoch 35: {'train_loss': '0.31583'}; time used = 0.3221774101257324s
epoch 40: {'train_loss': '0.40443'}; time used = 0.33223676681518555s
epoch 45: {'train_loss': '0.32866'}; time used = 0.4677579402923584s
epoch 50: {'train_loss': '0.29368'}; time used = 0.4417562484741211s
epoch 55: {'train_loss': '0.24103'}; time used = 0.27991533279418945s
epoch 60: {'train_loss': '0.20020'}; time used = 0.36507296562194824s
epoch 65: {'train_loss': '0.18293'}; time used = 0.41460585594177246s
epoch 70: {'train_loss': '0.16066'}; time used = 0.46059155464172363s
epoch 75: {'train_loss': '0.14148'}; time used = 0.2864809036254883s
epoch 80: {'train_loss': '0.13243'}; time used = 0.2996861934661865s
epoch 85: {'train_loss': '0.13909'}; time used = 0.28995513916015625s
epoch 90: {'train_loss': '0.11914'}; time used = 0.2909836769104004s
epoch 95: {'train_loss': '0.12084'}; time used = 0.3685891628265381s
epoch 100: {'train_loss': '0.13076'}; time used = 0.4197573661804199s
epoch 105: {'train_loss': '0.13619'}; time used = 0.40669751167297363s
epoch 110: {'train_loss': '0.12738'}; time used = 0.3948936462402344s
epoch 115: {'train_loss': '0.11929'}; time used = 0.4197719097137451s
epoch 120: {'train_loss': '0.10409'}; time used = 0.45673680305480957s
epoch 125: {'train_loss': '0.10162'}; time used = 0.31431150436401367s
epoch 130: {'train_loss': '0.09881'}; time used = 0.3432483673095703s
epoch 135: {'train_loss': '0.08345'}; time used = 0.35215187072753906s
epoch 140: {'train_loss': '0.09741'}; time used = 0.30854201316833496s
epoch 145: {'train_loss': '0.09556'}; time used = 0.3138124942779541s
epoch 150: {'train_loss': '0.09479'}; time used = 0.5719394683837891s
epoch 155: {'train_loss': '0.09780'}; time used = 0.38464808464050293s
epoch 160: {'train_loss': '0.09371'}; time used = 0.3772854804992676s
epoch 165: {'train_loss': '0.12155'}; time used = 0.4318814277648926s
epoch 170: {'train_loss': '0.09228'}; time used = 0.3346061706542969s
epoch 175: {'train_loss': '0.10644'}; time used = 0.34595465660095215s
epoch 180: {'train_loss': '0.08721'}; time used = 0.32503581047058105s
epoch 185: {'train_loss': '0.08746'}; time used = 0.31476664543151855s
epoch 190: {'train_loss': '0.08892'}; time used = 0.3077201843261719s
epoch 195: {'train_loss': '0.07076'}; time used = 0.3150331974029541s
epoch 200: {'train_loss': '0.07711'}; time used = 0.3077809810638428s
epoch 205: {'train_loss': '0.07811'}; time used = 0.3160369396209717s
epoch 210: {'train_loss': '0.07195'}; time used = 0.3469839096069336s
epoch 215: {'train_loss': '0.08796'}; time used = 0.33289265632629395s
epoch 220: {'train_loss': '0.07332'}; time used = 0.32990527153015137s
epoch 225: {'train_loss': '0.07418'}; time used = 0.32340002059936523s
epoch 230: {'train_loss': '0.08004'}; time used = 0.31737756729125977s
epoch 235: {'train_loss': '0.07775'}; time used = 0.3615727424621582s
epoch 240: {'train_loss': '0.07876'}; time used = 0.3991079330444336s
epoch 245: {'train_loss': '0.07883'}; time used = 0.36269307136535645s
epoch 250: {'train_loss': '0.16394'}; time used = 0.5048575401306152s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.96529984474182.
Training classifier using 20.00% nodes...
{'micro': 0.7494231656668204, 'macro': 0.7206045503600672, 'samples': 0.7494231656668204, 'weighted': 0.7443574646916957}
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210356.87it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 166.00 MiB (GPU 0; 10.76 GiB total capacity; 42.17 MiB already allocated; 73.44 MiB free; 56.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f9ea3db21e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f9ea400864b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f9ea4009464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f9ea4009aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f9c49de790e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f9c48221949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f9c4823b777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f9c82fd7c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f9c82fd7f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f9c830e2a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f9c82d724f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f9c82d74166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f9c82d7465d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f9c82d7480a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f9c82ab1eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f9c48210b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f9c82944530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f9c8312c81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f9c8307d82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f9c82bb4952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f9c82bb5f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f9c831898c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f9c831b308b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f9c830da337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f9c84ce8205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f9c831b308b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f9c830da337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f9c84c47f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f9c85263bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f9c8525f400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f9c8525ffa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f9c85258119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f9e709ad4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f9eacb2d6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f9eb0b886db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f9eb0ec171f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 245432.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206316.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185163.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209768.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217028.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212760.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151158.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 224238.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190401.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173124.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214930.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 9988/10556 [00:00<00:00, 99873.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 99735.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157027.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108299.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136015.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131652.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140966.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153125.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7277/10556 [00:00<00:00, 72766.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 79930.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148331.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147482.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152906.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152821.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152810.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153565.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144663.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152708.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154362.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153376.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152156.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154781.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143890.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150053.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144390.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138246.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151298.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148127.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156391.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152423.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157481.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153834.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152864.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148688.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107415.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 102013.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212996.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210196.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118921.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176124.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222239.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214731.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211312.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5497/10556 [00:00<00:00, 54967.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 71727.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213788.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214127.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8141/10556 [00:00<00:00, 81245.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 80335.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205950.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 232797.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205235.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202061.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193779.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208078.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209011.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193967.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198890.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204080.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211565.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214355.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201348.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216081.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198211.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211042.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211814.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214080.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214918.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156681.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155554.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146493.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153483.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151653.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147221.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150071.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141276.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152489.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152450.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148237.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150763.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151738.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152874.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152288.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153115.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153459.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147932.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153006.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151024.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152898.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152609.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141338.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152076.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142450.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151097.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152491.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148344.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147740.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145921.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147584.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147706.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147241.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150495.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135597.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152986.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153132.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131204.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175948.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214475.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202131.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201832.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215967.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213581.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214507.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199139.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206028.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192543.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217628.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214765.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212764.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126637.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196144.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193326.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215895.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210653.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212780.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214729.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216957.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214167.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217700.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 9992/10556 [00:00<00:00, 99916.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 99689.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194049.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218088.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148324.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209911.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215975.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217844.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217864.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205866.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217912.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 225325.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200830.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 224459.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220381.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201520.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221705.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181078.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205954.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197933.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191081.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195102.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200184.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218353.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210079.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216793.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████▏  | 7537/10556 [00:00<00:00, 75360.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 74752.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181653.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217621.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203764.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194678.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183241.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205009.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200834.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215425.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 230335.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195546.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189677.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181196.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173911.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108537.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205647.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214048.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210307.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7831/10556 [00:00<00:00, 78305.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 79021.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106791.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150628.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154645.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6162/10556 [00:00<00:00, 56910.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 74908.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151174.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108700.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9399/10556 [00:00<00:00, 93983.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 94711.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9114/10556 [00:00<00:00, 91138.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 96750.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153469.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151155.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151719.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148851.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153910.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153509.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149747.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145765.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150787.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151109.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154294.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144784.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153831.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152723.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148655.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153429.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145927.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153671.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153001.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149343.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147338.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146018.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155075.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146140.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144712.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155064.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147638.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147854.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152394.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144560.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150209.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152383.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145301.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153971.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152581.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149373.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153174.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142094.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153183.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125623.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137366.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178884.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217120.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192666.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204802.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136132.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181220.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216448.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218513.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213687.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206486.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197776.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207698.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206968.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201405.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198946.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203522.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206524.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196158.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209625.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202027.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112910.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121011.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10116/10556 [00:00<00:00, 101156.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 101734.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▊   | 7255/10556 [00:00<00:00, 72548.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 80424.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5538/10556 [00:00<00:00, 46516.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 65460.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123902.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9449/10556 [00:00<00:00, 94487.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 96688.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5561/10556 [00:00<00:00, 55609.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 71975.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118681.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6548/10556 [00:00<00:00, 65181.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 79279.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7359/10556 [00:00<00:00, 70306.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 63577.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10190/10556 [00:00<00:00, 101894.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 102153.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6707/10556 [00:00<00:00, 66080.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 61748.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124296.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7295/10556 [00:00<00:00, 72948.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 83271.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110786.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████▏    | 5423/10556 [00:00<00:00, 50217.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 52860.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8799/10556 [00:00<00:00, 86680.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 85111.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118843.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122803.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124683.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122528.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7497/10556 [00:00<00:00, 74966.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 84831.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10151/10556 [00:00<00:00, 101506.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 101289.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 103680.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6209/10556 [00:00<00:00, 62086.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 75135.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 100856.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7269/10556 [00:00<00:00, 72689.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 67129.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▋  | 8062/10556 [00:00<00:00, 80618.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 83613.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6016/10556 [00:00<00:00, 57673.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 56850.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106934.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10026/10556 [00:00<00:00, 100257.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 95702.99it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▌| 10043/10556 [00:00<00:00, 100426.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 96097.66it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5179/10556 [00:00<00:00, 51787.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 54372.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9095/10556 [00:00<00:00, 89624.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 84049.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7160/10556 [00:00<00:00, 71594.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 77784.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125556.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▎| 9890/10556 [00:00<00:00, 98897.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 99892.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8534/10556 [00:00<00:00, 80990.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 78012.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9070/10556 [00:00<00:00, 90697.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 93380.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9867/10556 [00:00<00:00, 98664.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 99354.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118706.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|████▌     | 4776/10556 [00:00<00:00, 46483.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 71729.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124088.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9531/10556 [00:00<00:00, 95306.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 92662.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118202.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10236/10556 [00:00<00:00, 102353.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 102687.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9463/10556 [00:00<00:00, 94627.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 88607.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107015.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6735/10556 [00:00<00:00, 67345.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 64582.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116888.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124657.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7174/10556 [00:00<00:00, 71739.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 75834.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123691.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110362.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112338.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7364/10556 [00:00<00:00, 73637.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 82402.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4924/10556 [00:00<00:00, 48945.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 64065.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125142.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6523/10556 [00:00<00:00, 65229.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 70797.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8343/10556 [00:00<00:00, 82564.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 77527.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115071.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122839.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125376.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6236/10556 [00:00<00:00, 61660.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 79110.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123685.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7230/10556 [00:00<00:00, 69791.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 67155.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7165/10556 [00:00<00:00, 68191.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 72958.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116515.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8005/10556 [00:00<00:00, 71702.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 77276.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126553.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112244.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9301/10556 [00:00<00:00, 93007.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 91052.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5574/10556 [00:00<00:00, 52100.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 53619.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5386/10556 [00:00<00:00, 50275.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 69386.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114355.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115414.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10355/10556 [00:00<00:00, 103547.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 98148.91it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5360/10556 [00:00<00:00, 53599.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 71734.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 9987/10556 [00:00<00:00, 99865.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 100498.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9352/10556 [00:00<00:00, 93514.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 95516.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9922/10556 [00:00<00:00, 99217.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 93608.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10120/10556 [00:00<00:00, 95970.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 86906.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8767/10556 [00:00<00:00, 87665.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 91063.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8525/10556 [00:00<00:00, 85248.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 80938.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|███████▉  | 8398/10556 [00:00<00:00, 83975.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 88428.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6873/10556 [00:00<00:00, 68727.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 82722.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▎| 9893/10556 [00:00<00:00, 98924.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 95326.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151161.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216519.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126298.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187554.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120579.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130106.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117324.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136305.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129419.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 228691.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148688.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191565.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212857.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167413.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215639.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134164.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146592.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 238521.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206682.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214307.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198217.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213717.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207443.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215465.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212420.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210734.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215371.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203180.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219707.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216203.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222912.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216309.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193719.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207092.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205855.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203041.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214483.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207549.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206234.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209714.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208738.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215184.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204000.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212920.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213315.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206292.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205821.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196129.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198705.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200247.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206843.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210779.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214940.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199136.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207320.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207587.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218397.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187067.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116465.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7670/10556 [00:00<00:00, 76694.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 73526.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142389.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206119.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204339.57it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.44807'}; time used = 0.3003959655761719s
epoch 10: {'train_loss': '1.42551'}; time used = 0.3180687427520752s
epoch 15: {'train_loss': '1.37698'}; time used = 0.4664769172668457s
epoch 20: {'train_loss': '1.37678'}; time used = 0.4651167392730713s
epoch 25: {'train_loss': '1.37194'}; time used = 0.38615918159484863s
epoch 30: {'train_loss': '1.36892'}; time used = 0.3772871494293213s
epoch 35: {'train_loss': '1.36734'}; time used = 0.4031550884246826s
epoch 40: {'train_loss': '1.36192'}; time used = 0.38390350341796875s
epoch 45: {'train_loss': '1.35931'}; time used = 0.44660234451293945s
epoch 50: {'train_loss': '1.35533'}; time used = 0.32497620582580566s
epoch 55: {'train_loss': '1.35523'}; time used = 0.4658694267272949s
epoch 60: {'train_loss': '1.34275'}; time used = 0.2844226360321045s
epoch 65: {'train_loss': '1.34743'}; time used = 0.2905235290527344s
epoch 70: {'train_loss': '1.33296'}; time used = 0.2833743095397949s
epoch 75: {'train_loss': '1.32703'}; time used = 0.2982289791107178s
epoch 80: {'train_loss': '1.31717'}; time used = 0.38378477096557617s
epoch 85: {'train_loss': '1.30158'}; time used = 0.38991427421569824s
epoch 90: {'train_loss': '1.29168'}; time used = 0.3843264579772949s
epoch 95: {'train_loss': '1.28186'}; time used = 0.38323330879211426s
epoch 100: {'train_loss': '1.31820'}; time used = 0.3943154811859131s
epoch 105: {'train_loss': '1.30372'}; time used = 0.3993828296661377s
epoch 110: {'train_loss': '1.28849'}; time used = 0.3993985652923584s
epoch 115: {'train_loss': '1.27926'}; time used = 0.3431577682495117s
epoch 120: {'train_loss': '1.31799'}; time used = 0.2842705249786377s
epoch 125: {'train_loss': '1.27060'}; time used = 0.2858240604400635s
epoch 130: {'train_loss': '1.24921'}; time used = 0.3450345993041992s
epoch 135: {'train_loss': '1.22547'}; time used = 0.2745959758758545s
epoch 140: {'train_loss': '1.20509'}; time used = 0.36888909339904785s
epoch 145: {'train_loss': '1.43991'}; time used = 0.2767181396484375s
epoch 150: {'train_loss': '1.29937'}; time used = 0.2796452045440674s
epoch 155: {'train_loss': '1.31798'}; time used = 0.29558300971984863s
epoch 160: {'train_loss': '1.30709'}; time used = 0.28789234161376953s
epoch 165: {'train_loss': '1.29145'}; time used = 0.3937692642211914s
epoch 170: {'train_loss': '1.27773'}; time used = 0.2938528060913086s
epoch 175: {'train_loss': '1.25933'}; time used = 0.3980724811553955s
epoch 180: {'train_loss': '1.22402'}; time used = 0.41989755630493164s
epoch 185: {'train_loss': '1.24501'}; time used = 0.49309492111206055s
epoch 190: {'train_loss': '1.17488'}; time used = 0.46953558921813965s
epoch 195: {'train_loss': '1.16539'}; time used = 0.3978712558746338s
epoch 200: {'train_loss': '1.13146'}; time used = 0.38294029235839844s
epoch 205: {'train_loss': '1.11267'}; time used = 0.38414812088012695s
epoch 210: {'train_loss': '1.11305'}; time used = 0.3821897506713867s
epoch 215: {'train_loss': '1.09300'}; time used = 0.3863797187805176s
epoch 220: {'train_loss': '1.12017'}; time used = 0.38495731353759766s
epoch 225: {'train_loss': '1.09148'}; time used = 0.38242006301879883s
epoch 230: {'train_loss': '1.08508'}; time used = 0.373180627822876s
epoch 235: {'train_loss': '1.07566'}; time used = 0.32493162155151367s
epoch 240: {'train_loss': '1.06115'}; time used = 0.28801655769348145s
epoch 245: {'train_loss': '1.06960'}; time used = 0.29840898513793945s
epoch 250: {'train_loss': '1.07498'}; time used = 0.37271904945373535s
epoch 255: {'train_loss': '1.07513'}; time used = 0.6460247039794922s
epoch 260: {'train_loss': '1.06376'}; time used = 0.7189638614654541s
epoch 265: {'train_loss': '1.06995'}; time used = 0.7407755851745605s
epoch 270: {'train_loss': '1.08182'}; time used = 0.5456924438476562s
epoch 275: {'train_loss': '1.06299'}; time used = 0.6419165134429932s
epoch 280: {'train_loss': '1.05568'}; time used = 0.7373652458190918s
epoch 285: {'train_loss': '1.05215'}; time used = 0.758812665939331s
epoch 290: {'train_loss': '1.15635'}; time used = 0.624885082244873s
epoch 295: {'train_loss': '1.06797'}; time used = 0.5885727405548096s
epoch 300: {'train_loss': '1.15372'}; time used = 0.6280174255371094s
epoch 305: {'train_loss': '1.06969'}; time used = 0.609614372253418s
epoch 310: {'train_loss': '1.06827'}; time used = 0.7196478843688965s
epoch 315: {'train_loss': '1.05931'}; time used = 0.6223821640014648s
epoch 320: {'train_loss': '1.07763'}; time used = 0.6324586868286133s
epoch 325: {'train_loss': '1.05598'}; time used = 0.7068569660186768s
epoch 330: {'train_loss': '1.04284'}; time used = 0.6510751247406006s
epoch 335: {'train_loss': '1.04531'}; time used = 0.6663937568664551s
epoch 340: {'train_loss': '1.03459'}; time used = 0.4120330810546875s
epoch 345: {'train_loss': '1.03725'}; time used = 0.4835050106048584s
epoch 350: {'train_loss': '1.04104'}; time used = 0.316875696182251s
epoch 355: {'train_loss': '1.16671'}; time used = 0.3398115634918213s
epoch 360: {'train_loss': '1.09371'}; time used = 0.2794055938720703s
epoch 365: {'train_loss': '1.09106'}; time used = 0.2829258441925049s
epoch 370: {'train_loss': '1.04551'}; time used = 0.2809464931488037s
epoch 375: {'train_loss': '1.05624'}; time used = 0.2836191654205322s
epoch 380: {'train_loss': '1.04717'}; time used = 0.2813117504119873s
epoch 385: {'train_loss': '1.03707'}; time used = 0.28798604011535645s
epoch 390: {'train_loss': '1.04014'}; time used = 0.2848799228668213s
epoch 395: {'train_loss': '1.03582'}; time used = 0.32860851287841797s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.990418434143066.
Training classifier using 20.00% nodes...
{'micro': 0.2893401015228426, 'macro': 0.07001207990661074, 'samples': 0.2893401015228426, 'weighted': 0.14015926137292134}
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114939.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8223/10556 [00:00<00:00, 75301.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 68932.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111789.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113953.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114088.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114598.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6407/10556 [00:00<00:00, 64065.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 69809.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 101061.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5594/10556 [00:00<00:00, 55936.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 83102.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132515.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10540/10556 [00:00<00:00, 105394.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 105078.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6982/10556 [00:00<00:00, 69818.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 81023.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6116/10556 [00:00<00:00, 61155.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 59690.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10093/10556 [00:00<00:00, 100929.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 95151.37it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10392/10556 [00:00<00:00, 99975.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 99973.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4462/10556 [00:00<00:00, 44617.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 53753.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111294.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199826.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203638.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193688.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193896.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168841.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179212.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192325.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123032.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 163299.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185576.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183669.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191178.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172584.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187220.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136515.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140818.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190146.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192779.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182997.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192118.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189941.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188271.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175703.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182049.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190042.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187317.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184898.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192910.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189207.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176825.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165071.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167526.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166958.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167912.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167928.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173735.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142472.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142148.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145262.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145904.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148884.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144792.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141651.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141629.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144712.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141024.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144407.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145235.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137333.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143304.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145872.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145227.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144977.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142385.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141490.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145535.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144951.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146743.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142763.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135368.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145169.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144544.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133224.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146132.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146683.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145660.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140806.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136117.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145408.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10216/10556 [00:00<00:00, 102154.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 101890.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149503.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139485.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142345.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136723.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126009.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10346/10556 [00:00<00:00, 103455.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 103670.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182304.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173135.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178452.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189696.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185519.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175021.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170859.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175650.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184125.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176388.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185079.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185001.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186032.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188585.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183395.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173845.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151463.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184315.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180768.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188573.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174569.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181323.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185861.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202428.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185530.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187869.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181524.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157599.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115043.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6375/10556 [00:00<00:00, 63745.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 70798.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6546/10556 [00:00<00:00, 63783.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 59202.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108593.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123937.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6852/10556 [00:00<00:00, 68519.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 64084.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6918/10556 [00:00<00:00, 69178.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 80944.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8177/10556 [00:00<00:00, 81765.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 88273.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9378/10556 [00:00<00:00, 93775.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 95475.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111197.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6900/10556 [00:00<00:00, 68995.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 70363.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114646.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6369/10556 [00:00<00:00, 63688.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 74410.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 103903.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6693/10556 [00:00<00:00, 65537.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 74936.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107669.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115575.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114074.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8013/10556 [00:00<00:00, 80129.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 78441.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6960/10556 [00:00<00:00, 69598.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 72005.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7557/10556 [00:00<00:00, 64945.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 62180.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9353/10556 [00:00<00:00, 93527.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 95976.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105762.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6264/10556 [00:00<00:00, 62639.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 58838.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9314/10556 [00:00<00:00, 93133.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 95068.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120953.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121554.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6791/10556 [00:00<00:00, 67344.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 63035.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7693/10556 [00:00<00:00, 68994.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 66916.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6655/10556 [00:00<00:00, 66543.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 66631.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7043/10556 [00:00<00:00, 70419.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 69138.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 31%|███       | 3267/10556 [00:00<00:00, 31361.24it/s] 77%|███████▋  | 8087/10556 [00:00<00:00, 35032.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 43641.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6683/10556 [00:00<00:00, 66822.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 66994.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|███▎      | 3461/10556 [00:00<00:00, 34609.54it/s] 87%|████████▋ | 9209/10556 [00:00<00:00, 39300.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 47102.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112355.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6569/10556 [00:00<00:00, 60380.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 58388.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6157/10556 [00:00<00:00, 60232.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 60955.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10329/10556 [00:00<00:00, 103281.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 103332.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8660/10556 [00:00<00:00, 85283.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 87121.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113888.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7591/10556 [00:00<00:00, 75350.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 77334.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8488/10556 [00:00<00:00, 84119.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 85608.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111893.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117740.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9786/10556 [00:00<00:00, 97856.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 98906.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7294/10556 [00:00<00:00, 72002.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 75074.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7969/10556 [00:00<00:00, 79685.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 80034.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6316/10556 [00:00<00:00, 63033.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 61847.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7266/10556 [00:00<00:00, 72654.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 80834.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118398.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118783.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117558.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119172.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114813.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115179.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117539.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118488.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6951/10556 [00:00<00:00, 69443.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 63587.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6838/10556 [00:00<00:00, 68377.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 63997.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120767.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7179/10556 [00:00<00:00, 70109.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 59960.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7877/10556 [00:00<00:00, 78766.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 79196.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5997/10556 [00:00<00:00, 58909.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 60022.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6888/10556 [00:00<00:00, 68878.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 66680.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7947/10556 [00:00<00:00, 79465.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 87132.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5771/10556 [00:00<00:00, 51801.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 69059.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120102.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189605.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181736.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181618.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183823.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181951.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129717.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10493/10556 [00:00<00:00, 104926.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 105047.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178227.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183733.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165414.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190618.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195063.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191001.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7349/10556 [00:00<00:00, 72650.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 86007.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190111.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7839/10556 [00:00<00:00, 78385.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 82940.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8036/10556 [00:00<00:00, 80357.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 81214.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125703.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139719.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145741.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141069.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146648.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145282.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145376.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144476.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138751.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146341.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145886.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146087.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146377.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144367.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144087.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144600.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145527.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130564.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145685.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150129.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148797.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144455.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144853.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144923.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147059.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145172.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145096.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144250.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143606.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127397.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9970/10556 [00:00<00:00, 99696.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 98713.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▎ | 8833/10556 [00:00<00:00, 88325.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 89926.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147896.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134117.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143061.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145049.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116930.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144586.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144946.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141111.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145428.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131643.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120491.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111489.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122783.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121821.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190455.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194854.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195767.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186300.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5857/10556 [00:00<00:00, 58561.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 68932.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10324/10556 [00:00<00:00, 103233.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 103693.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7729/10556 [00:00<00:00, 77283.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 90747.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 228527.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202988.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206324.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183162.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119771.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118171.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171105.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9140/10556 [00:00<00:00, 90136.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 84825.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206175.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202512.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201160.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190749.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195097.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175595.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169520.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182497.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176846.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171983.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173356.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184095.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193835.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194097.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172195.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179976.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190064.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135582.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144487.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140158.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144121.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146018.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141473.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146768.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141685.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147564.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148740.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140892.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147123.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146111.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140209.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144608.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146843.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146660.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147181.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139523.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147040.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121178.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9358/10556 [00:00<00:00, 93572.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 91699.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8570/10556 [00:00<00:00, 85691.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 85510.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145411.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141366.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178446.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197579.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160916.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190671.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182390.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189897.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184364.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191415.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191962.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186624.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185567.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183780.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187196.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189563.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191680.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177777.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190299.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180668.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193086.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191774.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182493.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148398.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████▏    | 5413/10556 [00:00<00:00, 54128.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 62132.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9304/10556 [00:00<00:00, 93038.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 95324.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6957/10556 [00:00<00:00, 67178.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 76258.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5831/10556 [00:00<00:00, 55076.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 53439.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5155/10556 [00:00<00:00, 51548.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 58398.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8550/10556 [00:00<00:00, 85059.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 85897.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10378/10556 [00:00<00:00, 103778.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 103628.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7023/10556 [00:00<00:00, 70224.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 80831.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7097/10556 [00:00<00:00, 70969.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 80086.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6892/10556 [00:00<00:00, 68915.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 62712.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▊   | 7244/10556 [00:00<00:00, 66336.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 75400.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7422/10556 [00:00<00:00, 74216.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 62644.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8185/10556 [00:00<00:00, 81845.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 83860.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7931/10556 [00:00<00:00, 79309.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 86129.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7060/10556 [00:00<00:00, 68051.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 64846.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6972/10556 [00:00<00:00, 66105.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 63541.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105039.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6116/10556 [00:00<00:00, 61157.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 66860.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7586/10556 [00:00<00:00, 75858.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 84342.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9808/10556 [00:00<00:00, 98079.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 95337.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6193/10556 [00:00<00:00, 61928.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 75756.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8226/10556 [00:00<00:00, 82253.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 81796.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7457/10556 [00:00<00:00, 74568.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 76030.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8546/10556 [00:00<00:00, 85457.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 90788.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116991.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6375/10556 [00:00<00:00, 63385.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 77242.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116174.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6782/10556 [00:00<00:00, 62856.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 67435.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5381/10556 [00:00<00:00, 51047.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 56299.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9088/10556 [00:00<00:00, 90788.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 93759.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6084/10556 [00:00<00:00, 58446.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 52457.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122013.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113224.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6313/10556 [00:00<00:00, 63129.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 60037.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119186.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8007/10556 [00:00<00:00, 80064.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 86905.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4987/10556 [00:00<00:00, 49867.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 71905.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6537/10556 [00:00<00:00, 65367.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 59933.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|███▉      | 4181/10556 [00:00<00:00, 41314.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 55608.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111676.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6311/10556 [00:00<00:00, 63104.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 67849.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107832.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8457/10556 [00:00<00:00, 84564.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 89709.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6487/10556 [00:00<00:00, 63180.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 72567.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6303/10556 [00:00<00:00, 63027.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 71763.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120323.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4434/10556 [00:00<00:00, 44337.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 50143.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5795/10556 [00:00<00:00, 57948.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 59853.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6889/10556 [00:00<00:00, 68889.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 79466.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5453/10556 [00:00<00:00, 54529.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 65828.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114117.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6090/10556 [00:00<00:00, 57215.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 58105.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9227/10556 [00:00<00:00, 92263.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 94924.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117787.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118863.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118670.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119428.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118727.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6086/10556 [00:00<00:00, 60847.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 62742.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5884/10556 [00:00<00:00, 57577.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 73103.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7869/10556 [00:00<00:00, 78683.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 80700.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▌| 10035/10556 [00:00<00:00, 100341.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 98006.39it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9279/10556 [00:00<00:00, 86150.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 73448.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112302.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6278/10556 [00:00<00:00, 62778.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 65485.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7833/10556 [00:00<00:00, 78326.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 77764.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▌| 10060/10556 [00:00<00:00, 100592.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 101019.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6227/10556 [00:00<00:00, 62269.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 72372.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119364.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 91640.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5498/10556 [00:00<00:00, 50732.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 55256.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|█████     | 5307/10556 [00:00<00:00, 52761.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 59779.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5471/10556 [00:00<00:00, 50328.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 52943.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6697/10556 [00:00<00:00, 66964.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 78548.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8632/10556 [00:00<00:00, 86318.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 86487.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7033/10556 [00:00<00:00, 70329.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 80529.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9208/10556 [00:00<00:00, 92076.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 99434.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187668.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200736.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7597/10556 [00:00<00:00, 75966.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 78426.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8545/10556 [00:00<00:00, 85442.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 85540.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144736.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176570.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177691.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199436.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107711.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179776.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184643.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186536.03it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.38025'}; time used = 0.593416690826416s
epoch 10: {'train_loss': '1.35944'}; time used = 0.6276018619537354s
epoch 15: {'train_loss': '1.31568'}; time used = 0.7907886505126953s
epoch 20: {'train_loss': '1.26769'}; time used = 0.34874629974365234s
epoch 25: {'train_loss': '1.18423'}; time used = 0.3755924701690674s
epoch 30: {'train_loss': '1.12027'}; time used = 0.3231465816497803s
epoch 35: {'train_loss': '1.04605'}; time used = 0.35340237617492676s
epoch 40: {'train_loss': '0.96110'}; time used = 0.33399176597595215s
epoch 45: {'train_loss': '0.89207'}; time used = 0.312896728515625s
epoch 50: {'train_loss': '0.80127'}; time used = 0.35317206382751465s
epoch 55: {'train_loss': '0.72968'}; time used = 0.38178157806396484s
epoch 60: {'train_loss': '0.65934'}; time used = 0.40732765197753906s
epoch 65: {'train_loss': '0.60449'}; time used = 0.41477251052856445s
epoch 70: {'train_loss': '0.56514'}; time used = 0.4033827781677246s
epoch 75: {'train_loss': '0.52229'}; time used = 0.39916324615478516s
epoch 80: {'train_loss': '0.49148'}; time used = 0.4269232749938965s
epoch 85: {'train_loss': '0.46029'}; time used = 0.4018383026123047s
epoch 90: {'train_loss': '0.44054'}; time used = 0.4514024257659912s
epoch 95: {'train_loss': '0.40694'}; time used = 0.4111189842224121s
epoch 100: {'train_loss': '0.39850'}; time used = 0.3336918354034424s
epoch 105: {'train_loss': '0.37064'}; time used = 0.3200356960296631s
epoch 110: {'train_loss': '0.35916'}; time used = 0.33539581298828125s
epoch 115: {'train_loss': '0.35286'}; time used = 0.33537960052490234s
epoch 120: {'train_loss': '0.36758'}; time used = 0.32422947883605957s
epoch 125: {'train_loss': '0.34991'}; time used = 0.6893792152404785s
epoch 130: {'train_loss': '0.31085'}; time used = 0.7078864574432373s
epoch 135: {'train_loss': '0.31131'}; time used = 0.7072081565856934s
epoch 140: {'train_loss': '0.30991'}; time used = 0.6427526473999023s
epoch 145: {'train_loss': '0.29148'}; time used = 0.744802713394165s
epoch 150: {'train_loss': '0.27441'}; time used = 0.7310178279876709s
epoch 155: {'train_loss': '0.27855'}; time used = 0.9451150894165039s
epoch 160: {'train_loss': '0.27192'}; time used = 0.7384853363037109s
epoch 165: {'train_loss': '0.26746'}; time used = 0.6441631317138672s
epoch 170: {'train_loss': '0.26121'}; time used = 0.7427096366882324s
epoch 175: {'train_loss': '0.25724'}; time used = 0.49193239212036133s
epoch 180: {'train_loss': '0.24800'}; time used = 0.6587841510772705s
epoch 185: {'train_loss': '0.25319'}; time used = 0.8304381370544434s
epoch 190: {'train_loss': '0.23287'}; time used = 0.46697282791137695s
epoch 195: {'train_loss': '0.24331'}; time used = 0.3910062313079834s
epoch 200: {'train_loss': '0.24808'}; time used = 0.32080578804016113s
epoch 205: {'train_loss': '0.22648'}; time used = 0.5609362125396729s
epoch 210: {'train_loss': '0.20979'}; time used = 0.401522159576416s
epoch 215: {'train_loss': '0.21049'}; time used = 0.4030468463897705s
epoch 220: {'train_loss': '0.20518'}; time used = 0.39560532569885254s
epoch 225: {'train_loss': '0.21171'}; time used = 0.41338300704956055s
epoch 230: {'train_loss': '0.21612'}; time used = 0.39995312690734863s
epoch 235: {'train_loss': '0.20366'}; time used = 0.46230292320251465s
epoch 240: {'train_loss': '0.21602'}; time used = 0.4746408462524414s
epoch 245: {'train_loss': '0.21029'}; time used = 0.43225860595703125s
epoch 250: {'train_loss': '0.19613'}; time used = 0.4727177619934082s
epoch 255: {'train_loss': '0.21324'}; time used = 0.432281494140625s
epoch 260: {'train_loss': '0.18946'}; time used = 0.4124772548675537s
epoch 265: {'train_loss': '0.19255'}; time used = 0.470231294631958s
epoch 270: {'train_loss': '0.18475'}; time used = 0.2943918704986572s
epoch 275: {'train_loss': '0.19382'}; time used = 0.32981252670288086s
epoch 280: {'train_loss': '0.18015'}; time used = 0.3183252811431885s
epoch 285: {'train_loss': '0.19690'}; time used = 0.37369370460510254s
epoch 290: {'train_loss': '0.18012'}; time used = 0.4009277820587158s
epoch 295: {'train_loss': '0.17659'}; time used = 0.39314818382263184s
epoch 300: {'train_loss': '0.18051'}; time used = 0.39935731887817383s
epoch 305: {'train_loss': '0.16929'}; time used = 0.5112049579620361s
epoch 310: {'train_loss': '0.18129'}; time used = 0.3698916435241699s
epoch 315: {'train_loss': '0.18312'}; time used = 0.31558680534362793s
epoch 320: {'train_loss': '0.17159'}; time used = 0.31842732429504395s
epoch 325: {'train_loss': '0.17007'}; time used = 0.3248565196990967s
epoch 330: {'train_loss': '0.17601'}; time used = 0.44785213470458984s
epoch 335: {'train_loss': '0.16657'}; time used = 0.8623015880584717s
epoch 340: {'train_loss': '0.17107'}; time used = 0.773054838180542s
epoch 345: {'train_loss': '0.16460'}; time used = 0.8420848846435547s
epoch 350: {'train_loss': '0.16157'}; time used = 0.7134206295013428s
epoch 355: {'train_loss': '0.16145'}; time used = 0.6794118881225586s
epoch 360: {'train_loss': '0.15505'}; time used = 0.8159744739532471s
epoch 365: {'train_loss': '0.17134'}; time used = 0.6449425220489502s
epoch 370: {'train_loss': '0.15455'}; time used = 0.8349976539611816s
epoch 375: {'train_loss': '0.16171'}; time used = 0.6753644943237305s
epoch 380: {'train_loss': '0.14338'}; time used = 0.8522663116455078s
epoch 385: {'train_loss': '0.15793'}; time used = 0.606910228729248s
epoch 390: {'train_loss': '0.15629'}; time used = 0.6705989837646484s
epoch 395: {'train_loss': '0.14858'}; time used = 0.7413785457611084s
epoch 400: {'train_loss': '0.14409'}; time used = 0.7043554782867432s
epoch 405: {'train_loss': '0.14292'}; time used = 0.8523058891296387s
epoch 410: {'train_loss': '0.14833'}; time used = 0.5138580799102783s
epoch 415: {'train_loss': '0.15528'}; time used = 0.3924531936645508s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 48.958911657333374.
Training classifier using 20.00% nodes...
{'micro': 0.7761882787263497, 'macro': 0.7536306000738658, 'samples': 0.7761882787263498, 'weighted': 0.7721927831998724}
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5919/10556 [00:00<00:00, 59186.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 65125.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|████▎     | 4616/10556 [00:00<00:00, 46156.41it/s] 98%|█████████▊| 10342/10556 [00:00<00:00, 48293.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 50332.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7892/10556 [00:00<00:00, 70680.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 68215.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6462/10556 [00:00<00:00, 57350.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 66881.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112509.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6032/10556 [00:00<00:00, 60129.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 76365.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10449/10556 [00:00<00:00, 104487.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 104345.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 5010/10556 [00:00<00:00, 50099.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 70591.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5438/10556 [00:00<00:00, 51937.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 55835.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7121/10556 [00:00<00:00, 71204.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 74304.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120888.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10012/10556 [00:00<00:00, 100112.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 100830.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6382/10556 [00:00<00:00, 63816.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 77303.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120581.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7052/10556 [00:00<00:00, 68574.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 64971.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7976/10556 [00:00<00:00, 74788.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 72651.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▎ | 8840/10556 [00:00<00:00, 83692.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 58142.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106878.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106038.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6461/10556 [00:00<00:00, 62308.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 73864.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121019.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9229/10556 [00:00<00:00, 92286.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 94922.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10305/10556 [00:00<00:00, 103048.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 103258.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10323/10556 [00:00<00:00, 103227.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 100538.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▎  | 7770/10556 [00:00<00:00, 77698.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 72851.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9509/10556 [00:00<00:00, 95083.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 96763.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6365/10556 [00:00<00:00, 63649.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 59167.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5731/10556 [00:00<00:00, 57306.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 56671.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120695.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121500.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10420/10556 [00:00<00:00, 101722.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 99441.36it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6555/10556 [00:00<00:00, 65548.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 79531.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120717.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7450/10556 [00:00<00:00, 74499.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 84083.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6366/10556 [00:00<00:00, 60939.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 58871.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7602/10556 [00:00<00:00, 76019.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 85048.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10210/10556 [00:00<00:00, 102092.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 102122.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10271/10556 [00:00<00:00, 102702.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 102872.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|███▊      | 3996/10556 [00:00<00:00, 36775.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 62951.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7321/10556 [00:00<00:00, 73204.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 82362.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121481.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117591.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9623/10556 [00:00<00:00, 96229.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 97882.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116869.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9961/10556 [00:00<00:00, 99607.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 100490.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|███▏      | 3411/10556 [00:00<00:00, 33126.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 60163.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10331/10556 [00:00<00:00, 103306.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 103147.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115202.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114227.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115868.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▎  | 7768/10556 [00:00<00:00, 70963.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 70610.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9376/10556 [00:00<00:00, 93753.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 91386.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9861/10556 [00:00<00:00, 98605.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 99294.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121077.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126877.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106584.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6306/10556 [00:00<00:00, 62917.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 60687.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████▏    | 5429/10556 [00:00<00:00, 54288.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 61237.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5945/10556 [00:00<00:00, 50333.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 62302.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9206/10556 [00:00<00:00, 92059.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 95102.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107921.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123960.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116544.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108125.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9945/10556 [00:00<00:00, 99445.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 99909.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9610/10556 [00:00<00:00, 91047.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 93164.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111771.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6374/10556 [00:00<00:00, 63738.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 70470.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8036/10556 [00:00<00:00, 74217.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 74344.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8804/10556 [00:00<00:00, 88034.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 78152.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5472/10556 [00:00<00:00, 54718.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 72340.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5037/10556 [00:00<00:00, 50365.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 67713.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115163.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6143/10556 [00:00<00:00, 61426.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 78120.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164406.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190362.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194125.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190046.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183907.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 163942.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139543.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106324.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▎| 9887/10556 [00:00<00:00, 98862.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 99504.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164246.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 161159.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187880.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188095.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195027.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200705.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177198.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118551.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199016.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186222.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190631.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195846.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191794.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190997.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189692.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188593.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194623.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186673.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192156.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185197.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187437.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187537.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196084.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177521.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182102.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187583.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193066.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191572.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180756.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186201.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195931.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191567.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191246.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194728.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187161.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197732.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199262.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199698.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191991.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203808.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184957.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205720.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190450.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184210.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191046.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200848.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198016.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188443.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198541.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197829.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190555.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190016.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191537.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188274.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196780.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192263.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197011.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184170.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184051.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183990.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197244.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184715.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▊  | 8301/10556 [00:00<00:00, 82998.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 77791.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105714.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149626.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185767.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208990.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204330.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210695.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189566.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205421.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200308.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187049.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189939.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186871.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178863.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124112.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179148.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199127.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182306.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187531.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186319.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190044.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187807.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190238.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119708.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 163116.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182456.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186149.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180479.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183033.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188094.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179762.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189095.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186457.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201682.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185988.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189556.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189078.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188330.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192215.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159337.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6397/10556 [00:00<00:00, 63968.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 62017.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5797/10556 [00:00<00:00, 57969.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 67393.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120155.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6984/10556 [00:00<00:00, 69835.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 73089.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9594/10556 [00:00<00:00, 95936.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 84934.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6822/10556 [00:00<00:00, 68216.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 74094.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6054/10556 [00:00<00:00, 56226.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 61980.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9547/10556 [00:00<00:00, 95466.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 96681.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████      | 4277/10556 [00:00<00:00, 41524.11it/s] 96%|█████████▌| 10084/10556 [00:00<00:00, 45404.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 48863.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7454/10556 [00:00<00:00, 74537.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 83758.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114257.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118933.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6796/10556 [00:00<00:00, 64842.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 62871.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6180/10556 [00:00<00:00, 61796.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 66973.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6383/10556 [00:00<00:00, 63825.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 71554.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108192.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5730/10556 [00:00<00:00, 56837.29it/s] 95%|█████████▍| 10009/10556 [00:00<00:00, 51137.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 48120.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7391/10556 [00:00<00:00, 70022.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 66972.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113683.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6802/10556 [00:00<00:00, 65614.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 60089.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6074/10556 [00:00<00:00, 57944.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 59785.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6635/10556 [00:00<00:00, 66349.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 74256.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10241/10556 [00:00<00:00, 102409.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 102796.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5600/10556 [00:00<00:00, 55997.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 73323.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7468/10556 [00:00<00:00, 66846.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 64588.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10024/10556 [00:00<00:00, 100236.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 100832.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9159/10556 [00:00<00:00, 91587.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 94315.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6367/10556 [00:00<00:00, 63669.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 59120.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6202/10556 [00:00<00:00, 59432.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 72468.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6145/10556 [00:00<00:00, 59901.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 59975.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108562.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117914.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117088.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117127.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118289.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6496/10556 [00:00<00:00, 64286.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 67393.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106502.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5528/10556 [00:00<00:00, 55275.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 66168.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8896/10556 [00:00<00:00, 88956.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 86309.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117740.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113027.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10158/10556 [00:00<00:00, 101572.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 99600.19it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10004/10556 [00:00<00:00, 100036.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 100755.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116498.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107492.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8981/10556 [00:00<00:00, 89808.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 92983.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9182/10556 [00:00<00:00, 91815.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 94277.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117196.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10214/10556 [00:00<00:00, 102133.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 102471.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116621.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118233.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116986.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9330/10556 [00:00<00:00, 93292.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 95633.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7084/10556 [00:00<00:00, 68322.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 65436.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6326/10556 [00:00<00:00, 60881.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 60730.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9433/10556 [00:00<00:00, 94326.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 96680.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6901/10556 [00:00<00:00, 69006.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 76788.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8524/10556 [00:00<00:00, 85235.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 85823.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5920/10556 [00:00<00:00, 53732.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 69796.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10353/10556 [00:00<00:00, 103526.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 103543.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113001.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109762.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6372/10556 [00:00<00:00, 63717.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 59892.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9928/10556 [00:00<00:00, 99275.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 100071.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114100.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118283.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118422.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116916.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113231.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8892/10556 [00:00<00:00, 88917.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 92863.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114997.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7023/10556 [00:00<00:00, 70224.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 75335.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5675/10556 [00:00<00:00, 56747.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 54490.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112018.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115116.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6145/10556 [00:00<00:00, 59019.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 67669.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7727/10556 [00:00<00:00, 77266.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 77441.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5915/10556 [00:00<00:00, 59144.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 57711.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7174/10556 [00:00<00:00, 71739.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 78139.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106020.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113589.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6200/10556 [00:00<00:00, 61999.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 57498.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|████      | 4235/10556 [00:00<00:00, 42346.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 61911.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|████▍     | 4724/10556 [00:00<00:00, 44655.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 55714.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117621.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117594.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119218.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5028/10556 [00:00<00:00, 50277.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 55190.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5363/10556 [00:00<00:00, 53329.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 56027.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7588/10556 [00:00<00:00, 75873.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 65547.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8689/10556 [00:00<00:00, 86883.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 91121.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116345.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113212.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6738/10556 [00:00<00:00, 67375.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 52247.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5888/10556 [00:00<00:00, 58877.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 75677.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114201.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6080/10556 [00:00<00:00, 60799.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 58713.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9483/10556 [00:00<00:00, 88152.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 84430.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6340/10556 [00:00<00:00, 62452.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 60642.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6990/10556 [00:00<00:00, 69896.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 74293.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10089/10556 [00:00<00:00, 91534.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 89040.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111878.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5547/10556 [00:00<00:00, 55466.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 72525.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5057/10556 [00:00<00:00, 50568.84it/s] 80%|████████  | 8447/10556 [00:00<00:00, 44067.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 48375.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10331/10556 [00:00<00:00, 103307.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 102873.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6193/10556 [00:00<00:00, 61927.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 69472.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109146.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9568/10556 [00:00<00:00, 95675.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 97032.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112893.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4828/10556 [00:00<00:00, 47034.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 52588.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10295/10556 [00:00<00:00, 102947.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 96801.08it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114824.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6303/10556 [00:00<00:00, 60988.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 58672.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113706.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117311.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5727/10556 [00:00<00:00, 57269.51it/s] 99%|█████████▉| 10437/10556 [00:00<00:00, 53553.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 51816.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▎| 9895/10556 [00:00<00:00, 98949.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 99809.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6676/10556 [00:00<00:00, 66758.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 75490.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118739.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7577/10556 [00:00<00:00, 75769.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 82969.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113291.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6412/10556 [00:00<00:00, 62371.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 76435.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117395.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 5013/10556 [00:00<00:00, 48786.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 52969.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6048/10556 [00:00<00:00, 60475.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 60401.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9595/10556 [00:00<00:00, 95942.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 97142.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5822/10556 [00:00<00:00, 58216.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 54388.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113461.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7048/10556 [00:00<00:00, 70476.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 81659.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10417/10556 [00:00<00:00, 104167.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 104148.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117198.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7087/10556 [00:00<00:00, 65817.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 76442.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8898/10556 [00:00<00:00, 88974.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 92054.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107153.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108600.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8342/10556 [00:00<00:00, 83417.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 88509.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████▏     | 4371/10556 [00:00<00:00, 43709.83it/s]100%|█████████▉| 10548/10556 [00:00<00:00, 47911.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 49795.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|███▌      | 3709/10556 [00:00<00:00, 37087.82it/s] 90%|█████████ | 9526/10556 [00:00<00:00, 41611.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 50471.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6017/10556 [00:00<00:00, 53314.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 49995.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████▏    | 5425/10556 [00:00<00:00, 50461.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 64654.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6448/10556 [00:00<00:00, 62868.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 63379.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107410.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8324/10556 [00:00<00:00, 83237.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 88120.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▊   | 7236/10556 [00:00<00:00, 72359.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 65048.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7417/10556 [00:00<00:00, 74169.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 70024.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9266/10556 [00:00<00:00, 92654.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 94595.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8277/10556 [00:00<00:00, 82764.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 88555.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10270/10556 [00:00<00:00, 102694.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 102636.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7707/10556 [00:00<00:00, 76508.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 79992.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7888/10556 [00:00<00:00, 78879.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 85467.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107029.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117249.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116037.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115633.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116915.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114702.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117903.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117538.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8352/10556 [00:00<00:00, 83257.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 84358.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7149/10556 [00:00<00:00, 71485.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 77279.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7886/10556 [00:00<00:00, 72128.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 65599.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110155.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119459.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117502.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119303.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118626.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118128.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116777.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5985/10556 [00:00<00:00, 59840.21it/s] 97%|█████████▋| 10223/10556 [00:00<00:00, 52299.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 49398.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5636/10556 [00:00<00:00, 56358.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 53848.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6215/10556 [00:00<00:00, 62146.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 76054.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118311.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6699/10556 [00:00<00:00, 66989.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 75515.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10389/10556 [00:00<00:00, 103881.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 103934.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8366/10556 [00:00<00:00, 83655.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 89110.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112761.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7370/10556 [00:00<00:00, 72085.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 68266.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7583/10556 [00:00<00:00, 75757.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 76006.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5742/10556 [00:00<00:00, 57416.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 74879.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7385/10556 [00:00<00:00, 73846.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 78078.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5725/10556 [00:00<00:00, 57249.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 57140.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7755/10556 [00:00<00:00, 77545.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 80696.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124697.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7346/10556 [00:00<00:00, 73458.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 83022.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117796.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6383/10556 [00:00<00:00, 63825.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 77736.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6847/10556 [00:00<00:00, 68469.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 69933.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5989/10556 [00:00<00:00, 59887.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 59537.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5078/10556 [00:00<00:00, 49343.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 50878.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6113/10556 [00:00<00:00, 57408.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 72689.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119022.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116166.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7297/10556 [00:00<00:00, 72968.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 83071.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117930.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6548/10556 [00:00<00:00, 65478.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 60928.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 9008/10556 [00:00<00:00, 90075.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 93374.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5534/10556 [00:00<00:00, 55337.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 57724.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 9002/10556 [00:00<00:00, 90019.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 93315.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6814/10556 [00:00<00:00, 68136.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 79807.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6626/10556 [00:00<00:00, 66255.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 68582.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113673.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7830/10556 [00:00<00:00, 78295.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 85609.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6029/10556 [00:00<00:00, 60289.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 58700.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6370/10556 [00:00<00:00, 61428.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 64399.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5794/10556 [00:00<00:00, 57936.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 58943.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 9025/10556 [00:00<00:00, 90247.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 93352.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7163/10556 [00:00<00:00, 71623.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 81476.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118496.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10244/10556 [00:00<00:00, 102434.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 102374.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114102.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9053/10556 [00:00<00:00, 90527.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 79947.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6838/10556 [00:00<00:00, 67946.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 64938.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9217/10556 [00:00<00:00, 92169.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 88085.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9310/10556 [00:00<00:00, 88619.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 89666.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4512/10556 [00:00<00:00, 43530.87it/s] 95%|█████████▌| 10070/10556 [00:00<00:00, 46558.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 50672.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7733/10556 [00:00<00:00, 77328.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 70429.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117329.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7101/10556 [00:00<00:00, 69772.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 73220.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6892/10556 [00:00<00:00, 68706.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 73298.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8795/10556 [00:00<00:00, 87946.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 79145.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 9017/10556 [00:00<00:00, 90167.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 93464.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6558/10556 [00:00<00:00, 65575.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 72344.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114203.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7100/10556 [00:00<00:00, 70994.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 76643.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6577/10556 [00:00<00:00, 63938.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 60025.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113661.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115547.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112611.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10110/10556 [00:00<00:00, 101099.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 101539.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7165/10556 [00:00<00:00, 71212.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 64140.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115491.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128230.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176031.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174784.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159820.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191286.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173044.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194746.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187570.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127098.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129878.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184944.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189346.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191922.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187892.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199178.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195896.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132439.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145468.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8648/10556 [00:00<00:00, 86475.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 84274.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117268.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214232.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193476.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196959.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196161.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197102.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179248.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191720.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204184.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201142.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 230877.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 230100.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205831.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191448.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188992.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192058.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176543.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188595.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175259.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110870.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197291.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200279.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205430.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197159.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191548.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201092.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198088.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193630.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123367.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169616.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206233.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 224337.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 233088.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205995.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203992.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196950.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196124.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198697.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201891.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203961.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204043.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201246.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200742.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196846.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198743.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204977.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204379.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205748.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205096.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204271.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195752.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200288.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202451.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203909.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204808.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206624.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203571.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207302.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203085.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203071.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202575.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192032.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 234122.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200875.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193433.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203984.65it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.29304'}; time used = 0.8817987442016602s
epoch 10: {'train_loss': '1.10328'}; time used = 0.7463629245758057s
epoch 15: {'train_loss': '0.83492'}; time used = 0.7338733673095703s
epoch 20: {'train_loss': '0.67029'}; time used = 0.7195091247558594s
epoch 25: {'train_loss': '0.51839'}; time used = 0.6516907215118408s
epoch 30: {'train_loss': '0.44469'}; time used = 0.6908762454986572s
epoch 35: {'train_loss': '0.42984'}; time used = 0.7181813716888428s
epoch 40: {'train_loss': '0.39265'}; time used = 0.6786668300628662s
epoch 45: {'train_loss': '0.33787'}; time used = 0.6393411159515381s
epoch 50: {'train_loss': '0.31060'}; time used = 0.6043193340301514s
epoch 55: {'train_loss': '0.28332'}; time used = 0.5729727745056152s
epoch 60: {'train_loss': '0.25005'}; time used = 0.7800965309143066s
epoch 65: {'train_loss': '0.21886'}; time used = 0.5508122444152832s
epoch 70: {'train_loss': '0.23138'}; time used = 0.756096601486206s
epoch 75: {'train_loss': '0.21777'}; time used = 0.5599501132965088s
epoch 80: {'train_loss': '0.24539'}; time used = 0.34051966667175293s
epoch 85: {'train_loss': '0.21984'}; time used = 0.43869924545288086s
epoch 90: {'train_loss': '0.19488'}; time used = 0.3459281921386719s
epoch 95: {'train_loss': '0.45791'}; time used = 0.3070366382598877s
epoch 100: {'train_loss': '0.79414'}; time used = 0.307157039642334s
epoch 105: {'train_loss': '0.49865'}; time used = 0.3220069408416748s
epoch 110: {'train_loss': '0.39359'}; time used = 0.31725549697875977s
epoch 115: {'train_loss': '0.32457'}; time used = 0.3120861053466797s
epoch 120: {'train_loss': '0.36900'}; time used = 0.30223846435546875s
epoch 125: {'train_loss': '0.28688'}; time used = 0.3001885414123535s
epoch 130: {'train_loss': '0.27357'}; time used = 0.30582547187805176s
epoch 135: {'train_loss': '0.21049'}; time used = 0.3028299808502197s
epoch 140: {'train_loss': '0.19535'}; time used = 0.3026881217956543s
epoch 145: {'train_loss': '0.16121'}; time used = 0.3965919017791748s
epoch 150: {'train_loss': '0.15293'}; time used = 0.37911105155944824s
epoch 155: {'train_loss': '0.14463'}; time used = 0.30312252044677734s
epoch 160: {'train_loss': '0.14853'}; time used = 0.3657493591308594s
epoch 165: {'train_loss': '0.12945'}; time used = 0.3192265033721924s
epoch 170: {'train_loss': '0.13303'}; time used = 0.36038947105407715s
epoch 175: {'train_loss': '0.13276'}; time used = 0.3271801471710205s
epoch 180: {'train_loss': '0.15540'}; time used = 0.3169388771057129s
epoch 185: {'train_loss': '0.21526'}; time used = 0.4477579593658447s
epoch 190: {'train_loss': '0.15889'}; time used = 0.7509078979492188s
epoch 195: {'train_loss': '0.14749'}; time used = 0.7915692329406738s
epoch 200: {'train_loss': '0.13252'}; time used = 0.7344980239868164s
epoch 205: {'train_loss': '0.13270'}; time used = 0.9176084995269775s
epoch 210: {'train_loss': '0.12357'}; time used = 0.7321975231170654s
epoch 215: {'train_loss': '0.13762'}; time used = 0.8016672134399414s
epoch 220: {'train_loss': '0.11250'}; time used = 0.5713002681732178s
epoch 225: {'train_loss': '0.11381'}; time used = 0.6687073707580566s
epoch 230: {'train_loss': '0.12199'}; time used = 0.6132738590240479s
epoch 235: {'train_loss': '0.12020'}; time used = 0.5644285678863525s
epoch 240: {'train_loss': '0.12130'}; time used = 0.726158618927002s
epoch 245: {'train_loss': '0.11856'}; time used = 0.6883602142333984s
epoch 250: {'train_loss': '0.10783'}; time used = 0.618699312210083s
epoch 255: {'train_loss': '0.11984'}; time used = 0.5393073558807373s
epoch 260: {'train_loss': '0.18508'}; time used = 0.7499260902404785s
epoch 265: {'train_loss': '0.18050'}; time used = 0.7576658725738525s
epoch 270: {'train_loss': '0.14992'}; time used = 0.8704335689544678s
epoch 275: {'train_loss': '0.15001'}; time used = 0.8292300701141357s
epoch 280: {'train_loss': '0.12457'}; time used = 0.6757931709289551s
epoch 285: {'train_loss': '0.12695'}; time used = 0.8246912956237793s
epoch 290: {'train_loss': '0.11352'}; time used = 0.8010547161102295s
epoch 295: {'train_loss': '0.09821'}; time used = 0.7031614780426025s
epoch 300: {'train_loss': '0.10470'}; time used = 0.7265498638153076s
epoch 305: {'train_loss': '0.09200'}; time used = 0.6164369583129883s
epoch 310: {'train_loss': '0.10314'}; time used = 0.781818151473999s
epoch 315: {'train_loss': '0.10950'}; time used = 0.6868422031402588s
epoch 320: {'train_loss': '0.10964'}; time used = 0.6657607555389404s
epoch 325: {'train_loss': '0.09875'}; time used = 1.0733399391174316s
epoch 330: {'train_loss': '0.10083'}; time used = 0.7493867874145508s
epoch 335: {'train_loss': '0.09454'}; time used = 0.6700265407562256s
epoch 340: {'train_loss': '0.09460'}; time used = 0.49220967292785645s
epoch 345: {'train_loss': '0.09769'}; time used = 0.6652336120605469s
epoch 350: {'train_loss': '0.10400'}; time used = 0.48951220512390137s
epoch 355: {'train_loss': '0.08971'}; time used = 0.7894861698150635s
epoch 360: {'train_loss': '0.08379'}; time used = 0.6011204719543457s
epoch 365: {'train_loss': '0.09923'}; time used = 0.8529658317565918s
epoch 370: {'train_loss': '0.09631'}; time used = 0.6322996616363525s
epoch 375: {'train_loss': '0.09305'}; time used = 0.8361351490020752s
epoch 380: {'train_loss': '0.09690'}; time used = 0.6570982933044434s
epoch 385: {'train_loss': '0.13063'}; time used = 0.7538745403289795s
epoch 390: {'train_loss': '0.14308'}; time used = 0.8663082122802734s
epoch 395: {'train_loss': '0.32286'}; time used = 0.6124305725097656s
epoch 400: {'train_loss': '0.24826'}; time used = 0.8566670417785645s
epoch 405: {'train_loss': '0.16511'}; time used = 0.7377688884735107s
epoch 410: {'train_loss': '0.14622'}; time used = 0.7350270748138428s
epoch 415: {'train_loss': '0.13198'}; time used = 0.6415221691131592s
epoch 420: {'train_loss': '0.10622'}; time used = 0.36392879486083984s
epoch 425: {'train_loss': '0.12345'}; time used = 0.3722853660583496s
epoch 430: {'train_loss': '0.10048'}; time used = 0.30771899223327637s
epoch 435: {'train_loss': '0.09891'}; time used = 0.4589731693267822s
epoch 440: {'train_loss': '0.10467'}; time used = 0.2976827621459961s
epoch 445: {'train_loss': '0.15851'}; time used = 0.30518364906311035s
epoch 450: {'train_loss': '0.15782'}; time used = 0.2932167053222656s
epoch 455: {'train_loss': '0.17223'}; time used = 0.4049222469329834s
epoch 460: {'train_loss': '0.10090'}; time used = 0.29477500915527344s
epoch 465: {'train_loss': '0.10548'}; time used = 0.34000611305236816s
epoch 470: {'train_loss': '0.09717'}; time used = 0.2793424129486084s
epoch 475: {'train_loss': '0.08776'}; time used = 0.2934892177581787s
epoch 480: {'train_loss': '0.08070'}; time used = 0.2950725555419922s
epoch 485: {'train_loss': '0.07871'}; time used = 0.29018449783325195s
epoch 490: {'train_loss': '0.08004'}; time used = 0.301743745803833s
epoch 495: {'train_loss': '0.08858'}; time used = 0.28801393508911133s
epoch 500: {'train_loss': '0.07353'}; time used = 0.2852921485900879s
Finished training. Time used = 60.57855010032654.
Training classifier using 20.00% nodes...
{'micro': 0.7425011536686663, 'macro': 0.6980965933474408, 'samples': 0.7425011536686663, 'weighted': 0.7347583693801981}

Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 226661.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187920.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|███████▉  | 8427/10556 [00:00<00:00, 84268.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 92476.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8550/10556 [00:00<00:00, 85497.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 85384.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9916/10556 [00:00<00:00, 99159.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 101717.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171683.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172180.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184137.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109480.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202835.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182488.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193235.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164888.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183422.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181098.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125501.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162530.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182834.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185461.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181490.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183285.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183469.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182245.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178423.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180682.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179373.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183562.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181013.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182779.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182334.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169287.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182214.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170557.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181539.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180409.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180812.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181847.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184505.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181705.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175757.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179743.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181821.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8940/10556 [00:00<00:00, 89395.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 86898.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150903.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181872.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171278.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121947.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173629.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179167.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166501.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181595.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126388.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107807.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118877.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116389.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120642.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105577.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121308.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121829.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152466.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132845.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125052.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142230.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142088.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150976.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141159.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136423.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124055.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139941.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144532.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141975.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145568.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142206.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8085/10556 [00:00<00:00, 80847.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 82197.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8317/10556 [00:00<00:00, 83161.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 83932.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8193/10556 [00:00<00:00, 81928.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 83052.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7557/10556 [00:00<00:00, 75567.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 83035.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9744/10556 [00:00<00:00, 97436.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 96279.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8221/10556 [00:00<00:00, 82206.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 83081.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▊  | 8302/10556 [00:00<00:00, 83018.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 83839.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133576.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7864/10556 [00:00<00:00, 77291.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 73582.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135344.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7602/10556 [00:00<00:00, 71945.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 58903.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122717.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7966/10556 [00:00<00:00, 79657.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 87433.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▎  | 7772/10556 [00:00<00:00, 77716.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 86336.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109454.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7941/10556 [00:00<00:00, 79404.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 86805.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▋| 10182/10556 [00:00<00:00, 96446.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 89232.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|████▍     | 4698/10556 [00:00<00:00, 46977.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 53203.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6766/10556 [00:00<00:00, 67659.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 63529.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6401/10556 [00:00<00:00, 63730.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 64463.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112245.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105852.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106136.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122229.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118557.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5957/10556 [00:00<00:00, 56079.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 71305.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112039.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5943/10556 [00:00<00:00, 57366.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 70520.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109978.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110192.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9949/10556 [00:00<00:00, 99483.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 100155.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6760/10556 [00:00<00:00, 64522.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 63903.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113614.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10334/10556 [00:00<00:00, 103334.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 103431.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8663/10556 [00:00<00:00, 86628.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 91626.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122901.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▋| 10161/10556 [00:00<00:00, 101608.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 102110.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120350.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9865/10556 [00:00<00:00, 98649.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 99879.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120289.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120794.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9109/10556 [00:00<00:00, 91086.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 94265.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9117/10556 [00:00<00:00, 91162.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 94529.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121244.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122656.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123186.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123832.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7589/10556 [00:00<00:00, 75876.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 84653.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7451/10556 [00:00<00:00, 74508.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 66885.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6459/10556 [00:00<00:00, 64588.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 61446.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6760/10556 [00:00<00:00, 65136.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 64442.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5775/10556 [00:00<00:00, 51665.67it/s] 73%|███████▎  | 7753/10556 [00:00<00:00, 34105.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 43411.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115082.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8963/10556 [00:00<00:00, 89623.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 93489.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6216/10556 [00:00<00:00, 62156.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 77314.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9839/10556 [00:00<00:00, 98389.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 99753.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▎    | 5660/10556 [00:00<00:00, 52499.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 65937.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5259/10556 [00:00<00:00, 49245.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 55899.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8990/10556 [00:00<00:00, 89895.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 93803.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130407.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128917.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8034/10556 [00:00<00:00, 76840.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 79412.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9255/10556 [00:00<00:00, 92547.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 95063.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6722/10556 [00:00<00:00, 67219.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 69391.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████▏ | 8598/10556 [00:00<00:00, 85979.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 85973.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114219.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8221/10556 [00:00<00:00, 82205.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 84637.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7652/10556 [00:00<00:00, 69360.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 68678.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8341/10556 [00:00<00:00, 83405.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 85179.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9562/10556 [00:00<00:00, 95615.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 97279.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8153/10556 [00:00<00:00, 81529.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 69322.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9101/10556 [00:00<00:00, 91007.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 90842.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5447/10556 [00:00<00:00, 54469.14it/s] 94%|█████████▍| 9942/10556 [00:00<00:00, 47992.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 46084.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 28%|██▊       | 3005/10556 [00:00<00:00, 27293.13it/s] 88%|████████▊ | 9261/10556 [00:00<00:00, 32847.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 41492.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████      | 4300/10556 [00:00<00:00, 39180.96it/s] 59%|█████▉    | 6277/10556 [00:00<00:00, 27956.38it/s] 87%|████████▋ | 9235/10556 [00:00<00:00, 28423.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 30386.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▊  | 8297/10556 [00:00<00:00, 82968.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 88777.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121881.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9520/10556 [00:00<00:00, 95197.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 97320.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6074/10556 [00:00<00:00, 60737.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 53023.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10280/10556 [00:00<00:00, 102792.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 97791.87it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8976/10556 [00:00<00:00, 89755.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 93121.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9929/10556 [00:00<00:00, 99283.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 99783.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5519/10556 [00:00<00:00, 49514.05it/s] 99%|█████████▊| 10422/10556 [00:00<00:00, 49367.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 49074.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9157/10556 [00:00<00:00, 91566.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 94137.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111763.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▊  | 8302/10556 [00:00<00:00, 74272.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 71429.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115300.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116270.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113196.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9415/10556 [00:00<00:00, 87158.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 89021.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116320.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6695/10556 [00:00<00:00, 66946.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 53725.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5981/10556 [00:00<00:00, 59809.06it/s] 96%|█████████▌| 10130/10556 [00:00<00:00, 50651.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 47272.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5982/10556 [00:00<00:00, 55069.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 53430.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10398/10556 [00:00<00:00, 103973.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 103791.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105536.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118245.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10321/10556 [00:00<00:00, 103201.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 103302.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7090/10556 [00:00<00:00, 69569.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 73206.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5745/10556 [00:00<00:00, 57448.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 69454.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116126.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 104126.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109013.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10401/10556 [00:00<00:00, 104009.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 103944.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9542/10556 [00:00<00:00, 95413.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 96051.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120118.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107996.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111513.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10451/10556 [00:00<00:00, 100204.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 100118.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6870/10556 [00:00<00:00, 68696.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 63667.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6688/10556 [00:00<00:00, 65526.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 63819.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9409/10556 [00:00<00:00, 94087.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 96045.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6906/10556 [00:00<00:00, 69056.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 64991.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6871/10556 [00:00<00:00, 68709.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 80946.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112200.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8331/10556 [00:00<00:00, 83303.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 88250.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111197.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5231/10556 [00:00<00:00, 52306.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 65081.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6560/10556 [00:00<00:00, 65594.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 78716.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6478/10556 [00:00<00:00, 59661.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 59299.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114921.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7678/10556 [00:00<00:00, 76779.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 84443.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114009.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10532/10556 [00:00<00:00, 105316.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 104991.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 7007/10556 [00:00<00:00, 70068.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 80340.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8955/10556 [00:00<00:00, 89544.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 93552.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9354/10556 [00:00<00:00, 93539.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 95302.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106171.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111404.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110618.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114941.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6545/10556 [00:00<00:00, 65448.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 76987.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8251/10556 [00:00<00:00, 75206.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 76611.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10244/10556 [00:00<00:00, 102435.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 102569.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9524/10556 [00:00<00:00, 95233.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 96644.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8621/10556 [00:00<00:00, 86072.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 76943.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105540.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8665/10556 [00:00<00:00, 86644.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 90656.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108542.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7345/10556 [00:00<00:00, 73446.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 83683.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 98533.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123120.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7301/10556 [00:00<00:00, 73005.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 83643.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8496/10556 [00:00<00:00, 84955.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 85121.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122042.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 9017/10556 [00:00<00:00, 90164.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 93763.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5837/10556 [00:00<00:00, 58365.46it/s] 95%|█████████▌| 10043/10556 [00:00<00:00, 51814.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 48638.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6055/10556 [00:00<00:00, 56511.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 55174.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120523.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4983/10556 [00:00<00:00, 43181.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 57800.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121331.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8008/10556 [00:00<00:00, 80076.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 86874.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4536/10556 [00:00<00:00, 45357.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 68292.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9130/10556 [00:00<00:00, 91299.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 94227.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112317.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121291.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128354.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8995/10556 [00:00<00:00, 89945.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 93839.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4817/10556 [00:00<00:00, 48168.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 71403.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120709.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113996.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105896.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 96217.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9364/10556 [00:00<00:00, 93632.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 95265.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 21%|██▏       | 2251/10556 [00:00<00:00, 19212.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 55285.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7088/10556 [00:00<00:00, 70874.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 79106.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123264.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108304.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121024.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7463/10556 [00:00<00:00, 74626.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 71449.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7831/10556 [00:00<00:00, 71721.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 69259.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8493/10556 [00:00<00:00, 82211.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 79841.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▎  | 7770/10556 [00:00<00:00, 77699.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 86134.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9248/10556 [00:00<00:00, 92474.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 95220.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125476.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7861/10556 [00:00<00:00, 78604.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 86490.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9794/10556 [00:00<00:00, 97939.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 98900.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4840/10556 [00:00<00:00, 48397.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 67723.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107358.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9946/10556 [00:00<00:00, 99459.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 99797.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110030.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6712/10556 [00:00<00:00, 61083.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 55104.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10347/10556 [00:00<00:00, 103468.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 94452.68it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6722/10556 [00:00<00:00, 67216.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 75973.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▉      | 4105/10556 [00:00<00:00, 37427.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 56875.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7421/10556 [00:00<00:00, 74203.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 82423.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7499/10556 [00:00<00:00, 68518.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 64654.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6775/10556 [00:00<00:00, 67105.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 65586.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8773/10556 [00:00<00:00, 87725.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 91038.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6192/10556 [00:00<00:00, 55397.04it/s] 83%|████████▎ | 8752/10556 [00:00<00:00, 40370.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 39004.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123956.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122169.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131818.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9215/10556 [00:00<00:00, 84683.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 79468.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6024/10556 [00:00<00:00, 60235.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 57467.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|████▍     | 4621/10556 [00:00<00:00, 46205.64it/s] 68%|██████▊   | 7136/10556 [00:00<00:00, 36929.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 39389.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7579/10556 [00:00<00:00, 75788.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 84613.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115828.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122089.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9722/10556 [00:00<00:00, 97213.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 93912.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10100/10556 [00:00<00:00, 100992.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 100667.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7806/10556 [00:00<00:00, 78058.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 86992.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133583.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5523/10556 [00:00<00:00, 55226.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 65254.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8105/10556 [00:00<00:00, 81049.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 87348.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10358/10556 [00:00<00:00, 103575.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 103332.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▎  | 7764/10556 [00:00<00:00, 77637.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 68059.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110295.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10301/10556 [00:00<00:00, 103004.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 100202.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117395.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7169/10556 [00:00<00:00, 71686.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 73886.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7421/10556 [00:00<00:00, 74208.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 82123.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7206/10556 [00:00<00:00, 72058.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 81710.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110608.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5776/10556 [00:00<00:00, 57750.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 58114.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7872/10556 [00:00<00:00, 78718.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 77749.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5745/10556 [00:00<00:00, 48329.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 49144.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112896.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6279/10556 [00:00<00:00, 62784.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 78487.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6520/10556 [00:00<00:00, 65194.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 77224.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▌| 10044/10556 [00:00<00:00, 100436.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 101069.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6957/10556 [00:00<00:00, 69565.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 74781.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6582/10556 [00:00<00:00, 65815.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 61345.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110534.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117535.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7107/10556 [00:00<00:00, 71064.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 81287.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115388.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5939/10556 [00:00<00:00, 58064.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 53226.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10463/10556 [00:00<00:00, 104627.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 104430.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120157.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121957.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7662/10556 [00:00<00:00, 76616.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 69388.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7347/10556 [00:00<00:00, 68243.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 67878.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▋| 10184/10556 [00:00<00:00, 101833.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 102065.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6581/10556 [00:00<00:00, 65802.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 66162.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6674/10556 [00:00<00:00, 66731.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 58037.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6084/10556 [00:00<00:00, 60833.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 60851.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122218.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124515.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148436.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 236558.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195386.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187687.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195915.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196537.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206355.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195118.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184474.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8119/10556 [00:00<00:00, 81187.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 94053.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189600.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144009.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144506.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197364.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197480.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124141.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 100282.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 228573.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204240.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200595.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200229.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199720.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160778.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218669.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206278.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204551.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206877.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204920.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200469.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199459.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203493.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201668.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208981.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205104.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206345.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203462.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190935.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202765.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195608.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206475.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197627.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202600.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185061.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202699.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205705.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195895.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200249.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204159.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203007.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193900.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192851.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205486.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200917.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185988.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194948.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190729.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205688.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204710.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202952.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193074.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205292.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207119.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179091.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211699.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10348/10556 [00:00<00:00, 95926.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 94578.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193808.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 223094.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201223.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183830.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198165.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200965.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201595.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190126.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107750.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112808.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138849.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191184.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200035.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 223831.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 223497.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184548.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9613/10556 [00:00<00:00, 96123.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 93964.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8018/10556 [00:00<00:00, 80177.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 80242.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192952.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188258.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205030.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197043.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211951.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187796.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208789.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203635.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196223.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197256.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199987.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202381.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200169.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174889.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194691.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193246.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202706.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183694.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185231.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136054.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141863.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141880.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143269.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151214.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151467.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10006/10556 [00:00<00:00, 100056.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 101240.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133023.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122088.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119233.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147896.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142914.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143132.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4875/10556 [00:00<00:00, 43044.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 54253.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8914/10556 [00:00<00:00, 89133.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 93191.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120676.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126654.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123661.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123169.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128700.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109234.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115891.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7572/10556 [00:00<00:00, 75717.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 83864.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111428.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9285/10556 [00:00<00:00, 92849.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 94916.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6066/10556 [00:00<00:00, 56323.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 72425.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149867.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108621.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▌| 10048/10556 [00:00<00:00, 100473.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 100863.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9914/10556 [00:00<00:00, 99137.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 100185.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9152/10556 [00:00<00:00, 91519.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 94222.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7361/10556 [00:00<00:00, 73607.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 75869.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6990/10556 [00:00<00:00, 69896.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 81098.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9548/10556 [00:00<00:00, 95479.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 87275.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8357/10556 [00:00<00:00, 83564.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 88953.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10090/10556 [00:00<00:00, 100898.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 91276.39it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4521/10556 [00:00<00:00, 45206.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 52210.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8805/10556 [00:00<00:00, 88047.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 91657.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120706.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9271/10556 [00:00<00:00, 92705.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 95368.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124534.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121770.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6865/10556 [00:00<00:00, 67030.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 64918.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122983.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|███████▉  | 8423/10556 [00:00<00:00, 84229.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 89700.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109993.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8337/10556 [00:00<00:00, 77599.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 74932.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6990/10556 [00:00<00:00, 67397.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 54999.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 104405.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118290.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7084/10556 [00:00<00:00, 70838.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 79158.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8519/10556 [00:00<00:00, 85182.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 90109.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6789/10556 [00:00<00:00, 65921.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 75408.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10360/10556 [00:00<00:00, 103595.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 103655.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6543/10556 [00:00<00:00, 64804.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 68955.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 102348.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5870/10556 [00:00<00:00, 52074.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 62879.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5712/10556 [00:00<00:00, 57114.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 55478.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|██▊       | 3016/10556 [00:00<00:00, 29705.34it/s] 61%|██████    | 6426/10556 [00:00<00:00, 30899.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 38851.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▎    | 5666/10556 [00:00<00:00, 56655.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 55905.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▋     | 4885/10556 [00:00<00:00, 48848.18it/s] 75%|███████▍  | 7897/10556 [00:00<00:00, 41038.13it/s] 99%|█████████▉| 10455/10556 [00:00<00:00, 34090.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 34121.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|███▍      | 3569/10556 [00:00<00:00, 35685.61it/s] 68%|██████▊   | 7200/10556 [00:00<00:00, 35870.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 42023.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10331/10556 [00:00<00:00, 103304.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 103404.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112246.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9516/10556 [00:00<00:00, 95152.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 97274.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106761.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8194/10556 [00:00<00:00, 81938.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 88882.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9922/10556 [00:00<00:00, 99216.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 100670.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4806/10556 [00:00<00:00, 48056.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 66541.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124652.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 102472.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107175.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10259/10556 [00:00<00:00, 102585.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 102497.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8842/10556 [00:00<00:00, 88418.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 91488.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10494/10556 [00:00<00:00, 104938.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 104641.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6150/10556 [00:00<00:00, 61499.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 58744.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10291/10556 [00:00<00:00, 102905.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 102776.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9260/10556 [00:00<00:00, 92595.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 92456.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9209/10556 [00:00<00:00, 92086.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 89630.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6833/10556 [00:00<00:00, 68329.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 80381.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7838/10556 [00:00<00:00, 78378.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 86287.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121236.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7420/10556 [00:00<00:00, 69020.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 66775.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6075/10556 [00:00<00:00, 60746.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 76677.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6385/10556 [00:00<00:00, 63842.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 61671.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6527/10556 [00:00<00:00, 65262.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 65868.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6011/10556 [00:00<00:00, 60102.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 61922.23it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '0.77621'}; time used = 0.533074140548706s
epoch 10: {'train_loss': '0.58975'}; time used = 0.38908934593200684s
epoch 15: {'train_loss': '0.45393'}; time used = 0.3810610771179199s
epoch 20: {'train_loss': '0.31024'}; time used = 0.3487522602081299s
epoch 25: {'train_loss': '0.24452'}; time used = 0.34055614471435547s
epoch 30: {'train_loss': '0.19176'}; time used = 0.3457047939300537s
epoch 35: {'train_loss': '0.15704'}; time used = 0.35031771659851074s
epoch 40: {'train_loss': '0.13159'}; time used = 0.34689760208129883s
epoch 45: {'train_loss': '0.12422'}; time used = 0.4353945255279541s
epoch 50: {'train_loss': '0.10489'}; time used = 0.3873429298400879s
epoch 55: {'train_loss': '0.10333'}; time used = 0.5246396064758301s
epoch 60: {'train_loss': '0.10105'}; time used = 0.47672224044799805s
epoch 65: {'train_loss': '0.08402'}; time used = 0.440915584564209s
epoch 70: {'train_loss': '0.08385'}; time used = 0.44895100593566895s
epoch 75: {'train_loss': '0.08315'}; time used = 0.5878033638000488s
epoch 80: {'train_loss': '0.08295'}; time used = 0.6277062892913818s
epoch 85: {'train_loss': '0.07938'}; time used = 0.665142297744751s
epoch 90: {'train_loss': '0.07983'}; time used = 0.7348942756652832s
epoch 95: {'train_loss': '0.06213'}; time used = 0.7010695934295654s
epoch 100: {'train_loss': '0.07364'}; time used = 0.6464776992797852s
epoch 105: {'train_loss': '0.07044'}; time used = 0.6251499652862549s
epoch 110: {'train_loss': '0.07142'}; time used = 0.588665246963501s
epoch 115: {'train_loss': '0.07031'}; time used = 0.6047735214233398s
epoch 120: {'train_loss': '0.06832'}; time used = 0.547783374786377s
epoch 125: {'train_loss': '0.06764'}; time used = 0.9234342575073242s
epoch 130: {'train_loss': '0.06505'}; time used = 0.8081603050231934s
epoch 135: {'train_loss': '0.06397'}; time used = 0.635246753692627s
epoch 140: {'train_loss': '0.06937'}; time used = 0.76845383644104s
epoch 145: {'train_loss': '0.05511'}; time used = 0.8159823417663574s
epoch 150: {'train_loss': '0.07099'}; time used = 1.0461127758026123s
epoch 155: {'train_loss': '0.06822'}; time used = 0.8543426990509033s
epoch 160: {'train_loss': '0.05872'}; time used = 0.6316351890563965s
epoch 165: {'train_loss': '0.06023'}; time used = 0.8241591453552246s
epoch 170: {'train_loss': '0.05662'}; time used = 0.6757464408874512s
epoch 175: {'train_loss': '0.05680'}; time used = 0.6596391201019287s
epoch 180: {'train_loss': '0.05251'}; time used = 0.6059222221374512s
epoch 185: {'train_loss': '0.05661'}; time used = 0.8060965538024902s
epoch 190: {'train_loss': '0.06292'}; time used = 0.705826997756958s
epoch 195: {'train_loss': '0.05409'}; time used = 0.7073032855987549s
epoch 200: {'train_loss': '0.05642'}; time used = 0.6838722229003906s
epoch 205: {'train_loss': '0.05785'}; time used = 0.6474096775054932s
epoch 210: {'train_loss': '0.05420'}; time used = 0.6517987251281738s
epoch 215: {'train_loss': '0.05493'}; time used = 0.6496086120605469s
epoch 220: {'train_loss': '0.05287'}; time used = 0.8025038242340088s
epoch 225: {'train_loss': '0.04537'}; time used = 0.7172019481658936s
epoch 230: {'train_loss': '0.05390'}; time used = 0.5838382244110107s
epoch 235: {'train_loss': '0.05620'}; time used = 0.6308667659759521s
epoch 240: {'train_loss': '0.06180'}; time used = 0.7096564769744873s
epoch 245: {'train_loss': '0.05030'}; time used = 0.7290401458740234s
epoch 250: {'train_loss': '0.04937'}; time used = 0.6538686752319336s
epoch 255: {'train_loss': '0.05658'}; time used = 0.6712632179260254s
epoch 260: {'train_loss': '0.05434'}; time used = 0.871964693069458s
epoch 265: {'train_loss': '0.04701'}; time used = 0.7490887641906738s
epoch 270: {'train_loss': '0.05531'}; time used = 0.9024538993835449s
epoch 275: {'train_loss': '0.05832'}; time used = 0.6188879013061523s
epoch 280: {'train_loss': '0.05185'}; time used = 0.729637861251831s
epoch 285: {'train_loss': '0.05042'}; time used = 0.6939868927001953s
epoch 290: {'train_loss': '0.05239'}; time used = 0.8090689182281494s
epoch 295: {'train_loss': '0.05105'}; time used = 0.7993512153625488s
epoch 300: {'train_loss': '0.05070'}; time used = 0.6855132579803467s
epoch 305: {'train_loss': '0.04627'}; time used = 0.6799695491790771s
epoch 310: {'train_loss': '0.05560'}; time used = 0.7986640930175781s
epoch 315: {'train_loss': '0.04786'}; time used = 0.3749568462371826s
epoch 320: {'train_loss': '0.04264'}; time used = 0.321195125579834s
epoch 325: {'train_loss': '0.05482'}; time used = 0.4221174716949463s
epoch 330: {'train_loss': '0.05517'}; time used = 0.40128660202026367s
epoch 335: {'train_loss': '0.04592'}; time used = 0.321185827255249s
epoch 340: {'train_loss': '0.05702'}; time used = 0.30883240699768066s
epoch 345: {'train_loss': '0.05390'}; time used = 0.31406593322753906s
epoch 350: {'train_loss': '0.05909'}; time used = 0.31791043281555176s
epoch 355: {'train_loss': '0.05361'}; time used = 0.33819127082824707s
epoch 360: {'train_loss': '0.04980'}; time used = 0.3169715404510498s
epoch 365: {'train_loss': '0.05225'}; time used = 0.3241729736328125s
epoch 370: {'train_loss': '0.04888'}; time used = 0.3127152919769287s
epoch 375: {'train_loss': '0.04197'}; time used = 0.31887054443359375s
epoch 380: {'train_loss': '0.06320'}; time used = 0.3754594326019287s
epoch 385: {'train_loss': '0.04993'}; time used = 0.3691427707672119s
epoch 390: {'train_loss': '0.05525'}; time used = 0.37537240982055664s
epoch 395: {'train_loss': '0.04071'}; time used = 0.4728426933288574s
epoch 400: {'train_loss': '0.05819'}; time used = 0.32280945777893066s
epoch 405: {'train_loss': '0.05567'}; time used = 0.3173344135284424s
epoch 410: {'train_loss': '0.03865'}; time used = 0.3289515972137451s
epoch 415: {'train_loss': '0.05471'}; time used = 0.37643885612487793s
epoch 420: {'train_loss': '0.04979'}; time used = 0.4467778205871582s
epoch 425: {'train_loss': '0.05419'}; time used = 0.45529651641845703s
epoch 430: {'train_loss': '0.05434'}; time used = 0.6321511268615723s
epoch 435: {'train_loss': '0.04115'}; time used = 0.5340309143066406s
epoch 440: {'train_loss': '0.05204'}; time used = 0.6527872085571289s
epoch 445: {'train_loss': '0.04669'}; time used = 0.6292667388916016s
epoch 450: {'train_loss': '0.05980'}; time used = 0.7914338111877441s
epoch 455: {'train_loss': '0.05528'}; time used = 0.5578713417053223s
epoch 460: {'train_loss': '0.04635'}; time used = 0.6840071678161621s
epoch 465: {'train_loss': '0.04239'}; time used = 0.7476241588592529s
epoch 470: {'train_loss': '0.04813'}; time used = 0.7500708103179932s
epoch 475: {'train_loss': '0.05122'}; time used = 1.2985320091247559s
epoch 480: {'train_loss': '0.05075'}; time used = 0.6069066524505615s
epoch 485: {'train_loss': '0.05062'}; time used = 0.6390726566314697s
epoch 490: {'train_loss': '0.03791'}; time used = 0.7126588821411133s
epoch 495: {'train_loss': '0.05592'}; time used = 0.6645004749298096s
epoch 500: {'train_loss': '0.03912'}; time used = 0.9098367691040039s
Finished training. Time used = 65.50190758705139.
Training classifier using 20.00% nodes...
{'micro': 0.7314259344716197, 'macro': 0.7130553498894565, 'samples': 0.7314259344716197, 'weighted': 0.7288977815003618}

  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5251/10556 [00:00<00:00, 52502.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 52854.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|████      | 4226/10556 [00:00<00:00, 40498.29it/s] 93%|█████████▎| 9765/10556 [00:00<00:00, 44050.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 49249.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9346/10556 [00:00<00:00, 93451.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 85317.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7046/10556 [00:00<00:00, 70457.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 67858.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8963/10556 [00:00<00:00, 89622.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 88589.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6577/10556 [00:00<00:00, 65763.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 74889.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6345/10556 [00:00<00:00, 63447.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 61174.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8658/10556 [00:00<00:00, 86574.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 87887.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████      | 4296/10556 [00:00<00:00, 42957.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 67718.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7479/10556 [00:00<00:00, 74786.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 75391.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6586/10556 [00:00<00:00, 59325.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 62748.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6621/10556 [00:00<00:00, 55321.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 54355.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████      | 4315/10556 [00:00<00:00, 43145.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 53805.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111446.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4918/10556 [00:00<00:00, 49177.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 68277.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9386/10556 [00:00<00:00, 93852.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 95587.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111125.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7046/10556 [00:00<00:00, 70457.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 81284.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115447.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122047.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121058.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9806/10556 [00:00<00:00, 98057.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 94040.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4429/10556 [00:00<00:00, 42495.02it/s] 90%|████████▉ | 9473/10556 [00:00<00:00, 44602.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 49328.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5791/10556 [00:00<00:00, 47940.91it/s] 95%|█████████▍| 10028/10556 [00:00<00:00, 46121.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 46131.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████▏    | 5410/10556 [00:00<00:00, 54097.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 57406.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10191/10556 [00:00<00:00, 101904.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 101624.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7380/10556 [00:00<00:00, 73798.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 76913.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9323/10556 [00:00<00:00, 93229.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 71373.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125204.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8280/10556 [00:00<00:00, 71587.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 71467.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119117.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7571/10556 [00:00<00:00, 56438.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 60999.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106359.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9188/10556 [00:00<00:00, 91874.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 94247.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106100.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7166/10556 [00:00<00:00, 60019.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 57960.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120255.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123099.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7924/10556 [00:00<00:00, 66674.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 72284.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7481/10556 [00:00<00:00, 69264.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 77193.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8940/10556 [00:00<00:00, 77181.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 66612.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6833/10556 [00:00<00:00, 66298.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 64622.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6859/10556 [00:00<00:00, 68580.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 68973.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7302/10556 [00:00<00:00, 66035.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 71035.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7906/10556 [00:00<00:00, 75658.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 65974.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6726/10556 [00:00<00:00, 67258.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 78571.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6427/10556 [00:00<00:00, 64265.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 66078.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112763.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7718/10556 [00:00<00:00, 77177.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 85998.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10026/10556 [00:00<00:00, 100256.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 100958.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121612.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6376/10556 [00:00<00:00, 63683.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 62824.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9303/10556 [00:00<00:00, 93029.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 94837.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118942.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122551.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9070/10556 [00:00<00:00, 90433.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 76097.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9802/10556 [00:00<00:00, 98017.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 99247.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124740.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124174.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124015.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7944/10556 [00:00<00:00, 79436.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 87084.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7879/10556 [00:00<00:00, 78786.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 86192.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117131.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|███▏      | 3416/10556 [00:00<00:00, 31138.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 62007.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8907/10556 [00:00<00:00, 89069.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 93156.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106809.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6742/10556 [00:00<00:00, 67418.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 79984.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9408/10556 [00:00<00:00, 94078.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 95717.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112901.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110337.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8281/10556 [00:00<00:00, 82805.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 79683.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6323/10556 [00:00<00:00, 62213.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 74533.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9404/10556 [00:00<00:00, 94033.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 96114.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5526/10556 [00:00<00:00, 54219.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 72845.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5988/10556 [00:00<00:00, 59879.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 72646.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9177/10556 [00:00<00:00, 91762.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 94377.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114770.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8864/10556 [00:00<00:00, 86672.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 79771.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122159.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6564/10556 [00:00<00:00, 60813.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 74797.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6920/10556 [00:00<00:00, 66402.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 69568.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 99843.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116617.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7574/10556 [00:00<00:00, 75738.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 67397.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6873/10556 [00:00<00:00, 66435.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 74993.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118636.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111147.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107067.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115794.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112340.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7733/10556 [00:00<00:00, 77328.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 77095.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 101405.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6318/10556 [00:00<00:00, 63176.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 55397.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129667.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9128/10556 [00:00<00:00, 91275.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 93844.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8694/10556 [00:00<00:00, 86933.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 91507.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6232/10556 [00:00<00:00, 60869.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 71147.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9250/10556 [00:00<00:00, 84691.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 80951.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6462/10556 [00:00<00:00, 64615.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 72568.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6603/10556 [00:00<00:00, 65134.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 63862.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6459/10556 [00:00<00:00, 64587.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 62927.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6944/10556 [00:00<00:00, 69438.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 59966.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4876/10556 [00:00<00:00, 46640.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 64484.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4437/10556 [00:00<00:00, 43126.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 58983.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8144/10556 [00:00<00:00, 81434.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 88237.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8731/10556 [00:00<00:00, 87305.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 90388.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8732/10556 [00:00<00:00, 87316.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 92749.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120549.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6365/10556 [00:00<00:00, 63649.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 76576.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6843/10556 [00:00<00:00, 68426.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 80540.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119540.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6325/10556 [00:00<00:00, 63077.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 77620.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122512.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5587/10556 [00:00<00:00, 55525.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 52862.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7623/10556 [00:00<00:00, 76226.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 67734.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119820.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10419/10556 [00:00<00:00, 102494.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 102427.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110239.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123466.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6811/10556 [00:00<00:00, 67432.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 65494.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118605.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7559/10556 [00:00<00:00, 75585.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 76580.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10313/10556 [00:00<00:00, 103127.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 99383.77it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8948/10556 [00:00<00:00, 87378.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 81179.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5793/10556 [00:00<00:00, 55090.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 59720.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6707/10556 [00:00<00:00, 63120.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 64148.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7311/10556 [00:00<00:00, 72821.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 67022.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9256/10556 [00:00<00:00, 92558.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 94748.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118974.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116589.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7074/10556 [00:00<00:00, 70737.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 76003.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8851/10556 [00:00<00:00, 88509.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 83190.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109139.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7825/10556 [00:00<00:00, 78245.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 86647.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9340/10556 [00:00<00:00, 93394.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 95255.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117963.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117852.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5744/10556 [00:00<00:00, 50694.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 55441.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6130/10556 [00:00<00:00, 61296.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 74911.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123075.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10304/10556 [00:00<00:00, 92178.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 92579.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6622/10556 [00:00<00:00, 61219.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 58002.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5236/10556 [00:00<00:00, 52356.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 63335.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████▏ | 8590/10556 [00:00<00:00, 85899.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 90383.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106669.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9453/10556 [00:00<00:00, 94527.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 96556.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9030/10556 [00:00<00:00, 90299.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 89380.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10083/10556 [00:00<00:00, 100821.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 101131.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129748.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7350/10556 [00:00<00:00, 73494.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 82685.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 100609.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114209.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10470/10556 [00:00<00:00, 104693.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 104508.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9612/10556 [00:00<00:00, 96112.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 97950.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9414/10556 [00:00<00:00, 89564.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 90139.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106323.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9449/10556 [00:00<00:00, 94489.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 86531.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6967/10556 [00:00<00:00, 69665.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 74338.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9034/10556 [00:00<00:00, 90335.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 93648.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5268/10556 [00:00<00:00, 52678.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 54563.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▉      | 4101/10556 [00:00<00:00, 37546.26it/s] 98%|█████████▊| 10343/10556 [00:00<00:00, 42642.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 49627.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5021/10556 [00:00<00:00, 50206.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 54905.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4939/10556 [00:00<00:00, 49389.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 54525.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5827/10556 [00:00<00:00, 58259.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 61134.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6667/10556 [00:00<00:00, 66665.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 66709.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6591/10556 [00:00<00:00, 65904.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 66149.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6642/10556 [00:00<00:00, 66418.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 60761.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5490/10556 [00:00<00:00, 54893.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 59841.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|███▌      | 3803/10556 [00:00<00:00, 37672.02it/s] 76%|███████▋  | 8052/10556 [00:00<00:00, 38997.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 44244.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|████▎     | 4611/10556 [00:00<00:00, 45528.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 50621.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122301.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7151/10556 [00:00<00:00, 71505.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 79752.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110817.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107964.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105549.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████▏| 9650/10556 [00:00<00:00, 96495.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 96904.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8339/10556 [00:00<00:00, 83384.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 88946.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8227/10556 [00:00<00:00, 73798.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 66180.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7105/10556 [00:00<00:00, 69760.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 73659.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6897/10556 [00:00<00:00, 64002.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 68732.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6459/10556 [00:00<00:00, 62202.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 71991.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121779.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7330/10556 [00:00<00:00, 70735.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 81134.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7979/10556 [00:00<00:00, 79788.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 87534.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119153.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6379/10556 [00:00<00:00, 61058.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 65264.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125040.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10088/10556 [00:00<00:00, 100876.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 83591.81it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8516/10556 [00:00<00:00, 85153.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 67381.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9724/10556 [00:00<00:00, 97233.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 98665.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145088.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198289.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197180.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189768.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192354.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117157.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146362.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120082.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107024.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194171.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193022.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192989.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145618.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114547.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199695.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202298.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124689.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193509.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206805.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201061.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193598.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203610.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196170.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200491.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205332.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 227056.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 232645.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 230700.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205126.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 231803.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214246.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199267.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 229705.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214557.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214495.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 228739.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216603.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 227884.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 230640.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207400.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197097.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187599.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214676.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216126.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 231552.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216715.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203302.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221951.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134860.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140496.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138389.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142710.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127697.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133962.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144549.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138945.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145004.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138006.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138170.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141865.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138947.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140696.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131016.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7822/10556 [00:00<00:00, 78217.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 79385.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8353/10556 [00:00<00:00, 83527.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 83408.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187294.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182031.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202166.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200181.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186091.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201630.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192944.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200684.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205437.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191146.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196740.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192420.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200773.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203909.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197534.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203860.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200582.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194913.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200740.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197731.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202299.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203512.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200668.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192362.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145910.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145586.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135432.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134127.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136681.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144210.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145084.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145139.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143444.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143889.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5641/10556 [00:00<00:00, 56407.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 58805.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6475/10556 [00:00<00:00, 64749.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 63210.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6421/10556 [00:00<00:00, 64207.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 64801.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6610/10556 [00:00<00:00, 55261.03it/s] 98%|█████████▊| 10387/10556 [00:00<00:00, 48161.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 46881.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5385/10556 [00:00<00:00, 49960.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 52862.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121594.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116653.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7602/10556 [00:00<00:00, 76016.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 71552.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9462/10556 [00:00<00:00, 94614.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 91915.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7605/10556 [00:00<00:00, 73060.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 77776.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5623/10556 [00:00<00:00, 52985.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 55516.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5802/10556 [00:00<00:00, 55211.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 68169.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4510/10556 [00:00<00:00, 44549.01it/s] 89%|████████▉ | 9393/10556 [00:00<00:00, 45751.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 46426.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9837/10556 [00:00<00:00, 96922.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 98067.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6293/10556 [00:00<00:00, 62574.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 64648.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6254/10556 [00:00<00:00, 60331.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 58397.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9773/10556 [00:00<00:00, 97725.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 98751.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6675/10556 [00:00<00:00, 66747.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 72242.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6112/10556 [00:00<00:00, 61054.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 58237.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6915/10556 [00:00<00:00, 69145.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 62756.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124541.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122429.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8901/10556 [00:00<00:00, 89004.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 92588.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7070/10556 [00:00<00:00, 66492.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 76353.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6730/10556 [00:00<00:00, 65570.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 78968.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122250.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7378/10556 [00:00<00:00, 73776.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 83511.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112902.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121898.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8989/10556 [00:00<00:00, 89883.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 93280.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118223.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7817/10556 [00:00<00:00, 78168.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 86444.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10135/10556 [00:00<00:00, 97301.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 97581.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10403/10556 [00:00<00:00, 104027.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 101771.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7595/10556 [00:00<00:00, 75945.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 85692.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9130/10556 [00:00<00:00, 74809.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 74314.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115456.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7329/10556 [00:00<00:00, 73288.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 82822.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9591/10556 [00:00<00:00, 95906.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 97797.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10449/10556 [00:00<00:00, 104488.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 104174.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117393.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123852.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124682.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123554.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117189.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121838.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7376/10556 [00:00<00:00, 73758.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 83657.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122246.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7229/10556 [00:00<00:00, 72288.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 67193.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 9990/10556 [00:00<00:00, 99893.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 100283.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9450/10556 [00:00<00:00, 94497.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 96625.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 102503.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9057/10556 [00:00<00:00, 90563.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 94129.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7438/10556 [00:00<00:00, 74376.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 72691.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120849.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6189/10556 [00:00<00:00, 61886.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 77901.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112174.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|█████     | 5315/10556 [00:00<00:00, 48860.02it/s] 97%|█████████▋| 10187/10556 [00:00<00:00, 48817.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 45425.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8355/10556 [00:00<00:00, 83547.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 77940.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▊      | 4076/10556 [00:00<00:00, 40758.87it/s] 91%|█████████ | 9555/10556 [00:00<00:00, 44150.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 50676.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9430/10556 [00:00<00:00, 92319.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 90826.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123953.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114452.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4456/10556 [00:00<00:00, 44559.41it/s] 81%|████████▏ | 8603/10556 [00:00<00:00, 43094.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 38355.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 25%|██▌       | 2673/10556 [00:00<00:00, 24895.80it/s] 57%|█████▋    | 6043/10556 [00:00<00:00, 27012.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 36523.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5592/10556 [00:00<00:00, 55915.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 59191.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6331/10556 [00:00<00:00, 63302.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 68412.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5842/10556 [00:00<00:00, 58412.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 55838.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6546/10556 [00:00<00:00, 63929.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 64577.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6618/10556 [00:00<00:00, 66173.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 65854.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▎    | 5662/10556 [00:00<00:00, 56617.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 55698.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6675/10556 [00:00<00:00, 66744.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 66502.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|██▉       | 3091/10556 [00:00<00:00, 29363.95it/s] 79%|███████▊  | 8304/10556 [00:00<00:00, 33657.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 46718.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113147.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6457/10556 [00:00<00:00, 63439.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 61591.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▉      | 4161/10556 [00:00<00:00, 38677.87it/s] 80%|███████▉  | 8432/10556 [00:00<00:00, 39225.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 39686.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6251/10556 [00:00<00:00, 62509.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 59653.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10481/10556 [00:00<00:00, 93801.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 85307.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123830.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114795.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10470/10556 [00:00<00:00, 104695.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 104492.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|█████     | 5287/10556 [00:00<00:00, 52869.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 62316.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8887/10556 [00:00<00:00, 76587.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 74294.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121691.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8992/10556 [00:00<00:00, 89914.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 87243.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119634.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|████▍     | 4704/10556 [00:00<00:00, 41974.81it/s] 78%|███████▊  | 8186/10556 [00:00<00:00, 39009.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 41184.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7813/10556 [00:00<00:00, 78129.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 75599.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5525/10556 [00:00<00:00, 55249.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 64073.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115010.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113875.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110240.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115781.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7056/10556 [00:00<00:00, 64211.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 62686.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7722/10556 [00:00<00:00, 70435.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 78750.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7334/10556 [00:00<00:00, 72128.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 65292.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5945/10556 [00:00<00:00, 57334.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 74367.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6696/10556 [00:00<00:00, 64518.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 77232.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121059.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8680/10556 [00:00<00:00, 86796.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 91210.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6713/10556 [00:00<00:00, 67126.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 72712.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6235/10556 [00:00<00:00, 62345.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 70210.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4555/10556 [00:00<00:00, 40030.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 54304.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5455/10556 [00:00<00:00, 53152.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 67251.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 9983/10556 [00:00<00:00, 99828.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 89237.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115955.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10258/10556 [00:00<00:00, 102572.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 102835.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10429/10556 [00:00<00:00, 94698.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 94687.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6685/10556 [00:00<00:00, 66848.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 67608.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6668/10556 [00:00<00:00, 62364.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 69674.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6471/10556 [00:00<00:00, 61244.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 75703.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122461.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7165/10556 [00:00<00:00, 71549.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 82233.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115971.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6955/10556 [00:00<00:00, 69413.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 78012.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115313.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6632/10556 [00:00<00:00, 66319.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 80175.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111484.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6562/10556 [00:00<00:00, 64885.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 72514.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7446/10556 [00:00<00:00, 74454.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 76513.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7901/10556 [00:00<00:00, 79006.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 86292.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118103.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4828/10556 [00:00<00:00, 48279.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 52902.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108705.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108197.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9526/10556 [00:00<00:00, 95255.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 96430.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149333.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8613/10556 [00:00<00:00, 86122.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 90300.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117966.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118327.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120105.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115711.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113266.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111501.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8857/10556 [00:00<00:00, 88566.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 92865.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111805.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6093/10556 [00:00<00:00, 60927.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 75844.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9448/10556 [00:00<00:00, 86880.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 78897.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10408/10556 [00:00<00:00, 100672.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 100219.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|███▊      | 3977/10556 [00:00<00:00, 34364.24it/s] 88%|████████▊ | 9266/10556 [00:00<00:00, 38085.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 43499.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5805/10556 [00:00<00:00, 58046.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 55902.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114715.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7635/10556 [00:00<00:00, 76349.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 75352.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109263.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8078/10556 [00:00<00:00, 80775.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 86346.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121351.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123297.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117329.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 24%|██▎       | 2505/10556 [00:00<00:00, 19123.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 52772.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 100539.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7031/10556 [00:00<00:00, 70304.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 57580.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6059/10556 [00:00<00:00, 60588.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 70725.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9723/10556 [00:00<00:00, 97225.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 98642.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120354.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8175/10556 [00:00<00:00, 79963.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 71933.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6512/10556 [00:00<00:00, 65116.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 60358.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 9997/10556 [00:00<00:00, 99961.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 100304.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9898/10556 [00:00<00:00, 98977.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 100000.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8328/10556 [00:00<00:00, 83276.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 88248.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125912.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▎ | 8823/10556 [00:00<00:00, 80432.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 81013.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6959/10556 [00:00<00:00, 64990.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 51996.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120083.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7622/10556 [00:00<00:00, 76214.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 80558.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4949/10556 [00:00<00:00, 49486.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 55791.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6071/10556 [00:00<00:00, 60705.43it/s] 93%|█████████▎| 9845/10556 [00:00<00:00, 51119.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 42909.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 25%|██▌       | 2639/10556 [00:00<00:00, 25616.75it/s] 79%|███████▉  | 8342/10556 [00:00<00:00, 30687.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 44533.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6532/10556 [00:00<00:00, 65315.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 65408.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6688/10556 [00:00<00:00, 66873.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 66759.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|███▋      | 3926/10556 [00:00<00:00, 39256.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 51248.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5251/10556 [00:00<00:00, 52507.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 59662.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5387/10556 [00:00<00:00, 53862.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 60260.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6638/10556 [00:00<00:00, 66373.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 67294.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6883/10556 [00:00<00:00, 68822.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 68816.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6891/10556 [00:00<00:00, 68902.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 68797.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4482/10556 [00:00<00:00, 41144.57it/s] 79%|███████▉  | 8371/10556 [00:00<00:00, 39962.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 41027.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6902/10556 [00:00<00:00, 69015.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 68875.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6876/10556 [00:00<00:00, 68753.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 66576.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6847/10556 [00:00<00:00, 68468.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 68516.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6861/10556 [00:00<00:00, 68602.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 68676.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6118/10556 [00:00<00:00, 61179.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 64215.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119268.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6813/10556 [00:00<00:00, 68129.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 78385.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10403/10556 [00:00<00:00, 104029.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 104036.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118586.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111006.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7455/10556 [00:00<00:00, 74548.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 76930.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110407.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6649/10556 [00:00<00:00, 66489.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 78928.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6754/10556 [00:00<00:00, 67537.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 71807.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121223.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111315.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118682.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6735/10556 [00:00<00:00, 66551.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 64726.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6105/10556 [00:00<00:00, 61049.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 76914.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120940.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121695.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123757.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6873/10556 [00:00<00:00, 68303.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 61143.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9351/10556 [00:00<00:00, 93504.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 96068.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6429/10556 [00:00<00:00, 64286.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 62929.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7798/10556 [00:00<00:00, 77975.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 67370.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113664.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110035.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5558/10556 [00:00<00:00, 54728.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 69024.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6674/10556 [00:00<00:00, 63106.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 65759.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▊   | 7240/10556 [00:00<00:00, 72397.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 74318.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▊  | 8294/10556 [00:00<00:00, 82932.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 76209.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7889/10556 [00:00<00:00, 78209.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 79107.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121989.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119198.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123330.61it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '2.40840'}; time used = 0.8668701648712158s
epoch 10: {'train_loss': '3.23878'}; time used = 0.8398892879486084s
epoch 15: {'train_loss': '2.02315'}; time used = 0.8349754810333252s
epoch 20: {'train_loss': '0.97242'}; time used = 0.5774507522583008s
epoch 25: {'train_loss': '0.85220'}; time used = 0.9316542148590088s
epoch 30: {'train_loss': '0.55877'}; time used = 0.6784141063690186s
epoch 35: {'train_loss': '0.45877'}; time used = 0.754997730255127s
epoch 40: {'train_loss': '0.35597'}; time used = 0.7105810642242432s
epoch 45: {'train_loss': '0.31281'}; time used = 0.8446106910705566s
epoch 50: {'train_loss': '0.26969'}; time used = 0.6556193828582764s
epoch 55: {'train_loss': '0.24411'}; time used = 0.6641592979431152s
epoch 60: {'train_loss': '0.23638'}; time used = 0.5637731552124023s
epoch 65: {'train_loss': '0.20073'}; time used = 0.6783158779144287s
epoch 70: {'train_loss': '0.18997'}; time used = 0.6600801944732666s
epoch 75: {'train_loss': '0.18266'}; time used = 0.7537891864776611s
epoch 80: {'train_loss': '0.16241'}; time used = 0.6937000751495361s
epoch 85: {'train_loss': '0.16092'}; time used = 0.6575119495391846s
epoch 90: {'train_loss': '0.15494'}; time used = 0.5930213928222656s
epoch 95: {'train_loss': '0.13495'}; time used = 0.6803114414215088s
epoch 100: {'train_loss': '0.13924'}; time used = 0.8391940593719482s
epoch 105: {'train_loss': '0.13656'}; time used = 0.8503007888793945s
epoch 110: {'train_loss': '0.12930'}; time used = 0.6301984786987305s
epoch 115: {'train_loss': '0.12060'}; time used = 0.7702319622039795s
epoch 120: {'train_loss': '0.12223'}; time used = 0.6197619438171387s
epoch 125: {'train_loss': '0.11533'}; time used = 0.786078929901123s
epoch 130: {'train_loss': '0.11269'}; time used = 0.6519896984100342s
epoch 135: {'train_loss': '0.10187'}; time used = 0.6171469688415527s
epoch 140: {'train_loss': '0.10749'}; time used = 0.7067039012908936s
epoch 145: {'train_loss': '0.09075'}; time used = 0.7409324645996094s
epoch 150: {'train_loss': '0.10332'}; time used = 0.6209237575531006s
epoch 155: {'train_loss': '0.10357'}; time used = 0.6055870056152344s
epoch 160: {'train_loss': '0.08542'}; time used = 0.8607323169708252s
epoch 165: {'train_loss': '0.08964'}; time used = 0.961331844329834s
epoch 170: {'train_loss': '0.09287'}; time used = 0.9802134037017822s
epoch 175: {'train_loss': '0.08548'}; time used = 0.608328104019165s
epoch 180: {'train_loss': '0.07911'}; time used = 0.8019165992736816s
epoch 185: {'train_loss': '0.07673'}; time used = 0.6688439846038818s
epoch 190: {'train_loss': '0.08344'}; time used = 0.6256814002990723s
epoch 195: {'train_loss': '0.07672'}; time used = 0.3633999824523926s
epoch 200: {'train_loss': '0.07384'}; time used = 0.4235351085662842s
epoch 205: {'train_loss': '0.07358'}; time used = 0.38523316383361816s
epoch 210: {'train_loss': '0.07401'}; time used = 0.3594484329223633s
epoch 215: {'train_loss': '0.07394'}; time used = 0.30451297760009766s
epoch 220: {'train_loss': '0.07342'}; time used = 0.2897520065307617s
epoch 225: {'train_loss': '0.06459'}; time used = 0.2977125644683838s
epoch 230: {'train_loss': '0.06868'}; time used = 0.3045494556427002s
epoch 235: {'train_loss': '0.07182'}; time used = 0.29723143577575684s
epoch 240: {'train_loss': '0.07090'}; time used = 0.38317394256591797s
epoch 245: {'train_loss': '0.06681'}; time used = 0.43694210052490234s
epoch 250: {'train_loss': '0.06243'}; time used = 0.43716859817504883s
epoch 255: {'train_loss': '0.06289'}; time used = 0.5344536304473877s
epoch 260: {'train_loss': '0.06430'}; time used = 0.32358217239379883s
epoch 265: {'train_loss': '0.05781'}; time used = 0.3348557949066162s
epoch 270: {'train_loss': '0.05853'}; time used = 0.32424330711364746s
epoch 275: {'train_loss': '0.06336'}; time used = 0.32097959518432617s
epoch 280: {'train_loss': '0.05873'}; time used = 0.3631460666656494s
epoch 285: {'train_loss': '0.05786'}; time used = 0.4412040710449219s
epoch 290: {'train_loss': '0.05928'}; time used = 0.6369991302490234s
epoch 295: {'train_loss': '0.05775'}; time used = 0.8497180938720703s
epoch 300: {'train_loss': '0.05270'}; time used = 0.8359646797180176s
epoch 305: {'train_loss': '0.05279'}; time used = 0.8667135238647461s
epoch 310: {'train_loss': '0.05850'}; time used = 0.7465877532958984s
epoch 315: {'train_loss': '0.05607'}; time used = 0.6965236663818359s
epoch 320: {'train_loss': '0.04737'}; time used = 0.5836808681488037s
epoch 325: {'train_loss': '0.05285'}; time used = 0.6714577674865723s
epoch 330: {'train_loss': '0.05577'}; time used = 0.617250919342041s
epoch 335: {'train_loss': '0.05583'}; time used = 0.5593574047088623s
epoch 340: {'train_loss': '0.05589'}; time used = 0.6590123176574707s
epoch 345: {'train_loss': '0.05464'}; time used = 0.6698143482208252s
epoch 350: {'train_loss': '0.05295'}; time used = 0.8618829250335693s
epoch 355: {'train_loss': '0.05354'}; time used = 1.0868525505065918s
epoch 360: {'train_loss': '0.04879'}; time used = 0.9534659385681152s
epoch 365: {'train_loss': '0.05216'}; time used = 1.0142195224761963s
epoch 370: {'train_loss': '0.04745'}; time used = 0.6762001514434814s
epoch 375: {'train_loss': '0.04460'}; time used = 0.7763066291809082s
epoch 380: {'train_loss': '0.06487'}; time used = 0.6690659523010254s
epoch 385: {'train_loss': '0.05132'}; time used = 0.7966852188110352s
epoch 390: {'train_loss': '0.05205'}; time used = 0.7300662994384766s
epoch 395: {'train_loss': '0.04241'}; time used = 0.743865966796875s
epoch 400: {'train_loss': '0.05874'}; time used = 0.713773250579834s
epoch 405: {'train_loss': '0.04710'}; time used = 0.6777510643005371s
epoch 410: {'train_loss': '0.04217'}; time used = 0.6689028739929199s
epoch 415: {'train_loss': '0.05112'}; time used = 0.6894745826721191s
epoch 420: {'train_loss': '0.04752'}; time used = 0.5485873222351074s
epoch 425: {'train_loss': '0.05051'}; time used = 0.6023468971252441s
epoch 430: {'train_loss': '0.05385'}; time used = 0.8486480712890625s
epoch 435: {'train_loss': '0.04089'}; time used = 0.6213934421539307s
epoch 440: {'train_loss': '0.04738'}; time used = 0.8315579891204834s
epoch 445: {'train_loss': '0.04396'}; time used = 0.7121338844299316s
epoch 450: {'train_loss': '0.05434'}; time used = 0.7210977077484131s
epoch 455: {'train_loss': '0.05234'}; time used = 0.9882082939147949s
epoch 460: {'train_loss': '0.04887'}; time used = 0.9687786102294922s
epoch 465: {'train_loss': '0.04556'}; time used = 0.9627737998962402s
epoch 470: {'train_loss': '0.04594'}; time used = 0.8147585391998291s
epoch 475: {'train_loss': '0.04759'}; time used = 0.6475763320922852s
epoch 480: {'train_loss': '0.04388'}; time used = 0.642578125s
epoch 485: {'train_loss': '0.04622'}; time used = 0.6585109233856201s
epoch 490: {'train_loss': '0.04146'}; time used = 0.7688491344451904s
epoch 495: {'train_loss': '0.05061'}; time used = 0.7285523414611816s
epoch 500: {'train_loss': '0.03835'}; time used = 0.6091625690460205s
Finished training. Time used = 72.35236644744873.
Training classifier using 20.00% nodes...
{'micro': 0.7314259344716197, 'macro': 0.7135228340735799, 'samples': 0.7314259344716197, 'weighted': 0.7285041322278556}

  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122841.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9254/10556 [00:00<00:00, 92534.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 95554.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7295/10556 [00:00<00:00, 72944.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 76602.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109415.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9933/10556 [00:00<00:00, 99324.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 91522.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117324.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9625/10556 [00:00<00:00, 96245.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 92658.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▉      | 4100/10556 [00:00<00:00, 40997.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 53968.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7122/10556 [00:00<00:00, 71216.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 82260.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6203/10556 [00:00<00:00, 62029.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 70703.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111000.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5964/10556 [00:00<00:00, 59638.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 63529.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6507/10556 [00:00<00:00, 65063.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 63708.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117722.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8004/10556 [00:00<00:00, 80035.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 86795.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9908/10556 [00:00<00:00, 99077.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 100323.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9863/10556 [00:00<00:00, 98624.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 100042.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9586/10556 [00:00<00:00, 95853.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 88941.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 7008/10556 [00:00<00:00, 70076.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 66154.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9433/10556 [00:00<00:00, 94325.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 96970.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9566/10556 [00:00<00:00, 95655.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 97431.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9631/10556 [00:00<00:00, 96305.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 98165.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115946.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7093/10556 [00:00<00:00, 70926.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 70891.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10335/10556 [00:00<00:00, 103340.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 103205.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6680/10556 [00:00<00:00, 66799.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 65310.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6970/10556 [00:00<00:00, 69694.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 81210.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6247/10556 [00:00<00:00, 61304.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 71942.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9196/10556 [00:00<00:00, 91956.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 94716.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6377/10556 [00:00<00:00, 63765.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 65459.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108506.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7737/10556 [00:00<00:00, 77368.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 70787.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7585/10556 [00:00<00:00, 73176.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 80740.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8040/10556 [00:00<00:00, 80396.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 87487.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 99572.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107859.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6212/10556 [00:00<00:00, 61580.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 71463.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122299.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9256/10556 [00:00<00:00, 92558.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 95918.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6566/10556 [00:00<00:00, 64714.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 61029.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122816.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 98260.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6198/10556 [00:00<00:00, 61976.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 63926.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|███▋      | 3908/10556 [00:00<00:00, 39075.94it/s] 95%|█████████▍| 10010/10556 [00:00<00:00, 43800.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 50651.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10510/10556 [00:00<00:00, 105095.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 99766.72it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10420/10556 [00:00<00:00, 104194.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 104216.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10500/10556 [00:00<00:00, 97647.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 97097.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124436.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9513/10556 [00:00<00:00, 95128.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 97584.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123165.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121223.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7635/10556 [00:00<00:00, 70034.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 79771.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9898/10556 [00:00<00:00, 98975.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 99708.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9564/10556 [00:00<00:00, 82331.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 82346.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5465/10556 [00:00<00:00, 54646.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 72755.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7725/10556 [00:00<00:00, 77246.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 67780.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10449/10556 [00:00<00:00, 104480.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 104347.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7372/10556 [00:00<00:00, 73713.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 79783.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8027/10556 [00:00<00:00, 80263.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 86626.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124196.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123032.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122736.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125643.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124129.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7370/10556 [00:00<00:00, 66813.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 77442.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118415.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6082/10556 [00:00<00:00, 60818.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 76903.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7615/10556 [00:00<00:00, 70227.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 68302.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120258.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123577.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8357/10556 [00:00<00:00, 83569.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 89686.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6465/10556 [00:00<00:00, 64417.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 62457.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6185/10556 [00:00<00:00, 61846.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 59214.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7128/10556 [00:00<00:00, 71271.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 65840.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|███▊      | 4025/10556 [00:00<00:00, 40249.56it/s] 86%|████████▌ | 9081/10556 [00:00<00:00, 42871.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 47048.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 30%|███       | 3219/10556 [00:00<00:00, 32189.34it/s] 66%|██████▋   | 6995/10556 [00:00<00:00, 33679.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 40124.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5908/10556 [00:00<00:00, 59071.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 60701.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6250/10556 [00:00<00:00, 62492.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 62156.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6609/10556 [00:00<00:00, 66086.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 66384.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6489/10556 [00:00<00:00, 64884.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 65463.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5336/10556 [00:00<00:00, 49509.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 54966.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6182/10556 [00:00<00:00, 61819.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 62619.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|███▍      | 3625/10556 [00:00<00:00, 36057.30it/s] 86%|████████▌ | 9077/10556 [00:00<00:00, 40133.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 47466.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 104899.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6439/10556 [00:00<00:00, 64389.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 71443.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9607/10556 [00:00<00:00, 96067.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 97893.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9814/10556 [00:00<00:00, 98132.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 99459.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115185.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9739/10556 [00:00<00:00, 97388.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 99806.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7217/10556 [00:00<00:00, 72165.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 83511.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122818.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118733.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6979/10556 [00:00<00:00, 69788.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 68913.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109002.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7517/10556 [00:00<00:00, 69842.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 73302.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120474.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5942/10556 [00:00<00:00, 59415.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 60909.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6317/10556 [00:00<00:00, 63161.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 64761.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6523/10556 [00:00<00:00, 65224.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 65884.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6218/10556 [00:00<00:00, 62179.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 62458.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6623/10556 [00:00<00:00, 66225.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 66215.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108053.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7659/10556 [00:00<00:00, 70376.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 74636.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6048/10556 [00:00<00:00, 58415.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 74678.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123355.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114784.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 7006/10556 [00:00<00:00, 70054.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 80880.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124256.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124777.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123325.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124672.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7166/10556 [00:00<00:00, 71655.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 68879.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8392/10556 [00:00<00:00, 83919.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 89234.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████▏  | 7522/10556 [00:00<00:00, 69830.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 78692.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109094.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118641.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122638.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115672.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124220.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10114/10556 [00:00<00:00, 101133.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 101800.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7022/10556 [00:00<00:00, 70216.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 64408.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6335/10556 [00:00<00:00, 56219.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 58999.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129111.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206911.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207156.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202507.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 227799.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214268.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211889.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217716.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170780.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128397.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 231922.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201018.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211375.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213032.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213595.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213777.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208606.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124721.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123291.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126325.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135526.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122080.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133062.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125948.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123461.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110036.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109591.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123592.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118772.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9473/10556 [00:00<00:00, 94729.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 97652.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9114/10556 [00:00<00:00, 91131.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 90430.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122309.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122758.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127143.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133394.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128067.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131776.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134239.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116671.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10116/10556 [00:00<00:00, 101156.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 100017.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123884.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144903.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148887.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147813.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148092.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149217.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148761.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134556.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145902.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144379.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147136.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154026.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147243.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148539.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141158.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218826.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 155282.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211598.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165650.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 223151.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164947.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201521.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171537.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195334.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173768.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 241072.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168796.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 244318.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158026.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205914.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172049.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 226716.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158289.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213565.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157662.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211659.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169541.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179541.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184914.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178177.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181416.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 240395.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200698.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192676.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193398.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194411.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202147.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204943.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216359.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213234.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200192.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203869.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207813.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198545.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210660.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209068.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209697.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209981.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208495.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202221.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210153.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151650.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10360/10556 [00:00<00:00, 103595.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 103365.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9971/10556 [00:00<00:00, 99702.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 100518.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106073.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114306.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7377/10556 [00:00<00:00, 73768.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 63766.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118173.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7753/10556 [00:00<00:00, 75395.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 70083.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10535/10556 [00:00<00:00, 105346.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 105042.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118824.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9027/10556 [00:00<00:00, 90266.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 92683.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118580.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5614/10556 [00:00<00:00, 52419.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 69702.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114993.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109918.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7106/10556 [00:00<00:00, 71057.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 67887.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6345/10556 [00:00<00:00, 63446.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 68074.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7048/10556 [00:00<00:00, 70478.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 82532.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9682/10556 [00:00<00:00, 96819.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 98524.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6726/10556 [00:00<00:00, 67257.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 59700.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7167/10556 [00:00<00:00, 67448.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 59142.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6428/10556 [00:00<00:00, 60590.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 58059.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117874.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9624/10556 [00:00<00:00, 96234.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 98337.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9612/10556 [00:00<00:00, 96112.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 98146.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125386.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6846/10556 [00:00<00:00, 65379.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 55144.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5403/10556 [00:00<00:00, 54026.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 52283.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8711/10556 [00:00<00:00, 87108.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 91910.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121105.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120589.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8264/10556 [00:00<00:00, 76728.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 75260.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9455/10556 [00:00<00:00, 94544.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 84212.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109225.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6339/10556 [00:00<00:00, 63388.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 61638.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6411/10556 [00:00<00:00, 58232.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 58265.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████▏| 9637/10556 [00:00<00:00, 96367.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 98266.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6510/10556 [00:00<00:00, 65091.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 65167.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6628/10556 [00:00<00:00, 66277.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 66061.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|████▌     | 4773/10556 [00:00<00:00, 47725.61it/s] 87%|████████▋ | 9160/10556 [00:00<00:00, 46497.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 42441.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6057/10556 [00:00<00:00, 60563.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 63215.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6618/10556 [00:00<00:00, 66179.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 64349.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6412/10556 [00:00<00:00, 64112.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 64571.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6510/10556 [00:00<00:00, 65097.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 65851.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|████▌     | 4767/10556 [00:00<00:00, 47664.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 53743.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10483/10556 [00:00<00:00, 104825.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 104577.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7262/10556 [00:00<00:00, 69531.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 67194.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105837.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6622/10556 [00:00<00:00, 66218.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 72141.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6106/10556 [00:00<00:00, 61055.84it/s] 78%|███████▊  | 8221/10556 [00:00<00:00, 38269.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 46332.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8103/10556 [00:00<00:00, 78890.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 74656.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8648/10556 [00:00<00:00, 86477.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 91561.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10004/10556 [00:00<00:00, 100034.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 91600.25it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7023/10556 [00:00<00:00, 67994.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 65955.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6841/10556 [00:00<00:00, 66784.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 65287.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7575/10556 [00:00<00:00, 75745.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 82377.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125999.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6629/10556 [00:00<00:00, 65885.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 80087.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124644.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6772/10556 [00:00<00:00, 67715.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 78124.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 9988/10556 [00:00<00:00, 99872.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 88640.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8036/10556 [00:00<00:00, 80356.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 86837.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122303.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10432/10556 [00:00<00:00, 104319.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 104133.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7521/10556 [00:00<00:00, 75208.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 79715.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125387.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9737/10556 [00:00<00:00, 97365.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 98395.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120287.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10555/10556 [00:00<00:00, 105379.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 104937.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7882/10556 [00:00<00:00, 78819.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 87316.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10160/10556 [00:00<00:00, 101594.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 102174.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8766/10556 [00:00<00:00, 87658.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 91318.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120772.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4878/10556 [00:00<00:00, 47037.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 69580.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118026.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7958/10556 [00:00<00:00, 79576.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 87290.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120953.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6627/10556 [00:00<00:00, 65420.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 64479.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9040/10556 [00:00<00:00, 90392.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 81020.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9343/10556 [00:00<00:00, 93426.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 95970.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7947/10556 [00:00<00:00, 79467.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 86071.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121698.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6783/10556 [00:00<00:00, 67824.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 79721.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8085/10556 [00:00<00:00, 80848.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 73045.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9473/10556 [00:00<00:00, 94727.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 96149.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10549/10556 [00:00<00:00, 105487.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 103184.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121197.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8330/10556 [00:00<00:00, 83294.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 88638.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6451/10556 [00:00<00:00, 62721.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 74665.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118604.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6662/10556 [00:00<00:00, 66169.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 80182.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10342/10556 [00:00<00:00, 103417.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 103353.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9312/10556 [00:00<00:00, 93116.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 95779.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123533.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122879.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7548/10556 [00:00<00:00, 69980.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 77646.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9898/10556 [00:00<00:00, 93489.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 94839.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120500.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122122.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115182.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7582/10556 [00:00<00:00, 75815.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 70938.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10156/10556 [00:00<00:00, 101554.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 96613.30it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10150/10556 [00:00<00:00, 99636.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 92785.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9477/10556 [00:00<00:00, 94766.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 97229.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9603/10556 [00:00<00:00, 96022.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 97938.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6680/10556 [00:00<00:00, 66797.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 60682.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6321/10556 [00:00<00:00, 62512.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 65423.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8337/10556 [00:00<00:00, 83365.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 89032.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120800.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5235/10556 [00:00<00:00, 46871.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 58869.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6799/10556 [00:00<00:00, 67986.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 70439.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6414/10556 [00:00<00:00, 64136.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 71455.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6664/10556 [00:00<00:00, 56780.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 58509.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109961.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▊  | 8308/10556 [00:00<00:00, 82435.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 72712.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7424/10556 [00:00<00:00, 74235.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 83942.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106231.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6721/10556 [00:00<00:00, 67209.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 61095.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111077.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10273/10556 [00:00<00:00, 102726.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 90691.93it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10437/10556 [00:00<00:00, 104365.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 104225.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7121/10556 [00:00<00:00, 67590.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 64730.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111890.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|███▊      | 4044/10556 [00:00<00:00, 37184.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 59101.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|████▍     | 4639/10556 [00:00<00:00, 46389.16it/s] 74%|███████▍  | 7837/10556 [00:00<00:00, 40306.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 36695.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|███▎      | 3466/10556 [00:00<00:00, 30490.08it/s] 64%|██████▍   | 6767/10556 [00:00<00:00, 30338.60it/s] 98%|█████████▊| 10350/10556 [00:00<00:00, 31800.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 32323.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125093.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113664.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7656/10556 [00:00<00:00, 76558.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 86143.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6882/10556 [00:00<00:00, 68819.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 79531.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122669.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7362/10556 [00:00<00:00, 67835.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 77459.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9187/10556 [00:00<00:00, 91863.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 94553.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5567/10556 [00:00<00:00, 55666.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 64529.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6592/10556 [00:00<00:00, 65915.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 53553.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6293/10556 [00:00<00:00, 62924.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 63871.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6279/10556 [00:00<00:00, 54056.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 57250.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7457/10556 [00:00<00:00, 68598.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 75821.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████      | 4350/10556 [00:00<00:00, 43496.20it/s] 83%|████████▎ | 8736/10556 [00:00<00:00, 43603.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 45787.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6796/10556 [00:00<00:00, 67954.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 76623.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119921.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6127/10556 [00:00<00:00, 61261.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 73008.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9211/10556 [00:00<00:00, 92109.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 90782.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119415.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6912/10556 [00:00<00:00, 66768.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 64617.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119493.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118104.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123149.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6644/10556 [00:00<00:00, 65993.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 67069.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109859.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10478/10556 [00:00<00:00, 104775.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 98330.05it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6582/10556 [00:00<00:00, 65819.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 71853.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8013/10556 [00:00<00:00, 80129.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 87569.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121602.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8916/10556 [00:00<00:00, 89155.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 91901.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8226/10556 [00:00<00:00, 82258.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 88964.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5985/10556 [00:00<00:00, 59848.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 58515.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6176/10556 [00:00<00:00, 61652.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 61858.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6665/10556 [00:00<00:00, 64738.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 63682.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▎| 9885/10556 [00:00<00:00, 94897.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 95893.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8460/10556 [00:00<00:00, 84599.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 89552.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8895/10556 [00:00<00:00, 88943.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 92627.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117741.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6383/10556 [00:00<00:00, 63822.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 65107.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8379/10556 [00:00<00:00, 74055.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 80756.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120855.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8890/10556 [00:00<00:00, 88899.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 84084.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6326/10556 [00:00<00:00, 60519.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 75358.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|█████     | 5287/10556 [00:00<00:00, 51204.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 53813.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115244.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8215/10556 [00:00<00:00, 82147.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 88067.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9216/10556 [00:00<00:00, 92157.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 95465.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8539/10556 [00:00<00:00, 85389.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 88287.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5563/10556 [00:00<00:00, 55628.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 75138.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5248/10556 [00:00<00:00, 52478.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 60037.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5825/10556 [00:00<00:00, 58246.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 60955.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▎    | 5659/10556 [00:00<00:00, 56586.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 67282.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8787/10556 [00:00<00:00, 87865.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 91436.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8515/10556 [00:00<00:00, 85145.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 90051.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5591/10556 [00:00<00:00, 50006.94it/s] 95%|█████████▌| 10049/10556 [00:00<00:00, 47620.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 46930.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7427/10556 [00:00<00:00, 68341.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 71660.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111201.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 98040.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5229/10556 [00:00<00:00, 52287.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 55390.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9246/10556 [00:00<00:00, 92459.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 85550.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5880/10556 [00:00<00:00, 58796.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 76887.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124427.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7147/10556 [00:00<00:00, 71466.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 70219.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108437.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123141.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████      | 4338/10556 [00:00<00:00, 43377.56it/s] 96%|█████████▋| 10167/10556 [00:00<00:00, 46982.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 50843.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████▏    | 5430/10556 [00:00<00:00, 54298.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 68003.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7085/10556 [00:00<00:00, 70848.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 66577.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7401/10556 [00:00<00:00, 66719.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 57058.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110896.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125699.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|███▌      | 3739/10556 [00:00<00:00, 36176.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 65593.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████▏  | 7532/10556 [00:00<00:00, 75318.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 73088.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6641/10556 [00:00<00:00, 66405.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 66465.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6137/10556 [00:00<00:00, 61362.45it/s] 97%|█████████▋| 10258/10556 [00:00<00:00, 53508.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 50334.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 25%|██▌       | 2689/10556 [00:00<00:00, 25701.32it/s] 76%|███████▌  | 8003/10556 [00:00<00:00, 30411.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 39540.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6194/10556 [00:00<00:00, 61931.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 55453.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6446/10556 [00:00<00:00, 64453.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 65121.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6699/10556 [00:00<00:00, 66984.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 67479.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 31%|███▏      | 3323/10556 [00:00<00:00, 33227.58it/s] 91%|█████████ | 9554/10556 [00:00<00:00, 38637.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 44580.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|██▉       | 3087/10556 [00:00<00:00, 30867.97it/s] 92%|█████████▏| 9706/10556 [00:00<00:00, 36750.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 49592.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4840/10556 [00:00<00:00, 48399.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 56748.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6443/10556 [00:00<00:00, 64427.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 62019.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4851/10556 [00:00<00:00, 48506.69it/s] 79%|███████▉  | 8374/10556 [00:00<00:00, 43578.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 43171.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|███▏      | 3340/10556 [00:00<00:00, 33397.56it/s] 84%|████████▍ | 8849/10556 [00:00<00:00, 37870.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 40019.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6721/10556 [00:00<00:00, 67204.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 67347.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126424.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6825/10556 [00:00<00:00, 66149.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 73975.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7605/10556 [00:00<00:00, 73532.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 80172.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109555.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122362.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123085.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|███▉      | 4201/10556 [00:00<00:00, 42008.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 53770.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6054/10556 [00:00<00:00, 60537.60it/s] 93%|█████████▎| 9777/10556 [00:00<00:00, 50965.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 49838.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4579/10556 [00:00<00:00, 45787.21it/s] 80%|███████▉  | 8414/10556 [00:00<00:00, 43268.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 41172.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5866/10556 [00:00<00:00, 58656.28it/s] 96%|█████████▌| 10113/10556 [00:00<00:00, 51504.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 48435.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6136/10556 [00:00<00:00, 61351.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 53016.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4829/10556 [00:00<00:00, 48286.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 56610.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5346/10556 [00:00<00:00, 53459.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 58704.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6248/10556 [00:00<00:00, 62474.70it/s]100%|█████████▉| 10550/10556 [00:00<00:00, 55010.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 51980.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4970/10556 [00:00<00:00, 49695.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 54432.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6735/10556 [00:00<00:00, 67344.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 57915.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|███▊      | 4024/10556 [00:00<00:00, 39758.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 50052.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7607/10556 [00:00<00:00, 76068.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 86760.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130642.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119848.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122645.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123946.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4977/10556 [00:00<00:00, 47490.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 64016.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6873/10556 [00:00<00:00, 68726.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 74160.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8879/10556 [00:00<00:00, 88787.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 88703.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129911.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195378.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8986/10556 [00:00<00:00, 89854.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 82606.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203343.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191832.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214405.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208448.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213867.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199411.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207650.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207178.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203650.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 245563.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 241619.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200665.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212665.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 223766.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204493.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 241358.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 246149.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200667.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210001.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213468.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212015.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210417.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209555.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193814.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199141.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207541.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198915.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211079.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210992.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213819.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196239.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212419.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203591.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201226.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150222.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147877.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144991.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148328.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147236.59it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '54.97142'}; time used = 0.6419069766998291s
epoch 10: {'train_loss': '2.27608'}; time used = 0.7634353637695312s
epoch 15: {'train_loss': '4.94321'}; time used = 0.7685377597808838s
epoch 20: {'train_loss': '4.41840'}; time used = 0.6780064105987549s
epoch 25: {'train_loss': '2.59079'}; time used = 0.694333553314209s
epoch 30: {'train_loss': '1.31710'}; time used = 0.7306115627288818s
epoch 35: {'train_loss': '1.06979'}; time used = 0.710761547088623s
epoch 40: {'train_loss': '0.61574'}; time used = 0.6873648166656494s
epoch 45: {'train_loss': '0.52297'}; time used = 0.7735388278961182s
epoch 50: {'train_loss': '0.41292'}; time used = 0.5375869274139404s
epoch 55: {'train_loss': '0.33142'}; time used = 0.758540153503418s
epoch 60: {'train_loss': '0.30023'}; time used = 0.5862786769866943s
epoch 65: {'train_loss': '0.24867'}; time used = 0.5527489185333252s
epoch 70: {'train_loss': '0.23022'}; time used = 0.6638674736022949s
epoch 75: {'train_loss': '0.21111'}; time used = 1.106909990310669s
epoch 80: {'train_loss': '0.19474'}; time used = 0.9434154033660889s
epoch 85: {'train_loss': '0.19517'}; time used = 0.8311636447906494s
epoch 90: {'train_loss': '0.18156'}; time used = 0.6081714630126953s
epoch 95: {'train_loss': '0.16372'}; time used = 0.638782262802124s
epoch 100: {'train_loss': '0.16640'}; time used = 0.9043252468109131s
epoch 105: {'train_loss': '0.16286'}; time used = 0.6374497413635254s
epoch 110: {'train_loss': '0.15738'}; time used = 0.5326111316680908s
epoch 115: {'train_loss': '0.14922'}; time used = 0.6721103191375732s
epoch 120: {'train_loss': '0.15006'}; time used = 0.6029922962188721s
epoch 125: {'train_loss': '0.14636'}; time used = 0.47249746322631836s
epoch 130: {'train_loss': '0.14307'}; time used = 0.3018832206726074s
epoch 135: {'train_loss': '0.13257'}; time used = 0.33002448081970215s
epoch 140: {'train_loss': '0.12992'}; time used = 0.3823971748352051s
epoch 145: {'train_loss': '0.11633'}; time used = 0.45879030227661133s
epoch 150: {'train_loss': '0.12687'}; time used = 0.5021045207977295s
epoch 155: {'train_loss': '0.13180'}; time used = 0.5359642505645752s
epoch 160: {'train_loss': '0.11062'}; time used = 0.4639589786529541s
epoch 165: {'train_loss': '0.11449'}; time used = 0.46150779724121094s
epoch 170: {'train_loss': '0.11748'}; time used = 0.41500329971313477s
epoch 175: {'train_loss': '0.11092'}; time used = 0.40863466262817383s
epoch 180: {'train_loss': '0.10325'}; time used = 0.3641946315765381s
epoch 185: {'train_loss': '0.09733'}; time used = 0.33621716499328613s
epoch 190: {'train_loss': '0.10450'}; time used = 0.3374977111816406s
epoch 195: {'train_loss': '0.09736'}; time used = 0.33136701583862305s
epoch 200: {'train_loss': '0.09695'}; time used = 0.3627622127532959s
epoch 205: {'train_loss': '0.09305'}; time used = 0.3242475986480713s
epoch 210: {'train_loss': '0.09344'}; time used = 0.3133735656738281s
epoch 215: {'train_loss': '0.09468'}; time used = 0.31447267532348633s
epoch 220: {'train_loss': '0.08880'}; time used = 0.30487060546875s
epoch 225: {'train_loss': '0.08385'}; time used = 0.4334137439727783s
epoch 230: {'train_loss': '0.08543'}; time used = 0.6802935600280762s
epoch 235: {'train_loss': '0.09011'}; time used = 0.6218180656433105s
epoch 240: {'train_loss': '0.09080'}; time used = 0.7061350345611572s
epoch 245: {'train_loss': '0.08460'}; time used = 0.8512179851531982s
epoch 250: {'train_loss': '0.07664'}; time used = 0.7766237258911133s
epoch 255: {'train_loss': '0.07901'}; time used = 0.6491150856018066s
epoch 260: {'train_loss': '0.08153'}; time used = 0.810096025466919s
epoch 265: {'train_loss': '0.07563'}; time used = 0.9890055656433105s
epoch 270: {'train_loss': '0.07238'}; time used = 0.7961957454681396s
epoch 275: {'train_loss': '0.07877'}; time used = 0.8529412746429443s
epoch 280: {'train_loss': '0.07106'}; time used = 0.7441174983978271s
epoch 285: {'train_loss': '0.07757'}; time used = 0.6213991641998291s
epoch 290: {'train_loss': '0.07266'}; time used = 0.6101467609405518s
epoch 295: {'train_loss': '0.06883'}; time used = 0.614386796951294s
epoch 300: {'train_loss': '0.06602'}; time used = 0.6892085075378418s
epoch 305: {'train_loss': '0.06407'}; time used = 0.657085657119751s
epoch 310: {'train_loss': '0.06770'}; time used = 0.6468100547790527s
epoch 315: {'train_loss': '0.06715'}; time used = 0.6516900062561035s
epoch 320: {'train_loss': '0.06216'}; time used = 0.5999479293823242s
epoch 325: {'train_loss': '0.06461'}; time used = 0.6359119415283203s
epoch 330: {'train_loss': '0.06646'}; time used = 0.754847526550293s
epoch 335: {'train_loss': '0.06794'}; time used = 0.828279972076416s
epoch 340: {'train_loss': '0.06661'}; time used = 0.7170195579528809s
epoch 345: {'train_loss': '0.06405'}; time used = 0.6577396392822266s
epoch 350: {'train_loss': '0.06178'}; time used = 1.086622714996338s
epoch 355: {'train_loss': '0.06604'}; time used = 0.6728296279907227s
epoch 360: {'train_loss': '0.05743'}; time used = 0.9252419471740723s
epoch 365: {'train_loss': '0.05992'}; time used = 0.8014559745788574s
epoch 370: {'train_loss': '0.05420'}; time used = 0.597766637802124s
epoch 375: {'train_loss': '0.05525'}; time used = 0.7142658233642578s
epoch 380: {'train_loss': '0.07369'}; time used = 0.7509472370147705s
epoch 385: {'train_loss': '0.06171'}; time used = 0.7103960514068604s
epoch 390: {'train_loss': '0.05769'}; time used = 0.7669398784637451s
epoch 395: {'train_loss': '0.05527'}; time used = 0.7366316318511963s
epoch 400: {'train_loss': '0.06328'}; time used = 0.8770358562469482s
epoch 405: {'train_loss': '0.05482'}; time used = 0.8019413948059082s
epoch 410: {'train_loss': '0.04923'}; time used = 0.7733888626098633s
epoch 415: {'train_loss': '0.05705'}; time used = 0.7931802272796631s
epoch 420: {'train_loss': '0.05502'}; time used = 0.7568192481994629s
epoch 425: {'train_loss': '0.05908'}; time used = 1.0869112014770508s
epoch 430: {'train_loss': '0.05897'}; time used = 1.052039384841919s
epoch 435: {'train_loss': '0.04915'}; time used = 1.0284159183502197s
epoch 440: {'train_loss': '0.05289'}; time used = 0.6857011318206787s
epoch 445: {'train_loss': '0.04817'}; time used = 1.1681759357452393s
epoch 450: {'train_loss': '0.05526'}; time used = 1.0621871948242188s
epoch 455: {'train_loss': '0.05874'}; time used = 0.5273213386535645s
epoch 460: {'train_loss': '0.05154'}; time used = 0.6138544082641602s
epoch 465: {'train_loss': '0.04875'}; time used = 0.3819918632507324s
epoch 470: {'train_loss': '0.05214'}; time used = 0.30284619331359863s
epoch 475: {'train_loss': '0.05327'}; time used = 0.2843666076660156s
epoch 480: {'train_loss': '0.05120'}; time used = 0.2931199073791504s
epoch 485: {'train_loss': '0.04869'}; time used = 0.3069167137145996s
epoch 490: {'train_loss': '0.04748'}; time used = 0.32611751556396484s
epoch 495: {'train_loss': '0.05264'}; time used = 0.30912113189697266s
epoch 500: {'train_loss': '0.04362'}; time used = 0.409881591796875s
Finished training. Time used = 69.53246855735779.
Training classifier using 20.00% nodes...
{'micro': 0.7544993077988003, 'macro': 0.7389202291066771, 'samples': 0.7544993077988001, 'weighted': 0.7520801601698145}

  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115023.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107885.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126075.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4856/10556 [00:00<00:00, 48151.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 50433.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7116/10556 [00:00<00:00, 71156.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 71368.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122266.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118733.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117079.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9169/10556 [00:00<00:00, 91687.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 95008.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5859/10556 [00:00<00:00, 51821.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 53701.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▋  | 8065/10556 [00:00<00:00, 80649.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 87897.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123283.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6836/10556 [00:00<00:00, 67770.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 79095.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116496.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6461/10556 [00:00<00:00, 64609.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 75730.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▎| 9892/10556 [00:00<00:00, 98916.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 99601.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123922.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8016/10556 [00:00<00:00, 80157.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 86389.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123087.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123267.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123117.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6788/10556 [00:00<00:00, 67876.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 72217.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|███▌      | 3782/10556 [00:00<00:00, 32420.82it/s] 69%|██████▉   | 7314/10556 [00:00<00:00, 32509.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 38415.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109079.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6688/10556 [00:00<00:00, 66778.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 65708.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7108/10556 [00:00<00:00, 71078.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 81434.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5959/10556 [00:00<00:00, 59586.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 58985.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6382/10556 [00:00<00:00, 63817.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 62432.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6777/10556 [00:00<00:00, 67452.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 74342.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113268.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116280.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121469.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7670/10556 [00:00<00:00, 76699.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 76329.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6692/10556 [00:00<00:00, 66918.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 65790.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 9020/10556 [00:00<00:00, 90199.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 93021.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7032/10556 [00:00<00:00, 64122.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 76331.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116670.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111493.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115830.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5763/10556 [00:00<00:00, 54646.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 70653.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▎ | 8821/10556 [00:00<00:00, 78910.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 76528.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6710/10556 [00:00<00:00, 65284.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 62477.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7465/10556 [00:00<00:00, 74644.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 78207.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9728/10556 [00:00<00:00, 84528.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 86463.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122476.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 102414.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6530/10556 [00:00<00:00, 65296.79it/s] 99%|█████████▉| 10458/10556 [00:00<00:00, 54421.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 52173.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6757/10556 [00:00<00:00, 65415.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 69414.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▌| 10039/10556 [00:00<00:00, 100384.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 100127.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119313.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112397.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108232.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109771.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6796/10556 [00:00<00:00, 67957.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 78295.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9147/10556 [00:00<00:00, 91466.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 87876.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9586/10556 [00:00<00:00, 95856.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 92054.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7335/10556 [00:00<00:00, 73346.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 65377.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8562/10556 [00:00<00:00, 85617.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 88318.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8176/10556 [00:00<00:00, 81759.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 87774.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111556.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124378.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122923.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123683.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9102/10556 [00:00<00:00, 91017.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 93954.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10361/10556 [00:00<00:00, 103601.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 103634.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109900.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107295.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131583.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9742/10556 [00:00<00:00, 97414.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 98991.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6636/10556 [00:00<00:00, 66355.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 86461.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115645.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9243/10556 [00:00<00:00, 89940.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 84799.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8648/10556 [00:00<00:00, 86474.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 90432.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108015.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6729/10556 [00:00<00:00, 67285.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 78721.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8341/10556 [00:00<00:00, 83409.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 88935.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118748.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6529/10556 [00:00<00:00, 65282.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 78048.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10189/10556 [00:00<00:00, 101885.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 91294.83it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9590/10556 [00:00<00:00, 95895.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 97804.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7948/10556 [00:00<00:00, 71208.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 51997.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116863.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7990/10556 [00:00<00:00, 79899.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 87545.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121911.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121722.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9913/10556 [00:00<00:00, 99124.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 100014.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106898.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118667.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114907.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6921/10556 [00:00<00:00, 69207.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 63762.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117737.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119923.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116008.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114195.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9383/10556 [00:00<00:00, 93825.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 88079.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7053/10556 [00:00<00:00, 65635.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 74524.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9503/10556 [00:00<00:00, 95026.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 97190.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8984/10556 [00:00<00:00, 89836.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 93310.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8986/10556 [00:00<00:00, 89854.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 92568.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6516/10556 [00:00<00:00, 58408.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 64198.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117940.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115000.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9144/10556 [00:00<00:00, 91435.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 93651.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8705/10556 [00:00<00:00, 87045.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 91899.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10196/10556 [00:00<00:00, 101955.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 102394.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123265.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147146.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218283.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219234.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 237636.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220727.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213800.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212000.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 234124.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 239526.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 237759.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████▏| 9655/10556 [00:00<00:00, 90284.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 86865.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191804.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 234193.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203070.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215370.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204175.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187221.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190983.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128519.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202769.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6895/10556 [00:00<00:00, 68944.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 73386.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8556/10556 [00:00<00:00, 85558.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 85382.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170031.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178011.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175539.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175575.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184308.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195976.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198260.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165474.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 230282.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212114.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184963.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202569.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193692.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205346.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218472.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184756.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199784.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192333.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198630.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193626.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186284.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189217.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185892.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177697.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▎| 9890/10556 [00:00<00:00, 98898.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 100008.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114646.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10402/10556 [00:00<00:00, 104018.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 103939.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109615.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109260.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108039.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112982.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119539.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117722.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117198.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120003.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118431.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119930.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116059.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109677.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151437.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143447.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140914.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142776.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143649.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143360.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142757.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144536.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145512.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141519.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145758.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205379.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203915.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198327.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194574.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214437.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 229803.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209705.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206501.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199615.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196092.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201946.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204761.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210252.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 236147.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 233746.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 238053.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206065.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207045.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203840.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209419.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207823.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203710.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189928.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137834.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████▏  | 7541/10556 [00:00<00:00, 74133.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 80810.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6049/10556 [00:00<00:00, 60485.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 56718.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5685/10556 [00:00<00:00, 56848.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 60693.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6725/10556 [00:00<00:00, 67243.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 67363.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6151/10556 [00:00<00:00, 61505.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 63329.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6650/10556 [00:00<00:00, 66498.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 66494.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|███▋      | 3938/10556 [00:00<00:00, 39379.94it/s] 68%|██████▊   | 7180/10556 [00:00<00:00, 36996.70it/s] 99%|█████████▉| 10457/10556 [00:00<00:00, 34999.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 34168.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|███▌      | 3722/10556 [00:00<00:00, 36083.50it/s] 68%|██████▊   | 7129/10556 [00:00<00:00, 35313.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 34923.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|███▌      | 3793/10556 [00:00<00:00, 36856.24it/s] 84%|████████▍ | 8897/10556 [00:00<00:00, 40208.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 46135.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6056/10556 [00:00<00:00, 60558.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 76886.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6429/10556 [00:00<00:00, 64286.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 60313.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5516/10556 [00:00<00:00, 55156.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 57838.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9330/10556 [00:00<00:00, 93298.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 96182.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████▏| 9655/10556 [00:00<00:00, 96544.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 97066.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106442.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9368/10556 [00:00<00:00, 93674.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 96270.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9571/10556 [00:00<00:00, 87764.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 87192.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6592/10556 [00:00<00:00, 65915.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 79614.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|████▍     | 4647/10556 [00:00<00:00, 46467.61it/s] 96%|█████████▌| 10104/10556 [00:00<00:00, 48164.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 49987.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7580/10556 [00:00<00:00, 75794.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 65631.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7396/10556 [00:00<00:00, 73957.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 69752.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120339.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122085.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▌| 10039/10556 [00:00<00:00, 100381.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 90449.59it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6805/10556 [00:00<00:00, 68044.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 74799.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6103/10556 [00:00<00:00, 58839.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 64782.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 9012/10556 [00:00<00:00, 87812.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 83962.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 9009/10556 [00:00<00:00, 90084.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 93031.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126504.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 103734.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 9984/10556 [00:00<00:00, 99834.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 100729.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115960.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118744.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117116.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108635.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8157/10556 [00:00<00:00, 81567.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 87352.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115180.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119151.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116870.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8878/10556 [00:00<00:00, 88776.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 77798.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111894.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122695.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120240.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6061/10556 [00:00<00:00, 56223.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 69502.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▊   | 7246/10556 [00:00<00:00, 72458.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 65943.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9620/10556 [00:00<00:00, 96197.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 98029.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7983/10556 [00:00<00:00, 71686.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 69343.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121128.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116098.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7998/10556 [00:00<00:00, 79975.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 87877.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7069/10556 [00:00<00:00, 65357.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 60473.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121513.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6863/10556 [00:00<00:00, 68629.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 75943.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124637.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8175/10556 [00:00<00:00, 81748.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 88131.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|████▍     | 4712/10556 [00:00<00:00, 43517.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 46657.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|███▋      | 3863/10556 [00:00<00:00, 36825.42it/s] 69%|██████▉   | 7287/10556 [00:00<00:00, 36008.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 41407.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5082/10556 [00:00<00:00, 50812.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 57073.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6228/10556 [00:00<00:00, 57166.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 62799.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10492/10556 [00:00<00:00, 104919.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 104658.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124474.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7028/10556 [00:00<00:00, 70162.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 67005.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6777/10556 [00:00<00:00, 67766.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 76965.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7995/10556 [00:00<00:00, 79949.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 82111.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124995.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▋  | 8072/10556 [00:00<00:00, 80717.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 74289.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▎| 9891/10556 [00:00<00:00, 98901.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 99839.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7832/10556 [00:00<00:00, 73558.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 81559.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108025.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9857/10556 [00:00<00:00, 98567.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 99398.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7999/10556 [00:00<00:00, 79983.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 87335.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6385/10556 [00:00<00:00, 61114.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 67929.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9919/10556 [00:00<00:00, 99182.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 99837.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10282/10556 [00:00<00:00, 95756.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 85658.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6545/10556 [00:00<00:00, 65447.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 76022.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5018/10556 [00:00<00:00, 48820.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 53723.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6618/10556 [00:00<00:00, 63168.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 62124.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116070.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6794/10556 [00:00<00:00, 67939.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 79329.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120667.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7403/10556 [00:00<00:00, 74028.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 83880.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109161.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9410/10556 [00:00<00:00, 94093.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 96660.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9401/10556 [00:00<00:00, 94004.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 96666.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9556/10556 [00:00<00:00, 95557.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 97584.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124432.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6576/10556 [00:00<00:00, 65757.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 63903.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6901/10556 [00:00<00:00, 69009.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 64480.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9495/10556 [00:00<00:00, 94948.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 96971.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▎| 9888/10556 [00:00<00:00, 98626.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 94595.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6516/10556 [00:00<00:00, 65155.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 72837.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112529.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6523/10556 [00:00<00:00, 64869.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 78536.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122105.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6543/10556 [00:00<00:00, 65227.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 79335.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123884.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123977.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124178.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122039.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118725.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118797.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9528/10556 [00:00<00:00, 95273.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 97547.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114783.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110393.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6707/10556 [00:00<00:00, 58080.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 67172.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7720/10556 [00:00<00:00, 77196.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 84711.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114159.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10260/10556 [00:00<00:00, 102596.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 102733.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6658/10556 [00:00<00:00, 66578.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 79799.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9435/10556 [00:00<00:00, 93375.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 88506.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10425/10556 [00:00<00:00, 104248.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 104189.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129758.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▉      | 4159/10556 [00:00<00:00, 38395.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 57901.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9285/10556 [00:00<00:00, 92842.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 95269.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9319/10556 [00:00<00:00, 93181.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 95429.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10142/10556 [00:00<00:00, 90753.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 91411.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9866/10556 [00:00<00:00, 98654.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 99973.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6754/10556 [00:00<00:00, 64446.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 55792.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10021/10556 [00:00<00:00, 100209.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 101152.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122010.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122769.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120762.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122565.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8918/10556 [00:00<00:00, 89176.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 93410.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8515/10556 [00:00<00:00, 85144.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 89729.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110884.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7566/10556 [00:00<00:00, 75342.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 84592.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170606.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121931.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121343.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9525/10556 [00:00<00:00, 95246.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 90238.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118374.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6295/10556 [00:00<00:00, 61584.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 77183.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6667/10556 [00:00<00:00, 66669.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 73555.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119891.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5151/10556 [00:00<00:00, 51507.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 56679.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7457/10556 [00:00<00:00, 74568.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 83923.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7953/10556 [00:00<00:00, 79524.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 86312.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10491/10556 [00:00<00:00, 97552.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 94637.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10461/10556 [00:00<00:00, 104603.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 104552.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7389/10556 [00:00<00:00, 73885.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 74957.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113300.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5947/10556 [00:00<00:00, 59462.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 60397.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▉      | 4122/10556 [00:00<00:00, 41218.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 65052.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8800/10556 [00:00<00:00, 87995.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 92450.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117531.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123225.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107880.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8903/10556 [00:00<00:00, 89026.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 92848.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7357/10556 [00:00<00:00, 71005.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 81726.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120009.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112374.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6115/10556 [00:00<00:00, 61146.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 77568.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109570.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9370/10556 [00:00<00:00, 93692.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 96364.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122481.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124790.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6657/10556 [00:00<00:00, 65273.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 78737.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7133/10556 [00:00<00:00, 71325.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 82211.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123464.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107216.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117149.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116362.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6369/10556 [00:00<00:00, 63684.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 71400.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8206/10556 [00:00<00:00, 82057.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 70759.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6026/10556 [00:00<00:00, 60259.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 59210.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6552/10556 [00:00<00:00, 65516.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 58396.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119653.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4932/10556 [00:00<00:00, 47757.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 68804.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7693/10556 [00:00<00:00, 76926.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 85889.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8729/10556 [00:00<00:00, 87286.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 77758.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8454/10556 [00:00<00:00, 84538.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 83396.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120236.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112878.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5505/10556 [00:00<00:00, 55045.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 73182.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▊  | 8312/10556 [00:00<00:00, 83114.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 89130.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6771/10556 [00:00<00:00, 67706.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 80547.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6323/10556 [00:00<00:00, 61575.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 64555.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107071.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5636/10556 [00:00<00:00, 56359.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 56496.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6413/10556 [00:00<00:00, 63883.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 76420.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8725/10556 [00:00<00:00, 87246.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 90064.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7338/10556 [00:00<00:00, 73378.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 66473.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123243.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▊   | 7254/10556 [00:00<00:00, 67983.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 62691.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6344/10556 [00:00<00:00, 63435.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 66150.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6708/10556 [00:00<00:00, 67075.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 73789.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5353/10556 [00:00<00:00, 53524.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 57937.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10017/10556 [00:00<00:00, 100164.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 100934.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7660/10556 [00:00<00:00, 73839.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 67186.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6895/10556 [00:00<00:00, 68949.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 64331.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6785/10556 [00:00<00:00, 65842.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 64155.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9031/10556 [00:00<00:00, 90309.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 89052.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120860.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121179.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121748.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10125/10556 [00:00<00:00, 100233.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 100810.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6226/10556 [00:00<00:00, 62258.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 77038.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8324/10556 [00:00<00:00, 83233.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 88865.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9368/10556 [00:00<00:00, 93673.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 92317.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5935/10556 [00:00<00:00, 56506.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 68183.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112845.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5640/10556 [00:00<00:00, 54807.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 61628.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10463/10556 [00:00<00:00, 104629.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 104396.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114466.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118245.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9922/10556 [00:00<00:00, 99219.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 94692.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5623/10556 [00:00<00:00, 56227.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 65412.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10101/10556 [00:00<00:00, 101006.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 101424.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10398/10556 [00:00<00:00, 103979.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 103797.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115322.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108213.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7270/10556 [00:00<00:00, 72696.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 82501.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7353/10556 [00:00<00:00, 73526.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 67529.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7215/10556 [00:00<00:00, 71415.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 58320.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9856/10556 [00:00<00:00, 98559.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 95415.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131030.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115161.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9335/10556 [00:00<00:00, 93342.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 91265.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120383.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10115/10556 [00:00<00:00, 101148.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 101754.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7992/10556 [00:00<00:00, 71569.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 79559.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126190.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10403/10556 [00:00<00:00, 104028.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 104020.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7568/10556 [00:00<00:00, 73017.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 66171.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7981/10556 [00:00<00:00, 78921.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 84192.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8604/10556 [00:00<00:00, 83639.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 88727.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████▏    | 5419/10556 [00:00<00:00, 46156.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 74799.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205012.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199587.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207135.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190696.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202543.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199726.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204383.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168195.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124827.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178497.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207951.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206027.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203901.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210099.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209692.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170959.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8668/10556 [00:00<00:00, 86679.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 97638.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213150.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 242846.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 230515.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 229142.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205820.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198849.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166965.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219821.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216371.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206385.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204429.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190617.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159121.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198043.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188304.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189862.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 223518.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162243.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9360/10556 [00:00<00:00, 93596.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 88665.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166753.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140374.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169733.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183771.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204553.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201752.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209020.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210330.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197157.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205923.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199050.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202808.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194786.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202406.81it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.30177'}; time used = 0.723761796951294s
epoch 10: {'train_loss': '0.99172'}; time used = 0.680844783782959s
epoch 15: {'train_loss': '0.70653'}; time used = 0.6449613571166992s
epoch 20: {'train_loss': '0.52891'}; time used = 0.5476560592651367s
epoch 25: {'train_loss': '0.41561'}; time used = 0.9162991046905518s
epoch 30: {'train_loss': '0.31949'}; time used = 0.7388675212860107s
epoch 35: {'train_loss': '0.34583'}; time used = 0.7556183338165283s
epoch 40: {'train_loss': '0.27478'}; time used = 0.6389877796173096s
epoch 45: {'train_loss': '0.23934'}; time used = 0.6962676048278809s
epoch 50: {'train_loss': '0.21075'}; time used = 0.736971378326416s
epoch 55: {'train_loss': '0.18526'}; time used = 0.6524901390075684s
epoch 60: {'train_loss': '0.17123'}; time used = 0.6743285655975342s
epoch 65: {'train_loss': '0.15479'}; time used = 0.5587899684906006s
epoch 70: {'train_loss': '0.14244'}; time used = 0.5808959007263184s
epoch 75: {'train_loss': '0.14372'}; time used = 0.692950963973999s
epoch 80: {'train_loss': '0.15104'}; time used = 0.73638916015625s
epoch 85: {'train_loss': '0.31384'}; time used = 0.6143476963043213s
epoch 90: {'train_loss': '0.33593'}; time used = 0.6154134273529053s
epoch 95: {'train_loss': '0.26090'}; time used = 0.6050159931182861s
epoch 100: {'train_loss': '0.19379'}; time used = 0.7097988128662109s
epoch 105: {'train_loss': '0.15479'}; time used = 0.6058487892150879s
epoch 110: {'train_loss': '0.12842'}; time used = 0.3152945041656494s
epoch 115: {'train_loss': '0.10773'}; time used = 0.2768716812133789s
epoch 120: {'train_loss': '0.10145'}; time used = 0.373563289642334s
epoch 125: {'train_loss': '0.09396'}; time used = 0.3527100086212158s
epoch 130: {'train_loss': '0.10122'}; time used = 0.5078535079956055s
epoch 135: {'train_loss': '0.09460'}; time used = 0.3413534164428711s
epoch 140: {'train_loss': '0.08310'}; time used = 0.3083667755126953s
epoch 145: {'train_loss': '0.08375'}; time used = 0.3191964626312256s
epoch 150: {'train_loss': '0.09272'}; time used = 0.3299093246459961s
epoch 155: {'train_loss': '0.08128'}; time used = 0.5120692253112793s
epoch 160: {'train_loss': '0.07799'}; time used = 0.5207846164703369s
epoch 165: {'train_loss': '0.09093'}; time used = 0.5021347999572754s
epoch 170: {'train_loss': '0.08503'}; time used = 0.44927144050598145s
epoch 175: {'train_loss': '0.07073'}; time used = 0.43259501457214355s
epoch 180: {'train_loss': '0.07518'}; time used = 0.3646886348724365s
epoch 185: {'train_loss': '0.08072'}; time used = 0.30634641647338867s
epoch 190: {'train_loss': '0.08117'}; time used = 0.317047119140625s
epoch 195: {'train_loss': '0.07408'}; time used = 0.2916297912597656s
epoch 200: {'train_loss': '0.07973'}; time used = 0.3145935535430908s
epoch 205: {'train_loss': '0.07721'}; time used = 0.7962930202484131s
epoch 210: {'train_loss': '0.07318'}; time used = 1.2497138977050781s
epoch 215: {'train_loss': '0.06789'}; time used = 0.7904760837554932s
epoch 220: {'train_loss': '0.06078'}; time used = 0.7560155391693115s
epoch 225: {'train_loss': '0.06629'}; time used = 0.675929069519043s
epoch 230: {'train_loss': '0.07268'}; time used = 0.6973593235015869s
epoch 235: {'train_loss': '0.07662'}; time used = 0.5633640289306641s
epoch 240: {'train_loss': '0.06731'}; time used = 0.5914394855499268s
epoch 245: {'train_loss': '0.06447'}; time used = 0.6608657836914062s
epoch 250: {'train_loss': '0.06132'}; time used = 0.7188930511474609s
epoch 255: {'train_loss': '0.05850'}; time used = 0.6740553379058838s
epoch 260: {'train_loss': '0.07766'}; time used = 1.0379834175109863s
epoch 265: {'train_loss': '0.06327'}; time used = 0.6796705722808838s
epoch 270: {'train_loss': '0.06649'}; time used = 0.6605696678161621s
epoch 275: {'train_loss': '0.07499'}; time used = 0.6962828636169434s
epoch 280: {'train_loss': '0.07445'}; time used = 0.7956576347351074s
epoch 285: {'train_loss': '0.07321'}; time used = 0.6077864170074463s
epoch 290: {'train_loss': '0.07699'}; time used = 0.7143702507019043s
epoch 295: {'train_loss': '0.06694'}; time used = 0.6572511196136475s
epoch 300: {'train_loss': '0.06913'}; time used = 0.5449199676513672s
epoch 305: {'train_loss': '0.07294'}; time used = 0.5526745319366455s
epoch 310: {'train_loss': '0.06982'}; time used = 0.7040035724639893s
epoch 315: {'train_loss': '0.06221'}; time used = 0.7057654857635498s
epoch 320: {'train_loss': '0.06476'}; time used = 0.7127506732940674s
epoch 325: {'train_loss': '0.06094'}; time used = 0.5232055187225342s
epoch 330: {'train_loss': '0.05885'}; time used = 0.548898458480835s
epoch 335: {'train_loss': '0.06651'}; time used = 0.6707220077514648s
epoch 340: {'train_loss': '0.05863'}; time used = 0.7141580581665039s
epoch 345: {'train_loss': '0.06049'}; time used = 0.7602593898773193s
epoch 350: {'train_loss': '0.06280'}; time used = 0.5836403369903564s
epoch 355: {'train_loss': '0.05918'}; time used = 0.6111288070678711s
epoch 360: {'train_loss': '0.06112'}; time used = 0.6036992073059082s
epoch 365: {'train_loss': '0.06448'}; time used = 0.6134834289550781s
epoch 370: {'train_loss': '0.05778'}; time used = 0.8438715934753418s
epoch 375: {'train_loss': '0.05808'}; time used = 0.6755027770996094s
epoch 380: {'train_loss': '0.05738'}; time used = 0.747612476348877s
epoch 385: {'train_loss': '0.06261'}; time used = 0.772545576095581s
epoch 390: {'train_loss': '0.06141'}; time used = 0.8585381507873535s
epoch 395: {'train_loss': '0.06170'}; time used = 0.7651107311248779s
epoch 400: {'train_loss': '0.04749'}; time used = 0.6190383434295654s
epoch 405: {'train_loss': '0.05123'}; time used = 0.7133431434631348s
epoch 410: {'train_loss': '0.05506'}; time used = 0.6584782600402832s
epoch 415: {'train_loss': '0.06155'}; time used = 0.665679931640625s
epoch 420: {'train_loss': '0.04850'}; time used = 0.6618669033050537s
epoch 425: {'train_loss': '0.05432'}; time used = 0.6282064914703369s
epoch 430: {'train_loss': '0.05001'}; time used = 0.7038280963897705s
epoch 435: {'train_loss': '0.05157'}; time used = 0.31307458877563477s
epoch 440: {'train_loss': '0.04778'}; time used = 0.35860466957092285s
epoch 445: {'train_loss': '0.05472'}; time used = 0.31220245361328125s
epoch 450: {'train_loss': '0.05830'}; time used = 0.3444051742553711s
epoch 455: {'train_loss': '0.06117'}; time used = 0.31522345542907715s
epoch 460: {'train_loss': '0.05692'}; time used = 0.3261077404022217s
epoch 465: {'train_loss': '0.04908'}; time used = 0.3963165283203125s
epoch 470: {'train_loss': '0.05643'}; time used = 0.36171555519104004s
epoch 475: {'train_loss': '0.05842'}; time used = 0.3081057071685791s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 62.15420413017273.
Training classifier using 20.00% nodes...
{'micro': 0.72634979233964, 'macro': 0.7050933919704097, 'samples': 0.72634979233964, 'weighted': 0.7252934718080578}
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7967/10556 [00:00<00:00, 79666.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 86128.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8707/10556 [00:00<00:00, 87063.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 91760.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118694.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10357/10556 [00:00<00:00, 103568.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 103309.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8764/10556 [00:00<00:00, 87636.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 89717.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7837/10556 [00:00<00:00, 78364.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 78754.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7590/10556 [00:00<00:00, 75897.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 83785.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5681/10556 [00:00<00:00, 52311.40it/s] 95%|█████████▍| 9980/10556 [00:00<00:00, 49116.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 47838.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10280/10556 [00:00<00:00, 102796.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 102919.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6671/10556 [00:00<00:00, 63965.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 71286.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118009.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9030/10556 [00:00<00:00, 90294.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 94056.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5942/10556 [00:00<00:00, 55031.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 57305.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9434/10556 [00:00<00:00, 94337.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 84112.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9847/10556 [00:00<00:00, 98468.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 99245.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7798/10556 [00:00<00:00, 77975.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 75087.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10152/10556 [00:00<00:00, 101517.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 102052.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121751.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122080.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7058/10556 [00:00<00:00, 70578.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 67005.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122359.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6710/10556 [00:00<00:00, 67098.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 79682.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6483/10556 [00:00<00:00, 63885.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 60834.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5459/10556 [00:00<00:00, 51730.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 70498.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9230/10556 [00:00<00:00, 92293.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 94450.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7377/10556 [00:00<00:00, 71121.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 67862.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10221/10556 [00:00<00:00, 102209.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 102599.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122851.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121859.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6818/10556 [00:00<00:00, 62664.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 61670.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6737/10556 [00:00<00:00, 67366.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 73534.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121018.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119092.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5674/10556 [00:00<00:00, 56739.65it/s] 96%|█████████▌| 10101/10556 [00:00<00:00, 52318.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 51762.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7148/10556 [00:00<00:00, 71476.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 74272.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9734/10556 [00:00<00:00, 97333.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 98895.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122032.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108487.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123737.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6445/10556 [00:00<00:00, 63906.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 73539.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7279/10556 [00:00<00:00, 68377.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 79160.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10544/10556 [00:00<00:00, 105431.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 105206.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108521.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108967.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6537/10556 [00:00<00:00, 65365.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 78069.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115891.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110704.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109745.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109367.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5182/10556 [00:00<00:00, 51819.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 63841.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8997/10556 [00:00<00:00, 89961.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 93264.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6762/10556 [00:00<00:00, 67614.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 78577.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 82547.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129295.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116019.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8921/10556 [00:00<00:00, 89206.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 92914.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████▏| 9641/10556 [00:00<00:00, 96404.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 98063.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121220.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106971.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118395.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10021/10556 [00:00<00:00, 100209.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 100458.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8024/10556 [00:00<00:00, 80239.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 71973.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113896.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111709.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121947.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122194.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114372.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111479.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7809/10556 [00:00<00:00, 78089.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 86100.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 6995/10556 [00:00<00:00, 69949.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 81936.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|████▍     | 4692/10556 [00:00<00:00, 46913.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 53618.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6467/10556 [00:00<00:00, 64665.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 63326.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7352/10556 [00:00<00:00, 73514.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 82111.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7562/10556 [00:00<00:00, 75617.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 78402.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9097/10556 [00:00<00:00, 90964.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 88033.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9835/10556 [00:00<00:00, 98349.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 98938.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5546/10556 [00:00<00:00, 55459.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 62017.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106603.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114504.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9285/10556 [00:00<00:00, 92844.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 95345.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5154/10556 [00:00<00:00, 51536.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 53530.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6705/10556 [00:00<00:00, 67044.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 77844.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118655.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9085/10556 [00:00<00:00, 90844.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 92580.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5191/10556 [00:00<00:00, 43121.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 54351.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9625/10556 [00:00<00:00, 96249.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 96919.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████▏     | 4356/10556 [00:00<00:00, 43484.98it/s] 98%|█████████▊| 10374/10556 [00:00<00:00, 47432.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 51056.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6347/10556 [00:00<00:00, 61309.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 72110.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118316.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7464/10556 [00:00<00:00, 74635.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 81974.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10151/10556 [00:00<00:00, 101506.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 101929.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119578.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6858/10556 [00:00<00:00, 68579.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 65533.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121380.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7556/10556 [00:00<00:00, 69069.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 66558.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123031.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6925/10556 [00:00<00:00, 68929.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 66008.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120070.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7367/10556 [00:00<00:00, 73669.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 83708.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9047/10556 [00:00<00:00, 90262.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 90210.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120741.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6430/10556 [00:00<00:00, 64298.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 78571.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120222.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 7017/10556 [00:00<00:00, 70167.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 63013.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8731/10556 [00:00<00:00, 87306.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 87422.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6500/10556 [00:00<00:00, 64995.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 62459.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8700/10556 [00:00<00:00, 86996.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 90981.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6177/10556 [00:00<00:00, 61769.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 53381.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10326/10556 [00:00<00:00, 103255.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 103228.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118597.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10197/10556 [00:00<00:00, 94125.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 94466.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9865/10556 [00:00<00:00, 98641.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 99739.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118947.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116731.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120880.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9218/10556 [00:00<00:00, 92176.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 94634.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111056.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8537/10556 [00:00<00:00, 85365.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 90776.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8789/10556 [00:00<00:00, 87884.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 92256.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108111.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▊   | 7244/10556 [00:00<00:00, 68269.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 65994.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7312/10556 [00:00<00:00, 70586.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 78139.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111715.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6677/10556 [00:00<00:00, 63663.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 62325.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7185/10556 [00:00<00:00, 71848.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 75305.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████▏  | 7545/10556 [00:00<00:00, 75449.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 84609.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7555/10556 [00:00<00:00, 75545.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 68612.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118842.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120591.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113813.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120391.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6482/10556 [00:00<00:00, 64458.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 78074.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6632/10556 [00:00<00:00, 66316.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 78319.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7293/10556 [00:00<00:00, 72925.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 76092.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6138/10556 [00:00<00:00, 61377.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 68224.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9863/10556 [00:00<00:00, 97769.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 93737.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 6995/10556 [00:00<00:00, 66895.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 74694.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107339.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5738/10556 [00:00<00:00, 57376.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 75302.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7652/10556 [00:00<00:00, 75779.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 70393.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 9981/10556 [00:00<00:00, 99801.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 100151.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116834.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7380/10556 [00:00<00:00, 73794.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 81552.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121606.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122870.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122260.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6060/10556 [00:00<00:00, 60321.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 52827.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8028/10556 [00:00<00:00, 80276.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 85481.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120963.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122563.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6916/10556 [00:00<00:00, 69155.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 81318.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116658.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8385/10556 [00:00<00:00, 83844.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 89704.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9613/10556 [00:00<00:00, 96126.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 83099.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9588/10556 [00:00<00:00, 95876.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 92004.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9745/10556 [00:00<00:00, 97442.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 98855.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7093/10556 [00:00<00:00, 70928.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 65564.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120878.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8234/10556 [00:00<00:00, 82338.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 88686.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9782/10556 [00:00<00:00, 97814.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 93821.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6092/10556 [00:00<00:00, 56511.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 55201.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10303/10556 [00:00<00:00, 103027.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 102839.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116844.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7266/10556 [00:00<00:00, 72656.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 62172.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6714/10556 [00:00<00:00, 67138.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 61361.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9819/10556 [00:00<00:00, 98182.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 99396.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7278/10556 [00:00<00:00, 68069.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 65934.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6665/10556 [00:00<00:00, 66644.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 63765.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7260/10556 [00:00<00:00, 72594.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 63782.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6809/10556 [00:00<00:00, 68084.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 78947.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110344.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████▏| 9652/10556 [00:00<00:00, 96515.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 97805.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7020/10556 [00:00<00:00, 70196.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 71358.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9380/10556 [00:00<00:00, 93794.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 76671.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7195/10556 [00:00<00:00, 71944.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 80967.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109810.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6413/10556 [00:00<00:00, 64128.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 69386.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7143/10556 [00:00<00:00, 71424.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 81589.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123085.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107417.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116758.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109679.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7953/10556 [00:00<00:00, 79522.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 84980.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8972/10556 [00:00<00:00, 81095.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 76650.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▌| 10064/10556 [00:00<00:00, 100632.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 101090.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6748/10556 [00:00<00:00, 65192.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 67982.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121542.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8864/10556 [00:00<00:00, 88633.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 92246.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114778.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6032/10556 [00:00<00:00, 60317.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 71668.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████▏  | 7531/10556 [00:00<00:00, 75303.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 69051.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105278.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5536/10556 [00:00<00:00, 55357.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 61267.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7317/10556 [00:00<00:00, 73169.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 68547.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4443/10556 [00:00<00:00, 40466.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 55025.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9928/10556 [00:00<00:00, 98623.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 97623.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8253/10556 [00:00<00:00, 82525.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 88313.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8955/10556 [00:00<00:00, 89546.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 92602.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7061/10556 [00:00<00:00, 70604.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 65186.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5181/10556 [00:00<00:00, 51808.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 54609.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 103763.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5956/10556 [00:00<00:00, 59557.22it/s] 96%|█████████▌| 10092/10556 [00:00<00:00, 51229.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 49147.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5767/10556 [00:00<00:00, 56674.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 63385.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110726.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9155/10556 [00:00<00:00, 91546.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 92625.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 30%|███       | 3178/10556 [00:00<00:00, 31776.32it/s] 66%|██████▌   | 6972/10556 [00:00<00:00, 33098.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 39301.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10452/10556 [00:00<00:00, 104517.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 104317.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10148/10556 [00:00<00:00, 101475.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 98097.37it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125498.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10257/10556 [00:00<00:00, 102562.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 92114.61it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████▏    | 5434/10556 [00:00<00:00, 54336.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 62253.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▋  | 8075/10556 [00:00<00:00, 80747.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 83784.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5047/10556 [00:00<00:00, 50464.63it/s] 80%|████████  | 8446/10556 [00:00<00:00, 44056.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 45162.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6332/10556 [00:00<00:00, 63315.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 53690.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|███▊      | 4054/10556 [00:00<00:00, 40538.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 67274.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110384.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6812/10556 [00:00<00:00, 68118.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 80834.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6897/10556 [00:00<00:00, 68849.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 73584.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117924.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|███████▉  | 8395/10556 [00:00<00:00, 83943.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 89624.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122110.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9571/10556 [00:00<00:00, 95704.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 93184.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114168.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6040/10556 [00:00<00:00, 60393.72it/s] 98%|█████████▊| 10393/10556 [00:00<00:00, 49857.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 43464.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|███▍      | 3662/10556 [00:00<00:00, 36617.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 55187.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6757/10556 [00:00<00:00, 65638.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 63884.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9685/10556 [00:00<00:00, 96842.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 82667.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108971.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7299/10556 [00:00<00:00, 72987.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 65641.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 27%|██▋       | 2897/10556 [00:00<00:00, 18366.85it/s] 44%|████▍     | 4649/10556 [00:00<00:00, 17528.16it/s] 63%|██████▎   | 6697/10556 [00:00<00:00, 17375.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 23078.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107458.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9829/10556 [00:00<00:00, 94383.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 95823.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 96698.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7287/10556 [00:00<00:00, 72866.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 83151.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7184/10556 [00:00<00:00, 62934.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 52596.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121134.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125550.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6340/10556 [00:00<00:00, 63395.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 69120.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130569.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123753.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118814.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128024.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189909.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117966.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193679.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218022.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207968.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207381.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218595.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 224423.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 232660.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147252.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135374.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181880.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190120.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196428.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202358.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182442.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182183.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199658.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193384.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188411.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194248.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173852.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152662.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196441.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186173.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218876.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 234023.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221844.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 229014.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171084.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212632.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221803.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198341.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192642.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183576.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191745.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159808.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205002.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203791.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182400.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 225927.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194712.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192191.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203085.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203690.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200679.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181618.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199575.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191774.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195103.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6685/10556 [00:00<00:00, 64547.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 77918.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 224781.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193758.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130138.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140594.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190804.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195384.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118395.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219727.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207711.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135064.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160969.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198788.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200424.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133810.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127239.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190517.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201102.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172702.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203657.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204521.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198569.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191049.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201831.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200327.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193878.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207072.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205778.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201000.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203483.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206086.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198878.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207274.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202354.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203183.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205610.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201881.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188886.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206359.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204681.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187209.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196375.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198939.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205294.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200969.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198348.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203649.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202649.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193201.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176997.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7396/10556 [00:00<00:00, 73957.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 83942.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108298.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107460.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6495/10556 [00:00<00:00, 64002.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 77932.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6294/10556 [00:00<00:00, 53973.22it/s] 90%|█████████ | 9511/10556 [00:00<00:00, 44553.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 43574.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5897/10556 [00:00<00:00, 56696.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 52997.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6181/10556 [00:00<00:00, 61122.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 60542.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|███▊      | 3991/10556 [00:00<00:00, 39907.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 54532.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7883/10556 [00:00<00:00, 78828.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 83137.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123840.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9672/10556 [00:00<00:00, 96714.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 93228.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129648.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6909/10556 [00:00<00:00, 66719.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 75142.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123880.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119367.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118216.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118713.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6012/10556 [00:00<00:00, 60119.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 76624.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120275.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7131/10556 [00:00<00:00, 67261.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 65612.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 7000/10556 [00:00<00:00, 66224.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 64672.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6106/10556 [00:00<00:00, 60776.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 61013.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8541/10556 [00:00<00:00, 85401.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 90530.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122090.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123715.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121014.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121411.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9268/10556 [00:00<00:00, 92674.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 94961.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115785.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7992/10556 [00:00<00:00, 79918.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 87492.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9367/10556 [00:00<00:00, 93669.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 96123.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7450/10556 [00:00<00:00, 68617.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 73738.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10413/10556 [00:00<00:00, 104125.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 97777.18it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5553/10556 [00:00<00:00, 53203.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 66463.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109243.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6409/10556 [00:00<00:00, 63458.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 77738.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122295.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9309/10556 [00:00<00:00, 93083.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 94738.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9676/10556 [00:00<00:00, 96755.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 97615.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9348/10556 [00:00<00:00, 93473.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 95357.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8462/10556 [00:00<00:00, 84615.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 89719.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6611/10556 [00:00<00:00, 65026.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 63513.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8724/10556 [00:00<00:00, 87237.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 91266.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9364/10556 [00:00<00:00, 93636.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 96058.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10411/10556 [00:00<00:00, 104106.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 103702.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7216/10556 [00:00<00:00, 61929.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 72942.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119722.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7028/10556 [00:00<00:00, 70277.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 81606.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120188.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4860/10556 [00:00<00:00, 46251.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 51331.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7492/10556 [00:00<00:00, 74914.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 80751.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6686/10556 [00:00<00:00, 66854.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 77861.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113575.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5511/10556 [00:00<00:00, 50583.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 58792.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9426/10556 [00:00<00:00, 94257.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 91935.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9679/10556 [00:00<00:00, 88655.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 87037.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8971/10556 [00:00<00:00, 89684.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 92200.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9737/10556 [00:00<00:00, 97361.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 98735.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 9014/10556 [00:00<00:00, 90136.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 92767.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7926/10556 [00:00<00:00, 76636.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 64589.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116813.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6742/10556 [00:00<00:00, 67417.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 80728.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119510.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109797.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122597.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121975.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110552.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117632.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110492.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8276/10556 [00:00<00:00, 82758.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 88440.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9930/10556 [00:00<00:00, 99296.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 100139.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110988.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109887.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9129/10556 [00:00<00:00, 91287.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 93959.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▌| 10050/10556 [00:00<00:00, 100493.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 101161.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8475/10556 [00:00<00:00, 84748.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 72922.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111483.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8098/10556 [00:00<00:00, 80975.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 88003.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123089.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118007.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123099.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112690.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6916/10556 [00:00<00:00, 69159.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 63411.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115198.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7560/10556 [00:00<00:00, 75596.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 84746.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120089.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|████▌     | 4864/10556 [00:00<00:00, 44782.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 62773.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10360/10556 [00:00<00:00, 92734.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 92948.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119989.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6246/10556 [00:00<00:00, 62454.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 76080.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6652/10556 [00:00<00:00, 66518.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 67264.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120844.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10002/10556 [00:00<00:00, 97087.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 97084.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8027/10556 [00:00<00:00, 80267.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 87438.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8903/10556 [00:00<00:00, 89029.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 92569.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7748/10556 [00:00<00:00, 77478.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 75523.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6200/10556 [00:00<00:00, 61995.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 60787.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5354/10556 [00:00<00:00, 52193.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 68926.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8808/10556 [00:00<00:00, 88077.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 91290.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9181/10556 [00:00<00:00, 91806.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 93478.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6127/10556 [00:00<00:00, 58779.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 59881.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7225/10556 [00:00<00:00, 60442.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 70143.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6107/10556 [00:00<00:00, 61067.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 69435.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112894.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6546/10556 [00:00<00:00, 65458.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 62153.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105603.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8032/10556 [00:00<00:00, 80317.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 86966.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116959.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6718/10556 [00:00<00:00, 67176.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 75911.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121603.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115249.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7411/10556 [00:00<00:00, 68400.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 73176.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9567/10556 [00:00<00:00, 93058.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 88546.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6675/10556 [00:00<00:00, 65025.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 63291.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120598.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7096/10556 [00:00<00:00, 70957.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 81085.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121369.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6377/10556 [00:00<00:00, 63400.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 76696.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116253.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6914/10556 [00:00<00:00, 67879.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 71885.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6790/10556 [00:00<00:00, 67896.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 61807.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115151.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7820/10556 [00:00<00:00, 78198.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 86220.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8323/10556 [00:00<00:00, 81959.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 77810.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 28%|██▊       | 2988/10556 [00:00<00:00, 28773.62it/s] 62%|██████▏   | 6523/10556 [00:00<00:00, 30473.81it/s] 94%|█████████▍| 9944/10556 [00:00<00:00, 30902.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 32036.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|███▍      | 3593/10556 [00:00<00:00, 35059.30it/s] 94%|█████████▍| 9962/10556 [00:00<00:00, 39972.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 47675.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6834/10556 [00:00<00:00, 65700.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 63989.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|███████▉  | 8427/10556 [00:00<00:00, 84264.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 89983.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6990/10556 [00:00<00:00, 66785.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 78583.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8952/10556 [00:00<00:00, 89514.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 93101.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8224/10556 [00:00<00:00, 82238.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 67431.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7090/10556 [00:00<00:00, 66538.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 63399.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122753.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6863/10556 [00:00<00:00, 68629.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 80068.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120957.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 16%|█▋        | 1731/10556 [00:00<00:00, 17047.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 59810.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5818/10556 [00:00<00:00, 58178.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 74594.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▉      | 4137/10556 [00:00<00:00, 36261.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 54119.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118600.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10524/10556 [00:00<00:00, 105238.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 104899.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8079/10556 [00:00<00:00, 80785.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 87188.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9566/10556 [00:00<00:00, 95659.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 97845.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119112.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8711/10556 [00:00<00:00, 87108.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 91686.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118068.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119536.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 6995/10556 [00:00<00:00, 69949.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 78336.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110283.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9608/10556 [00:00<00:00, 96079.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 90947.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7947/10556 [00:00<00:00, 77521.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 85478.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6886/10556 [00:00<00:00, 68858.59it/s] 93%|█████████▎| 9774/10556 [00:00<00:00, 47507.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 39858.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████      | 4351/10556 [00:00<00:00, 43504.75it/s] 70%|██████▉   | 7346/10556 [00:00<00:00, 38303.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 38989.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6236/10556 [00:00<00:00, 62357.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 62891.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6107/10556 [00:00<00:00, 61064.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 62668.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|███▋      | 3953/10556 [00:00<00:00, 39527.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 67490.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120841.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10276/10556 [00:00<00:00, 102753.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 102945.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108998.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7074/10556 [00:00<00:00, 69658.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 80701.74it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '3.14024'}; time used = 0.6717410087585449s
epoch 10: {'train_loss': '1.37939'}; time used = 0.7706024646759033s
epoch 15: {'train_loss': '1.37876'}; time used = 0.7600283622741699s
epoch 20: {'train_loss': '1.37620'}; time used = 0.5911178588867188s
epoch 25: {'train_loss': '1.37222'}; time used = 0.817033052444458s
epoch 30: {'train_loss': '1.37035'}; time used = 0.7200698852539062s
epoch 35: {'train_loss': '1.36715'}; time used = 0.7390749454498291s
epoch 40: {'train_loss': '1.36270'}; time used = 0.6428613662719727s
epoch 45: {'train_loss': '1.35983'}; time used = 0.6113042831420898s
epoch 50: {'train_loss': '1.35983'}; time used = 0.6327440738677979s
epoch 55: {'train_loss': '1.36015'}; time used = 0.6453447341918945s
epoch 60: {'train_loss': '1.35477'}; time used = 0.5699865818023682s
epoch 65: {'train_loss': '1.35329'}; time used = 0.5653767585754395s
epoch 70: {'train_loss': '1.35092'}; time used = 0.734487771987915s
epoch 75: {'train_loss': '1.34611'}; time used = 0.7313518524169922s
epoch 80: {'train_loss': '1.34643'}; time used = 0.7727417945861816s
epoch 85: {'train_loss': '1.34482'}; time used = 0.7300598621368408s
epoch 90: {'train_loss': '1.34464'}; time used = 0.7923228740692139s
epoch 95: {'train_loss': '1.34361'}; time used = 0.6531836986541748s
epoch 100: {'train_loss': '1.34180'}; time used = 0.6693000793457031s
epoch 105: {'train_loss': '1.33990'}; time used = 0.7612209320068359s
epoch 110: {'train_loss': '1.33819'}; time used = 0.7116143703460693s
epoch 115: {'train_loss': '1.34061'}; time used = 0.5869457721710205s
epoch 120: {'train_loss': '1.33600'}; time used = 0.7148904800415039s
epoch 125: {'train_loss': '1.33517'}; time used = 0.769749641418457s
epoch 130: {'train_loss': '1.33188'}; time used = 0.6070878505706787s
epoch 135: {'train_loss': '1.32156'}; time used = 0.7645542621612549s
epoch 140: {'train_loss': '1.32515'}; time used = 0.7197842597961426s
epoch 145: {'train_loss': '1.31618'}; time used = 0.5518298149108887s
epoch 150: {'train_loss': '1.30371'}; time used = 0.7012999057769775s
epoch 155: {'train_loss': '1.27823'}; time used = 0.6614785194396973s
epoch 160: {'train_loss': '1.30202'}; time used = 0.818619966506958s
epoch 165: {'train_loss': '1.32275'}; time used = 0.7272219657897949s
epoch 170: {'train_loss': '1.33416'}; time used = 0.8027570247650146s
epoch 175: {'train_loss': '1.34639'}; time used = 0.7322690486907959s
epoch 180: {'train_loss': '1.33613'}; time used = 0.6421971321105957s
epoch 185: {'train_loss': '1.33305'}; time used = 0.7118470668792725s
epoch 190: {'train_loss': '1.31487'}; time used = 0.6962616443634033s
epoch 195: {'train_loss': '1.31198'}; time used = 0.8073983192443848s
epoch 200: {'train_loss': '1.31134'}; time used = 0.7806708812713623s
epoch 205: {'train_loss': '1.30581'}; time used = 0.9607551097869873s
epoch 210: {'train_loss': '1.30158'}; time used = 0.6887402534484863s
epoch 215: {'train_loss': '1.29698'}; time used = 0.908865213394165s
epoch 220: {'train_loss': '1.29433'}; time used = 0.6473228931427002s
epoch 225: {'train_loss': '1.29245'}; time used = 0.9116566181182861s
epoch 230: {'train_loss': '1.28596'}; time used = 1.079113245010376s
epoch 235: {'train_loss': '1.28437'}; time used = 0.7247347831726074s
epoch 240: {'train_loss': '1.27688'}; time used = 0.5588901042938232s
epoch 245: {'train_loss': '1.25832'}; time used = 0.40331244468688965s
epoch 250: {'train_loss': '1.25542'}; time used = 0.29699039459228516s
epoch 255: {'train_loss': '1.33942'}; time used = 0.3691112995147705s
epoch 260: {'train_loss': '1.32153'}; time used = 0.3276197910308838s
epoch 265: {'train_loss': '1.32144'}; time used = 0.35460805892944336s
epoch 270: {'train_loss': '1.32330'}; time used = 0.3024027347564697s
epoch 275: {'train_loss': '1.31341'}; time used = 0.34122371673583984s
epoch 280: {'train_loss': '1.31000'}; time used = 0.3374021053314209s
epoch 285: {'train_loss': '1.30957'}; time used = 0.32431960105895996s
epoch 290: {'train_loss': '1.30480'}; time used = 0.32651233673095703s
epoch 295: {'train_loss': '1.30596'}; time used = 0.42992639541625977s
epoch 300: {'train_loss': '1.29907'}; time used = 0.38268184661865234s
epoch 305: {'train_loss': '1.30324'}; time used = 0.3692307472229004s
epoch 310: {'train_loss': '1.30150'}; time used = 0.38431382179260254s
epoch 315: {'train_loss': '1.30082'}; time used = 0.33966970443725586s
epoch 320: {'train_loss': '1.29510'}; time used = 0.32337427139282227s
epoch 325: {'train_loss': '1.29265'}; time used = 0.31905627250671387s
epoch 330: {'train_loss': '1.28730'}; time used = 0.3213796615600586s
epoch 335: {'train_loss': '1.27023'}; time used = 0.3228566646575928s
epoch 340: {'train_loss': '1.31657'}; time used = 0.322049617767334s
epoch 345: {'train_loss': '1.29841'}; time used = 0.6006391048431396s
epoch 350: {'train_loss': '1.29644'}; time used = 1.0204830169677734s
epoch 355: {'train_loss': '1.29182'}; time used = 0.6096415519714355s
epoch 360: {'train_loss': '1.28531'}; time used = 0.5850780010223389s
epoch 365: {'train_loss': '1.27756'}; time used = 0.7789232730865479s
epoch 370: {'train_loss': '1.26602'}; time used = 0.5314149856567383s
epoch 375: {'train_loss': '1.25361'}; time used = 0.7130165100097656s
epoch 380: {'train_loss': '1.26994'}; time used = 0.6163408756256104s
epoch 385: {'train_loss': '1.25676'}; time used = 0.7238912582397461s
epoch 390: {'train_loss': '1.24816'}; time used = 0.6738791465759277s
epoch 395: {'train_loss': '1.24141'}; time used = 0.842376708984375s
epoch 400: {'train_loss': '1.22758'}; time used = 0.6513400077819824s
epoch 405: {'train_loss': '1.22275'}; time used = 0.6412615776062012s
epoch 410: {'train_loss': '1.21758'}; time used = 0.5326483249664307s
epoch 415: {'train_loss': '1.21485'}; time used = 0.6443812847137451s
epoch 420: {'train_loss': '1.20410'}; time used = 0.6362721920013428s
epoch 425: {'train_loss': '1.20459'}; time used = 0.6124439239501953s
epoch 430: {'train_loss': '1.20629'}; time used = 0.6700196266174316s
epoch 435: {'train_loss': '1.19964'}; time used = 0.7045817375183105s
epoch 440: {'train_loss': '1.19953'}; time used = 0.7807018756866455s
epoch 445: {'train_loss': '1.18872'}; time used = 0.7943520545959473s
epoch 450: {'train_loss': '1.19709'}; time used = 0.7016696929931641s
epoch 455: {'train_loss': '1.20148'}; time used = 0.6776092052459717s
epoch 460: {'train_loss': '1.19134'}; time used = 0.6228244304656982s
epoch 465: {'train_loss': '1.19212'}; time used = 0.7532956600189209s
epoch 470: {'train_loss': '1.19110'}; time used = 1.0723788738250732s
epoch 475: {'train_loss': '1.18981'}; time used = 0.7603709697723389s
epoch 480: {'train_loss': '1.18298'}; time used = 0.8165385723114014s
epoch 485: {'train_loss': '1.17478'}; time used = 0.6777558326721191s
epoch 490: {'train_loss': '1.16373'}; time used = 0.6440982818603516s
epoch 495: {'train_loss': '1.16737'}; time used = 1.0894989967346191s
epoch 500: {'train_loss': '1.16821'}; time used = 0.6642014980316162s
Finished training. Time used = 68.84202814102173.
Training classifier using 20.00% nodes...
{'micro': 0.31195200738347945, 'macro': 0.10780292092777032, 'samples': 0.31195200738347945, 'weighted': 0.1874455586712928}

  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164580.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126737.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156710.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215924.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221631.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222884.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216237.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210233.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169329.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179035.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196763.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 156352.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214278.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202192.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208502.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212414.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209485.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208467.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208848.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204616.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192006.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196407.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208814.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187453.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207753.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201181.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208715.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 165106.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175142.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175937.00it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '3.49291'}; time used = 0.36612915992736816s
epoch 10: {'train_loss': '1.38640'}; time used = 0.331831693649292s
epoch 15: {'train_loss': '1.38631'}; time used = 0.32421374320983887s
epoch 20: {'train_loss': '1.38629'}; time used = 0.3160123825073242s
epoch 25: {'train_loss': '1.38630'}; time used = 0.3221404552459717s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.20637583732605.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4437/10556 [00:00<00:00, 44368.35it/s] 82%|████████▏ | 8681/10556 [00:00<00:00, 43717.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 40732.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6071/10556 [00:00<00:00, 60707.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 75159.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116340.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6506/10556 [00:00<00:00, 65058.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 63461.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6859/10556 [00:00<00:00, 68589.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 71056.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9721/10556 [00:00<00:00, 97202.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 84748.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8970/10556 [00:00<00:00, 89698.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 92569.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10192/10556 [00:00<00:00, 101911.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 101676.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8750/10556 [00:00<00:00, 87494.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 91213.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6100/10556 [00:00<00:00, 60997.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 59411.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9048/10556 [00:00<00:00, 90473.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 92496.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116605.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7441/10556 [00:00<00:00, 74407.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 83652.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5988/10556 [00:00<00:00, 59653.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 69271.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9711/10556 [00:00<00:00, 97106.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 98105.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109165.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8103/10556 [00:00<00:00, 81023.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 79703.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8343/10556 [00:00<00:00, 83423.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 83543.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8709/10556 [00:00<00:00, 87086.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 91237.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120054.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8211/10556 [00:00<00:00, 81899.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 83902.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10300/10556 [00:00<00:00, 102992.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 103218.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6990/10556 [00:00<00:00, 67755.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 72572.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106688.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7172/10556 [00:00<00:00, 63991.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 61997.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6071/10556 [00:00<00:00, 60708.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 57376.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10208/10556 [00:00<00:00, 102072.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 98863.82it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7075/10556 [00:00<00:00, 70748.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 81362.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105767.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|███▊      | 3975/10556 [00:00<00:00, 39746.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 54198.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5826/10556 [00:00<00:00, 56668.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 53088.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8377/10556 [00:00<00:00, 83769.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 86627.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6627/10556 [00:00<00:00, 66268.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 82403.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115683.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|████▏     | 4391/10556 [00:00<00:00, 43908.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 53818.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5984/10556 [00:00<00:00, 59836.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 54029.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▎    | 5672/10556 [00:00<00:00, 52762.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 61654.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106424.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 166346.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115031.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111310.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9040/10556 [00:00<00:00, 90397.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 93965.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124732.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10418/10556 [00:00<00:00, 104175.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 99357.23it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107836.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9490/10556 [00:00<00:00, 94898.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 96780.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115650.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117601.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112874.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9550/10556 [00:00<00:00, 95498.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 96374.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114558.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7994/10556 [00:00<00:00, 79936.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 86497.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|█████     | 5320/10556 [00:00<00:00, 50803.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 71146.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7139/10556 [00:00<00:00, 71387.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 71898.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9277/10556 [00:00<00:00, 90532.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 93230.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6530/10556 [00:00<00:00, 63769.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 61204.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5572/10556 [00:00<00:00, 55717.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 68589.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9264/10556 [00:00<00:00, 90685.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 88680.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6155/10556 [00:00<00:00, 60963.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 67659.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118375.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5975/10556 [00:00<00:00, 59748.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 72817.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6540/10556 [00:00<00:00, 62312.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 69586.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 7005/10556 [00:00<00:00, 70049.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 65014.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117190.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8923/10556 [00:00<00:00, 89227.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 92990.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10096/10556 [00:00<00:00, 100959.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 101460.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9297/10556 [00:00<00:00, 92964.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 88259.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118694.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8244/10556 [00:00<00:00, 82435.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 87669.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6300/10556 [00:00<00:00, 62996.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 66739.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7918/10556 [00:00<00:00, 79176.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 73109.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6630/10556 [00:00<00:00, 66295.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 62541.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5613/10556 [00:00<00:00, 54323.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 59790.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9204/10556 [00:00<00:00, 92033.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 95199.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7974/10556 [00:00<00:00, 79733.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 86969.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119712.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109680.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▊     | 5141/10556 [00:00<00:00, 51407.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 61935.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118489.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115857.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111306.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123428.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118898.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7822/10556 [00:00<00:00, 72549.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 69862.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7021/10556 [00:00<00:00, 70208.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 73991.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▊     | 5138/10556 [00:00<00:00, 51378.33it/s] 89%|████████▉ | 9413/10556 [00:00<00:00, 48014.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 47431.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8161/10556 [00:00<00:00, 81609.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 82127.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9590/10556 [00:00<00:00, 95894.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 97574.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7327/10556 [00:00<00:00, 66270.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 65714.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6674/10556 [00:00<00:00, 64743.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 71336.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116407.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109655.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114537.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5994/10556 [00:00<00:00, 59939.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 75224.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9205/10556 [00:00<00:00, 92043.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 94895.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9420/10556 [00:00<00:00, 94193.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 95613.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6165/10556 [00:00<00:00, 61648.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 64607.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9783/10556 [00:00<00:00, 97824.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 98803.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6569/10556 [00:00<00:00, 64870.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 78110.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9038/10556 [00:00<00:00, 78929.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 82829.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████▏  | 7526/10556 [00:00<00:00, 75257.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 80074.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7385/10556 [00:00<00:00, 73844.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 83246.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119654.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111796.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121291.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9230/10556 [00:00<00:00, 92299.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 95014.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114686.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118400.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116911.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7403/10556 [00:00<00:00, 71092.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 69533.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118681.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111932.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112532.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119502.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120839.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10499/10556 [00:00<00:00, 104989.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 104715.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106617.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4988/10556 [00:00<00:00, 49879.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 53610.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120216.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7929/10556 [00:00<00:00, 79286.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 73774.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6199/10556 [00:00<00:00, 61985.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 61338.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10499/10556 [00:00<00:00, 104984.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 104858.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120271.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10140/10556 [00:00<00:00, 101394.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 99726.27it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10087/10556 [00:00<00:00, 100867.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 99692.14it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8569/10556 [00:00<00:00, 85689.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 90676.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9770/10556 [00:00<00:00, 97697.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 94503.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117397.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9351/10556 [00:00<00:00, 93505.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 95417.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8177/10556 [00:00<00:00, 81768.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 74692.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105512.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7072/10556 [00:00<00:00, 70719.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 81430.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7514/10556 [00:00<00:00, 69042.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 73792.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|███████▉  | 8436/10556 [00:00<00:00, 82547.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 78472.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117063.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6670/10556 [00:00<00:00, 62830.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 61858.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111061.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105632.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122436.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114322.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8688/10556 [00:00<00:00, 86876.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 79024.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9162/10556 [00:00<00:00, 91617.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 94545.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118203.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8867/10556 [00:00<00:00, 88665.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 87989.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110839.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142735.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151800.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157058.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171356.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 163469.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 164459.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193642.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196661.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191830.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200572.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191062.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194848.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195342.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201969.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198219.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208307.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203957.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209789.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206686.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204402.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199605.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207326.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202216.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202121.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202760.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204228.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207004.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205170.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192202.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202989.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207832.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201048.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193766.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193374.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193921.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188127.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203823.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197710.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202628.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198377.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196580.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212517.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203143.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202790.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204253.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203023.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203334.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200486.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193708.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205690.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205266.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203667.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202241.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189333.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204433.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207844.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199579.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190276.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200410.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192205.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206052.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201223.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200766.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203776.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199938.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171264.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184365.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172182.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129694.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132759.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143361.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138781.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145683.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147038.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141853.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8361/10556 [00:00<00:00, 83606.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 95633.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191425.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185427.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178052.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187375.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181637.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112156.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████▏| 9645/10556 [00:00<00:00, 96443.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 98940.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162519.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179083.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184146.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184551.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181650.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178513.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186259.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193193.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182505.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186951.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191724.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188415.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194762.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188969.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189588.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193278.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193038.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172965.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190448.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194875.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185125.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 134217.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154185.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150973.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146911.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144624.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143181.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145115.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146421.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144578.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144309.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147093.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145134.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143495.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145817.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143377.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148015.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139978.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140433.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142755.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147359.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141698.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144858.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142004.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145390.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145946.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141775.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146680.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144889.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143842.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139193.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146083.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144985.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146093.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142335.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141820.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145953.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206403.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193117.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133608.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205666.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200739.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180272.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177020.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186456.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190359.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140697.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151986.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140348.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144732.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139085.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145234.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139494.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145910.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145735.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145113.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136087.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137409.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143520.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144639.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143396.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142519.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138064.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141285.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147297.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144738.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140206.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140834.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139431.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208725.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199587.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210902.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189442.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202558.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200953.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147947.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218905.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205270.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196259.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8384/10556 [00:00<00:00, 83835.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 88548.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112438.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9686/10556 [00:00<00:00, 89758.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 87364.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 103249.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6118/10556 [00:00<00:00, 60401.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 58467.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10276/10556 [00:00<00:00, 102752.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 100971.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7321/10556 [00:00<00:00, 73204.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 82854.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121735.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130414.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 5985/10556 [00:00<00:00, 57475.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 58726.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6743/10556 [00:00<00:00, 67426.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 72335.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6828/10556 [00:00<00:00, 62409.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 75542.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6596/10556 [00:00<00:00, 65956.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 72582.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123250.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121221.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9322/10556 [00:00<00:00, 93107.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 86100.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9626/10556 [00:00<00:00, 96254.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 92925.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7688/10556 [00:00<00:00, 76874.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 65105.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8085/10556 [00:00<00:00, 80848.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 79538.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113098.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▊     | 5139/10556 [00:00<00:00, 46975.62it/s] 97%|█████████▋| 10236/10556 [00:00<00:00, 48106.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 48858.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6731/10556 [00:00<00:00, 67309.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 60741.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8917/10556 [00:00<00:00, 89165.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 90230.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116541.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117026.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9199/10556 [00:00<00:00, 91989.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 94725.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118887.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5917/10556 [00:00<00:00, 59167.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 52283.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6914/10556 [00:00<00:00, 69135.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 80752.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7823/10556 [00:00<00:00, 78225.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 83080.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5811/10556 [00:00<00:00, 56976.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 57204.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|███▌      | 3818/10556 [00:00<00:00, 36789.94it/s] 85%|████████▍ | 8967/10556 [00:00<00:00, 39945.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 44192.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4530/10556 [00:00<00:00, 42025.24it/s] 91%|█████████ | 9571/10556 [00:00<00:00, 44157.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 47877.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7187/10556 [00:00<00:00, 69700.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 65510.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10362/10556 [00:00<00:00, 103612.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 103640.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6850/10556 [00:00<00:00, 68464.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 73991.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7126/10556 [00:00<00:00, 66067.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 67589.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▊      | 4073/10556 [00:00<00:00, 40616.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 59089.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████▏ | 8583/10556 [00:00<00:00, 85825.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 85556.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7051/10556 [00:00<00:00, 70367.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 75378.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108684.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10160/10556 [00:00<00:00, 101596.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 101787.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6355/10556 [00:00<00:00, 62252.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 74858.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6373/10556 [00:00<00:00, 61254.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 70351.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110324.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107246.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112368.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8673/10556 [00:00<00:00, 86722.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 86254.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123724.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8880/10556 [00:00<00:00, 88795.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 84980.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10440/10556 [00:00<00:00, 104398.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 104258.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5337/10556 [00:00<00:00, 53369.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 55351.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118172.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4528/10556 [00:00<00:00, 43642.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 56798.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108594.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106817.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112192.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 104918.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118156.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115236.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8955/10556 [00:00<00:00, 89548.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 89549.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7506/10556 [00:00<00:00, 72182.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 59054.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6746/10556 [00:00<00:00, 66912.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 64892.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110164.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 23%|██▎       | 2447/10556 [00:00<00:00, 20809.64it/s] 74%|███████▍  | 7806/10556 [00:00<00:00, 25486.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 38751.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9580/10556 [00:00<00:00, 95797.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 82027.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6825/10556 [00:00<00:00, 65441.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 64229.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6548/10556 [00:00<00:00, 63509.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 60244.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8717/10556 [00:00<00:00, 69461.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 50579.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6655/10556 [00:00<00:00, 59907.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 52587.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6451/10556 [00:00<00:00, 58677.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 57366.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124237.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130677.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109350.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125791.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117795.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114794.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123247.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118442.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120318.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9576/10556 [00:00<00:00, 95755.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 81348.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9049/10556 [00:00<00:00, 90484.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 93621.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119213.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120555.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118463.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120474.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119357.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116027.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118755.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116045.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5386/10556 [00:00<00:00, 53857.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 64456.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117125.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10529/10556 [00:00<00:00, 105284.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 104692.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114122.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8345/10556 [00:00<00:00, 83020.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 81729.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8226/10556 [00:00<00:00, 82257.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 82609.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9202/10556 [00:00<00:00, 92012.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 93101.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112236.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7633/10556 [00:00<00:00, 76329.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 81112.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116123.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9813/10556 [00:00<00:00, 98128.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 97844.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7497/10556 [00:00<00:00, 74969.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 84507.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7053/10556 [00:00<00:00, 66332.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 64685.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117469.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107179.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7589/10556 [00:00<00:00, 75886.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 84055.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10275/10556 [00:00<00:00, 102749.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 102885.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6556/10556 [00:00<00:00, 65559.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 60538.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9525/10556 [00:00<00:00, 95249.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 97074.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10513/10556 [00:00<00:00, 105129.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 104825.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118219.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6641/10556 [00:00<00:00, 66404.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 78292.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112270.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7098/10556 [00:00<00:00, 70978.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 65289.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110576.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8766/10556 [00:00<00:00, 87653.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 91595.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114294.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127264.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112079.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10419/10556 [00:00<00:00, 104181.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 98862.05it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6685/10556 [00:00<00:00, 66846.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 68749.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8380/10556 [00:00<00:00, 83798.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 89429.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7934/10556 [00:00<00:00, 79339.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 86538.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115483.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110825.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6574/10556 [00:00<00:00, 65735.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 79286.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6617/10556 [00:00<00:00, 66165.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 78544.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8098/10556 [00:00<00:00, 80976.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 86569.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6674/10556 [00:00<00:00, 66739.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 78307.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7729/10556 [00:00<00:00, 77288.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 85168.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 98533.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7619/10556 [00:00<00:00, 76186.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 84731.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9825/10556 [00:00<00:00, 97474.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 98579.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6341/10556 [00:00<00:00, 59499.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 73308.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112991.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6471/10556 [00:00<00:00, 64574.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 77451.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5948/10556 [00:00<00:00, 58646.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 65435.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8624/10556 [00:00<00:00, 86238.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 90912.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9161/10556 [00:00<00:00, 91609.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 94732.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111212.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8160/10556 [00:00<00:00, 81595.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 81256.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6036/10556 [00:00<00:00, 55273.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 55567.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▊   | 7234/10556 [00:00<00:00, 72019.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 82228.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109147.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107458.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9975/10556 [00:00<00:00, 99748.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 100504.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|████████▉ | 9451/10556 [00:00<00:00, 94506.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 96806.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10137/10556 [00:00<00:00, 101367.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 101734.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6632/10556 [00:00<00:00, 66314.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 79265.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6791/10556 [00:00<00:00, 67904.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 76847.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112081.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6921/10556 [00:00<00:00, 69205.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 76640.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117629.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6718/10556 [00:00<00:00, 65976.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 65826.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6390/10556 [00:00<00:00, 62557.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 62502.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6092/10556 [00:00<00:00, 60917.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 59222.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7848/10556 [00:00<00:00, 78474.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 85530.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7422/10556 [00:00<00:00, 74216.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 82815.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6581/10556 [00:00<00:00, 65806.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 67203.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|████      | 4228/10556 [00:00<00:00, 36394.44it/s] 83%|████████▎ | 8772/10556 [00:00<00:00, 37430.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 40377.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110956.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7717/10556 [00:00<00:00, 77163.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 86095.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123225.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6175/10556 [00:00<00:00, 60050.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 60718.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8700/10556 [00:00<00:00, 86993.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 90766.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115510.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7391/10556 [00:00<00:00, 73907.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 82722.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115974.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128441.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10088/10556 [00:00<00:00, 96156.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 97343.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114093.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8038/10556 [00:00<00:00, 80379.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 87348.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121920.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7570/10556 [00:00<00:00, 66564.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 75508.86it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.36696'}; time used = 0.8155560493469238s
epoch 10: {'train_loss': '1.29931'}; time used = 0.7003233432769775s
epoch 15: {'train_loss': '1.24589'}; time used = 0.6657922267913818s
epoch 20: {'train_loss': '1.16117'}; time used = 0.7036449909210205s
epoch 25: {'train_loss': '1.01199'}; time used = 0.7810201644897461s
epoch 30: {'train_loss': '0.87835'}; time used = 0.8403773307800293s
epoch 35: {'train_loss': '0.76060'}; time used = 0.8479313850402832s
epoch 40: {'train_loss': '0.65409'}; time used = 0.601346492767334s
epoch 45: {'train_loss': '0.55646'}; time used = 0.5864355564117432s
epoch 50: {'train_loss': '0.49801'}; time used = 0.5349981784820557s
epoch 55: {'train_loss': '0.45752'}; time used = 0.8177852630615234s
epoch 60: {'train_loss': '0.39834'}; time used = 0.7766032218933105s
epoch 65: {'train_loss': '0.38403'}; time used = 0.7061812877655029s
epoch 70: {'train_loss': '0.34221'}; time used = 0.7323257923126221s
epoch 75: {'train_loss': '0.32851'}; time used = 0.8063178062438965s
epoch 80: {'train_loss': '0.29660'}; time used = 0.6399953365325928s
epoch 85: {'train_loss': '0.27463'}; time used = 0.8107645511627197s
epoch 90: {'train_loss': '0.25778'}; time used = 0.7294375896453857s
epoch 95: {'train_loss': '0.24634'}; time used = 0.6559648513793945s
epoch 100: {'train_loss': '0.25020'}; time used = 0.744511604309082s
epoch 105: {'train_loss': '0.23151'}; time used = 0.6120123863220215s
epoch 110: {'train_loss': '0.22207'}; time used = 0.6088399887084961s
epoch 115: {'train_loss': '0.21136'}; time used = 0.5823898315429688s
epoch 120: {'train_loss': '0.22633'}; time used = 0.7937593460083008s
epoch 125: {'train_loss': '0.36294'}; time used = 0.610945463180542s
epoch 130: {'train_loss': '0.25732'}; time used = 0.6527383327484131s
epoch 135: {'train_loss': '0.21730'}; time used = 0.7683906555175781s
epoch 140: {'train_loss': '0.20478'}; time used = 0.6004428863525391s
epoch 145: {'train_loss': '0.19809'}; time used = 0.5652825832366943s
epoch 150: {'train_loss': '0.18451'}; time used = 0.3757951259613037s
epoch 155: {'train_loss': '0.18458'}; time used = 0.3288581371307373s
epoch 160: {'train_loss': '0.17439'}; time used = 0.3086051940917969s
epoch 165: {'train_loss': '0.16506'}; time used = 0.3029215335845947s
epoch 170: {'train_loss': '0.15915'}; time used = 0.3050224781036377s
epoch 175: {'train_loss': '0.14963'}; time used = 0.30779337882995605s
epoch 180: {'train_loss': '0.16128'}; time used = 0.3200953006744385s
epoch 185: {'train_loss': '0.15075'}; time used = 0.3115396499633789s
epoch 190: {'train_loss': '0.14518'}; time used = 0.3067665100097656s
epoch 195: {'train_loss': '0.14315'}; time used = 0.30875110626220703s
epoch 200: {'train_loss': '0.13570'}; time used = 0.31039977073669434s
epoch 205: {'train_loss': '0.13944'}; time used = 0.31447291374206543s
epoch 210: {'train_loss': '0.13369'}; time used = 0.3206508159637451s
epoch 215: {'train_loss': '0.13277'}; time used = 0.42228031158447266s
epoch 220: {'train_loss': '0.13215'}; time used = 0.46865248680114746s
epoch 225: {'train_loss': '0.13570'}; time used = 0.3364980220794678s
epoch 230: {'train_loss': '0.12919'}; time used = 0.43854570388793945s
epoch 235: {'train_loss': '0.12960'}; time used = 0.346909761428833s
epoch 240: {'train_loss': '0.12461'}; time used = 0.3402397632598877s
epoch 245: {'train_loss': '0.13345'}; time used = 0.34705233573913574s
epoch 250: {'train_loss': '0.13809'}; time used = 0.36882662773132324s
epoch 255: {'train_loss': '0.12800'}; time used = 0.4210200309753418s
epoch 260: {'train_loss': '0.11568'}; time used = 0.4182727336883545s
epoch 265: {'train_loss': '0.13030'}; time used = 0.4303908348083496s
epoch 270: {'train_loss': '0.11883'}; time used = 0.42620849609375s
epoch 275: {'train_loss': '0.12536'}; time used = 0.4263031482696533s
epoch 280: {'train_loss': '0.12186'}; time used = 0.42856574058532715s
epoch 285: {'train_loss': '0.12528'}; time used = 0.4136486053466797s
epoch 290: {'train_loss': '0.12845'}; time used = 0.3494572639465332s
epoch 295: {'train_loss': '0.12215'}; time used = 0.3751533031463623s
epoch 300: {'train_loss': '0.11798'}; time used = 0.4391968250274658s
epoch 305: {'train_loss': '0.11012'}; time used = 0.44229650497436523s
epoch 310: {'train_loss': '0.11619'}; time used = 0.4308507442474365s
epoch 315: {'train_loss': '0.10426'}; time used = 0.43320178985595703s
epoch 320: {'train_loss': '0.11081'}; time used = 0.3567633628845215s
epoch 325: {'train_loss': '0.10976'}; time used = 0.35582637786865234s
epoch 330: {'train_loss': '0.11225'}; time used = 0.5607104301452637s
epoch 335: {'train_loss': '0.10728'}; time used = 0.6837747097015381s
epoch 340: {'train_loss': '0.11417'}; time used = 0.7830703258514404s
epoch 345: {'train_loss': '0.10759'}; time used = 0.7101848125457764s
epoch 350: {'train_loss': '0.10263'}; time used = 0.7771644592285156s
epoch 355: {'train_loss': '0.10382'}; time used = 0.7016696929931641s
epoch 360: {'train_loss': '0.09813'}; time used = 1.0245280265808105s
epoch 365: {'train_loss': '0.11019'}; time used = 0.8220186233520508s
epoch 370: {'train_loss': '0.10057'}; time used = 0.7423677444458008s
epoch 375: {'train_loss': '0.09260'}; time used = 0.5862009525299072s
epoch 380: {'train_loss': '0.09883'}; time used = 0.8337910175323486s
epoch 385: {'train_loss': '0.08539'}; time used = 0.5796215534210205s
epoch 390: {'train_loss': '0.08761'}; time used = 0.7461514472961426s
epoch 395: {'train_loss': '0.09416'}; time used = 1.035639762878418s
epoch 400: {'train_loss': '0.10329'}; time used = 0.7598333358764648s
epoch 405: {'train_loss': '0.10138'}; time used = 0.4938325881958008s
epoch 410: {'train_loss': '0.10488'}; time used = 0.572481632232666s
epoch 415: {'train_loss': '0.09393'}; time used = 0.5155370235443115s
epoch 420: {'train_loss': '0.09033'}; time used = 0.6329288482666016s
epoch 425: {'train_loss': '0.09460'}; time used = 0.7163324356079102s
epoch 430: {'train_loss': '0.09510'}; time used = 0.6792981624603271s
epoch 435: {'train_loss': '0.08598'}; time used = 0.7099609375s
epoch 440: {'train_loss': '0.09854'}; time used = 0.6637682914733887s
epoch 445: {'train_loss': '0.09055'}; time used = 0.562324047088623s
epoch 450: {'train_loss': '0.08148'}; time used = 0.7000746726989746s
epoch 455: {'train_loss': '0.07940'}; time used = 0.7069377899169922s
epoch 460: {'train_loss': '0.08924'}; time used = 0.698375940322876s
epoch 465: {'train_loss': '0.08991'}; time used = 0.7356312274932861s
epoch 470: {'train_loss': '0.08866'}; time used = 0.7371103763580322s
epoch 475: {'train_loss': '0.08432'}; time used = 0.7133505344390869s
epoch 480: {'train_loss': '0.08537'}; time used = 0.7105534076690674s
epoch 485: {'train_loss': '0.08191'}; time used = 0.8409547805786133s
epoch 490: {'train_loss': '0.08650'}; time used = 0.8539988994598389s
epoch 495: {'train_loss': '0.08569'}; time used = 0.6110179424285889s
epoch 500: {'train_loss': '0.08672'}; time used = 0.6396133899688721s
Finished training. Time used = 64.65559124946594.
Training classifier using 20.00% nodes...
{'micro': 0.7544993077988003, 'macro': 0.7446148771419775, 'samples': 0.7544993077988001, 'weighted': 0.7519972279868037}

  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208071.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175701.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176773.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142839.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149153.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173071.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 162332.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181758.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175589.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158877.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171424.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176027.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176831.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167005.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176153.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171666.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177389.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181426.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168917.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140812.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141953.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138000.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147617.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137353.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139943.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129386.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137903.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127929.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138198.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141440.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137053.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140294.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141737.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140020.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123934.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138613.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140623.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140401.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141680.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142360.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143240.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136646.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139587.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142833.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131856.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137699.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140657.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188792.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190909.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180737.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159262.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157033.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218588.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190138.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211961.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189631.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185111.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191718.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159745.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189392.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182934.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137588.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143490.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141292.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119184.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141245.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124370.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129363.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139829.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140462.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142585.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140684.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142446.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120061.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145070.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113599.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122841.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143638.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144561.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125140.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185020.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 163025.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108607.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112506.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114319.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7131/10556 [00:00<00:00, 71309.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 75181.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106210.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6340/10556 [00:00<00:00, 62367.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 71438.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7608/10556 [00:00<00:00, 76075.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 84062.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115446.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6577/10556 [00:00<00:00, 57728.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 69214.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111359.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6653/10556 [00:00<00:00, 66527.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 76058.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9811/10556 [00:00<00:00, 98101.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 98482.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6351/10556 [00:00<00:00, 63509.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 65577.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9250/10556 [00:00<00:00, 92494.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 94189.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109865.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▋  | 8061/10556 [00:00<00:00, 80603.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 86423.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110171.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8191/10556 [00:00<00:00, 81902.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 82638.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5943/10556 [00:00<00:00, 57415.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 61466.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6352/10556 [00:00<00:00, 63518.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 70285.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108509.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113651.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106753.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114248.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7220/10556 [00:00<00:00, 72198.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 71197.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▋| 10161/10556 [00:00<00:00, 101606.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 101746.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6371/10556 [00:00<00:00, 62533.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 61202.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 9024/10556 [00:00<00:00, 90236.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 93508.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5729/10556 [00:00<00:00, 57288.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 55648.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6759/10556 [00:00<00:00, 67588.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 79697.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5843/10556 [00:00<00:00, 58427.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 74771.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6888/10556 [00:00<00:00, 68875.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 80231.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6789/10556 [00:00<00:00, 67882.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 64617.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6296/10556 [00:00<00:00, 62956.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 76729.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5090/10556 [00:00<00:00, 50899.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 70593.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119321.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116116.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10307/10556 [00:00<00:00, 96096.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 93920.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117192.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119663.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9617/10556 [00:00<00:00, 96164.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 96787.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116309.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116415.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117087.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6045/10556 [00:00<00:00, 60447.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 60917.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10304/10556 [00:00<00:00, 101770.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 101873.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6282/10556 [00:00<00:00, 62819.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 66475.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109505.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109614.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9955/10556 [00:00<00:00, 95446.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 73892.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10473/10556 [00:00<00:00, 104728.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 103144.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10109/10556 [00:00<00:00, 101080.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 99588.76it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9765/10556 [00:00<00:00, 97648.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 98213.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6106/10556 [00:00<00:00, 61059.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 57724.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112605.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115367.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9188/10556 [00:00<00:00, 91879.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 88142.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|█████     | 5325/10556 [00:00<00:00, 53248.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 72109.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7618/10556 [00:00<00:00, 76175.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 83784.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 7972/10556 [00:00<00:00, 77377.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 83551.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7599/10556 [00:00<00:00, 74298.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 76563.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111652.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116264.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8640/10556 [00:00<00:00, 86395.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 90803.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117425.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117654.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6238/10556 [00:00<00:00, 60208.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 63484.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7070/10556 [00:00<00:00, 70696.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 62355.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7455/10556 [00:00<00:00, 71063.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 70936.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6908/10556 [00:00<00:00, 64356.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 60638.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▋ | 9115/10556 [00:00<00:00, 91148.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 78955.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5611/10556 [00:00<00:00, 56108.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 67626.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112050.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6621/10556 [00:00<00:00, 66208.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 78489.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111714.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6352/10556 [00:00<00:00, 59825.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 53259.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115257.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108885.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8719/10556 [00:00<00:00, 87188.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 91718.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9028/10556 [00:00<00:00, 90274.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 93820.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114973.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106500.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6661/10556 [00:00<00:00, 66275.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 64353.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7021/10556 [00:00<00:00, 70209.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 67599.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8328/10556 [00:00<00:00, 83278.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 86010.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7182/10556 [00:00<00:00, 66656.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 68983.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▊  | 8311/10556 [00:00<00:00, 83108.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 87763.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6145/10556 [00:00<00:00, 60455.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 58467.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5855/10556 [00:00<00:00, 58450.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 61304.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10365/10556 [00:00<00:00, 103644.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 103682.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7025/10556 [00:00<00:00, 70244.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 76761.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110128.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6818/10556 [00:00<00:00, 68175.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 77718.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114701.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6381/10556 [00:00<00:00, 63217.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 77921.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115357.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7505/10556 [00:00<00:00, 75049.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 83817.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7129/10556 [00:00<00:00, 71285.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 64755.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7480/10556 [00:00<00:00, 74795.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 83590.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117227.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6197/10556 [00:00<00:00, 61937.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 60816.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10190/10556 [00:00<00:00, 101895.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 97328.39it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5941/10556 [00:00<00:00, 59406.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 57586.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6771/10556 [00:00<00:00, 64871.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 62045.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5834/10556 [00:00<00:00, 57644.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 56649.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▊   | 7233/10556 [00:00<00:00, 65128.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 62518.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113278.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10291/10556 [00:00<00:00, 102904.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 103725.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108147.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112235.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6510/10556 [00:00<00:00, 63707.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 73029.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106071.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114415.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107709.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9765/10556 [00:00<00:00, 97642.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 98676.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6787/10556 [00:00<00:00, 64380.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 62304.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6325/10556 [00:00<00:00, 63246.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 78408.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8641/10556 [00:00<00:00, 86408.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 89649.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7225/10556 [00:00<00:00, 72244.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 64198.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9504/10556 [00:00<00:00, 95037.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 97214.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9799/10556 [00:00<00:00, 97988.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 96017.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6845/10556 [00:00<00:00, 63995.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 73387.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116233.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7225/10556 [00:00<00:00, 72248.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 82695.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106852.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 9013/10556 [00:00<00:00, 90127.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 93582.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117154.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6510/10556 [00:00<00:00, 64371.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 58323.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115924.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7193/10556 [00:00<00:00, 71924.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 80497.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6019/10556 [00:00<00:00, 60188.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 53703.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10240/10556 [00:00<00:00, 102399.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 102649.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 6999/10556 [00:00<00:00, 64840.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 59995.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8898/10556 [00:00<00:00, 88978.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 92720.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9818/10556 [00:00<00:00, 98176.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 98335.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9742/10556 [00:00<00:00, 97413.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 98278.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7434/10556 [00:00<00:00, 74337.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 81542.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106791.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7549/10556 [00:00<00:00, 75489.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 83989.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117128.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7475/10556 [00:00<00:00, 68666.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 69099.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9717/10556 [00:00<00:00, 97164.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 98679.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5230/10556 [00:00<00:00, 52296.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 72680.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114964.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6719/10556 [00:00<00:00, 66768.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 79291.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7061/10556 [00:00<00:00, 70608.72it/s] 92%|█████████▏| 9714/10556 [00:00<00:00, 47119.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 48652.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6008/10556 [00:00<00:00, 60075.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 70172.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5240/10556 [00:00<00:00, 49448.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 54901.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7307/10556 [00:00<00:00, 71696.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 71912.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 9987/10556 [00:00<00:00, 99867.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 98592.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6415/10556 [00:00<00:00, 64140.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 73181.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8348/10556 [00:00<00:00, 81638.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 73045.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7814/10556 [00:00<00:00, 78136.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 80700.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4962/10556 [00:00<00:00, 49617.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 58182.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7085/10556 [00:00<00:00, 68648.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 54669.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7157/10556 [00:00<00:00, 71565.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 76117.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7715/10556 [00:00<00:00, 77149.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 85048.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6607/10556 [00:00<00:00, 66068.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 79830.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114947.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110067.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████▏    | 5428/10556 [00:00<00:00, 54275.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 66651.42it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.40356'}; time used = 0.4033365249633789s
epoch 10: {'train_loss': '1.38665'}; time used = 0.3650500774383545s
epoch 15: {'train_loss': '1.38237'}; time used = 0.3563976287841797s
epoch 20: {'train_loss': '1.33156'}; time used = 0.380748987197876s
epoch 25: {'train_loss': '1.36583'}; time used = 0.4368457794189453s
epoch 30: {'train_loss': '1.32528'}; time used = 0.44416213035583496s
epoch 35: {'train_loss': '1.23109'}; time used = 0.4470241069793701s
epoch 40: {'train_loss': '1.14315'}; time used = 0.42742085456848145s
epoch 45: {'train_loss': '1.08249'}; time used = 0.4472038745880127s
epoch 50: {'train_loss': '1.04137'}; time used = 0.3712489604949951s
epoch 55: {'train_loss': '0.93100'}; time used = 0.3522377014160156s
epoch 60: {'train_loss': '0.86411'}; time used = 0.3477308750152588s
epoch 65: {'train_loss': '0.80286'}; time used = 0.450242280960083s
epoch 70: {'train_loss': '0.75950'}; time used = 0.4511754512786865s
epoch 75: {'train_loss': '0.72308'}; time used = 0.46295762062072754s
epoch 80: {'train_loss': '0.68539'}; time used = 0.4371352195739746s
epoch 85: {'train_loss': '0.65780'}; time used = 0.5474367141723633s
epoch 90: {'train_loss': '0.60356'}; time used = 0.6925842761993408s
epoch 95: {'train_loss': '0.57430'}; time used = 0.6901419162750244s
epoch 100: {'train_loss': '0.55401'}; time used = 0.6954817771911621s
epoch 105: {'train_loss': '0.55833'}; time used = 0.6192140579223633s
epoch 110: {'train_loss': '0.53776'}; time used = 0.8079726696014404s
epoch 115: {'train_loss': '0.60360'}; time used = 0.8188283443450928s
epoch 120: {'train_loss': '0.60496'}; time used = 0.6198909282684326s
epoch 125: {'train_loss': '0.54227'}; time used = 0.566413402557373s
epoch 130: {'train_loss': '0.50243'}; time used = 0.7178399562835693s
epoch 135: {'train_loss': '0.45941'}; time used = 0.7297425270080566s
epoch 140: {'train_loss': '0.43466'}; time used = 0.6796722412109375s
epoch 145: {'train_loss': '0.41855'}; time used = 0.6558923721313477s
epoch 150: {'train_loss': '0.40007'}; time used = 0.7498509883880615s
epoch 155: {'train_loss': '0.45886'}; time used = 0.7841196060180664s
epoch 160: {'train_loss': '0.39224'}; time used = 0.6860294342041016s
epoch 165: {'train_loss': '0.39983'}; time used = 0.7164785861968994s
epoch 170: {'train_loss': '0.37552'}; time used = 0.850745677947998s
epoch 175: {'train_loss': '0.39664'}; time used = 0.6435961723327637s
epoch 180: {'train_loss': '0.41311'}; time used = 0.7524855136871338s
epoch 185: {'train_loss': '0.35749'}; time used = 0.8233718872070312s
epoch 190: {'train_loss': '0.33615'}; time used = 0.731217622756958s
epoch 195: {'train_loss': '0.33806'}; time used = 0.5886290073394775s
epoch 200: {'train_loss': '0.32616'}; time used = 0.8271872997283936s
epoch 205: {'train_loss': '0.32083'}; time used = 0.6790080070495605s
epoch 210: {'train_loss': '0.38033'}; time used = 0.6531767845153809s
epoch 215: {'train_loss': '0.33815'}; time used = 0.8200333118438721s
epoch 220: {'train_loss': '0.32305'}; time used = 0.66214919090271s
epoch 225: {'train_loss': '0.30708'}; time used = 0.6735491752624512s
epoch 230: {'train_loss': '0.28772'}; time used = 0.9363529682159424s
epoch 235: {'train_loss': '0.27515'}; time used = 0.8235869407653809s
epoch 240: {'train_loss': '0.32822'}; time used = 0.8104152679443359s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.85195994377136.
Training classifier using 20.00% nodes...
{'micro': 0.753576372865713, 'macro': 0.7197262419392615, 'samples': 0.753576372865713, 'weighted': 0.7509132968928501}
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 234228.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174498.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110410.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133713.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137140.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151796.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182694.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130923.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141055.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151940.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146099.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158739.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108098.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132826.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150934.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128198.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 135290.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149677.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10478/10556 [00:00<00:00, 104775.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 103138.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124518.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125502.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6540/10556 [00:00<00:00, 64190.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 76533.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6132/10556 [00:00<00:00, 61318.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 58367.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6962/10556 [00:00<00:00, 63649.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 75939.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8965/10556 [00:00<00:00, 82767.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 85628.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 102164.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7157/10556 [00:00<00:00, 71565.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 83909.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10294/10556 [00:00<00:00, 102935.68it/s]100%|██████████| 10556/10556 [00:00<00:00, 103041.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10359/10556 [00:00<00:00, 103588.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 103759.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108365.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112194.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7851/10556 [00:00<00:00, 78507.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 87175.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124646.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7144/10556 [00:00<00:00, 69110.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 63402.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5550/10556 [00:00<00:00, 55499.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 63797.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9428/10556 [00:00<00:00, 94276.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 96465.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7463/10556 [00:00<00:00, 54669.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 61723.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8698/10556 [00:00<00:00, 86397.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 78958.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6287/10556 [00:00<00:00, 62867.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 57743.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6038/10556 [00:00<00:00, 60379.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 55725.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117324.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6387/10556 [00:00<00:00, 63864.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 61523.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5928/10556 [00:00<00:00, 57556.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 57806.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124951.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8547/10556 [00:00<00:00, 85469.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 90579.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118011.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10359/10556 [00:00<00:00, 103584.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 103695.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108073.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110887.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5947/10556 [00:00<00:00, 51337.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 63539.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|████      | 4254/10556 [00:00<00:00, 36904.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 50044.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123566.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9529/10556 [00:00<00:00, 95284.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 97516.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118511.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7284/10556 [00:00<00:00, 72837.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 83779.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 101257.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6910/10556 [00:00<00:00, 67235.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 70209.69it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.40654'}; time used = 0.4786205291748047s
epoch 10: {'train_loss': '1.39003'}; time used = 0.416184663772583s
epoch 15: {'train_loss': '1.39023'}; time used = 0.4607069492340088s
epoch 20: {'train_loss': '1.38968'}; time used = 0.4876077175140381s
epoch 25: {'train_loss': '1.38873'}; time used = 0.7549810409545898s
epoch 30: {'train_loss': '1.38776'}; time used = 0.5892050266265869s
epoch 35: {'train_loss': '1.38701'}; time used = 0.749443531036377s
epoch 40: {'train_loss': '1.38656'}; time used = 0.8538846969604492s
epoch 45: {'train_loss': '1.38635'}; time used = 0.7198710441589355s
epoch 50: {'train_loss': '1.38630'}; time used = 0.7587709426879883s
epoch 55: {'train_loss': '1.38630'}; time used = 0.5928182601928711s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.450379610061646.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111870.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105631.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112031.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7122/10556 [00:00<00:00, 71214.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 80221.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113140.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6265/10556 [00:00<00:00, 62647.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 60940.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115870.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107656.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7188/10556 [00:00<00:00, 71874.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 82017.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10300/10556 [00:00<00:00, 102998.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 102827.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7033/10556 [00:00<00:00, 70325.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 78080.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10334/10556 [00:00<00:00, 103336.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 103290.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6179/10556 [00:00<00:00, 61789.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 69907.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107686.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6278/10556 [00:00<00:00, 61483.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 63916.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8001/10556 [00:00<00:00, 80005.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 71144.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114986.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9740/10556 [00:00<00:00, 97397.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 98703.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████▏| 9658/10556 [00:00<00:00, 96142.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 98064.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117578.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7930/10556 [00:00<00:00, 71072.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 68309.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113247.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7117/10556 [00:00<00:00, 69593.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 80364.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109080.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9347/10556 [00:00<00:00, 93469.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 92565.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 9007/10556 [00:00<00:00, 90065.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 93811.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9945/10556 [00:00<00:00, 99446.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 99854.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10188/10556 [00:00<00:00, 101878.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 102178.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9527/10556 [00:00<00:00, 95268.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 96901.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118659.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6182/10556 [00:00<00:00, 61816.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 60183.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6130/10556 [00:00<00:00, 61295.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 66254.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5627/10556 [00:00<00:00, 56268.85it/s] 97%|█████████▋| 10217/10556 [00:00<00:00, 52586.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 50930.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6380/10556 [00:00<00:00, 63023.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 62340.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 9022/10556 [00:00<00:00, 89740.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 84832.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8903/10556 [00:00<00:00, 88479.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 77782.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|████▋     | 4916/10556 [00:00<00:00, 46496.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 52901.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7799/10556 [00:00<00:00, 77984.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 78577.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9859/10556 [00:00<00:00, 98575.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 95898.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7578/10556 [00:00<00:00, 75774.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 78438.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████▏  | 7530/10556 [00:00<00:00, 73145.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 82493.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8180/10556 [00:00<00:00, 81796.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 83369.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6370/10556 [00:00<00:00, 63696.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 66407.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107330.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123283.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112388.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6137/10556 [00:00<00:00, 61364.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 71875.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6628/10556 [00:00<00:00, 66275.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 63632.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7848/10556 [00:00<00:00, 78476.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 85761.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8701/10556 [00:00<00:00, 87005.10it/s]100%|██████████| 10556/10556 [00:00<00:00, 89534.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6565/10556 [00:00<00:00, 63872.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 61387.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6737/10556 [00:00<00:00, 65073.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 64166.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6886/10556 [00:00<00:00, 68859.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 81752.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7485/10556 [00:00<00:00, 74848.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 74330.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7397/10556 [00:00<00:00, 73967.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 62174.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109790.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6816/10556 [00:00<00:00, 68158.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 80739.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9057/10556 [00:00<00:00, 86895.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 75278.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105860.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7792/10556 [00:00<00:00, 71369.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 56944.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5557/10556 [00:00<00:00, 51136.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 61727.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6858/10556 [00:00<00:00, 68575.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 62052.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7548/10556 [00:00<00:00, 75471.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 68632.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9278/10556 [00:00<00:00, 92776.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 95290.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6503/10556 [00:00<00:00, 65029.75it/s]100%|██████████| 10556/10556 [00:00<00:00, 61553.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6725/10556 [00:00<00:00, 65300.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 64584.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9032/10556 [00:00<00:00, 90319.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 93639.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7408/10556 [00:00<00:00, 68723.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 63993.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6058/10556 [00:00<00:00, 59150.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 54266.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8913/10556 [00:00<00:00, 89122.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 92293.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6366/10556 [00:00<00:00, 63250.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 75943.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119125.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6586/10556 [00:00<00:00, 64974.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 63917.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9358/10556 [00:00<00:00, 93579.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 95637.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6001/10556 [00:00<00:00, 57194.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 64524.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6325/10556 [00:00<00:00, 63247.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 61982.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7681/10556 [00:00<00:00, 76807.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 66584.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7024/10556 [00:00<00:00, 70238.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 74439.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114227.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6247/10556 [00:00<00:00, 56111.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 71870.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130778.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126315.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190866.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199411.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201925.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119858.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131985.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217082.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216530.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 126535.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203841.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 226657.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206106.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219834.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203344.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207188.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188730.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124872.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181827.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190235.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205558.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191491.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188906.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191527.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189608.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190361.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198010.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201877.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193443.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203292.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192016.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192816.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203475.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184107.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192343.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 161535.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139578.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158776.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187045.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190930.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190687.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197427.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204083.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193892.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192989.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201164.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152731.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168609.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196280.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203850.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197505.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197981.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197784.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190796.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207057.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189672.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190620.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192672.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191556.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185105.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149530.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157919.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202379.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 169804.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214977.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 236370.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201875.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218000.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214131.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216772.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220502.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213291.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210507.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218174.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204687.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175852.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125304.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137859.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150408.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147608.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147668.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137418.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151218.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133098.47it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.38446'}; time used = 0.7232687473297119s
epoch 10: {'train_loss': '1.49955'}; time used = 0.6599781513214111s
epoch 15: {'train_loss': '1.37448'}; time used = 0.7678964138031006s
epoch 20: {'train_loss': '1.34659'}; time used = 0.673551082611084s
epoch 25: {'train_loss': '1.27896'}; time used = 0.6197333335876465s
epoch 30: {'train_loss': '1.24445'}; time used = 0.685431718826294s
epoch 35: {'train_loss': '1.14551'}; time used = 0.9057662487030029s
epoch 40: {'train_loss': '1.10220'}; time used = 0.802445650100708s
epoch 45: {'train_loss': '1.03499'}; time used = 0.6582355499267578s
epoch 50: {'train_loss': '0.99081'}; time used = 0.8365633487701416s
epoch 55: {'train_loss': '0.93128'}; time used = 0.8036062717437744s
epoch 60: {'train_loss': '0.91277'}; time used = 0.8172531127929688s
epoch 65: {'train_loss': '0.90454'}; time used = 0.8517956733703613s
epoch 70: {'train_loss': '0.82652'}; time used = 0.8158698081970215s
epoch 75: {'train_loss': '0.77794'}; time used = 0.784299373626709s
epoch 80: {'train_loss': '0.71656'}; time used = 0.6947705745697021s
epoch 85: {'train_loss': '0.67899'}; time used = 0.392075777053833s
epoch 90: {'train_loss': '0.65133'}; time used = 0.3672056198120117s
epoch 95: {'train_loss': '0.65694'}; time used = 0.3013277053833008s
epoch 100: {'train_loss': '0.62870'}; time used = 0.3706984519958496s
epoch 105: {'train_loss': '0.63071'}; time used = 0.3292105197906494s
epoch 110: {'train_loss': '0.65841'}; time used = 0.31783413887023926s
epoch 115: {'train_loss': '0.58044'}; time used = 0.3360164165496826s
epoch 120: {'train_loss': '0.54545'}; time used = 0.36584925651550293s
epoch 125: {'train_loss': '0.58344'}; time used = 0.318861722946167s
epoch 130: {'train_loss': '0.71323'}; time used = 0.35779786109924316s
epoch 135: {'train_loss': '0.62827'}; time used = 0.32593727111816406s
epoch 140: {'train_loss': '0.56576'}; time used = 0.34664344787597656s
epoch 145: {'train_loss': '0.53677'}; time used = 0.3417830467224121s
epoch 150: {'train_loss': '0.50807'}; time used = 0.3042116165161133s
epoch 155: {'train_loss': '0.50259'}; time used = 0.31627535820007324s
epoch 160: {'train_loss': '0.50283'}; time used = 0.4397597312927246s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.113768815994263.
Training classifier using 20.00% nodes...
{'micro': 0.5579141670512229, 'macro': 0.5003403515955854, 'samples': 0.5579141670512229, 'weighted': 0.5392140270609048}
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6714/10556 [00:00<00:00, 67139.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 68032.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112959.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6845/10556 [00:00<00:00, 62929.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 63202.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10458/10556 [00:00<00:00, 104579.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 104325.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8897/10556 [00:00<00:00, 81293.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 83913.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9221/10556 [00:00<00:00, 92202.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 95019.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119763.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113506.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117861.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10313/10556 [00:00<00:00, 103126.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 103281.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6463/10556 [00:00<00:00, 64624.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 72773.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7261/10556 [00:00<00:00, 72607.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 82458.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6838/10556 [00:00<00:00, 68379.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 69470.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110430.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7084/10556 [00:00<00:00, 70836.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 81039.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116597.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9590/10556 [00:00<00:00, 95899.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 97725.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7020/10556 [00:00<00:00, 68524.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 76278.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5522/10556 [00:00<00:00, 55218.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 62548.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9549/10556 [00:00<00:00, 95487.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 84153.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9935/10556 [00:00<00:00, 99349.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 99898.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8342/10556 [00:00<00:00, 83419.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 81377.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6634/10556 [00:00<00:00, 66339.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 73554.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10328/10556 [00:00<00:00, 103272.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 103372.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6760/10556 [00:00<00:00, 67595.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 71733.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6666/10556 [00:00<00:00, 66659.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 77386.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|█████████▏| 9758/10556 [00:00<00:00, 97573.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 98889.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117840.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105109.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6189/10556 [00:00<00:00, 54807.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 60098.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7322/10556 [00:00<00:00, 67949.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 66411.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8554/10556 [00:00<00:00, 77682.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 83581.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▎  | 7770/10556 [00:00<00:00, 77699.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 85780.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8729/10556 [00:00<00:00, 87282.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 91114.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7047/10556 [00:00<00:00, 66120.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 62978.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▋    | 5942/10556 [00:00<00:00, 59417.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 57142.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▋| 10184/10556 [00:00<00:00, 101836.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 101912.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 9984/10556 [00:00<00:00, 99839.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 99816.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8727/10556 [00:00<00:00, 87268.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 90163.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7803/10556 [00:00<00:00, 69960.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 67480.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9621/10556 [00:00<00:00, 96202.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 97035.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6325/10556 [00:00<00:00, 63247.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 61725.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6784/10556 [00:00<00:00, 66281.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 73758.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▊ | 9347/10556 [00:00<00:00, 93460.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 95474.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117506.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117559.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120279.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7031/10556 [00:00<00:00, 70269.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 67783.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112719.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7968/10556 [00:00<00:00, 72678.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 67094.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▎    | 5664/10556 [00:00<00:00, 56635.46it/s]100%|██████████| 10556/10556 [00:00<00:00, 61723.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6947/10556 [00:00<00:00, 66315.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 64396.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▎   | 6706/10556 [00:00<00:00, 67059.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 63222.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 9992/10556 [00:00<00:00, 99914.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 99892.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7077/10556 [00:00<00:00, 70767.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 65169.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10188/10556 [00:00<00:00, 101874.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 102006.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121219.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116728.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114881.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111169.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8703/10556 [00:00<00:00, 87024.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 91047.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6685/10556 [00:00<00:00, 66844.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 63362.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6856/10556 [00:00<00:00, 63220.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 58486.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120032.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5443/10556 [00:00<00:00, 54427.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 62395.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▋| 10181/10556 [00:00<00:00, 101806.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 99380.65it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7036/10556 [00:00<00:00, 67797.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 78627.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6293/10556 [00:00<00:00, 61525.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 64466.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8144/10556 [00:00<00:00, 81434.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 86103.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 121414.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10007/10556 [00:00<00:00, 99168.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 99655.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▋  | 8061/10556 [00:00<00:00, 80604.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 87007.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6227/10556 [00:00<00:00, 56298.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 66054.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6613/10556 [00:00<00:00, 65503.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 77131.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106043.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7505/10556 [00:00<00:00, 75046.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 77940.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5531/10556 [00:00<00:00, 55305.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 56136.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6667/10556 [00:00<00:00, 64882.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 77483.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120634.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6368/10556 [00:00<00:00, 63261.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 77890.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10002/10556 [00:00<00:00, 100013.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 100986.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6367/10556 [00:00<00:00, 63668.24it/s]100%|██████████| 10556/10556 [00:00<00:00, 65545.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9160/10556 [00:00<00:00, 91594.63it/s]100%|██████████| 10556/10556 [00:00<00:00, 94697.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117512.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113414.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9533/10556 [00:00<00:00, 95328.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 96650.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114344.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8446/10556 [00:00<00:00, 83797.38it/s]100%|██████████| 10556/10556 [00:00<00:00, 88728.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6849/10556 [00:00<00:00, 68487.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 80241.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7945/10556 [00:00<00:00, 79447.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 82070.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10125/10556 [00:00<00:00, 101246.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 99853.34it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8007/10556 [00:00<00:00, 80063.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 86577.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6616/10556 [00:00<00:00, 65496.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 68325.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9792/10556 [00:00<00:00, 97915.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 98968.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9258/10556 [00:00<00:00, 92578.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 84286.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6305/10556 [00:00<00:00, 61485.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 52936.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7622/10556 [00:00<00:00, 76214.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 78434.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6302/10556 [00:00<00:00, 63019.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 70472.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108492.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111643.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113396.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110384.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6432/10556 [00:00<00:00, 62289.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 68561.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6314/10556 [00:00<00:00, 63134.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 57436.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110118.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▊    | 6185/10556 [00:00<00:00, 61846.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 68306.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113461.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111467.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7690/10556 [00:00<00:00, 72318.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 68380.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6286/10556 [00:00<00:00, 59863.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 59441.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6981/10556 [00:00<00:00, 65975.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 67101.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▋  | 8050/10556 [00:00<00:00, 80495.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 77681.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▋  | 8069/10556 [00:00<00:00, 80687.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 86754.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111136.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5513/10556 [00:00<00:00, 55128.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 71047.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8873/10556 [00:00<00:00, 88718.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 89273.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108534.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8076/10556 [00:00<00:00, 80756.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 85773.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120036.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6688/10556 [00:00<00:00, 64732.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 74526.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8219/10556 [00:00<00:00, 82186.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 88373.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118748.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7406/10556 [00:00<00:00, 74058.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 66451.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115958.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111145.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8211/10556 [00:00<00:00, 74676.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 71830.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120456.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113385.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7505/10556 [00:00<00:00, 75042.20it/s]100%|██████████| 10556/10556 [00:00<00:00, 76248.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10160/10556 [00:00<00:00, 101594.28it/s]100%|██████████| 10556/10556 [00:00<00:00, 102149.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4497/10556 [00:00<00:00, 44967.79it/s] 85%|████████▌ | 9025/10556 [00:00<00:00, 45060.66it/s]100%|██████████| 10556/10556 [00:00<00:00, 44018.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5771/10556 [00:00<00:00, 57342.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 58964.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6911/10556 [00:00<00:00, 69109.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 80684.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▋| 10165/10556 [00:00<00:00, 101642.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 101593.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7127/10556 [00:00<00:00, 71265.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 81792.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8734/10556 [00:00<00:00, 87337.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 89771.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6252/10556 [00:00<00:00, 62512.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 64339.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7560/10556 [00:00<00:00, 68190.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 65878.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6831/10556 [00:00<00:00, 64666.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 68063.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6944/10556 [00:00<00:00, 69435.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 66615.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9907/10556 [00:00<00:00, 99068.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 99853.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6123/10556 [00:00<00:00, 58875.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 69215.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106305.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6703/10556 [00:00<00:00, 67026.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 76862.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109572.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10371/10556 [00:00<00:00, 103702.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 103357.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▎| 9893/10556 [00:00<00:00, 98928.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 99188.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113672.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117957.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5043/10556 [00:00<00:00, 50426.80it/s]100%|██████████| 10556/10556 [00:00<00:00, 65155.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6466/10556 [00:00<00:00, 62375.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 60620.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|█████▌    | 5860/10556 [00:00<00:00, 58599.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 61377.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6238/10556 [00:00<00:00, 62379.76it/s]100%|██████████| 10556/10556 [00:00<00:00, 62561.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105617.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|████▊     | 5032/10556 [00:00<00:00, 49855.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 53395.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████▏     | 4375/10556 [00:00<00:00, 40636.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 51097.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9280/10556 [00:00<00:00, 83044.54it/s]100%|██████████| 10556/10556 [00:00<00:00, 77770.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10251/10556 [00:00<00:00, 102505.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 100993.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115187.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119043.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10290/10556 [00:00<00:00, 102899.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 103030.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6467/10556 [00:00<00:00, 64666.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 71666.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7922/10556 [00:00<00:00, 79218.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 76435.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8167/10556 [00:00<00:00, 81665.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 86952.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|█████     | 5391/10556 [00:00<00:00, 52527.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 55629.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7205/10556 [00:00<00:00, 72045.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 82296.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6480/10556 [00:00<00:00, 64797.44it/s]100%|██████████| 10556/10556 [00:00<00:00, 73966.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 99134.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8629/10556 [00:00<00:00, 86283.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 90513.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7120/10556 [00:00<00:00, 67223.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 64093.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6612/10556 [00:00<00:00, 66116.91it/s]100%|██████████| 10556/10556 [00:00<00:00, 71950.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▊   | 7235/10556 [00:00<00:00, 72343.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 72683.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8604/10556 [00:00<00:00, 86033.52it/s]100%|██████████| 10556/10556 [00:00<00:00, 91028.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119099.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106507.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9917/10556 [00:00<00:00, 99164.42it/s]100%|██████████| 10556/10556 [00:00<00:00, 99915.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8199/10556 [00:00<00:00, 81985.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 82337.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106463.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▎| 9870/10556 [00:00<00:00, 98681.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 99792.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6105/10556 [00:00<00:00, 61045.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 62994.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107536.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113979.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▋   | 6994/10556 [00:00<00:00, 69937.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 63959.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10340/10556 [00:00<00:00, 103391.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 98575.25it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122071.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|█████████▉| 10531/10556 [00:00<00:00, 105300.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 104975.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6627/10556 [00:00<00:00, 66266.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 74259.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|██▊       | 3032/10556 [00:00<00:00, 30316.13it/s] 93%|█████████▎| 9810/10556 [00:00<00:00, 36342.09it/s]100%|██████████| 10556/10556 [00:00<00:00, 49864.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▎  | 7783/10556 [00:00<00:00, 77826.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 76318.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7896/10556 [00:00<00:00, 78955.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 76972.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|██████▍   | 6743/10556 [00:00<00:00, 67426.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 63394.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7499/10556 [00:00<00:00, 74986.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 83214.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████ | 9555/10556 [00:00<00:00, 95548.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 95090.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7500/10556 [00:00<00:00, 74997.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 82390.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6570/10556 [00:00<00:00, 61028.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 72612.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6415/10556 [00:00<00:00, 62987.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 64015.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▎  | 7781/10556 [00:00<00:00, 75461.12it/s]100%|██████████| 10556/10556 [00:00<00:00, 72873.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6519/10556 [00:00<00:00, 63620.00it/s]100%|██████████| 10556/10556 [00:00<00:00, 62187.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████▏| 9651/10556 [00:00<00:00, 96508.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 87834.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7559/10556 [00:00<00:00, 75586.29it/s]100%|██████████| 10556/10556 [00:00<00:00, 68363.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6095/10556 [00:00<00:00, 60946.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 57972.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6679/10556 [00:00<00:00, 65030.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 63397.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6104/10556 [00:00<00:00, 61038.17it/s]100%|██████████| 10556/10556 [00:00<00:00, 60043.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6146/10556 [00:00<00:00, 61459.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 71687.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123021.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8695/10556 [00:00<00:00, 85594.83it/s]100%|██████████| 10556/10556 [00:00<00:00, 87243.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████▏  | 7541/10556 [00:00<00:00, 75404.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 82264.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6695/10556 [00:00<00:00, 66946.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 79872.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9811/10556 [00:00<00:00, 98103.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 94178.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118551.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▎  | 7783/10556 [00:00<00:00, 77828.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 78184.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7912/10556 [00:00<00:00, 79119.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 87080.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8647/10556 [00:00<00:00, 77897.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 71775.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7263/10556 [00:00<00:00, 72625.05it/s]100%|██████████| 10556/10556 [00:00<00:00, 72155.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|███▉      | 4102/10556 [00:00<00:00, 40751.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 53519.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114474.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6021/10556 [00:00<00:00, 60207.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 61043.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%|█████████ | 9505/10556 [00:00<00:00, 95047.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 96388.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8937/10556 [00:00<00:00, 89348.57it/s]100%|██████████| 10556/10556 [00:00<00:00, 92100.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119886.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10092/10556 [00:00<00:00, 100911.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 101043.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9842/10556 [00:00<00:00, 98417.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 99351.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113188.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110908.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|█████████▏| 9642/10556 [00:00<00:00, 96416.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 88329.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6422/10556 [00:00<00:00, 62382.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 70190.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178353.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186638.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189947.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185460.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190346.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183937.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187035.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123250.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157368.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209221.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202594.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200549.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204266.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194337.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141741.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125382.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132980.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187358.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185737.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186217.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176140.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189158.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206895.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188471.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185557.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188008.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183462.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183515.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172945.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181268.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182332.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173457.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174681.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145780.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141896.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205730.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203385.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192602.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138549.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144844.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141027.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148481.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131313.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110607.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157131.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147674.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▋  | 8050/10556 [00:00<00:00, 73542.13it/s]100%|██████████| 10556/10556 [00:00<00:00, 74182.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151191.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9958/10556 [00:00<00:00, 99053.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 88692.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109458.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152778.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185380.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200544.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139851.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108232.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 125202.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173235.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197220.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185041.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211875.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198550.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205809.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184363.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184832.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167727.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181963.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178702.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177464.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180487.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 172550.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179654.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177806.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191978.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180058.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136216.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157244.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147995.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132754.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151554.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150019.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148296.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148938.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143793.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148236.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150464.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 138309.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142930.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150355.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140451.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149470.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140114.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158394.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194463.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199678.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7494/10556 [00:00<00:00, 74935.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 82430.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174635.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 181473.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178357.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178440.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167798.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178874.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198072.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 142539.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 128845.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117318.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8247/10556 [00:00<00:00, 82460.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 83202.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191765.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193145.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196537.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185754.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210547.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214861.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213976.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212325.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205811.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 236283.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 233945.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222886.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219597.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191178.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184436.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192844.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205596.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211333.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 161105.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 176499.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183988.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179733.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 175977.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153575.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151412.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153371.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146092.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146660.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 141790.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148796.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146478.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150174.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143705.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154801.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158068.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149463.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 131013.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6699/10556 [00:00<00:00, 66985.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 80651.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111708.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7646/10556 [00:00<00:00, 76456.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 61485.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9148/10556 [00:00<00:00, 91477.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 94546.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5799/10556 [00:00<00:00, 57729.64it/s]100%|██████████| 10556/10556 [00:00<00:00, 58346.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6880/10556 [00:00<00:00, 68531.45it/s]100%|██████████| 10556/10556 [00:00<00:00, 72746.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8007/10556 [00:00<00:00, 80067.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 79599.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117814.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8013/10556 [00:00<00:00, 80125.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 78965.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 109940.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6953/10556 [00:00<00:00, 68638.84it/s]100%|██████████| 10556/10556 [00:00<00:00, 61516.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6821/10556 [00:00<00:00, 68206.49it/s]100%|██████████| 10556/10556 [00:00<00:00, 71935.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112544.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 111803.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6124/10556 [00:00<00:00, 60931.36it/s]100%|██████████| 10556/10556 [00:00<00:00, 74567.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114567.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113708.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110725.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10028/10556 [00:00<00:00, 90502.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 91244.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7217/10556 [00:00<00:00, 72168.35it/s]100%|██████████| 10556/10556 [00:00<00:00, 81050.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10277/10556 [00:00<00:00, 102673.89it/s]100%|██████████| 10556/10556 [00:00<00:00, 102710.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9434/10556 [00:00<00:00, 94335.82it/s]100%|██████████| 10556/10556 [00:00<00:00, 94723.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7710/10556 [00:00<00:00, 76010.56it/s]100%|██████████| 10556/10556 [00:00<00:00, 80045.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9141/10556 [00:00<00:00, 91407.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 89306.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110943.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|███▍      | 3590/10556 [00:00<00:00, 35899.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 66135.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9224/10556 [00:00<00:00, 92235.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 94948.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117801.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117044.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6076/10556 [00:00<00:00, 60756.73it/s]100%|██████████| 10556/10556 [00:00<00:00, 59465.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5175/10556 [00:00<00:00, 50849.52it/s] 95%|█████████▌| 10065/10556 [00:00<00:00, 49217.27it/s]100%|██████████| 10556/10556 [00:00<00:00, 48558.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|█████▉    | 6317/10556 [00:00<00:00, 61438.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 66528.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114968.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6120/10556 [00:00<00:00, 61198.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 75773.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████   | 7471/10556 [00:00<00:00, 73968.50it/s]100%|██████████| 10556/10556 [00:00<00:00, 76573.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 116283.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10464/10556 [00:00<00:00, 104630.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 104303.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|█████████▌| 10106/10556 [00:00<00:00, 101058.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 96203.73it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▎ | 8819/10556 [00:00<00:00, 88189.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 88820.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▌   | 6879/10556 [00:00<00:00, 62058.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 73898.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5510/10556 [00:00<00:00, 55097.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 55046.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|████▎     | 4590/10556 [00:00<00:00, 45899.39it/s]100%|██████████| 10556/10556 [00:00<00:00, 53714.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105531.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113221.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120478.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|█████████▍| 9940/10556 [00:00<00:00, 99397.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 100018.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114539.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|██████    | 6384/10556 [00:00<00:00, 62449.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 59699.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8215/10556 [00:00<00:00, 80792.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 87145.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8391/10556 [00:00<00:00, 83907.48it/s]100%|██████████| 10556/10556 [00:00<00:00, 84573.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8027/10556 [00:00<00:00, 80267.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 83305.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119020.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7270/10556 [00:00<00:00, 72699.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 79256.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▎    | 5665/10556 [00:00<00:00, 56648.43it/s]100%|██████████| 10556/10556 [00:00<00:00, 58509.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118856.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|██████▉   | 7261/10556 [00:00<00:00, 72609.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 78243.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110144.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7868/10556 [00:00<00:00, 78677.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 86213.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|████████  | 8495/10556 [00:00<00:00, 84940.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 80555.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106281.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110741.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 123826.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114474.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9101/10556 [00:00<00:00, 91002.93it/s]100%|██████████| 10556/10556 [00:00<00:00, 94135.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|███████▏  | 7627/10556 [00:00<00:00, 76236.81it/s]100%|██████████| 10556/10556 [00:00<00:00, 70941.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|█████████▋| 10195/10556 [00:00<00:00, 101945.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 102289.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8771/10556 [00:00<00:00, 87706.32it/s]100%|██████████| 10556/10556 [00:00<00:00, 87517.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|█████▋    | 6019/10556 [00:00<00:00, 60185.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 75669.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|███████▏  | 7526/10556 [00:00<00:00, 75257.92it/s]100%|██████████| 10556/10556 [00:00<00:00, 84842.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|███████▎  | 7745/10556 [00:00<00:00, 77424.23it/s]100%|██████████| 10556/10556 [00:00<00:00, 80546.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8550/10556 [00:00<00:00, 85496.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 90210.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 113013.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119291.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9217/10556 [00:00<00:00, 92164.16it/s]100%|██████████| 10556/10556 [00:00<00:00, 94088.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8891/10556 [00:00<00:00, 88478.06it/s]100%|██████████| 10556/10556 [00:00<00:00, 82286.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████▏   | 6487/10556 [00:00<00:00, 64864.19it/s]100%|██████████| 10556/10556 [00:00<00:00, 75293.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▎  | 7776/10556 [00:00<00:00, 76048.65it/s]100%|██████████| 10556/10556 [00:00<00:00, 77273.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▌ | 8984/10556 [00:00<00:00, 89833.87it/s]100%|██████████| 10556/10556 [00:00<00:00, 87727.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|█████████▎| 9809/10556 [00:00<00:00, 98082.61it/s]100%|██████████| 10556/10556 [00:00<00:00, 94577.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|██████▎   | 6676/10556 [00:00<00:00, 66759.90it/s]100%|██████████| 10556/10556 [00:00<00:00, 61638.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6164/10556 [00:00<00:00, 61636.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 60059.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7836/10556 [00:00<00:00, 78355.59it/s]100%|██████████| 10556/10556 [00:00<00:00, 85189.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|██████▊   | 7215/10556 [00:00<00:00, 72145.94it/s]100%|██████████| 10556/10556 [00:00<00:00, 69284.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▎    | 5669/10556 [00:00<00:00, 55820.86it/s]100%|██████████| 10556/10556 [00:00<00:00, 54691.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|███████▌  | 8010/10556 [00:00<00:00, 80045.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 79461.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8151/10556 [00:00<00:00, 81509.11it/s]100%|██████████| 10556/10556 [00:00<00:00, 81627.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6537/10556 [00:00<00:00, 63329.30it/s]100%|██████████| 10556/10556 [00:00<00:00, 53170.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 112272.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120237.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6969/10556 [00:00<00:00, 62934.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 74706.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117715.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5745/10556 [00:00<00:00, 57443.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 66509.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115822.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120727.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117510.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 115476.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|██████    | 6400/10556 [00:00<00:00, 63995.33it/s]100%|██████████| 10556/10556 [00:00<00:00, 62663.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%|████████▎ | 8810/10556 [00:00<00:00, 88095.04it/s]100%|██████████| 10556/10556 [00:00<00:00, 82247.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████      | 4344/10556 [00:00<00:00, 40609.22it/s]100%|██████████| 10556/10556 [00:00<00:00, 64950.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|████▉     | 5267/10556 [00:00<00:00, 48662.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 61130.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|████      | 4259/10556 [00:00<00:00, 42586.69it/s]100%|██████████| 10556/10556 [00:00<00:00, 55819.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|███████▊  | 8237/10556 [00:00<00:00, 82364.78it/s]100%|██████████| 10556/10556 [00:00<00:00, 83010.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%|████████▋ | 9132/10556 [00:00<00:00, 91315.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 93792.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106786.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 120501.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8558/10556 [00:00<00:00, 85566.21it/s]100%|██████████| 10556/10556 [00:00<00:00, 82480.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|██████▍   | 6835/10556 [00:00<00:00, 67552.67it/s]100%|██████████| 10556/10556 [00:00<00:00, 79864.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118134.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5484/10556 [00:00<00:00, 54839.79it/s]100%|██████████| 10556/10556 [00:00<00:00, 57822.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118008.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|████▉     | 5174/10556 [00:00<00:00, 49602.58it/s]100%|██████████| 10556/10556 [00:00<00:00, 69350.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9264/10556 [00:00<00:00, 92637.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 86772.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|██████▏   | 6539/10556 [00:00<00:00, 63756.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 65803.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124711.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 140860.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 136992.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110671.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▎ | 8817/10556 [00:00<00:00, 88163.99it/s]100%|██████████| 10556/10556 [00:00<00:00, 87730.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▉| 10453/10556 [00:00<00:00, 104522.37it/s]100%|██████████| 10556/10556 [00:00<00:00, 104365.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|█████▍    | 5751/10556 [00:00<00:00, 56998.01it/s]100%|██████████| 10556/10556 [00:00<00:00, 66156.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118866.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▍  | 7880/10556 [00:00<00:00, 78797.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 87033.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|███████▍  | 7841/10556 [00:00<00:00, 77930.15it/s]100%|██████████| 10556/10556 [00:00<00:00, 77631.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|█████▎    | 5622/10556 [00:00<00:00, 56214.96it/s] 98%|█████████▊| 10336/10556 [00:00<00:00, 51863.72it/s]100%|██████████| 10556/10556 [00:00<00:00, 48720.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6280/10556 [00:00<00:00, 62796.02it/s]100%|██████████| 10556/10556 [00:00<00:00, 76215.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107650.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▍    | 5769/10556 [00:00<00:00, 57683.18it/s]100%|██████████| 10556/10556 [00:00<00:00, 62057.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7030/10556 [00:00<00:00, 70295.88it/s]100%|██████████| 10556/10556 [00:00<00:00, 81319.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114428.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|█████▉    | 6219/10556 [00:00<00:00, 62189.47it/s]100%|██████████| 10556/10556 [00:00<00:00, 55744.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%|████████▏ | 8605/10556 [00:00<00:00, 86043.31it/s]100%|██████████| 10556/10556 [00:00<00:00, 90481.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|███████   | 7408/10556 [00:00<00:00, 64996.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 75248.98it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.38634'}; time used = 0.7561945915222168s
epoch 10: {'train_loss': '1.37943'}; time used = 0.6054284572601318s
epoch 15: {'train_loss': '1.38736'}; time used = 0.705528736114502s
epoch 20: {'train_loss': '1.37566'}; time used = 0.7293064594268799s
epoch 25: {'train_loss': '1.30542'}; time used = 0.7346396446228027s
epoch 30: {'train_loss': '1.30741'}; time used = 0.7221131324768066s
epoch 35: {'train_loss': '1.20284'}; time used = 0.8137040138244629s
epoch 40: {'train_loss': '1.18198'}; time used = 0.6987495422363281s
epoch 45: {'train_loss': '1.20757'}; time used = 0.6876471042633057s
epoch 50: {'train_loss': '1.11710'}; time used = 0.7457449436187744s
epoch 55: {'train_loss': '1.06472'}; time used = 0.7795405387878418s
epoch 60: {'train_loss': '1.04512'}; time used = 0.5498659610748291s
epoch 65: {'train_loss': '1.01886'}; time used = 0.7847826480865479s
epoch 70: {'train_loss': '1.00108'}; time used = 0.6932351589202881s
epoch 75: {'train_loss': '0.98806'}; time used = 0.7537729740142822s
epoch 80: {'train_loss': '1.02257'}; time used = 0.7324614524841309s
epoch 85: {'train_loss': '1.06880'}; time used = 0.6711509227752686s
epoch 90: {'train_loss': '1.05416'}; time used = 0.6780357360839844s
epoch 95: {'train_loss': '1.01578'}; time used = 0.7892274856567383s
epoch 100: {'train_loss': '0.99641'}; time used = 0.6593153476715088s
epoch 105: {'train_loss': '0.96484'}; time used = 0.7660584449768066s
epoch 110: {'train_loss': '0.95753'}; time used = 0.7614095211029053s
epoch 115: {'train_loss': '0.93940'}; time used = 0.7054083347320557s
epoch 120: {'train_loss': '0.93144'}; time used = 0.661085844039917s
epoch 125: {'train_loss': '0.91800'}; time used = 0.664740800857544s
epoch 130: {'train_loss': '0.91190'}; time used = 0.7558102607727051s
epoch 135: {'train_loss': '0.92094'}; time used = 0.7469203472137451s
epoch 140: {'train_loss': '0.91251'}; time used = 0.8376138210296631s
epoch 145: {'train_loss': '0.92786'}; time used = 0.6873500347137451s
epoch 150: {'train_loss': '0.92046'}; time used = 0.7341279983520508s
epoch 155: {'train_loss': '0.88828'}; time used = 0.9802837371826172s
epoch 160: {'train_loss': '0.89606'}; time used = 0.6074411869049072s
epoch 165: {'train_loss': '0.88125'}; time used = 0.8370006084442139s
epoch 170: {'train_loss': '0.86867'}; time used = 0.7651188373565674s
epoch 175: {'train_loss': '0.87826'}; time used = 0.6519849300384521s
epoch 180: {'train_loss': '0.91450'}; time used = 0.7350940704345703s
epoch 185: {'train_loss': '0.88914'}; time used = 0.6507182121276855s
epoch 190: {'train_loss': '0.86436'}; time used = 0.9312746524810791s
epoch 195: {'train_loss': '0.86499'}; time used = 0.7666370868682861s
epoch 200: {'train_loss': '0.86630'}; time used = 0.8769633769989014s
epoch 205: {'train_loss': '0.85943'}; time used = 0.771831750869751s
epoch 210: {'train_loss': '0.84828'}; time used = 0.6947031021118164s
epoch 215: {'train_loss': '0.84553'}; time used = 0.8041937351226807s
epoch 220: {'train_loss': '0.84283'}; time used = 0.6817765235900879s
epoch 225: {'train_loss': '0.83071'}; time used = 0.6615703105926514s
epoch 230: {'train_loss': '0.86996'}; time used = 0.3370046615600586s
epoch 235: {'train_loss': '0.81984'}; time used = 0.378568172454834s
epoch 240: {'train_loss': '0.80984'}; time used = 0.3396279811859131s
epoch 245: {'train_loss': '0.79172'}; time used = 0.40235066413879395s
epoch 250: {'train_loss': '0.99909'}; time used = 0.34057140350341797s
epoch 255: {'train_loss': '0.92126'}; time used = 0.35143113136291504s
epoch 260: {'train_loss': '0.86673'}; time used = 0.4030039310455322s
epoch 265: {'train_loss': '0.84488'}; time used = 0.37087440490722656s
epoch 270: {'train_loss': '0.80113'}; time used = 0.44862961769104004s
epoch 275: {'train_loss': '0.78517'}; time used = 0.568795919418335s
epoch 280: {'train_loss': '0.77846'}; time used = 0.40683555603027344s
epoch 285: {'train_loss': '0.78346'}; time used = 0.3750736713409424s
epoch 290: {'train_loss': '0.88051'}; time used = 0.3429374694824219s
epoch 295: {'train_loss': '0.83985'}; time used = 0.3590114116668701s
epoch 300: {'train_loss': '0.80446'}; time used = 0.3654916286468506s
epoch 305: {'train_loss': '0.76827'}; time used = 0.41624951362609863s
epoch 310: {'train_loss': '0.75098'}; time used = 0.41347837448120117s
epoch 315: {'train_loss': '0.73165'}; time used = 0.4231994152069092s
epoch 320: {'train_loss': '0.76250'}; time used = 0.4341239929199219s
epoch 325: {'train_loss': '0.78058'}; time used = 0.3662991523742676s
epoch 330: {'train_loss': '0.74066'}; time used = 0.4241294860839844s
epoch 335: {'train_loss': '0.72596'}; time used = 0.41709041595458984s
epoch 340: {'train_loss': '0.70907'}; time used = 0.3099038600921631s
epoch 345: {'train_loss': '0.69197'}; time used = 0.3054490089416504s
epoch 350: {'train_loss': '0.75742'}; time used = 0.3503880500793457s
epoch 355: {'train_loss': '0.79494'}; time used = 0.37122011184692383s
epoch 360: {'train_loss': '0.77448'}; time used = 0.41988158226013184s
epoch 365: {'train_loss': '0.72462'}; time used = 0.42019224166870117s
epoch 370: {'train_loss': '0.70846'}; time used = 0.5085873603820801s
epoch 375: {'train_loss': '0.69376'}; time used = 0.8300762176513672s
epoch 380: {'train_loss': '0.66094'}; time used = 0.7602965831756592s
epoch 385: {'train_loss': '0.69501'}; time used = 0.61478590965271s
epoch 390: {'train_loss': '0.67642'}; time used = 0.6809403896331787s
epoch 395: {'train_loss': '0.65659'}; time used = 0.7123539447784424s
epoch 400: {'train_loss': '0.66624'}; time used = 0.8262574672698975s
epoch 405: {'train_loss': '0.63065'}; time used = 0.6464183330535889s
epoch 410: {'train_loss': '0.62602'}; time used = 0.8795754909515381s
epoch 415: {'train_loss': '0.64759'}; time used = 0.5965015888214111s
epoch 420: {'train_loss': '0.63862'}; time used = 0.7352855205535889s
epoch 425: {'train_loss': '0.62685'}; time used = 0.7094058990478516s
epoch 430: {'train_loss': '0.61444'}; time used = 0.6291477680206299s
epoch 435: {'train_loss': '0.60686'}; time used = 0.6687741279602051s
epoch 440: {'train_loss': '0.59811'}; time used = 0.7123937606811523s
epoch 445: {'train_loss': '0.61077'}; time used = 0.7047200202941895s
epoch 450: {'train_loss': '0.60780'}; time used = 0.8093554973602295s
epoch 455: {'train_loss': '0.59606'}; time used = 0.911113977432251s
epoch 460: {'train_loss': '0.64347'}; time used = 0.6637237071990967s
epoch 465: {'train_loss': '0.63638'}; time used = 0.6412849426269531s
epoch 470: {'train_loss': '0.66347'}; time used = 0.8987574577331543s
epoch 475: {'train_loss': '0.62062'}; time used = 0.6622292995452881s
epoch 480: {'train_loss': '0.61008'}; time used = 0.737940788269043s
epoch 485: {'train_loss': '0.59270'}; time used = 0.5619087219238281s
epoch 490: {'train_loss': '0.56921'}; time used = 0.6827569007873535s
epoch 495: {'train_loss': '0.59948'}; time used = 0.882535457611084s
epoch 500: {'train_loss': '0.58885'}; time used = 0.7571578025817871s
Finished training. Time used = 69.05483531951904.
Training classifier using 20.00% nodes...
{'micro': 0.43147208121827413, 'macro': 0.24202817439022858, 'samples': 0.43147208121827413, 'weighted': 0.30464976255177006}

  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6075/10556 [00:00<00:00, 60749.77it/s]100%|██████████| 10556/10556 [00:00<00:00, 58968.49it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 0; 10.76 GiB total capacity; 73.04 MiB already allocated; 1.81 GiB free; 86.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f9c2c0531e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f9c2c2a964b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f9c2c2aa464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f9c2c2aaaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f99eb59d90e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f99e99d7949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f99e99f1777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f9c2d5a5c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f9c2d5a5f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f9c2d6b0a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f9c2d3404f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f9c2d342166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f9c2d34265d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f9c2d34280a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f9c2d07feb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f99e99c6b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f9c2cf12530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f9c2d6fa81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f9c2d64b82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f9c2d182952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f9c2d183f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f9c2d7578c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f9c2d78108b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f9c2d6a8337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f9c2f2b6205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f9c2d78108b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f9c2d6a8337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f9c2f215f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f9c2f831bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f9c2f82d400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f9c2f82dfa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f9c2f826119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f9c3cfc64ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f9c3e1226df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f9c4217d6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f9c424b671f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183463.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 171815.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195531.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 231843.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 177495.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 244956.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211711.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173781.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186212.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209520.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222285.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217893.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220137.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188830.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129295.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10384/10556 [00:00<00:00, 103829.95it/s]100%|██████████| 10556/10556 [00:00<00:00, 103290.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 152614.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151133.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160439.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206219.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 229491.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 228775.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|███████▉  | 8383/10556 [00:00<00:00, 77512.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 74934.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114585.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 151093.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158688.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 173457.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189944.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214753.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 168445.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218091.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211334.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209866.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|█████████▍| 10014/10556 [00:00<00:00, 100135.08it/s]100%|██████████| 10556/10556 [00:00<00:00, 101096.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174739.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 195690.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213556.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214903.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190830.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6123/10556 [00:00<00:00, 61224.07it/s]100%|██████████| 10556/10556 [00:00<00:00, 71435.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196895.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193045.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133691.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 149646.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213635.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204767.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|████      | 4339/10556 [00:00<00:00, 43387.25it/s]100%|██████████| 10556/10556 [00:00<00:00, 75290.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159702.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 157760.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198856.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 159732.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 117814.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 145285.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147427.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153738.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182250.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213127.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190034.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219793.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203892.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%|████████▉ | 9409/10556 [00:00<00:00, 94085.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 96606.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%|████████▍ | 8947/10556 [00:00<00:00, 89459.85it/s]100%|██████████| 10556/10556 [00:00<00:00, 89211.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124147.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194766.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187955.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220055.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190932.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220746.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222018.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222104.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201717.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212650.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215590.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 106059.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 228979.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179247.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 229518.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 238411.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 205259.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8546/10556 [00:00<00:00, 85457.03it/s]100%|██████████| 10556/10556 [00:00<00:00, 89138.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|██████▌   | 6926/10556 [00:00<00:00, 60627.55it/s]100%|██████████| 10556/10556 [00:00<00:00, 52639.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|██████▉   | 7351/10556 [00:00<00:00, 73506.74it/s]100%|██████████| 10556/10556 [00:00<00:00, 69215.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7039/10556 [00:00<00:00, 70385.70it/s]100%|██████████| 10556/10556 [00:00<00:00, 70630.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|███████▌  | 7968/10556 [00:00<00:00, 75215.53it/s]100%|██████████| 10556/10556 [00:00<00:00, 77007.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%|████████▍ | 8872/10556 [00:00<00:00, 88712.26it/s]100%|██████████| 10556/10556 [00:00<00:00, 90478.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188948.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192491.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189322.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192397.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194249.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192358.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194816.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219033.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197429.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 161252.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194197.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 150765.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187987.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 127104.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189156.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191607.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 180744.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10405/10556 [00:00<00:00, 104045.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 104121.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 188367.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167838.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|█████████▊| 10364/10556 [00:00<00:00, 103629.97it/s]100%|██████████| 10556/10556 [00:00<00:00, 101269.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 114219.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 122816.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████▏ | 8603/10556 [00:00<00:00, 86027.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 89069.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 170164.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132070.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%|████████▊ | 9293/10556 [00:00<00:00, 92928.98it/s]100%|██████████| 10556/10556 [00:00<00:00, 97275.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124295.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|███████▋  | 8126/10556 [00:00<00:00, 81256.40it/s]100%|██████████| 10556/10556 [00:00<00:00, 88732.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 108029.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 167741.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 174735.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139720.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 225239.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189399.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7040/10556 [00:00<00:00, 70396.71it/s]100%|██████████| 10556/10556 [00:00<00:00, 85465.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191941.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187086.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 143484.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147869.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 148123.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 146112.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158782.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160559.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154543.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 139377.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|█████████▊| 10408/10556 [00:00<00:00, 104079.60it/s]100%|██████████| 10556/10556 [00:00<00:00, 103410.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214796.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 187689.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191857.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 193920.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179914.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 184180.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183203.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217844.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 185463.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 190769.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189509.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220258.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215716.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217947.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216826.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 194007.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214990.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210337.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 229743.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219389.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221503.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 230789.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222801.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 224061.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212158.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 216147.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200640.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107778.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201916.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 224034.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212045.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206518.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203193.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%|████████▌ | 9091/10556 [00:00<00:00, 90908.14it/s]100%|██████████| 10556/10556 [00:00<00:00, 97046.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214493.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219823.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217376.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211014.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207113.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214817.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 189078.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221031.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 191606.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209691.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 178729.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 154035.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118562.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211588.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213050.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202336.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 236069.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 230322.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 230766.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 225801.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 199606.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221950.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221394.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 224319.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218251.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 110539.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203000.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 203271.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212891.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202312.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 200537.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 130549.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153591.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220060.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220374.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 183094.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 204494.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212401.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 225553.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207612.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207818.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209369.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217823.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218771.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222208.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206299.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 217807.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 225120.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 225738.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 223606.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214302.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215930.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222166.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220069.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214431.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 207359.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 224350.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219134.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213269.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220224.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 201136.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213198.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214941.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215436.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 186046.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213427.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213336.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 215339.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 214694.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 202033.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221807.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 153467.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160507.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 158315.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 160622.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 144393.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 137431.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 132248.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 118159.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 230557.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222636.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 192823.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 179960.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213120.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 208352.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218708.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 226297.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 182906.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 206521.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222788.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 198291.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218967.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220608.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 227877.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219814.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 218142.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 210926.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 229618.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 220822.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 226149.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 219170.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 197316.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221322.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 227955.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 229314.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 222449.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 226354.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 225030.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 238486.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 230529.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 234530.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 225069.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 241765.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 241319.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 241492.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 244012.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 244117.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 238982.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 241072.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 233725.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 227861.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213400.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 212619.69it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '2.93656'}; time used = 0.4549872875213623s
epoch 10: {'train_loss': '0.80523'}; time used = 0.3960294723510742s
epoch 15: {'train_loss': '0.62204'}; time used = 0.46561217308044434s
epoch 20: {'train_loss': '0.48785'}; time used = 0.43009281158447266s
epoch 25: {'train_loss': '0.35510'}; time used = 0.5398468971252441s
epoch 30: {'train_loss': '0.28632'}; time used = 0.41156721115112305s
epoch 35: {'train_loss': '0.23438'}; time used = 0.4420759677886963s
epoch 40: {'train_loss': '0.19158'}; time used = 0.5025043487548828s
epoch 45: {'train_loss': '0.16286'}; time used = 0.43302226066589355s
epoch 50: {'train_loss': '0.13578'}; time used = 0.5320892333984375s
epoch 55: {'train_loss': '0.12310'}; time used = 0.49532008171081543s
epoch 60: {'train_loss': '0.11847'}; time used = 0.4566044807434082s
epoch 65: {'train_loss': '0.10901'}; time used = 0.5035519599914551s
epoch 70: {'train_loss': '0.10021'}; time used = 0.3825340270996094s
epoch 75: {'train_loss': '0.09291'}; time used = 0.45627665519714355s
epoch 80: {'train_loss': '0.08787'}; time used = 0.6117756366729736s
epoch 85: {'train_loss': '0.08258'}; time used = 0.7585644721984863s
epoch 90: {'train_loss': '0.08315'}; time used = 0.4016115665435791s
epoch 95: {'train_loss': '0.08151'}; time used = 0.4045677185058594s
epoch 100: {'train_loss': '0.06864'}; time used = 0.45845794677734375s
epoch 105: {'train_loss': '0.07051'}; time used = 0.5383639335632324s
epoch 110: {'train_loss': '0.07314'}; time used = 0.5922131538391113s
epoch 115: {'train_loss': '0.06670'}; time used = 0.6277885437011719s
epoch 120: {'train_loss': '0.06977'}; time used = 0.4987199306488037s
epoch 125: {'train_loss': '0.06593'}; time used = 0.4698178768157959s
epoch 130: {'train_loss': '0.06998'}; time used = 0.47874975204467773s
epoch 135: {'train_loss': '0.06363'}; time used = 0.44742774963378906s
epoch 140: {'train_loss': '0.07151'}; time used = 0.41695713996887207s
epoch 145: {'train_loss': '0.05950'}; time used = 0.40305233001708984s
epoch 150: {'train_loss': '0.06663'}; time used = 0.3737325668334961s
epoch 155: {'train_loss': '0.05884'}; time used = 0.371964693069458s
epoch 160: {'train_loss': '0.05702'}; time used = 0.42525172233581543s
epoch 165: {'train_loss': '0.04936'}; time used = 0.44474196434020996s
epoch 170: {'train_loss': '0.05541'}; time used = 0.3651456832885742s
epoch 175: {'train_loss': '0.06344'}; time used = 0.3880753517150879s
epoch 180: {'train_loss': '0.05039'}; time used = 0.46519994735717773s
epoch 185: {'train_loss': '0.05266'}; time used = 0.3556954860687256s
epoch 190: {'train_loss': '0.06082'}; time used = 0.37291693687438965s
epoch 195: {'train_loss': '0.04264'}; time used = 0.43192267417907715s
epoch 200: {'train_loss': '0.06203'}; time used = 0.4228091239929199s
epoch 205: {'train_loss': '0.05067'}; time used = 0.38468122482299805s
epoch 210: {'train_loss': '0.03969'}; time used = 0.37226104736328125s
epoch 215: {'train_loss': '0.04572'}; time used = 0.3581430912017822s
epoch 220: {'train_loss': '0.06111'}; time used = 0.36945295333862305s
epoch 225: {'train_loss': '0.04696'}; time used = 0.3608529567718506s
epoch 230: {'train_loss': '0.04033'}; time used = 0.374039888381958s
epoch 235: {'train_loss': '0.05684'}; time used = 0.375244140625s
epoch 240: {'train_loss': '0.06105'}; time used = 0.4344503879547119s
epoch 245: {'train_loss': '0.05754'}; time used = 0.4975903034210205s
epoch 250: {'train_loss': '0.05842'}; time used = 0.38138723373413086s
epoch 255: {'train_loss': '0.05410'}; time used = 0.3701152801513672s
epoch 260: {'train_loss': '0.05561'}; time used = 0.37400245666503906s
epoch 265: {'train_loss': '0.05607'}; time used = 0.3651614189147949s
epoch 270: {'train_loss': '0.04439'}; time used = 0.35999631881713867s
epoch 275: {'train_loss': '0.05112'}; time used = 0.35559558868408203s
epoch 280: {'train_loss': '0.04670'}; time used = 0.3502767086029053s
epoch 285: {'train_loss': '0.04424'}; time used = 0.3382596969604492s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.595919370651245.
Training classifier using 20.00% nodes...
{'micro': 0.7494231656668204, 'macro': 0.7290176176556898, 'samples': 0.7494231656668204, 'weighted': 0.7461192296037001}
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 228882.72it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 0; 10.76 GiB total capacity; 73.04 MiB already allocated; 960.44 MiB free; 86.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f9c1ce511e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f9c2d27964b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f9c2d27a464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f9c2d27aaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f99cb03a90e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f99c9474949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f99c948e777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f9a0422ac7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f9a0422af97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f9a04335a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f9a03fc54f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f9a03fc7166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f9a03fc765d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f9a03fc780a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f9a03d04eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f99c9463b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f9a03b97530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f9a0437f81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f9a042d082b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f9a03e07952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f9a03e08f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f9a043dc8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f9a0440608b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f9a0432d337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f9a05f3b205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f9a0440608b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f9a0432d337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f9a05e9af78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f9a064b6bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f9a064b2400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f9a064b2fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f9a064ab119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f9b0bbe44ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f9c2dd806df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f9c31ddb6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f9c3211471f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|█████▌    | 5856/10556 [00:00<00:00, 56725.34it/s]100%|██████████| 10556/10556 [00:00<00:00, 66142.32it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 0; 10.76 GiB total capacity; 73.04 MiB already allocated; 1.71 GiB free; 86.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f56bd3311e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f56cd75964b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f56cd75a464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f56cd75aaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f546b51a90e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f5469954949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f546996e777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f54a470ac7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f54a470af97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f54a4815a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f54a44a54f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f54a44a7166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f54a44a765d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f54a44a780a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f54a41e4eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f5469943b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f54a4077530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f54a485f81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f54a47b082b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f54a42e7952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f54a42e8f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f54a48bc8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f54a48e608b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f54a480d337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f54a641b205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f54a48e608b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f54a480d337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f54a637af78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f54a6996bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f54a6992400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f54a6992fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f54a698b119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f56920e04ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f56ce2606df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f56d22bb6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f56d25f471f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|█████▏    | 5498/10556 [00:00<00:00, 54976.51it/s]100%|██████████| 10556/10556 [00:00<00:00, 68588.44it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 0; 10.76 GiB total capacity; 78.58 MiB already allocated; 1.38 GiB free; 94.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f5cad61f1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f5cad87564b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f5cad876464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f5cad876aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f5a6cb6990e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f5a6afa3949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f5a6afbd777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f5caeb71c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f5caeb71f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f5caec7ca1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f5cae90c4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f5cae90e166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f5cae90e65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f5cae90e80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f5cae64beb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f5a6af92b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f5cae4de530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f5caecc681c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f5caec1782b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f5cae74e952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f5cae74ff4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f5caed238c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f5caed4d08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f5caec74337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f5cb0882205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f5caed4d08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f5caec74337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f5cb07e1f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f5cb0dfdbb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f5cb0df9400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f5cb0df9fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f5cb0df2119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f5cbe5924ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f5cbf6ee6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f5cc37496db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f5cc3a8271f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 105807.57it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 0; 10.76 GiB total capacity; 78.58 MiB already allocated; 1.70 GiB free; 94.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f9a790471e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f9a7929d64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f9a7929e464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f9a7929eaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f983859190e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f98369cb949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f98369e5777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f9a7a599c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f9a7a599f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f9a7a6a4a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f9a7a3344f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f9a7a336166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f9a7a33665d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f9a7a33680a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f9a7a073eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f98369bab40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f9a79f06530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f9a7a6ee81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f9a7a63f82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f9a7a176952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f9a7a177f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f9a7a74b8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f9a7a77508b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f9a7a69c337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f9a7c2aa205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f9a7a77508b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f9a7a69c337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f9a7c209f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f9a7c825bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f9a7c821400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f9a7c821fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f9a7c81a119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f9a89fba4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f9a8b1166df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f9a8f1716db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f9a8f4aa71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|█████▊    | 6087/10556 [00:00<00:00, 60869.62it/s]100%|██████████| 10556/10556 [00:00<00:00, 64762.49it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 0; 10.76 GiB total capacity; 78.58 MiB already allocated; 403.44 MiB free; 94.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f213caf31e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f213cd4964b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f213cd4a464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f213cd4aaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f1efc03d90e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f1efa477949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f1efa491777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f213e045c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f213e045f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f213e150a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f213dde04f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f213dde2166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f213dde265d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f213dde280a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f213db1feb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f1efa466b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f213d9b2530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f213e19a81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f213e0eb82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f213dc22952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f213dc23f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f213e1f78c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f213e22108b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f213e148337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f213fd56205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f213e22108b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f213e148337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f213fcb5f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f21402d1bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f21402cd400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f21402cdfa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f21402c6119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f214da664ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f214ebc26df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f2152c1d6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f2152f5671f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 213518.94it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 0; 10.76 GiB total capacity; 84.12 MiB already allocated; 2.41 GiB free; 106.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f50d61b91e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f50d640f64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f50d6410464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f50d6410aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f4e9570390e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f4e93b3d949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f4e93b57777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f50d770bc7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f50d770bf97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f50d7816a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f50d74a64f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f50d74a8166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f50d74a865d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f50d74a880a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f50d71e5eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f4e93b2cb40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f50d7078530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f50d786081c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f50d77b182b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f50d72e8952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f50d72e9f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f50d78bd8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f50d78e708b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f50d780e337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f50d941c205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f50d78e708b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f50d780e337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f50d937bf78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f50d9997bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f50d9993400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f50d9993fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f50d998c119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f50e712c4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f50e82886df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f50ec2e36db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f50ec61c71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 238790.34it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 0; 10.76 GiB total capacity; 84.12 MiB already allocated; 1022.44 MiB free; 106.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f859f88b1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f85afcb364b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f85afcb4464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f85afcb4aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f834da7490e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f834beae949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f834bec8777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f8386c64c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f8386c64f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f8386d6fa1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f83869ff4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f8386a01166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f8386a0165d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f8386a0180a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f838673eeb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f834be9db40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f83865d1530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f8386db981c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f8386d0a82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f8386841952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f8386842f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f8386e168c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f8386e4008b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f8386d67337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f8388975205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f8386e4008b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f8386d67337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f83888d4f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f8388ef0bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f8388eec400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f8388eecfa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f8388ee5119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f856be394ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f85b07ba6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f85b48156db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f85b4b4e71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 119118.28it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 0; 10.76 GiB total capacity; 84.12 MiB already allocated; 902.44 MiB free; 106.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fdbf3eac1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7fdc042d464b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7fdc042d5464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7fdc042d5aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7fd9a209590e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7fd9a04cf949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7fd9a04e9777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7fd9db285c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7fd9db285f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7fd9db390a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7fd9db0204f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7fd9db022166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7fd9db02265d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7fd9db02280a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7fd9dad5feb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7fd9a04beb40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7fd9dabf2530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7fd9db3da81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7fd9db32b82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7fd9dae62952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7fd9dae63f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7fd9db4378c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7fd9db46108b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7fd9db388337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7fd9dcf96205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7fd9db46108b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7fd9db388337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7fd9dcef5f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7fd9dd511bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7fd9dd50d400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7fd9dd50dfa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7fd9dd506119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7fda8e4364ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7fdc04ddb6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7fdc08e366db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7fdc0916f71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 107148.05it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 0; 10.76 GiB total capacity; 84.12 MiB already allocated; 1.13 GiB free; 106.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f0c650ed1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f0c6534364b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f0c65344464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f0c65344aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f0a2463790e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f0a22a71949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f0a22a8b777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f0c6663fc7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f0c6663ff97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f0c6674aa1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f0c663da4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f0c663dc166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f0c663dc65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f0c663dc80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f0c66119eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f0a22a60b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f0c65fac530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f0c6679481c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f0c666e582b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f0c6621c952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f0c6621df4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f0c667f18c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f0c6681b08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f0c66742337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f0c68350205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f0c6681b08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f0c66742337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f0c682aff78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f0c688cbbb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f0c688c7400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f0c688c7fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f0c688c0119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f0c760604ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f0c771bc6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f0c7b2176db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f0c7b55071f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 209740.04it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 0; 10.76 GiB total capacity; 89.65 MiB already allocated; 1.87 GiB free; 106.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fc75a6761e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7fc75a8cc64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7fc75a8cd464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7fc75a8cdaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7fc519bc090e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7fc517ffa949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7fc518014777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7fc75bbc8c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7fc75bbc8f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7fc75bcd3a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7fc75b9634f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7fc75b965166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7fc75b96565d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7fc75b96580a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7fc75b6a2eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7fc517fe9b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7fc75b535530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7fc75bd1d81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7fc75bc6e82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7fc75b7a5952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7fc75b7a6f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7fc75bd7a8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7fc75bda408b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7fc75bccb337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7fc75d8d9205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7fc75bda408b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7fc75bccb337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7fc75d838f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7fc75de54bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7fc75de50400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7fc75de50fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7fc75de49119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7fc76b5e94ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7fc76c7456df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7fc7707a06db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7fc770ad971f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 133209.80it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 2.58 GiB (GPU 0; 10.76 GiB total capacity; 89.65 MiB already allocated; 1.87 GiB free; 106.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f64771e01e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f64887b964b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f64887ba464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f64887baaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f622657a90e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f62249b4949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f62249ce777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f625f76ac7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f625f76af97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f625f875a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f625f5054f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f625f507166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f625f50765d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f625f50780a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f625f244eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f62249a3b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f625f0d7530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f625f8bf81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f625f81082b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f625f347952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f625f348f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f625f91c8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f625f94608b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f625f86d337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f626147b205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f625f94608b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f625f86d337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f62613daf78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f62619f6bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f62619f2400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f62619f2fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f62619eb119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f64779454ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f64892c06df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f648d31b6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f648d65471f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|██████▋   | 7108/10556 [00:00<00:00, 66362.41it/s]100%|██████████| 10556/10556 [00:00<00:00, 65116.82it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 10.31 GiB (GPU 0; 10.76 GiB total capacity; 116.42 MiB already allocated; 1.85 GiB free; 126.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f332cf6f1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f333d39764b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f333d398464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f333d398aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f30db15890e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f30d9592949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f30d95ac777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f3114348c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f3114348f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f3114453a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f31140e34f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f31140e5166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f31140e565d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f31140e580a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f3113e22eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f30d9581b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f3113cb5530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f311449d81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f31143ee82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f3113f25952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f3113f26f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f31144fa8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f311452408b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f311444b337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f3116059205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f311452408b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f311444b337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f3115fb8f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f31165d4bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f31165d0400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f31165d0fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f31165c9119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f32e851b4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f333de9e6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f3341ef96db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f334223271f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 239561.69it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 10.31 GiB (GPU 0; 10.76 GiB total capacity; 116.42 MiB already allocated; 2.84 GiB free; 126.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7eff306831e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7eff308d964b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7eff308da464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7eff308daaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7efcefbcd90e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7efcee007949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7efcee021777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7eff31bd5c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7eff31bd5f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7eff31ce0a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7eff319704f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7eff31972166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7eff3197265d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7eff3197280a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7eff316afeb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7efcedff6b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7eff31542530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7eff31d2a81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7eff31c7b82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7eff317b2952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7eff317b3f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7eff31d878c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7eff31db108b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7eff31cd8337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7eff338e6205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7eff31db108b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7eff31cd8337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7eff33845f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7eff33e61bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7eff33e5d400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7eff33e5dfa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7eff33e56119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7eff415f64ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7eff427526df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7eff467ad6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7eff46ae671f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 147242.47it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 10.31 GiB (GPU 0; 10.76 GiB total capacity; 128.00 MiB already allocated; 1.83 GiB free; 148.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f8d6d6101e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f8d7da3864b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f8d7da39464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f8d7da39aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f8b1b7f990e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f8b19c33949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f8b19c4d777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f8b549e9c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f8b549e9f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f8b54af4a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f8b547844f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f8b54786166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f8b5478665d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f8b5478680a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f8b544c3eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f8b19c22b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f8b54356530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f8b54b3e81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f8b54a8f82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f8b545c6952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f8b545c7f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f8b54b9b8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f8b54bc508b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f8b54aec337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f8b566fa205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f8b54bc508b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f8b54aec337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f8b56659f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f8b56c75bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f8b56c71400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f8b56c71fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f8b56c6a119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f8c18b9c4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f8d7e53f6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f8d8259a6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f8d828d371f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 124042.40it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 10.31 GiB (GPU 0; 10.76 GiB total capacity; 128.00 MiB already allocated; 942.44 MiB free; 148.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f1cd28991e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f1ce2cc164b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f1ce2cc2464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f1ce2cc2aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f1a80a8290e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f1a7eebc949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f1a7eed6777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f1ab9c72c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f1ab9c72f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f1ab9d7da1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f1ab9a0d4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f1ab9a0f166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f1ab9a0f65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f1ab9a0f80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f1ab974ceb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f1a7eeabb40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f1ab95df530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f1ab9dc781c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f1ab9d1882b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f1ab984f952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f1ab9850f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f1ab9e248c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f1ab9e4e08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f1ab9d75337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f1abb983205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f1ab9e4e08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f1ab9d75337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f1abb8e2f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f1abbefebb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f1abbefa400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f1abbefafa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f1abbef3119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f1c8de454ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f1ce37c86df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f1ce78236db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f1ce7b5c71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|████████  | 8556/10556 [00:00<00:00, 85553.96it/s]100%|██████████| 10556/10556 [00:00<00:00, 90797.94it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 10.31 GiB (GPU 0; 10.76 GiB total capacity; 128.00 MiB already allocated; 1.83 GiB free; 148.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fc8933d71e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7fc89362d64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7fc89362e464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7fc89362eaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7fc65292190e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7fc650d5b949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7fc650d75777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7fc894929c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7fc894929f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7fc894a34a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7fc8946c44f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7fc8946c6166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7fc8946c665d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7fc8946c680a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7fc894403eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7fc650d4ab40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7fc894296530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7fc894a7e81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7fc8949cf82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7fc894506952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7fc894507f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7fc894adb8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7fc894b0508b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7fc894a2c337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7fc89663a205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7fc894b0508b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7fc894a2c337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7fc896599f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7fc896bb5bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7fc896bb1400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7fc896bb1fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7fc896baa119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7fc8a434a4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7fc8a54a66df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7fc8a95016db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7fc8a983a71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 221271.37it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 10.31 GiB (GPU 0; 10.76 GiB total capacity; 139.58 MiB already allocated; 831.44 MiB free; 168.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f4e22c5b1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f4e22eb164b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f4e22eb2464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f4e22eb2aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f4be21a590e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f4be05df949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f4be05f9777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f4e241adc7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f4e241adf97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f4e242b8a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f4e23f484f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f4e23f4a166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f4e23f4a65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f4e23f4a80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f4e23c87eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f4be05ceb40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f4e23b1a530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f4e2430281c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f4e2425382b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f4e23d8a952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f4e23d8bf4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f4e2435f8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f4e2438908b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f4e242b0337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f4e25ebe205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f4e2438908b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f4e242b0337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f4e25e1df78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f4e26439bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f4e26435400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f4e26435fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f4e2642e119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f4e33bce4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f4e34d2a6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f4e38d856db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f4e390be71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 196405.37it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 10.31 GiB (GPU 0; 10.76 GiB total capacity; 139.58 MiB already allocated; 1.48 GiB free; 168.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fbdb23291e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7fbdc275164b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7fbdc2752464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7fbdc2752aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7fbb6051290e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7fbb5e94c949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7fbb5e966777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7fbb99702c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7fbb99702f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7fbb9980da1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7fbb9949d4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7fbb9949f166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7fbb9949f65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7fbb9949f80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7fbb991dceb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7fbb5e93bb40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7fbb9906f530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7fbb9985781c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7fbb997a882b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7fbb992df952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7fbb992e0f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7fbb998b48c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7fbb998de08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7fbb99805337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7fbb9b413205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7fbb998de08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7fbb99805337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7fbb9b372f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7fbb9b98ebb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7fbb9b98a400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7fbb9b98afa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7fbb9b983119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7fbd870d84ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7fbdc32586df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7fbdc72b36db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7fbdc75ec71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 211908.36it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 10.31 GiB (GPU 0; 10.76 GiB total capacity; 151.16 MiB already allocated; 1.81 GiB free; 170.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fa0a1aa21e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7fa0a9eac64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7fa0a9ead464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7fa0a9eadaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f9e4fc8b90e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f9e4e0c5949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f9e4e0df777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f9e88e7bc7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f9e88e7bf97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f9e88f86a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f9e88c164f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f9e88c18166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f9e88c1865d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f9e88c1880a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f9e88955eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f9e4e0b4b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f9e887e8530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f9e88fd081c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f9e88f2182b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f9e88a58952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f9e88a59f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f9e8902d8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f9e8905708b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f9e88f7e337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f9e8ab8c205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f9e8905708b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f9e88f7e337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f9e8aaebf78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f9e8b107bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f9e8b103400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f9e8b103fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f9e8b0fc119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7fa0988554ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7fa0b29d16df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7fa0b6a2c6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7fa0b6d6571f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 223031.37it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 10.31 GiB (GPU 0; 10.76 GiB total capacity; 151.16 MiB already allocated; 1.54 GiB free; 170.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f149777c1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f14979d264b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f14979d3464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f14979d3aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f123579390e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f1233bcd949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f1233be7777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f126e983c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f126e983f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f126ea8ea1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f126e71e4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f126e720166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f126e72065d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f126e72080a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f126e45deb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f1233bbcb40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f126e2f0530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f126ead881c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f126ea2982b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f126e560952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f126e561f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f126eb358c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f126eb5f08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f126ea86337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f1270694205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f126eb5f08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f126ea86337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f12705f3f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f1270c0fbb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f1270c0b400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f1270c0bfa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f1270c04119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f147e35d4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f14984d96df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f149c5346db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f149c86d71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 235423.06it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 10.31 GiB (GPU 0; 10.76 GiB total capacity; 151.16 MiB already allocated; 1.81 GiB free; 170.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f50451191e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f505554164b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f5055542464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f5055542aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f4df330290e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f4df173c949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f4df1756777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f4e2c4f2c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f4e2c4f2f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f4e2c5fda1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f4e2c28d4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f4e2c28f166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f4e2c28f65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f4e2c28f80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f4e2bfcceb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f4df172bb40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f4e2be5f530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f4e2c64781c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f4e2c59882b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f4e2c0cf952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f4e2c0d0f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f4e2c6a48c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f4e2c6ce08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f4e2c5f5337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f4e2e203205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f4e2c6ce08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f4e2c5f5337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f4e2e162f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f4e2e77ebb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f4e2e77a400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f4e2e77afa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f4e2e773119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f503becc4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f50560486df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f505a0a36db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f505a3dc71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/10556 [00:00<?, ?it/s]100%|██████████| 10556/10556 [00:00<00:00, 129782.98it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 10.31 GiB (GPU 0; 10.76 GiB total capacity; 151.16 MiB already allocated; 1.81 GiB free; 170.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f26332361e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f263b64064b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f263b641464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f263b641aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f23e141f90e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f23df859949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f23df873777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f241a60fc7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f241a60ff97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f241a71aa1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f241a3aa4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f241a3ac166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f241a3ac65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f241a3ac80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f241a0e9eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f23df848b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f2419f7c530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f241a76481c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f241a6b582b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f241a1ec952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f241a1edf4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f241a7c18c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f241a7eb08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f241a712337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f241c320205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f241a7eb08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f241a712337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f241c27ff78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f241c89bbb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f241c897400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f241c897fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f241c890119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f24c2fbb4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f26441656df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f26481c06db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f26484f971f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 113223.40it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.05666160583496094 seconds.
Run epoch 1
Epoch 1 ends in 0.027059078216552734 seconds.
5416 sentences created
mode 1: time used = 0.07712721824645996
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '1.35922'}; time used = 0.6063616275787354s
epoch 10: {'train_loss': '1.31056'}; time used = 0.4901716709136963s
epoch 15: {'train_loss': '1.23785'}; time used = 0.7279386520385742s
epoch 20: {'train_loss': '1.14025'}; time used = 0.5936932563781738s
epoch 25: {'train_loss': '1.04356'}; time used = 0.6048095226287842s
epoch 30: {'train_loss': '0.95669'}; time used = 0.6172971725463867s
epoch 35: {'train_loss': '0.87379'}; time used = 0.5695648193359375s
epoch 40: {'train_loss': '0.80474'}; time used = 0.6458573341369629s
epoch 45: {'train_loss': '0.74068'}; time used = 0.6500921249389648s
epoch 50: {'train_loss': '0.69163'}; time used = 0.6649172306060791s
epoch 55: {'train_loss': '0.64391'}; time used = 0.6963391304016113s
epoch 60: {'train_loss': '0.60814'}; time used = 0.702178955078125s
epoch 65: {'train_loss': '0.57201'}; time used = 0.5082957744598389s
epoch 70: {'train_loss': '0.54200'}; time used = 0.5421023368835449s
epoch 75: {'train_loss': '0.51304'}; time used = 0.5480644702911377s
epoch 80: {'train_loss': '0.48924'}; time used = 0.8048741817474365s
epoch 85: {'train_loss': '0.46732'}; time used = 0.6325678825378418s
epoch 90: {'train_loss': '0.44584'}; time used = 0.7423288822174072s
epoch 95: {'train_loss': '0.42967'}; time used = 0.6504909992218018s
epoch 100: {'train_loss': '0.41229'}; time used = 0.8358545303344727s
epoch 105: {'train_loss': '0.40214'}; time used = 0.7922046184539795s
epoch 110: {'train_loss': '0.38692'}; time used = 0.7361235618591309s
epoch 115: {'train_loss': '0.37185'}; time used = 0.7218582630157471s
epoch 120: {'train_loss': '0.35959'}; time used = 0.7482321262359619s
epoch 125: {'train_loss': '0.34919'}; time used = 0.7290699481964111s
epoch 130: {'train_loss': '0.33927'}; time used = 0.573615550994873s
epoch 135: {'train_loss': '0.33094'}; time used = 0.5795814990997314s
epoch 140: {'train_loss': '0.32207'}; time used = 0.5473473072052002s
epoch 145: {'train_loss': '0.31471'}; time used = 0.6245706081390381s
epoch 150: {'train_loss': '0.30056'}; time used = 0.4581582546234131s
epoch 155: {'train_loss': '0.29925'}; time used = 0.09450125694274902s
epoch 160: {'train_loss': '0.29516'}; time used = 0.09257388114929199s
epoch 165: {'train_loss': '0.28574'}; time used = 0.10252976417541504s
epoch 170: {'train_loss': '0.27848'}; time used = 0.0941925048828125s
epoch 175: {'train_loss': '0.27130'}; time used = 0.11409163475036621s
epoch 180: {'train_loss': '0.27000'}; time used = 0.1831982135772705s
epoch 185: {'train_loss': '0.26194'}; time used = 0.0890960693359375s
epoch 190: {'train_loss': '0.25640'}; time used = 0.08882594108581543s
epoch 195: {'train_loss': '0.24551'}; time used = 0.08877420425415039s
epoch 200: {'train_loss': '0.24778'}; time used = 0.10699582099914551s
epoch 205: {'train_loss': '0.24280'}; time used = 0.17573070526123047s
epoch 210: {'train_loss': '0.23401'}; time used = 0.1741023063659668s
epoch 215: {'train_loss': '0.23221'}; time used = 0.08360981941223145s
epoch 220: {'train_loss': '0.22814'}; time used = 0.08899664878845215s
epoch 225: {'train_loss': '0.22454'}; time used = 0.09474420547485352s
epoch 230: {'train_loss': '0.21595'}; time used = 0.09359145164489746s
epoch 235: {'train_loss': '0.21449'}; time used = 0.08943557739257812s
epoch 240: {'train_loss': '0.21586'}; time used = 0.08949685096740723s
epoch 245: {'train_loss': '0.20955'}; time used = 0.09160208702087402s
epoch 250: {'train_loss': '0.20683'}; time used = 0.08893680572509766s
epoch 255: {'train_loss': '0.20244'}; time used = 0.08329153060913086s
epoch 260: {'train_loss': '0.19674'}; time used = 0.11351871490478516s
epoch 265: {'train_loss': '0.19516'}; time used = 0.0851435661315918s
epoch 270: {'train_loss': '0.19262'}; time used = 0.08157634735107422s
epoch 275: {'train_loss': '0.18935'}; time used = 0.0808112621307373s
epoch 280: {'train_loss': '0.19087'}; time used = 0.08085894584655762s
epoch 285: {'train_loss': '0.18913'}; time used = 0.0914769172668457s
epoch 290: {'train_loss': '0.18321'}; time used = 0.0942387580871582s
epoch 295: {'train_loss': '0.18030'}; time used = 0.10082149505615234s
epoch 300: {'train_loss': '0.17699'}; time used = 0.0827484130859375s
epoch 305: {'train_loss': '0.17612'}; time used = 0.08712506294250488s
epoch 310: {'train_loss': '0.17260'}; time used = 0.08353376388549805s
epoch 315: {'train_loss': '0.16996'}; time used = 0.08608293533325195s
epoch 320: {'train_loss': '0.16781'}; time used = 0.10642480850219727s
epoch 325: {'train_loss': '0.16306'}; time used = 0.10168647766113281s
epoch 330: {'train_loss': '0.16051'}; time used = 0.09325623512268066s
epoch 335: {'train_loss': '0.16222'}; time used = 0.08829569816589355s
epoch 340: {'train_loss': '0.16135'}; time used = 0.08688902854919434s
epoch 345: {'train_loss': '0.15575'}; time used = 0.0834360122680664s
epoch 350: {'train_loss': '0.16147'}; time used = 0.08587861061096191s
epoch 355: {'train_loss': '0.15475'}; time used = 0.09038472175598145s
epoch 360: {'train_loss': '0.15225'}; time used = 0.0972130298614502s
epoch 365: {'train_loss': '0.15105'}; time used = 0.08999347686767578s
epoch 370: {'train_loss': '0.15182'}; time used = 0.08997583389282227s
epoch 375: {'train_loss': '0.15322'}; time used = 0.09465622901916504s
epoch 380: {'train_loss': '0.14275'}; time used = 0.09601330757141113s
epoch 385: {'train_loss': '0.14459'}; time used = 0.1338968276977539s
epoch 390: {'train_loss': '0.14379'}; time used = 0.12313151359558105s
epoch 395: {'train_loss': '0.14267'}; time used = 0.09076189994812012s
epoch 400: {'train_loss': '0.14179'}; time used = 0.09069108963012695s
epoch 405: {'train_loss': '0.14091'}; time used = 0.08883166313171387s
epoch 410: {'train_loss': '0.13544'}; time used = 0.09963130950927734s
epoch 415: {'train_loss': '0.13643'}; time used = 0.09104776382446289s
epoch 420: {'train_loss': '0.13246'}; time used = 0.08581304550170898s
epoch 425: {'train_loss': '0.13589'}; time used = 0.08621859550476074s
epoch 430: {'train_loss': '0.13363'}; time used = 0.0851588249206543s
epoch 435: {'train_loss': '0.13030'}; time used = 0.0836181640625s
epoch 440: {'train_loss': '0.12925'}; time used = 0.0992422103881836s
epoch 445: {'train_loss': '0.13122'}; time used = 0.09058737754821777s
epoch 450: {'train_loss': '0.12776'}; time used = 0.09109020233154297s
epoch 455: {'train_loss': '0.13085'}; time used = 0.08834576606750488s
epoch 460: {'train_loss': '0.12559'}; time used = 0.08783268928527832s
epoch 465: {'train_loss': '0.12355'}; time used = 0.08678627014160156s
epoch 470: {'train_loss': '0.12654'}; time used = 0.08768296241760254s
epoch 475: {'train_loss': '0.12357'}; time used = 0.10744976997375488s
epoch 480: {'train_loss': '0.11958'}; time used = 0.09672379493713379s
epoch 485: {'train_loss': '0.12062'}; time used = 0.09603309631347656s
epoch 490: {'train_loss': '0.12321'}; time used = 0.09516382217407227s

epoch 495: {'train_loss': '0.11868'}; time used = 0.09290409088134766s
epoch 500: {'train_loss': '0.11840'}; time used = 0.08773660659790039s
Finished training. Time used = 33.89699339866638.
Training classifier using 20.00% nodes...
{'micro': 0.7780341485925242, 'macro': 0.7652070247383881, 'samples': 0.7780341485925242, 'weighted': 0.7758960250586567}
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 193553.02it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.021294116973876953 seconds.
Run epoch 1
Epoch 1 ends in 0.016535043716430664 seconds.
5416 sentences created
mode 1: time used = 0.03654813766479492
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '0.95845'}; time used = 0.1078951358795166s
epoch 10: {'train_loss': '0.72758'}; time used = 0.1058804988861084s
epoch 15: {'train_loss': '0.54846'}; time used = 0.11486005783081055s
epoch 20: {'train_loss': '0.45693'}; time used = 0.13093948364257812s
epoch 25: {'train_loss': '0.38405'}; time used = 0.12159061431884766s
epoch 30: {'train_loss': '0.33568'}; time used = 0.12175655364990234s
epoch 35: {'train_loss': '0.29661'}; time used = 0.12489724159240723s
epoch 40: {'train_loss': '0.26766'}; time used = 0.10518288612365723s
epoch 45: {'train_loss': '0.23942'}; time used = 0.09486007690429688s
epoch 50: {'train_loss': '0.22118'}; time used = 0.08710813522338867s
epoch 55: {'train_loss': '0.20425'}; time used = 0.09249234199523926s
epoch 60: {'train_loss': '0.19134'}; time used = 0.12555742263793945s
epoch 65: {'train_loss': '0.17774'}; time used = 0.37715864181518555s
epoch 70: {'train_loss': '0.16875'}; time used = 0.5876221656799316s
epoch 75: {'train_loss': '0.15514'}; time used = 0.5580706596374512s
epoch 80: {'train_loss': '0.14994'}; time used = 0.5301597118377686s
epoch 85: {'train_loss': '0.14178'}; time used = 0.520561695098877s
epoch 90: {'train_loss': '0.13804'}; time used = 0.5104458332061768s
epoch 95: {'train_loss': '0.13397'}; time used = 0.5306017398834229s
epoch 100: {'train_loss': '0.12814'}; time used = 0.5011477470397949s
epoch 105: {'train_loss': '0.12746'}; time used = 0.5513780117034912s
epoch 110: {'train_loss': '0.13653'}; time used = 0.5792343616485596s
epoch 115: {'train_loss': '0.12658'}; time used = 0.5568773746490479s
epoch 120: {'train_loss': '0.25229'}; time used = 0.521597146987915s
epoch 125: {'train_loss': '0.18451'}; time used = 0.6468808650970459s
epoch 130: {'train_loss': '0.22989'}; time used = 0.597022533416748s
epoch 135: {'train_loss': '0.27254'}; time used = 0.6191146373748779s
epoch 140: {'train_loss': '0.21854'}; time used = 0.6605179309844971s
epoch 145: {'train_loss': '0.15766'}; time used = 0.6079950332641602s
epoch 150: {'train_loss': '0.13411'}; time used = 0.6455457210540771s
epoch 155: {'train_loss': '0.11953'}; time used = 0.5146872997283936s
epoch 160: {'train_loss': '0.11199'}; time used = 0.5800161361694336s
epoch 165: {'train_loss': '0.10534'}; time used = 0.5957610607147217s
epoch 170: {'train_loss': '0.10168'}; time used = 0.7749688625335693s
epoch 175: {'train_loss': '0.09538'}; time used = 0.9193763732910156s
epoch 180: {'train_loss': '0.09640'}; time used = 0.5122227668762207s
epoch 185: {'train_loss': '0.09162'}; time used = 0.6238536834716797s
epoch 190: {'train_loss': '0.08744'}; time used = 0.5655877590179443s
epoch 195: {'train_loss': '0.08476'}; time used = 0.5760278701782227s
epoch 200: {'train_loss': '0.08723'}; time used = 0.5365731716156006s
epoch 205: {'train_loss': '0.08315'}; time used = 1.0320491790771484s
epoch 210: {'train_loss': '0.08030'}; time used = 1.325061559677124s
epoch 215: {'train_loss': '0.08116'}; time used = 1.150275707244873s
epoch 220: {'train_loss': '0.07834'}; time used = 0.5749955177307129s
epoch 225: {'train_loss': '0.08000'}; time used = 0.6040771007537842s
epoch 230: {'train_loss': '0.07596'}; time used = 0.4817688465118408s
epoch 235: {'train_loss': '0.07714'}; time used = 0.6269841194152832s
epoch 240: {'train_loss': '0.07590'}; time used = 0.599724292755127s
epoch 245: {'train_loss': '0.07551'}; time used = 0.46950578689575195s
epoch 250: {'train_loss': '0.07325'}; time used = 0.516268253326416s
epoch 255: {'train_loss': '0.07295'}; time used = 0.5780391693115234s
epoch 260: {'train_loss': '0.07082'}; time used = 0.5395150184631348s
epoch 265: {'train_loss': '0.07402'}; time used = 0.6194536685943604s
epoch 270: {'train_loss': '0.06976'}; time used = 0.4848506450653076s
epoch 275: {'train_loss': '0.06896'}; time used = 0.5580852031707764s
epoch 280: {'train_loss': '0.07390'}; time used = 0.5812625885009766s
epoch 285: {'train_loss': '0.07220'}; time used = 0.5466694831848145s
epoch 290: {'train_loss': '0.07070'}; time used = 0.5309309959411621s
epoch 295: {'train_loss': '0.06925'}; time used = 0.5753803253173828s
epoch 300: {'train_loss': '0.06709'}; time used = 0.6191437244415283s
epoch 305: {'train_loss': '0.06764'}; time used = 0.5185563564300537s
epoch 310: {'train_loss': '0.06661'}; time used = 0.5360105037689209s
epoch 315: {'train_loss': '0.06812'}; time used = 0.6336202621459961s
epoch 320: {'train_loss': '0.06700'}; time used = 0.5588107109069824s
epoch 325: {'train_loss': '0.06423'}; time used = 0.5889928340911865s
epoch 330: {'train_loss': '0.06202'}; time used = 0.4839491844177246s
epoch 335: {'train_loss': '0.06333'}; time used = 0.5287847518920898s
epoch 340: {'train_loss': '0.06374'}; time used = 0.5919740200042725s
epoch 345: {'train_loss': '0.06287'}; time used = 0.5909028053283691s
epoch 350: {'train_loss': '0.06488'}; time used = 0.6624345779418945s
epoch 355: {'train_loss': '0.06128'}; time used = 0.535264253616333s
epoch 360: {'train_loss': '0.06113'}; time used = 0.5514018535614014s
epoch 365: {'train_loss': '0.06229'}; time used = 0.5356314182281494s
epoch 370: {'train_loss': '0.06369'}; time used = 0.5963079929351807s
epoch 375: {'train_loss': '0.06520'}; time used = 0.5552723407745361s
epoch 380: {'train_loss': '0.06057'}; time used = 0.5523960590362549s
epoch 385: {'train_loss': '0.06107'}; time used = 0.5497739315032959s
epoch 390: {'train_loss': '0.06156'}; time used = 0.5441403388977051s
epoch 395: {'train_loss': '0.06078'}; time used = 0.5355510711669922s
epoch 400: {'train_loss': '0.06332'}; time used = 0.5368070602416992s
epoch 405: {'train_loss': '0.06163'}; time used = 0.48996925354003906s
epoch 410: {'train_loss': '0.05802'}; time used = 0.21423721313476562s
epoch 415: {'train_loss': '0.06113'}; time used = 0.09979724884033203s
epoch 420: {'train_loss': '0.05837'}; time used = 0.09269070625305176s
epoch 425: {'train_loss': '0.05875'}; time used = 0.09709763526916504s
epoch 430: {'train_loss': '0.05977'}; time used = 0.08605337142944336s
epoch 435: {'train_loss': '0.05661'}; time used = 0.08682513236999512s
epoch 440: {'train_loss': '0.05695'}; time used = 0.1357109546661377s
epoch 445: {'train_loss': '0.06270'}; time used = 0.14818906784057617s
epoch 450: {'train_loss': '0.05820'}; time used = 0.16463637351989746s
epoch 455: {'train_loss': '0.05894'}; time used = 0.09302139282226562s
epoch 460: {'train_loss': '0.05710'}; time used = 0.09868073463439941s
epoch 465: {'train_loss': '0.05631'}; time used = 0.19426798820495605s
epoch 470: {'train_loss': '0.05794'}; time used = 0.09298324584960938s
epoch 475: {'train_loss': '0.05731'}; time used = 0.09596872329711914s
epoch 480: {'train_loss': '0.05587'}; time used = 0.19867801666259766s
epoch 485: {'train_loss': '0.05642'}; time used = 0.09559774398803711s
epoch 490: {'train_loss': '0.05919'}; time used = 0.08988404273986816s
epoch 495: {'train_loss': '0.05856'}; time used = 0.1017305850982666s

epoch 500: {'train_loss': '0.05668'}; time used = 0.09295248985290527s
Finished training. Time used = 48.79223036766052.
Training classifier using 20.00% nodes...
{'micro': 0.7540378403322567, 'macro': 0.7364774602375038, 'samples': 0.7540378403322566, 'weighted': 0.7527908813942978}
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 199374.66it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.015250921249389648 seconds.
Run epoch 1
Epoch 1 ends in 0.014633893966674805 seconds.
5416 sentences created
mode 1: time used = 0.03401327133178711
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '1.16084'}; time used = 0.14462685585021973s
epoch 10: {'train_loss': '0.75658'}; time used = 0.10055065155029297s
epoch 15: {'train_loss': '0.61663'}; time used = 0.08960652351379395s
epoch 20: {'train_loss': '0.47692'}; time used = 0.08903670310974121s
epoch 25: {'train_loss': '0.39813'}; time used = 0.09817314147949219s
epoch 30: {'train_loss': '0.34017'}; time used = 0.09312629699707031s
epoch 35: {'train_loss': '0.29338'}; time used = 0.09961962699890137s
epoch 40: {'train_loss': '0.25969'}; time used = 0.09964466094970703s
epoch 45: {'train_loss': '0.23154'}; time used = 0.10592484474182129s
epoch 50: {'train_loss': '0.21167'}; time used = 0.09201383590698242s
epoch 55: {'train_loss': '0.19219'}; time used = 0.10036039352416992s
epoch 60: {'train_loss': '0.18024'}; time used = 0.09613776206970215s
epoch 65: {'train_loss': '0.16693'}; time used = 0.10193014144897461s
epoch 70: {'train_loss': '0.15677'}; time used = 0.09716963768005371s
epoch 75: {'train_loss': '0.14488'}; time used = 0.09516429901123047s
epoch 80: {'train_loss': '0.14004'}; time used = 0.09503316879272461s
epoch 85: {'train_loss': '0.16046'}; time used = 0.09557271003723145s
epoch 90: {'train_loss': '0.20704'}; time used = 0.09905552864074707s
epoch 95: {'train_loss': '0.29417'}; time used = 0.09507489204406738s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 5.9816062450408936.
Training classifier using 20.00% nodes...
{'micro': 0.7600369173973235, 'macro': 0.744086756792746, 'samples': 0.7600369173973235, 'weighted': 0.758817889398262}
  0%|          | 0/5416 [00:00<?, ?it/s] 80%|████████  | 4341/5416 [00:00<00:00, 42878.24it/s]100%|██████████| 5416/5416 [00:00<00:00, 41606.64it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.04775643348693848 seconds.
Run epoch 1
Epoch 1 ends in 0.03500795364379883 seconds.
5416 sentences created
mode 1: time used = 0.17095613479614258
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '7.86312'}; time used = 0.525244951248169s
epoch 10: {'train_loss': '3.19342'}; time used = 0.4687521457672119s
epoch 15: {'train_loss': '1.17720'}; time used = 0.5251119136810303s
epoch 20: {'train_loss': '1.01574'}; time used = 0.5941839218139648s
epoch 25: {'train_loss': '0.83964'}; time used = 0.5562734603881836s
epoch 30: {'train_loss': '0.63635'}; time used = 0.5476374626159668s
epoch 35: {'train_loss': '0.54810'}; time used = 0.607172966003418s
epoch 40: {'train_loss': '0.48341'}; time used = 0.6521141529083252s
epoch 45: {'train_loss': '0.43437'}; time used = 0.5683908462524414s
epoch 50: {'train_loss': '0.39887'}; time used = 0.5217523574829102s
epoch 55: {'train_loss': '0.36082'}; time used = 0.4990365505218506s
epoch 60: {'train_loss': '0.33947'}; time used = 0.5556745529174805s
epoch 65: {'train_loss': '0.31892'}; time used = 0.6154680252075195s
epoch 70: {'train_loss': '0.30118'}; time used = 0.5927734375s
epoch 75: {'train_loss': '0.28233'}; time used = 0.593066930770874s
epoch 80: {'train_loss': '0.26870'}; time used = 0.5722458362579346s
epoch 85: {'train_loss': '0.25670'}; time used = 0.5998506546020508s
epoch 90: {'train_loss': '0.24202'}; time used = 0.5539717674255371s
epoch 95: {'train_loss': '0.23668'}; time used = 0.5642907619476318s
epoch 100: {'train_loss': '0.22510'}; time used = 0.586972713470459s
epoch 105: {'train_loss': '0.21993'}; time used = 0.5428760051727295s
epoch 110: {'train_loss': '0.21130'}; time used = 0.36554384231567383s
epoch 115: {'train_loss': '0.20287'}; time used = 0.08771824836730957s
epoch 120: {'train_loss': '0.19266'}; time used = 0.08968138694763184s
epoch 125: {'train_loss': '0.18876'}; time used = 0.08698487281799316s
epoch 130: {'train_loss': '0.18357'}; time used = 0.08675932884216309s
epoch 135: {'train_loss': '0.17741'}; time used = 0.14072608947753906s
epoch 140: {'train_loss': '0.17350'}; time used = 0.28929948806762695s
epoch 145: {'train_loss': '0.16719'}; time used = 0.16510391235351562s
epoch 150: {'train_loss': '0.15827'}; time used = 0.10430598258972168s
epoch 155: {'train_loss': '0.15716'}; time used = 0.09705138206481934s
epoch 160: {'train_loss': '0.15790'}; time used = 0.13232421875s
epoch 165: {'train_loss': '0.15319'}; time used = 0.1803760528564453s
epoch 170: {'train_loss': '0.14946'}; time used = 0.09977340698242188s
epoch 175: {'train_loss': '0.14484'}; time used = 0.12274670600891113s
epoch 180: {'train_loss': '0.14604'}; time used = 0.09855341911315918s
epoch 185: {'train_loss': '0.14237'}; time used = 0.10273361206054688s
epoch 190: {'train_loss': '0.13739'}; time used = 0.09002375602722168s
epoch 195: {'train_loss': '0.13278'}; time used = 0.09368658065795898s
epoch 200: {'train_loss': '0.13299'}; time used = 0.09677696228027344s
epoch 205: {'train_loss': '0.12789'}; time used = 0.1010136604309082s
epoch 210: {'train_loss': '0.12216'}; time used = 0.09662151336669922s
epoch 215: {'train_loss': '0.12274'}; time used = 0.09426283836364746s
epoch 220: {'train_loss': '0.11904'}; time used = 0.08608484268188477s
epoch 225: {'train_loss': '0.11900'}; time used = 0.09090161323547363s
epoch 230: {'train_loss': '0.11393'}; time used = 0.09892630577087402s
epoch 235: {'train_loss': '0.11443'}; time used = 0.1336672306060791s
epoch 240: {'train_loss': '0.11457'}; time used = 0.09312701225280762s
epoch 245: {'train_loss': '0.11090'}; time used = 0.09870147705078125s
epoch 250: {'train_loss': '0.10934'}; time used = 0.09577107429504395s
epoch 255: {'train_loss': '0.10592'}; time used = 0.09976768493652344s
epoch 260: {'train_loss': '0.10488'}; time used = 0.13478469848632812s
epoch 265: {'train_loss': '0.10445'}; time used = 0.08819127082824707s
epoch 270: {'train_loss': '0.10275'}; time used = 0.08138036727905273s
epoch 275: {'train_loss': '0.10004'}; time used = 0.0851447582244873s
epoch 280: {'train_loss': '0.10283'}; time used = 0.08864998817443848s
epoch 285: {'train_loss': '0.10406'}; time used = 0.20199942588806152s
epoch 290: {'train_loss': '0.10505'}; time used = 0.08146786689758301s
epoch 295: {'train_loss': '0.11172'}; time used = 0.09998703002929688s
epoch 300: {'train_loss': '0.17361'}; time used = 0.27269840240478516s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.464261531829834.
Training classifier using 20.00% nodes...
{'micro': 0.7669589293954776, 'macro': 0.7491993792768622, 'samples': 0.7669589293954776, 'weighted': 0.7645138452519985}
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 71535.39it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.035373687744140625 seconds.
Run epoch 1
Epoch 1 ends in 0.037164926528930664 seconds.
5416 sentences created
mode 1: time used = 0.09830474853515625
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '1.22488'}; time used = 0.487079381942749s
epoch 10: {'train_loss': '0.89970'}; time used = 0.46265268325805664s
epoch 15: {'train_loss': '0.76815'}; time used = 0.5620810985565186s
epoch 20: {'train_loss': '0.58204'}; time used = 0.5561730861663818s
epoch 25: {'train_loss': '0.45635'}; time used = 0.5555391311645508s
epoch 30: {'train_loss': '0.37809'}; time used = 0.6044232845306396s
epoch 35: {'train_loss': '0.33073'}; time used = 0.5619032382965088s
epoch 40: {'train_loss': '0.27488'}; time used = 0.49724411964416504s
epoch 45: {'train_loss': '0.24600'}; time used = 0.5031514167785645s
epoch 50: {'train_loss': '0.22583'}; time used = 0.4456517696380615s
epoch 55: {'train_loss': '0.55584'}; time used = 0.4655327796936035s
epoch 60: {'train_loss': '0.40553'}; time used = 0.5111894607543945s
epoch 65: {'train_loss': '0.34123'}; time used = 0.5073010921478271s
epoch 70: {'train_loss': '0.25650'}; time used = 0.5379786491394043s
epoch 75: {'train_loss': '0.22388'}; time used = 0.5054526329040527s
epoch 80: {'train_loss': '0.19194'}; time used = 0.5113856792449951s
epoch 85: {'train_loss': '0.18223'}; time used = 0.6355302333831787s
epoch 90: {'train_loss': '0.16106'}; time used = 0.465451717376709s
epoch 95: {'train_loss': '0.15382'}; time used = 0.49259305000305176s
epoch 100: {'train_loss': '0.14922'}; time used = 0.5506856441497803s
epoch 105: {'train_loss': '0.13990'}; time used = 0.5274732112884521s
epoch 110: {'train_loss': '0.13413'}; time used = 0.5548038482666016s
epoch 115: {'train_loss': '0.13101'}; time used = 0.596196174621582s
epoch 120: {'train_loss': '0.12501'}; time used = 0.4828653335571289s
epoch 125: {'train_loss': '0.12634'}; time used = 0.5313231945037842s
epoch 130: {'train_loss': '0.11955'}; time used = 0.5003666877746582s
epoch 135: {'train_loss': '0.11821'}; time used = 0.5332014560699463s
epoch 140: {'train_loss': '0.11480'}; time used = 0.5124416351318359s
epoch 145: {'train_loss': '0.11474'}; time used = 0.5138683319091797s
epoch 150: {'train_loss': '0.11196'}; time used = 0.5010154247283936s
epoch 155: {'train_loss': '0.10852'}; time used = 0.4685847759246826s
epoch 160: {'train_loss': '0.10574'}; time used = 0.5159947872161865s
epoch 165: {'train_loss': '0.10799'}; time used = 0.5623650550842285s
epoch 170: {'train_loss': '0.10429'}; time used = 0.5551350116729736s
epoch 175: {'train_loss': '0.10291'}; time used = 0.6077139377593994s
epoch 180: {'train_loss': '0.10107'}; time used = 0.5092663764953613s
epoch 185: {'train_loss': '0.10097'}; time used = 0.6078050136566162s
epoch 190: {'train_loss': '0.09856'}; time used = 0.5334341526031494s
epoch 195: {'train_loss': '0.09779'}; time used = 0.5263912677764893s
epoch 200: {'train_loss': '0.09633'}; time used = 0.5712368488311768s
epoch 205: {'train_loss': '0.09369'}; time used = 0.5088777542114258s
epoch 210: {'train_loss': '0.09706'}; time used = 0.5720605850219727s
epoch 215: {'train_loss': '0.09692'}; time used = 0.6283676624298096s
epoch 220: {'train_loss': '0.10250'}; time used = 0.6626021862030029s
epoch 225: {'train_loss': '0.10370'}; time used = 0.5650150775909424s
epoch 230: {'train_loss': '0.09793'}; time used = 0.5606787204742432s
epoch 235: {'train_loss': '0.09477'}; time used = 0.7166233062744141s
epoch 240: {'train_loss': '0.09205'}; time used = 1.5862312316894531s
epoch 245: {'train_loss': '0.08723'}; time used = 0.7431418895721436s
epoch 250: {'train_loss': '0.08632'}; time used = 0.8724076747894287s
epoch 255: {'train_loss': '0.08816'}; time used = 0.6647219657897949s
epoch 260: {'train_loss': '0.08651'}; time used = 0.719900369644165s
epoch 265: {'train_loss': '0.08266'}; time used = 0.6840159893035889s
epoch 270: {'train_loss': '0.08945'}; time used = 0.47726988792419434s
epoch 275: {'train_loss': '0.08172'}; time used = 0.6063787937164307s
epoch 280: {'train_loss': '0.08202'}; time used = 0.6918127536773682s
epoch 285: {'train_loss': '0.08149'}; time used = 0.494586706161499s
epoch 290: {'train_loss': '0.08134'}; time used = 0.6008760929107666s
epoch 295: {'train_loss': '0.08497'}; time used = 0.6397812366485596s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.68502068519592.
Training classifier using 20.00% nodes...
{'micro': 0.7609598523304107, 'macro': 0.7415003522295377, 'samples': 0.7609598523304107, 'weighted': 0.7584473617781738}
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 220499.99it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.016395092010498047 seconds.
Run epoch 1
Epoch 1 ends in 0.015378236770629883 seconds.
5416 sentences created
mode 1: time used = 0.030758142471313477
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '1.37225'}; time used = 0.14740872383117676s
epoch 10: {'train_loss': '1.18434'}; time used = 0.09159636497497559s
epoch 15: {'train_loss': '0.98366'}; time used = 0.0919351577758789s
epoch 20: {'train_loss': '0.80899'}; time used = 0.1021268367767334s
epoch 25: {'train_loss': '0.69145'}; time used = 0.09581685066223145s
epoch 30: {'train_loss': '0.60702'}; time used = 0.10425066947937012s
epoch 35: {'train_loss': '0.56975'}; time used = 0.09302997589111328s
epoch 40: {'train_loss': '0.53877'}; time used = 0.1018686294555664s
epoch 45: {'train_loss': '0.52621'}; time used = 0.09270238876342773s
epoch 50: {'train_loss': '0.47521'}; time used = 0.09600615501403809s
epoch 55: {'train_loss': '0.44075'}; time used = 0.09192824363708496s
epoch 60: {'train_loss': '0.40689'}; time used = 0.09032630920410156s
epoch 65: {'train_loss': '0.39565'}; time used = 0.10386872291564941s
epoch 70: {'train_loss': '0.38053'}; time used = 0.12110137939453125s
epoch 75: {'train_loss': '0.37583'}; time used = 0.09239530563354492s
epoch 80: {'train_loss': '0.35924'}; time used = 0.09882211685180664s
epoch 85: {'train_loss': '0.36470'}; time used = 0.09544730186462402s
epoch 90: {'train_loss': '0.34721'}; time used = 0.0964045524597168s
epoch 95: {'train_loss': '0.38647'}; time used = 0.11448287963867188s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 5.1677024364471436.
Training classifier using 20.00% nodes...
{'micro': 0.7245039224734656, 'macro': 0.6813014912832863, 'samples': 0.7245039224734656, 'weighted': 0.7183209711295594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 185720.07it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.021468162536621094 seconds.
Run epoch 1
Epoch 1 ends in 0.018537282943725586 seconds.
5416 sentences created
mode 1: time used = 0.0359339714050293
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '1.37986'}; time used = 0.11545634269714355s
epoch 10: {'train_loss': '1.36133'}; time used = 0.09642601013183594s
epoch 15: {'train_loss': '1.31704'}; time used = 0.10694360733032227s
epoch 20: {'train_loss': '1.23316'}; time used = 0.09433531761169434s
epoch 25: {'train_loss': '1.14707'}; time used = 0.09842395782470703s
epoch 30: {'train_loss': '1.04120'}; time used = 0.0952918529510498s
epoch 35: {'train_loss': '0.93593'}; time used = 0.09379816055297852s
epoch 40: {'train_loss': '0.83432'}; time used = 0.1646745204925537s
epoch 45: {'train_loss': '0.73726'}; time used = 0.09430432319641113s
epoch 50: {'train_loss': '0.65775'}; time used = 0.09302449226379395s
epoch 55: {'train_loss': '0.59399'}; time used = 0.09075331687927246s
epoch 60: {'train_loss': '0.54824'}; time used = 0.09328818321228027s
epoch 65: {'train_loss': '0.49875'}; time used = 0.09128451347351074s
epoch 70: {'train_loss': '0.46266'}; time used = 0.10905647277832031s
epoch 75: {'train_loss': '0.42886'}; time used = 0.09577751159667969s
epoch 80: {'train_loss': '0.39891'}; time used = 0.09423112869262695s
epoch 85: {'train_loss': '0.37381'}; time used = 0.09578561782836914s
epoch 90: {'train_loss': '0.35348'}; time used = 0.09365582466125488s
epoch 95: {'train_loss': '0.33883'}; time used = 0.09797906875610352s
epoch 100: {'train_loss': '0.32029'}; time used = 0.09444093704223633s
epoch 105: {'train_loss': '0.30992'}; time used = 0.09052872657775879s
epoch 110: {'train_loss': '0.30086'}; time used = 0.0923166275024414s
epoch 115: {'train_loss': '0.28892'}; time used = 0.09172558784484863s
epoch 120: {'train_loss': '0.27779'}; time used = 0.10001540184020996s
epoch 125: {'train_loss': '0.27023'}; time used = 0.08767271041870117s
epoch 130: {'train_loss': '0.25909'}; time used = 0.08803033828735352s
epoch 135: {'train_loss': '0.25243'}; time used = 0.09600257873535156s
epoch 140: {'train_loss': '0.24640'}; time used = 0.09306979179382324s
epoch 145: {'train_loss': '0.24129'}; time used = 0.10066604614257812s
epoch 150: {'train_loss': '0.23273'}; time used = 0.08938097953796387s
epoch 155: {'train_loss': '0.22888'}; time used = 0.09093785285949707s
epoch 160: {'train_loss': '0.22112'}; time used = 0.09200429916381836s
epoch 165: {'train_loss': '0.21703'}; time used = 0.0927431583404541s
epoch 170: {'train_loss': '0.21176'}; time used = 0.10091805458068848s
epoch 175: {'train_loss': '0.20780'}; time used = 0.08973813056945801s
epoch 180: {'train_loss': '0.20907'}; time used = 0.0893397331237793s
epoch 185: {'train_loss': '0.20811'}; time used = 0.08920788764953613s
epoch 190: {'train_loss': '0.19952'}; time used = 0.09820866584777832s
epoch 195: {'train_loss': '0.19825'}; time used = 0.11612534523010254s
epoch 200: {'train_loss': '0.19519'}; time used = 0.09907889366149902s
epoch 205: {'train_loss': '0.19618'}; time used = 0.16057229042053223s
epoch 210: {'train_loss': '0.19318'}; time used = 0.09930634498596191s
epoch 215: {'train_loss': '0.18793'}; time used = 0.10017228126525879s
epoch 220: {'train_loss': '0.18547'}; time used = 0.08814430236816406s
epoch 225: {'train_loss': '0.18175'}; time used = 0.09166550636291504s
epoch 230: {'train_loss': '0.18018'}; time used = 0.10225987434387207s
epoch 235: {'train_loss': '0.17867'}; time used = 0.10281682014465332s
epoch 240: {'train_loss': '0.17473'}; time used = 0.10274410247802734s
epoch 245: {'train_loss': '0.17961'}; time used = 0.0986626148223877s
epoch 250: {'train_loss': '0.17216'}; time used = 0.09651994705200195s
epoch 255: {'train_loss': '0.17295'}; time used = 0.09345507621765137s
epoch 260: {'train_loss': '0.17515'}; time used = 0.09349489212036133s
epoch 265: {'train_loss': '0.17191'}; time used = 0.10073280334472656s
epoch 270: {'train_loss': '0.16474'}; time used = 0.09069514274597168s
epoch 275: {'train_loss': '0.17087'}; time used = 0.09467816352844238s
epoch 280: {'train_loss': '0.16301'}; time used = 0.09567928314208984s
epoch 285: {'train_loss': '0.16086'}; time used = 0.08919811248779297s
epoch 290: {'train_loss': '0.16118'}; time used = 0.10394740104675293s
epoch 295: {'train_loss': '0.16137'}; time used = 0.09426259994506836s
epoch 300: {'train_loss': '0.15813'}; time used = 0.09350848197937012s
epoch 305: {'train_loss': '0.15713'}; time used = 0.09243965148925781s
epoch 310: {'train_loss': '0.15530'}; time used = 0.09482502937316895s
epoch 315: {'train_loss': '0.15780'}; time used = 0.10470032691955566s
epoch 320: {'train_loss': '0.15284'}; time used = 0.09274911880493164s
epoch 325: {'train_loss': '0.15257'}; time used = 0.09387803077697754s
epoch 330: {'train_loss': '0.14813'}; time used = 0.09313559532165527s
epoch 335: {'train_loss': '0.15210'}; time used = 0.09327268600463867s
epoch 340: {'train_loss': '0.15314'}; time used = 0.09300422668457031s
epoch 345: {'train_loss': '0.14892'}; time used = 0.1036977767944336s
epoch 350: {'train_loss': '0.14957'}; time used = 0.14828753471374512s
epoch 355: {'train_loss': '0.14998'}; time used = 0.10115218162536621s
epoch 360: {'train_loss': '0.14341'}; time used = 0.09268379211425781s
epoch 365: {'train_loss': '0.14406'}; time used = 0.09684491157531738s
epoch 370: {'train_loss': '0.14352'}; time used = 0.09557819366455078s
epoch 375: {'train_loss': '0.14148'}; time used = 0.09338235855102539s
epoch 380: {'train_loss': '0.14207'}; time used = 0.09405136108398438s
epoch 385: {'train_loss': '0.14064'}; time used = 0.09373807907104492s
epoch 390: {'train_loss': '0.14314'}; time used = 0.100311279296875s
epoch 395: {'train_loss': '0.14049'}; time used = 0.11489558219909668s
epoch 400: {'train_loss': '0.13883'}; time used = 0.08189272880554199s
epoch 405: {'train_loss': '0.14173'}; time used = 0.08856034278869629s
epoch 410: {'train_loss': '0.13767'}; time used = 0.09382772445678711s
epoch 415: {'train_loss': '0.13703'}; time used = 0.09357333183288574s
epoch 420: {'train_loss': '0.13312'}; time used = 0.09221410751342773s
epoch 425: {'train_loss': '0.13259'}; time used = 0.09819531440734863s
epoch 430: {'train_loss': '0.13328'}; time used = 0.09168243408203125s
epoch 435: {'train_loss': '0.13085'}; time used = 0.09500575065612793s
epoch 440: {'train_loss': '0.13532'}; time used = 0.09349513053894043s
epoch 445: {'train_loss': '0.13412'}; time used = 0.08597707748413086s
epoch 450: {'train_loss': '0.13186'}; time used = 0.0857691764831543s
epoch 455: {'train_loss': '0.13607'}; time used = 0.10323405265808105s
epoch 460: {'train_loss': '0.12780'}; time used = 0.08792996406555176s
epoch 465: {'train_loss': '0.13191'}; time used = 0.09208440780639648s
epoch 470: {'train_loss': '0.13242'}; time used = 0.09424209594726562s
epoch 475: {'train_loss': '0.13053'}; time used = 0.09333324432373047s
epoch 480: {'train_loss': '0.13159'}; time used = 0.08836054801940918s
epoch 485: {'train_loss': '0.12958'}; time used = 0.10167551040649414s

epoch 490: {'train_loss': '0.12638'}; time used = 0.09195446968078613s
epoch 495: {'train_loss': '0.12968'}; time used = 0.09093165397644043s
epoch 500: {'train_loss': '0.12759'}; time used = 0.09622454643249512s
Finished training. Time used = 12.657179832458496.
Training classifier using 20.00% nodes...
{'micro': 0.7489616982002769, 'macro': 0.7289655763508137, 'samples': 0.7489616982002769, 'weighted': 0.7480467780851452}
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 199150.93it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.0466914176940918 seconds.
Run epoch 1
Epoch 1 ends in 0.0220339298248291 seconds.
5416 sentences created
mode 1: time used = 0.03456377983093262
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '1.31317'}; time used = 0.11579132080078125s
epoch 10: {'train_loss': '1.05071'}; time used = 0.11225318908691406s
epoch 15: {'train_loss': '0.80815'}; time used = 0.2461247444152832s
epoch 20: {'train_loss': '0.70312'}; time used = 0.3971703052520752s
epoch 25: {'train_loss': '0.54934'}; time used = 0.25145435333251953s
epoch 30: {'train_loss': '0.45002'}; time used = 0.26056838035583496s
epoch 35: {'train_loss': '0.53413'}; time used = 0.1302180290222168s
epoch 40: {'train_loss': '0.45006'}; time used = 0.13456273078918457s
epoch 45: {'train_loss': '0.38272'}; time used = 0.10236191749572754s
epoch 50: {'train_loss': '0.32025'}; time used = 0.10122251510620117s
epoch 55: {'train_loss': '0.28506'}; time used = 0.12849068641662598s
epoch 60: {'train_loss': '0.26145'}; time used = 0.0972442626953125s
epoch 65: {'train_loss': '0.23965'}; time used = 0.09431982040405273s
epoch 70: {'train_loss': '0.21989'}; time used = 0.11326980590820312s
epoch 75: {'train_loss': '0.25078'}; time used = 0.10417747497558594s
epoch 80: {'train_loss': '0.21916'}; time used = 0.12734246253967285s
epoch 85: {'train_loss': '0.19476'}; time used = 0.09996724128723145s
epoch 90: {'train_loss': '0.20071'}; time used = 0.09972214698791504s
epoch 95: {'train_loss': '0.21119'}; time used = 0.09483504295349121s
epoch 100: {'train_loss': '0.21776'}; time used = 0.09695124626159668s
epoch 105: {'train_loss': '0.21111'}; time used = 0.09805846214294434s
epoch 110: {'train_loss': '0.27269'}; time used = 0.13534331321716309s
epoch 115: {'train_loss': '0.22038'}; time used = 0.10204076766967773s
epoch 120: {'train_loss': '0.20180'}; time used = 0.09448695182800293s
epoch 125: {'train_loss': '0.19038'}; time used = 0.09157609939575195s
epoch 130: {'train_loss': '0.16530'}; time used = 0.09930610656738281s
epoch 135: {'train_loss': '0.16036'}; time used = 0.19506621360778809s
epoch 140: {'train_loss': '0.14756'}; time used = 0.1084904670715332s
epoch 145: {'train_loss': '0.14615'}; time used = 0.09453248977661133s
epoch 150: {'train_loss': '0.13846'}; time used = 0.15291810035705566s
epoch 155: {'train_loss': '0.13679'}; time used = 0.24029278755187988s
epoch 160: {'train_loss': '0.13037'}; time used = 0.0928962230682373s
epoch 165: {'train_loss': '0.13199'}; time used = 0.09235954284667969s
epoch 170: {'train_loss': '0.12716'}; time used = 0.09365439414978027s
epoch 175: {'train_loss': '0.12987'}; time used = 0.11735248565673828s
epoch 180: {'train_loss': '0.12648'}; time used = 0.1467118263244629s
epoch 185: {'train_loss': '0.15139'}; time used = 0.08812379837036133s
epoch 190: {'train_loss': '0.25334'}; time used = 0.09313011169433594s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.410388469696045.
Training classifier using 20.00% nodes...
{'micro': 0.7365020766035996, 'macro': 0.7115673972663915, 'samples': 0.7365020766035995, 'weighted': 0.7328940363490317}
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 231134.39it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.014708995819091797 seconds.
Run epoch 1
Epoch 1 ends in 0.014159440994262695 seconds.
5416 sentences created
mode 1: time used = 0.02919936180114746
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '1.38376'}; time used = 0.10495615005493164s
epoch 10: {'train_loss': '1.35649'}; time used = 0.09176445007324219s
epoch 15: {'train_loss': '1.22679'}; time used = 0.1602494716644287s
epoch 20: {'train_loss': '1.16913'}; time used = 0.08623075485229492s
epoch 25: {'train_loss': '1.14767'}; time used = 0.09358453750610352s
epoch 30: {'train_loss': '1.11875'}; time used = 0.09310245513916016s
epoch 35: {'train_loss': '1.07845'}; time used = 0.09769630432128906s
epoch 40: {'train_loss': '1.07715'}; time used = 0.09856700897216797s
epoch 45: {'train_loss': '1.04904'}; time used = 0.09013032913208008s
epoch 50: {'train_loss': '1.00764'}; time used = 0.08592915534973145s
epoch 55: {'train_loss': '0.95260'}; time used = 0.08730459213256836s
epoch 60: {'train_loss': '0.90624'}; time used = 0.08729386329650879s
epoch 65: {'train_loss': '0.84781'}; time used = 0.0855093002319336s
epoch 70: {'train_loss': '0.81600'}; time used = 0.09766030311584473s
epoch 75: {'train_loss': '0.79935'}; time used = 0.0914297103881836s
epoch 80: {'train_loss': '0.84173'}; time used = 0.08770751953125s
epoch 85: {'train_loss': '0.75880'}; time used = 0.07980537414550781s
epoch 90: {'train_loss': '0.74033'}; time used = 0.08010387420654297s
epoch 95: {'train_loss': '0.77154'}; time used = 0.08199000358581543s
epoch 100: {'train_loss': '0.74592'}; time used = 0.0952157974243164s
epoch 105: {'train_loss': '0.69847'}; time used = 0.08671808242797852s
epoch 110: {'train_loss': '0.67303'}; time used = 0.08068466186523438s
epoch 115: {'train_loss': '0.64388'}; time used = 0.08363032341003418s
epoch 120: {'train_loss': '0.72011'}; time used = 0.09958744049072266s
epoch 125: {'train_loss': '0.64653'}; time used = 0.09064459800720215s
epoch 130: {'train_loss': '0.63245'}; time used = 0.08683228492736816s
epoch 135: {'train_loss': '0.62678'}; time used = 0.09872841835021973s
epoch 140: {'train_loss': '0.60322'}; time used = 0.09224152565002441s
epoch 145: {'train_loss': '0.58831'}; time used = 0.09239745140075684s
epoch 150: {'train_loss': '0.62014'}; time used = 0.09187102317810059s
epoch 155: {'train_loss': '0.70345'}; time used = 0.09166812896728516s
epoch 160: {'train_loss': '0.65762'}; time used = 0.0961916446685791s
epoch 165: {'train_loss': '0.60111'}; time used = 0.08528327941894531s
epoch 170: {'train_loss': '0.58052'}; time used = 0.09322452545166016s
epoch 175: {'train_loss': '0.55579'}; time used = 0.12496232986450195s
epoch 180: {'train_loss': '0.54628'}; time used = 0.12163090705871582s
epoch 185: {'train_loss': '0.77976'}; time used = 0.09944367408752441s
epoch 190: {'train_loss': '0.87192'}; time used = 0.09104204177856445s
epoch 195: {'train_loss': '0.77509'}; time used = 0.08853888511657715s
epoch 200: {'train_loss': '0.70653'}; time used = 0.08588528633117676s
epoch 205: {'train_loss': '0.65094'}; time used = 0.09170246124267578s
epoch 210: {'train_loss': '0.62406'}; time used = 0.0844278335571289s
epoch 215: {'train_loss': '0.58467'}; time used = 0.09475517272949219s
epoch 220: {'train_loss': '0.57234'}; time used = 0.09177875518798828s
epoch 225: {'train_loss': '0.55966'}; time used = 0.08950304985046387s
epoch 230: {'train_loss': '0.53763'}; time used = 0.0915822982788086s
epoch 235: {'train_loss': '0.53024'}; time used = 0.09238719940185547s
epoch 240: {'train_loss': '0.54230'}; time used = 0.0956575870513916s
epoch 245: {'train_loss': '0.52387'}; time used = 0.09721875190734863s
epoch 250: {'train_loss': '0.57341'}; time used = 0.09323477745056152s
epoch 255: {'train_loss': '0.54389'}; time used = 0.09299135208129883s
epoch 260: {'train_loss': '0.56481'}; time used = 0.09240579605102539s
epoch 265: {'train_loss': '0.52386'}; time used = 0.09305810928344727s
epoch 270: {'train_loss': '0.50690'}; time used = 0.0924386978149414s
epoch 275: {'train_loss': '0.49536'}; time used = 0.0979621410369873s
epoch 280: {'train_loss': '0.48968'}; time used = 0.09938931465148926s
epoch 285: {'train_loss': '0.48057'}; time used = 0.09299421310424805s
epoch 290: {'train_loss': '0.48182'}; time used = 0.09269976615905762s
epoch 295: {'train_loss': '0.48460'}; time used = 0.09359455108642578s
epoch 300: {'train_loss': '0.53596'}; time used = 0.0937347412109375s
epoch 305: {'train_loss': '0.67542'}; time used = 0.09330868721008301s
epoch 310: {'train_loss': '0.71050'}; time used = 0.10382413864135742s
epoch 315: {'train_loss': '0.65750'}; time used = 0.09004592895507812s
epoch 320: {'train_loss': '0.61000'}; time used = 0.0928196907043457s
epoch 325: {'train_loss': '0.56599'}; time used = 0.08887910842895508s
epoch 330: {'train_loss': '0.54606'}; time used = 0.09281086921691895s
epoch 335: {'train_loss': '0.52408'}; time used = 0.08777379989624023s
epoch 340: {'train_loss': '0.50963'}; time used = 0.09546160697937012s
epoch 345: {'train_loss': '0.49299'}; time used = 0.1299588680267334s
epoch 350: {'train_loss': '0.48402'}; time used = 0.09126853942871094s
epoch 355: {'train_loss': '0.47463'}; time used = 0.08925414085388184s
epoch 360: {'train_loss': '0.46675'}; time used = 0.08926939964294434s
epoch 365: {'train_loss': '0.46217'}; time used = 0.08621358871459961s
epoch 370: {'train_loss': '0.46961'}; time used = 0.08222246170043945s
epoch 375: {'train_loss': '0.66386'}; time used = 0.07737135887145996s
epoch 380: {'train_loss': '0.91063'}; time used = 0.08078980445861816s
epoch 385: {'train_loss': '0.88636'}; time used = 0.0889427661895752s
epoch 390: {'train_loss': '0.80715'}; time used = 0.09319233894348145s
epoch 395: {'train_loss': '0.75009'}; time used = 0.09602689743041992s
epoch 400: {'train_loss': '0.68556'}; time used = 0.0971062183380127s
epoch 405: {'train_loss': '0.63821'}; time used = 0.09420084953308105s
epoch 410: {'train_loss': '0.61322'}; time used = 0.0932919979095459s
epoch 415: {'train_loss': '0.58983'}; time used = 0.09365105628967285s
epoch 420: {'train_loss': '0.57703'}; time used = 0.09341859817504883s
epoch 425: {'train_loss': '0.57107'}; time used = 0.10706448554992676s
epoch 430: {'train_loss': '0.55777'}; time used = 0.09942460060119629s
epoch 435: {'train_loss': '0.53461'}; time used = 0.09291958808898926s
epoch 440: {'train_loss': '0.53169'}; time used = 0.09322500228881836s
epoch 445: {'train_loss': '0.54645'}; time used = 0.09390974044799805s
epoch 450: {'train_loss': '1.19796'}; time used = 0.09711170196533203s
epoch 455: {'train_loss': '0.83930'}; time used = 0.08768296241760254s
epoch 460: {'train_loss': '0.74402'}; time used = 0.08363461494445801s
epoch 465: {'train_loss': '0.66129'}; time used = 0.08636283874511719s
epoch 470: {'train_loss': '0.62329'}; time used = 0.08700919151306152s
epoch 475: {'train_loss': '0.58563'}; time used = 0.08513426780700684s
epoch 480: {'train_loss': '0.55758'}; time used = 0.09037399291992188s
epoch 485: {'train_loss': '0.54177'}; time used = 0.1046440601348877s
epoch 490: {'train_loss': '0.52257'}; time used = 0.09200549125671387s

epoch 495: {'train_loss': '0.51125'}; time used = 0.09527778625488281s
epoch 500: {'train_loss': '0.50601'}; time used = 0.09347271919250488s
Finished training. Time used = 11.980706214904785.
Training classifier using 20.00% nodes...
{'micro': 0.630826026765113, 'macro': 0.5973823996519462, 'samples': 0.630826026765113, 'weighted': 0.6185790224737825}
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 226852.72it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.014977693557739258 seconds.
Run epoch 1
Epoch 1 ends in 0.01426243782043457 seconds.
5416 sentences created
mode 1: time used = 0.029937744140625
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '1.38185'}; time used = 0.1350867748260498s
epoch 10: {'train_loss': '1.39020'}; time used = 0.10696625709533691s
epoch 15: {'train_loss': '1.37738'}; time used = 0.11421370506286621s
epoch 20: {'train_loss': '1.35608'}; time used = 0.10302233695983887s
epoch 25: {'train_loss': '1.34721'}; time used = 0.11246657371520996s
epoch 30: {'train_loss': '1.33785'}; time used = 0.10841727256774902s
epoch 35: {'train_loss': '1.26499'}; time used = 0.13045787811279297s
epoch 40: {'train_loss': '1.23388'}; time used = 0.1054224967956543s
epoch 45: {'train_loss': '1.17182'}; time used = 0.1596822738647461s
epoch 50: {'train_loss': '1.12150'}; time used = 0.09976434707641602s
epoch 55: {'train_loss': '1.12287'}; time used = 0.09142684936523438s
epoch 60: {'train_loss': '1.09722'}; time used = 0.09956693649291992s
epoch 65: {'train_loss': '1.07971'}; time used = 0.09668254852294922s
epoch 70: {'train_loss': '1.13729'}; time used = 0.08912301063537598s
epoch 75: {'train_loss': '1.11710'}; time used = 0.09644150733947754s
epoch 80: {'train_loss': '1.07789'}; time used = 0.08951044082641602s
epoch 85: {'train_loss': '1.07881'}; time used = 0.09867143630981445s
epoch 90: {'train_loss': '1.06665'}; time used = 0.09093332290649414s
epoch 95: {'train_loss': '1.05266'}; time used = 0.09293508529663086s
epoch 100: {'train_loss': '1.04760'}; time used = 0.10099649429321289s
epoch 105: {'train_loss': '1.04199'}; time used = 0.11442375183105469s
epoch 110: {'train_loss': '1.03933'}; time used = 0.09419536590576172s
epoch 115: {'train_loss': '1.03323'}; time used = 0.08825564384460449s
epoch 120: {'train_loss': '1.03893'}; time used = 0.09716153144836426s
epoch 125: {'train_loss': '1.13310'}; time used = 0.10717988014221191s
epoch 130: {'train_loss': '1.24036'}; time used = 0.09546136856079102s
epoch 135: {'train_loss': '1.17731'}; time used = 0.08856534957885742s
epoch 140: {'train_loss': '1.07429'}; time used = 0.09302020072937012s
epoch 145: {'train_loss': '1.05685'}; time used = 0.09444189071655273s
epoch 150: {'train_loss': '1.07025'}; time used = 0.09263491630554199s
epoch 155: {'train_loss': '1.07756'}; time used = 0.10254740715026855s
epoch 160: {'train_loss': '1.07235'}; time used = 0.10760712623596191s
epoch 165: {'train_loss': '1.06633'}; time used = 0.0905003547668457s
epoch 170: {'train_loss': '1.04796'}; time used = 0.09355664253234863s
epoch 175: {'train_loss': '1.04543'}; time used = 0.08965492248535156s
epoch 180: {'train_loss': '1.04582'}; time used = 0.10675692558288574s
epoch 185: {'train_loss': '1.03400'}; time used = 0.09056735038757324s
epoch 190: {'train_loss': '1.03151'}; time used = 0.10580706596374512s
epoch 195: {'train_loss': '1.02762'}; time used = 0.09328222274780273s
epoch 200: {'train_loss': '1.02567'}; time used = 0.0918726921081543s
epoch 205: {'train_loss': '1.02298'}; time used = 0.13993573188781738s
epoch 210: {'train_loss': '1.02321'}; time used = 0.0945284366607666s
epoch 215: {'train_loss': '1.01833'}; time used = 0.0930776596069336s
epoch 220: {'train_loss': '1.01928'}; time used = 0.0947117805480957s
epoch 225: {'train_loss': '1.03232'}; time used = 0.09313344955444336s
epoch 230: {'train_loss': '1.03401'}; time used = 0.09333086013793945s
epoch 235: {'train_loss': '1.03050'}; time used = 0.09302783012390137s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.96328854560852.
Training classifier using 20.00% nodes...
{'micro': 0.4310106137517305, 'macro': 0.21324529095792544, 'samples': 0.4310106137517305, 'weighted': 0.3104021172309209}
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 161234.65it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.02078866958618164 seconds.
Run epoch 1
Epoch 1 ends in 0.020227670669555664 seconds.
5416 sentences created
mode 1: time used = 0.04248523712158203
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '1.38307'}; time used = 0.1230008602142334s
epoch 10: {'train_loss': '1.37107'}; time used = 0.09524893760681152s
epoch 15: {'train_loss': '1.33033'}; time used = 0.08498096466064453s
epoch 20: {'train_loss': '1.24488'}; time used = 0.10484123229980469s
epoch 25: {'train_loss': '1.16334'}; time used = 0.15573477745056152s
epoch 30: {'train_loss': '1.05866'}; time used = 0.10203433036804199s
epoch 35: {'train_loss': '0.97242'}; time used = 0.09461116790771484s
epoch 40: {'train_loss': '0.88084'}; time used = 0.09402060508728027s
epoch 45: {'train_loss': '0.81212'}; time used = 0.0898745059967041s
epoch 50: {'train_loss': '0.74806'}; time used = 0.09086775779724121s
epoch 55: {'train_loss': '0.69048'}; time used = 0.10079169273376465s
epoch 60: {'train_loss': '0.63672'}; time used = 0.09244513511657715s
epoch 65: {'train_loss': '0.58671'}; time used = 0.09320187568664551s
epoch 70: {'train_loss': '0.55142'}; time used = 0.08460402488708496s
epoch 75: {'train_loss': '0.51437'}; time used = 0.08047747611999512s
epoch 80: {'train_loss': '0.47875'}; time used = 0.0820302963256836s
epoch 85: {'train_loss': '0.44622'}; time used = 0.09648275375366211s
epoch 90: {'train_loss': '0.43071'}; time used = 0.08924484252929688s
epoch 95: {'train_loss': '0.41105'}; time used = 0.09328174591064453s
epoch 100: {'train_loss': '0.38622'}; time used = 0.09829401969909668s
epoch 105: {'train_loss': '0.36332'}; time used = 0.0946199893951416s
epoch 110: {'train_loss': '0.34989'}; time used = 0.10213232040405273s
epoch 115: {'train_loss': '0.34411'}; time used = 0.08283019065856934s
epoch 120: {'train_loss': '0.32882'}; time used = 0.08606123924255371s
epoch 125: {'train_loss': '0.32496'}; time used = 0.08836603164672852s
epoch 130: {'train_loss': '0.31445'}; time used = 0.09582281112670898s
epoch 135: {'train_loss': '0.30589'}; time used = 0.09488463401794434s
epoch 140: {'train_loss': '0.29108'}; time used = 0.10111451148986816s
epoch 145: {'train_loss': '0.28518'}; time used = 0.1011972427368164s
epoch 150: {'train_loss': '0.27981'}; time used = 0.0946660041809082s
epoch 155: {'train_loss': '0.27383'}; time used = 0.09430527687072754s
epoch 160: {'train_loss': '0.26695'}; time used = 0.0960390567779541s
epoch 165: {'train_loss': '0.26027'}; time used = 0.09543228149414062s
epoch 170: {'train_loss': '0.27372'}; time used = 0.10559582710266113s
epoch 175: {'train_loss': '0.26957'}; time used = 0.10828852653503418s
epoch 180: {'train_loss': '0.26605'}; time used = 0.09332704544067383s
epoch 185: {'train_loss': '0.24393'}; time used = 0.10584449768066406s
epoch 190: {'train_loss': '0.24025'}; time used = 0.13250184059143066s
epoch 195: {'train_loss': '0.23999'}; time used = 0.09499502182006836s
epoch 200: {'train_loss': '0.23210'}; time used = 0.09439373016357422s
epoch 205: {'train_loss': '0.22880'}; time used = 0.10024809837341309s
epoch 210: {'train_loss': '0.22940'}; time used = 0.08308839797973633s
epoch 215: {'train_loss': '0.22580'}; time used = 0.08829998970031738s
epoch 220: {'train_loss': '0.21878'}; time used = 0.0873420238494873s
epoch 225: {'train_loss': '0.22079'}; time used = 0.08758330345153809s
epoch 230: {'train_loss': '0.22350'}; time used = 0.09044528007507324s
epoch 235: {'train_loss': '0.21735'}; time used = 0.09635519981384277s
epoch 240: {'train_loss': '0.21425'}; time used = 0.09358382225036621s
epoch 245: {'train_loss': '0.20858'}; time used = 0.09073209762573242s
epoch 250: {'train_loss': '0.20977'}; time used = 0.09653663635253906s
epoch 255: {'train_loss': '0.20653'}; time used = 0.09188985824584961s
epoch 260: {'train_loss': '0.20552'}; time used = 0.08635783195495605s
epoch 265: {'train_loss': '0.20379'}; time used = 0.09480834007263184s
epoch 270: {'train_loss': '0.20257'}; time used = 0.09291911125183105s
epoch 275: {'train_loss': '0.19568'}; time used = 0.08836102485656738s
epoch 280: {'train_loss': '0.19877'}; time used = 0.08988428115844727s
epoch 285: {'train_loss': '0.19964'}; time used = 0.09167718887329102s
epoch 290: {'train_loss': '0.19432'}; time used = 0.08916640281677246s
epoch 295: {'train_loss': '0.25338'}; time used = 0.09690117835998535s
epoch 300: {'train_loss': '0.24814'}; time used = 0.08447647094726562s
epoch 305: {'train_loss': '0.46088'}; time used = 0.09147453308105469s
epoch 310: {'train_loss': '0.33554'}; time used = 0.10009384155273438s
epoch 315: {'train_loss': '0.30202'}; time used = 0.09334254264831543s
epoch 320: {'train_loss': '0.27965'}; time used = 0.09402203559875488s
epoch 325: {'train_loss': '0.25932'}; time used = 0.10019278526306152s
epoch 330: {'train_loss': '0.23768'}; time used = 0.1079251766204834s
epoch 335: {'train_loss': '0.22287'}; time used = 0.09019708633422852s
epoch 340: {'train_loss': '0.21133'}; time used = 0.09337306022644043s
epoch 345: {'train_loss': '0.20437'}; time used = 0.09373760223388672s
epoch 350: {'train_loss': '0.20213'}; time used = 0.10802888870239258s
epoch 355: {'train_loss': '0.19643'}; time used = 0.10175657272338867s
epoch 360: {'train_loss': '0.19345'}; time used = 0.13152194023132324s
epoch 365: {'train_loss': '0.18918'}; time used = 0.08719873428344727s
epoch 370: {'train_loss': '0.18701'}; time used = 0.08601236343383789s
epoch 375: {'train_loss': '0.18570'}; time used = 0.08559274673461914s
epoch 380: {'train_loss': '0.18427'}; time used = 0.08544039726257324s
epoch 385: {'train_loss': '0.18497'}; time used = 0.10187888145446777s
epoch 390: {'train_loss': '0.18162'}; time used = 0.09010148048400879s
epoch 395: {'train_loss': '0.18202'}; time used = 0.08562517166137695s
epoch 400: {'train_loss': '0.17991'}; time used = 0.09292721748352051s
epoch 405: {'train_loss': '0.18053'}; time used = 0.09353184700012207s
epoch 410: {'train_loss': '0.17380'}; time used = 0.09391474723815918s
epoch 415: {'train_loss': '0.17870'}; time used = 0.10458254814147949s
epoch 420: {'train_loss': '0.18005'}; time used = 0.09438323974609375s
epoch 425: {'train_loss': '0.17238'}; time used = 0.09571313858032227s
epoch 430: {'train_loss': '0.17259'}; time used = 0.09550166130065918s
epoch 435: {'train_loss': '0.17423'}; time used = 0.0953056812286377s
epoch 440: {'train_loss': '0.17175'}; time used = 0.09199237823486328s
epoch 445: {'train_loss': '0.17010'}; time used = 0.10136294364929199s
epoch 450: {'train_loss': '0.17075'}; time used = 0.09412860870361328s
epoch 455: {'train_loss': '0.17244'}; time used = 0.09345531463623047s
epoch 460: {'train_loss': '0.16965'}; time used = 0.09367752075195312s
epoch 465: {'train_loss': '0.16395'}; time used = 0.0943450927734375s
epoch 470: {'train_loss': '0.16951'}; time used = 0.0940089225769043s
epoch 475: {'train_loss': '0.16513'}; time used = 0.09336614608764648s
epoch 480: {'train_loss': '0.16246'}; time used = 0.09981393814086914s
epoch 485: {'train_loss': '0.16698'}; time used = 0.09633493423461914s

epoch 490: {'train_loss': '0.16804'}; time used = 0.0957643985748291s
epoch 495: {'train_loss': '0.16589'}; time used = 0.09184861183166504s
epoch 500: {'train_loss': '0.16278'}; time used = 0.09942102432250977s
Finished training. Time used = 12.821240663528442.
Training classifier using 20.00% nodes...
{'micro': 0.7508075680664514, 'macro': 0.7249774212969073, 'samples': 0.7508075680664513, 'weighted': 0.7474171967123441}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 220068.50it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.016415119171142578 seconds.
Run epoch 1
Epoch 1 ends in 0.014455795288085938 seconds.
5416 sentences created
mode 1: time used = 0.03047633171081543
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '1.38558'}; time used = 0.09652256965637207s
epoch 10: {'train_loss': '1.63171'}; time used = 0.1115419864654541s
epoch 15: {'train_loss': '1.38221'}; time used = 0.09143590927124023s
epoch 20: {'train_loss': '1.34965'}; time used = 0.0911858081817627s
epoch 25: {'train_loss': '1.25450'}; time used = 0.2822558879852295s
epoch 30: {'train_loss': '1.15675'}; time used = 0.12563180923461914s
epoch 35: {'train_loss': '1.13364'}; time used = 0.09108233451843262s
epoch 40: {'train_loss': '1.08598'}; time used = 0.10190010070800781s
epoch 45: {'train_loss': '1.04331'}; time used = 0.10348010063171387s
epoch 50: {'train_loss': '1.04243'}; time used = 0.0964212417602539s
epoch 55: {'train_loss': '1.01531'}; time used = 0.09263277053833008s
epoch 60: {'train_loss': '0.99360'}; time used = 0.08786797523498535s
epoch 65: {'train_loss': '0.95745'}; time used = 0.0855867862701416s
epoch 70: {'train_loss': '0.91023'}; time used = 0.11731195449829102s
epoch 75: {'train_loss': '0.91678'}; time used = 0.09453129768371582s
epoch 80: {'train_loss': '1.04441'}; time used = 0.0958256721496582s
epoch 85: {'train_loss': '0.96333'}; time used = 0.09006524085998535s
epoch 90: {'train_loss': '0.92103'}; time used = 0.08878087997436523s
epoch 95: {'train_loss': '0.87825'}; time used = 0.09019970893859863s
epoch 100: {'train_loss': '0.84866'}; time used = 0.09640741348266602s
epoch 105: {'train_loss': '0.83638'}; time used = 0.09369754791259766s
epoch 110: {'train_loss': '0.82040'}; time used = 0.08564257621765137s
epoch 115: {'train_loss': '0.80640'}; time used = 0.08725833892822266s
epoch 120: {'train_loss': '0.83194'}; time used = 0.09672427177429199s
epoch 125: {'train_loss': '0.83467'}; time used = 0.0966188907623291s
epoch 130: {'train_loss': '0.78193'}; time used = 0.0932912826538086s
epoch 135: {'train_loss': '0.82388'}; time used = 0.13358545303344727s
epoch 140: {'train_loss': '0.74892'}; time used = 0.08683657646179199s
epoch 145: {'train_loss': '0.70553'}; time used = 0.18793988227844238s
epoch 150: {'train_loss': '0.66321'}; time used = 0.13452482223510742s
epoch 155: {'train_loss': '0.65609'}; time used = 0.09578895568847656s
epoch 160: {'train_loss': '0.67353'}; time used = 0.10091948509216309s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 6.3614490032196045.
Training classifier using 20.00% nodes...
{'micro': 0.5357637286571296, 'macro': 0.4305631699413871, 'samples': 0.5357637286571296, 'weighted': 0.4622346363914308}
  0%|          | 0/5416 [00:00<?, ?it/s]100%|██████████| 5416/5416 [00:00<00:00, 223043.88it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'linear', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = linear
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.015511751174926758 seconds.
Run epoch 1
Epoch 1 ends in 0.014890193939208984 seconds.
5416 sentences created
mode 1: time used = 0.03029155731201172
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '1.38685'}; time used = 0.09942150115966797s
epoch 10: {'train_loss': '1.39225'}; time used = 0.11507606506347656s
epoch 15: {'train_loss': '1.38532'}; time used = 0.09949803352355957s
epoch 20: {'train_loss': '1.36057'}; time used = 0.09759378433227539s
epoch 25: {'train_loss': '1.24309'}; time used = 0.09752130508422852s
epoch 30: {'train_loss': '1.16649'}; time used = 0.09623456001281738s
epoch 35: {'train_loss': '1.13512'}; time used = 0.1248924732208252s
epoch 40: {'train_loss': '1.11527'}; time used = 0.09481287002563477s
epoch 45: {'train_loss': '1.07573'}; time used = 0.10145688056945801s
epoch 50: {'train_loss': '1.06613'}; time used = 0.09334683418273926s
epoch 55: {'train_loss': '1.04661'}; time used = 0.0941915512084961s
epoch 60: {'train_loss': '1.11704'}; time used = 0.09322214126586914s
epoch 65: {'train_loss': '1.17473'}; time used = 0.09294557571411133s
epoch 70: {'train_loss': '1.07861'}; time used = 0.09416913986206055s
epoch 75: {'train_loss': '1.06287'}; time used = 0.0979757308959961s
epoch 80: {'train_loss': '1.05084'}; time used = 0.09762263298034668s
epoch 85: {'train_loss': '1.03843'}; time used = 0.09391570091247559s
epoch 90: {'train_loss': '1.02375'}; time used = 0.09344315528869629s
epoch 95: {'train_loss': '1.01614'}; time used = 0.09369945526123047s
epoch 100: {'train_loss': '1.02257'}; time used = 0.09422802925109863s
epoch 105: {'train_loss': '1.01423'}; time used = 0.10135698318481445s
epoch 110: {'train_loss': '1.15477'}; time used = 0.09674715995788574s
epoch 115: {'train_loss': '1.26526'}; time used = 0.09729766845703125s
epoch 120: {'train_loss': '1.13305'}; time used = 0.09499073028564453s
epoch 125: {'train_loss': '1.12730'}; time used = 0.09905600547790527s
epoch 130: {'train_loss': '1.07096'}; time used = 0.10656571388244629s
epoch 135: {'train_loss': '1.05156'}; time used = 0.09810447692871094s
epoch 140: {'train_loss': '1.04351'}; time used = 0.09571313858032227s
epoch 145: {'train_loss': '1.03353'}; time used = 0.08929920196533203s
epoch 150: {'train_loss': '1.02291'}; time used = 0.08292913436889648s
epoch 155: {'train_loss': '1.01495'}; time used = 0.09343934059143066s
epoch 160: {'train_loss': '1.00673'}; time used = 0.09998083114624023s
epoch 165: {'train_loss': '1.09561'}; time used = 0.0951542854309082s
epoch 170: {'train_loss': '1.03304'}; time used = 0.11881160736083984s
epoch 175: {'train_loss': '1.01996'}; time used = 0.0948631763458252s
epoch 180: {'train_loss': '1.01860'}; time used = 0.09562277793884277s
epoch 185: {'train_loss': '1.00997'}; time used = 0.10230350494384766s
epoch 190: {'train_loss': '1.00106'}; time used = 0.12203097343444824s
epoch 195: {'train_loss': '1.09460'}; time used = 0.11663675308227539s
epoch 200: {'train_loss': '1.03153'}; time used = 0.13556909561157227s
epoch 205: {'train_loss': '1.04064'}; time used = 0.1889667510986328s
epoch 210: {'train_loss': '1.18479'}; time used = 0.09253454208374023s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 7.323145389556885.
Training classifier using 20.00% nodes...
{'micro': 0.3913244116289802, 'macro': 0.1674745810238268, 'samples': 0.3913244116289802, 'weighted': 0.26945800856370755}
