actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '6.41292'}; time used = 0.026140689849853516s
epoch 10: {'train_loss': '6.32878'}; time used = 0.021629810333251953s
epoch 15: {'train_loss': '6.16862'}; time used = 0.02207016944885254s
epoch 20: {'train_loss': '5.97722'}; time used = 0.02181077003479004s
epoch 25: {'train_loss': '6.04750'}; time used = 0.021702289581298828s
epoch 30: {'train_loss': '5.96511'}; time used = 0.022170305252075195s
epoch 35: {'train_loss': '5.82590'}; time used = 0.021975994110107422s
epoch 40: {'train_loss': '5.63698'}; time used = 0.022233963012695312s
epoch 45: {'train_loss': '5.53123'}; time used = 0.021318435668945312s
epoch 50: {'train_loss': '5.44339'}; time used = 0.02221846580505371s
epoch 55: {'train_loss': '5.26437'}; time used = 0.022195100784301758s
epoch 60: {'train_loss': '5.20667'}; time used = 0.02236628532409668s
epoch 65: {'train_loss': '5.12553'}; time used = 0.02258443832397461s
epoch 70: {'train_loss': '5.02510'}; time used = 0.022378921508789062s
epoch 75: {'train_loss': '4.89522'}; time used = 0.02235889434814453s
epoch 80: {'train_loss': '4.92565'}; time used = 0.02221822738647461s
epoch 85: {'train_loss': '4.77256'}; time used = 0.029519319534301758s
epoch 90: {'train_loss': '4.74197'}; time used = 0.022618770599365234s
epoch 95: {'train_loss': '4.64861'}; time used = 0.022069931030273438s
epoch 100: {'train_loss': '4.56097'}; time used = 0.02678060531616211s
epoch 105: {'train_loss': '4.53692'}; time used = 0.022843599319458008s
epoch 110: {'train_loss': '4.44792'}; time used = 0.021390676498413086s
epoch 115: {'train_loss': '4.41941'}; time used = 0.02231907844543457s
epoch 120: {'train_loss': '4.38917'}; time used = 0.02243661880493164s
epoch 125: {'train_loss': '4.27180'}; time used = 0.0224301815032959s
epoch 130: {'train_loss': '4.15518'}; time used = 0.0224764347076416s
epoch 135: {'train_loss': '4.20996'}; time used = 0.023175477981567383s
epoch 140: {'train_loss': '4.11664'}; time used = 0.022385597229003906s
epoch 145: {'train_loss': '4.03713'}; time used = 0.022128820419311523s
epoch 150: {'train_loss': '3.96283'}; time used = 0.022228717803955078s
epoch 155: {'train_loss': '3.84671'}; time used = 0.022521018981933594s
epoch 160: {'train_loss': '3.90853'}; time used = 0.030803203582763672s
epoch 165: {'train_loss': '3.81573'}; time used = 0.022949934005737305s
epoch 170: {'train_loss': '3.85392'}; time used = 0.022771835327148438s
epoch 175: {'train_loss': '3.78300'}; time used = 0.022422075271606445s
epoch 180: {'train_loss': '3.73822'}; time used = 0.02269768714904785s
epoch 185: {'train_loss': '3.67708'}; time used = 0.022715091705322266s
epoch 190: {'train_loss': '3.69467'}; time used = 0.02245187759399414s
epoch 195: {'train_loss': '3.64069'}; time used = 0.022353649139404297s
epoch 200: {'train_loss': '3.57374'}; time used = 0.022655963897705078s
epoch 205: {'train_loss': '3.55726'}; time used = 0.022572755813598633s
epoch 210: {'train_loss': '3.55672'}; time used = 0.02286839485168457s
epoch 215: {'train_loss': '3.56761'}; time used = 0.022354602813720703s
epoch 220: {'train_loss': '3.53321'}; time used = 0.022610187530517578s
epoch 225: {'train_loss': '3.48333'}; time used = 0.02204108238220215s
epoch 230: {'train_loss': '3.41455'}; time used = 0.02240896224975586s
epoch 235: {'train_loss': '3.26345'}; time used = 0.029519081115722656s
epoch 240: {'train_loss': '3.39026'}; time used = 0.02280879020690918s
epoch 245: {'train_loss': '3.39396'}; time used = 0.02310037612915039s
epoch 250: {'train_loss': '3.33486'}; time used = 0.022713661193847656s
epoch 255: {'train_loss': '3.39734'}; time used = 0.022190093994140625s
epoch 260: {'train_loss': '3.32800'}; time used = 0.022965192794799805s
epoch 265: {'train_loss': '3.30721'}; time used = 0.021961450576782227s
epoch 270: {'train_loss': '3.25989'}; time used = 0.02299213409423828s
epoch 275: {'train_loss': '3.23027'}; time used = 0.022470474243164062s
epoch 280: {'train_loss': '3.24702'}; time used = 0.022668838500976562s
epoch 285: {'train_loss': '3.16656'}; time used = 0.02269268035888672s
epoch 290: {'train_loss': '3.15817'}; time used = 0.02260446548461914s
epoch 295: {'train_loss': '3.15963'}; time used = 0.022777795791625977s
epoch 300: {'train_loss': '3.22389'}; time used = 0.021997451782226562s
epoch 305: {'train_loss': '3.10830'}; time used = 0.02297353744506836s
epoch 310: {'train_loss': '3.18850'}; time used = 0.022282838821411133s
epoch 315: {'train_loss': '3.09876'}; time used = 0.028666257858276367s
epoch 320: {'train_loss': '3.12315'}; time used = 0.022475242614746094s
epoch 325: {'train_loss': '3.07729'}; time used = 0.022130966186523438s
epoch 330: {'train_loss': '3.16692'}; time used = 0.0204470157623291s
epoch 335: {'train_loss': '3.12907'}; time used = 0.022075176239013672s
epoch 340: {'train_loss': '3.08344'}; time used = 0.021439790725708008s
epoch 345: {'train_loss': '3.00517'}; time used = 0.019893646240234375s
epoch 350: {'train_loss': '3.07471'}; time used = 0.02166128158569336s
epoch 355: {'train_loss': '2.99866'}; time used = 0.021602869033813477s
epoch 360: {'train_loss': '3.10487'}; time used = 0.02187037467956543s
epoch 365: {'train_loss': '3.00550'}; time used = 0.021541118621826172s
epoch 370: {'train_loss': '3.04839'}; time used = 0.020882129669189453s
epoch 375: {'train_loss': '2.95896'}; time used = 0.020506620407104492s
epoch 380: {'train_loss': '3.00821'}; time used = 0.02196812629699707s
epoch 385: {'train_loss': '3.00348'}; time used = 0.021923065185546875s
epoch 390: {'train_loss': '3.04179'}; time used = 0.02196669578552246s
epoch 395: {'train_loss': '3.02085'}; time used = 0.02178192138671875s
epoch 400: {'train_loss': '2.95133'}; time used = 0.022284746170043945s
epoch 405: {'train_loss': '2.98730'}; time used = 0.02164173126220703s
epoch 410: {'train_loss': '2.91360'}; time used = 0.022205591201782227s
epoch 415: {'train_loss': '3.03888'}; time used = 0.02071523666381836s
epoch 420: {'train_loss': '3.00807'}; time used = 0.018092870712280273s
epoch 425: {'train_loss': '3.01115'}; time used = 0.018034934997558594s
epoch 430: {'train_loss': '2.94034'}; time used = 0.025936603546142578s
epoch 435: {'train_loss': '2.94319'}; time used = 0.02189183235168457s
epoch 440: {'train_loss': '2.94890'}; time used = 0.02267622947692871s
epoch 445: {'train_loss': '2.95670'}; time used = 0.017679691314697266s
epoch 450: {'train_loss': '2.92606'}; time used = 0.018471956253051758s
epoch 455: {'train_loss': '2.92027'}; time used = 0.024289846420288086s
epoch 460: {'train_loss': '2.91579'}; time used = 0.019603490829467773s
epoch 465: {'train_loss': '2.93357'}; time used = 0.019829273223876953s
epoch 470: {'train_loss': '2.83125'}; time used = 0.018171072006225586s
epoch 475: {'train_loss': '2.83933'}; time used = 0.019166946411132812s
epoch 480: {'train_loss': '2.91697'}; time used = 0.019496679306030273s
epoch 485: {'train_loss': '2.94508'}; time used = 0.019257307052612305s
epoch 490: {'train_loss': '2.86966'}; time used = 0.01906442642211914s
epoch 495: {'train_loss': '2.88411'}; time used = 0.01945948600769043s
epoch 500: {'train_loss': '2.82717'}; time used = 0.022082805633544922s
Finished training. Time used = 4.793905019760132.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '5.55832'}; time used = 0.024764537811279297s
epoch 10: {'train_loss': '4.67000'}; time used = 0.022719860076904297s
epoch 15: {'train_loss': '3.98939'}; time used = 0.022311687469482422s
epoch 20: {'train_loss': '3.51294'}; time used = 0.023649930953979492s
epoch 25: {'train_loss': '3.40695'}; time used = 0.022057056427001953s
epoch 30: {'train_loss': '3.27472'}; time used = 0.023701906204223633s
epoch 35: {'train_loss': '3.13836'}; time used = 0.022979736328125s
epoch 40: {'train_loss': '2.95003'}; time used = 0.030950546264648438s
epoch 45: {'train_loss': '2.90008'}; time used = 0.023555278778076172s
epoch 50: {'train_loss': '2.86244'}; time used = 0.02211761474609375s
epoch 55: {'train_loss': '2.74068'}; time used = 0.022282123565673828s
epoch 60: {'train_loss': '2.72135'}; time used = 0.02208256721496582s
epoch 65: {'train_loss': '2.67605'}; time used = 0.022454500198364258s
epoch 70: {'train_loss': '2.62137'}; time used = 0.022082805633544922s
epoch 75: {'train_loss': '2.55152'}; time used = 0.022086381912231445s
epoch 80: {'train_loss': '2.58896'}; time used = 0.021756649017333984s
epoch 85: {'train_loss': '2.48834'}; time used = 0.027138233184814453s
epoch 90: {'train_loss': '2.48176'}; time used = 0.021971702575683594s
epoch 95: {'train_loss': '2.43222'}; time used = 0.02366495132446289s
epoch 100: {'train_loss': '2.38903'}; time used = 0.02339315414428711s
epoch 105: {'train_loss': '2.35745'}; time used = 0.0255887508392334s
epoch 110: {'train_loss': '2.32605'}; time used = 0.022179841995239258s
epoch 115: {'train_loss': '2.30731'}; time used = 0.02808856964111328s
epoch 120: {'train_loss': '2.26679'}; time used = 0.0158536434173584s
epoch 125: {'train_loss': '2.20963'}; time used = 0.016596317291259766s
epoch 130: {'train_loss': '2.13760'}; time used = 0.016194581985473633s
epoch 135: {'train_loss': '2.16330'}; time used = 0.016224145889282227s
epoch 140: {'train_loss': '2.10171'}; time used = 0.017293214797973633s
epoch 145: {'train_loss': '2.05583'}; time used = 0.017989635467529297s
epoch 150: {'train_loss': '1.99546'}; time used = 0.020537853240966797s
epoch 155: {'train_loss': '1.92016'}; time used = 0.0188753604888916s
epoch 160: {'train_loss': '1.95884'}; time used = 0.016499042510986328s
epoch 165: {'train_loss': '1.89644'}; time used = 0.018208742141723633s
epoch 170: {'train_loss': '1.90737'}; time used = 0.018022775650024414s
epoch 175: {'train_loss': '1.86853'}; time used = 0.020841360092163086s
epoch 180: {'train_loss': '1.82652'}; time used = 0.020610332489013672s
epoch 185: {'train_loss': '1.79729'}; time used = 0.01971912384033203s
epoch 190: {'train_loss': '1.78456'}; time used = 0.017189741134643555s
epoch 195: {'train_loss': '1.76250'}; time used = 0.0185701847076416s
epoch 200: {'train_loss': '1.70932'}; time used = 0.01949000358581543s
epoch 205: {'train_loss': '1.69655'}; time used = 0.027035951614379883s
epoch 210: {'train_loss': '1.67549'}; time used = 0.020766258239746094s
epoch 215: {'train_loss': '1.66930'}; time used = 0.020070314407348633s
epoch 220: {'train_loss': '1.64033'}; time used = 0.018286705017089844s
epoch 225: {'train_loss': '1.60272'}; time used = 0.020045042037963867s
epoch 230: {'train_loss': '1.55617'}; time used = 0.0210263729095459s
epoch 235: {'train_loss': '1.49387'}; time used = 0.021487712860107422s
epoch 240: {'train_loss': '1.53545'}; time used = 0.021567106246948242s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 3.5690643787384033.
Training classifier using 20.00% nodes...
{'micro': 0.286571296723581, 'macro': 0.08138532453562543, 'samples': 0.286571296723581, 'weighted': 0.15221843340023927}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '4.78621'}; time used = 0.020913362503051758s
epoch 10: {'train_loss': '3.65921'}; time used = 0.021102428436279297s
epoch 15: {'train_loss': '3.15496'}; time used = 0.01944899559020996s
epoch 20: {'train_loss': '2.91175'}; time used = 0.01879262924194336s
epoch 25: {'train_loss': '2.94691'}; time used = 0.018665075302124023s
epoch 30: {'train_loss': '2.88065'}; time used = 0.01850271224975586s
epoch 35: {'train_loss': '2.76862'}; time used = 0.017507314682006836s
epoch 40: {'train_loss': '2.56965'}; time used = 0.017557859420776367s
epoch 45: {'train_loss': '2.50165'}; time used = 0.015918493270874023s
epoch 50: {'train_loss': '2.42469'}; time used = 0.016891002655029297s
epoch 55: {'train_loss': '2.29246'}; time used = 0.017058372497558594s
epoch 60: {'train_loss': '2.23826'}; time used = 0.01676487922668457s
epoch 65: {'train_loss': '2.16267'}; time used = 0.01748180389404297s
epoch 70: {'train_loss': '2.08250'}; time used = 0.017519712448120117s
epoch 75: {'train_loss': '2.00671'}; time used = 0.016928672790527344s
epoch 80: {'train_loss': '1.99193'}; time used = 0.01749873161315918s
epoch 85: {'train_loss': '1.88620'}; time used = 0.01799750328063965s
epoch 90: {'train_loss': '1.85158'}; time used = 0.026062726974487305s
epoch 95: {'train_loss': '1.79166'}; time used = 0.020949602127075195s
epoch 100: {'train_loss': '1.74020'}; time used = 0.022304296493530273s
epoch 105: {'train_loss': '1.68230'}; time used = 0.022395610809326172s
epoch 110: {'train_loss': '1.65055'}; time used = 0.022954702377319336s
epoch 115: {'train_loss': '1.61266'}; time used = 0.022931337356567383s
epoch 120: {'train_loss': '1.56052'}; time used = 0.022548437118530273s
epoch 125: {'train_loss': '1.51403'}; time used = 0.021888256072998047s
epoch 130: {'train_loss': '1.45020'}; time used = 0.022214651107788086s
epoch 135: {'train_loss': '1.45118'}; time used = 0.022051572799682617s
epoch 140: {'train_loss': '1.39024'}; time used = 0.022446870803833008s
epoch 145: {'train_loss': '1.35809'}; time used = 0.022845029830932617s
epoch 150: {'train_loss': '1.30934'}; time used = 0.0229947566986084s
epoch 155: {'train_loss': '1.25567'}; time used = 0.022352933883666992s
epoch 160: {'train_loss': '1.26745'}; time used = 0.02254939079284668s
epoch 165: {'train_loss': '1.22457'}; time used = 0.023052453994750977s
epoch 170: {'train_loss': '1.21756'}; time used = 0.023003816604614258s
epoch 175: {'train_loss': '1.19527'}; time used = 0.02741074562072754s
epoch 180: {'train_loss': '1.15948'}; time used = 0.021956443786621094s
epoch 185: {'train_loss': '1.14435'}; time used = 0.022330284118652344s
epoch 190: {'train_loss': '1.12457'}; time used = 0.02184319496154785s
epoch 195: {'train_loss': '1.12447'}; time used = 0.022143840789794922s
epoch 200: {'train_loss': '1.07499'}; time used = 0.021968603134155273s
epoch 205: {'train_loss': '1.07661'}; time used = 0.022017717361450195s
epoch 210: {'train_loss': '1.05243'}; time used = 0.022121667861938477s
epoch 215: {'train_loss': '1.04939'}; time used = 0.022393465042114258s
epoch 220: {'train_loss': '1.03459'}; time used = 0.02242445945739746s
epoch 225: {'train_loss': '1.01406'}; time used = 0.022852420806884766s
epoch 230: {'train_loss': '0.99199'}; time used = 0.022430419921875s
epoch 235: {'train_loss': '0.96915'}; time used = 0.022306203842163086s
epoch 240: {'train_loss': '0.97889'}; time used = 0.022701025009155273s
epoch 245: {'train_loss': '0.96716'}; time used = 0.0279998779296875s
epoch 250: {'train_loss': '0.95587'}; time used = 0.032083749771118164s
epoch 255: {'train_loss': '0.95206'}; time used = 0.024874210357666016s
epoch 260: {'train_loss': '0.94656'}; time used = 0.024918556213378906s
epoch 265: {'train_loss': '0.93548'}; time used = 0.02549123764038086s
epoch 270: {'train_loss': '0.92191'}; time used = 0.024439096450805664s
epoch 275: {'train_loss': '0.90968'}; time used = 0.023592233657836914s
epoch 280: {'train_loss': '0.91380'}; time used = 0.024799346923828125s
epoch 285: {'train_loss': '0.89643'}; time used = 0.02357792854309082s
epoch 290: {'train_loss': '0.88537'}; time used = 0.023656129837036133s
epoch 295: {'train_loss': '0.88439'}; time used = 0.022713184356689453s
epoch 300: {'train_loss': '0.87911'}; time used = 0.02343273162841797s
epoch 305: {'train_loss': '0.86676'}; time used = 0.022698402404785156s
epoch 310: {'train_loss': '0.88377'}; time used = 0.02292776107788086s
epoch 315: {'train_loss': '0.86430'}; time used = 0.02662062644958496s
epoch 320: {'train_loss': '0.86498'}; time used = 0.030262231826782227s
epoch 325: {'train_loss': '0.85016'}; time used = 0.024187564849853516s
epoch 330: {'train_loss': '0.85553'}; time used = 0.024587154388427734s
epoch 335: {'train_loss': '0.85236'}; time used = 0.023391008377075195s
epoch 340: {'train_loss': '0.84670'}; time used = 0.023651599884033203s
epoch 345: {'train_loss': '0.83768'}; time used = 0.02303147315979004s
epoch 350: {'train_loss': '0.84242'}; time used = 0.022759675979614258s
epoch 355: {'train_loss': '0.83050'}; time used = 0.023403406143188477s
epoch 360: {'train_loss': '0.83889'}; time used = 0.023270368576049805s
epoch 365: {'train_loss': '0.83520'}; time used = 0.021907329559326172s
epoch 370: {'train_loss': '0.83175'}; time used = 0.0241696834564209s
epoch 375: {'train_loss': '0.82545'}; time used = 0.022058486938476562s
epoch 380: {'train_loss': '0.82621'}; time used = 0.02260446548461914s
epoch 385: {'train_loss': '0.81479'}; time used = 0.022287368774414062s
epoch 390: {'train_loss': '0.81873'}; time used = 0.029824018478393555s
epoch 395: {'train_loss': '0.81776'}; time used = 0.027058839797973633s
epoch 400: {'train_loss': '0.82251'}; time used = 0.024146556854248047s
epoch 405: {'train_loss': '0.80866'}; time used = 0.02491450309753418s
epoch 410: {'train_loss': '0.80826'}; time used = 0.023833513259887695s
epoch 415: {'train_loss': '0.81148'}; time used = 0.023227453231811523s
epoch 420: {'train_loss': '0.80382'}; time used = 0.02375936508178711s
epoch 425: {'train_loss': '0.80196'}; time used = 0.02426314353942871s
epoch 430: {'train_loss': '0.80207'}; time used = 0.022450923919677734s
epoch 435: {'train_loss': '0.80483'}; time used = 0.022974252700805664s
epoch 440: {'train_loss': '0.79657'}; time used = 0.026715517044067383s
epoch 445: {'train_loss': '0.79618'}; time used = 0.02239680290222168s
epoch 450: {'train_loss': '0.79441'}; time used = 0.021960735321044922s
epoch 455: {'train_loss': '0.79331'}; time used = 0.02544999122619629s
epoch 460: {'train_loss': '0.78889'}; time used = 0.0314178466796875s
epoch 465: {'train_loss': '0.79413'}; time used = 0.02292180061340332s
epoch 470: {'train_loss': '0.78652'}; time used = 0.022199630737304688s
epoch 475: {'train_loss': '0.77837'}; time used = 0.022356510162353516s
epoch 480: {'train_loss': '0.78842'}; time used = 0.021660804748535156s
epoch 485: {'train_loss': '0.78811'}; time used = 0.025110721588134766s
epoch 490: {'train_loss': '0.79070'}; time used = 0.022235393524169922s
epoch 495: {'train_loss': '0.77740'}; time used = 0.022161006927490234s
epoch 500: {'train_loss': '0.78961'}; time used = 0.022707223892211914s
Finished training. Time used = 4.914332866668701.
Training classifier using 20.00% nodes...
{'micro': 0.4688509460083064, 'macro': 0.39275850737380974, 'samples': 0.4688509460083064, 'weighted': 0.4401586848934796}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '6.41292'}; time used = 0.04007387161254883s
epoch 10: {'train_loss': '6.32878'}; time used = 0.023158788681030273s
epoch 15: {'train_loss': '6.16862'}; time used = 0.024437904357910156s
epoch 20: {'train_loss': '5.97722'}; time used = 0.027816295623779297s
epoch 25: {'train_loss': '6.04750'}; time used = 0.02066493034362793s
epoch 30: {'train_loss': '5.96511'}; time used = 0.021581172943115234s
epoch 35: {'train_loss': '5.82590'}; time used = 0.03700399398803711s
epoch 40: {'train_loss': '5.63698'}; time used = 0.024562358856201172s
epoch 45: {'train_loss': '5.53123'}; time used = 0.027343273162841797s
epoch 50: {'train_loss': '5.44339'}; time used = 0.02916264533996582s
epoch 55: {'train_loss': '5.26437'}; time used = 0.02311873435974121s
epoch 60: {'train_loss': '5.20667'}; time used = 0.01760101318359375s
epoch 65: {'train_loss': '5.12553'}; time used = 0.02336430549621582s
epoch 70: {'train_loss': '5.02510'}; time used = 0.02676105499267578s
epoch 75: {'train_loss': '4.89522'}; time used = 0.01741814613342285s
epoch 80: {'train_loss': '4.92565'}; time used = 0.02507805824279785s
epoch 85: {'train_loss': '4.77256'}; time used = 0.0179288387298584s
epoch 90: {'train_loss': '4.74197'}; time used = 0.017882823944091797s
epoch 95: {'train_loss': '4.64861'}; time used = 0.017236948013305664s
epoch 100: {'train_loss': '4.56097'}; time used = 0.017765283584594727s
epoch 105: {'train_loss': '4.53692'}; time used = 0.038762569427490234s
epoch 110: {'train_loss': '4.44792'}; time used = 0.01765275001525879s
epoch 115: {'train_loss': '4.41941'}; time used = 0.01815509796142578s
epoch 120: {'train_loss': '4.38917'}; time used = 0.031880855560302734s
epoch 125: {'train_loss': '4.27180'}; time used = 0.017520904541015625s
epoch 130: {'train_loss': '4.15518'}; time used = 0.01773977279663086s
epoch 135: {'train_loss': '4.20996'}; time used = 0.017836570739746094s
epoch 140: {'train_loss': '4.11664'}; time used = 0.017787933349609375s
epoch 145: {'train_loss': '4.03713'}; time used = 0.018575429916381836s
epoch 150: {'train_loss': '3.96283'}; time used = 0.017264366149902344s
epoch 155: {'train_loss': '3.84671'}; time used = 0.02261519432067871s
epoch 160: {'train_loss': '3.90853'}; time used = 0.028832674026489258s
epoch 165: {'train_loss': '3.81573'}; time used = 0.024777650833129883s
epoch 170: {'train_loss': '3.85392'}; time used = 0.019002199172973633s
epoch 175: {'train_loss': '3.78300'}; time used = 0.02018260955810547s
epoch 180: {'train_loss': '3.73822'}; time used = 0.0185849666595459s
epoch 185: {'train_loss': '3.67708'}; time used = 0.0202639102935791s
epoch 190: {'train_loss': '3.69467'}; time used = 0.01948833465576172s
epoch 195: {'train_loss': '3.64069'}; time used = 0.018860578536987305s
epoch 200: {'train_loss': '3.57374'}; time used = 0.018167734146118164s
epoch 205: {'train_loss': '3.55726'}; time used = 0.01793813705444336s
epoch 210: {'train_loss': '3.55672'}; time used = 0.017959117889404297s
epoch 215: {'train_loss': '3.56761'}; time used = 0.01808929443359375s
epoch 220: {'train_loss': '3.53321'}; time used = 0.017225027084350586s
epoch 225: {'train_loss': '3.48333'}; time used = 0.017325878143310547s
epoch 230: {'train_loss': '3.41455'}; time used = 0.017826318740844727s
epoch 235: {'train_loss': '3.26345'}; time used = 0.01763916015625s
epoch 240: {'train_loss': '3.39026'}; time used = 0.017143964767456055s
epoch 245: {'train_loss': '3.39396'}; time used = 0.03182649612426758s
epoch 250: {'train_loss': '3.33486'}; time used = 0.02925395965576172s
epoch 255: {'train_loss': '3.39734'}; time used = 0.01846623420715332s
epoch 260: {'train_loss': '3.32800'}; time used = 0.01918959617614746s
epoch 265: {'train_loss': '3.30721'}; time used = 0.019359827041625977s
epoch 270: {'train_loss': '3.25989'}; time used = 0.0196840763092041s
epoch 275: {'train_loss': '3.23027'}; time used = 0.019766807556152344s
epoch 280: {'train_loss': '3.24702'}; time used = 0.019148588180541992s
epoch 285: {'train_loss': '3.16656'}; time used = 0.0190887451171875s
epoch 290: {'train_loss': '3.15817'}; time used = 0.0194399356842041s
epoch 295: {'train_loss': '3.15963'}; time used = 0.01905536651611328s
epoch 300: {'train_loss': '3.22389'}; time used = 0.019193410873413086s
epoch 305: {'train_loss': '3.10830'}; time used = 0.01905989646911621s
epoch 310: {'train_loss': '3.18850'}; time used = 0.0189363956451416s
epoch 315: {'train_loss': '3.09876'}; time used = 0.020996570587158203s
epoch 320: {'train_loss': '3.12315'}; time used = 0.019018173217773438s
epoch 325: {'train_loss': '3.07729'}; time used = 0.01990342140197754s
epoch 330: {'train_loss': '3.16692'}; time used = 0.04763340950012207s
epoch 335: {'train_loss': '3.12907'}; time used = 0.01932525634765625s
epoch 340: {'train_loss': '3.08344'}; time used = 0.019197940826416016s
epoch 345: {'train_loss': '3.00517'}; time used = 0.019685029983520508s
epoch 350: {'train_loss': '3.07471'}; time used = 0.019246339797973633s
epoch 355: {'train_loss': '2.99866'}; time used = 0.019137144088745117s
epoch 360: {'train_loss': '3.10487'}; time used = 0.019364118576049805s
epoch 365: {'train_loss': '3.00550'}; time used = 0.018051624298095703s
epoch 370: {'train_loss': '3.04839'}; time used = 0.019899845123291016s
epoch 375: {'train_loss': '2.95896'}; time used = 0.022402048110961914s
epoch 380: {'train_loss': '3.00821'}; time used = 0.020887136459350586s
epoch 385: {'train_loss': '3.00348'}; time used = 0.017580032348632812s
epoch 390: {'train_loss': '3.04179'}; time used = 0.017588376998901367s
epoch 395: {'train_loss': '3.02085'}; time used = 0.018163442611694336s
epoch 400: {'train_loss': '2.95133'}; time used = 0.02710580825805664s
epoch 405: {'train_loss': '2.98730'}; time used = 0.0261380672454834s
epoch 410: {'train_loss': '2.91360'}; time used = 0.01889777183532715s
epoch 415: {'train_loss': '3.03888'}; time used = 0.018831968307495117s
epoch 420: {'train_loss': '3.00807'}; time used = 0.01718902587890625s
epoch 425: {'train_loss': '3.01115'}; time used = 0.017436742782592773s
epoch 430: {'train_loss': '2.94034'}; time used = 0.02574920654296875s
epoch 435: {'train_loss': '2.94319'}; time used = 0.018979549407958984s
epoch 440: {'train_loss': '2.94890'}; time used = 0.019959449768066406s
epoch 445: {'train_loss': '2.95670'}; time used = 0.020149946212768555s
epoch 450: {'train_loss': '2.92606'}; time used = 0.02097177505493164s
epoch 455: {'train_loss': '2.92027'}; time used = 0.019941091537475586s
epoch 460: {'train_loss': '2.91579'}; time used = 0.020116329193115234s
epoch 465: {'train_loss': '2.93357'}; time used = 0.020377397537231445s
epoch 470: {'train_loss': '2.83125'}; time used = 0.01972675323486328s
epoch 475: {'train_loss': '2.83933'}; time used = 0.020020723342895508s
epoch 480: {'train_loss': '2.91697'}; time used = 0.02152729034423828s
epoch 485: {'train_loss': '2.94508'}; time used = 0.03909802436828613s
epoch 490: {'train_loss': '2.86966'}; time used = 0.021684885025024414s
epoch 495: {'train_loss': '2.88411'}; time used = 0.02433300018310547s
epoch 500: {'train_loss': '2.82717'}; time used = 0.04692983627319336s
Finished training. Time used = 4.757266044616699.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '4.78621'}; time used = 0.032599687576293945s
epoch 10: {'train_loss': '3.65921'}; time used = 0.028285503387451172s
epoch 15: {'train_loss': '3.15496'}; time used = 0.02967667579650879s
epoch 20: {'train_loss': '2.91175'}; time used = 0.024274587631225586s
epoch 25: {'train_loss': '2.94691'}; time used = 0.02541971206665039s
epoch 30: {'train_loss': '2.88065'}; time used = 0.03887176513671875s
epoch 35: {'train_loss': '2.76862'}; time used = 0.023030996322631836s
epoch 40: {'train_loss': '2.56965'}; time used = 0.026338577270507812s
epoch 45: {'train_loss': '2.50165'}; time used = 0.025198936462402344s
epoch 50: {'train_loss': '2.42469'}; time used = 0.023481130599975586s
epoch 55: {'train_loss': '2.29246'}; time used = 0.023555517196655273s
epoch 60: {'train_loss': '2.23826'}; time used = 0.02780294418334961s
epoch 65: {'train_loss': '2.16267'}; time used = 0.023621082305908203s
epoch 70: {'train_loss': '2.08250'}; time used = 0.022701501846313477s
epoch 75: {'train_loss': '2.00671'}; time used = 0.026502132415771484s
epoch 80: {'train_loss': '1.99193'}; time used = 0.023680925369262695s
epoch 85: {'train_loss': '1.88620'}; time used = 0.02255725860595703s
epoch 90: {'train_loss': '1.85158'}; time used = 0.02657914161682129s
epoch 95: {'train_loss': '1.79166'}; time used = 0.025111675262451172s
epoch 100: {'train_loss': '1.74020'}; time used = 0.03023552894592285s
epoch 105: {'train_loss': '1.68230'}; time used = 0.024897336959838867s
epoch 110: {'train_loss': '1.65055'}; time used = 0.023108959197998047s
epoch 115: {'train_loss': '1.61266'}; time used = 0.023490428924560547s
epoch 120: {'train_loss': '1.56052'}; time used = 0.025366783142089844s
epoch 125: {'train_loss': '1.51403'}; time used = 0.022971391677856445s
epoch 130: {'train_loss': '1.45020'}; time used = 0.02351546287536621s
epoch 135: {'train_loss': '1.45118'}; time used = 0.026125192642211914s
epoch 140: {'train_loss': '1.39024'}; time used = 0.023729562759399414s
epoch 145: {'train_loss': '1.35809'}; time used = 0.02358102798461914s
epoch 150: {'train_loss': '1.30934'}; time used = 0.02292656898498535s
epoch 155: {'train_loss': '1.25567'}; time used = 0.02611064910888672s
epoch 160: {'train_loss': '1.26745'}; time used = 0.023266077041625977s
epoch 165: {'train_loss': '1.22457'}; time used = 0.025759458541870117s
epoch 170: {'train_loss': '1.21756'}; time used = 0.033464908599853516s
epoch 175: {'train_loss': '1.19527'}; time used = 0.023833036422729492s
epoch 180: {'train_loss': '1.15948'}; time used = 0.022892475128173828s
epoch 185: {'train_loss': '1.14435'}; time used = 0.026822805404663086s
epoch 190: {'train_loss': '1.12457'}; time used = 0.02393174171447754s
epoch 195: {'train_loss': '1.12447'}; time used = 0.024616479873657227s
epoch 200: {'train_loss': '1.07499'}; time used = 0.0275423526763916s
epoch 205: {'train_loss': '1.07661'}; time used = 0.02430868148803711s
epoch 210: {'train_loss': '1.05243'}; time used = 0.02355670928955078s
epoch 215: {'train_loss': '1.04939'}; time used = 0.025441646575927734s
epoch 220: {'train_loss': '1.03459'}; time used = 0.027062177658081055s
epoch 225: {'train_loss': '1.01406'}; time used = 0.02324843406677246s
epoch 230: {'train_loss': '0.99199'}; time used = 0.025534391403198242s
epoch 235: {'train_loss': '0.96915'}; time used = 0.02172064781188965s
epoch 240: {'train_loss': '0.97889'}; time used = 0.02956366539001465s
epoch 245: {'train_loss': '0.96716'}; time used = 0.020812273025512695s
epoch 250: {'train_loss': '0.95587'}; time used = 0.023497819900512695s
epoch 255: {'train_loss': '0.95206'}; time used = 0.02317047119140625s
epoch 260: {'train_loss': '0.94656'}; time used = 0.02129077911376953s
epoch 265: {'train_loss': '0.93548'}; time used = 0.024556398391723633s
epoch 270: {'train_loss': '0.92191'}; time used = 0.02182173728942871s
epoch 275: {'train_loss': '0.90968'}; time used = 0.021799564361572266s
epoch 280: {'train_loss': '0.91380'}; time used = 0.02294015884399414s
epoch 285: {'train_loss': '0.89643'}; time used = 0.025493621826171875s
epoch 290: {'train_loss': '0.88537'}; time used = 0.021523237228393555s
epoch 295: {'train_loss': '0.88439'}; time used = 0.022453784942626953s
epoch 300: {'train_loss': '0.87911'}; time used = 0.02916431427001953s
epoch 305: {'train_loss': '0.86676'}; time used = 0.019357919692993164s
epoch 310: {'train_loss': '0.88377'}; time used = 0.019762277603149414s
epoch 315: {'train_loss': '0.86430'}; time used = 0.01934528350830078s
epoch 320: {'train_loss': '0.86498'}; time used = 0.019849777221679688s
epoch 325: {'train_loss': '0.85016'}; time used = 0.019591331481933594s
epoch 330: {'train_loss': '0.85553'}; time used = 0.01625370979309082s
epoch 335: {'train_loss': '0.85236'}; time used = 0.025950193405151367s
epoch 340: {'train_loss': '0.84670'}; time used = 0.02366185188293457s
epoch 345: {'train_loss': '0.83768'}; time used = 0.02183222770690918s
epoch 350: {'train_loss': '0.84242'}; time used = 0.02440333366394043s
epoch 355: {'train_loss': '0.83050'}; time used = 0.022404909133911133s
epoch 360: {'train_loss': '0.83889'}; time used = 0.025647640228271484s
epoch 365: {'train_loss': '0.83520'}; time used = 0.02266836166381836s
epoch 370: {'train_loss': '0.83175'}; time used = 0.025977134704589844s
epoch 375: {'train_loss': '0.82545'}; time used = 0.02266526222229004s
epoch 380: {'train_loss': '0.82621'}; time used = 0.023163557052612305s
epoch 385: {'train_loss': '0.81479'}; time used = 0.025739669799804688s
epoch 390: {'train_loss': '0.81873'}; time used = 0.021784067153930664s
epoch 395: {'train_loss': '0.81776'}; time used = 0.025935888290405273s
epoch 400: {'train_loss': '0.82251'}; time used = 0.022844314575195312s
epoch 405: {'train_loss': '0.80866'}; time used = 0.018797874450683594s
epoch 410: {'train_loss': '0.80826'}; time used = 0.025840044021606445s
epoch 415: {'train_loss': '0.81148'}; time used = 0.02055048942565918s
epoch 420: {'train_loss': '0.80382'}; time used = 0.02892136573791504s
epoch 425: {'train_loss': '0.80196'}; time used = 0.03481936454772949s
epoch 430: {'train_loss': '0.80207'}; time used = 0.03180360794067383s
epoch 435: {'train_loss': '0.80483'}; time used = 0.02193307876586914s
epoch 440: {'train_loss': '0.79657'}; time used = 0.018322467803955078s
epoch 445: {'train_loss': '0.79618'}; time used = 0.02161407470703125s
epoch 450: {'train_loss': '0.79441'}; time used = 0.02276468276977539s
epoch 455: {'train_loss': '0.79331'}; time used = 0.018302440643310547s
epoch 460: {'train_loss': '0.78889'}; time used = 0.02360987663269043s
epoch 465: {'train_loss': '0.79413'}; time used = 0.01899576187133789s
epoch 470: {'train_loss': '0.78652'}; time used = 0.018952369689941406s
epoch 475: {'train_loss': '0.77837'}; time used = 0.020660400390625s
epoch 480: {'train_loss': '0.78842'}; time used = 0.019746780395507812s
epoch 485: {'train_loss': '0.78811'}; time used = 0.018555164337158203s
epoch 490: {'train_loss': '0.79070'}; time used = 0.020529508590698242s
epoch 495: {'train_loss': '0.77740'}; time used = 0.023229598999023438s
epoch 500: {'train_loss': '0.78961'}; time used = 0.020041465759277344s
Finished training. Time used = 5.339345932006836.
Training classifier using 20.00% nodes...
{'micro': 0.4688509460083064, 'macro': 0.39275850737380974, 'samples': 0.4688509460083064, 'weighted': 0.4401586848934796}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '4.20655'}; time used = 0.028757333755493164s
epoch 10: {'train_loss': '3.21208'}; time used = 0.027463674545288086s
epoch 15: {'train_loss': '2.91717'}; time used = 0.030005931854248047s
epoch 20: {'train_loss': '2.73576'}; time used = 0.03238487243652344s
epoch 25: {'train_loss': '2.74997'}; time used = 0.023561954498291016s
epoch 30: {'train_loss': '2.64226'}; time used = 0.024390697479248047s
epoch 35: {'train_loss': '2.50298'}; time used = 0.03217148780822754s
epoch 40: {'train_loss': '2.27733'}; time used = 0.023752450942993164s
epoch 45: {'train_loss': '2.18915'}; time used = 0.04042816162109375s
epoch 50: {'train_loss': '2.08142'}; time used = 0.019142627716064453s
epoch 55: {'train_loss': '1.94612'}; time used = 0.022823810577392578s
epoch 60: {'train_loss': '1.87293'}; time used = 0.01887679100036621s
epoch 65: {'train_loss': '1.78251'}; time used = 0.02092719078063965s
epoch 70: {'train_loss': '1.69717'}; time used = 0.025176286697387695s
epoch 75: {'train_loss': '1.62454'}; time used = 0.02451491355895996s
epoch 80: {'train_loss': '1.58495'}; time used = 0.02431654930114746s
epoch 85: {'train_loss': '1.48744'}; time used = 0.02910470962524414s
epoch 90: {'train_loss': '1.45056'}; time used = 0.024739742279052734s
epoch 95: {'train_loss': '1.39410'}; time used = 0.02483654022216797s
epoch 100: {'train_loss': '1.35000'}; time used = 0.022223949432373047s
epoch 105: {'train_loss': '1.29505'}; time used = 0.028201580047607422s
epoch 110: {'train_loss': '1.27053'}; time used = 0.022867918014526367s
epoch 115: {'train_loss': '1.23450'}; time used = 0.020567893981933594s
epoch 120: {'train_loss': '1.19019'}; time used = 0.019720792770385742s
epoch 125: {'train_loss': '1.16140'}; time used = 0.019417524337768555s
epoch 130: {'train_loss': '1.11255'}; time used = 0.02033829689025879s
epoch 135: {'train_loss': '1.11574'}; time used = 0.022491931915283203s
epoch 140: {'train_loss': '1.06682'}; time used = 0.03281760215759277s
epoch 145: {'train_loss': '1.04727'}; time used = 0.028777122497558594s
epoch 150: {'train_loss': '1.02100'}; time used = 0.024385690689086914s
epoch 155: {'train_loss': '0.98559'}; time used = 0.029644250869750977s
epoch 160: {'train_loss': '0.99123'}; time used = 0.02442622184753418s
epoch 165: {'train_loss': '0.96915'}; time used = 0.02485513687133789s
epoch 170: {'train_loss': '0.96248'}; time used = 0.029399633407592773s
epoch 175: {'train_loss': '0.95256'}; time used = 0.024981260299682617s
epoch 180: {'train_loss': '0.92681'}; time used = 0.02519679069519043s
epoch 185: {'train_loss': '0.92446'}; time used = 0.028642892837524414s
epoch 190: {'train_loss': '0.90783'}; time used = 0.024384498596191406s
epoch 195: {'train_loss': '0.92055'}; time used = 0.027153730392456055s
epoch 200: {'train_loss': '0.87918'}; time used = 0.026537179946899414s
epoch 205: {'train_loss': '0.89104'}; time used = 0.02546072006225586s
epoch 210: {'train_loss': '0.87363'}; time used = 0.034632205963134766s
epoch 215: {'train_loss': '0.87489'}; time used = 0.02939319610595703s
epoch 220: {'train_loss': '0.87047'}; time used = 0.024804115295410156s
epoch 225: {'train_loss': '0.86073'}; time used = 0.02113938331604004s
epoch 230: {'train_loss': '0.84734'}; time used = 0.022540569305419922s
epoch 235: {'train_loss': '0.83740'}; time used = 0.024127483367919922s
epoch 240: {'train_loss': '0.84412'}; time used = 0.03420686721801758s
epoch 245: {'train_loss': '0.83493'}; time used = 0.019129276275634766s
epoch 250: {'train_loss': '0.82977'}; time used = 0.02007269859313965s
epoch 255: {'train_loss': '0.82703'}; time used = 0.022986888885498047s
epoch 260: {'train_loss': '0.83075'}; time used = 0.022435665130615234s
epoch 265: {'train_loss': '0.82796'}; time used = 0.019511938095092773s
epoch 270: {'train_loss': '0.82103'}; time used = 0.021505117416381836s
epoch 275: {'train_loss': '0.81425'}; time used = 0.028551340103149414s
epoch 280: {'train_loss': '0.81454'}; time used = 0.02497100830078125s
epoch 285: {'train_loss': '0.80582'}; time used = 0.029922008514404297s
epoch 290: {'train_loss': '0.80253'}; time used = 0.026944637298583984s
epoch 295: {'train_loss': '0.80292'}; time used = 0.026731252670288086s
epoch 300: {'train_loss': '0.79872'}; time used = 0.0249483585357666s
epoch 305: {'train_loss': '0.79506'}; time used = 0.03565573692321777s
epoch 310: {'train_loss': '0.80680'}; time used = 0.024616718292236328s
epoch 315: {'train_loss': '0.79698'}; time used = 0.028181076049804688s
epoch 320: {'train_loss': '0.80076'}; time used = 0.02680039405822754s
epoch 325: {'train_loss': '0.79069'}; time used = 0.024228334426879883s
epoch 330: {'train_loss': '0.79171'}; time used = 0.02715134620666504s
epoch 335: {'train_loss': '0.79228'}; time used = 0.029402732849121094s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 5.166070461273193.
Training classifier using 20.00% nodes...
{'micro': 0.46746654360867557, 'macro': 0.39869526652148857, 'samples': 0.46746654360867557, 'weighted': 0.44546480925812154}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '6.13401'}; time used = 0.08529925346374512s
epoch 10: {'train_loss': '4.75144'}; time used = 0.020193099975585938s
epoch 15: {'train_loss': '4.37557'}; time used = 0.029495716094970703s
epoch 20: {'train_loss': '4.28536'}; time used = 0.0226590633392334s
epoch 25: {'train_loss': '4.05257'}; time used = 0.023885250091552734s
epoch 30: {'train_loss': '4.11406'}; time used = 0.03360414505004883s
epoch 35: {'train_loss': '3.80123'}; time used = 0.023258209228515625s
epoch 40: {'train_loss': '3.80922'}; time used = 0.023993730545043945s
epoch 45: {'train_loss': '3.71145'}; time used = 0.02611517906188965s
epoch 50: {'train_loss': '3.61578'}; time used = 0.02294611930847168s
epoch 55: {'train_loss': '3.51132'}; time used = 0.03354787826538086s
epoch 60: {'train_loss': '3.46247'}; time used = 0.03237795829772949s
epoch 65: {'train_loss': '3.25142'}; time used = 0.03206920623779297s
epoch 70: {'train_loss': '3.20207'}; time used = 0.031072139739990234s
epoch 75: {'train_loss': '3.19183'}; time used = 0.020757436752319336s
epoch 80: {'train_loss': '3.06683'}; time used = 0.019580364227294922s
epoch 85: {'train_loss': '2.97325'}; time used = 0.02793598175048828s
epoch 90: {'train_loss': '2.84892'}; time used = 0.024013280868530273s
epoch 95: {'train_loss': '2.79399'}; time used = 0.020529508590698242s
epoch 100: {'train_loss': '2.74219'}; time used = 0.024826765060424805s
epoch 105: {'train_loss': '2.66527'}; time used = 0.024515867233276367s
epoch 110: {'train_loss': '2.56124'}; time used = 0.028860092163085938s
epoch 115: {'train_loss': '2.51990'}; time used = 0.0223236083984375s
epoch 120: {'train_loss': '2.37377'}; time used = 0.022053956985473633s
epoch 125: {'train_loss': '2.41553'}; time used = 0.020609617233276367s
epoch 130: {'train_loss': '2.32905'}; time used = 0.021292686462402344s
epoch 135: {'train_loss': '2.28455'}; time used = 0.048712730407714844s
epoch 140: {'train_loss': '2.15704'}; time used = 0.028547048568725586s
epoch 145: {'train_loss': '2.16434'}; time used = 0.03283286094665527s
epoch 150: {'train_loss': '2.11033'}; time used = 0.022233009338378906s
epoch 155: {'train_loss': '2.05200'}; time used = 0.033942222595214844s
epoch 160: {'train_loss': '1.95595'}; time used = 0.03510689735412598s
epoch 165: {'train_loss': '1.94400'}; time used = 0.03041553497314453s
epoch 170: {'train_loss': '1.84527'}; time used = 0.023132801055908203s
epoch 175: {'train_loss': '1.87546'}; time used = 0.02285909652709961s
epoch 180: {'train_loss': '1.85503'}; time used = 0.03695273399353027s
epoch 185: {'train_loss': '1.79658'}; time used = 0.031656503677368164s
epoch 190: {'train_loss': '1.75981'}; time used = 0.02394580841064453s
epoch 195: {'train_loss': '1.72198'}; time used = 0.029065847396850586s
epoch 200: {'train_loss': '1.67641'}; time used = 0.028543949127197266s
epoch 205: {'train_loss': '1.65773'}; time used = 0.03024578094482422s
epoch 210: {'train_loss': '1.60272'}; time used = 0.03317427635192871s
epoch 215: {'train_loss': '1.54841'}; time used = 0.029607772827148438s
epoch 220: {'train_loss': '1.51779'}; time used = 0.034903526306152344s
epoch 225: {'train_loss': '1.51478'}; time used = 0.026564359664916992s
epoch 230: {'train_loss': '1.46589'}; time used = 0.024148225784301758s
epoch 235: {'train_loss': '1.41416'}; time used = 0.020982742309570312s
epoch 240: {'train_loss': '1.38847'}; time used = 0.017393112182617188s
epoch 245: {'train_loss': '1.35898'}; time used = 0.018769264221191406s
epoch 250: {'train_loss': '1.33961'}; time used = 0.03425478935241699s
epoch 255: {'train_loss': '1.33203'}; time used = 0.029432058334350586s
epoch 260: {'train_loss': '1.32367'}; time used = 0.03226590156555176s
epoch 265: {'train_loss': '1.27939'}; time used = 0.03016352653503418s
epoch 270: {'train_loss': '1.25570'}; time used = 0.027490615844726562s
epoch 275: {'train_loss': '1.24544'}; time used = 0.025935888290405273s
epoch 280: {'train_loss': '1.20882'}; time used = 0.03857421875s
epoch 285: {'train_loss': '1.19765'}; time used = 0.04260873794555664s
epoch 290: {'train_loss': '1.16624'}; time used = 0.028003692626953125s
epoch 295: {'train_loss': '1.15813'}; time used = 0.023358583450317383s
epoch 300: {'train_loss': '1.17738'}; time used = 0.022399425506591797s
epoch 305: {'train_loss': '1.13671'}; time used = 0.023189783096313477s
epoch 310: {'train_loss': '1.11340'}; time used = 0.0337064266204834s
epoch 315: {'train_loss': '1.10903'}; time used = 0.03156542778015137s
epoch 320: {'train_loss': '1.11843'}; time used = 0.02349114418029785s
epoch 325: {'train_loss': '1.07703'}; time used = 0.019812345504760742s
epoch 330: {'train_loss': '1.05909'}; time used = 0.020891427993774414s
epoch 335: {'train_loss': '1.04421'}; time used = 0.02002406120300293s
epoch 340: {'train_loss': '1.02421'}; time used = 0.020411968231201172s
epoch 345: {'train_loss': '1.02982'}; time used = 0.03430485725402832s
epoch 350: {'train_loss': '1.01639'}; time used = 0.03365635871887207s
epoch 355: {'train_loss': '1.01235'}; time used = 0.04276299476623535s
epoch 360: {'train_loss': '0.98592'}; time used = 0.018977880477905273s
epoch 365: {'train_loss': '0.98296'}; time used = 0.026835203170776367s
epoch 370: {'train_loss': '0.98585'}; time used = 0.026672840118408203s
epoch 375: {'train_loss': '0.97432'}; time used = 0.025368213653564453s
epoch 380: {'train_loss': '0.97051'}; time used = 0.03105473518371582s
epoch 385: {'train_loss': '0.94834'}; time used = 0.03922748565673828s
epoch 390: {'train_loss': '0.92053'}; time used = 0.02439284324645996s
epoch 395: {'train_loss': '0.94399'}; time used = 0.02704787254333496s
epoch 400: {'train_loss': '0.92661'}; time used = 0.030784130096435547s
epoch 405: {'train_loss': '0.92730'}; time used = 0.02117443084716797s
epoch 410: {'train_loss': '0.92834'}; time used = 0.03115081787109375s
epoch 415: {'train_loss': '0.91535'}; time used = 0.020615100860595703s
epoch 420: {'train_loss': '0.89828'}; time used = 0.02982187271118164s
epoch 425: {'train_loss': '0.90341'}; time used = 0.03482699394226074s
epoch 430: {'train_loss': '0.90626'}; time used = 0.018170595169067383s
epoch 435: {'train_loss': '0.89381'}; time used = 0.016998291015625s
epoch 440: {'train_loss': '0.89209'}; time used = 0.02434515953063965s
epoch 445: {'train_loss': '0.88021'}; time used = 0.02234673500061035s
epoch 450: {'train_loss': '0.87990'}; time used = 0.040532588958740234s
epoch 455: {'train_loss': '0.87735'}; time used = 0.041712284088134766s
epoch 460: {'train_loss': '0.86617'}; time used = 0.03483152389526367s
epoch 465: {'train_loss': '0.86126'}; time used = 0.02591252326965332s
epoch 470: {'train_loss': '0.86775'}; time used = 0.021988630294799805s
epoch 475: {'train_loss': '0.86857'}; time used = 0.026411771774291992s
epoch 480: {'train_loss': '0.84945'}; time used = 0.02127552032470703s
epoch 485: {'train_loss': '0.84008'}; time used = 0.02486443519592285s
epoch 490: {'train_loss': '0.84112'}; time used = 0.03764152526855469s
epoch 495: {'train_loss': '0.83896'}; time used = 0.041918277740478516s
epoch 500: {'train_loss': '0.83762'}; time used = 0.024614572525024414s
Finished training. Time used = 10.886608600616455.
Training classifier using 20.00% nodes...
{'micro': 0.33917858790955235, 'macro': 0.18646871817943045, 'samples': 0.33917858790955235, 'weighted': 0.2610750443902996}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '7.92557'}; time used = 0.06012701988220215s
epoch 10: {'train_loss': '6.42783'}; time used = 0.027211666107177734s
epoch 15: {'train_loss': '6.29153'}; time used = 0.029489517211914062s
epoch 20: {'train_loss': '6.01615'}; time used = 0.023853063583374023s
epoch 25: {'train_loss': '5.99693'}; time used = 0.032599687576293945s
epoch 30: {'train_loss': '5.88872'}; time used = 0.02976822853088379s
epoch 35: {'train_loss': '5.67134'}; time used = 0.05645251274108887s
epoch 40: {'train_loss': '5.72792'}; time used = 0.025360584259033203s
epoch 45: {'train_loss': '5.31443'}; time used = 0.02631235122680664s
epoch 50: {'train_loss': '5.23439'}; time used = 0.021775484085083008s
epoch 55: {'train_loss': '5.37842'}; time used = 0.021691560745239258s
epoch 60: {'train_loss': '5.02775'}; time used = 0.018723249435424805s
epoch 65: {'train_loss': '4.93214'}; time used = 0.041094064712524414s
epoch 70: {'train_loss': '5.11318'}; time used = 0.022472143173217773s
epoch 75: {'train_loss': '4.75716'}; time used = 0.02422189712524414s
epoch 80: {'train_loss': '4.91290'}; time used = 0.0235445499420166s
epoch 85: {'train_loss': '4.57063'}; time used = 0.020583152770996094s
epoch 90: {'train_loss': '4.46576'}; time used = 0.019004344940185547s
epoch 95: {'train_loss': '4.47804'}; time used = 0.02144598960876465s
epoch 100: {'train_loss': '4.38248'}; time used = 0.04097485542297363s
epoch 105: {'train_loss': '4.21329'}; time used = 0.034943580627441406s
epoch 110: {'train_loss': '4.17841'}; time used = 0.02438974380493164s
epoch 115: {'train_loss': '4.06738'}; time used = 0.01985931396484375s
epoch 120: {'train_loss': '4.09585'}; time used = 0.023139476776123047s
epoch 125: {'train_loss': '3.91134'}; time used = 0.025946855545043945s
epoch 130: {'train_loss': '4.01153'}; time used = 0.01819324493408203s
epoch 135: {'train_loss': '3.71261'}; time used = 0.021627187728881836s
epoch 140: {'train_loss': '3.74077'}; time used = 0.02376270294189453s
epoch 145: {'train_loss': '3.69124'}; time used = 0.018962383270263672s
epoch 150: {'train_loss': '3.59575'}; time used = 0.01776599884033203s
epoch 155: {'train_loss': '3.43336'}; time used = 0.034647464752197266s
epoch 160: {'train_loss': '3.33293'}; time used = 0.02151322364807129s
epoch 165: {'train_loss': '3.37216'}; time used = 0.024336576461791992s
epoch 170: {'train_loss': '3.19923'}; time used = 0.020463943481445312s
epoch 175: {'train_loss': '3.27688'}; time used = 0.017246007919311523s
epoch 180: {'train_loss': '3.19802'}; time used = 0.025059223175048828s
epoch 185: {'train_loss': '3.12592'}; time used = 0.022281408309936523s
epoch 190: {'train_loss': '3.07516'}; time used = 0.024660825729370117s
epoch 195: {'train_loss': '2.95585'}; time used = 0.030907869338989258s
epoch 200: {'train_loss': '2.92331'}; time used = 0.02339315414428711s
epoch 205: {'train_loss': '2.86077'}; time used = 0.018732547760009766s
epoch 210: {'train_loss': '2.90571'}; time used = 0.0189054012298584s
epoch 215: {'train_loss': '2.76366'}; time used = 0.03046107292175293s
epoch 220: {'train_loss': '2.65427'}; time used = 0.018658161163330078s
epoch 225: {'train_loss': '2.60378'}; time used = 0.020563840866088867s
epoch 230: {'train_loss': '2.67606'}; time used = 0.025385379791259766s
epoch 235: {'train_loss': '2.56727'}; time used = 0.02170419692993164s
epoch 240: {'train_loss': '2.50120'}; time used = 0.02008795738220215s
epoch 245: {'train_loss': '2.48141'}; time used = 0.031206130981445312s
epoch 250: {'train_loss': '2.44216'}; time used = 0.021697521209716797s
epoch 255: {'train_loss': '2.31811'}; time used = 0.020650625228881836s
epoch 260: {'train_loss': '2.36013'}; time used = 0.033854007720947266s
epoch 265: {'train_loss': '2.26140'}; time used = 0.026754140853881836s
epoch 270: {'train_loss': '2.24037'}; time used = 0.0309293270111084s
epoch 275: {'train_loss': '2.24386'}; time used = 0.024918079376220703s
epoch 280: {'train_loss': '2.20187'}; time used = 0.02358102798461914s
epoch 285: {'train_loss': '2.09529'}; time used = 0.05576467514038086s
epoch 290: {'train_loss': '2.09707'}; time used = 0.025106191635131836s
epoch 295: {'train_loss': '2.06199'}; time used = 0.021204710006713867s
epoch 300: {'train_loss': '2.01111'}; time used = 0.019130229949951172s
epoch 305: {'train_loss': '1.99250'}; time used = 0.02775430679321289s
epoch 310: {'train_loss': '1.98989'}; time used = 0.054892539978027344s
epoch 315: {'train_loss': '1.90807'}; time used = 0.01878190040588379s
epoch 320: {'train_loss': '1.86564'}; time used = 0.019415616989135742s
epoch 325: {'train_loss': '1.82191'}; time used = 0.02617812156677246s
epoch 330: {'train_loss': '1.79836'}; time used = 0.05555367469787598s
epoch 335: {'train_loss': '1.80908'}; time used = 0.03535771369934082s
epoch 340: {'train_loss': '1.72521'}; time used = 0.017232179641723633s
epoch 345: {'train_loss': '1.72707'}; time used = 0.025690317153930664s
epoch 350: {'train_loss': '1.69699'}; time used = 0.018049955368041992s
epoch 355: {'train_loss': '1.67281'}; time used = 0.020664215087890625s
epoch 360: {'train_loss': '1.60582'}; time used = 0.02792835235595703s
epoch 365: {'train_loss': '1.64764'}; time used = 0.025417566299438477s
epoch 370: {'train_loss': '1.62135'}; time used = 0.03363323211669922s
epoch 375: {'train_loss': '1.63632'}; time used = 0.023851394653320312s
epoch 380: {'train_loss': '1.52935'}; time used = 0.018038511276245117s
epoch 385: {'train_loss': '1.54169'}; time used = 0.02627110481262207s
epoch 390: {'train_loss': '1.51100'}; time used = 0.02398061752319336s
epoch 395: {'train_loss': '1.51237'}; time used = 0.0331723690032959s
epoch 400: {'train_loss': '1.44511'}; time used = 0.03433370590209961s
epoch 405: {'train_loss': '1.47883'}; time used = 0.021384239196777344s
epoch 410: {'train_loss': '1.43677'}; time used = 0.019066572189331055s
epoch 415: {'train_loss': '1.42420'}; time used = 0.020341873168945312s
epoch 420: {'train_loss': '1.39677'}; time used = 0.02274155616760254s
epoch 425: {'train_loss': '1.34486'}; time used = 0.026210784912109375s
epoch 430: {'train_loss': '1.36482'}; time used = 0.030905961990356445s
epoch 435: {'train_loss': '1.33347'}; time used = 0.024893522262573242s
epoch 440: {'train_loss': '1.31407'}; time used = 0.018528461456298828s
epoch 445: {'train_loss': '1.31605'}; time used = 0.018056154251098633s
epoch 450: {'train_loss': '1.27439'}; time used = 0.01842808723449707s
epoch 455: {'train_loss': '1.26080'}; time used = 0.020115375518798828s
epoch 460: {'train_loss': '1.24626'}; time used = 0.021492481231689453s
epoch 465: {'train_loss': '1.20551'}; time used = 0.020663976669311523s
epoch 470: {'train_loss': '1.20555'}; time used = 0.017071008682250977s
epoch 475: {'train_loss': '1.24914'}; time used = 0.02183842658996582s
epoch 480: {'train_loss': '1.19363'}; time used = 0.022504329681396484s
epoch 485: {'train_loss': '1.17502'}; time used = 0.023468017578125s
epoch 490: {'train_loss': '1.17001'}; time used = 0.04552268981933594s
epoch 495: {'train_loss': '1.17958'}; time used = 0.01755356788635254s
epoch 500: {'train_loss': '1.14006'}; time used = 0.0210568904876709s
Finished training. Time used = 11.144063949584961.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '7.04271'}; time used = 0.06770563125610352s
epoch 10: {'train_loss': '6.29107'}; time used = 0.02902531623840332s
epoch 15: {'train_loss': '6.16454'}; time used = 0.022217988967895508s
epoch 20: {'train_loss': '5.84661'}; time used = 0.020834922790527344s
epoch 25: {'train_loss': '5.78239'}; time used = 0.02532362937927246s
epoch 30: {'train_loss': '5.64356'}; time used = 0.03263139724731445s
epoch 35: {'train_loss': '5.39794'}; time used = 0.02815079689025879s
epoch 40: {'train_loss': '5.39329'}; time used = 0.030284643173217773s
epoch 45: {'train_loss': '4.94573'}; time used = 0.03539133071899414s
epoch 50: {'train_loss': '4.85837'}; time used = 0.02819514274597168s
epoch 55: {'train_loss': '4.92809'}; time used = 0.03365588188171387s
epoch 60: {'train_loss': '4.56532'}; time used = 0.024905920028686523s
epoch 65: {'train_loss': '4.44824'}; time used = 0.039542436599731445s
epoch 70: {'train_loss': '4.56917'}; time used = 0.023493051528930664s
epoch 75: {'train_loss': '4.22236'}; time used = 0.025435924530029297s
epoch 80: {'train_loss': '4.34831'}; time used = 0.05133700370788574s
epoch 85: {'train_loss': '4.01849'}; time used = 0.02505660057067871s
epoch 90: {'train_loss': '3.85517'}; time used = 0.027086973190307617s
epoch 95: {'train_loss': '3.84936'}; time used = 0.02447652816772461s
epoch 100: {'train_loss': '3.74830'}; time used = 0.0313112735748291s
epoch 105: {'train_loss': '3.56054'}; time used = 0.027571439743041992s
epoch 110: {'train_loss': '3.49734'}; time used = 0.03381991386413574s
epoch 115: {'train_loss': '3.38562'}; time used = 0.026688337326049805s
epoch 120: {'train_loss': '3.37323'}; time used = 0.028950929641723633s
epoch 125: {'train_loss': '3.21314'}; time used = 0.039638519287109375s
epoch 130: {'train_loss': '3.26699'}; time used = 0.024955034255981445s
epoch 135: {'train_loss': '2.99079'}; time used = 0.03499770164489746s
epoch 140: {'train_loss': '2.99531'}; time used = 0.024807453155517578s
epoch 145: {'train_loss': '2.95445'}; time used = 0.03302621841430664s
epoch 150: {'train_loss': '2.84636'}; time used = 0.02424025535583496s
epoch 155: {'train_loss': '2.68709'}; time used = 0.022220134735107422s
epoch 160: {'train_loss': '2.61053'}; time used = 0.025395631790161133s
epoch 165: {'train_loss': '2.62779'}; time used = 0.0169675350189209s
epoch 170: {'train_loss': '2.45499'}; time used = 0.018149852752685547s
epoch 175: {'train_loss': '2.49763'}; time used = 0.019728899002075195s
epoch 180: {'train_loss': '2.42936'}; time used = 0.026270151138305664s
epoch 185: {'train_loss': '2.37482'}; time used = 0.023805618286132812s
epoch 190: {'train_loss': '2.29242'}; time used = 0.03916311264038086s
epoch 195: {'train_loss': '2.20591'}; time used = 0.02224898338317871s
epoch 200: {'train_loss': '2.16769'}; time used = 0.07243037223815918s
epoch 205: {'train_loss': '2.11341'}; time used = 0.0213930606842041s
epoch 210: {'train_loss': '2.12785'}; time used = 0.027534008026123047s
epoch 215: {'train_loss': '2.01752'}; time used = 0.02350640296936035s
epoch 220: {'train_loss': '1.93599'}; time used = 0.0290834903717041s
epoch 225: {'train_loss': '1.87987'}; time used = 0.030977487564086914s
epoch 230: {'train_loss': '1.91476'}; time used = 0.0401461124420166s
epoch 235: {'train_loss': '1.82868'}; time used = 0.06324362754821777s
epoch 240: {'train_loss': '1.78467'}; time used = 0.04613780975341797s
epoch 245: {'train_loss': '1.75993'}; time used = 0.032872915267944336s
epoch 250: {'train_loss': '1.71136'}; time used = 0.02346014976501465s
epoch 255: {'train_loss': '1.65151'}; time used = 0.03182554244995117s
epoch 260: {'train_loss': '1.66141'}; time used = 0.029122114181518555s
epoch 265: {'train_loss': '1.57256'}; time used = 0.03092479705810547s
epoch 270: {'train_loss': '1.56716'}; time used = 0.03973126411437988s
epoch 275: {'train_loss': '1.55948'}; time used = 0.04180717468261719s
epoch 280: {'train_loss': '1.51814'}; time used = 0.035299062728881836s
epoch 285: {'train_loss': '1.46300'}; time used = 0.021265029907226562s
epoch 290: {'train_loss': '1.46005'}; time used = 0.018331050872802734s
epoch 295: {'train_loss': '1.43300'}; time used = 0.019045591354370117s
epoch 300: {'train_loss': '1.39093'}; time used = 0.029215335845947266s
epoch 305: {'train_loss': '1.37250'}; time used = 0.02132391929626465s
epoch 310: {'train_loss': '1.37756'}; time used = 0.020909547805786133s
epoch 315: {'train_loss': '1.32151'}; time used = 0.046712636947631836s
epoch 320: {'train_loss': '1.30594'}; time used = 0.03657341003417969s
epoch 325: {'train_loss': '1.26039'}; time used = 0.032379150390625s
epoch 330: {'train_loss': '1.25911'}; time used = 0.030051708221435547s
epoch 335: {'train_loss': '1.24624'}; time used = 0.022638797760009766s
epoch 340: {'train_loss': '1.19590'}; time used = 0.018940448760986328s
epoch 345: {'train_loss': '1.20479'}; time used = 0.0177915096282959s
epoch 350: {'train_loss': '1.18885'}; time used = 0.019939899444580078s
epoch 355: {'train_loss': '1.16231'}; time used = 0.019420146942138672s
epoch 360: {'train_loss': '1.12674'}; time used = 0.022559165954589844s
epoch 365: {'train_loss': '1.14681'}; time used = 0.022516965866088867s
epoch 370: {'train_loss': '1.13728'}; time used = 0.0234677791595459s
epoch 375: {'train_loss': '1.14230'}; time used = 0.030873775482177734s
epoch 380: {'train_loss': '1.07917'}; time used = 0.02952861785888672s
epoch 385: {'train_loss': '1.09278'}; time used = 0.01883244514465332s
epoch 390: {'train_loss': '1.08203'}; time used = 0.02532672882080078s
epoch 395: {'train_loss': '1.07134'}; time used = 0.027545452117919922s
epoch 400: {'train_loss': '1.04358'}; time used = 0.020569324493408203s
epoch 405: {'train_loss': '1.05274'}; time used = 0.020647287368774414s
epoch 410: {'train_loss': '1.02576'}; time used = 0.019713640213012695s
epoch 415: {'train_loss': '1.02975'}; time used = 0.022495508193969727s
epoch 420: {'train_loss': '1.01194'}; time used = 0.016777992248535156s
epoch 425: {'train_loss': '0.98212'}; time used = 0.019315481185913086s
epoch 430: {'train_loss': '0.99086'}; time used = 0.023862123489379883s
epoch 435: {'train_loss': '0.97955'}; time used = 0.027530908584594727s
epoch 440: {'train_loss': '0.96322'}; time used = 0.05375242233276367s
epoch 445: {'train_loss': '0.96395'}; time used = 0.018888235092163086s
epoch 450: {'train_loss': '0.95173'}; time used = 0.024832487106323242s
epoch 455: {'train_loss': '0.94221'}; time used = 0.021231651306152344s
epoch 460: {'train_loss': '0.93352'}; time used = 0.01822042465209961s
epoch 465: {'train_loss': '0.91739'}; time used = 0.01738452911376953s
epoch 470: {'train_loss': '0.91606'}; time used = 0.02225470542907715s
epoch 475: {'train_loss': '0.95108'}; time used = 0.0180513858795166s
epoch 480: {'train_loss': '0.91167'}; time used = 0.02198934555053711s
epoch 485: {'train_loss': '0.89638'}; time used = 0.01847076416015625s
epoch 490: {'train_loss': '0.90369'}; time used = 0.019695043563842773s
epoch 495: {'train_loss': '0.90536'}; time used = 0.02300858497619629s
epoch 500: {'train_loss': '0.89142'}; time used = 0.018053054809570312s
Finished training. Time used = 11.270692825317383.
Training classifier using 20.00% nodes...
{'micro': 0.33317951084448544, 'macro': 0.12948526380777411, 'samples': 0.33317951084448544, 'weighted': 0.20620844263766175}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '7.04271'}; time used = 0.11663007736206055s
epoch 10: {'train_loss': '6.29107'}; time used = 0.04187154769897461s
epoch 15: {'train_loss': '6.16454'}; time used = 0.029592514038085938s
epoch 20: {'train_loss': '5.84661'}; time used = 0.03648519515991211s
epoch 25: {'train_loss': '5.78239'}; time used = 0.024134159088134766s
epoch 30: {'train_loss': '5.64356'}; time used = 0.023993492126464844s
epoch 35: {'train_loss': '5.39794'}; time used = 0.023436546325683594s
epoch 40: {'train_loss': '5.39329'}; time used = 0.02573227882385254s
epoch 45: {'train_loss': '4.94573'}; time used = 0.022754669189453125s
epoch 50: {'train_loss': '4.85837'}; time used = 0.03002166748046875s
epoch 55: {'train_loss': '4.92809'}; time used = 0.030573368072509766s
epoch 60: {'train_loss': '4.56532'}; time used = 0.02670741081237793s
epoch 65: {'train_loss': '4.44824'}; time used = 0.020241737365722656s
epoch 70: {'train_loss': '4.56917'}; time used = 0.019614696502685547s
epoch 75: {'train_loss': '4.22236'}; time used = 0.02646946907043457s
epoch 80: {'train_loss': '4.34831'}; time used = 0.03167724609375s
epoch 85: {'train_loss': '4.01849'}; time used = 0.03243684768676758s
epoch 90: {'train_loss': '3.85517'}; time used = 0.02762770652770996s
epoch 95: {'train_loss': '3.84936'}; time used = 0.034911155700683594s
epoch 100: {'train_loss': '3.74830'}; time used = 0.029917478561401367s
epoch 105: {'train_loss': '3.56054'}; time used = 0.023323774337768555s
epoch 110: {'train_loss': '3.49734'}; time used = 0.019527673721313477s
epoch 115: {'train_loss': '3.38562'}; time used = 0.03151559829711914s
epoch 120: {'train_loss': '3.37323'}; time used = 0.020280122756958008s
epoch 125: {'train_loss': '3.21314'}; time used = 0.0236055850982666s
epoch 130: {'train_loss': '3.26699'}; time used = 0.02851390838623047s
epoch 135: {'train_loss': '2.99079'}; time used = 0.02995920181274414s
epoch 140: {'train_loss': '2.99531'}; time used = 0.029779911041259766s
epoch 145: {'train_loss': '2.95445'}; time used = 0.029807329177856445s
epoch 150: {'train_loss': '2.84636'}; time used = 0.02503347396850586s
epoch 155: {'train_loss': '2.68709'}; time used = 0.02544379234313965s
epoch 160: {'train_loss': '2.61053'}; time used = 0.027257919311523438s
epoch 165: {'train_loss': '2.62779'}; time used = 0.03700900077819824s
epoch 170: {'train_loss': '2.45499'}; time used = 0.039972543716430664s
epoch 175: {'train_loss': '2.49763'}; time used = 0.02962517738342285s
epoch 180: {'train_loss': '2.42936'}; time used = 0.026790857315063477s
epoch 185: {'train_loss': '2.37482'}; time used = 0.031594038009643555s
epoch 190: {'train_loss': '2.29242'}; time used = 0.027552127838134766s
epoch 195: {'train_loss': '2.20591'}; time used = 0.026712417602539062s
epoch 200: {'train_loss': '2.16769'}; time used = 0.023236513137817383s
epoch 205: {'train_loss': '2.11341'}; time used = 0.03315877914428711s
epoch 210: {'train_loss': '2.12785'}; time used = 0.028641462326049805s
epoch 215: {'train_loss': '2.01752'}; time used = 0.028842687606811523s
epoch 220: {'train_loss': '1.93599'}; time used = 0.02680182456970215s
epoch 225: {'train_loss': '1.87987'}; time used = 0.027771949768066406s
epoch 230: {'train_loss': '1.91476'}; time used = 0.026014089584350586s
epoch 235: {'train_loss': '1.82868'}; time used = 0.02310967445373535s
epoch 240: {'train_loss': '1.78467'}; time used = 0.021918535232543945s
epoch 245: {'train_loss': '1.75993'}; time used = 0.021588802337646484s
epoch 250: {'train_loss': '1.71136'}; time used = 0.028003692626953125s
epoch 255: {'train_loss': '1.65151'}; time used = 0.022769927978515625s
epoch 260: {'train_loss': '1.66141'}; time used = 0.01707625389099121s
epoch 265: {'train_loss': '1.57256'}; time used = 0.014127254486083984s
epoch 270: {'train_loss': '1.56716'}; time used = 0.0161588191986084s
epoch 275: {'train_loss': '1.55948'}; time used = 0.019768953323364258s
epoch 280: {'train_loss': '1.51814'}; time used = 0.01771259307861328s
epoch 285: {'train_loss': '1.46300'}; time used = 0.017622709274291992s
epoch 290: {'train_loss': '1.46005'}; time used = 0.017537832260131836s
epoch 295: {'train_loss': '1.43300'}; time used = 0.018618345260620117s
epoch 300: {'train_loss': '1.39093'}; time used = 0.01869964599609375s
epoch 305: {'train_loss': '1.37250'}; time used = 0.017812490463256836s
epoch 310: {'train_loss': '1.37756'}; time used = 0.02266669273376465s
epoch 315: {'train_loss': '1.32151'}; time used = 0.02157759666442871s
epoch 320: {'train_loss': '1.30594'}; time used = 0.028376102447509766s
epoch 325: {'train_loss': '1.26039'}; time used = 0.020390748977661133s
epoch 330: {'train_loss': '1.25911'}; time used = 0.022199630737304688s
epoch 335: {'train_loss': '1.24624'}; time used = 0.01978278160095215s
epoch 340: {'train_loss': '1.19590'}; time used = 0.020185232162475586s
epoch 345: {'train_loss': '1.20479'}; time used = 0.019265413284301758s
epoch 350: {'train_loss': '1.18885'}; time used = 0.016982316970825195s
epoch 355: {'train_loss': '1.16231'}; time used = 0.020877838134765625s
epoch 360: {'train_loss': '1.12674'}; time used = 0.024738073348999023s
epoch 365: {'train_loss': '1.14681'}; time used = 0.024405241012573242s
epoch 370: {'train_loss': '1.13728'}; time used = 0.024708986282348633s
epoch 375: {'train_loss': '1.14230'}; time used = 0.02196788787841797s
epoch 380: {'train_loss': '1.07917'}; time used = 0.020373106002807617s
epoch 385: {'train_loss': '1.09278'}; time used = 0.022823572158813477s
epoch 390: {'train_loss': '1.08203'}; time used = 0.02277684211730957s
epoch 395: {'train_loss': '1.07134'}; time used = 0.017217159271240234s
epoch 400: {'train_loss': '1.04358'}; time used = 0.0497589111328125s
epoch 405: {'train_loss': '1.05274'}; time used = 0.02374863624572754s
epoch 410: {'train_loss': '1.02576'}; time used = 0.018724918365478516s
epoch 415: {'train_loss': '1.02975'}; time used = 0.018950939178466797s
epoch 420: {'train_loss': '1.01194'}; time used = 0.02186441421508789s
epoch 425: {'train_loss': '0.98212'}; time used = 0.015991926193237305s
epoch 430: {'train_loss': '0.99086'}; time used = 0.01789236068725586s
epoch 435: {'train_loss': '0.97955'}; time used = 0.0165102481842041s
epoch 440: {'train_loss': '0.96322'}; time used = 0.016588687896728516s
epoch 445: {'train_loss': '0.96395'}; time used = 0.015436172485351562s
epoch 450: {'train_loss': '0.95173'}; time used = 0.020338773727416992s
epoch 455: {'train_loss': '0.94221'}; time used = 0.019850730895996094s
epoch 460: {'train_loss': '0.93352'}; time used = 0.027645349502563477s
epoch 465: {'train_loss': '0.91739'}; time used = 0.03277134895324707s
epoch 470: {'train_loss': '0.91606'}; time used = 0.04386186599731445s
epoch 475: {'train_loss': '0.95108'}; time used = 0.020480632781982422s
epoch 480: {'train_loss': '0.91167'}; time used = 0.02120351791381836s
epoch 485: {'train_loss': '0.89638'}; time used = 0.02236008644104004s
epoch 490: {'train_loss': '0.90369'}; time used = 0.02096843719482422s
epoch 495: {'train_loss': '0.90536'}; time used = 0.026132822036743164s
epoch 500: {'train_loss': '0.89142'}; time used = 0.021814584732055664s
Finished training. Time used = 9.230751752853394.
Training classifier using 20.00% nodes...
{'micro': 0.33317951084448544, 'macro': 0.12948526380777411, 'samples': 0.33317951084448544, 'weighted': 0.20620844263766175}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '7.92557'}; time used = 0.06163311004638672s
epoch 10: {'train_loss': '6.42783'}; time used = 0.028673171997070312s
epoch 15: {'train_loss': '6.29153'}; time used = 0.02813577651977539s
epoch 20: {'train_loss': '6.01615'}; time used = 0.028826475143432617s
epoch 25: {'train_loss': '5.99693'}; time used = 0.02495861053466797s
epoch 30: {'train_loss': '5.88872'}; time used = 0.031180381774902344s
epoch 35: {'train_loss': '5.67134'}; time used = 0.025261402130126953s
epoch 40: {'train_loss': '5.72792'}; time used = 0.02472686767578125s
epoch 45: {'train_loss': '5.31443'}; time used = 0.03332090377807617s
epoch 50: {'train_loss': '5.23439'}; time used = 0.03250312805175781s
epoch 55: {'train_loss': '5.37842'}; time used = 0.030976295471191406s
epoch 60: {'train_loss': '5.02775'}; time used = 0.025916576385498047s
epoch 65: {'train_loss': '4.93214'}; time used = 0.024007081985473633s
epoch 70: {'train_loss': '5.11318'}; time used = 0.04638504981994629s
epoch 75: {'train_loss': '4.75716'}; time used = 0.02548956871032715s
epoch 80: {'train_loss': '4.91290'}; time used = 0.023916244506835938s
epoch 85: {'train_loss': '4.57063'}; time used = 0.02539801597595215s
epoch 90: {'train_loss': '4.46576'}; time used = 0.027292251586914062s
epoch 95: {'train_loss': '4.47804'}; time used = 0.022362470626831055s
epoch 100: {'train_loss': '4.38248'}; time used = 0.02566075325012207s
epoch 105: {'train_loss': '4.21329'}; time used = 0.026101350784301758s
epoch 110: {'train_loss': '4.17841'}; time used = 0.0294187068939209s
epoch 115: {'train_loss': '4.06738'}; time used = 0.0406956672668457s
epoch 120: {'train_loss': '4.09585'}; time used = 0.027238130569458008s
epoch 125: {'train_loss': '3.91134'}; time used = 0.020393848419189453s
epoch 130: {'train_loss': '4.01153'}; time used = 0.020140886306762695s
epoch 135: {'train_loss': '3.71261'}; time used = 0.01859307289123535s
epoch 140: {'train_loss': '3.74077'}; time used = 0.017586708068847656s
epoch 145: {'train_loss': '3.69124'}; time used = 0.02731633186340332s
epoch 150: {'train_loss': '3.59575'}; time used = 0.023887157440185547s
epoch 155: {'train_loss': '3.43336'}; time used = 0.023476839065551758s
epoch 160: {'train_loss': '3.33293'}; time used = 0.024854183197021484s
epoch 165: {'train_loss': '3.37216'}; time used = 0.02043604850769043s
epoch 170: {'train_loss': '3.19923'}; time used = 0.02030777931213379s
epoch 175: {'train_loss': '3.27688'}; time used = 0.053029775619506836s
epoch 180: {'train_loss': '3.19802'}; time used = 0.02519512176513672s
epoch 185: {'train_loss': '3.12592'}; time used = 0.023154020309448242s
epoch 190: {'train_loss': '3.07516'}; time used = 0.023134231567382812s
epoch 195: {'train_loss': '2.95585'}; time used = 0.022742033004760742s
epoch 200: {'train_loss': '2.92331'}; time used = 0.024573326110839844s
epoch 205: {'train_loss': '2.86077'}; time used = 0.02731156349182129s
epoch 210: {'train_loss': '2.90571'}; time used = 0.02834010124206543s
epoch 215: {'train_loss': '2.76366'}; time used = 0.02028656005859375s
epoch 220: {'train_loss': '2.65427'}; time used = 0.028485536575317383s
epoch 225: {'train_loss': '2.60378'}; time used = 0.035124778747558594s
epoch 230: {'train_loss': '2.67606'}; time used = 0.045137643814086914s
epoch 235: {'train_loss': '2.56727'}; time used = 0.01761913299560547s
epoch 240: {'train_loss': '2.50120'}; time used = 0.019429922103881836s
epoch 245: {'train_loss': '2.48141'}; time used = 0.022115230560302734s
epoch 250: {'train_loss': '2.44216'}; time used = 0.018921613693237305s
epoch 255: {'train_loss': '2.31811'}; time used = 0.0259397029876709s
epoch 260: {'train_loss': '2.36013'}; time used = 0.024841785430908203s
epoch 265: {'train_loss': '2.26140'}; time used = 0.021382808685302734s
epoch 270: {'train_loss': '2.24037'}; time used = 0.020788192749023438s
epoch 275: {'train_loss': '2.24386'}; time used = 0.03381776809692383s
epoch 280: {'train_loss': '2.20187'}; time used = 0.02792048454284668s
epoch 285: {'train_loss': '2.09529'}; time used = 0.02147388458251953s
epoch 290: {'train_loss': '2.09707'}; time used = 0.03117084503173828s
epoch 295: {'train_loss': '2.06199'}; time used = 0.031010866165161133s
epoch 300: {'train_loss': '2.01111'}; time used = 0.022092103958129883s
epoch 305: {'train_loss': '1.99250'}; time used = 0.033980369567871094s
epoch 310: {'train_loss': '1.98989'}; time used = 0.058629751205444336s
epoch 315: {'train_loss': '1.90807'}; time used = 0.03327751159667969s
epoch 320: {'train_loss': '1.86564'}; time used = 0.019193410873413086s
epoch 325: {'train_loss': '1.82191'}; time used = 0.019174575805664062s
epoch 330: {'train_loss': '1.79836'}; time used = 0.01986074447631836s
epoch 335: {'train_loss': '1.80908'}; time used = 0.0192415714263916s
epoch 340: {'train_loss': '1.72521'}; time used = 0.019022226333618164s
epoch 345: {'train_loss': '1.72707'}; time used = 0.026568174362182617s
epoch 350: {'train_loss': '1.69699'}; time used = 0.021031856536865234s
epoch 355: {'train_loss': '1.67281'}; time used = 0.024082660675048828s
epoch 360: {'train_loss': '1.60582'}; time used = 0.0217587947845459s
epoch 365: {'train_loss': '1.64764'}; time used = 0.0184786319732666s
epoch 370: {'train_loss': '1.62135'}; time used = 0.018291711807250977s
epoch 375: {'train_loss': '1.63632'}; time used = 0.020832300186157227s
epoch 380: {'train_loss': '1.52935'}; time used = 0.019161462783813477s
epoch 385: {'train_loss': '1.54169'}; time used = 0.018634557723999023s
epoch 390: {'train_loss': '1.51100'}; time used = 0.022869348526000977s
epoch 395: {'train_loss': '1.51237'}; time used = 0.021951675415039062s
epoch 400: {'train_loss': '1.44511'}; time used = 0.018909692764282227s
epoch 405: {'train_loss': '1.47883'}; time used = 0.02018260955810547s
epoch 410: {'train_loss': '1.43677'}; time used = 0.023646831512451172s
epoch 415: {'train_loss': '1.42420'}; time used = 0.036145687103271484s
epoch 420: {'train_loss': '1.39677'}; time used = 0.026409149169921875s
epoch 425: {'train_loss': '1.34486'}; time used = 0.024405956268310547s
epoch 430: {'train_loss': '1.36482'}; time used = 0.019111156463623047s
epoch 435: {'train_loss': '1.33347'}; time used = 0.021195173263549805s
epoch 440: {'train_loss': '1.31407'}; time used = 0.042330265045166016s
epoch 445: {'train_loss': '1.31605'}; time used = 0.022396087646484375s
epoch 450: {'train_loss': '1.27439'}; time used = 0.01980447769165039s
epoch 455: {'train_loss': '1.26080'}; time used = 0.02687835693359375s
epoch 460: {'train_loss': '1.24626'}; time used = 0.025412321090698242s
epoch 465: {'train_loss': '1.20551'}; time used = 0.02051377296447754s
epoch 470: {'train_loss': '1.20555'}; time used = 0.024351835250854492s
epoch 475: {'train_loss': '1.24914'}; time used = 0.023366212844848633s
epoch 480: {'train_loss': '1.19363'}; time used = 0.0223388671875s
epoch 485: {'train_loss': '1.17502'}; time used = 0.02235269546508789s
epoch 490: {'train_loss': '1.17001'}; time used = 0.026894330978393555s
epoch 495: {'train_loss': '1.17958'}; time used = 0.02359318733215332s
epoch 500: {'train_loss': '1.14006'}; time used = 0.01897597312927246s
Finished training. Time used = 10.921249389648438.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '7.04271'}; time used = 0.0537722110748291s
epoch 10: {'train_loss': '6.29107'}; time used = 0.041306495666503906s
epoch 15: {'train_loss': '6.16454'}; time used = 0.02966475486755371s
epoch 20: {'train_loss': '5.84661'}; time used = 0.04040265083312988s
epoch 25: {'train_loss': '5.78239'}; time used = 0.032103776931762695s
epoch 30: {'train_loss': '5.64356'}; time used = 0.030444860458374023s
epoch 35: {'train_loss': '5.39794'}; time used = 0.03182625770568848s
epoch 40: {'train_loss': '5.39329'}; time used = 0.03156399726867676s
epoch 45: {'train_loss': '4.94573'}; time used = 0.030580997467041016s
epoch 50: {'train_loss': '4.85837'}; time used = 0.025821208953857422s
epoch 55: {'train_loss': '4.92809'}; time used = 0.03043985366821289s
epoch 60: {'train_loss': '4.56532'}; time used = 0.029343366622924805s
epoch 65: {'train_loss': '4.44824'}; time used = 0.028787612915039062s
epoch 70: {'train_loss': '4.56917'}; time used = 0.028552770614624023s
epoch 75: {'train_loss': '4.22236'}; time used = 0.035805702209472656s
epoch 80: {'train_loss': '4.34831'}; time used = 0.021714210510253906s
epoch 85: {'train_loss': '4.01849'}; time used = 0.02227020263671875s
epoch 90: {'train_loss': '3.85517'}; time used = 0.030906200408935547s
epoch 95: {'train_loss': '3.84936'}; time used = 0.03397488594055176s
epoch 100: {'train_loss': '3.74830'}; time used = 0.02835392951965332s
epoch 105: {'train_loss': '3.56054'}; time used = 0.029755830764770508s
epoch 110: {'train_loss': '3.49734'}; time used = 0.027123689651489258s
epoch 115: {'train_loss': '3.38562'}; time used = 0.03087592124938965s
epoch 120: {'train_loss': '3.37323'}; time used = 0.026501178741455078s
epoch 125: {'train_loss': '3.21314'}; time used = 0.031075716018676758s
epoch 130: {'train_loss': '3.26699'}; time used = 0.028359413146972656s
epoch 135: {'train_loss': '2.99079'}; time used = 0.03052496910095215s
epoch 140: {'train_loss': '2.99531'}; time used = 0.027256250381469727s
epoch 145: {'train_loss': '2.95445'}; time used = 0.03315591812133789s
epoch 150: {'train_loss': '2.84636'}; time used = 0.03255462646484375s
epoch 155: {'train_loss': '2.68709'}; time used = 0.02150106430053711s
epoch 160: {'train_loss': '2.61053'}; time used = 0.018352270126342773s
epoch 165: {'train_loss': '2.62779'}; time used = 0.0412752628326416s
epoch 170: {'train_loss': '2.45499'}; time used = 0.021299362182617188s
epoch 175: {'train_loss': '2.49763'}; time used = 0.022792816162109375s
epoch 180: {'train_loss': '2.42936'}; time used = 0.024550437927246094s
epoch 185: {'train_loss': '2.37482'}; time used = 0.02888321876525879s
epoch 190: {'train_loss': '2.29242'}; time used = 0.03591346740722656s
epoch 195: {'train_loss': '2.20591'}; time used = 0.01941204071044922s
epoch 200: {'train_loss': '2.16769'}; time used = 0.021453380584716797s
epoch 205: {'train_loss': '2.11341'}; time used = 0.0358738899230957s
epoch 210: {'train_loss': '2.12785'}; time used = 0.03371429443359375s
epoch 215: {'train_loss': '2.01752'}; time used = 0.028884172439575195s
epoch 220: {'train_loss': '1.93599'}; time used = 0.02019047737121582s
epoch 225: {'train_loss': '1.87987'}; time used = 0.028687477111816406s
epoch 230: {'train_loss': '1.91476'}; time used = 0.03194904327392578s
epoch 235: {'train_loss': '1.82868'}; time used = 0.028259754180908203s
epoch 240: {'train_loss': '1.78467'}; time used = 0.031449079513549805s
epoch 245: {'train_loss': '1.75993'}; time used = 0.02852940559387207s
epoch 250: {'train_loss': '1.71136'}; time used = 0.03169584274291992s
epoch 255: {'train_loss': '1.65151'}; time used = 0.029656171798706055s
epoch 260: {'train_loss': '1.66141'}; time used = 0.029888391494750977s
epoch 265: {'train_loss': '1.57256'}; time used = 0.022882938385009766s
epoch 270: {'train_loss': '1.56716'}; time used = 0.020416259765625s
epoch 275: {'train_loss': '1.55948'}; time used = 0.02541351318359375s
epoch 280: {'train_loss': '1.51814'}; time used = 0.03264880180358887s
epoch 285: {'train_loss': '1.46300'}; time used = 0.023957014083862305s
epoch 290: {'train_loss': '1.46005'}; time used = 0.02423548698425293s
epoch 295: {'train_loss': '1.43300'}; time used = 0.028297901153564453s
epoch 300: {'train_loss': '1.39093'}; time used = 0.02227950096130371s
epoch 305: {'train_loss': '1.37250'}; time used = 0.017202138900756836s
epoch 310: {'train_loss': '1.37756'}; time used = 0.023185014724731445s
epoch 315: {'train_loss': '1.32151'}; time used = 0.02093648910522461s
epoch 320: {'train_loss': '1.30594'}; time used = 0.03129315376281738s
epoch 325: {'train_loss': '1.26039'}; time used = 0.03379321098327637s
epoch 330: {'train_loss': '1.25911'}; time used = 0.03531336784362793s
epoch 335: {'train_loss': '1.24624'}; time used = 0.03420901298522949s
epoch 340: {'train_loss': '1.19590'}; time used = 0.02504444122314453s
epoch 345: {'train_loss': '1.20479'}; time used = 0.03163957595825195s
epoch 350: {'train_loss': '1.18885'}; time used = 0.03709220886230469s
epoch 355: {'train_loss': '1.16231'}; time used = 0.03195333480834961s
epoch 360: {'train_loss': '1.12674'}; time used = 0.05185580253601074s
epoch 365: {'train_loss': '1.14681'}; time used = 0.026522397994995117s
epoch 370: {'train_loss': '1.13728'}; time used = 0.02146172523498535s
epoch 375: {'train_loss': '1.14230'}; time used = 0.024291038513183594s
epoch 380: {'train_loss': '1.07917'}; time used = 0.029103755950927734s
epoch 385: {'train_loss': '1.09278'}; time used = 0.035799503326416016s
epoch 390: {'train_loss': '1.08203'}; time used = 0.02558732032775879s
epoch 395: {'train_loss': '1.07134'}; time used = 0.02476811408996582s
epoch 400: {'train_loss': '1.04358'}; time used = 0.02736353874206543s
epoch 405: {'train_loss': '1.05274'}; time used = 0.04071307182312012s
epoch 410: {'train_loss': '1.02576'}; time used = 0.04735422134399414s
epoch 415: {'train_loss': '1.02975'}; time used = 0.03346657752990723s
epoch 420: {'train_loss': '1.01194'}; time used = 0.022351503372192383s
epoch 425: {'train_loss': '0.98212'}; time used = 0.018233299255371094s
epoch 430: {'train_loss': '0.99086'}; time used = 0.04473066329956055s
epoch 435: {'train_loss': '0.97955'}; time used = 0.03438997268676758s
epoch 440: {'train_loss': '0.96322'}; time used = 0.039237260818481445s
epoch 445: {'train_loss': '0.96395'}; time used = 0.023041486740112305s
epoch 450: {'train_loss': '0.95173'}; time used = 0.02731800079345703s
epoch 455: {'train_loss': '0.94221'}; time used = 0.02489447593688965s
epoch 460: {'train_loss': '0.93352'}; time used = 0.03743696212768555s
epoch 465: {'train_loss': '0.91739'}; time used = 0.026454448699951172s
epoch 470: {'train_loss': '0.91606'}; time used = 0.030896663665771484s
epoch 475: {'train_loss': '0.95108'}; time used = 0.041311025619506836s
epoch 480: {'train_loss': '0.91167'}; time used = 0.04014134407043457s
epoch 485: {'train_loss': '0.89638'}; time used = 0.057825326919555664s
epoch 490: {'train_loss': '0.90369'}; time used = 0.041060447692871094s
epoch 495: {'train_loss': '0.90536'}; time used = 0.02817058563232422s
epoch 500: {'train_loss': '0.89142'}; time used = 0.035163164138793945s
Finished training. Time used = 10.073402166366577.
Training classifier using 20.00% nodes...
{'micro': 0.33317951084448544, 'macro': 0.12948526380777411, 'samples': 0.33317951084448544, 'weighted': 0.20620844263766175}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 10.76 GiB total capacity; 103.11 MiB already allocated; 16.44 MiB free; 126.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f5fc50961e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f5fc52ec64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f5fc52ed464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f5fc52edaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f5d845e090e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f5d82a1a949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f5d82a34777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f5fc65e8c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f5fc65e8f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f5fc66f3a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f5fc63834f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f5fc6385166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f5fc638565d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f5fc638580a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f5fc60c2eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f5d82a09b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f5fc5f55530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f5fc673d81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f5fc668e82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0x2f16968 (0x7f5fc8415968 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: <unknown function> + 0xa56530 (0x7f5fc5f55530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f5fc673d81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: at::Tensor::mul(at::Tensor const&) const + 0x4b (0x7f5fc6823d6b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: torch::autograd::generated::MulBackward0::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x235 (0x7f5fc822cda5 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x3375bb7 (0x7f5fc8874bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f5fc8870400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f5fc8870fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f5fc8869119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f5fd60094ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #29: <unknown function> + 0xbd6df (0x7f5fd71656df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #30: <unknown function> + 0x76db (0x7f5fdb1c06db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #31: clone + 0x3f (0x7f5fdb4f971f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148781.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8367/10556 [00:00<00:00, 83664.10it/s]100%|| 10556/10556 [00:00<00:00, 84808.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117249.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7503/10556 [00:00<00:00, 75023.10it/s]100%|| 10556/10556 [00:00<00:00, 60509.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124300.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149432.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10426/10556 [00:00<00:00, 97739.26it/s]100%|| 10556/10556 [00:00<00:00, 96103.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9761/10556 [00:00<00:00, 97603.58it/s]100%|| 10556/10556 [00:00<00:00, 83924.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9032/10556 [00:00<00:00, 90315.56it/s]100%|| 10556/10556 [00:00<00:00, 90809.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8711/10556 [00:00<00:00, 87105.72it/s]100%|| 10556/10556 [00:00<00:00, 90896.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7378/10556 [00:00<00:00, 73775.85it/s]100%|| 10556/10556 [00:00<00:00, 89619.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156514.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6752/10556 [00:00<00:00, 61838.79it/s]100%|| 10556/10556 [00:00<00:00, 59904.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130220.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 27%|       | 2807/10556 [00:00<00:00, 24662.71it/s]100%|| 10556/10556 [00:00<00:00, 60381.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4477/10556 [00:00<00:00, 43758.07it/s]100%|| 10556/10556 [00:00<00:00, 63787.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123012.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114034.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9502/10556 [00:00<00:00, 94326.52it/s]100%|| 10556/10556 [00:00<00:00, 75740.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113515.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3867/10556 [00:00<00:00, 37708.16it/s] 70%|   | 7429/10556 [00:00<00:00, 37056.38it/s]100%|| 10556/10556 [00:00<00:00, 42582.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7472/10556 [00:00<00:00, 74718.82it/s]100%|| 10556/10556 [00:00<00:00, 70437.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124436.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112300.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122168.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132614.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113722.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118955.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132606.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8754/10556 [00:00<00:00, 87535.07it/s]100%|| 10556/10556 [00:00<00:00, 64942.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109994.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155018.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6619/10556 [00:00<00:00, 56542.07it/s]100%|| 10556/10556 [00:00<00:00, 69706.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196203.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 217445.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196474.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176134.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138415.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169662.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141582.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123905.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185345.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182166.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190083.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194262.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182764.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186528.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197705.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188242.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186089.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185057.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177838.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187599.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185720.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192329.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145313.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140932.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195900.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4908/10556 [00:00<00:00, 48868.69it/s]100%|| 10556/10556 [00:00<00:00, 73192.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190070.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119644.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139140.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186773.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121525.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6281/10556 [00:00<00:00, 62803.62it/s]100%|| 10556/10556 [00:00<00:00, 65113.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7485/10556 [00:00<00:00, 66144.78it/s]100%|| 10556/10556 [00:00<00:00, 56694.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8214/10556 [00:00<00:00, 82135.97it/s]100%|| 10556/10556 [00:00<00:00, 67325.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123498.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180794.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178092.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171176.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105637.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120962.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112413.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8766/10556 [00:00<00:00, 87654.86it/s]100%|| 10556/10556 [00:00<00:00, 93704.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171374.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182068.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166549.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163630.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162216.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160223.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178705.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129474.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146928.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 201241.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149163.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117339.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192918.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187919.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8305/10556 [00:00<00:00, 80989.95it/s]100%|| 10556/10556 [00:00<00:00, 78881.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 201935.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 204726.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192912.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123013.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109334.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9180/10556 [00:00<00:00, 91798.34it/s]100%|| 10556/10556 [00:00<00:00, 87813.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6695/10556 [00:00<00:00, 66947.19it/s]100%|| 10556/10556 [00:00<00:00, 77915.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10014/10556 [00:00<00:00, 100131.74it/s]100%|| 10556/10556 [00:00<00:00, 100231.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9959/10556 [00:00<00:00, 99589.38it/s]100%|| 10556/10556 [00:00<00:00, 99745.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9720/10556 [00:00<00:00, 97197.31it/s]100%|| 10556/10556 [00:00<00:00, 97374.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9274/10556 [00:00<00:00, 92732.35it/s]100%|| 10556/10556 [00:00<00:00, 76760.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6923/10556 [00:00<00:00, 69226.60it/s]100%|| 10556/10556 [00:00<00:00, 64962.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6275/10556 [00:00<00:00, 62744.23it/s]100%|| 10556/10556 [00:00<00:00, 60867.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8956/10556 [00:00<00:00, 89557.31it/s]100%|| 10556/10556 [00:00<00:00, 85391.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8824/10556 [00:00<00:00, 88234.82it/s]100%|| 10556/10556 [00:00<00:00, 91304.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10053/10556 [00:00<00:00, 100521.95it/s]100%|| 10556/10556 [00:00<00:00, 100612.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5840/10556 [00:00<00:00, 57052.07it/s]100%|| 10556/10556 [00:00<00:00, 60328.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7846/10556 [00:00<00:00, 78458.20it/s]100%|| 10556/10556 [00:00<00:00, 85908.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114241.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115635.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7335/10556 [00:00<00:00, 69200.02it/s]100%|| 10556/10556 [00:00<00:00, 53557.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6253/10556 [00:00<00:00, 62521.26it/s]100%|| 10556/10556 [00:00<00:00, 64541.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|      | 4036/10556 [00:00<00:00, 40358.11it/s]100%|| 10556/10556 [00:00<00:00, 53004.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5941/10556 [00:00<00:00, 59401.70it/s]100%|| 10556/10556 [00:00<00:00, 63817.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5691/10556 [00:00<00:00, 53561.61it/s] 85%| | 9012/10556 [00:00<00:00, 44452.88it/s]100%|| 10556/10556 [00:00<00:00, 35157.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120208.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6715/10556 [00:00<00:00, 67143.66it/s]100%|| 10556/10556 [00:00<00:00, 76375.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114239.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114053.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10353/10556 [00:00<00:00, 103524.42it/s]100%|| 10556/10556 [00:00<00:00, 90839.86it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111902.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132754.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6848/10556 [00:00<00:00, 66966.95it/s]100%|| 10556/10556 [00:00<00:00, 54419.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7090/10556 [00:00<00:00, 60018.15it/s]100%|| 10556/10556 [00:00<00:00, 65482.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8252/10556 [00:00<00:00, 82519.29it/s]100%|| 10556/10556 [00:00<00:00, 91633.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174791.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182074.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172958.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105115.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5811/10556 [00:00<00:00, 58107.84it/s]100%|| 10556/10556 [00:00<00:00, 75395.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6113/10556 [00:00<00:00, 59374.43it/s]100%|| 10556/10556 [00:00<00:00, 64619.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178894.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175258.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168773.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177729.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8663/10556 [00:00<00:00, 80990.50it/s]100%|| 10556/10556 [00:00<00:00, 77759.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116525.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8368/10556 [00:00<00:00, 81708.24it/s]100%|| 10556/10556 [00:00<00:00, 78850.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7895/10556 [00:00<00:00, 78943.68it/s]100%|| 10556/10556 [00:00<00:00, 79889.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10032/10556 [00:00<00:00, 100319.86it/s]100%|| 10556/10556 [00:00<00:00, 102369.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184552.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186168.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7662/10556 [00:00<00:00, 63589.04it/s]100%|| 10556/10556 [00:00<00:00, 69358.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173769.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143578.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158136.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9482/10556 [00:00<00:00, 94815.12it/s]100%|| 10556/10556 [00:00<00:00, 84454.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150365.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190194.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179078.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184661.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174108.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173934.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174411.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7284/10556 [00:00<00:00, 71888.82it/s]100%|| 10556/10556 [00:00<00:00, 69329.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123210.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10238/10556 [00:00<00:00, 102376.44it/s]100%|| 10556/10556 [00:00<00:00, 98742.33it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188817.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181895.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184310.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10002/10556 [00:00<00:00, 100011.03it/s]100%|| 10556/10556 [00:00<00:00, 87521.59it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108514.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121452.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185428.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185965.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178309.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175844.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170577.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154990.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4968/10556 [00:00<00:00, 49677.20it/s]100%|| 10556/10556 [00:00<00:00, 62837.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107669.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107805.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115518.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8165/10556 [00:00<00:00, 81646.96it/s]100%|| 10556/10556 [00:00<00:00, 86747.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125522.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144772.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5242/10556 [00:00<00:00, 52417.55it/s]100%|| 10556/10556 [00:00<00:00, 66328.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108252.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145836.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172081.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165314.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181378.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188687.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6157/10556 [00:00<00:00, 61564.63it/s]100%|| 10556/10556 [00:00<00:00, 77360.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6029/10556 [00:00<00:00, 60287.90it/s]100%|| 10556/10556 [00:00<00:00, 82010.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179428.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170040.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159603.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175866.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178839.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175463.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172279.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161431.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169497.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167241.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163654.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168771.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164205.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162208.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 207973.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200062.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178578.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177350.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10175/10556 [00:00<00:00, 101737.48it/s]100%|| 10556/10556 [00:00<00:00, 94536.58it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8395/10556 [00:00<00:00, 83945.88it/s]100%|| 10556/10556 [00:00<00:00, 89975.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107632.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125217.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144638.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144954.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138783.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108257.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9673/10556 [00:00<00:00, 96729.63it/s]100%|| 10556/10556 [00:00<00:00, 79804.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6030/10556 [00:00<00:00, 60296.61it/s]100%|| 10556/10556 [00:00<00:00, 67666.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 215230.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 24%|       | 2559/10556 [00:00<00:00, 23748.91it/s] 85%| | 8923/10556 [00:00<00:00, 29248.98it/s]100%|| 10556/10556 [00:00<00:00, 45460.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5111/10556 [00:00<00:00, 51109.81it/s]100%|| 10556/10556 [00:00<00:00, 65546.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123677.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185657.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148439.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7760/10556 [00:00<00:00, 77598.41it/s]100%|| 10556/10556 [00:00<00:00, 61800.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6471/10556 [00:00<00:00, 60044.96it/s] 86%| | 9126/10556 [00:00<00:00, 42414.46it/s]100%|| 10556/10556 [00:00<00:00, 42360.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8859/10556 [00:00<00:00, 88588.39it/s]100%|| 10556/10556 [00:00<00:00, 92766.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7507/10556 [00:00<00:00, 65261.88it/s]100%|| 10556/10556 [00:00<00:00, 60954.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116924.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151942.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114026.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131855.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 31%|       | 3256/10556 [00:00<00:00, 28207.08it/s] 68%|   | 7184/10556 [00:00<00:00, 30102.54it/s]100%|| 10556/10556 [00:00<00:00, 35008.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9120/10556 [00:00<00:00, 71767.99it/s]100%|| 10556/10556 [00:00<00:00, 72286.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176348.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175397.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183281.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6961/10556 [00:00<00:00, 69605.92it/s]100%|| 10556/10556 [00:00<00:00, 76617.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5201/10556 [00:00<00:00, 49569.79it/s]100%|| 10556/10556 [00:00<00:00, 57815.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108383.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192148.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7243/10556 [00:00<00:00, 72425.75it/s]100%|| 10556/10556 [00:00<00:00, 88841.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191116.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174785.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171676.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8683/10556 [00:00<00:00, 86825.11it/s]100%|| 10556/10556 [00:00<00:00, 90249.54it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '5.55832'}; time used = 0.659149169921875s
epoch 10: {'train_loss': '4.67000'}; time used = 0.6784114837646484s
epoch 15: {'train_loss': '3.98939'}; time used = 0.6989161968231201s
epoch 20: {'train_loss': '3.51294'}; time used = 0.7149257659912109s
epoch 25: {'train_loss': '3.40695'}; time used = 0.5455856323242188s
epoch 30: {'train_loss': '3.27472'}; time used = 0.5827975273132324s
epoch 35: {'train_loss': '3.13836'}; time used = 0.4061927795410156s
epoch 40: {'train_loss': '2.95003'}; time used = 0.3869767189025879s
epoch 45: {'train_loss': '2.90008'}; time used = 0.30853748321533203s
epoch 50: {'train_loss': '2.86244'}; time used = 0.3106703758239746s
epoch 55: {'train_loss': '2.74068'}; time used = 0.32860469818115234s
epoch 60: {'train_loss': '2.72135'}; time used = 0.4593374729156494s
epoch 65: {'train_loss': '2.67605'}; time used = 0.6333236694335938s
epoch 70: {'train_loss': '2.62137'}; time used = 0.47865772247314453s
epoch 75: {'train_loss': '2.55152'}; time used = 0.5242230892181396s
epoch 80: {'train_loss': '2.58896'}; time used = 0.3619992733001709s
epoch 85: {'train_loss': '2.48834'}; time used = 0.3769233226776123s
epoch 90: {'train_loss': '2.48176'}; time used = 0.44350457191467285s
epoch 95: {'train_loss': '2.43222'}; time used = 0.45162224769592285s
epoch 100: {'train_loss': '2.38903'}; time used = 0.6380524635314941s
epoch 105: {'train_loss': '2.35745'}; time used = 0.7442235946655273s
epoch 110: {'train_loss': '2.32605'}; time used = 0.7239000797271729s
epoch 115: {'train_loss': '2.30731'}; time used = 0.9774649143218994s
epoch 120: {'train_loss': '2.26679'}; time used = 0.6126101016998291s
epoch 125: {'train_loss': '2.20963'}; time used = 0.6675925254821777s
epoch 130: {'train_loss': '2.13760'}; time used = 0.5600845813751221s
epoch 135: {'train_loss': '2.16330'}; time used = 0.4076671600341797s
epoch 140: {'train_loss': '2.10171'}; time used = 0.5942463874816895s
epoch 145: {'train_loss': '2.05583'}; time used = 0.4387996196746826s
epoch 150: {'train_loss': '1.99546'}; time used = 0.4133601188659668s
epoch 155: {'train_loss': '1.92016'}; time used = 0.4520528316497803s
epoch 160: {'train_loss': '1.95884'}; time used = 0.45016026496887207s
epoch 165: {'train_loss': '1.89644'}; time used = 0.3939096927642822s
epoch 170: {'train_loss': '1.90737'}; time used = 0.5116443634033203s
epoch 175: {'train_loss': '1.86853'}; time used = 0.5125513076782227s
epoch 180: {'train_loss': '1.82652'}; time used = 0.5171396732330322s
epoch 185: {'train_loss': '1.79729'}; time used = 0.49145936965942383s
epoch 190: {'train_loss': '1.78456'}; time used = 0.34834790229797363s
epoch 195: {'train_loss': '1.76250'}; time used = 0.3484487533569336s
epoch 200: {'train_loss': '1.70932'}; time used = 0.34511303901672363s
epoch 205: {'train_loss': '1.69655'}; time used = 0.48613572120666504s
epoch 210: {'train_loss': '1.67549'}; time used = 0.43837475776672363s
epoch 215: {'train_loss': '1.66930'}; time used = 0.7991831302642822s
epoch 220: {'train_loss': '1.64033'}; time used = 0.6797301769256592s
epoch 225: {'train_loss': '1.60272'}; time used = 0.5788214206695557s
epoch 230: {'train_loss': '1.55617'}; time used = 0.6805093288421631s
epoch 235: {'train_loss': '1.49387'}; time used = 0.5979790687561035s
epoch 240: {'train_loss': '1.53545'}; time used = 0.47676873207092285s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.519233465194702.
Training classifier using 20.00% nodes...
{'micro': 0.286571296723581, 'macro': 0.08138532453562543, 'samples': 0.286571296723581, 'weighted': 0.15221843340023927}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3724/10556 [00:00<00:00, 37239.24it/s] 69%|   | 7268/10556 [00:00<00:00, 36679.63it/s]100%|| 10556/10556 [00:00<00:00, 42391.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127931.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115261.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 27%|       | 2807/10556 [00:00<00:00, 24760.69it/s] 55%|    | 5796/10556 [00:00<00:00, 26104.48it/s]100%|| 10556/10556 [00:00<00:00, 39537.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9263/10556 [00:00<00:00, 92623.46it/s]100%|| 10556/10556 [00:00<00:00, 83847.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10468/10556 [00:00<00:00, 104677.35it/s]100%|| 10556/10556 [00:00<00:00, 101326.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6341/10556 [00:00<00:00, 63367.61it/s]100%|| 10556/10556 [00:00<00:00, 63219.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6552/10556 [00:00<00:00, 65519.13it/s]100%|| 10556/10556 [00:00<00:00, 73374.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126314.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9522/10556 [00:00<00:00, 95217.14it/s]100%|| 10556/10556 [00:00<00:00, 97302.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7018/10556 [00:00<00:00, 70168.69it/s]100%|| 10556/10556 [00:00<00:00, 84282.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126324.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5961/10556 [00:00<00:00, 59607.21it/s]100%|| 10556/10556 [00:00<00:00, 60391.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127864.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10020/10556 [00:00<00:00, 100199.38it/s]100%|| 10556/10556 [00:00<00:00, 100958.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 19%|        | 1978/10556 [00:00<00:00, 19265.62it/s]100%|| 10556/10556 [00:00<00:00, 57700.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124303.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7291/10556 [00:00<00:00, 72908.85it/s]100%|| 10556/10556 [00:00<00:00, 84351.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117201.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4808/10556 [00:00<00:00, 48078.10it/s]100%|| 10556/10556 [00:00<00:00, 53681.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6293/10556 [00:00<00:00, 62925.71it/s]100%|| 10556/10556 [00:00<00:00, 58644.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7964/10556 [00:00<00:00, 79634.95it/s]100%|| 10556/10556 [00:00<00:00, 87212.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8795/10556 [00:00<00:00, 87944.63it/s]100%|| 10556/10556 [00:00<00:00, 80291.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7028/10556 [00:00<00:00, 68872.34it/s]100%|| 10556/10556 [00:00<00:00, 73814.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6137/10556 [00:00<00:00, 61365.38it/s]100%|| 10556/10556 [00:00<00:00, 77908.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6331/10556 [00:00<00:00, 63306.14it/s]100%|| 10556/10556 [00:00<00:00, 58158.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7511/10556 [00:00<00:00, 65425.35it/s]100%|| 10556/10556 [00:00<00:00, 75659.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7035/10556 [00:00<00:00, 70346.38it/s]100%|| 10556/10556 [00:00<00:00, 65586.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6732/10556 [00:00<00:00, 67319.10it/s]100%|| 10556/10556 [00:00<00:00, 80384.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111603.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7309/10556 [00:00<00:00, 73088.50it/s]100%|| 10556/10556 [00:00<00:00, 65161.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7718/10556 [00:00<00:00, 75190.20it/s]100%|| 10556/10556 [00:00<00:00, 84594.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6626/10556 [00:00<00:00, 66255.96it/s]100%|| 10556/10556 [00:00<00:00, 56235.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|      | 3431/10556 [00:00<00:00, 30386.19it/s]100%|| 10556/10556 [00:00<00:00, 62528.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6946/10556 [00:00<00:00, 69459.57it/s]100%|| 10556/10556 [00:00<00:00, 66776.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6667/10556 [00:00<00:00, 66669.43it/s]100%|| 10556/10556 [00:00<00:00, 65180.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6703/10556 [00:00<00:00, 67026.39it/s]100%|| 10556/10556 [00:00<00:00, 64962.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6645/10556 [00:00<00:00, 66447.69it/s]100%|| 10556/10556 [00:00<00:00, 80616.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10216/10556 [00:00<00:00, 102152.30it/s]100%|| 10556/10556 [00:00<00:00, 102491.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6481/10556 [00:00<00:00, 64809.91it/s]100%|| 10556/10556 [00:00<00:00, 58433.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122728.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119464.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109076.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6574/10556 [00:00<00:00, 64471.63it/s]100%|| 10556/10556 [00:00<00:00, 65171.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7236/10556 [00:00<00:00, 72355.41it/s]100%|| 10556/10556 [00:00<00:00, 63124.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6021/10556 [00:00<00:00, 60209.48it/s]100%|| 10556/10556 [00:00<00:00, 61726.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118371.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7226/10556 [00:00<00:00, 72256.45it/s]100%|| 10556/10556 [00:00<00:00, 82304.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9814/10556 [00:00<00:00, 98132.61it/s]100%|| 10556/10556 [00:00<00:00, 94867.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7880/10556 [00:00<00:00, 78795.00it/s]100%|| 10556/10556 [00:00<00:00, 79094.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7375/10556 [00:00<00:00, 73747.78it/s]100%|| 10556/10556 [00:00<00:00, 75783.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8693/10556 [00:00<00:00, 86929.25it/s]100%|| 10556/10556 [00:00<00:00, 91045.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9282/10556 [00:00<00:00, 92812.34it/s]100%|| 10556/10556 [00:00<00:00, 80582.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6115/10556 [00:00<00:00, 61148.60it/s]100%|| 10556/10556 [00:00<00:00, 78858.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7394/10556 [00:00<00:00, 73814.94it/s]100%|| 10556/10556 [00:00<00:00, 72289.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107959.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109882.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6118/10556 [00:00<00:00, 60730.19it/s]100%|| 10556/10556 [00:00<00:00, 66115.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7094/10556 [00:00<00:00, 70936.18it/s]100%|| 10556/10556 [00:00<00:00, 77245.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109200.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 9015/10556 [00:00<00:00, 90149.01it/s]100%|| 10556/10556 [00:00<00:00, 93972.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9776/10556 [00:00<00:00, 97560.06it/s]100%|| 10556/10556 [00:00<00:00, 93454.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7316/10556 [00:00<00:00, 72372.38it/s]100%|| 10556/10556 [00:00<00:00, 50156.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7800/10556 [00:00<00:00, 77995.24it/s]100%|| 10556/10556 [00:00<00:00, 80328.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122246.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6815/10556 [00:00<00:00, 65322.73it/s]100%|| 10556/10556 [00:00<00:00, 63913.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8953/10556 [00:00<00:00, 89525.82it/s]100%|| 10556/10556 [00:00<00:00, 93792.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122361.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7714/10556 [00:00<00:00, 77138.97it/s]100%|| 10556/10556 [00:00<00:00, 76721.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|    | 5427/10556 [00:00<00:00, 54266.17it/s]100%|| 10556/10556 [00:00<00:00, 70738.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120176.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|      | 3500/10556 [00:00<00:00, 34996.45it/s] 75%|  | 7914/10556 [00:00<00:00, 37314.19it/s]100%|| 10556/10556 [00:00<00:00, 41800.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6652/10556 [00:00<00:00, 66517.21it/s]100%|| 10556/10556 [00:00<00:00, 59304.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118852.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124916.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6693/10556 [00:00<00:00, 66929.43it/s]100%|| 10556/10556 [00:00<00:00, 70667.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117672.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124943.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109353.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118661.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120167.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113116.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121066.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5739/10556 [00:00<00:00, 45701.92it/s]100%|| 10556/10556 [00:00<00:00, 47727.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4885/10556 [00:00<00:00, 48848.42it/s] 96%|| 10150/10556 [00:00<00:00, 49929.07it/s]100%|| 10556/10556 [00:00<00:00, 50780.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5626/10556 [00:00<00:00, 56258.04it/s]100%|| 10556/10556 [00:00<00:00, 53137.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112282.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122856.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5575/10556 [00:00<00:00, 55746.86it/s]100%|| 10556/10556 [00:00<00:00, 57957.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4787/10556 [00:00<00:00, 47869.70it/s]100%|| 10556/10556 [00:00<00:00, 54201.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122339.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9723/10556 [00:00<00:00, 97229.17it/s]100%|| 10556/10556 [00:00<00:00, 97694.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4570/10556 [00:00<00:00, 45694.16it/s] 91%| | 9577/10556 [00:00<00:00, 46922.63it/s]100%|| 10556/10556 [00:00<00:00, 49101.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117078.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10529/10556 [00:00<00:00, 105285.08it/s]100%|| 10556/10556 [00:00<00:00, 104870.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8068/10556 [00:00<00:00, 80676.81it/s]100%|| 10556/10556 [00:00<00:00, 86922.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117137.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7456/10556 [00:00<00:00, 74546.92it/s]100%|| 10556/10556 [00:00<00:00, 73084.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116260.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123740.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120470.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117068.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121293.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126493.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7552/10556 [00:00<00:00, 75513.41it/s]100%|| 10556/10556 [00:00<00:00, 69700.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6389/10556 [00:00<00:00, 63885.64it/s]100%|| 10556/10556 [00:00<00:00, 63866.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7170/10556 [00:00<00:00, 71695.28it/s]100%|| 10556/10556 [00:00<00:00, 82869.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8573/10556 [00:00<00:00, 85728.65it/s]100%|| 10556/10556 [00:00<00:00, 91260.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10323/10556 [00:00<00:00, 103222.72it/s]100%|| 10556/10556 [00:00<00:00, 95933.37it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124497.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121535.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120751.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7604/10556 [00:00<00:00, 76038.26it/s]100%|| 10556/10556 [00:00<00:00, 84586.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122026.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10172/10556 [00:00<00:00, 101717.19it/s]100%|| 10556/10556 [00:00<00:00, 102061.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10131/10556 [00:00<00:00, 101304.30it/s]100%|| 10556/10556 [00:00<00:00, 101920.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7556/10556 [00:00<00:00, 75559.89it/s]100%|| 10556/10556 [00:00<00:00, 86877.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7140/10556 [00:00<00:00, 71397.68it/s]100%|| 10556/10556 [00:00<00:00, 82955.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8338/10556 [00:00<00:00, 83375.71it/s]100%|| 10556/10556 [00:00<00:00, 89250.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123656.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6910/10556 [00:00<00:00, 67404.47it/s]100%|| 10556/10556 [00:00<00:00, 71839.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126916.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7506/10556 [00:00<00:00, 73539.25it/s]100%|| 10556/10556 [00:00<00:00, 79538.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109043.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9477/10556 [00:00<00:00, 94764.44it/s]100%|| 10556/10556 [00:00<00:00, 96993.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5390/10556 [00:00<00:00, 52701.84it/s]100%|| 10556/10556 [00:00<00:00, 55766.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106793.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5266/10556 [00:00<00:00, 52655.41it/s]100%|| 10556/10556 [00:00<00:00, 54525.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4773/10556 [00:00<00:00, 47064.08it/s] 97%|| 10219/10556 [00:00<00:00, 49062.96it/s]100%|| 10556/10556 [00:00<00:00, 51620.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7790/10556 [00:00<00:00, 77892.27it/s]100%|| 10556/10556 [00:00<00:00, 84459.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5876/10556 [00:00<00:00, 55944.11it/s]100%|| 10556/10556 [00:00<00:00, 57043.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6132/10556 [00:00<00:00, 61315.38it/s]100%|| 10556/10556 [00:00<00:00, 75250.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10483/10556 [00:00<00:00, 104829.85it/s]100%|| 10556/10556 [00:00<00:00, 104491.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4157/10556 [00:00<00:00, 41357.25it/s] 84%| | 8867/10556 [00:00<00:00, 42925.67it/s]100%|| 10556/10556 [00:00<00:00, 43863.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9597/10556 [00:00<00:00, 93462.78it/s]100%|| 10556/10556 [00:00<00:00, 79997.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7742/10556 [00:00<00:00, 71249.94it/s]100%|| 10556/10556 [00:00<00:00, 51435.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126373.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7494/10556 [00:00<00:00, 74934.53it/s]100%|| 10556/10556 [00:00<00:00, 79961.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109418.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8676/10556 [00:00<00:00, 86753.88it/s]100%|| 10556/10556 [00:00<00:00, 88864.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6417/10556 [00:00<00:00, 64167.15it/s]100%|| 10556/10556 [00:00<00:00, 66940.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7073/10556 [00:00<00:00, 66633.08it/s]100%|| 10556/10556 [00:00<00:00, 64224.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6509/10556 [00:00<00:00, 64128.51it/s]100%|| 10556/10556 [00:00<00:00, 59088.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7631/10556 [00:00<00:00, 76308.80it/s]100%|| 10556/10556 [00:00<00:00, 66771.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6871/10556 [00:00<00:00, 68705.64it/s]100%|| 10556/10556 [00:00<00:00, 68716.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9304/10556 [00:00<00:00, 93036.32it/s]100%|| 10556/10556 [00:00<00:00, 85593.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10120/10556 [00:00<00:00, 88120.20it/s]100%|| 10556/10556 [00:00<00:00, 88832.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6102/10556 [00:00<00:00, 61018.89it/s]100%|| 10556/10556 [00:00<00:00, 63736.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 27%|       | 2831/10556 [00:00<00:00, 27744.40it/s] 56%|    | 5933/10556 [00:00<00:00, 28525.69it/s] 93%|| 9765/10556 [00:00<00:00, 30893.86it/s]100%|| 10556/10556 [00:00<00:00, 31338.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3920/10556 [00:00<00:00, 34321.55it/s] 81%|  | 8523/10556 [00:00<00:00, 37156.25it/s]100%|| 10556/10556 [00:00<00:00, 42890.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8335/10556 [00:00<00:00, 83314.92it/s]100%|| 10556/10556 [00:00<00:00, 88285.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108113.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131115.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126524.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119133.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8064/10556 [00:00<00:00, 80637.96it/s]100%|| 10556/10556 [00:00<00:00, 88618.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107644.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8371/10556 [00:00<00:00, 83698.51it/s]100%|| 10556/10556 [00:00<00:00, 83615.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8630/10556 [00:00<00:00, 86298.23it/s]100%|| 10556/10556 [00:00<00:00, 85890.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7323/10556 [00:00<00:00, 73229.72it/s]100%|| 10556/10556 [00:00<00:00, 72853.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3905/10556 [00:00<00:00, 39046.22it/s]100%|| 10514/10556 [00:00<00:00, 44509.16it/s]100%|| 10556/10556 [00:00<00:00, 52524.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9744/10556 [00:00<00:00, 97433.12it/s]100%|| 10556/10556 [00:00<00:00, 99020.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5642/10556 [00:00<00:00, 51535.13it/s] 86%| | 9130/10556 [00:00<00:00, 45076.70it/s]100%|| 10556/10556 [00:00<00:00, 45237.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4617/10556 [00:00<00:00, 46166.19it/s] 98%|| 10364/10556 [00:00<00:00, 49057.00it/s]100%|| 10556/10556 [00:00<00:00, 51699.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121401.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6995/10556 [00:00<00:00, 69949.90it/s]100%|| 10556/10556 [00:00<00:00, 78249.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10354/10556 [00:00<00:00, 96847.82it/s]100%|| 10556/10556 [00:00<00:00, 96838.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5392/10556 [00:00<00:00, 53442.11it/s]100%|| 10556/10556 [00:00<00:00, 64385.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3856/10556 [00:00<00:00, 34099.31it/s] 96%|| 10135/10556 [00:00<00:00, 39515.79it/s]100%|| 10556/10556 [00:00<00:00, 47360.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6927/10556 [00:00<00:00, 69267.92it/s]100%|| 10556/10556 [00:00<00:00, 81281.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3818/10556 [00:00<00:00, 38178.94it/s] 93%|| 9798/10556 [00:00<00:00, 42823.18it/s]100%|| 10556/10556 [00:00<00:00, 50864.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8558/10556 [00:00<00:00, 85577.84it/s]100%|| 10556/10556 [00:00<00:00, 90327.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5029/10556 [00:00<00:00, 50285.73it/s]100%|| 10556/10556 [00:00<00:00, 54600.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6916/10556 [00:00<00:00, 69157.59it/s]100%|| 10556/10556 [00:00<00:00, 67276.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114878.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5805/10556 [00:00<00:00, 58049.78it/s]100%|| 10556/10556 [00:00<00:00, 58046.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4470/10556 [00:00<00:00, 44696.74it/s] 91%| | 9597/10556 [00:00<00:00, 46484.28it/s]100%|| 10556/10556 [00:00<00:00, 50782.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8495/10556 [00:00<00:00, 84949.47it/s]100%|| 10556/10556 [00:00<00:00, 87013.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108611.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113961.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115065.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10527/10556 [00:00<00:00, 105262.32it/s]100%|| 10556/10556 [00:00<00:00, 104895.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127683.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111830.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115688.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130399.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112781.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129772.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120847.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124851.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106221.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119311.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6793/10556 [00:00<00:00, 67924.56it/s]100%|| 10556/10556 [00:00<00:00, 67933.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6253/10556 [00:00<00:00, 62522.16it/s]100%|| 10556/10556 [00:00<00:00, 62889.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5182/10556 [00:00<00:00, 51812.76it/s]100%|| 10556/10556 [00:00<00:00, 56270.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 30%|       | 3210/10556 [00:00<00:00, 32095.59it/s] 95%|| 10066/10556 [00:00<00:00, 38188.71it/s]100%|| 10556/10556 [00:00<00:00, 50912.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3385/10556 [00:00<00:00, 33849.23it/s] 73%|  | 7715/10556 [00:00<00:00, 36220.83it/s]100%|| 10556/10556 [00:00<00:00, 42737.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8141/10556 [00:00<00:00, 81406.78it/s]100%|| 10556/10556 [00:00<00:00, 85514.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115149.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123647.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108717.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8124/10556 [00:00<00:00, 81234.46it/s]100%|| 10556/10556 [00:00<00:00, 79707.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 90232.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124136.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117903.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9366/10556 [00:00<00:00, 93658.97it/s]100%|| 10556/10556 [00:00<00:00, 88078.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10021/10556 [00:00<00:00, 100201.73it/s]100%|| 10556/10556 [00:00<00:00, 99706.06it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|      | 3442/10556 [00:00<00:00, 32302.86it/s] 86%| | 9109/10556 [00:00<00:00, 37072.48it/s]100%|| 10556/10556 [00:00<00:00, 43499.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8932/10556 [00:00<00:00, 89316.68it/s]100%|| 10556/10556 [00:00<00:00, 92021.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112078.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10205/10556 [00:00<00:00, 102049.12it/s]100%|| 10556/10556 [00:00<00:00, 102848.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124643.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116208.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6956/10556 [00:00<00:00, 69555.92it/s]100%|| 10556/10556 [00:00<00:00, 85141.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113069.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106373.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126106.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124793.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115906.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9432/10556 [00:00<00:00, 94316.04it/s]100%|| 10556/10556 [00:00<00:00, 96634.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113401.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122684.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125717.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144088.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145229.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113371.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120971.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10404/10556 [00:00<00:00, 104036.13it/s]100%|| 10556/10556 [00:00<00:00, 103595.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106225.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7365/10556 [00:00<00:00, 73649.37it/s]100%|| 10556/10556 [00:00<00:00, 71543.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7783/10556 [00:00<00:00, 77825.06it/s]100%|| 10556/10556 [00:00<00:00, 77446.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7698/10556 [00:00<00:00, 76979.89it/s]100%|| 10556/10556 [00:00<00:00, 77193.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7571/10556 [00:00<00:00, 75704.30it/s]100%|| 10556/10556 [00:00<00:00, 76289.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118886.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197614.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112736.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134049.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109112.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145273.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135921.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158446.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10289/10556 [00:00<00:00, 102879.31it/s]100%|| 10556/10556 [00:00<00:00, 96636.28it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116357.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113756.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117821.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108457.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111854.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129611.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167460.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10186/10556 [00:00<00:00, 101855.73it/s]100%|| 10556/10556 [00:00<00:00, 99412.56it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153459.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130089.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123783.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120831.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4256/10556 [00:00<00:00, 42559.03it/s]100%|| 10556/10556 [00:00<00:00, 78588.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171446.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136201.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117564.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174307.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139882.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127663.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158681.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169430.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172383.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123381.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136620.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6471/10556 [00:00<00:00, 64706.67it/s]100%|| 10556/10556 [00:00<00:00, 80888.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8623/10556 [00:00<00:00, 86225.35it/s]100%|| 10556/10556 [00:00<00:00, 91306.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10468/10556 [00:00<00:00, 104676.11it/s]100%|| 10556/10556 [00:00<00:00, 104404.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126746.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179328.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163804.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180384.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138738.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142871.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194527.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153472.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4425/10556 [00:00<00:00, 44246.35it/s]100%|| 10556/10556 [00:00<00:00, 55575.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4084/10556 [00:00<00:00, 40839.26it/s] 87%| | 9231/10556 [00:00<00:00, 43536.49it/s]100%|| 10556/10556 [00:00<00:00, 50902.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132022.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175548.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181921.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185304.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131161.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8160/10556 [00:00<00:00, 81597.35it/s]100%|| 10556/10556 [00:00<00:00, 71118.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8884/10556 [00:00<00:00, 88835.43it/s]100%|| 10556/10556 [00:00<00:00, 75844.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122013.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 30%|       | 3201/10556 [00:00<00:00, 28397.20it/s]100%|| 10556/10556 [00:00<00:00, 65310.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 96800.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127499.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129081.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105558.84it/s]100%|| 10556/10556 [00:00<00:00, 105136.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6530/10556 [00:00<00:00, 65020.87it/s]100%|| 10556/10556 [00:00<00:00, 78505.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4777/10556 [00:00<00:00, 47768.91it/s]100%|| 10556/10556 [00:00<00:00, 74821.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7412/10556 [00:00<00:00, 64683.63it/s]100%|| 10556/10556 [00:00<00:00, 59732.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128511.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149729.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5700/10556 [00:00<00:00, 56996.52it/s]100%|| 10556/10556 [00:00<00:00, 82169.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180772.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7058/10556 [00:00<00:00, 70574.18it/s]100%|| 10556/10556 [00:00<00:00, 69960.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183504.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167419.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185024.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122368.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150479.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7374/10556 [00:00<00:00, 72974.02it/s]100%|| 10556/10556 [00:00<00:00, 85139.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164746.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189874.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172208.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170318.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177350.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167807.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186750.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5626/10556 [00:00<00:00, 56256.97it/s]100%|| 10556/10556 [00:00<00:00, 74486.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129763.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178140.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173661.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183172.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176801.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179799.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183035.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182369.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187163.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182835.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192247.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200836.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200173.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191897.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195988.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192593.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185245.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188324.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187472.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189654.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179555.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6967/10556 [00:00<00:00, 69666.91it/s]100%|| 10556/10556 [00:00<00:00, 87780.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166581.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8404/10556 [00:00<00:00, 84036.27it/s]100%|| 10556/10556 [00:00<00:00, 89844.81it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '4.20655'}; time used = 0.923539400100708s
epoch 10: {'train_loss': '3.21208'}; time used = 0.704254150390625s
epoch 15: {'train_loss': '2.91717'}; time used = 0.726630687713623s
epoch 20: {'train_loss': '2.73576'}; time used = 0.9149816036224365s
epoch 25: {'train_loss': '2.74997'}; time used = 0.8885321617126465s
epoch 30: {'train_loss': '2.64226'}; time used = 0.771064043045044s
epoch 35: {'train_loss': '2.50298'}; time used = 0.8906662464141846s
epoch 40: {'train_loss': '2.27733'}; time used = 0.7336289882659912s
epoch 45: {'train_loss': '2.18915'}; time used = 0.794269323348999s
epoch 50: {'train_loss': '2.08142'}; time used = 0.7099316120147705s
epoch 55: {'train_loss': '1.94612'}; time used = 0.7201428413391113s
epoch 60: {'train_loss': '1.87293'}; time used = 0.7314834594726562s
epoch 65: {'train_loss': '1.78251'}; time used = 0.7612614631652832s
epoch 70: {'train_loss': '1.69717'}; time used = 0.6442418098449707s
epoch 75: {'train_loss': '1.62454'}; time used = 0.8166885375976562s
epoch 80: {'train_loss': '1.58495'}; time used = 0.5254008769989014s
epoch 85: {'train_loss': '1.48744'}; time used = 0.8705005645751953s
epoch 90: {'train_loss': '1.45056'}; time used = 0.7487037181854248s
epoch 95: {'train_loss': '1.39410'}; time used = 0.723663330078125s
epoch 100: {'train_loss': '1.35000'}; time used = 0.5794413089752197s
epoch 105: {'train_loss': '1.29505'}; time used = 0.6517794132232666s
epoch 110: {'train_loss': '1.27053'}; time used = 0.5810050964355469s
epoch 115: {'train_loss': '1.23450'}; time used = 0.5812115669250488s
epoch 120: {'train_loss': '1.19019'}; time used = 0.69454026222229s
epoch 125: {'train_loss': '1.16140'}; time used = 0.7287693023681641s
epoch 130: {'train_loss': '1.11255'}; time used = 0.9228856563568115s
epoch 135: {'train_loss': '1.11574'}; time used = 0.9085178375244141s
epoch 140: {'train_loss': '1.06682'}; time used = 0.826695442199707s
epoch 145: {'train_loss': '1.04727'}; time used = 0.9659562110900879s
epoch 150: {'train_loss': '1.02100'}; time used = 1.1081523895263672s
epoch 155: {'train_loss': '0.98559'}; time used = 0.522813081741333s
epoch 160: {'train_loss': '0.99123'}; time used = 0.7529318332672119s
epoch 165: {'train_loss': '0.96915'}; time used = 0.8266339302062988s
epoch 170: {'train_loss': '0.96248'}; time used = 0.9130649566650391s
epoch 175: {'train_loss': '0.95256'}; time used = 0.829808235168457s
epoch 180: {'train_loss': '0.92681'}; time used = 0.7232263088226318s
epoch 185: {'train_loss': '0.92446'}; time used = 0.5246415138244629s
epoch 190: {'train_loss': '0.90783'}; time used = 0.5331406593322754s
epoch 195: {'train_loss': '0.92055'}; time used = 0.8620510101318359s
epoch 200: {'train_loss': '0.87918'}; time used = 0.7435235977172852s
epoch 205: {'train_loss': '0.89104'}; time used = 0.6117722988128662s
epoch 210: {'train_loss': '0.87363'}; time used = 0.7680120468139648s
epoch 215: {'train_loss': '0.87489'}; time used = 0.566657304763794s
epoch 220: {'train_loss': '0.87047'}; time used = 0.520758867263794s
epoch 225: {'train_loss': '0.86073'}; time used = 0.46468067169189453s
epoch 230: {'train_loss': '0.84734'}; time used = 0.6284592151641846s
epoch 235: {'train_loss': '0.83740'}; time used = 0.5678324699401855s
epoch 240: {'train_loss': '0.84412'}; time used = 0.48316073417663574s
epoch 245: {'train_loss': '0.83493'}; time used = 0.5608558654785156s
epoch 250: {'train_loss': '0.82977'}; time used = 0.46016931533813477s
epoch 255: {'train_loss': '0.82703'}; time used = 0.5012500286102295s
epoch 260: {'train_loss': '0.83075'}; time used = 0.4334254264831543s
epoch 265: {'train_loss': '0.82796'}; time used = 0.3952140808105469s
epoch 270: {'train_loss': '0.82103'}; time used = 0.5733964443206787s
epoch 275: {'train_loss': '0.81425'}; time used = 0.35535573959350586s
epoch 280: {'train_loss': '0.81454'}; time used = 0.6542410850524902s
epoch 285: {'train_loss': '0.80582'}; time used = 0.5481231212615967s
epoch 290: {'train_loss': '0.80253'}; time used = 0.6391298770904541s
epoch 295: {'train_loss': '0.80292'}; time used = 0.7121784687042236s
epoch 300: {'train_loss': '0.79872'}; time used = 0.5096657276153564s
epoch 305: {'train_loss': '0.79506'}; time used = 0.4600818157196045s
epoch 310: {'train_loss': '0.80680'}; time used = 0.33172106742858887s
epoch 315: {'train_loss': '0.79698'}; time used = 0.4409775733947754s
epoch 320: {'train_loss': '0.80076'}; time used = 0.32356786727905273s
epoch 325: {'train_loss': '0.79069'}; time used = 0.30284762382507324s
epoch 330: {'train_loss': '0.79171'}; time used = 0.3053910732269287s
epoch 335: {'train_loss': '0.79228'}; time used = 0.38445091247558594s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 59.07056951522827.
Training classifier using 20.00% nodes...
{'micro': 0.46746654360867557, 'macro': 0.39869526652148857, 'samples': 0.46746654360867557, 'weighted': 0.44546480925812154}
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5689/10556 [00:00<00:00, 56884.90it/s]100%|| 10556/10556 [00:00<00:00, 58632.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8876/10556 [00:00<00:00, 88758.60it/s]100%|| 10556/10556 [00:00<00:00, 92282.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8085/10556 [00:00<00:00, 80849.31it/s]100%|| 10556/10556 [00:00<00:00, 77294.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5581/10556 [00:00<00:00, 45126.73it/s] 89%| | 9368/10556 [00:00<00:00, 42672.97it/s]100%|| 10556/10556 [00:00<00:00, 42143.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8274/10556 [00:00<00:00, 82739.09it/s]100%|| 10556/10556 [00:00<00:00, 88230.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6371/10556 [00:00<00:00, 59672.56it/s] 97%|| 10207/10556 [00:00<00:00, 47411.39it/s]100%|| 10556/10556 [00:00<00:00, 44035.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5471/10556 [00:00<00:00, 53825.35it/s] 96%|| 10086/10556 [00:00<00:00, 51267.27it/s]100%|| 10556/10556 [00:00<00:00, 49302.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10379/10556 [00:00<00:00, 103783.42it/s]100%|| 10556/10556 [00:00<00:00, 103619.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7052/10556 [00:00<00:00, 69392.07it/s]100%|| 10556/10556 [00:00<00:00, 69115.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3939/10556 [00:00<00:00, 38207.28it/s] 94%|| 9918/10556 [00:00<00:00, 42847.30it/s]100%|| 10556/10556 [00:00<00:00, 50593.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122843.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114947.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8071/10556 [00:00<00:00, 80708.54it/s]100%|| 10556/10556 [00:00<00:00, 86442.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7304/10556 [00:00<00:00, 68461.60it/s]100%|| 10556/10556 [00:00<00:00, 58995.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6380/10556 [00:00<00:00, 63798.08it/s]100%|| 10556/10556 [00:00<00:00, 51464.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 28%|       | 2963/10556 [00:00<00:00, 28463.80it/s] 66%|   | 6943/10556 [00:00<00:00, 31060.67it/s]100%|| 10556/10556 [00:00<00:00, 36788.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4609/10556 [00:00<00:00, 46087.63it/s] 80%|  | 8471/10556 [00:00<00:00, 42762.78it/s]100%|| 10556/10556 [00:00<00:00, 40694.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4470/10556 [00:00<00:00, 44698.98it/s] 87%| | 9230/10556 [00:00<00:00, 45531.23it/s]100%|| 10556/10556 [00:00<00:00, 41544.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4936/10556 [00:00<00:00, 44476.28it/s] 89%| | 9362/10556 [00:00<00:00, 44410.99it/s]100%|| 10556/10556 [00:00<00:00, 38294.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|      | 3632/10556 [00:00<00:00, 29923.95it/s] 65%|   | 6848/10556 [00:00<00:00, 30438.70it/s]100%|| 10543/10556 [00:00<00:00, 31631.12it/s]100%|| 10556/10556 [00:00<00:00, 31982.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|       | 3046/10556 [00:00<00:00, 30459.30it/s] 61%|    | 6462/10556 [00:00<00:00, 31482.33it/s]100%|| 10556/10556 [00:00<00:00, 34432.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4231/10556 [00:00<00:00, 42305.40it/s] 81%|  | 8539/10556 [00:00<00:00, 42533.11it/s]100%|| 10556/10556 [00:00<00:00, 41292.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4792/10556 [00:00<00:00, 47543.49it/s] 85%| | 8959/10556 [00:00<00:00, 45352.06it/s]100%|| 10556/10556 [00:00<00:00, 43642.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5511/10556 [00:00<00:00, 52426.90it/s] 96%|| 10095/10556 [00:00<00:00, 48755.17it/s]100%|| 10556/10556 [00:00<00:00, 46608.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6956/10556 [00:00<00:00, 69558.08it/s]100%|| 10556/10556 [00:00<00:00, 63751.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4529/10556 [00:00<00:00, 36093.69it/s] 86%| | 9055/10556 [00:00<00:00, 38427.81it/s]100%|| 10556/10556 [00:00<00:00, 40592.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6120/10556 [00:00<00:00, 61198.75it/s]100%|| 10556/10556 [00:00<00:00, 58933.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6046/10556 [00:00<00:00, 60456.45it/s]100%|| 10556/10556 [00:00<00:00, 60502.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4986/10556 [00:00<00:00, 49857.55it/s] 67%|   | 7052/10556 [00:00<00:00, 34221.67it/s]100%|| 10556/10556 [00:00<00:00, 43395.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 22%|       | 2374/10556 [00:00<00:00, 23139.62it/s] 57%|    | 6008/10556 [00:00<00:00, 25911.56it/s] 96%|| 10170/10556 [00:00<00:00, 28854.56it/s]100%|| 10556/10556 [00:00<00:00, 33353.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6453/10556 [00:00<00:00, 64527.14it/s]100%|| 10556/10556 [00:00<00:00, 63003.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6484/10556 [00:00<00:00, 64836.97it/s]100%|| 10556/10556 [00:00<00:00, 63010.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6828/10556 [00:00<00:00, 63797.24it/s]100%|| 10556/10556 [00:00<00:00, 48621.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6884/10556 [00:00<00:00, 66027.11it/s]100%|| 10556/10556 [00:00<00:00, 64200.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6421/10556 [00:00<00:00, 64208.38it/s]100%|| 10556/10556 [00:00<00:00, 63055.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6472/10556 [00:00<00:00, 64717.75it/s]100%|| 10556/10556 [00:00<00:00, 63430.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6483/10556 [00:00<00:00, 64829.13it/s]100%|| 10556/10556 [00:00<00:00, 63104.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6798/10556 [00:00<00:00, 67977.63it/s]100%|| 10556/10556 [00:00<00:00, 63964.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6602/10556 [00:00<00:00, 66019.59it/s]100%|| 10556/10556 [00:00<00:00, 62769.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6475/10556 [00:00<00:00, 64749.60it/s]100%|| 10556/10556 [00:00<00:00, 62980.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6414/10556 [00:00<00:00, 54622.12it/s]100%|| 10556/10556 [00:00<00:00, 58879.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7233/10556 [00:00<00:00, 70679.81it/s]100%|| 10556/10556 [00:00<00:00, 67674.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6540/10556 [00:00<00:00, 65398.66it/s]100%|| 10556/10556 [00:00<00:00, 57566.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7279/10556 [00:00<00:00, 72454.08it/s]100%|| 10556/10556 [00:00<00:00, 68732.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5473/10556 [00:00<00:00, 40163.39it/s] 89%| | 9388/10556 [00:00<00:00, 39853.14it/s]100%|| 10556/10556 [00:00<00:00, 41120.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 23%|       | 2472/10556 [00:00<00:00, 24509.08it/s] 58%|    | 6102/10556 [00:00<00:00, 26859.20it/s] 94%|| 9879/10556 [00:00<00:00, 28692.93it/s]100%|| 10556/10556 [00:00<00:00, 31411.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7167/10556 [00:00<00:00, 71668.19it/s]100%|| 10556/10556 [00:00<00:00, 57345.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4346/10556 [00:00<00:00, 41801.27it/s]100%|| 10556/10556 [00:00<00:00, 51535.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7075/10556 [00:00<00:00, 70566.18it/s]100%|| 10556/10556 [00:00<00:00, 67630.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|      | 3635/10556 [00:00<00:00, 31432.94it/s] 79%|  | 8365/10556 [00:00<00:00, 34702.99it/s]100%|| 10556/10556 [00:00<00:00, 41655.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4765/10556 [00:00<00:00, 47647.32it/s] 76%|  | 8007/10556 [00:00<00:00, 41021.36it/s]100%|| 10556/10556 [00:00<00:00, 39644.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4195/10556 [00:00<00:00, 40674.80it/s] 78%|  | 8209/10556 [00:00<00:00, 38061.22it/s]100%|| 10556/10556 [00:00<00:00, 34366.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4787/10556 [00:00<00:00, 46316.13it/s] 84%| | 8900/10556 [00:00<00:00, 43399.21it/s]100%|| 10556/10556 [00:00<00:00, 43300.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3855/10556 [00:00<00:00, 35740.19it/s] 61%|   | 6491/10556 [00:00<00:00, 31953.14it/s]100%|| 10556/10556 [00:00<00:00, 34382.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4430/10556 [00:00<00:00, 44299.09it/s] 74%|  | 7802/10556 [00:00<00:00, 39267.51it/s]100%|| 10556/10556 [00:00<00:00, 34651.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 27%|       | 2833/10556 [00:00<00:00, 24292.21it/s] 72%|  | 7578/10556 [00:00<00:00, 27923.51it/s] 95%|| 10027/10556 [00:00<00:00, 26796.06it/s]100%|| 10556/10556 [00:00<00:00, 29354.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 19%|        | 1966/10556 [00:00<00:00, 18648.31it/s] 53%|    | 5615/10556 [00:00<00:00, 21853.53it/s] 88%| | 9251/10556 [00:00<00:00, 24824.48it/s]100%|| 10556/10556 [00:00<00:00, 29438.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4438/10556 [00:00<00:00, 38975.77it/s] 82%| | 8701/10556 [00:00<00:00, 40004.29it/s]100%|| 10556/10556 [00:00<00:00, 39759.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7558/10556 [00:00<00:00, 75578.81it/s]100%|| 10556/10556 [00:00<00:00, 66274.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4702/10556 [00:00<00:00, 41305.88it/s]100%|| 10556/10556 [00:00<00:00, 49360.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6199/10556 [00:00<00:00, 61989.76it/s]100%|| 10556/10556 [00:00<00:00, 60716.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6204/10556 [00:00<00:00, 62039.62it/s]100%|| 10556/10556 [00:00<00:00, 62063.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7133/10556 [00:00<00:00, 71329.05it/s]100%|| 10556/10556 [00:00<00:00, 63136.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5344/10556 [00:00<00:00, 47076.23it/s] 81%|  | 8571/10556 [00:00<00:00, 41274.41it/s]100%|| 10556/10556 [00:00<00:00, 40222.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5718/10556 [00:00<00:00, 57179.78it/s] 96%|| 10176/10556 [00:00<00:00, 50009.11it/s]100%|| 10556/10556 [00:00<00:00, 45238.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4129/10556 [00:00<00:00, 41286.20it/s] 74%|  | 7801/10556 [00:00<00:00, 39523.88it/s]100%|| 10556/10556 [00:00<00:00, 39121.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5401/10556 [00:00<00:00, 53461.08it/s]100%|| 10556/10556 [00:00<00:00, 57317.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4315/10556 [00:00<00:00, 41743.37it/s] 82%| | 8633/10556 [00:00<00:00, 42163.35it/s]100%|| 10556/10556 [00:00<00:00, 41674.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3396/10556 [00:00<00:00, 30392.21it/s] 81%|  | 8533/10556 [00:00<00:00, 34635.20it/s]100%|| 10556/10556 [00:00<00:00, 39270.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6400/10556 [00:00<00:00, 60303.20it/s]100%|| 10556/10556 [00:00<00:00, 56048.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5752/10556 [00:00<00:00, 57515.26it/s]100%|| 10556/10556 [00:00<00:00, 52183.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5043/10556 [00:00<00:00, 50261.68it/s] 79%|  | 8364/10556 [00:00<00:00, 43552.19it/s]100%|| 10556/10556 [00:00<00:00, 40926.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5878/10556 [00:00<00:00, 47619.65it/s] 98%|| 10325/10556 [00:00<00:00, 46627.77it/s]100%|| 10556/10556 [00:00<00:00, 44052.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4271/10556 [00:00<00:00, 39317.31it/s]100%|| 10556/10556 [00:00<00:00, 49056.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4697/10556 [00:00<00:00, 45249.00it/s] 74%|  | 7809/10556 [00:00<00:00, 37703.32it/s]100%|| 10556/10556 [00:00<00:00, 40070.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5873/10556 [00:00<00:00, 58727.26it/s]100%|| 10556/10556 [00:00<00:00, 52031.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 5006/10556 [00:00<00:00, 50057.18it/s] 93%|| 9840/10556 [00:00<00:00, 47642.79it/s]100%|| 10556/10556 [00:00<00:00, 44428.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4234/10556 [00:00<00:00, 42339.64it/s] 82%| | 8648/10556 [00:00<00:00, 42244.32it/s]100%|| 10556/10556 [00:00<00:00, 39441.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3880/10556 [00:00<00:00, 38798.46it/s] 83%| | 8739/10556 [00:00<00:00, 41106.01it/s]100%|| 10556/10556 [00:00<00:00, 41213.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5774/10556 [00:00<00:00, 56076.72it/s] 94%|| 9875/10556 [00:00<00:00, 50508.81it/s]100%|| 10556/10556 [00:00<00:00, 47111.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3720/10556 [00:00<00:00, 35391.28it/s] 85%| | 9015/10556 [00:00<00:00, 39300.71it/s]100%|| 10556/10556 [00:00<00:00, 42920.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 30%|       | 3133/10556 [00:00<00:00, 31327.27it/s] 54%|    | 5670/10556 [00:00<00:00, 28865.69it/s] 97%|| 10219/10556 [00:00<00:00, 32419.62it/s]100%|| 10556/10556 [00:00<00:00, 32790.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|      | 4043/10556 [00:00<00:00, 40427.34it/s] 73%|  | 7714/10556 [00:00<00:00, 39235.31it/s]100%|| 10556/10556 [00:00<00:00, 37873.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6301/10556 [00:00<00:00, 56864.91it/s]100%|| 10556/10556 [00:00<00:00, 53087.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5593/10556 [00:00<00:00, 54172.23it/s] 92%|| 9692/10556 [00:00<00:00, 49023.42it/s]100%|| 10556/10556 [00:00<00:00, 46025.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3408/10556 [00:00<00:00, 31141.95it/s] 59%|    | 6192/10556 [00:00<00:00, 29520.81it/s] 93%|| 9789/10556 [00:00<00:00, 31198.56it/s]100%|| 10556/10556 [00:00<00:00, 30418.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3754/10556 [00:00<00:00, 34166.41it/s] 68%|   | 7140/10556 [00:00<00:00, 33958.50it/s]100%|| 10556/10556 [00:00<00:00, 33642.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 28%|       | 3007/10556 [00:00<00:00, 24781.60it/s] 63%|   | 6602/10556 [00:00<00:00, 26338.99it/s] 95%|| 10008/10556 [00:00<00:00, 27955.13it/s]100%|| 10556/10556 [00:00<00:00, 29315.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3337/10556 [00:00<00:00, 29733.88it/s] 67%|   | 7061/10556 [00:00<00:00, 30729.77it/s] 99%|| 10420/10556 [00:00<00:00, 31528.02it/s]100%|| 10556/10556 [00:00<00:00, 32124.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3792/10556 [00:00<00:00, 33632.06it/s] 71%|  | 7531/10556 [00:00<00:00, 34677.64it/s] 99%|| 10474/10556 [00:00<00:00, 31293.96it/s]100%|| 10556/10556 [00:00<00:00, 31813.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 28%|       | 2998/10556 [00:00<00:00, 29691.07it/s] 64%|   | 6750/10556 [00:00<00:00, 31217.56it/s]100%|| 10556/10556 [00:00<00:00, 37304.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4501/10556 [00:00<00:00, 45008.43it/s] 78%|  | 8192/10556 [00:00<00:00, 42151.79it/s]100%|| 10556/10556 [00:00<00:00, 40890.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4584/10556 [00:00<00:00, 40547.24it/s] 79%|  | 8374/10556 [00:00<00:00, 39462.04it/s]100%|| 10556/10556 [00:00<00:00, 39766.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5122/10556 [00:00<00:00, 51219.19it/s] 76%|  | 8004/10556 [00:00<00:00, 40951.32it/s]100%|| 10556/10556 [00:00<00:00, 36729.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5038/10556 [00:00<00:00, 50377.53it/s] 85%| | 8966/10556 [00:00<00:00, 45440.44it/s]100%|| 10556/10556 [00:00<00:00, 44522.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4710/10556 [00:00<00:00, 47099.15it/s] 83%| | 8758/10556 [00:00<00:00, 44893.05it/s]100%|| 10556/10556 [00:00<00:00, 43423.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4589/10556 [00:00<00:00, 45888.95it/s] 91%| | 9613/10556 [00:00<00:00, 47113.00it/s]100%|| 10556/10556 [00:00<00:00, 46842.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3760/10556 [00:00<00:00, 36575.74it/s] 83%| | 8814/10556 [00:00<00:00, 39881.34it/s]100%|| 10556/10556 [00:00<00:00, 40894.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3805/10556 [00:00<00:00, 38047.77it/s] 64%|   | 6776/10556 [00:00<00:00, 34101.45it/s] 89%| | 9398/10556 [00:00<00:00, 30927.01it/s]100%|| 10556/10556 [00:00<00:00, 30265.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|      | 3585/10556 [00:00<00:00, 35848.15it/s] 79%|  | 8369/10556 [00:00<00:00, 38636.29it/s]100%|| 10556/10556 [00:00<00:00, 40544.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4106/10556 [00:00<00:00, 41021.90it/s] 74%|  | 7769/10556 [00:00<00:00, 37767.23it/s]100%|| 10556/10556 [00:00<00:00, 39106.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4349/10556 [00:00<00:00, 43486.83it/s] 73%|  | 7754/10556 [00:00<00:00, 37813.17it/s]100%|| 10556/10556 [00:00<00:00, 34867.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4723/10556 [00:00<00:00, 42959.87it/s] 86%| | 9059/10556 [00:00<00:00, 43078.35it/s]100%|| 10556/10556 [00:00<00:00, 43107.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5358/10556 [00:00<00:00, 53576.60it/s] 85%| | 8933/10556 [00:00<00:00, 46002.93it/s]100%|| 10556/10556 [00:00<00:00, 43989.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4561/10556 [00:00<00:00, 45607.76it/s] 85%| | 8977/10556 [00:00<00:00, 45161.82it/s]100%|| 10556/10556 [00:00<00:00, 43607.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5262/10556 [00:00<00:00, 48682.12it/s] 91%| | 9594/10556 [00:00<00:00, 46455.12it/s]100%|| 10556/10556 [00:00<00:00, 45040.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4480/10556 [00:00<00:00, 44798.12it/s] 85%| | 8968/10556 [00:00<00:00, 43792.89it/s]100%|| 10556/10556 [00:00<00:00, 40807.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4105/10556 [00:00<00:00, 41048.08it/s] 82%| | 8654/10556 [00:00<00:00, 42286.08it/s]100%|| 10556/10556 [00:00<00:00, 44493.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6926/10556 [00:00<00:00, 69256.60it/s]100%|| 10556/10556 [00:00<00:00, 59592.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|      | 3449/10556 [00:00<00:00, 32359.29it/s] 92%|| 9747/10556 [00:00<00:00, 37884.95it/s]100%|| 10556/10556 [00:00<00:00, 47018.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6210/10556 [00:00<00:00, 61943.96it/s]100%|| 10556/10556 [00:00<00:00, 60614.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6203/10556 [00:00<00:00, 62027.55it/s]100%|| 10556/10556 [00:00<00:00, 60034.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6249/10556 [00:00<00:00, 62486.19it/s]100%|| 10556/10556 [00:00<00:00, 60954.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6420/10556 [00:00<00:00, 63203.41it/s]100%|| 10556/10556 [00:00<00:00, 61402.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|    | 5410/10556 [00:00<00:00, 53517.32it/s] 75%|  | 7942/10556 [00:00<00:00, 40000.43it/s]100%|| 10556/10556 [00:00<00:00, 37461.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6606/10556 [00:00<00:00, 62548.42it/s]100%|| 10556/10556 [00:00<00:00, 51891.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5951/10556 [00:00<00:00, 58882.53it/s]100%|| 10556/10556 [00:00<00:00, 59240.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7685/10556 [00:00<00:00, 66504.14it/s]100%|| 10556/10556 [00:00<00:00, 53562.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7946/10556 [00:00<00:00, 79456.67it/s]100%|| 10556/10556 [00:00<00:00, 72819.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7025/10556 [00:00<00:00, 69115.04it/s]100%|| 10556/10556 [00:00<00:00, 65133.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7024/10556 [00:00<00:00, 64717.98it/s]100%|| 10556/10556 [00:00<00:00, 62623.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6263/10556 [00:00<00:00, 61807.78it/s]100%|| 10556/10556 [00:00<00:00, 60655.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6746/10556 [00:00<00:00, 62009.56it/s] 97%|| 10238/10556 [00:00<00:00, 49725.32it/s]100%|| 10556/10556 [00:00<00:00, 47766.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6284/10556 [00:00<00:00, 62837.51it/s]100%|| 10556/10556 [00:00<00:00, 61442.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7240/10556 [00:00<00:00, 72396.10it/s]100%|| 10556/10556 [00:00<00:00, 66310.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7155/10556 [00:00<00:00, 71549.39it/s]100%|| 10556/10556 [00:00<00:00, 64397.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6317/10556 [00:00<00:00, 63165.99it/s]100%|| 10556/10556 [00:00<00:00, 61610.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7117/10556 [00:00<00:00, 71167.18it/s]100%|| 10556/10556 [00:00<00:00, 67053.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6374/10556 [00:00<00:00, 63736.26it/s]100%|| 10556/10556 [00:00<00:00, 61851.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7360/10556 [00:00<00:00, 73597.96it/s]100%|| 10556/10556 [00:00<00:00, 66582.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6493/10556 [00:00<00:00, 64927.59it/s]100%|| 10556/10556 [00:00<00:00, 60498.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6396/10556 [00:00<00:00, 63956.55it/s]100%|| 10556/10556 [00:00<00:00, 62850.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|      | 3629/10556 [00:00<00:00, 32694.80it/s] 89%| | 9400/10556 [00:00<00:00, 37437.25it/s]100%|| 10556/10556 [00:00<00:00, 42617.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 30%|       | 3159/10556 [00:00<00:00, 31587.92it/s] 50%|     | 5276/10556 [00:00<00:00, 26377.88it/s] 71%|   | 7515/10556 [00:00<00:00, 24833.18it/s]100%|| 10556/10556 [00:00<00:00, 27955.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6551/10556 [00:00<00:00, 60585.83it/s]100%|| 10556/10556 [00:00<00:00, 60748.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7398/10556 [00:00<00:00, 70797.61it/s]100%|| 10556/10556 [00:00<00:00, 67929.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7493/10556 [00:00<00:00, 64510.40it/s]100%|| 10556/10556 [00:00<00:00, 46427.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4069/10556 [00:00<00:00, 40687.71it/s] 63%|   | 6611/10556 [00:00<00:00, 33552.83it/s]100%|| 10556/10556 [00:00<00:00, 34877.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6935/10556 [00:00<00:00, 69346.43it/s] 97%|| 10226/10556 [00:00<00:00, 48466.41it/s]100%|| 10556/10556 [00:00<00:00, 46811.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5552/10556 [00:00<00:00, 54776.43it/s]100%|| 10556/10556 [00:00<00:00, 57184.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6386/10556 [00:00<00:00, 63856.25it/s] 91%|| 9646/10556 [00:00<00:00, 47702.65it/s]100%|| 10556/10556 [00:00<00:00, 45700.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|      | 3987/10556 [00:00<00:00, 38216.22it/s] 81%|  | 8505/10556 [00:00<00:00, 40068.42it/s]100%|| 10556/10556 [00:00<00:00, 33234.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8772/10556 [00:00<00:00, 72316.87it/s]100%|| 10556/10556 [00:00<00:00, 49495.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4754/10556 [00:00<00:00, 47538.91it/s] 80%|  | 8397/10556 [00:00<00:00, 41037.94it/s]100%|| 10556/10556 [00:00<00:00, 39667.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 23%|       | 2389/10556 [00:00<00:00, 23888.31it/s]100%|| 10556/10556 [00:00<00:00, 53072.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5196/10556 [00:00<00:00, 51955.71it/s] 79%|  | 8357/10556 [00:00<00:00, 43103.38it/s]100%|| 10556/10556 [00:00<00:00, 35753.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6447/10556 [00:00<00:00, 63497.23it/s] 86%| | 9115/10556 [00:00<00:00, 44905.57it/s]100%|| 10556/10556 [00:00<00:00, 45405.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6462/10556 [00:00<00:00, 64616.52it/s]100%|| 10556/10556 [00:00<00:00, 62542.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5768/10556 [00:00<00:00, 52148.75it/s] 85%| | 8939/10556 [00:00<00:00, 43697.87it/s]100%|| 10556/10556 [00:00<00:00, 43461.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5145/10556 [00:00<00:00, 51448.82it/s] 91%| | 9628/10556 [00:00<00:00, 49265.75it/s]100%|| 10556/10556 [00:00<00:00, 46692.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4702/10556 [00:00<00:00, 47016.79it/s] 87%| | 9168/10556 [00:00<00:00, 46283.99it/s]100%|| 10556/10556 [00:00<00:00, 45100.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4596/10556 [00:00<00:00, 45959.06it/s] 87%| | 9185/10556 [00:00<00:00, 45938.04it/s]100%|| 10556/10556 [00:00<00:00, 44826.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4662/10556 [00:00<00:00, 46217.52it/s] 87%| | 9166/10556 [00:00<00:00, 45857.03it/s]100%|| 10556/10556 [00:00<00:00, 44527.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4227/10556 [00:00<00:00, 42266.82it/s] 83%| | 8731/10556 [00:00<00:00, 42458.35it/s]100%|| 10556/10556 [00:00<00:00, 43198.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|     | 4372/10556 [00:00<00:00, 42837.41it/s] 83%| | 8725/10556 [00:00<00:00, 43041.90it/s]100%|| 10556/10556 [00:00<00:00, 43039.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4508/10556 [00:00<00:00, 45077.89it/s] 85%| | 8980/10556 [00:00<00:00, 44968.68it/s]100%|| 10556/10556 [00:00<00:00, 43639.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4612/10556 [00:00<00:00, 46116.42it/s] 87%| | 9166/10556 [00:00<00:00, 45941.05it/s]100%|| 10556/10556 [00:00<00:00, 44629.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|     | 4364/10556 [00:00<00:00, 39744.26it/s] 83%| | 8714/10556 [00:00<00:00, 39209.84it/s]100%|| 10556/10556 [00:00<00:00, 38888.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3757/10556 [00:00<00:00, 32193.02it/s] 71%|   | 7464/10556 [00:00<00:00, 33441.56it/s]100%|| 10556/10556 [00:00<00:00, 36961.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4277/10556 [00:00<00:00, 42768.61it/s] 77%|  | 8118/10556 [00:00<00:00, 41208.72it/s]100%|| 10556/10556 [00:00<00:00, 40893.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4888/10556 [00:00<00:00, 37802.13it/s] 83%| | 8777/10556 [00:00<00:00, 37363.58it/s]100%|| 10556/10556 [00:00<00:00, 35212.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4263/10556 [00:00<00:00, 40933.86it/s] 79%|  | 8339/10556 [00:00<00:00, 40061.16it/s]100%|| 10556/10556 [00:00<00:00, 40265.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4872/10556 [00:00<00:00, 48715.40it/s] 65%|   | 6884/10556 [00:00<00:00, 33939.17it/s] 98%|| 10354/10556 [00:00<00:00, 34163.18it/s]100%|| 10556/10556 [00:00<00:00, 33807.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3332/10556 [00:00<00:00, 30792.43it/s] 60%|    | 6295/10556 [00:00<00:00, 30328.85it/s] 82%| | 8622/10556 [00:00<00:00, 27798.74it/s]100%|| 10556/10556 [00:00<00:00, 26949.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3372/10556 [00:00<00:00, 33717.62it/s] 49%|     | 5126/10556 [00:00<00:00, 25547.53it/s] 88%| | 9256/10556 [00:00<00:00, 28320.40it/s]100%|| 10556/10556 [00:00<00:00, 31453.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5645/10556 [00:00<00:00, 52304.06it/s]100%|| 10556/10556 [00:00<00:00, 57078.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6431/10556 [00:00<00:00, 58852.36it/s]100%|| 10556/10556 [00:00<00:00, 65879.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7431/10556 [00:00<00:00, 74307.06it/s]100%|| 10556/10556 [00:00<00:00, 77218.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8009/10556 [00:00<00:00, 80084.54it/s]100%|| 10556/10556 [00:00<00:00, 67488.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5922/10556 [00:00<00:00, 56077.33it/s] 83%| | 8745/10556 [00:00<00:00, 43269.13it/s]100%|| 10556/10556 [00:00<00:00, 43079.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 26%|       | 2746/10556 [00:00<00:00, 26296.70it/s] 91%| | 9607/10556 [00:00<00:00, 32265.20it/s]100%|| 10556/10556 [00:00<00:00, 48757.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8078/10556 [00:00<00:00, 80777.19it/s]100%|| 10556/10556 [00:00<00:00, 87534.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6781/10556 [00:00<00:00, 67803.60it/s]100%|| 10556/10556 [00:00<00:00, 61062.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7955/10556 [00:00<00:00, 79549.32it/s]100%|| 10556/10556 [00:00<00:00, 86063.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 104137.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6509/10556 [00:00<00:00, 65088.98it/s]100%|| 10556/10556 [00:00<00:00, 67053.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6043/10556 [00:00<00:00, 60427.18it/s]100%|| 10556/10556 [00:00<00:00, 60120.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9260/10556 [00:00<00:00, 92599.43it/s]100%|| 10556/10556 [00:00<00:00, 95124.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10242/10556 [00:00<00:00, 102418.39it/s]100%|| 10556/10556 [00:00<00:00, 102506.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6409/10556 [00:00<00:00, 64088.38it/s]100%|| 10556/10556 [00:00<00:00, 69190.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7252/10556 [00:00<00:00, 72519.03it/s]100%|| 10556/10556 [00:00<00:00, 81371.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4962/10556 [00:00<00:00, 47875.58it/s]100%|| 10556/10556 [00:00<00:00, 55380.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9571/10556 [00:00<00:00, 95703.93it/s]100%|| 10556/10556 [00:00<00:00, 96474.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6981/10556 [00:00<00:00, 69804.41it/s]100%|| 10556/10556 [00:00<00:00, 79285.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5387/10556 [00:00<00:00, 53543.50it/s] 94%|| 9959/10556 [00:00<00:00, 49652.02it/s]100%|| 10556/10556 [00:00<00:00, 47723.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5128/10556 [00:00<00:00, 44736.92it/s] 98%|| 10390/10556 [00:00<00:00, 46732.91it/s]100%|| 10556/10556 [00:00<00:00, 48210.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10438/10556 [00:00<00:00, 104372.39it/s]100%|| 10556/10556 [00:00<00:00, 104139.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6468/10556 [00:00<00:00, 64078.74it/s]100%|| 10556/10556 [00:00<00:00, 62211.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8481/10556 [00:00<00:00, 84805.63it/s]100%|| 10556/10556 [00:00<00:00, 89873.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7018/10556 [00:00<00:00, 70176.55it/s]100%|| 10556/10556 [00:00<00:00, 64031.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6670/10556 [00:00<00:00, 64495.77it/s]100%|| 10556/10556 [00:00<00:00, 59021.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6274/10556 [00:00<00:00, 62739.01it/s]100%|| 10556/10556 [00:00<00:00, 74739.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118487.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 103777.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7346/10556 [00:00<00:00, 73457.44it/s]100%|| 10556/10556 [00:00<00:00, 82896.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115184.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119921.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10358/10556 [00:00<00:00, 101069.21it/s]100%|| 10556/10556 [00:00<00:00, 101308.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9778/10556 [00:00<00:00, 97771.93it/s]100%|| 10556/10556 [00:00<00:00, 98628.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9312/10556 [00:00<00:00, 93115.43it/s]100%|| 10556/10556 [00:00<00:00, 95012.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5446/10556 [00:00<00:00, 53395.78it/s]100%|| 10556/10556 [00:00<00:00, 67731.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115292.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120541.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119928.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10000/10556 [00:00<00:00, 99998.19it/s]100%|| 10556/10556 [00:00<00:00, 100268.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106251.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10548/10556 [00:00<00:00, 105479.60it/s]100%|| 10556/10556 [00:00<00:00, 105126.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 9012/10556 [00:00<00:00, 90117.08it/s]100%|| 10556/10556 [00:00<00:00, 93287.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8763/10556 [00:00<00:00, 86173.42it/s]100%|| 10556/10556 [00:00<00:00, 88416.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6375/10556 [00:00<00:00, 63744.44it/s]100%|| 10556/10556 [00:00<00:00, 53342.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8828/10556 [00:00<00:00, 86669.76it/s]100%|| 10556/10556 [00:00<00:00, 90558.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8560/10556 [00:00<00:00, 85598.45it/s]100%|| 10556/10556 [00:00<00:00, 89970.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111159.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6052/10556 [00:00<00:00, 58064.34it/s]100%|| 10556/10556 [00:00<00:00, 63392.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5730/10556 [00:00<00:00, 57298.42it/s]100%|| 10556/10556 [00:00<00:00, 72078.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5666/10556 [00:00<00:00, 55775.48it/s] 94%|| 9946/10556 [00:00<00:00, 49994.55it/s]100%|| 10556/10556 [00:00<00:00, 47384.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119176.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5555/10556 [00:00<00:00, 50805.96it/s]100%|| 10556/10556 [00:00<00:00, 52544.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6197/10556 [00:00<00:00, 61967.84it/s]100%|| 10556/10556 [00:00<00:00, 75716.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4870/10556 [00:00<00:00, 48698.65it/s]100%|| 10556/10556 [00:00<00:00, 63312.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123529.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107234.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10446/10556 [00:00<00:00, 104458.36it/s]100%|| 10556/10556 [00:00<00:00, 92265.11it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7371/10556 [00:00<00:00, 66020.79it/s]100%|| 10556/10556 [00:00<00:00, 65760.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7146/10556 [00:00<00:00, 71458.19it/s]100%|| 10556/10556 [00:00<00:00, 82784.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117064.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10328/10556 [00:00<00:00, 103275.42it/s]100%|| 10556/10556 [00:00<00:00, 103301.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120138.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121121.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120364.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120848.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114680.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7923/10556 [00:00<00:00, 79228.75it/s]100%|| 10556/10556 [00:00<00:00, 85587.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8464/10556 [00:00<00:00, 84635.44it/s]100%|| 10556/10556 [00:00<00:00, 77684.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6572/10556 [00:00<00:00, 65718.03it/s]100%|| 10556/10556 [00:00<00:00, 60530.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7440/10556 [00:00<00:00, 74397.41it/s]100%|| 10556/10556 [00:00<00:00, 73731.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112388.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116028.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7473/10556 [00:00<00:00, 74725.97it/s]100%|| 10556/10556 [00:00<00:00, 83507.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111615.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113298.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10090/10556 [00:00<00:00, 100896.25it/s]100%|| 10556/10556 [00:00<00:00, 101211.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7180/10556 [00:00<00:00, 66583.47it/s]100%|| 10556/10556 [00:00<00:00, 59292.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6056/10556 [00:00<00:00, 60399.49it/s]100%|| 10556/10556 [00:00<00:00, 55695.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6016/10556 [00:00<00:00, 59752.33it/s]100%|| 10556/10556 [00:00<00:00, 75216.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116776.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8191/10556 [00:00<00:00, 81291.04it/s]100%|| 10556/10556 [00:00<00:00, 76868.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110600.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 7974/10556 [00:00<00:00, 79713.28it/s]100%|| 10556/10556 [00:00<00:00, 79361.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9351/10556 [00:00<00:00, 93505.63it/s]100%|| 10556/10556 [00:00<00:00, 90883.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 9992/10556 [00:00<00:00, 99918.67it/s]100%|| 10556/10556 [00:00<00:00, 100197.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6587/10556 [00:00<00:00, 65868.96it/s]100%|| 10556/10556 [00:00<00:00, 81017.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108228.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 97173.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6813/10556 [00:00<00:00, 68129.74it/s]100%|| 10556/10556 [00:00<00:00, 77249.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129979.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7335/10556 [00:00<00:00, 72460.36it/s]100%|| 10556/10556 [00:00<00:00, 82542.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5785/10556 [00:00<00:00, 55006.80it/s]100%|| 10556/10556 [00:00<00:00, 72762.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5371/10556 [00:00<00:00, 53706.47it/s]100%|| 10556/10556 [00:00<00:00, 62277.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8700/10556 [00:00<00:00, 82410.46it/s]100%|| 10556/10556 [00:00<00:00, 87474.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7078/10556 [00:00<00:00, 70775.01it/s]100%|| 10556/10556 [00:00<00:00, 65727.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4931/10556 [00:00<00:00, 49305.58it/s]100%|| 10556/10556 [00:00<00:00, 55528.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9672/10556 [00:00<00:00, 96715.71it/s]100%|| 10556/10556 [00:00<00:00, 94562.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6693/10556 [00:00<00:00, 66925.28it/s]100%|| 10556/10556 [00:00<00:00, 73429.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10469/10556 [00:00<00:00, 104682.86it/s]100%|| 10556/10556 [00:00<00:00, 104294.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6630/10556 [00:00<00:00, 61843.63it/s]100%|| 10556/10556 [00:00<00:00, 68303.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8216/10556 [00:00<00:00, 82156.36it/s]100%|| 10556/10556 [00:00<00:00, 88410.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5078/10556 [00:00<00:00, 45134.93it/s]100%|| 10556/10556 [00:00<00:00, 49467.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5782/10556 [00:00<00:00, 57815.92it/s]100%|| 10556/10556 [00:00<00:00, 75736.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6296/10556 [00:00<00:00, 62955.41it/s]100%|| 10556/10556 [00:00<00:00, 60534.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5587/10556 [00:00<00:00, 55867.12it/s]100%|| 10556/10556 [00:00<00:00, 74354.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9051/10556 [00:00<00:00, 90506.85it/s]100%|| 10556/10556 [00:00<00:00, 93435.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119975.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8816/10556 [00:00<00:00, 88158.82it/s]100%|| 10556/10556 [00:00<00:00, 92369.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5505/10556 [00:00<00:00, 50971.08it/s] 82%| | 8691/10556 [00:00<00:00, 42470.51it/s]100%|| 10556/10556 [00:00<00:00, 41479.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4906/10556 [00:00<00:00, 49059.93it/s] 73%|  | 7663/10556 [00:00<00:00, 39761.62it/s] 98%|| 10360/10556 [00:00<00:00, 33870.55it/s]100%|| 10556/10556 [00:00<00:00, 34154.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5382/10556 [00:00<00:00, 49549.90it/s] 95%|| 9996/10556 [00:00<00:00, 48291.95it/s]100%|| 10556/10556 [00:00<00:00, 47558.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3691/10556 [00:00<00:00, 34081.11it/s]100%|| 10556/10556 [00:00<00:00, 62168.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4197/10556 [00:00<00:00, 39351.13it/s]100%|| 10556/10556 [00:00<00:00, 59658.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4640/10556 [00:00<00:00, 46397.61it/s]100%|| 10556/10556 [00:00<00:00, 68634.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5578/10556 [00:00<00:00, 55775.66it/s]100%|| 10556/10556 [00:00<00:00, 74332.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8355/10556 [00:00<00:00, 81628.62it/s]100%|| 10556/10556 [00:00<00:00, 70422.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9592/10556 [00:00<00:00, 95919.41it/s]100%|| 10556/10556 [00:00<00:00, 97081.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4789/10556 [00:00<00:00, 47886.39it/s] 80%|  | 8495/10556 [00:00<00:00, 44027.61it/s]100%|| 10556/10556 [00:00<00:00, 41139.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5733/10556 [00:00<00:00, 57326.09it/s] 94%|| 9933/10556 [00:00<00:00, 51481.09it/s]100%|| 10556/10556 [00:00<00:00, 51104.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8223/10556 [00:00<00:00, 75054.10it/s]100%|| 10556/10556 [00:00<00:00, 54611.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7919/10556 [00:00<00:00, 74026.09it/s]100%|| 10556/10556 [00:00<00:00, 61621.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7147/10556 [00:00<00:00, 64395.37it/s]100%|| 10556/10556 [00:00<00:00, 61733.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8097/10556 [00:00<00:00, 80967.95it/s]100%|| 10556/10556 [00:00<00:00, 81738.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131603.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176688.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161704.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4160/10556 [00:00<00:00, 41598.35it/s]100%|| 10556/10556 [00:00<00:00, 73650.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8335/10556 [00:00<00:00, 83349.68it/s]100%|| 10556/10556 [00:00<00:00, 90424.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123887.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134484.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172625.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174181.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147054.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109677.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7946/10556 [00:00<00:00, 79454.77it/s]100%|| 10556/10556 [00:00<00:00, 80777.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8608/10556 [00:00<00:00, 86074.95it/s]100%|| 10556/10556 [00:00<00:00, 88928.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144101.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142543.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167900.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174366.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119840.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171685.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170830.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166458.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173780.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166019.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177213.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109009.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9739/10556 [00:00<00:00, 96694.10it/s]100%|| 10556/10556 [00:00<00:00, 88503.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141409.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167071.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175476.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167623.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127174.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117137.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131444.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%| | 8594/10556 [00:00<00:00, 83702.78it/s]100%|| 10556/10556 [00:00<00:00, 73474.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150436.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185378.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184068.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130333.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10182/10556 [00:00<00:00, 101813.54it/s]100%|| 10556/10556 [00:00<00:00, 92913.16it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8237/10556 [00:00<00:00, 82366.35it/s]100%|| 10556/10556 [00:00<00:00, 92602.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145204.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8021/10556 [00:00<00:00, 80205.10it/s]100%|| 10556/10556 [00:00<00:00, 78623.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127349.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154721.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10424/10556 [00:00<00:00, 104233.39it/s]100%|| 10556/10556 [00:00<00:00, 100861.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6495/10556 [00:00<00:00, 64949.91it/s]100%|| 10556/10556 [00:00<00:00, 65813.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126154.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167955.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184537.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172160.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10263/10556 [00:00<00:00, 98680.12it/s]100%|| 10556/10556 [00:00<00:00, 82324.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127147.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150084.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168104.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168494.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139525.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129599.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172377.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146508.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112431.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142636.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124250.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142206.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108931.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117650.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166129.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175870.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145135.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9406/10556 [00:00<00:00, 94056.73it/s]100%|| 10556/10556 [00:00<00:00, 98815.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|| 9654/10556 [00:00<00:00, 92084.60it/s]100%|| 10556/10556 [00:00<00:00, 88198.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144618.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173629.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168275.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170351.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173733.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115582.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7438/10556 [00:00<00:00, 74378.47it/s]100%|| 10556/10556 [00:00<00:00, 89905.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173261.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170455.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167895.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173431.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140445.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150539.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6132/10556 [00:00<00:00, 53061.02it/s]100%|| 10556/10556 [00:00<00:00, 67783.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186265.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174118.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123798.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120778.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121516.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131337.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141554.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6615/10556 [00:00<00:00, 66148.64it/s]100%|| 10556/10556 [00:00<00:00, 65862.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 9022/10556 [00:00<00:00, 90210.19it/s]100%|| 10556/10556 [00:00<00:00, 94812.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123225.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10151/10556 [00:00<00:00, 101505.26it/s]100%|| 10556/10556 [00:00<00:00, 98972.99it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123855.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153338.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7006/10556 [00:00<00:00, 70056.23it/s]100%|| 10556/10556 [00:00<00:00, 84680.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9803/10556 [00:00<00:00, 98022.38it/s]100%|| 10556/10556 [00:00<00:00, 98984.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115540.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154583.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120914.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116863.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146516.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175138.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158857.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149350.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132201.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143578.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9067/10556 [00:00<00:00, 90668.14it/s]100%|| 10556/10556 [00:00<00:00, 59500.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151720.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144051.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113123.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8046/10556 [00:00<00:00, 80456.24it/s]100%|| 10556/10556 [00:00<00:00, 85631.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112603.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122157.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181579.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106158.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6425/10556 [00:00<00:00, 64245.77it/s] 94%|| 9957/10556 [00:00<00:00, 51573.71it/s]100%|| 10556/10556 [00:00<00:00, 51448.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110942.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4689/10556 [00:00<00:00, 44722.74it/s] 89%| | 9400/10556 [00:00<00:00, 45220.66it/s]100%|| 10556/10556 [00:00<00:00, 48197.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6887/10556 [00:00<00:00, 68865.47it/s]100%|| 10556/10556 [00:00<00:00, 70867.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121074.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166749.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7597/10556 [00:00<00:00, 75966.27it/s]100%|| 10556/10556 [00:00<00:00, 85132.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5822/10556 [00:00<00:00, 54870.25it/s]100%|| 10556/10556 [00:00<00:00, 70421.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8759/10556 [00:00<00:00, 76614.56it/s]100%|| 10556/10556 [00:00<00:00, 73695.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115558.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7487/10556 [00:00<00:00, 74865.79it/s]100%|| 10556/10556 [00:00<00:00, 69136.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110532.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7255/10556 [00:00<00:00, 68196.01it/s]100%|| 10556/10556 [00:00<00:00, 71069.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129197.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151525.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9508/10556 [00:00<00:00, 95075.33it/s]100%|| 10556/10556 [00:00<00:00, 86455.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8332/10556 [00:00<00:00, 83318.09it/s]100%|| 10556/10556 [00:00<00:00, 91169.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156544.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155023.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123375.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123115.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121481.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144405.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175837.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176775.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165850.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168968.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168250.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172822.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171137.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163908.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167145.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172611.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172975.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156017.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129550.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142307.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146006.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149903.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148954.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140640.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147536.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140654.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|    | 5425/10556 [00:00<00:00, 54245.14it/s] 97%|| 10229/10556 [00:00<00:00, 51594.41it/s]100%|| 10556/10556 [00:00<00:00, 49995.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137742.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144216.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7634/10556 [00:00<00:00, 74831.07it/s]100%|| 10556/10556 [00:00<00:00, 62682.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10506/10556 [00:00<00:00, 105053.84it/s]100%|| 10556/10556 [00:00<00:00, 104918.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147287.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145567.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4654/10556 [00:00<00:00, 45571.10it/s]100%|| 10556/10556 [00:00<00:00, 61902.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154485.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178662.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5953/10556 [00:00<00:00, 54019.53it/s]100%|| 10556/10556 [00:00<00:00, 60960.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10401/10556 [00:00<00:00, 104008.86it/s]100%|| 10556/10556 [00:00<00:00, 104550.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115541.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9108/10556 [00:00<00:00, 91067.49it/s]100%|| 10556/10556 [00:00<00:00, 89888.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8885/10556 [00:00<00:00, 88846.91it/s]100%|| 10556/10556 [00:00<00:00, 88463.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9759/10556 [00:00<00:00, 97587.07it/s]100%|| 10556/10556 [00:00<00:00, 91315.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121510.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146887.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152094.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170004.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171526.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175575.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175168.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114172.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108636.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160851.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174098.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169590.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171830.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172563.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172088.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169169.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171043.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172592.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168228.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6913/10556 [00:00<00:00, 68128.52it/s]100%|| 10556/10556 [00:00<00:00, 71914.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158233.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10288/10556 [00:00<00:00, 98042.60it/s]100%|| 10556/10556 [00:00<00:00, 93238.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8509/10556 [00:00<00:00, 85088.26it/s]100%|| 10556/10556 [00:00<00:00, 90410.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113774.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111445.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111813.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111335.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114400.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6773/10556 [00:00<00:00, 67152.57it/s]100%|| 10556/10556 [00:00<00:00, 58072.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9536/10556 [00:00<00:00, 95353.50it/s]100%|| 10556/10556 [00:00<00:00, 97050.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111767.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123114.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5398/10556 [00:00<00:00, 53977.22it/s]100%|| 10556/10556 [00:00<00:00, 62110.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174784.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166126.01it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '6.41292'}; time used = 1.016770601272583s
epoch 10: {'train_loss': '6.32878'}; time used = 0.8472909927368164s
epoch 15: {'train_loss': '6.16862'}; time used = 0.94576096534729s
epoch 20: {'train_loss': '5.97722'}; time used = 1.5096616744995117s
epoch 25: {'train_loss': '6.04750'}; time used = 1.2420570850372314s
epoch 30: {'train_loss': '5.96511'}; time used = 1.1467680931091309s
epoch 35: {'train_loss': '5.82590'}; time used = 0.9483234882354736s
epoch 40: {'train_loss': '5.63698'}; time used = 0.9020466804504395s
epoch 45: {'train_loss': '5.53123'}; time used = 1.1951534748077393s
epoch 50: {'train_loss': '5.44339'}; time used = 1.16811203956604s
epoch 55: {'train_loss': '5.26437'}; time used = 1.6258845329284668s
epoch 60: {'train_loss': '5.20667'}; time used = 1.2425994873046875s
epoch 65: {'train_loss': '5.12553'}; time used = 1.1807525157928467s
epoch 70: {'train_loss': '5.02510'}; time used = 1.1829829216003418s
epoch 75: {'train_loss': '4.89522'}; time used = 1.2930238246917725s
epoch 80: {'train_loss': '4.92565'}; time used = 1.3167154788970947s
epoch 85: {'train_loss': '4.77256'}; time used = 1.4631142616271973s
epoch 90: {'train_loss': '4.74197'}; time used = 1.6965782642364502s
epoch 95: {'train_loss': '4.64861'}; time used = 1.3585174083709717s
epoch 100: {'train_loss': '4.56097'}; time used = 1.436748743057251s
epoch 105: {'train_loss': '4.53692'}; time used = 1.3784596920013428s
epoch 110: {'train_loss': '4.44792'}; time used = 1.164675235748291s
epoch 115: {'train_loss': '4.41941'}; time used = 1.0699503421783447s
epoch 120: {'train_loss': '4.38917'}; time used = 0.966254711151123s
epoch 125: {'train_loss': '4.27180'}; time used = 0.9855151176452637s
epoch 130: {'train_loss': '4.15518'}; time used = 0.9100968837738037s
epoch 135: {'train_loss': '4.20996'}; time used = 1.1932947635650635s
epoch 140: {'train_loss': '4.11664'}; time used = 1.2666490077972412s
epoch 145: {'train_loss': '4.03713'}; time used = 1.3892886638641357s
epoch 150: {'train_loss': '3.96283'}; time used = 1.173901081085205s
epoch 155: {'train_loss': '3.84671'}; time used = 1.262965202331543s
epoch 160: {'train_loss': '3.90853'}; time used = 1.4316601753234863s
epoch 165: {'train_loss': '3.81573'}; time used = 1.5768568515777588s
epoch 170: {'train_loss': '3.85392'}; time used = 1.0111041069030762s
epoch 175: {'train_loss': '3.78300'}; time used = 0.7597496509552002s
epoch 180: {'train_loss': '3.73822'}; time used = 0.7496998310089111s
epoch 185: {'train_loss': '3.67708'}; time used = 0.9534225463867188s
epoch 190: {'train_loss': '3.69467'}; time used = 0.8200480937957764s
epoch 195: {'train_loss': '3.64069'}; time used = 0.6093590259552002s
epoch 200: {'train_loss': '3.57374'}; time used = 0.6344685554504395s
epoch 205: {'train_loss': '3.55726'}; time used = 0.5107090473175049s
epoch 210: {'train_loss': '3.55672'}; time used = 0.7319777011871338s
epoch 215: {'train_loss': '3.56761'}; time used = 0.8393433094024658s
epoch 220: {'train_loss': '3.53321'}; time used = 0.7515246868133545s
epoch 225: {'train_loss': '3.48333'}; time used = 0.6578369140625s
epoch 230: {'train_loss': '3.41455'}; time used = 0.48285341262817383s
epoch 235: {'train_loss': '3.26345'}; time used = 0.7276046276092529s
epoch 240: {'train_loss': '3.39026'}; time used = 0.553152322769165s
epoch 245: {'train_loss': '3.39396'}; time used = 0.7616333961486816s
epoch 250: {'train_loss': '3.33486'}; time used = 0.6639189720153809s
epoch 255: {'train_loss': '3.39734'}; time used = 0.613412618637085s
epoch 260: {'train_loss': '3.32800'}; time used = 0.8127450942993164s
epoch 265: {'train_loss': '3.30721'}; time used = 0.7695281505584717s
epoch 270: {'train_loss': '3.25989'}; time used = 0.8568451404571533s
epoch 275: {'train_loss': '3.23027'}; time used = 0.9412422180175781s
epoch 280: {'train_loss': '3.24702'}; time used = 0.9152750968933105s
epoch 285: {'train_loss': '3.16656'}; time used = 0.9809563159942627s
epoch 290: {'train_loss': '3.15817'}; time used = 0.6477210521697998s
epoch 295: {'train_loss': '3.15963'}; time used = 0.5532364845275879s
epoch 300: {'train_loss': '3.22389'}; time used = 0.4642958641052246s
epoch 305: {'train_loss': '3.10830'}; time used = 0.4206686019897461s
epoch 310: {'train_loss': '3.18850'}; time used = 0.3804893493652344s
epoch 315: {'train_loss': '3.09876'}; time used = 0.4826068878173828s
epoch 320: {'train_loss': '3.12315'}; time used = 0.41056084632873535s
epoch 325: {'train_loss': '3.07729'}; time used = 0.4551680088043213s
epoch 330: {'train_loss': '3.16692'}; time used = 0.565056562423706s
epoch 335: {'train_loss': '3.12907'}; time used = 0.5590739250183105s
epoch 340: {'train_loss': '3.08344'}; time used = 0.42354559898376465s
epoch 345: {'train_loss': '3.00517'}; time used = 0.38373899459838867s
epoch 350: {'train_loss': '3.07471'}; time used = 0.4218323230743408s
epoch 355: {'train_loss': '2.99866'}; time used = 0.421004056930542s
epoch 360: {'train_loss': '3.10487'}; time used = 0.4754631519317627s
epoch 365: {'train_loss': '3.00550'}; time used = 0.4372105598449707s
epoch 370: {'train_loss': '3.04839'}; time used = 0.3620731830596924s
epoch 375: {'train_loss': '2.95896'}; time used = 0.4648311138153076s
epoch 380: {'train_loss': '3.00821'}; time used = 0.5447497367858887s
epoch 385: {'train_loss': '3.00348'}; time used = 0.5309765338897705s
epoch 390: {'train_loss': '3.04179'}; time used = 0.5192182064056396s
epoch 395: {'train_loss': '3.02085'}; time used = 0.402904748916626s
epoch 400: {'train_loss': '2.95133'}; time used = 0.5249238014221191s
epoch 405: {'train_loss': '2.98730'}; time used = 0.48995041847229004s
epoch 410: {'train_loss': '2.91360'}; time used = 0.8040814399719238s
epoch 415: {'train_loss': '3.03888'}; time used = 0.6158843040466309s
epoch 420: {'train_loss': '3.00807'}; time used = 0.622589111328125s
epoch 425: {'train_loss': '3.01115'}; time used = 0.4854466915130615s
epoch 430: {'train_loss': '2.94034'}; time used = 0.4159386157989502s
epoch 435: {'train_loss': '2.94319'}; time used = 0.33576369285583496s
epoch 440: {'train_loss': '2.94890'}; time used = 0.33378171920776367s
epoch 445: {'train_loss': '2.95670'}; time used = 0.4107818603515625s
epoch 450: {'train_loss': '2.92606'}; time used = 0.5636320114135742s
epoch 455: {'train_loss': '2.92027'}; time used = 0.5243077278137207s
epoch 460: {'train_loss': '2.91579'}; time used = 0.5797016620635986s
epoch 465: {'train_loss': '2.93357'}; time used = 0.5987441539764404s
epoch 470: {'train_loss': '2.83125'}; time used = 0.39066100120544434s
epoch 475: {'train_loss': '2.83933'}; time used = 0.41761088371276855s
epoch 480: {'train_loss': '2.91697'}; time used = 0.3403480052947998s
epoch 485: {'train_loss': '2.94508'}; time used = 0.4397766590118408s
epoch 490: {'train_loss': '2.86966'}; time used = 0.5475423336029053s
epoch 495: {'train_loss': '2.88411'}; time used = 0.6389257907867432s
epoch 500: {'train_loss': '2.82717'}; time used = 0.5313506126403809s
Finished training. Time used = 91.84921336174011.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}

  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115126.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5910/10556 [00:00<00:00, 59095.69it/s]100%|| 10556/10556 [00:00<00:00, 75492.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116405.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7009/10556 [00:00<00:00, 70084.39it/s]100%|| 10556/10556 [00:00<00:00, 80860.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105686.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5711/10556 [00:00<00:00, 44663.52it/s] 96%|| 10173/10556 [00:00<00:00, 44650.34it/s]100%|| 10556/10556 [00:00<00:00, 44720.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6235/10556 [00:00<00:00, 59842.67it/s]100%|| 10556/10556 [00:00<00:00, 73661.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8605/10556 [00:00<00:00, 86046.18it/s]100%|| 10556/10556 [00:00<00:00, 82139.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5685/10556 [00:00<00:00, 54626.35it/s] 91%|| 9646/10556 [00:00<00:00, 48879.61it/s]100%|| 10556/10556 [00:00<00:00, 45947.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%| | 8588/10556 [00:00<00:00, 85876.19it/s]100%|| 10556/10556 [00:00<00:00, 81873.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 9980/10556 [00:00<00:00, 99793.43it/s]100%|| 10556/10556 [00:00<00:00, 98153.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6533/10556 [00:00<00:00, 65326.32it/s]100%|| 10556/10556 [00:00<00:00, 69934.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5668/10556 [00:00<00:00, 56679.38it/s]100%|| 10556/10556 [00:00<00:00, 52469.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 7983/10556 [00:00<00:00, 79822.84it/s]100%|| 10556/10556 [00:00<00:00, 75506.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6311/10556 [00:00<00:00, 58436.32it/s]100%|| 10556/10556 [00:00<00:00, 68863.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6914/10556 [00:00<00:00, 69139.24it/s]100%|| 10556/10556 [00:00<00:00, 71625.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107536.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7810/10556 [00:00<00:00, 77791.82it/s]100%|| 10556/10556 [00:00<00:00, 63455.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6643/10556 [00:00<00:00, 65780.77it/s]100%|| 10556/10556 [00:00<00:00, 56645.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5776/10556 [00:00<00:00, 50818.93it/s]100%|| 10556/10556 [00:00<00:00, 51466.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6192/10556 [00:00<00:00, 61916.07it/s]100%|| 10556/10556 [00:00<00:00, 71200.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9484/10556 [00:00<00:00, 94818.84it/s]100%|| 10556/10556 [00:00<00:00, 92947.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6189/10556 [00:00<00:00, 50668.22it/s]100%|| 10556/10556 [00:00<00:00, 54715.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5842/10556 [00:00<00:00, 58090.43it/s]100%|| 10556/10556 [00:00<00:00, 53907.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117149.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9041/10556 [00:00<00:00, 90403.84it/s]100%|| 10556/10556 [00:00<00:00, 92849.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6605/10556 [00:00<00:00, 66049.75it/s]100%|| 10556/10556 [00:00<00:00, 60995.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5829/10556 [00:00<00:00, 54814.53it/s]100%|| 10556/10556 [00:00<00:00, 71982.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6872/10556 [00:00<00:00, 63105.66it/s]100%|| 10556/10556 [00:00<00:00, 53165.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|    | 5434/10556 [00:00<00:00, 54338.50it/s]100%|| 10556/10556 [00:00<00:00, 73438.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6311/10556 [00:00<00:00, 62612.21it/s]100%|| 10556/10556 [00:00<00:00, 58502.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8797/10556 [00:00<00:00, 87967.99it/s]100%|| 10556/10556 [00:00<00:00, 91909.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5640/10556 [00:00<00:00, 55890.89it/s]100%|| 10556/10556 [00:00<00:00, 57521.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9101/10556 [00:00<00:00, 91004.01it/s]100%|| 10556/10556 [00:00<00:00, 94035.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6970/10556 [00:00<00:00, 69696.74it/s]100%|| 10556/10556 [00:00<00:00, 64142.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117694.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6613/10556 [00:00<00:00, 64073.27it/s]100%|| 10556/10556 [00:00<00:00, 62091.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9383/10556 [00:00<00:00, 93828.52it/s]100%|| 10556/10556 [00:00<00:00, 95926.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7221/10556 [00:00<00:00, 67717.83it/s]100%|| 10556/10556 [00:00<00:00, 65022.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106945.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117934.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10147/10556 [00:00<00:00, 101464.53it/s]100%|| 10556/10556 [00:00<00:00, 101423.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114575.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106207.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7843/10556 [00:00<00:00, 78427.08it/s]100%|| 10556/10556 [00:00<00:00, 82356.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114474.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106490.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8272/10556 [00:00<00:00, 82716.13it/s]100%|| 10556/10556 [00:00<00:00, 87717.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6002/10556 [00:00<00:00, 60017.05it/s]100%|| 10556/10556 [00:00<00:00, 74439.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10085/10556 [00:00<00:00, 100846.49it/s]100%|| 10556/10556 [00:00<00:00, 101203.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6632/10556 [00:00<00:00, 66318.32it/s]100%|| 10556/10556 [00:00<00:00, 62843.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6763/10556 [00:00<00:00, 61919.93it/s]100%|| 10556/10556 [00:00<00:00, 61071.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120309.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5702/10556 [00:00<00:00, 56617.52it/s]100%|| 10556/10556 [00:00<00:00, 61545.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5702/10556 [00:00<00:00, 49962.75it/s]100%|| 10556/10556 [00:00<00:00, 46936.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4545/10556 [00:00<00:00, 45449.18it/s] 80%|  | 8480/10556 [00:00<00:00, 41966.40it/s]100%|| 10556/10556 [00:00<00:00, 39549.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10315/10556 [00:00<00:00, 103143.21it/s]100%|| 10556/10556 [00:00<00:00, 102894.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5580/10556 [00:00<00:00, 55798.72it/s]100%|| 10556/10556 [00:00<00:00, 73005.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108552.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 97937.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8384/10556 [00:00<00:00, 83838.48it/s]100%|| 10556/10556 [00:00<00:00, 88913.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 5981/10556 [00:00<00:00, 59806.21it/s]100%|| 10556/10556 [00:00<00:00, 53144.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8370/10556 [00:00<00:00, 77720.10it/s]100%|| 10556/10556 [00:00<00:00, 81776.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9487/10556 [00:00<00:00, 90151.76it/s]100%|| 10556/10556 [00:00<00:00, 78205.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 24%|       | 2519/10556 [00:00<00:00, 22387.47it/s] 68%|   | 7207/10556 [00:00<00:00, 26370.93it/s]100%|| 10556/10556 [00:00<00:00, 42934.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10145/10556 [00:00<00:00, 101442.12it/s]100%|| 10556/10556 [00:00<00:00, 101809.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8076/10556 [00:00<00:00, 54731.92it/s]100%|| 10556/10556 [00:00<00:00, 48448.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9123/10556 [00:00<00:00, 91222.47it/s]100%|| 10556/10556 [00:00<00:00, 94307.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5173/10556 [00:00<00:00, 50963.23it/s]100%|| 10556/10556 [00:00<00:00, 65768.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4710/10556 [00:00<00:00, 47099.82it/s]100%|| 10556/10556 [00:00<00:00, 71764.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117359.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6210/10556 [00:00<00:00, 62098.28it/s]100%|| 10556/10556 [00:00<00:00, 58556.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4397/10556 [00:00<00:00, 43864.00it/s] 93%|| 9831/10556 [00:00<00:00, 46362.69it/s]100%|| 10556/10556 [00:00<00:00, 48046.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3900/10556 [00:00<00:00, 38413.80it/s] 84%| | 8886/10556 [00:00<00:00, 40452.00it/s]100%|| 10556/10556 [00:00<00:00, 44418.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6041/10556 [00:00<00:00, 60408.33it/s]100%|| 10556/10556 [00:00<00:00, 55060.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6907/10556 [00:00<00:00, 61048.20it/s]100%|| 10556/10556 [00:00<00:00, 51224.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7500/10556 [00:00<00:00, 74996.14it/s]100%|| 10556/10556 [00:00<00:00, 62346.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8838/10556 [00:00<00:00, 77819.86it/s]100%|| 10556/10556 [00:00<00:00, 75237.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5657/10556 [00:00<00:00, 56567.09it/s] 81%|  | 8502/10556 [00:00<00:00, 43629.93it/s]100%|| 10556/10556 [00:00<00:00, 43360.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6761/10556 [00:00<00:00, 63027.59it/s]100%|| 10556/10556 [00:00<00:00, 61544.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5647/10556 [00:00<00:00, 56468.98it/s]100%|| 10556/10556 [00:00<00:00, 58252.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6564/10556 [00:00<00:00, 65635.99it/s]100%|| 10556/10556 [00:00<00:00, 56593.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6171/10556 [00:00<00:00, 61707.70it/s]100%|| 10556/10556 [00:00<00:00, 57900.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6262/10556 [00:00<00:00, 62615.73it/s]100%|| 10556/10556 [00:00<00:00, 71053.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9840/10556 [00:00<00:00, 98397.04it/s]100%|| 10556/10556 [00:00<00:00, 86962.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5912/10556 [00:00<00:00, 58742.47it/s]100%|| 10556/10556 [00:00<00:00, 60151.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7686/10556 [00:00<00:00, 76859.52it/s]100%|| 10556/10556 [00:00<00:00, 85199.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116519.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6871/10556 [00:00<00:00, 68532.78it/s]100%|| 10556/10556 [00:00<00:00, 81288.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6520/10556 [00:00<00:00, 65196.33it/s]100%|| 10556/10556 [00:00<00:00, 70212.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5630/10556 [00:00<00:00, 56295.49it/s]100%|| 10556/10556 [00:00<00:00, 61204.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6473/10556 [00:00<00:00, 64727.75it/s]100%|| 10556/10556 [00:00<00:00, 61712.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6946/10556 [00:00<00:00, 60429.94it/s]100%|| 10556/10556 [00:00<00:00, 60349.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5255/10556 [00:00<00:00, 46642.33it/s]100%|| 10556/10556 [00:00<00:00, 59923.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 30%|       | 3208/10556 [00:00<00:00, 32077.89it/s] 96%|| 10106/10556 [00:00<00:00, 37553.41it/s]100%|| 10556/10556 [00:00<00:00, 48277.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6034/10556 [00:00<00:00, 60337.61it/s]100%|| 10556/10556 [00:00<00:00, 57604.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8898/10556 [00:00<00:00, 88975.84it/s]100%|| 10556/10556 [00:00<00:00, 90213.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6641/10556 [00:00<00:00, 66408.64it/s]100%|| 10556/10556 [00:00<00:00, 79111.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10427/10556 [00:00<00:00, 104266.87it/s]100%|| 10556/10556 [00:00<00:00, 101526.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5889/10556 [00:00<00:00, 58887.53it/s]100%|| 10556/10556 [00:00<00:00, 68014.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5837/10556 [00:00<00:00, 58367.13it/s]100%|| 10556/10556 [00:00<00:00, 58111.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 7972/10556 [00:00<00:00, 79718.18it/s]100%|| 10556/10556 [00:00<00:00, 79248.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111551.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117701.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5353/10556 [00:00<00:00, 53523.93it/s]100%|| 10556/10556 [00:00<00:00, 71495.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133410.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186100.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183398.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174193.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173901.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173493.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172617.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173271.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173836.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166481.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6267/10556 [00:00<00:00, 61261.90it/s]100%|| 10556/10556 [00:00<00:00, 72425.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8828/10556 [00:00<00:00, 88279.66it/s]100%|| 10556/10556 [00:00<00:00, 91616.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9731/10556 [00:00<00:00, 90174.68it/s]100%|| 10556/10556 [00:00<00:00, 91705.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126308.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127216.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123414.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9445/10556 [00:00<00:00, 82646.51it/s]100%|| 10556/10556 [00:00<00:00, 67554.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8955/10556 [00:00<00:00, 89546.24it/s]100%|| 10556/10556 [00:00<00:00, 82354.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118393.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112451.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117709.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112253.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173468.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165865.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176137.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175795.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116411.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107177.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178021.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112193.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5835/10556 [00:00<00:00, 58348.11it/s]100%|| 10556/10556 [00:00<00:00, 77752.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133940.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159251.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189545.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188989.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184731.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170265.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170668.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176994.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176382.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168933.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175049.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171885.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165992.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139616.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110098.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190449.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158938.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9481/10556 [00:00<00:00, 94802.41it/s]100%|| 10556/10556 [00:00<00:00, 96507.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145867.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183017.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175207.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176554.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173764.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126107.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121226.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119951.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106229.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127290.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146723.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125295.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122196.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125550.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124026.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 26%|       | 2770/10556 [00:00<00:00, 23540.16it/s]100%|| 10556/10556 [00:00<00:00, 59201.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152196.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147541.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147332.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148523.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124340.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137922.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8493/10556 [00:00<00:00, 84929.47it/s]100%|| 10556/10556 [00:00<00:00, 88046.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131257.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9181/10556 [00:00<00:00, 89876.82it/s]100%|| 10556/10556 [00:00<00:00, 69535.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150206.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183200.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7855/10556 [00:00<00:00, 75614.76it/s]100%|| 10556/10556 [00:00<00:00, 70826.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179140.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177910.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5322/10556 [00:00<00:00, 53218.15it/s]100%|| 10556/10556 [00:00<00:00, 58627.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8732/10556 [00:00<00:00, 87319.88it/s]100%|| 10556/10556 [00:00<00:00, 82575.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4915/10556 [00:00<00:00, 47590.80it/s] 87%| | 9197/10556 [00:00<00:00, 46037.29it/s]100%|| 10556/10556 [00:00<00:00, 49266.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122994.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142294.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107115.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137041.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158905.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156988.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4631/10556 [00:00<00:00, 45312.57it/s] 78%|  | 8248/10556 [00:00<00:00, 42117.39it/s]100%|| 10556/10556 [00:00<00:00, 42138.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7171/10556 [00:00<00:00, 70241.86it/s]100%|| 10556/10556 [00:00<00:00, 59587.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113367.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121633.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162049.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186150.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125677.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151436.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3357/10556 [00:00<00:00, 28261.96it/s]100%|| 10556/10556 [00:00<00:00, 56180.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121916.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152484.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184197.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184174.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182904.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178185.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7653/10556 [00:00<00:00, 74541.38it/s]100%|| 10556/10556 [00:00<00:00, 84164.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9053/10556 [00:00<00:00, 90525.55it/s]100%|| 10556/10556 [00:00<00:00, 95281.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176122.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184632.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176069.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175093.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175452.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164971.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159333.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164781.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174362.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171188.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170242.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171410.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177299.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168381.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176588.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174981.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174005.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175052.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176626.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174838.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119499.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124195.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130978.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129211.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6488/10556 [00:00<00:00, 64879.13it/s]100%|| 10556/10556 [00:00<00:00, 78921.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108608.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150685.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150062.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146045.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10479/10556 [00:00<00:00, 104780.86it/s]100%|| 10556/10556 [00:00<00:00, 104427.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112450.91it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '5.55832'}; time used = 0.8226199150085449s
epoch 10: {'train_loss': '4.67000'}; time used = 0.8284976482391357s
epoch 15: {'train_loss': '3.98939'}; time used = 0.87896728515625s
epoch 20: {'train_loss': '3.51294'}; time used = 0.8721303939819336s
epoch 25: {'train_loss': '3.40695'}; time used = 0.8260862827301025s
epoch 30: {'train_loss': '3.27472'}; time used = 0.9684262275695801s
epoch 35: {'train_loss': '3.13836'}; time used = 0.7293312549591064s
epoch 40: {'train_loss': '2.95003'}; time used = 0.6883773803710938s
epoch 45: {'train_loss': '2.90008'}; time used = 0.5843958854675293s
epoch 50: {'train_loss': '2.86244'}; time used = 0.7351713180541992s
epoch 55: {'train_loss': '2.74068'}; time used = 0.9850986003875732s
epoch 60: {'train_loss': '2.72135'}; time used = 0.635326623916626s
epoch 65: {'train_loss': '2.67605'}; time used = 0.8787024021148682s
epoch 70: {'train_loss': '2.62137'}; time used = 0.7862861156463623s
epoch 75: {'train_loss': '2.55152'}; time used = 1.1280195713043213s
epoch 80: {'train_loss': '2.58896'}; time used = 0.9869198799133301s
epoch 85: {'train_loss': '2.48834'}; time used = 0.8875784873962402s
epoch 90: {'train_loss': '2.48176'}; time used = 0.7362000942230225s
epoch 95: {'train_loss': '2.43222'}; time used = 1.0160562992095947s
epoch 100: {'train_loss': '2.38903'}; time used = 0.759056806564331s
epoch 105: {'train_loss': '2.35745'}; time used = 0.6161849498748779s
epoch 110: {'train_loss': '2.32605'}; time used = 0.3308372497558594s
epoch 115: {'train_loss': '2.30731'}; time used = 0.4297757148742676s
epoch 120: {'train_loss': '2.26679'}; time used = 0.5337224006652832s
epoch 125: {'train_loss': '2.20963'}; time used = 0.5940113067626953s
epoch 130: {'train_loss': '2.13760'}; time used = 0.3741624355316162s
epoch 135: {'train_loss': '2.16330'}; time used = 0.5202658176422119s
epoch 140: {'train_loss': '2.10171'}; time used = 0.3427317142486572s
epoch 145: {'train_loss': '2.05583'}; time used = 0.3332796096801758s
epoch 150: {'train_loss': '1.99546'}; time used = 0.4009428024291992s
epoch 155: {'train_loss': '1.92016'}; time used = 0.41080665588378906s
epoch 160: {'train_loss': '1.95884'}; time used = 0.4044778347015381s
epoch 165: {'train_loss': '1.89644'}; time used = 0.46517252922058105s
epoch 170: {'train_loss': '1.90737'}; time used = 0.5471348762512207s
epoch 175: {'train_loss': '1.86853'}; time used = 0.40349650382995605s
epoch 180: {'train_loss': '1.82652'}; time used = 0.6124172210693359s
epoch 185: {'train_loss': '1.79729'}; time used = 0.6172010898590088s
epoch 190: {'train_loss': '1.78456'}; time used = 0.6052873134613037s
epoch 195: {'train_loss': '1.76250'}; time used = 0.7003364562988281s
epoch 200: {'train_loss': '1.70932'}; time used = 0.3854355812072754s
epoch 205: {'train_loss': '1.69655'}; time used = 0.48482418060302734s
epoch 210: {'train_loss': '1.67549'}; time used = 0.4726903438568115s
epoch 215: {'train_loss': '1.66930'}; time used = 0.32704925537109375s
epoch 220: {'train_loss': '1.64033'}; time used = 0.339982271194458s
epoch 225: {'train_loss': '1.60272'}; time used = 0.3286113739013672s
epoch 230: {'train_loss': '1.55617'}; time used = 0.3531484603881836s
epoch 235: {'train_loss': '1.49387'}; time used = 0.5274546146392822s
epoch 240: {'train_loss': '1.53545'}; time used = 0.4653809070587158s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.51248502731323.
Training classifier using 20.00% nodes...
{'micro': 0.286571296723581, 'macro': 0.08138532453562543, 'samples': 0.286571296723581, 'weighted': 0.15221843340023927}
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151877.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144525.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131288.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10068/10556 [00:00<00:00, 100669.54it/s]100%|| 10556/10556 [00:00<00:00, 97392.62it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6869/10556 [00:00<00:00, 68689.25it/s]100%|| 10556/10556 [00:00<00:00, 51646.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9811/10556 [00:00<00:00, 98100.74it/s]100%|| 10556/10556 [00:00<00:00, 98319.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7918/10556 [00:00<00:00, 79178.75it/s]100%|| 10556/10556 [00:00<00:00, 86618.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120264.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135341.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178903.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173881.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179962.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133993.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144018.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166338.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145259.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113345.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179009.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175343.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156027.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141286.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110751.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183791.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161308.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122962.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158111.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174439.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175275.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172810.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173997.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10084/10556 [00:00<00:00, 100835.05it/s]100%|| 10556/10556 [00:00<00:00, 98451.18it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9965/10556 [00:00<00:00, 99645.34it/s]100%|| 10556/10556 [00:00<00:00, 99389.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140107.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7951/10556 [00:00<00:00, 79504.96it/s]100%|| 10556/10556 [00:00<00:00, 67118.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7195/10556 [00:00<00:00, 70380.96it/s]100%|| 10556/10556 [00:00<00:00, 84651.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178205.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119280.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162150.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177904.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169023.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107102.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7440/10556 [00:00<00:00, 74392.62it/s]100%|| 10556/10556 [00:00<00:00, 73454.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186839.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195475.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156227.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5604/10556 [00:00<00:00, 56037.11it/s]100%|| 10556/10556 [00:00<00:00, 64132.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160017.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6021/10556 [00:00<00:00, 60207.19it/s]100%|| 10556/10556 [00:00<00:00, 70046.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112767.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140316.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141222.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194943.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179188.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180986.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125777.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149002.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126607.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187077.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10051/10556 [00:00<00:00, 95382.46it/s]100%|| 10556/10556 [00:00<00:00, 86586.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124753.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117148.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 206645.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197449.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196975.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194250.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191451.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7413/10556 [00:00<00:00, 74127.24it/s]100%|| 10556/10556 [00:00<00:00, 89982.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7037/10556 [00:00<00:00, 68889.24it/s] 88%| | 9326/10556 [00:00<00:00, 42518.15it/s]100%|| 10556/10556 [00:00<00:00, 48533.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145865.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165266.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179570.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174696.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176269.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7959/10556 [00:00<00:00, 66802.61it/s] 94%|| 9964/10556 [00:00<00:00, 38270.14it/s]100%|| 10556/10556 [00:00<00:00, 46131.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5248/10556 [00:00<00:00, 47890.58it/s]100%|| 10556/10556 [00:00<00:00, 63714.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6786/10556 [00:00<00:00, 67488.69it/s]100%|| 10556/10556 [00:00<00:00, 72254.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176809.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141977.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130667.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|      | 4043/10556 [00:00<00:00, 40427.44it/s]100%|| 10556/10556 [00:00<00:00, 68162.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119583.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8239/10556 [00:00<00:00, 82385.36it/s]100%|| 10556/10556 [00:00<00:00, 46326.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123902.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158868.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161890.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117406.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6040/10556 [00:00<00:00, 54940.58it/s]100%|| 10556/10556 [00:00<00:00, 57368.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188507.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178537.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185762.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181054.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181554.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181146.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169886.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185911.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180418.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182958.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190089.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188855.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187750.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177832.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185449.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185311.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187809.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185814.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186862.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186650.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182626.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187725.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179131.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184544.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178663.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180820.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177491.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124991.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126387.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152613.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9325/10556 [00:00<00:00, 93245.20it/s]100%|| 10556/10556 [00:00<00:00, 83342.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125825.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123860.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9473/10556 [00:00<00:00, 94729.19it/s]100%|| 10556/10556 [00:00<00:00, 94029.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10283/10556 [00:00<00:00, 102829.12it/s]100%|| 10556/10556 [00:00<00:00, 101798.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5693/10556 [00:00<00:00, 56924.49it/s]100%|| 10556/10556 [00:00<00:00, 57543.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 22%|       | 2362/10556 [00:00<00:00, 23619.46it/s]100%|| 10556/10556 [00:00<00:00, 65916.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147622.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130161.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174802.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175515.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116705.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141135.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138382.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5395/10556 [00:00<00:00, 53948.25it/s]100%|| 10556/10556 [00:00<00:00, 71055.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6205/10556 [00:00<00:00, 62049.17it/s]100%|| 10556/10556 [00:00<00:00, 80597.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170592.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175515.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159730.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179268.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178539.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178035.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179029.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179496.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181063.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171565.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173091.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175307.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174085.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174952.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178550.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178120.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174338.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177921.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178095.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174513.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177232.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171867.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175147.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176983.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160503.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155795.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179251.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179846.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9448/10556 [00:00<00:00, 94479.64it/s]100%|| 10556/10556 [00:00<00:00, 99433.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141808.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149196.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114585.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9967/10556 [00:00<00:00, 99662.02it/s]100%|| 10556/10556 [00:00<00:00, 98305.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10203/10556 [00:00<00:00, 102022.07it/s]100%|| 10556/10556 [00:00<00:00, 101721.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140993.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9371/10556 [00:00<00:00, 93707.86it/s]100%|| 10556/10556 [00:00<00:00, 95855.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4993/10556 [00:00<00:00, 49925.64it/s]100%|| 10556/10556 [00:00<00:00, 59609.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153311.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143520.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139688.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109942.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8875/10556 [00:00<00:00, 88748.60it/s]100%|| 10556/10556 [00:00<00:00, 92040.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117640.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7349/10556 [00:00<00:00, 73488.49it/s]100%|| 10556/10556 [00:00<00:00, 70000.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119364.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185270.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6140/10556 [00:00<00:00, 61395.52it/s]100%|| 10556/10556 [00:00<00:00, 82925.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173776.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140812.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128185.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190724.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181727.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181457.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182424.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184164.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180509.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179774.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179143.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180452.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179757.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|  | 7544/10556 [00:00<00:00, 68979.73it/s]100%|| 10556/10556 [00:00<00:00, 81839.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158279.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186102.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183205.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179879.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175817.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178854.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162974.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4407/10556 [00:00<00:00, 44066.68it/s]100%|| 10556/10556 [00:00<00:00, 72313.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122638.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127749.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8053/10556 [00:00<00:00, 79648.01it/s]100%|| 10556/10556 [00:00<00:00, 70765.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8374/10556 [00:00<00:00, 83735.89it/s]100%|| 10556/10556 [00:00<00:00, 83966.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184706.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183163.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193329.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9677/10556 [00:00<00:00, 94169.50it/s]100%|| 10556/10556 [00:00<00:00, 71268.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131008.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9126/10556 [00:00<00:00, 87787.56it/s]100%|| 10556/10556 [00:00<00:00, 62367.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126551.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9081/10556 [00:00<00:00, 90805.11it/s]100%|| 10556/10556 [00:00<00:00, 77390.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 24%|       | 2544/10556 [00:00<00:00, 23234.71it/s]100%|| 10556/10556 [00:00<00:00, 52681.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173748.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172830.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114932.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107678.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|      | 3460/10556 [00:00<00:00, 34598.88it/s] 87%| | 9213/10556 [00:00<00:00, 39297.39it/s]100%|| 10556/10556 [00:00<00:00, 50033.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171549.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9135/10556 [00:00<00:00, 91342.25it/s]100%|| 10556/10556 [00:00<00:00, 74797.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6822/10556 [00:00<00:00, 68218.11it/s]100%|| 10556/10556 [00:00<00:00, 81183.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144597.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167012.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187942.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10180/10556 [00:00<00:00, 101793.06it/s]100%|| 10556/10556 [00:00<00:00, 98008.99it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7611/10556 [00:00<00:00, 76107.35it/s]100%|| 10556/10556 [00:00<00:00, 91346.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177416.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171500.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178281.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180651.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177690.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152540.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10102/10556 [00:00<00:00, 101015.28it/s]100%|| 10556/10556 [00:00<00:00, 89181.55it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7194/10556 [00:00<00:00, 71936.64it/s]100%|| 10556/10556 [00:00<00:00, 88247.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136780.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142341.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188453.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 205889.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189412.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193939.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133267.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6671/10556 [00:00<00:00, 66708.31it/s]100%|| 10556/10556 [00:00<00:00, 80648.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202149.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185135.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132734.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147336.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163076.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126548.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187655.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155074.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149412.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146314.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124865.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121593.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7640/10556 [00:00<00:00, 76396.43it/s]100%|| 10556/10556 [00:00<00:00, 69173.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189668.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111385.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124078.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115930.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135798.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112227.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8211/10556 [00:00<00:00, 82102.84it/s]100%|| 10556/10556 [00:00<00:00, 88473.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113763.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8139/10556 [00:00<00:00, 77974.25it/s]100%|| 10556/10556 [00:00<00:00, 75689.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177129.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177559.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186300.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8708/10556 [00:00<00:00, 87076.35it/s]100%|| 10556/10556 [00:00<00:00, 95320.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9460/10556 [00:00<00:00, 94586.78it/s]100%|| 10556/10556 [00:00<00:00, 90846.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10217/10556 [00:00<00:00, 92763.48it/s]100%|| 10556/10556 [00:00<00:00, 90471.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10179/10556 [00:00<00:00, 95740.44it/s]100%|| 10556/10556 [00:00<00:00, 93191.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106871.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186577.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184182.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7355/10556 [00:00<00:00, 73548.14it/s]100%|| 10556/10556 [00:00<00:00, 73209.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111660.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126783.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171245.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6518/10556 [00:00<00:00, 63479.97it/s]100%|| 10556/10556 [00:00<00:00, 64646.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118554.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105057.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115265.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155956.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173413.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169818.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8251/10556 [00:00<00:00, 76218.25it/s]100%|| 10556/10556 [00:00<00:00, 80975.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147759.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113830.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121455.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125358.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160367.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9770/10556 [00:00<00:00, 96560.28it/s]100%|| 10556/10556 [00:00<00:00, 97932.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124415.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177951.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127621.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135068.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179895.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190671.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149745.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3846/10556 [00:00<00:00, 38278.42it/s]100%|| 10556/10556 [00:00<00:00, 70253.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180986.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7350/10556 [00:00<00:00, 72095.06it/s]100%|| 10556/10556 [00:00<00:00, 88091.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167210.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128221.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122790.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114089.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135473.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173040.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157556.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114200.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176441.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9216/10556 [00:00<00:00, 92157.01it/s]100%|| 10556/10556 [00:00<00:00, 95748.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167610.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132458.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115427.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163277.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116858.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9762/10556 [00:00<00:00, 97619.39it/s]100%|| 10556/10556 [00:00<00:00, 99089.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120067.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187419.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119820.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172451.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125870.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187325.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189816.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10498/10556 [00:00<00:00, 104974.09it/s]100%|| 10556/10556 [00:00<00:00, 98169.37it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107524.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106429.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%| | 8601/10556 [00:00<00:00, 86007.21it/s]100%|| 10556/10556 [00:00<00:00, 74120.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166385.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176491.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158799.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175989.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167986.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109600.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113398.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186515.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8023/10556 [00:00<00:00, 80227.78it/s]100%|| 10556/10556 [00:00<00:00, 76277.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6891/10556 [00:00<00:00, 68857.37it/s]100%|| 10556/10556 [00:00<00:00, 84793.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141942.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123686.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169817.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154758.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170880.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183701.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162181.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123988.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136653.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 30%|       | 3209/10556 [00:00<00:00, 30846.12it/s]100%|| 10556/10556 [00:00<00:00, 53662.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4450/10556 [00:00<00:00, 40165.12it/s]100%|| 10556/10556 [00:00<00:00, 53716.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185002.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168691.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|      | 3561/10556 [00:00<00:00, 35606.98it/s]100%|| 10556/10556 [00:00<00:00, 63326.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4581/10556 [00:00<00:00, 40963.18it/s]100%|| 10556/10556 [00:00<00:00, 64961.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125564.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3763/10556 [00:00<00:00, 37629.23it/s]100%|| 10556/10556 [00:00<00:00, 56163.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6960/10556 [00:00<00:00, 69599.73it/s]100%|| 10556/10556 [00:00<00:00, 78924.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120195.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140348.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105976.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 25%|       | 2622/10556 [00:00<00:00, 25724.40it/s] 70%|   | 7358/10556 [00:00<00:00, 29809.76it/s]100%|| 10556/10556 [00:00<00:00, 41401.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7003/10556 [00:00<00:00, 64641.36it/s]100%|| 10556/10556 [00:00<00:00, 70655.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119318.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179035.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 102038.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136557.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157615.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110072.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6343/10556 [00:00<00:00, 63426.73it/s]100%|| 10556/10556 [00:00<00:00, 86556.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119264.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174866.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181618.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189317.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130991.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142201.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182138.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179665.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179515.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182553.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187614.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146115.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7312/10556 [00:00<00:00, 73119.37it/s]100%|| 10556/10556 [00:00<00:00, 82778.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140791.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189592.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178588.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161318.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169380.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111868.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114923.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177954.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177364.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178104.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189065.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150736.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134280.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188764.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172917.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175597.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174859.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166109.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178373.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186743.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108030.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110017.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10426/10556 [00:00<00:00, 96766.64it/s]100%|| 10556/10556 [00:00<00:00, 94175.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8186/10556 [00:00<00:00, 81858.52it/s]100%|| 10556/10556 [00:00<00:00, 88060.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119345.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155525.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114969.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179872.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182804.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174537.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6313/10556 [00:00<00:00, 63126.15it/s]100%|| 10556/10556 [00:00<00:00, 78774.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191794.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10325/10556 [00:00<00:00, 103244.19it/s]100%|| 10556/10556 [00:00<00:00, 99036.97it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8117/10556 [00:00<00:00, 81167.37it/s]100%|| 10556/10556 [00:00<00:00, 73919.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|  | 7546/10556 [00:00<00:00, 73321.93it/s]100%|| 10556/10556 [00:00<00:00, 82129.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154498.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188108.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128604.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120441.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181622.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184080.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176595.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133289.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115037.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118373.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114788.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10511/10556 [00:00<00:00, 105108.60it/s]100%|| 10556/10556 [00:00<00:00, 104514.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9954/10556 [00:00<00:00, 97037.75it/s]100%|| 10556/10556 [00:00<00:00, 93510.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119709.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9969/10556 [00:00<00:00, 93647.64it/s]100%|| 10556/10556 [00:00<00:00, 90753.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8864/10556 [00:00<00:00, 88639.87it/s]100%|| 10556/10556 [00:00<00:00, 96591.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7938/10556 [00:00<00:00, 79372.32it/s]100%|| 10556/10556 [00:00<00:00, 83488.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128368.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117698.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146550.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173425.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125950.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 7973/10556 [00:00<00:00, 74799.11it/s]100%|| 10556/10556 [00:00<00:00, 87169.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141692.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6263/10556 [00:00<00:00, 62629.01it/s]100%|| 10556/10556 [00:00<00:00, 66925.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9511/10556 [00:00<00:00, 95109.86it/s]100%|| 10556/10556 [00:00<00:00, 100482.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151978.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114618.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140002.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131244.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162689.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177628.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172557.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176061.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177509.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151725.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130591.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190436.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178680.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185337.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171394.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10195/10556 [00:00<00:00, 101942.32it/s]100%|| 10556/10556 [00:00<00:00, 101545.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183465.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175482.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6997/10556 [00:00<00:00, 68373.97it/s]100%|| 10556/10556 [00:00<00:00, 78350.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179137.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173418.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174944.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130929.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136366.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179017.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175216.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177367.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167549.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110603.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126511.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133630.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8507/10556 [00:00<00:00, 85064.00it/s]100%|| 10556/10556 [00:00<00:00, 81228.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8313/10556 [00:00<00:00, 83125.92it/s]100%|| 10556/10556 [00:00<00:00, 85894.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|      | 3539/10556 [00:00<00:00, 31604.41it/s]100%|| 10556/10556 [00:00<00:00, 62068.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124580.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8012/10556 [00:00<00:00, 80118.17it/s]100%|| 10556/10556 [00:00<00:00, 84338.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124036.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124245.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6303/10556 [00:00<00:00, 63029.76it/s]100%|| 10556/10556 [00:00<00:00, 76863.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4203/10556 [00:00<00:00, 40910.02it/s] 67%|   | 7105/10556 [00:00<00:00, 35173.13it/s]100%|| 10556/10556 [00:00<00:00, 39179.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7058/10556 [00:00<00:00, 63383.92it/s]100%|| 10556/10556 [00:00<00:00, 62758.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154755.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125115.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159141.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144295.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147266.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7502/10556 [00:00<00:00, 72264.43it/s]100%|| 10556/10556 [00:00<00:00, 64122.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8285/10556 [00:00<00:00, 82847.91it/s]100%|| 10556/10556 [00:00<00:00, 88457.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145797.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148126.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143670.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154022.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154058.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139531.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150135.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152120.83it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '4.78621'}; time used = 0.6424269676208496s
epoch 10: {'train_loss': '3.65921'}; time used = 0.4578742980957031s
epoch 15: {'train_loss': '3.15496'}; time used = 0.40701794624328613s
epoch 20: {'train_loss': '2.91175'}; time used = 0.3943789005279541s
epoch 25: {'train_loss': '2.94691'}; time used = 0.4076700210571289s
epoch 30: {'train_loss': '2.88065'}; time used = 0.38498926162719727s
epoch 35: {'train_loss': '2.76862'}; time used = 0.568134069442749s
epoch 40: {'train_loss': '2.56965'}; time used = 0.42150330543518066s
epoch 45: {'train_loss': '2.50165'}; time used = 0.5805909633636475s
epoch 50: {'train_loss': '2.42469'}; time used = 0.5164856910705566s
epoch 55: {'train_loss': '2.29246'}; time used = 0.3515317440032959s
epoch 60: {'train_loss': '2.23826'}; time used = 0.4873964786529541s
epoch 65: {'train_loss': '2.16267'}; time used = 0.2933158874511719s
epoch 70: {'train_loss': '2.08250'}; time used = 0.5944287776947021s
epoch 75: {'train_loss': '2.00671'}; time used = 0.7034451961517334s
epoch 80: {'train_loss': '1.99193'}; time used = 0.5040321350097656s
epoch 85: {'train_loss': '1.88620'}; time used = 0.5745368003845215s
epoch 90: {'train_loss': '1.85158'}; time used = 0.45890021324157715s
epoch 95: {'train_loss': '1.79166'}; time used = 0.3227705955505371s
epoch 100: {'train_loss': '1.74020'}; time used = 0.3125646114349365s
epoch 105: {'train_loss': '1.68230'}; time used = 0.31022047996520996s
epoch 110: {'train_loss': '1.65055'}; time used = 0.31391477584838867s
epoch 115: {'train_loss': '1.61266'}; time used = 0.3896067142486572s
epoch 120: {'train_loss': '1.56052'}; time used = 0.5131368637084961s
epoch 125: {'train_loss': '1.51403'}; time used = 0.6628522872924805s
epoch 130: {'train_loss': '1.45020'}; time used = 0.4004225730895996s
epoch 135: {'train_loss': '1.45118'}; time used = 0.5053048133850098s
epoch 140: {'train_loss': '1.39024'}; time used = 0.322551965713501s
epoch 145: {'train_loss': '1.35809'}; time used = 0.3399817943572998s
epoch 150: {'train_loss': '1.30934'}; time used = 0.3257899284362793s
epoch 155: {'train_loss': '1.25567'}; time used = 0.32837581634521484s
epoch 160: {'train_loss': '1.26745'}; time used = 0.33860087394714355s
epoch 165: {'train_loss': '1.22457'}; time used = 0.5353186130523682s
epoch 170: {'train_loss': '1.21756'}; time used = 0.5911176204681396s
epoch 175: {'train_loss': '1.19527'}; time used = 0.5089411735534668s
epoch 180: {'train_loss': '1.15948'}; time used = 0.5560681819915771s
epoch 185: {'train_loss': '1.14435'}; time used = 0.3791933059692383s
epoch 190: {'train_loss': '1.12457'}; time used = 0.3201577663421631s
epoch 195: {'train_loss': '1.12447'}; time used = 0.3912992477416992s
epoch 200: {'train_loss': '1.07499'}; time used = 0.32105588912963867s
epoch 205: {'train_loss': '1.07661'}; time used = 0.6180260181427002s
epoch 210: {'train_loss': '1.05243'}; time used = 0.44148874282836914s
epoch 215: {'train_loss': '1.04939'}; time used = 0.7271401882171631s
epoch 220: {'train_loss': '1.03459'}; time used = 0.5639402866363525s
epoch 225: {'train_loss': '1.01406'}; time used = 0.5088014602661133s
epoch 230: {'train_loss': '0.99199'}; time used = 0.4384152889251709s
epoch 235: {'train_loss': '0.96915'}; time used = 0.4582996368408203s
epoch 240: {'train_loss': '0.97889'}; time used = 0.3404421806335449s
epoch 245: {'train_loss': '0.96716'}; time used = 0.4038069248199463s
epoch 250: {'train_loss': '0.95587'}; time used = 0.3994283676147461s
epoch 255: {'train_loss': '0.95206'}; time used = 0.4269399642944336s
epoch 260: {'train_loss': '0.94656'}; time used = 0.5141899585723877s
epoch 265: {'train_loss': '0.93548'}; time used = 0.5791685581207275s
epoch 270: {'train_loss': '0.92191'}; time used = 0.4574441909790039s
epoch 275: {'train_loss': '0.90968'}; time used = 0.5008318424224854s
epoch 280: {'train_loss': '0.91380'}; time used = 0.6016137599945068s
epoch 285: {'train_loss': '0.89643'}; time used = 0.4669651985168457s
epoch 290: {'train_loss': '0.88537'}; time used = 0.4948699474334717s
epoch 295: {'train_loss': '0.88439'}; time used = 0.4612767696380615s
epoch 300: {'train_loss': '0.87911'}; time used = 0.38640785217285156s
epoch 305: {'train_loss': '0.86676'}; time used = 0.5239813327789307s
epoch 310: {'train_loss': '0.88377'}; time used = 0.45797181129455566s
epoch 315: {'train_loss': '0.86430'}; time used = 0.4588813781738281s
epoch 320: {'train_loss': '0.86498'}; time used = 0.501140832901001s
epoch 325: {'train_loss': '0.85016'}; time used = 0.3934009075164795s
epoch 330: {'train_loss': '0.85553'}; time used = 0.5647695064544678s
epoch 335: {'train_loss': '0.85236'}; time used = 0.35818958282470703s
epoch 340: {'train_loss': '0.84670'}; time used = 0.5528018474578857s
epoch 345: {'train_loss': '0.83768'}; time used = 0.39006495475769043s
epoch 350: {'train_loss': '0.84242'}; time used = 0.5383474826812744s
epoch 355: {'train_loss': '0.83050'}; time used = 0.708949089050293s
epoch 360: {'train_loss': '0.83889'}; time used = 0.6279816627502441s
epoch 365: {'train_loss': '0.83520'}; time used = 0.7006521224975586s
epoch 370: {'train_loss': '0.83175'}; time used = 0.5041470527648926s
epoch 375: {'train_loss': '0.82545'}; time used = 0.3723866939544678s
epoch 380: {'train_loss': '0.82621'}; time used = 0.3460724353790283s
epoch 385: {'train_loss': '0.81479'}; time used = 0.4284346103668213s
epoch 390: {'train_loss': '0.81873'}; time used = 0.4068746566772461s
epoch 395: {'train_loss': '0.81776'}; time used = 0.32939720153808594s
epoch 400: {'train_loss': '0.82251'}; time used = 0.35555386543273926s
epoch 405: {'train_loss': '0.80866'}; time used = 0.4057736396789551s
epoch 410: {'train_loss': '0.80826'}; time used = 0.5480690002441406s
epoch 415: {'train_loss': '0.81148'}; time used = 0.39642882347106934s
epoch 420: {'train_loss': '0.80382'}; time used = 0.550525426864624s
epoch 425: {'train_loss': '0.80196'}; time used = 0.38254356384277344s
epoch 430: {'train_loss': '0.80207'}; time used = 0.497485876083374s
epoch 435: {'train_loss': '0.80483'}; time used = 0.6214168071746826s
epoch 440: {'train_loss': '0.79657'}; time used = 0.450833797454834s
epoch 445: {'train_loss': '0.79618'}; time used = 0.585822343826294s
epoch 450: {'train_loss': '0.79441'}; time used = 0.43286824226379395s
epoch 455: {'train_loss': '0.79331'}; time used = 0.3788485527038574s
epoch 460: {'train_loss': '0.78889'}; time used = 0.3671078681945801s
epoch 465: {'train_loss': '0.79413'}; time used = 0.41722607612609863s
epoch 470: {'train_loss': '0.78652'}; time used = 0.37013792991638184s
epoch 475: {'train_loss': '0.77837'}; time used = 0.4144906997680664s
epoch 480: {'train_loss': '0.78842'}; time used = 0.6942479610443115s
epoch 485: {'train_loss': '0.78811'}; time used = 0.8288519382476807s
epoch 490: {'train_loss': '0.79070'}; time used = 0.42509031295776367s
epoch 495: {'train_loss': '0.77740'}; time used = 0.5528848171234131s
epoch 500: {'train_loss': '0.78961'}; time used = 0.38474035263061523s
Finished training. Time used = 53.66693568229675.
Training classifier using 20.00% nodes...
{'micro': 0.4688509460083064, 'macro': 0.39275850737380974, 'samples': 0.4688509460083064, 'weighted': 0.4401586848934796}

  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10519/10556 [00:00<00:00, 105189.10it/s]100%|| 10556/10556 [00:00<00:00, 104186.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9602/10556 [00:00<00:00, 96017.34it/s]100%|| 10556/10556 [00:00<00:00, 93209.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4103/10556 [00:00<00:00, 41027.98it/s] 96%|| 10107/10556 [00:00<00:00, 43711.63it/s]100%|| 10556/10556 [00:00<00:00, 47199.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7296/10556 [00:00<00:00, 69633.54it/s]100%|| 10556/10556 [00:00<00:00, 63900.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10239/10556 [00:00<00:00, 102389.12it/s]100%|| 10556/10556 [00:00<00:00, 102192.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7927/10556 [00:00<00:00, 79265.92it/s]100%|| 10556/10556 [00:00<00:00, 86740.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9725/10556 [00:00<00:00, 97249.40it/s]100%|| 10556/10556 [00:00<00:00, 85110.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9893/10556 [00:00<00:00, 95606.89it/s]100%|| 10556/10556 [00:00<00:00, 91302.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8219/10556 [00:00<00:00, 82182.63it/s]100%|| 10556/10556 [00:00<00:00, 88309.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6732/10556 [00:00<00:00, 67319.58it/s]100%|| 10556/10556 [00:00<00:00, 69256.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9061/10556 [00:00<00:00, 90602.96it/s]100%|| 10556/10556 [00:00<00:00, 93786.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6350/10556 [00:00<00:00, 63493.40it/s]100%|| 10556/10556 [00:00<00:00, 63026.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120506.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120896.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6172/10556 [00:00<00:00, 61716.82it/s]100%|| 10556/10556 [00:00<00:00, 53433.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10481/10556 [00:00<00:00, 104806.10it/s]100%|| 10556/10556 [00:00<00:00, 104463.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110036.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116271.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121652.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8608/10556 [00:00<00:00, 86075.16it/s]100%|| 10556/10556 [00:00<00:00, 76236.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9603/10556 [00:00<00:00, 96023.91it/s]100%|| 10556/10556 [00:00<00:00, 96355.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8995/10556 [00:00<00:00, 86601.88it/s]100%|| 10556/10556 [00:00<00:00, 87845.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7093/10556 [00:00<00:00, 67185.02it/s]100%|| 10556/10556 [00:00<00:00, 70126.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8070/10556 [00:00<00:00, 80695.84it/s]100%|| 10556/10556 [00:00<00:00, 83975.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9135/10556 [00:00<00:00, 91347.91it/s]100%|| 10556/10556 [00:00<00:00, 93350.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7854/10556 [00:00<00:00, 71935.17it/s]100%|| 10556/10556 [00:00<00:00, 77403.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117408.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7014/10556 [00:00<00:00, 70135.72it/s]100%|| 10556/10556 [00:00<00:00, 79304.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10137/10556 [00:00<00:00, 101365.26it/s]100%|| 10556/10556 [00:00<00:00, 101692.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125799.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6271/10556 [00:00<00:00, 61119.38it/s]100%|| 10556/10556 [00:00<00:00, 76250.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8295/10556 [00:00<00:00, 82943.75it/s]100%|| 10556/10556 [00:00<00:00, 88300.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7454/10556 [00:00<00:00, 66371.88it/s]100%|| 10556/10556 [00:00<00:00, 69960.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114764.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8968/10556 [00:00<00:00, 76919.89it/s]100%|| 10556/10556 [00:00<00:00, 81599.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6687/10556 [00:00<00:00, 66867.99it/s]100%|| 10556/10556 [00:00<00:00, 77589.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8746/10556 [00:00<00:00, 87458.21it/s]100%|| 10556/10556 [00:00<00:00, 91131.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6463/10556 [00:00<00:00, 64627.60it/s]100%|| 10556/10556 [00:00<00:00, 73191.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10329/10556 [00:00<00:00, 103280.99it/s]100%|| 10556/10556 [00:00<00:00, 102909.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6521/10556 [00:00<00:00, 65207.26it/s]100%|| 10556/10556 [00:00<00:00, 62537.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 100185.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7358/10556 [00:00<00:00, 73576.74it/s]100%|| 10556/10556 [00:00<00:00, 79978.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10342/10556 [00:00<00:00, 103414.67it/s]100%|| 10556/10556 [00:00<00:00, 98159.36it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5396/10556 [00:00<00:00, 53957.48it/s]100%|| 10556/10556 [00:00<00:00, 72891.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118146.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8838/10556 [00:00<00:00, 88374.61it/s]100%|| 10556/10556 [00:00<00:00, 91118.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7037/10556 [00:00<00:00, 70365.71it/s]100%|| 10556/10556 [00:00<00:00, 80278.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6357/10556 [00:00<00:00, 63567.03it/s]100%|| 10556/10556 [00:00<00:00, 62436.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8089/10556 [00:00<00:00, 80888.15it/s]100%|| 10556/10556 [00:00<00:00, 49186.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106521.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4156/10556 [00:00<00:00, 41559.74it/s] 72%|  | 7649/10556 [00:00<00:00, 39319.01it/s]100%|| 10556/10556 [00:00<00:00, 43210.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5800/10556 [00:00<00:00, 57993.56it/s] 99%|| 10403/10556 [00:00<00:00, 53798.40it/s]100%|| 10556/10556 [00:00<00:00, 52085.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3333/10556 [00:00<00:00, 31748.76it/s] 61%|    | 6462/10556 [00:00<00:00, 31609.71it/s] 88%| | 9305/10556 [00:00<00:00, 30583.46it/s]100%|| 10556/10556 [00:00<00:00, 30872.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5494/10556 [00:00<00:00, 54934.03it/s] 97%|| 10192/10556 [00:00<00:00, 51036.03it/s]100%|| 10556/10556 [00:00<00:00, 49794.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8801/10556 [00:00<00:00, 88008.82it/s]100%|| 10556/10556 [00:00<00:00, 87042.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4476/10556 [00:00<00:00, 42337.66it/s]100%|| 10556/10556 [00:00<00:00, 62199.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117802.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4428/10556 [00:00<00:00, 36672.27it/s] 65%|   | 6895/10556 [00:00<00:00, 31371.14it/s]100%|| 10556/10556 [00:00<00:00, 34318.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6506/10556 [00:00<00:00, 65058.82it/s]100%|| 10556/10556 [00:00<00:00, 64279.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 31%|       | 3281/10556 [00:00<00:00, 26202.52it/s]100%|| 10556/10556 [00:00<00:00, 53331.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5113/10556 [00:00<00:00, 51129.68it/s]100%|| 10556/10556 [00:00<00:00, 55653.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9689/10556 [00:00<00:00, 96883.86it/s]100%|| 10556/10556 [00:00<00:00, 79955.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3897/10556 [00:00<00:00, 36142.76it/s] 98%|| 10360/10556 [00:00<00:00, 41649.80it/s]100%|| 10556/10556 [00:00<00:00, 48907.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4583/10556 [00:00<00:00, 44283.20it/s] 92%|| 9758/10556 [00:00<00:00, 44485.84it/s]100%|| 10556/10556 [00:00<00:00, 43481.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5165/10556 [00:00<00:00, 51649.68it/s] 76%|  | 8047/10556 [00:00<00:00, 40582.94it/s]100%|| 10556/10556 [00:00<00:00, 41748.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6170/10556 [00:00<00:00, 59085.90it/s] 84%| | 8824/10556 [00:00<00:00, 43194.52it/s]100%|| 10556/10556 [00:00<00:00, 39171.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5626/10556 [00:00<00:00, 56257.51it/s] 87%| | 9156/10556 [00:00<00:00, 47751.51it/s]100%|| 10556/10556 [00:00<00:00, 41463.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6289/10556 [00:00<00:00, 58612.39it/s] 85%| | 8963/10556 [00:00<00:00, 41658.53it/s]100%|| 10556/10556 [00:00<00:00, 39649.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6934/10556 [00:00<00:00, 69338.25it/s]100%|| 10556/10556 [00:00<00:00, 71413.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5927/10556 [00:00<00:00, 44035.99it/s]100%|| 10556/10556 [00:00<00:00, 47175.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10101/10556 [00:00<00:00, 101007.93it/s]100%|| 10556/10556 [00:00<00:00, 101502.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6276/10556 [00:00<00:00, 60571.19it/s]100%|| 10556/10556 [00:00<00:00, 61492.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6142/10556 [00:00<00:00, 52285.57it/s]100%|| 10556/10556 [00:00<00:00, 65123.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4189/10556 [00:00<00:00, 35199.44it/s]100%|| 10556/10556 [00:00<00:00, 51328.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7807/10556 [00:00<00:00, 78068.77it/s]100%|| 10556/10556 [00:00<00:00, 68236.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7784/10556 [00:00<00:00, 77835.06it/s]100%|| 10556/10556 [00:00<00:00, 85859.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8047/10556 [00:00<00:00, 80466.62it/s]100%|| 10556/10556 [00:00<00:00, 88223.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8782/10556 [00:00<00:00, 87815.48it/s]100%|| 10556/10556 [00:00<00:00, 62615.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6279/10556 [00:00<00:00, 62788.11it/s]100%|| 10556/10556 [00:00<00:00, 61341.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6307/10556 [00:00<00:00, 60693.57it/s]100%|| 10556/10556 [00:00<00:00, 55451.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6718/10556 [00:00<00:00, 64906.19it/s]100%|| 10556/10556 [00:00<00:00, 61948.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6520/10556 [00:00<00:00, 62133.04it/s]100%|| 10556/10556 [00:00<00:00, 75502.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118792.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6204/10556 [00:00<00:00, 57451.78it/s]100%|| 10556/10556 [00:00<00:00, 71801.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110064.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6829/10556 [00:00<00:00, 68288.60it/s]100%|| 10556/10556 [00:00<00:00, 76939.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5594/10556 [00:00<00:00, 55938.45it/s]100%|| 10556/10556 [00:00<00:00, 55594.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 27%|       | 2842/10556 [00:00<00:00, 27936.47it/s] 74%|  | 7772/10556 [00:00<00:00, 32110.49it/s]100%|| 10556/10556 [00:00<00:00, 41341.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5209/10556 [00:00<00:00, 47314.80it/s] 81%|  | 8565/10556 [00:00<00:00, 40904.63it/s]100%|| 10556/10556 [00:00<00:00, 37934.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8456/10556 [00:00<00:00, 84558.67it/s]100%|| 10556/10556 [00:00<00:00, 88801.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4566/10556 [00:00<00:00, 45658.08it/s] 85%| | 8943/10556 [00:00<00:00, 45074.02it/s]100%|| 10556/10556 [00:00<00:00, 44830.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5893/10556 [00:00<00:00, 58925.42it/s]100%|| 10556/10556 [00:00<00:00, 62128.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|  | 7533/10556 [00:00<00:00, 75326.48it/s]100%|| 10556/10556 [00:00<00:00, 68037.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5347/10556 [00:00<00:00, 53467.76it/s]100%|| 10556/10556 [00:00<00:00, 60608.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|       | 3040/10556 [00:00<00:00, 25703.92it/s] 94%|| 9897/10556 [00:00<00:00, 31636.91it/s]100%|| 10556/10556 [00:00<00:00, 45704.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5747/10556 [00:00<00:00, 56660.07it/s]100%|| 10556/10556 [00:00<00:00, 70531.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9110/10556 [00:00<00:00, 91091.83it/s]100%|| 10556/10556 [00:00<00:00, 94457.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8567/10556 [00:00<00:00, 85666.41it/s]100%|| 10556/10556 [00:00<00:00, 90903.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120453.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8646/10556 [00:00<00:00, 86455.96it/s]100%|| 10556/10556 [00:00<00:00, 72597.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3819/10556 [00:00<00:00, 37539.10it/s] 89%| | 9397/10556 [00:00<00:00, 41622.10it/s]100%|| 10556/10556 [00:00<00:00, 47271.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8852/10556 [00:00<00:00, 88516.07it/s]100%|| 10556/10556 [00:00<00:00, 92319.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10476/10556 [00:00<00:00, 104756.60it/s]100%|| 10556/10556 [00:00<00:00, 104445.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113607.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10028/10556 [00:00<00:00, 100279.86it/s]100%|| 10556/10556 [00:00<00:00, 100890.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6033/10556 [00:00<00:00, 55545.46it/s]100%|| 10556/10556 [00:00<00:00, 55773.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6820/10556 [00:00<00:00, 63835.83it/s]100%|| 10556/10556 [00:00<00:00, 72490.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6477/10556 [00:00<00:00, 64769.60it/s]100%|| 10556/10556 [00:00<00:00, 66802.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5156/10556 [00:00<00:00, 45966.64it/s]100%|| 10556/10556 [00:00<00:00, 54422.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8911/10556 [00:00<00:00, 89103.71it/s]100%|| 10556/10556 [00:00<00:00, 83975.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123467.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129662.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6049/10556 [00:00<00:00, 60484.87it/s]100%|| 10556/10556 [00:00<00:00, 51458.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7302/10556 [00:00<00:00, 72933.13it/s]100%|| 10556/10556 [00:00<00:00, 75561.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8402/10556 [00:00<00:00, 84018.28it/s]100%|| 10556/10556 [00:00<00:00, 88918.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5512/10556 [00:00<00:00, 54531.48it/s]100%|| 10556/10556 [00:00<00:00, 53464.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5396/10556 [00:00<00:00, 51898.97it/s]100%|| 10556/10556 [00:00<00:00, 57969.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10133/10556 [00:00<00:00, 101327.44it/s]100%|| 10556/10556 [00:00<00:00, 101880.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4691/10556 [00:00<00:00, 46908.81it/s] 99%|| 10420/10556 [00:00<00:00, 49362.25it/s]100%|| 10556/10556 [00:00<00:00, 51565.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6205/10556 [00:00<00:00, 62048.73it/s]100%|| 10556/10556 [00:00<00:00, 70777.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6768/10556 [00:00<00:00, 67676.68it/s]100%|| 10556/10556 [00:00<00:00, 66157.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8857/10556 [00:00<00:00, 88564.59it/s]100%|| 10556/10556 [00:00<00:00, 80987.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9106/10556 [00:00<00:00, 91055.09it/s]100%|| 10556/10556 [00:00<00:00, 93627.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6428/10556 [00:00<00:00, 58078.79it/s]100%|| 10556/10556 [00:00<00:00, 63212.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163569.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139985.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137684.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175142.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176172.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181038.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173942.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185876.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134475.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121821.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167266.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176894.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180406.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187886.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176711.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154536.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 9002/10556 [00:00<00:00, 90018.37it/s]100%|| 10556/10556 [00:00<00:00, 97741.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126303.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9204/10556 [00:00<00:00, 92036.14it/s]100%|| 10556/10556 [00:00<00:00, 95704.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185014.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202006.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189297.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115474.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177327.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 199248.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187750.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168008.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3802/10556 [00:00<00:00, 38019.49it/s]100%|| 10556/10556 [00:00<00:00, 77700.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179697.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141307.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4956/10556 [00:00<00:00, 49559.93it/s]100%|| 10556/10556 [00:00<00:00, 74890.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9616/10556 [00:00<00:00, 96152.53it/s]100%|| 10556/10556 [00:00<00:00, 86778.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9617/10556 [00:00<00:00, 96164.36it/s]100%|| 10556/10556 [00:00<00:00, 98615.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165604.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188110.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180759.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200553.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 210517.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175774.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176878.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7952/10556 [00:00<00:00, 79514.20it/s]100%|| 10556/10556 [00:00<00:00, 82609.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9571/10556 [00:00<00:00, 95707.58it/s]100%|| 10556/10556 [00:00<00:00, 99992.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168531.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174115.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173953.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156198.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7654/10556 [00:00<00:00, 76538.98it/s]100%|| 10556/10556 [00:00<00:00, 85805.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9354/10556 [00:00<00:00, 93535.41it/s]100%|| 10556/10556 [00:00<00:00, 88115.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118398.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111461.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107416.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178833.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183630.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110547.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132468.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126210.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143687.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129494.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129754.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195012.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182556.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6892/10556 [00:00<00:00, 66479.18it/s]100%|| 10556/10556 [00:00<00:00, 54049.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154434.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140192.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4431/10556 [00:00<00:00, 44307.19it/s]100%|| 10556/10556 [00:00<00:00, 78620.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200663.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 203896.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200840.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6954/10556 [00:00<00:00, 62325.32it/s]100%|| 10556/10556 [00:00<00:00, 56901.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9517/10556 [00:00<00:00, 93274.49it/s]100%|| 10556/10556 [00:00<00:00, 72427.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9356/10556 [00:00<00:00, 84974.69it/s]100%|| 10556/10556 [00:00<00:00, 68320.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9322/10556 [00:00<00:00, 92050.77it/s]100%|| 10556/10556 [00:00<00:00, 74313.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9565/10556 [00:00<00:00, 95647.13it/s]100%|| 10556/10556 [00:00<00:00, 97051.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172145.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181404.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8410/10556 [00:00<00:00, 75174.59it/s]100%|| 10556/10556 [00:00<00:00, 64667.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115155.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7733/10556 [00:00<00:00, 69254.14it/s]100%|| 10556/10556 [00:00<00:00, 63152.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189204.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155043.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5043/10556 [00:00<00:00, 49004.87it/s]100%|| 10556/10556 [00:00<00:00, 52812.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151140.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121402.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8911/10556 [00:00<00:00, 89107.75it/s]100%|| 10556/10556 [00:00<00:00, 88895.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107297.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134825.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6072/10556 [00:00<00:00, 59008.46it/s]100%|| 10556/10556 [00:00<00:00, 76066.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135324.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115311.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9884/10556 [00:00<00:00, 98834.44it/s]100%|| 10556/10556 [00:00<00:00, 99998.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115353.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117914.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115602.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172769.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170997.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149172.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8982/10556 [00:00<00:00, 89814.73it/s]100%|| 10556/10556 [00:00<00:00, 93867.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5777/10556 [00:00<00:00, 57768.13it/s]100%|| 10556/10556 [00:00<00:00, 62783.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119683.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181047.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177657.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177910.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178715.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138598.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152983.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150692.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150037.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148433.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150476.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145669.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 7979/10556 [00:00<00:00, 76220.13it/s]100%|| 10556/10556 [00:00<00:00, 66639.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177203.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162783.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7942/10556 [00:00<00:00, 79418.56it/s]100%|| 10556/10556 [00:00<00:00, 87282.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132800.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164264.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5097/10556 [00:00<00:00, 50963.12it/s]100%|| 10556/10556 [00:00<00:00, 57115.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130416.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7301/10556 [00:00<00:00, 72840.40it/s]100%|| 10556/10556 [00:00<00:00, 74568.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8288/10556 [00:00<00:00, 77332.25it/s]100%|| 10556/10556 [00:00<00:00, 57714.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112184.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115793.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137017.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168771.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164610.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165474.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166810.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5289/10556 [00:00<00:00, 52889.17it/s]100%|| 10556/10556 [00:00<00:00, 82400.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177327.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176229.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165715.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174402.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174105.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159670.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167867.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181308.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178765.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170462.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179988.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170811.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177735.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181827.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185204.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166922.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149207.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148154.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10311/10556 [00:00<00:00, 103109.12it/s]100%|| 10556/10556 [00:00<00:00, 103525.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132809.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7401/10556 [00:00<00:00, 74007.42it/s]100%|| 10556/10556 [00:00<00:00, 82081.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115736.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151150.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150533.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153202.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147568.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147526.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8743/10556 [00:00<00:00, 87422.16it/s]100%|| 10556/10556 [00:00<00:00, 70193.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6043/10556 [00:00<00:00, 59355.95it/s]100%|| 10556/10556 [00:00<00:00, 68773.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10257/10556 [00:00<00:00, 102565.21it/s]100%|| 10556/10556 [00:00<00:00, 102271.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109134.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127520.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8328/10556 [00:00<00:00, 83276.90it/s]100%|| 10556/10556 [00:00<00:00, 91876.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185829.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173038.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179611.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130313.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 9023/10556 [00:00<00:00, 90224.06it/s]100%|| 10556/10556 [00:00<00:00, 91862.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177506.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120388.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7685/10556 [00:00<00:00, 76848.42it/s]100%|| 10556/10556 [00:00<00:00, 81147.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 9987/10556 [00:00<00:00, 99867.00it/s]100%|| 10556/10556 [00:00<00:00, 100257.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122977.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124263.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132568.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176207.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135375.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134590.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142343.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166991.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179427.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180127.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191623.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194525.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 103563.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6966/10556 [00:00<00:00, 65512.19it/s]100%|| 10556/10556 [00:00<00:00, 56312.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10459/10556 [00:00<00:00, 104585.61it/s]100%|| 10556/10556 [00:00<00:00, 104211.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4704/10556 [00:00<00:00, 47038.47it/s]100%|| 10556/10556 [00:00<00:00, 69354.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121794.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6139/10556 [00:00<00:00, 45831.27it/s]100%|| 10556/10556 [00:00<00:00, 58058.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168619.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8566/10556 [00:00<00:00, 85651.30it/s]100%|| 10556/10556 [00:00<00:00, 67862.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 27%|       | 2879/10556 [00:00<00:00, 26210.76it/s]100%|| 10556/10556 [00:00<00:00, 54136.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173531.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8366/10556 [00:00<00:00, 83656.49it/s]100%|| 10556/10556 [00:00<00:00, 73520.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125454.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5566/10556 [00:00<00:00, 52999.04it/s] 81%| | 8588/10556 [00:00<00:00, 42700.98it/s]100%|| 10556/10556 [00:00<00:00, 45102.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126059.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122217.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 28%|       | 2995/10556 [00:00<00:00, 26207.07it/s]100%|| 10556/10556 [00:00<00:00, 49277.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 9997/10556 [00:00<00:00, 99969.86it/s]100%|| 10556/10556 [00:00<00:00, 86954.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111312.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183266.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130644.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123512.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164246.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186845.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162529.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10316/10556 [00:00<00:00, 103157.15it/s]100%|| 10556/10556 [00:00<00:00, 103602.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149681.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117996.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179896.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172538.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179358.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178540.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172125.19it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '4.20655'}; time used = 0.9442753791809082s
epoch 10: {'train_loss': '3.21208'}; time used = 0.7701165676116943s
epoch 15: {'train_loss': '2.91717'}; time used = 0.7047250270843506s
epoch 20: {'train_loss': '2.73576'}; time used = 0.5987770557403564s
epoch 25: {'train_loss': '2.74997'}; time used = 0.7310998439788818s
epoch 30: {'train_loss': '2.64226'}; time used = 0.6446940898895264s
epoch 35: {'train_loss': '2.50298'}; time used = 0.6871874332427979s
epoch 40: {'train_loss': '2.27733'}; time used = 0.7126014232635498s
epoch 45: {'train_loss': '2.18915'}; time used = 0.6726794242858887s
epoch 50: {'train_loss': '2.08142'}; time used = 0.9244296550750732s
epoch 55: {'train_loss': '1.94612'}; time used = 1.1260197162628174s
epoch 60: {'train_loss': '1.87293'}; time used = 1.0109412670135498s
epoch 65: {'train_loss': '1.78251'}; time used = 1.1981139183044434s
epoch 70: {'train_loss': '1.69717'}; time used = 1.0762302875518799s
epoch 75: {'train_loss': '1.62454'}; time used = 0.9006550312042236s
epoch 80: {'train_loss': '1.58495'}; time used = 0.8814849853515625s
epoch 85: {'train_loss': '1.48744'}; time used = 0.6989419460296631s
epoch 90: {'train_loss': '1.45056'}; time used = 1.1499054431915283s
epoch 95: {'train_loss': '1.39410'}; time used = 0.960545539855957s
epoch 100: {'train_loss': '1.35000'}; time used = 0.7497141361236572s
epoch 105: {'train_loss': '1.29505'}; time used = 0.665492057800293s
epoch 110: {'train_loss': '1.27053'}; time used = 0.7611193656921387s
epoch 115: {'train_loss': '1.23450'}; time used = 0.813291072845459s
epoch 120: {'train_loss': '1.19019'}; time used = 0.8622229099273682s
epoch 125: {'train_loss': '1.16140'}; time used = 0.5988249778747559s
epoch 130: {'train_loss': '1.11255'}; time used = 0.34961652755737305s
epoch 135: {'train_loss': '1.11574'}; time used = 0.3877449035644531s
epoch 140: {'train_loss': '1.06682'}; time used = 0.39222264289855957s
epoch 145: {'train_loss': '1.04727'}; time used = 0.3977670669555664s
epoch 150: {'train_loss': '1.02100'}; time used = 0.3640162944793701s
epoch 155: {'train_loss': '0.98559'}; time used = 0.5786728858947754s
epoch 160: {'train_loss': '0.99123'}; time used = 0.4021718502044678s
epoch 165: {'train_loss': '0.96915'}; time used = 0.4627351760864258s
epoch 170: {'train_loss': '0.96248'}; time used = 0.445615291595459s
epoch 175: {'train_loss': '0.95256'}; time used = 0.5001266002655029s
epoch 180: {'train_loss': '0.92681'}; time used = 0.4306776523590088s
epoch 185: {'train_loss': '0.92446'}; time used = 0.5073885917663574s
epoch 190: {'train_loss': '0.90783'}; time used = 0.4224543571472168s
epoch 195: {'train_loss': '0.92055'}; time used = 0.7301208972930908s
epoch 200: {'train_loss': '0.87918'}; time used = 0.515017032623291s
epoch 205: {'train_loss': '0.89104'}; time used = 0.6010241508483887s
epoch 210: {'train_loss': '0.87363'}; time used = 0.5686883926391602s
epoch 215: {'train_loss': '0.87489'}; time used = 0.5068213939666748s
epoch 220: {'train_loss': '0.87047'}; time used = 0.43066954612731934s
epoch 225: {'train_loss': '0.86073'}; time used = 0.47339797019958496s
epoch 230: {'train_loss': '0.84734'}; time used = 0.37720322608947754s
epoch 235: {'train_loss': '0.83740'}; time used = 0.4842977523803711s
epoch 240: {'train_loss': '0.84412'}; time used = 0.5544590950012207s
epoch 245: {'train_loss': '0.83493'}; time used = 0.6419570446014404s
epoch 250: {'train_loss': '0.82977'}; time used = 0.36679601669311523s
epoch 255: {'train_loss': '0.82703'}; time used = 0.41483068466186523s
epoch 260: {'train_loss': '0.83075'}; time used = 0.3429751396179199s
epoch 265: {'train_loss': '0.82796'}; time used = 0.33660006523132324s
epoch 270: {'train_loss': '0.82103'}; time used = 0.39846038818359375s
epoch 275: {'train_loss': '0.81425'}; time used = 0.5033535957336426s
epoch 280: {'train_loss': '0.81454'}; time used = 0.5715861320495605s
epoch 285: {'train_loss': '0.80582'}; time used = 0.5089092254638672s
epoch 290: {'train_loss': '0.80253'}; time used = 0.4142463207244873s
epoch 295: {'train_loss': '0.80292'}; time used = 0.5459344387054443s
epoch 300: {'train_loss': '0.79872'}; time used = 0.4525625705718994s
epoch 305: {'train_loss': '0.79506'}; time used = 0.31872034072875977s
epoch 310: {'train_loss': '0.80680'}; time used = 0.6784811019897461s
epoch 315: {'train_loss': '0.79698'}; time used = 0.6955845355987549s
epoch 320: {'train_loss': '0.80076'}; time used = 0.6611025333404541s
epoch 325: {'train_loss': '0.79069'}; time used = 0.6302032470703125s
epoch 330: {'train_loss': '0.79171'}; time used = 0.4094219207763672s
epoch 335: {'train_loss': '0.79228'}; time used = 0.38246870040893555s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 51.593165159225464.
Training classifier using 20.00% nodes...
{'micro': 0.46746654360867557, 'macro': 0.39869526652148857, 'samples': 0.46746654360867557, 'weighted': 0.44546480925812154}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9594/10556 [00:00<00:00, 95927.06it/s]100%|| 10556/10556 [00:00<00:00, 91158.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114944.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115463.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129708.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143844.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8473/10556 [00:00<00:00, 81657.34it/s]100%|| 10556/10556 [00:00<00:00, 85598.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126803.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9942/10556 [00:00<00:00, 89991.22it/s]100%|| 10556/10556 [00:00<00:00, 76801.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122464.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122205.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177902.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172247.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7190/10556 [00:00<00:00, 71898.53it/s]100%|| 10556/10556 [00:00<00:00, 76563.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173800.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176605.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146563.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6988/10556 [00:00<00:00, 69879.23it/s]100%|| 10556/10556 [00:00<00:00, 85770.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116720.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115058.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166440.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152858.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122258.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125174.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162850.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140811.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158532.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171065.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149814.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121502.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152379.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109586.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187873.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197982.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 209440.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 208494.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188560.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131855.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8778/10556 [00:00<00:00, 87773.39it/s]100%|| 10556/10556 [00:00<00:00, 78245.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4969/10556 [00:00<00:00, 47138.63it/s]100%|| 10556/10556 [00:00<00:00, 56010.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8902/10556 [00:00<00:00, 89018.81it/s]100%|| 10556/10556 [00:00<00:00, 97782.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9764/10556 [00:00<00:00, 90673.00it/s]100%|| 10556/10556 [00:00<00:00, 71181.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157034.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159343.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107044.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116433.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9599/10556 [00:00<00:00, 95983.46it/s]100%|| 10556/10556 [00:00<00:00, 97314.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9384/10556 [00:00<00:00, 93839.42it/s]100%|| 10556/10556 [00:00<00:00, 96008.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6309/10556 [00:00<00:00, 58147.08it/s]100%|| 10556/10556 [00:00<00:00, 55187.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6081/10556 [00:00<00:00, 47951.17it/s]100%|| 10556/10556 [00:00<00:00, 59960.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132574.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156286.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6095/10556 [00:00<00:00, 55283.33it/s]100%|| 10556/10556 [00:00<00:00, 69648.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181531.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%| | 8599/10556 [00:00<00:00, 80671.06it/s]100%|| 10556/10556 [00:00<00:00, 79517.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9532/10556 [00:00<00:00, 95316.45it/s]100%|| 10556/10556 [00:00<00:00, 76741.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4657/10556 [00:00<00:00, 45381.07it/s]100%|| 10556/10556 [00:00<00:00, 53100.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127112.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198636.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9562/10556 [00:00<00:00, 87552.44it/s]100%|| 10556/10556 [00:00<00:00, 84000.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124045.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8925/10556 [00:00<00:00, 89246.68it/s]100%|| 10556/10556 [00:00<00:00, 64880.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9916/10556 [00:00<00:00, 99158.44it/s]100%|| 10556/10556 [00:00<00:00, 101835.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162359.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176592.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111307.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107090.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142364.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141595.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9772/10556 [00:00<00:00, 97719.16it/s]100%|| 10556/10556 [00:00<00:00, 100998.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172463.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171153.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161298.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5879/10556 [00:00<00:00, 58785.85it/s]100%|| 10556/10556 [00:00<00:00, 75684.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139515.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177143.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174257.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171758.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133257.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136889.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113481.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119433.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121216.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147783.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105601.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|      | 4007/10556 [00:00<00:00, 40068.03it/s]100%|| 10556/10556 [00:00<00:00, 63807.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5893/10556 [00:00<00:00, 58928.93it/s]100%|| 10556/10556 [00:00<00:00, 70218.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145422.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146067.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146384.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120905.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7438/10556 [00:00<00:00, 74373.69it/s]100%|| 10556/10556 [00:00<00:00, 80549.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|      | 3477/10556 [00:00<00:00, 33647.33it/s]100%|| 10556/10556 [00:00<00:00, 55493.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133990.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10078/10556 [00:00<00:00, 100777.45it/s]100%|| 10556/10556 [00:00<00:00, 102249.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167136.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112030.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116881.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141691.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10517/10556 [00:00<00:00, 105164.08it/s]100%|| 10556/10556 [00:00<00:00, 104384.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7255/10556 [00:00<00:00, 72546.09it/s]100%|| 10556/10556 [00:00<00:00, 75486.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4798/10556 [00:00<00:00, 47978.33it/s]100%|| 10556/10556 [00:00<00:00, 62932.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146425.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141454.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172046.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173503.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155857.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8441/10556 [00:00<00:00, 79657.74it/s]100%|| 10556/10556 [00:00<00:00, 75575.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147325.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165473.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170259.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178581.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9198/10556 [00:00<00:00, 91184.83it/s]100%|| 10556/10556 [00:00<00:00, 75329.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152260.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168559.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116873.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169181.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182735.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182435.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182050.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167907.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9435/10556 [00:00<00:00, 94131.72it/s]100%|| 10556/10556 [00:00<00:00, 84908.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10226/10556 [00:00<00:00, 102258.39it/s]100%|| 10556/10556 [00:00<00:00, 102463.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170852.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157603.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148273.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167995.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170733.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128925.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123865.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118608.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123260.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180250.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7093/10556 [00:00<00:00, 69826.64it/s]100%|| 10556/10556 [00:00<00:00, 77735.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135665.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177015.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 9979/10556 [00:00<00:00, 94844.26it/s]100%|| 10556/10556 [00:00<00:00, 87485.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9441/10556 [00:00<00:00, 94401.09it/s]100%|| 10556/10556 [00:00<00:00, 89796.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6920/10556 [00:00<00:00, 69198.09it/s]100%|| 10556/10556 [00:00<00:00, 69134.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185815.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191142.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155328.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180673.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124712.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142393.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152311.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136424.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6577/10556 [00:00<00:00, 65765.20it/s]100%|| 10556/10556 [00:00<00:00, 81399.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8922/10556 [00:00<00:00, 89216.89it/s]100%|| 10556/10556 [00:00<00:00, 78536.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127695.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165280.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147950.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144649.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147393.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133216.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10398/10556 [00:00<00:00, 103977.37it/s]100%|| 10556/10556 [00:00<00:00, 104355.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132060.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8811/10556 [00:00<00:00, 88102.10it/s]100%|| 10556/10556 [00:00<00:00, 91544.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118575.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174592.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173629.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167655.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135444.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166913.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173380.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169746.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147810.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117691.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149528.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8460/10556 [00:00<00:00, 84596.05it/s]100%|| 10556/10556 [00:00<00:00, 94973.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181809.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174185.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118114.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 31%|       | 3261/10556 [00:00<00:00, 28783.79it/s]100%|| 10556/10556 [00:00<00:00, 52142.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8081/10556 [00:00<00:00, 80804.10it/s]100%|| 10556/10556 [00:00<00:00, 88191.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119564.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8791/10556 [00:00<00:00, 87908.83it/s]100%|| 10556/10556 [00:00<00:00, 96642.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191431.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181695.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8896/10556 [00:00<00:00, 85412.29it/s]100%|| 10556/10556 [00:00<00:00, 80358.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5019/10556 [00:00<00:00, 40567.90it/s] 75%|  | 7944/10556 [00:00<00:00, 36347.86it/s]100%|| 10556/10556 [00:00<00:00, 39525.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6705/10556 [00:00<00:00, 67047.35it/s]100%|| 10556/10556 [00:00<00:00, 84056.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132749.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131256.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107735.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4450/10556 [00:00<00:00, 44499.83it/s] 84%| | 8822/10556 [00:00<00:00, 43662.63it/s]100%|| 10556/10556 [00:00<00:00, 44234.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115493.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 25%|       | 2676/10556 [00:00<00:00, 26675.44it/s]100%|| 10556/10556 [00:00<00:00, 60940.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9550/10556 [00:00<00:00, 90757.62it/s]100%|| 10556/10556 [00:00<00:00, 86041.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131204.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148885.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137004.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 27%|       | 2898/10556 [00:00<00:00, 28978.09it/s]100%|| 10556/10556 [00:00<00:00, 53190.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202282.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185472.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184621.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174989.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161325.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7409/10556 [00:00<00:00, 74084.07it/s]100%|| 10556/10556 [00:00<00:00, 83947.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142463.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195908.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187790.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174858.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179114.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128750.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135719.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187810.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177544.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182022.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178306.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181634.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168432.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170288.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7926/10556 [00:00<00:00, 77931.95it/s]100%|| 10556/10556 [00:00<00:00, 78212.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110665.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133172.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145913.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165114.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172413.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9247/10556 [00:00<00:00, 83978.90it/s]100%|| 10556/10556 [00:00<00:00, 74065.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5470/10556 [00:00<00:00, 54698.62it/s]100%|| 10556/10556 [00:00<00:00, 75572.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128857.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189305.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189627.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194919.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 104699.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109952.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5528/10556 [00:00<00:00, 52855.96it/s]100%|| 10556/10556 [00:00<00:00, 70765.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126931.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117924.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132369.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160166.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170830.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150088.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122883.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6579/10556 [00:00<00:00, 65393.27it/s]100%|| 10556/10556 [00:00<00:00, 72778.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135766.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6824/10556 [00:00<00:00, 68236.32it/s]100%|| 10556/10556 [00:00<00:00, 77831.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189528.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176907.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178084.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174345.63it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '5.55832'}; time used = 0.6032848358154297s
epoch 10: {'train_loss': '4.67000'}; time used = 0.510739803314209s
epoch 15: {'train_loss': '3.98939'}; time used = 0.43067121505737305s
epoch 20: {'train_loss': '3.51294'}; time used = 0.4821438789367676s
epoch 25: {'train_loss': '3.40695'}; time used = 0.43025636672973633s
epoch 30: {'train_loss': '3.27472'}; time used = 0.4156489372253418s
epoch 35: {'train_loss': '3.13836'}; time used = 0.29367709159851074s
epoch 40: {'train_loss': '2.95003'}; time used = 0.7026107311248779s
epoch 45: {'train_loss': '2.90008'}; time used = 0.49707508087158203s
epoch 50: {'train_loss': '2.86244'}; time used = 0.6836662292480469s
epoch 55: {'train_loss': '2.74068'}; time used = 0.7194242477416992s
epoch 60: {'train_loss': '2.72135'}; time used = 0.5374031066894531s
epoch 65: {'train_loss': '2.67605'}; time used = 0.4548795223236084s
epoch 70: {'train_loss': '2.62137'}; time used = 0.4340345859527588s
epoch 75: {'train_loss': '2.55152'}; time used = 0.44933438301086426s
epoch 80: {'train_loss': '2.58896'}; time used = 0.45360493659973145s
epoch 85: {'train_loss': '2.48834'}; time used = 0.6160240173339844s
epoch 90: {'train_loss': '2.48176'}; time used = 0.47831082344055176s
epoch 95: {'train_loss': '2.43222'}; time used = 0.5872788429260254s
epoch 100: {'train_loss': '2.38903'}; time used = 0.6297428607940674s
epoch 105: {'train_loss': '2.35745'}; time used = 0.3730347156524658s
epoch 110: {'train_loss': '2.32605'}; time used = 0.43866515159606934s
epoch 115: {'train_loss': '2.30731'}; time used = 0.46927905082702637s
epoch 120: {'train_loss': '2.26679'}; time used = 0.39486074447631836s
epoch 125: {'train_loss': '2.20963'}; time used = 0.4105715751647949s
epoch 130: {'train_loss': '2.13760'}; time used = 0.43717122077941895s
epoch 135: {'train_loss': '2.16330'}; time used = 0.48848390579223633s
epoch 140: {'train_loss': '2.10171'}; time used = 0.51943039894104s
epoch 145: {'train_loss': '2.05583'}; time used = 0.4062221050262451s
epoch 150: {'train_loss': '1.99546'}; time used = 0.5309500694274902s
epoch 155: {'train_loss': '1.92016'}; time used = 0.4381215572357178s
epoch 160: {'train_loss': '1.95884'}; time used = 0.4280705451965332s
epoch 165: {'train_loss': '1.89644'}; time used = 0.36494970321655273s
epoch 170: {'train_loss': '1.90737'}; time used = 0.43537235260009766s
epoch 175: {'train_loss': '1.86853'}; time used = 0.6852471828460693s
epoch 180: {'train_loss': '1.82652'}; time used = 0.679581880569458s
epoch 185: {'train_loss': '1.79729'}; time used = 0.6189882755279541s
epoch 190: {'train_loss': '1.78456'}; time used = 0.5842556953430176s
epoch 195: {'train_loss': '1.76250'}; time used = 0.45740842819213867s
epoch 200: {'train_loss': '1.70932'}; time used = 0.4125964641571045s
epoch 205: {'train_loss': '1.69655'}; time used = 0.3647134304046631s
epoch 210: {'train_loss': '1.67549'}; time used = 0.32813549041748047s
epoch 215: {'train_loss': '1.66930'}; time used = 0.47428154945373535s
epoch 220: {'train_loss': '1.64033'}; time used = 0.5310251712799072s
epoch 225: {'train_loss': '1.60272'}; time used = 0.4051482677459717s
epoch 230: {'train_loss': '1.55617'}; time used = 0.5438003540039062s
epoch 235: {'train_loss': '1.49387'}; time used = 0.48302459716796875s
epoch 240: {'train_loss': '1.53545'}; time used = 0.4024631977081299s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.459400415420532.
Training classifier using 20.00% nodes...
{'micro': 0.286571296723581, 'macro': 0.08138532453562543, 'samples': 0.286571296723581, 'weighted': 0.15221843340023927}
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171341.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155347.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143756.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119253.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134095.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8632/10556 [00:00<00:00, 86318.64it/s]100%|| 10556/10556 [00:00<00:00, 90771.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123948.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171620.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148937.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173355.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172204.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169187.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7282/10556 [00:00<00:00, 68618.51it/s]100%|| 10556/10556 [00:00<00:00, 80132.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183775.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183139.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183422.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136970.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174125.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134479.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146162.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105477.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8654/10556 [00:00<00:00, 86535.75it/s]100%|| 10556/10556 [00:00<00:00, 93748.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146834.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146092.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137687.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107686.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8850/10556 [00:00<00:00, 88498.61it/s]100%|| 10556/10556 [00:00<00:00, 84101.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9703/10556 [00:00<00:00, 97022.00it/s]100%|| 10556/10556 [00:00<00:00, 97856.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5843/10556 [00:00<00:00, 58423.65it/s] 72%|  | 7596/10556 [00:00<00:00, 34194.52it/s]100%|| 10556/10556 [00:00<00:00, 45212.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3688/10556 [00:00<00:00, 36844.11it/s] 69%|   | 7336/10556 [00:00<00:00, 35531.87it/s]100%|| 10556/10556 [00:00<00:00, 38930.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115547.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145513.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 22%|       | 2284/10556 [00:00<00:00, 19835.78it/s]100%|| 10556/10556 [00:00<00:00, 54786.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|      | 4042/10556 [00:00<00:00, 40416.67it/s] 72%|  | 7621/10556 [00:00<00:00, 38906.47it/s] 95%|| 10006/10556 [00:00<00:00, 32280.97it/s]100%|| 10556/10556 [00:00<00:00, 33186.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|      | 3959/10556 [00:00<00:00, 39587.02it/s]100%|| 10556/10556 [00:00<00:00, 62989.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9895/10556 [00:00<00:00, 98943.02it/s]100%|| 10556/10556 [00:00<00:00, 77086.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115642.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7417/10556 [00:00<00:00, 74166.53it/s]100%|| 10556/10556 [00:00<00:00, 83424.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5510/10556 [00:00<00:00, 49634.92it/s]100%|| 10556/10556 [00:00<00:00, 51690.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121032.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10451/10556 [00:00<00:00, 104509.85it/s]100%|| 10556/10556 [00:00<00:00, 101778.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|      | 4014/10556 [00:00<00:00, 40139.75it/s]100%|| 10556/10556 [00:00<00:00, 73794.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147638.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141801.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119769.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121704.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128856.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111284.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159448.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182813.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185791.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178631.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174839.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171489.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166195.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130883.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120121.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120589.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142280.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140395.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147900.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146800.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142544.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147224.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140385.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128997.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3652/10556 [00:00<00:00, 36519.51it/s]100%|| 10556/10556 [00:00<00:00, 72960.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183262.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177775.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185374.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183340.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176888.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173353.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4897/10556 [00:00<00:00, 48967.13it/s]100%|| 10556/10556 [00:00<00:00, 53628.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184510.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192747.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182411.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183230.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7020/10556 [00:00<00:00, 65216.36it/s]100%|| 10556/10556 [00:00<00:00, 70566.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176238.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142324.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10149/10556 [00:00<00:00, 101486.95it/s]100%|| 10556/10556 [00:00<00:00, 103044.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157779.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160272.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155125.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149892.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7627/10556 [00:00<00:00, 76266.44it/s]100%|| 10556/10556 [00:00<00:00, 89173.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184021.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115585.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114625.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180412.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4185/10556 [00:00<00:00, 41848.14it/s]100%|| 10556/10556 [00:00<00:00, 59189.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110161.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118513.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108102.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116372.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 104037.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6669/10556 [00:00<00:00, 66685.77it/s]100%|| 10556/10556 [00:00<00:00, 81144.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129768.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135649.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142350.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141809.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138231.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130839.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140722.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131782.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7384/10556 [00:00<00:00, 73837.08it/s]100%|| 10556/10556 [00:00<00:00, 86651.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9625/10556 [00:00<00:00, 96246.65it/s]100%|| 10556/10556 [00:00<00:00, 96289.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130895.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10218/10556 [00:00<00:00, 102179.85it/s]100%|| 10556/10556 [00:00<00:00, 102877.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139137.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142994.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133117.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10029/10556 [00:00<00:00, 100288.90it/s]100%|| 10556/10556 [00:00<00:00, 99695.95it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10358/10556 [00:00<00:00, 103571.21it/s]100%|| 10556/10556 [00:00<00:00, 102483.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9253/10556 [00:00<00:00, 92522.81it/s]100%|| 10556/10556 [00:00<00:00, 92369.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7627/10556 [00:00<00:00, 76260.98it/s]100%|| 10556/10556 [00:00<00:00, 78421.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9610/10556 [00:00<00:00, 96093.22it/s]100%|| 10556/10556 [00:00<00:00, 93613.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8340/10556 [00:00<00:00, 83399.88it/s]100%|| 10556/10556 [00:00<00:00, 82291.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8749/10556 [00:00<00:00, 87482.16it/s]100%|| 10556/10556 [00:00<00:00, 87060.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|| 9657/10556 [00:00<00:00, 96569.86it/s]100%|| 10556/10556 [00:00<00:00, 99976.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166575.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9373/10556 [00:00<00:00, 91170.37it/s]100%|| 10556/10556 [00:00<00:00, 76314.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152776.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186779.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7135/10556 [00:00<00:00, 67124.89it/s]100%|| 10556/10556 [00:00<00:00, 76472.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190364.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178230.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183744.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195899.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180336.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183272.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9803/10556 [00:00<00:00, 98028.69it/s]100%|| 10556/10556 [00:00<00:00, 86805.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115517.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7373/10556 [00:00<00:00, 72821.17it/s]100%|| 10556/10556 [00:00<00:00, 82357.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152965.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5599/10556 [00:00<00:00, 55987.52it/s]100%|| 10556/10556 [00:00<00:00, 55542.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135391.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160225.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170471.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173035.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169954.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178942.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180198.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148892.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4683/10556 [00:00<00:00, 46829.26it/s]100%|| 10556/10556 [00:00<00:00, 55209.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143436.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8339/10556 [00:00<00:00, 77729.60it/s]100%|| 10556/10556 [00:00<00:00, 71202.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119063.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182954.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9774/10556 [00:00<00:00, 97734.50it/s]100%|| 10556/10556 [00:00<00:00, 97660.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143092.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120192.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178599.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179696.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7168/10556 [00:00<00:00, 71348.53it/s]100%|| 10556/10556 [00:00<00:00, 75338.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7185/10556 [00:00<00:00, 70408.26it/s]100%|| 10556/10556 [00:00<00:00, 54942.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|       | 3086/10556 [00:00<00:00, 30859.15it/s]100%|| 10556/10556 [00:00<00:00, 69413.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 9997/10556 [00:00<00:00, 99968.67it/s]100%|| 10556/10556 [00:00<00:00, 95060.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9686/10556 [00:00<00:00, 96858.01it/s]100%|| 10556/10556 [00:00<00:00, 98202.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6564/10556 [00:00<00:00, 63960.20it/s]100%|| 10556/10556 [00:00<00:00, 62712.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3714/10556 [00:00<00:00, 36808.22it/s] 95%|| 10052/10556 [00:00<00:00, 41735.87it/s]100%|| 10556/10556 [00:00<00:00, 48910.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5213/10556 [00:00<00:00, 52125.82it/s]100%|| 10556/10556 [00:00<00:00, 61799.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4461/10556 [00:00<00:00, 41896.27it/s]100%|| 10556/10556 [00:00<00:00, 54791.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118770.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121113.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140410.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7562/10556 [00:00<00:00, 66661.05it/s]100%|| 10556/10556 [00:00<00:00, 70817.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9618/10556 [00:00<00:00, 96175.74it/s]100%|| 10556/10556 [00:00<00:00, 92767.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7958/10556 [00:00<00:00, 76365.63it/s]100%|| 10556/10556 [00:00<00:00, 70618.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137844.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171088.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178759.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172904.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189191.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174005.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178784.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155370.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163771.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191619.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 207386.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 210600.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163458.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 211580.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202000.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 227009.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 208739.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200014.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 209924.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142569.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141353.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|| 9658/10556 [00:00<00:00, 96575.49it/s]100%|| 10556/10556 [00:00<00:00, 96433.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9574/10556 [00:00<00:00, 95736.67it/s]100%|| 10556/10556 [00:00<00:00, 95142.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112829.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9891/10556 [00:00<00:00, 98900.66it/s]100%|| 10556/10556 [00:00<00:00, 98468.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8216/10556 [00:00<00:00, 74156.71it/s]100%|| 10556/10556 [00:00<00:00, 66168.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115150.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5552/10556 [00:00<00:00, 52898.40it/s]100%|| 10556/10556 [00:00<00:00, 70931.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138516.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170151.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165049.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169525.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129957.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8575/10556 [00:00<00:00, 85746.20it/s]100%|| 10556/10556 [00:00<00:00, 86922.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6227/10556 [00:00<00:00, 59434.85it/s]100%|| 10556/10556 [00:00<00:00, 55558.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120145.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155584.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163522.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136905.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133441.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146605.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160577.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163616.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171213.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130961.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160548.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152144.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151381.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159572.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160736.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160163.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165991.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5471/10556 [00:00<00:00, 54707.97it/s]100%|| 10556/10556 [00:00<00:00, 78380.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186466.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173625.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176029.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166947.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176467.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166435.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174408.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168149.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7175/10556 [00:00<00:00, 71748.02it/s]100%|| 10556/10556 [00:00<00:00, 88898.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8315/10556 [00:00<00:00, 83145.32it/s]100%|| 10556/10556 [00:00<00:00, 83097.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8233/10556 [00:00<00:00, 82323.21it/s]100%|| 10556/10556 [00:00<00:00, 82593.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 7972/10556 [00:00<00:00, 79714.37it/s]100%|| 10556/10556 [00:00<00:00, 79991.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134690.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129362.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7444/10556 [00:00<00:00, 74437.41it/s]100%|| 10556/10556 [00:00<00:00, 80365.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185514.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171821.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124128.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117242.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6413/10556 [00:00<00:00, 59301.19it/s]100%|| 10556/10556 [00:00<00:00, 61073.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 201080.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181753.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168115.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7628/10556 [00:00<00:00, 76279.35it/s]100%|| 10556/10556 [00:00<00:00, 90718.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120705.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116604.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121707.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6561/10556 [00:00<00:00, 55622.81it/s]100%|| 10556/10556 [00:00<00:00, 52640.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136666.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9973/10556 [00:00<00:00, 99723.20it/s]100%|| 10556/10556 [00:00<00:00, 100436.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5512/10556 [00:00<00:00, 52181.24it/s]100%|| 10556/10556 [00:00<00:00, 63709.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4980/10556 [00:00<00:00, 49797.44it/s]100%|| 10556/10556 [00:00<00:00, 65746.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8429/10556 [00:00<00:00, 74869.42it/s]100%|| 10556/10556 [00:00<00:00, 55928.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5309/10556 [00:00<00:00, 51699.90it/s]100%|| 10556/10556 [00:00<00:00, 53056.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9035/10556 [00:00<00:00, 90346.64it/s]100%|| 10556/10556 [00:00<00:00, 96418.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132600.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 25%|       | 2627/10556 [00:00<00:00, 25403.85it/s]100%|| 10556/10556 [00:00<00:00, 67425.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107395.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121149.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6310/10556 [00:00<00:00, 60320.68it/s] 85%| | 8939/10556 [00:00<00:00, 43448.18it/s]100%|| 10556/10556 [00:00<00:00, 47932.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7648/10556 [00:00<00:00, 76477.16it/s]100%|| 10556/10556 [00:00<00:00, 54993.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7675/10556 [00:00<00:00, 76739.83it/s]100%|| 10556/10556 [00:00<00:00, 73988.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9739/10556 [00:00<00:00, 97389.16it/s]100%|| 10556/10556 [00:00<00:00, 98644.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9137/10556 [00:00<00:00, 89712.43it/s]100%|| 10556/10556 [00:00<00:00, 84164.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184497.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164198.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157801.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6917/10556 [00:00<00:00, 69165.61it/s]100%|| 10556/10556 [00:00<00:00, 80218.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174696.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6486/10556 [00:00<00:00, 64858.98it/s]100%|| 10556/10556 [00:00<00:00, 72516.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5860/10556 [00:00<00:00, 58598.38it/s]100%|| 10556/10556 [00:00<00:00, 69227.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165885.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186937.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179033.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168466.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178486.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165642.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106849.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200241.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 199262.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166678.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131669.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155270.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181493.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185661.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183259.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177037.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193841.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172092.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153913.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169847.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174139.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177141.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183933.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186916.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130042.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111257.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8096/10556 [00:00<00:00, 80954.87it/s]100%|| 10556/10556 [00:00<00:00, 90618.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149052.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142729.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10269/10556 [00:00<00:00, 100753.95it/s]100%|| 10556/10556 [00:00<00:00, 100333.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131846.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5958/10556 [00:00<00:00, 59573.81it/s]100%|| 10556/10556 [00:00<00:00, 69592.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128353.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6086/10556 [00:00<00:00, 60856.87it/s]100%|| 10556/10556 [00:00<00:00, 76387.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119665.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195713.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181989.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10501/10556 [00:00<00:00, 96782.56it/s]100%|| 10556/10556 [00:00<00:00, 95053.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5803/10556 [00:00<00:00, 58026.32it/s]100%|| 10556/10556 [00:00<00:00, 73788.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7293/10556 [00:00<00:00, 72924.85it/s]100%|| 10556/10556 [00:00<00:00, 82792.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168559.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163921.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8127/10556 [00:00<00:00, 81266.98it/s]100%|| 10556/10556 [00:00<00:00, 77502.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105900.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151436.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131646.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7553/10556 [00:00<00:00, 75526.29it/s]100%|| 10556/10556 [00:00<00:00, 90762.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187039.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190894.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168424.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167884.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157762.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165352.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160118.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143388.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119372.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172042.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165755.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165122.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153952.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176783.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170599.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180818.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7672/10556 [00:00<00:00, 76717.51it/s]100%|| 10556/10556 [00:00<00:00, 84261.89it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '4.20655'}; time used = 0.47944045066833496s
epoch 10: {'train_loss': '3.21208'}; time used = 0.3736844062805176s
epoch 15: {'train_loss': '2.91717'}; time used = 0.40262818336486816s
epoch 20: {'train_loss': '2.73576'}; time used = 0.41779136657714844s
epoch 25: {'train_loss': '2.74997'}; time used = 0.46302294731140137s
epoch 30: {'train_loss': '2.64226'}; time used = 0.8624160289764404s
epoch 35: {'train_loss': '2.50298'}; time used = 0.9308712482452393s
epoch 40: {'train_loss': '2.27733'}; time used = 0.6853392124176025s
epoch 45: {'train_loss': '2.18915'}; time used = 0.507636547088623s
epoch 50: {'train_loss': '2.08142'}; time used = 0.40257859230041504s
epoch 55: {'train_loss': '1.94612'}; time used = 0.3522191047668457s
epoch 60: {'train_loss': '1.87293'}; time used = 0.42014288902282715s
epoch 65: {'train_loss': '1.78251'}; time used = 0.3996424674987793s
epoch 70: {'train_loss': '1.69717'}; time used = 0.41713666915893555s
epoch 75: {'train_loss': '1.62454'}; time used = 0.4699981212615967s
epoch 80: {'train_loss': '1.58495'}; time used = 0.4328629970550537s
epoch 85: {'train_loss': '1.48744'}; time used = 0.41606879234313965s
epoch 90: {'train_loss': '1.45056'}; time used = 0.48097729682922363s
epoch 95: {'train_loss': '1.39410'}; time used = 0.6041569709777832s
epoch 100: {'train_loss': '1.35000'}; time used = 0.5052618980407715s
epoch 105: {'train_loss': '1.29505'}; time used = 0.4230685234069824s
epoch 110: {'train_loss': '1.27053'}; time used = 0.5433897972106934s
epoch 115: {'train_loss': '1.23450'}; time used = 0.5429558753967285s
epoch 120: {'train_loss': '1.19019'}; time used = 0.6776907444000244s
epoch 125: {'train_loss': '1.16140'}; time used = 0.506152868270874s
epoch 130: {'train_loss': '1.11255'}; time used = 0.3347764015197754s
epoch 135: {'train_loss': '1.11574'}; time used = 0.5078516006469727s
epoch 140: {'train_loss': '1.06682'}; time used = 0.5063951015472412s
epoch 145: {'train_loss': '1.04727'}; time used = 0.4680671691894531s
epoch 150: {'train_loss': '1.02100'}; time used = 0.5100007057189941s
epoch 155: {'train_loss': '0.98559'}; time used = 0.5066783428192139s
epoch 160: {'train_loss': '0.99123'}; time used = 0.7716929912567139s
epoch 165: {'train_loss': '0.96915'}; time used = 0.832935094833374s
epoch 170: {'train_loss': '0.96248'}; time used = 0.6466879844665527s
epoch 175: {'train_loss': '0.95256'}; time used = 0.3245837688446045s
epoch 180: {'train_loss': '0.92681'}; time used = 0.3342397212982178s
epoch 185: {'train_loss': '0.92446'}; time used = 0.28852057456970215s
epoch 190: {'train_loss': '0.90783'}; time used = 0.3254063129425049s
epoch 195: {'train_loss': '0.92055'}; time used = 0.6302580833435059s
epoch 200: {'train_loss': '0.87918'}; time used = 0.48491740226745605s
epoch 205: {'train_loss': '0.89104'}; time used = 0.5996031761169434s
epoch 210: {'train_loss': '0.87363'}; time used = 0.4077134132385254s
epoch 215: {'train_loss': '0.87489'}; time used = 0.37775754928588867s
epoch 220: {'train_loss': '0.87047'}; time used = 0.3652079105377197s
epoch 225: {'train_loss': '0.86073'}; time used = 0.4095499515533447s
epoch 230: {'train_loss': '0.84734'}; time used = 0.3481011390686035s
epoch 235: {'train_loss': '0.83740'}; time used = 0.6301999092102051s
epoch 240: {'train_loss': '0.84412'}; time used = 0.46675968170166016s
epoch 245: {'train_loss': '0.83493'}; time used = 0.4712817668914795s
epoch 250: {'train_loss': '0.82977'}; time used = 0.6309680938720703s
epoch 255: {'train_loss': '0.82703'}; time used = 0.7541954517364502s
epoch 260: {'train_loss': '0.83075'}; time used = 0.6896252632141113s
epoch 265: {'train_loss': '0.82796'}; time used = 0.8192996978759766s
epoch 270: {'train_loss': '0.82103'}; time used = 0.48120665550231934s
epoch 275: {'train_loss': '0.81425'}; time used = 0.5381066799163818s
epoch 280: {'train_loss': '0.81454'}; time used = 0.38039398193359375s
epoch 285: {'train_loss': '0.80582'}; time used = 0.34438443183898926s
epoch 290: {'train_loss': '0.80253'}; time used = 0.3161590099334717s
epoch 295: {'train_loss': '0.80292'}; time used = 0.3390007019042969s
epoch 300: {'train_loss': '0.79872'}; time used = 0.444690465927124s
epoch 305: {'train_loss': '0.79506'}; time used = 0.5222434997558594s
epoch 310: {'train_loss': '0.80680'}; time used = 0.4725673198699951s
epoch 315: {'train_loss': '0.79698'}; time used = 0.5716397762298584s
epoch 320: {'train_loss': '0.80076'}; time used = 0.5453276634216309s
epoch 325: {'train_loss': '0.79069'}; time used = 0.3375725746154785s
epoch 330: {'train_loss': '0.79171'}; time used = 0.38602757453918457s
epoch 335: {'train_loss': '0.79228'}; time used = 0.34969305992126465s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.68596005439758.
Training classifier using 20.00% nodes...
{'micro': 0.46746654360867557, 'macro': 0.39869526652148857, 'samples': 0.46746654360867557, 'weighted': 0.44546480925812154}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128189.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128563.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125776.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134586.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181901.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169949.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166730.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150143.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109415.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9402/10556 [00:00<00:00, 94011.35it/s]100%|| 10556/10556 [00:00<00:00, 92871.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7570/10556 [00:00<00:00, 75695.20it/s]100%|| 10556/10556 [00:00<00:00, 78623.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116404.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173822.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139161.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9053/10556 [00:00<00:00, 90522.53it/s]100%|| 10556/10556 [00:00<00:00, 94890.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170921.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171360.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173773.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168883.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5878/10556 [00:00<00:00, 52988.27it/s]100%|| 10556/10556 [00:00<00:00, 64416.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125197.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124419.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9335/10556 [00:00<00:00, 93346.31it/s]100%|| 10556/10556 [00:00<00:00, 94805.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7049/10556 [00:00<00:00, 70485.87it/s]100%|| 10556/10556 [00:00<00:00, 87882.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119421.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6900/10556 [00:00<00:00, 66685.33it/s]100%|| 10556/10556 [00:00<00:00, 56596.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9316/10556 [00:00<00:00, 93158.98it/s]100%|| 10556/10556 [00:00<00:00, 95284.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6026/10556 [00:00<00:00, 53822.48it/s]100%|| 10556/10556 [00:00<00:00, 65797.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6533/10556 [00:00<00:00, 65326.95it/s]100%|| 10556/10556 [00:00<00:00, 80803.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5574/10556 [00:00<00:00, 55364.51it/s] 98%|| 10343/10556 [00:00<00:00, 52813.47it/s]100%|| 10556/10556 [00:00<00:00, 52054.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129335.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177178.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8330/10556 [00:00<00:00, 78751.80it/s]100%|| 10556/10556 [00:00<00:00, 67044.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154794.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4135/10556 [00:00<00:00, 34944.15it/s]100%|| 10556/10556 [00:00<00:00, 60353.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4744/10556 [00:00<00:00, 45569.27it/s]100%|| 10556/10556 [00:00<00:00, 56841.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7403/10556 [00:00<00:00, 58629.97it/s]100%|| 10556/10556 [00:00<00:00, 56244.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113209.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177190.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168425.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3662/10556 [00:00<00:00, 35947.25it/s] 87%| | 9131/10556 [00:00<00:00, 40065.88it/s]100%|| 10556/10556 [00:00<00:00, 49167.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139023.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7187/10556 [00:00<00:00, 71869.73it/s]100%|| 10556/10556 [00:00<00:00, 77138.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174191.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171291.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182718.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178725.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9936/10556 [00:00<00:00, 93011.21it/s]100%|| 10556/10556 [00:00<00:00, 87870.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151492.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163269.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152398.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181522.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145056.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149882.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171172.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182541.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185977.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186195.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154079.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164284.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164932.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157730.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169054.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164079.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128937.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134794.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126604.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106215.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7952/10556 [00:00<00:00, 79516.28it/s]100%|| 10556/10556 [00:00<00:00, 89875.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174081.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9701/10556 [00:00<00:00, 97002.46it/s]100%|| 10556/10556 [00:00<00:00, 83364.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114121.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163556.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165482.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159468.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6958/10556 [00:00<00:00, 59818.78it/s]100%|| 10556/10556 [00:00<00:00, 61686.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107498.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107581.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110418.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108533.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169746.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169648.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146714.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117375.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171322.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175779.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156793.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169251.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168088.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133772.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119680.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117551.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170374.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169205.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164038.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136119.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7620/10556 [00:00<00:00, 76199.35it/s]100%|| 10556/10556 [00:00<00:00, 69434.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10154/10556 [00:00<00:00, 101534.77it/s]100%|| 10556/10556 [00:00<00:00, 101440.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109899.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116454.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124768.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7704/10556 [00:00<00:00, 77039.16it/s]100%|| 10556/10556 [00:00<00:00, 69186.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9830/10556 [00:00<00:00, 98291.42it/s]100%|| 10556/10556 [00:00<00:00, 97621.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8749/10556 [00:00<00:00, 87481.95it/s]100%|| 10556/10556 [00:00<00:00, 89520.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%| | 8591/10556 [00:00<00:00, 85903.73it/s]100%|| 10556/10556 [00:00<00:00, 87664.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147821.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145306.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144355.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138381.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6363/10556 [00:00<00:00, 63628.85it/s]100%|| 10556/10556 [00:00<00:00, 81279.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7559/10556 [00:00<00:00, 73404.03it/s]100%|| 10556/10556 [00:00<00:00, 78303.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10481/10556 [00:00<00:00, 104809.10it/s]100%|| 10556/10556 [00:00<00:00, 104641.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177715.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175426.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127369.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169555.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180273.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162906.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159106.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121832.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123095.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4516/10556 [00:00<00:00, 42173.80it/s]100%|| 10556/10556 [00:00<00:00, 58893.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173889.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181367.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163674.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155977.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177031.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182684.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184040.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173140.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121220.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123664.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126111.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172619.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180132.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167196.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 101147.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8857/10556 [00:00<00:00, 88568.61it/s]100%|| 10556/10556 [00:00<00:00, 96687.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129523.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8701/10556 [00:00<00:00, 87002.82it/s]100%|| 10556/10556 [00:00<00:00, 58212.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177122.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177440.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149460.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105792.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5203/10556 [00:00<00:00, 39081.24it/s] 96%|| 10146/10556 [00:00<00:00, 41699.86it/s]100%|| 10556/10556 [00:00<00:00, 44594.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3953/10556 [00:00<00:00, 38685.73it/s]100%|| 10556/10556 [00:00<00:00, 63307.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131407.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9955/10556 [00:00<00:00, 99544.16it/s]100%|| 10556/10556 [00:00<00:00, 100357.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121275.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163690.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6898/10556 [00:00<00:00, 68979.08it/s]100%|| 10556/10556 [00:00<00:00, 81864.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4071/10556 [00:00<00:00, 38061.28it/s]100%|| 10556/10556 [00:00<00:00, 60994.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7344/10556 [00:00<00:00, 73438.32it/s]100%|| 10556/10556 [00:00<00:00, 84679.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122223.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7568/10556 [00:00<00:00, 75675.20it/s]100%|| 10556/10556 [00:00<00:00, 73638.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122703.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134139.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6477/10556 [00:00<00:00, 64769.60it/s]100%|| 10556/10556 [00:00<00:00, 78075.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185754.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159961.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171754.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162004.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169912.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118648.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124423.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196558.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172794.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171734.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170568.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173260.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173953.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160855.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174811.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173232.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174047.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172453.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170534.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151080.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106684.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169500.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171024.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169142.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156611.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170899.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176837.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133542.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109618.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172692.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10389/10556 [00:00<00:00, 103887.37it/s]100%|| 10556/10556 [00:00<00:00, 95455.80it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142574.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138151.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9688/10556 [00:00<00:00, 96873.39it/s]100%|| 10556/10556 [00:00<00:00, 95935.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159079.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160443.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163974.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161518.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154851.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6078/10556 [00:00<00:00, 60775.42it/s]100%|| 10556/10556 [00:00<00:00, 60076.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124709.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119208.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4893/10556 [00:00<00:00, 48929.46it/s]100%|| 10556/10556 [00:00<00:00, 78084.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184657.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171572.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118574.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114399.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6045/10556 [00:00<00:00, 58001.95it/s]100%|| 10556/10556 [00:00<00:00, 70171.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159192.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159777.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155056.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116253.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145400.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156196.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156767.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144943.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154525.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146753.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146797.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132150.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109465.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142091.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141038.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140786.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143000.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117646.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10058/10556 [00:00<00:00, 100575.78it/s]100%|| 10556/10556 [00:00<00:00, 86442.34it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107348.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 9998/10556 [00:00<00:00, 99975.09it/s]100%|| 10556/10556 [00:00<00:00, 99686.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128239.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132960.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5663/10556 [00:00<00:00, 54054.71it/s]100%|| 10556/10556 [00:00<00:00, 62596.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113457.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122438.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143560.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121238.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8244/10556 [00:00<00:00, 82434.77it/s]100%|| 10556/10556 [00:00<00:00, 88721.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125027.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9945/10556 [00:00<00:00, 99444.64it/s]100%|| 10556/10556 [00:00<00:00, 99922.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107520.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8502/10556 [00:00<00:00, 85016.23it/s]100%|| 10556/10556 [00:00<00:00, 89438.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117658.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116530.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117033.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164604.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122696.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138148.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130362.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178790.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130369.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158820.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9106/10556 [00:00<00:00, 91055.74it/s]100%|| 10556/10556 [00:00<00:00, 94773.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167987.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173654.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9466/10556 [00:00<00:00, 94656.03it/s]100%|| 10556/10556 [00:00<00:00, 100086.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 201400.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188016.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 5987/10556 [00:00<00:00, 59869.77it/s]100%|| 10556/10556 [00:00<00:00, 63061.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6692/10556 [00:00<00:00, 66915.28it/s]100%|| 10556/10556 [00:00<00:00, 55585.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181517.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140624.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8053/10556 [00:00<00:00, 76682.86it/s] 98%|| 10354/10556 [00:00<00:00, 42633.86it/s]100%|| 10556/10556 [00:00<00:00, 48695.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107888.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118319.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157480.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 26%|       | 2708/10556 [00:00<00:00, 26625.07it/s] 71%|   | 7502/10556 [00:00<00:00, 30723.05it/s]100%|| 10556/10556 [00:00<00:00, 46079.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5057/10556 [00:00<00:00, 46656.89it/s]100%|| 10556/10556 [00:00<00:00, 54194.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140270.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5345/10556 [00:00<00:00, 48935.67it/s]100%|| 10556/10556 [00:00<00:00, 56384.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 30%|       | 3121/10556 [00:00<00:00, 29865.13it/s] 82%| | 8675/10556 [00:00<00:00, 34518.96it/s]100%|| 10556/10556 [00:00<00:00, 43502.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6659/10556 [00:00<00:00, 66586.41it/s]100%|| 10556/10556 [00:00<00:00, 86836.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125231.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7580/10556 [00:00<00:00, 75796.82it/s]100%|| 10556/10556 [00:00<00:00, 58823.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144205.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120522.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125491.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162715.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173513.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167568.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174907.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176367.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180425.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145400.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113834.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122511.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181272.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176034.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176763.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166641.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172383.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172801.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123482.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112318.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155386.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183006.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171593.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178964.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138687.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170795.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158324.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7031/10556 [00:00<00:00, 70309.23it/s]100%|| 10556/10556 [00:00<00:00, 87760.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168302.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8405/10556 [00:00<00:00, 75045.13it/s]100%|| 10556/10556 [00:00<00:00, 66129.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9264/10556 [00:00<00:00, 92638.54it/s]100%|| 10556/10556 [00:00<00:00, 92927.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113956.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131890.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132560.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7925/10556 [00:00<00:00, 79248.19it/s]100%|| 10556/10556 [00:00<00:00, 89982.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128791.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8217/10556 [00:00<00:00, 82166.55it/s]100%|| 10556/10556 [00:00<00:00, 87603.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7299/10556 [00:00<00:00, 72985.20it/s]100%|| 10556/10556 [00:00<00:00, 59973.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9604/10556 [00:00<00:00, 92233.58it/s]100%|| 10556/10556 [00:00<00:00, 88099.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149878.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165510.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166900.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163441.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170220.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118414.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175908.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108241.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155050.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151752.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153671.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172139.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161374.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143317.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169272.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167472.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172827.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168649.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168169.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164503.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164105.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138771.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10103/10556 [00:00<00:00, 101027.93it/s]100%|| 10556/10556 [00:00<00:00, 100091.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124673.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7312/10556 [00:00<00:00, 73118.50it/s]100%|| 10556/10556 [00:00<00:00, 86901.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126119.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146416.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144845.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142869.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112691.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10406/10556 [00:00<00:00, 104056.13it/s]100%|| 10556/10556 [00:00<00:00, 103195.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6105/10556 [00:00<00:00, 59703.06it/s]100%|| 10556/10556 [00:00<00:00, 76222.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10003/10556 [00:00<00:00, 100027.47it/s]100%|| 10556/10556 [00:00<00:00, 99459.68it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5639/10556 [00:00<00:00, 56387.77it/s]100%|| 10556/10556 [00:00<00:00, 66162.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115890.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141347.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131150.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141991.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141240.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|      | 3541/10556 [00:00<00:00, 35409.95it/s]100%|| 10556/10556 [00:00<00:00, 72394.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159190.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6855/10556 [00:00<00:00, 68545.00it/s]100%|| 10556/10556 [00:00<00:00, 82007.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130466.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6573/10556 [00:00<00:00, 65726.93it/s]100%|| 10556/10556 [00:00<00:00, 65571.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8321/10556 [00:00<00:00, 83206.11it/s]100%|| 10556/10556 [00:00<00:00, 86144.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9232/10556 [00:00<00:00, 92317.67it/s]100%|| 10556/10556 [00:00<00:00, 91966.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106810.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116886.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119899.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123210.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122307.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183864.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195389.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109474.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10050/10556 [00:00<00:00, 100494.59it/s]100%|| 10556/10556 [00:00<00:00, 101172.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116217.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129076.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160618.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156125.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120536.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10087/10556 [00:00<00:00, 100869.13it/s]100%|| 10556/10556 [00:00<00:00, 82275.03it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 28%|       | 2976/10556 [00:00<00:00, 29021.74it/s] 82%| | 8639/10556 [00:00<00:00, 33993.28it/s]100%|| 10556/10556 [00:00<00:00, 48566.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113846.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178543.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176191.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178907.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178462.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5189/10556 [00:00<00:00, 46892.15it/s] 78%|  | 8284/10556 [00:00<00:00, 40615.08it/s]100%|| 10556/10556 [00:00<00:00, 46129.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9242/10556 [00:00<00:00, 90527.65it/s]100%|| 10556/10556 [00:00<00:00, 85741.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7074/10556 [00:00<00:00, 70209.10it/s]100%|| 10556/10556 [00:00<00:00, 62097.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121058.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138280.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127244.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120231.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8257/10556 [00:00<00:00, 71645.52it/s]100%|| 10556/10556 [00:00<00:00, 64620.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4234/10556 [00:00<00:00, 36557.95it/s] 71%|   | 7473/10556 [00:00<00:00, 34401.95it/s]100%|| 10556/10556 [00:00<00:00, 38198.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119711.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161385.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174461.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120393.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159461.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5452/10556 [00:00<00:00, 48922.48it/s]100%|| 10556/10556 [00:00<00:00, 68730.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153221.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171888.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176576.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171210.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9432/10556 [00:00<00:00, 94315.59it/s]100%|| 10556/10556 [00:00<00:00, 92249.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117347.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112593.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122552.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7683/10556 [00:00<00:00, 76823.66it/s]100%|| 10556/10556 [00:00<00:00, 84997.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179337.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180115.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173639.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169803.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170473.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172339.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146058.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6355/10556 [00:00<00:00, 63546.58it/s]100%|| 10556/10556 [00:00<00:00, 81142.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163996.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166125.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159055.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135764.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161942.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141606.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114306.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6712/10556 [00:00<00:00, 63675.83it/s]100%|| 10556/10556 [00:00<00:00, 73298.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10454/10556 [00:00<00:00, 104537.61it/s]100%|| 10556/10556 [00:00<00:00, 104130.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132748.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107562.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9210/10556 [00:00<00:00, 84695.33it/s]100%|| 10556/10556 [00:00<00:00, 81946.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143203.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170569.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137825.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7234/10556 [00:00<00:00, 70913.28it/s]100%|| 10556/10556 [00:00<00:00, 65956.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172554.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157841.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 7990/10556 [00:00<00:00, 79894.36it/s]100%|| 10556/10556 [00:00<00:00, 86154.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9233/10556 [00:00<00:00, 83995.98it/s]100%|| 10556/10556 [00:00<00:00, 77190.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127746.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170058.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166634.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156079.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164954.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160418.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160056.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125506.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6805/10556 [00:00<00:00, 68047.31it/s]100%|| 10556/10556 [00:00<00:00, 82401.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137341.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151035.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164495.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146665.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144479.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140161.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144216.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145645.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144710.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9729/10556 [00:00<00:00, 97280.82it/s]100%|| 10556/10556 [00:00<00:00, 97276.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190805.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177471.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179051.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145956.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114214.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10228/10556 [00:00<00:00, 102278.63it/s]100%|| 10556/10556 [00:00<00:00, 101892.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112891.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7206/10556 [00:00<00:00, 72053.54it/s]100%|| 10556/10556 [00:00<00:00, 82917.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147581.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169638.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172505.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121913.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176161.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108987.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10084/10556 [00:00<00:00, 100838.17it/s]100%|| 10556/10556 [00:00<00:00, 102044.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172895.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170809.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171713.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159982.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174351.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185354.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110373.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4764/10556 [00:00<00:00, 47636.87it/s]100%|| 10556/10556 [00:00<00:00, 67371.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9239/10556 [00:00<00:00, 91202.63it/s]100%|| 10556/10556 [00:00<00:00, 86067.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167758.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176361.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130216.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148092.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171719.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171738.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5385/10556 [00:00<00:00, 53846.59it/s]100%|| 10556/10556 [00:00<00:00, 62362.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184562.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179462.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5437/10556 [00:00<00:00, 54366.94it/s]100%|| 10556/10556 [00:00<00:00, 73600.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122801.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5408/10556 [00:00<00:00, 49989.19it/s] 95%|| 9978/10556 [00:00<00:00, 45856.08it/s]100%|| 10556/10556 [00:00<00:00, 45153.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180245.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175057.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168185.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175218.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9411/10556 [00:00<00:00, 93762.25it/s]100%|| 10556/10556 [00:00<00:00, 72167.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4186/10556 [00:00<00:00, 40432.10it/s]100%|| 10556/10556 [00:00<00:00, 58268.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5684/10556 [00:00<00:00, 56834.77it/s]100%|| 10556/10556 [00:00<00:00, 63315.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8100/10556 [00:00<00:00, 80999.50it/s]100%|| 10556/10556 [00:00<00:00, 87030.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9474/10556 [00:00<00:00, 94734.90it/s]100%|| 10556/10556 [00:00<00:00, 96564.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156968.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119917.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9101/10556 [00:00<00:00, 91003.14it/s]100%|| 10556/10556 [00:00<00:00, 82902.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7959/10556 [00:00<00:00, 79583.62it/s]100%|| 10556/10556 [00:00<00:00, 64830.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4813/10556 [00:00<00:00, 48126.60it/s]100%|| 10556/10556 [00:00<00:00, 64191.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9303/10556 [00:00<00:00, 91995.70it/s]100%|| 10556/10556 [00:00<00:00, 75270.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5548/10556 [00:00<00:00, 55477.54it/s]100%|| 10556/10556 [00:00<00:00, 81116.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166007.04it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '6.13401'}; time used = 0.4925837516784668s
epoch 10: {'train_loss': '4.75144'}; time used = 0.5311920642852783s
epoch 15: {'train_loss': '4.37557'}; time used = 0.44852638244628906s
epoch 20: {'train_loss': '4.28536'}; time used = 0.45774316787719727s
epoch 25: {'train_loss': '4.05257'}; time used = 0.6414101123809814s
epoch 30: {'train_loss': '4.11406'}; time used = 0.7568244934082031s
epoch 35: {'train_loss': '3.80123'}; time used = 0.7042825222015381s
epoch 40: {'train_loss': '3.80922'}; time used = 0.6807479858398438s
epoch 45: {'train_loss': '3.71145'}; time used = 0.4195847511291504s
epoch 50: {'train_loss': '3.61578'}; time used = 0.42167186737060547s
epoch 55: {'train_loss': '3.51132'}; time used = 0.35197997093200684s
epoch 60: {'train_loss': '3.46247'}; time used = 0.3493335247039795s
epoch 65: {'train_loss': '3.25142'}; time used = 0.3820478916168213s
epoch 70: {'train_loss': '3.20207'}; time used = 0.5338783264160156s
epoch 75: {'train_loss': '3.19183'}; time used = 0.49280214309692383s
epoch 80: {'train_loss': '3.06683'}; time used = 0.4936971664428711s
epoch 85: {'train_loss': '2.97325'}; time used = 0.39440250396728516s
epoch 90: {'train_loss': '2.84892'}; time used = 0.39321231842041016s
epoch 95: {'train_loss': '2.79399'}; time used = 0.3985574245452881s
epoch 100: {'train_loss': '2.74219'}; time used = 0.5728771686553955s
epoch 105: {'train_loss': '2.66527'}; time used = 0.6333339214324951s
epoch 110: {'train_loss': '2.56124'}; time used = 0.5297048091888428s
epoch 115: {'train_loss': '2.51990'}; time used = 0.40137648582458496s
epoch 120: {'train_loss': '2.37377'}; time used = 0.41834068298339844s
epoch 125: {'train_loss': '2.41553'}; time used = 0.458179235458374s
epoch 130: {'train_loss': '2.32905'}; time used = 0.34801626205444336s
epoch 135: {'train_loss': '2.28455'}; time used = 0.3981289863586426s
epoch 140: {'train_loss': '2.15704'}; time used = 0.6134130954742432s
epoch 145: {'train_loss': '2.16434'}; time used = 0.6705145835876465s
epoch 150: {'train_loss': '2.11033'}; time used = 0.5309360027313232s
epoch 155: {'train_loss': '2.05200'}; time used = 0.6812558174133301s
epoch 160: {'train_loss': '1.95595'}; time used = 0.43943238258361816s
epoch 165: {'train_loss': '1.94400'}; time used = 0.3900032043457031s
epoch 170: {'train_loss': '1.84527'}; time used = 0.32613134384155273s
epoch 175: {'train_loss': '1.87546'}; time used = 0.3312869071960449s
epoch 180: {'train_loss': '1.85503'}; time used = 0.3878512382507324s
epoch 185: {'train_loss': '1.79658'}; time used = 0.3626434803009033s
epoch 190: {'train_loss': '1.75981'}; time used = 0.4543876647949219s
epoch 195: {'train_loss': '1.72198'}; time used = 0.4259467124938965s
epoch 200: {'train_loss': '1.67641'}; time used = 0.5897455215454102s
epoch 205: {'train_loss': '1.65773'}; time used = 0.4848034381866455s
epoch 210: {'train_loss': '1.60272'}; time used = 0.42894983291625977s
epoch 215: {'train_loss': '1.54841'}; time used = 0.3842906951904297s
epoch 220: {'train_loss': '1.51779'}; time used = 0.4393000602722168s
epoch 225: {'train_loss': '1.51478'}; time used = 0.5114364624023438s
epoch 230: {'train_loss': '1.46589'}; time used = 0.5763959884643555s
epoch 235: {'train_loss': '1.41416'}; time used = 0.493549108505249s
epoch 240: {'train_loss': '1.38847'}; time used = 0.5525574684143066s
epoch 245: {'train_loss': '1.35898'}; time used = 0.4314565658569336s
epoch 250: {'train_loss': '1.33961'}; time used = 0.41724395751953125s
epoch 255: {'train_loss': '1.33203'}; time used = 0.4737241268157959s
epoch 260: {'train_loss': '1.32367'}; time used = 0.6835668087005615s
epoch 265: {'train_loss': '1.27939'}; time used = 0.7073354721069336s
epoch 270: {'train_loss': '1.25570'}; time used = 0.8732280731201172s
epoch 275: {'train_loss': '1.24544'}; time used = 0.40575742721557617s
epoch 280: {'train_loss': '1.20882'}; time used = 0.34193849563598633s
epoch 285: {'train_loss': '1.19765'}; time used = 0.4000816345214844s
epoch 290: {'train_loss': '1.16624'}; time used = 0.4102044105529785s
epoch 295: {'train_loss': '1.15813'}; time used = 0.34946417808532715s
epoch 300: {'train_loss': '1.17738'}; time used = 0.5161242485046387s
epoch 305: {'train_loss': '1.13671'}; time used = 0.5324621200561523s
epoch 310: {'train_loss': '1.11340'}; time used = 0.6143441200256348s
epoch 315: {'train_loss': '1.10903'}; time used = 0.37978076934814453s
epoch 320: {'train_loss': '1.11843'}; time used = 0.4058408737182617s
epoch 325: {'train_loss': '1.07703'}; time used = 0.36235475540161133s
epoch 330: {'train_loss': '1.05909'}; time used = 0.3575937747955322s
epoch 335: {'train_loss': '1.04421'}; time used = 0.512765645980835s
epoch 340: {'train_loss': '1.02421'}; time used = 0.4533560276031494s
epoch 345: {'train_loss': '1.02982'}; time used = 0.6273651123046875s
epoch 350: {'train_loss': '1.01639'}; time used = 0.49024176597595215s
epoch 355: {'train_loss': '1.01235'}; time used = 0.694692850112915s
epoch 360: {'train_loss': '0.98592'}; time used = 0.47661447525024414s
epoch 365: {'train_loss': '0.98296'}; time used = 0.45560622215270996s
epoch 370: {'train_loss': '0.98585'}; time used = 0.46689486503601074s
epoch 375: {'train_loss': '0.97432'}; time used = 0.5535435676574707s
epoch 380: {'train_loss': '0.97051'}; time used = 0.7039074897766113s
epoch 385: {'train_loss': '0.94834'}; time used = 0.7331979274749756s
epoch 390: {'train_loss': '0.92053'}; time used = 0.40780019760131836s
epoch 395: {'train_loss': '0.94399'}; time used = 0.4414491653442383s
epoch 400: {'train_loss': '0.92661'}; time used = 0.5634758472442627s
epoch 405: {'train_loss': '0.92730'}; time used = 0.33212852478027344s
epoch 410: {'train_loss': '0.92834'}; time used = 0.42067909240722656s
epoch 415: {'train_loss': '0.91535'}; time used = 0.40428638458251953s
epoch 420: {'train_loss': '0.89828'}; time used = 0.5984342098236084s
epoch 425: {'train_loss': '0.90341'}; time used = 0.489809513092041s
epoch 430: {'train_loss': '0.90626'}; time used = 0.543428897857666s
epoch 435: {'train_loss': '0.89381'}; time used = 0.3576786518096924s
epoch 440: {'train_loss': '0.89209'}; time used = 0.464247465133667s
epoch 445: {'train_loss': '0.88021'}; time used = 0.4081857204437256s
epoch 450: {'train_loss': '0.87990'}; time used = 0.40209007263183594s
epoch 455: {'train_loss': '0.87735'}; time used = 0.5377256870269775s
epoch 460: {'train_loss': '0.86617'}; time used = 0.39634203910827637s
epoch 465: {'train_loss': '0.86126'}; time used = 0.43302345275878906s
epoch 470: {'train_loss': '0.86775'}; time used = 0.476839542388916s
epoch 475: {'train_loss': '0.86857'}; time used = 0.46502065658569336s
epoch 480: {'train_loss': '0.84945'}; time used = 0.4283595085144043s
epoch 485: {'train_loss': '0.84008'}; time used = 0.6169776916503906s
epoch 490: {'train_loss': '0.84112'}; time used = 0.6727886199951172s
epoch 495: {'train_loss': '0.83896'}; time used = 0.5651154518127441s
epoch 500: {'train_loss': '0.83762'}; time used = 0.7202677726745605s
Finished training. Time used = 56.050662994384766.
Training classifier using 20.00% nodes...
{'micro': 0.33917858790955235, 'macro': 0.18646871817943045, 'samples': 0.33917858790955235, 'weighted': 0.2610750443902996}

  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6386/10556 [00:00<00:00, 62179.24it/s]100%|| 10556/10556 [00:00<00:00, 66653.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9157/10556 [00:00<00:00, 91564.85it/s]100%|| 10556/10556 [00:00<00:00, 94565.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7140/10556 [00:00<00:00, 68831.15it/s]100%|| 10556/10556 [00:00<00:00, 71126.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112990.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10551/10556 [00:00<00:00, 105509.85it/s]100%|| 10556/10556 [00:00<00:00, 105069.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 99997.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116411.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124883.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6562/10556 [00:00<00:00, 65619.28it/s]100%|| 10556/10556 [00:00<00:00, 67100.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9032/10556 [00:00<00:00, 90319.44it/s]100%|| 10556/10556 [00:00<00:00, 83664.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6258/10556 [00:00<00:00, 59008.04it/s]100%|| 10556/10556 [00:00<00:00, 62571.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121114.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8884/10556 [00:00<00:00, 88833.52it/s]100%|| 10556/10556 [00:00<00:00, 92808.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124908.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|      | 3514/10556 [00:00<00:00, 32664.95it/s]100%|| 10556/10556 [00:00<00:00, 63923.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7415/10556 [00:00<00:00, 74148.48it/s]100%|| 10556/10556 [00:00<00:00, 71762.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5202/10556 [00:00<00:00, 51600.04it/s] 96%|| 10089/10556 [00:00<00:00, 50121.76it/s]100%|| 10556/10556 [00:00<00:00, 49756.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8280/10556 [00:00<00:00, 82795.74it/s]100%|| 10556/10556 [00:00<00:00, 80006.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5374/10556 [00:00<00:00, 53739.15it/s]100%|| 10556/10556 [00:00<00:00, 61006.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|      | 3432/10556 [00:00<00:00, 28262.72it/s] 89%| | 9431/10556 [00:00<00:00, 33592.42it/s]100%|| 10556/10556 [00:00<00:00, 39631.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6288/10556 [00:00<00:00, 62879.31it/s]100%|| 10556/10556 [00:00<00:00, 53381.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6446/10556 [00:00<00:00, 57711.57it/s]100%|| 10556/10556 [00:00<00:00, 59843.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9782/10556 [00:00<00:00, 97819.86it/s]100%|| 10556/10556 [00:00<00:00, 98411.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10439/10556 [00:00<00:00, 104389.85it/s]100%|| 10556/10556 [00:00<00:00, 104182.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116698.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7835/10556 [00:00<00:00, 78348.95it/s]100%|| 10556/10556 [00:00<00:00, 85119.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8037/10556 [00:00<00:00, 80364.33it/s]100%|| 10556/10556 [00:00<00:00, 80712.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 7991/10556 [00:00<00:00, 74080.99it/s]100%|| 10556/10556 [00:00<00:00, 59678.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3782/10556 [00:00<00:00, 37161.21it/s]100%|| 10556/10556 [00:00<00:00, 53083.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4414/10556 [00:00<00:00, 37527.25it/s] 76%|  | 8054/10556 [00:00<00:00, 35842.78it/s]100%|| 10556/10556 [00:00<00:00, 37828.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4445/10556 [00:00<00:00, 42309.21it/s]100%|| 10556/10556 [00:00<00:00, 60456.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5096/10556 [00:00<00:00, 50957.38it/s] 85%| | 8992/10556 [00:00<00:00, 44786.17it/s]100%|| 10556/10556 [00:00<00:00, 42300.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3648/10556 [00:00<00:00, 32609.26it/s] 67%|   | 7074/10556 [00:00<00:00, 33087.20it/s]100%|| 10556/10556 [00:00<00:00, 34540.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|       | 3105/10556 [00:00<00:00, 28198.51it/s] 77%|  | 8089/10556 [00:00<00:00, 32421.09it/s] 99%|| 10488/10556 [00:00<00:00, 29328.22it/s]100%|| 10556/10556 [00:00<00:00, 33766.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9791/10556 [00:00<00:00, 97902.62it/s]100%|| 10556/10556 [00:00<00:00, 95843.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5735/10556 [00:00<00:00, 57346.50it/s] 88%| | 9259/10556 [00:00<00:00, 48126.37it/s]100%|| 10556/10556 [00:00<00:00, 46944.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3860/10556 [00:00<00:00, 31999.24it/s] 87%| | 9221/10556 [00:00<00:00, 35834.58it/s]100%|| 10556/10556 [00:00<00:00, 40952.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4586/10556 [00:00<00:00, 45855.89it/s] 97%|| 10233/10556 [00:00<00:00, 48596.11it/s]100%|| 10556/10556 [00:00<00:00, 47211.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3885/10556 [00:00<00:00, 38848.00it/s] 60%|    | 6372/10556 [00:00<00:00, 33095.18it/s]100%|| 10556/10556 [00:00<00:00, 41886.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8570/10556 [00:00<00:00, 83607.26it/s]100%|| 10556/10556 [00:00<00:00, 79299.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|       | 3094/10556 [00:00<00:00, 27959.07it/s]100%|| 10556/10556 [00:00<00:00, 60308.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7153/10556 [00:00<00:00, 66391.65it/s]100%|| 10556/10556 [00:00<00:00, 77439.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6906/10556 [00:00<00:00, 69056.77it/s]100%|| 10556/10556 [00:00<00:00, 75335.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6586/10556 [00:00<00:00, 65855.98it/s]100%|| 10556/10556 [00:00<00:00, 62698.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7036/10556 [00:00<00:00, 70353.36it/s]100%|| 10556/10556 [00:00<00:00, 60079.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6257/10556 [00:00<00:00, 62565.58it/s]100%|| 10556/10556 [00:00<00:00, 59765.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6001/10556 [00:00<00:00, 60008.48it/s]100%|| 10556/10556 [00:00<00:00, 54265.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4631/10556 [00:00<00:00, 44437.63it/s] 91%| | 9589/10556 [00:00<00:00, 45863.69it/s]100%|| 10556/10556 [00:00<00:00, 47346.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6258/10556 [00:00<00:00, 62579.46it/s]100%|| 10556/10556 [00:00<00:00, 61814.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7924/10556 [00:00<00:00, 79238.75it/s]100%|| 10556/10556 [00:00<00:00, 86710.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120984.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6971/10556 [00:00<00:00, 69704.25it/s]100%|| 10556/10556 [00:00<00:00, 65140.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8529/10556 [00:00<00:00, 85218.97it/s]100%|| 10556/10556 [00:00<00:00, 84054.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118883.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8788/10556 [00:00<00:00, 87876.52it/s]100%|| 10556/10556 [00:00<00:00, 87504.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5503/10556 [00:00<00:00, 54527.84it/s]100%|| 10556/10556 [00:00<00:00, 53644.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4317/10556 [00:00<00:00, 40625.92it/s]100%|| 10556/10556 [00:00<00:00, 56656.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7064/10556 [00:00<00:00, 67986.92it/s]100%|| 10556/10556 [00:00<00:00, 76074.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125033.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117636.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5894/10556 [00:00<00:00, 58939.92it/s]100%|| 10556/10556 [00:00<00:00, 55665.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5281/10556 [00:00<00:00, 49693.69it/s] 73%|  | 7722/10556 [00:00<00:00, 37302.74it/s]100%|| 10556/10556 [00:00<00:00, 41268.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114460.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|      | 3543/10556 [00:00<00:00, 35428.68it/s] 91%| | 9583/10556 [00:00<00:00, 39826.33it/s]100%|| 10556/10556 [00:00<00:00, 44928.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9112/10556 [00:00<00:00, 91115.31it/s]100%|| 10556/10556 [00:00<00:00, 81872.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10261/10556 [00:00<00:00, 102603.25it/s]100%|| 10556/10556 [00:00<00:00, 102732.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114624.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6276/10556 [00:00<00:00, 60439.07it/s]100%|| 10556/10556 [00:00<00:00, 61500.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5802/10556 [00:00<00:00, 58016.60it/s]100%|| 10556/10556 [00:00<00:00, 64578.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6710/10556 [00:00<00:00, 66043.35it/s]100%|| 10556/10556 [00:00<00:00, 73513.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6150/10556 [00:00<00:00, 61495.66it/s]100%|| 10556/10556 [00:00<00:00, 56063.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5353/10556 [00:00<00:00, 53528.77it/s] 81%|  | 8565/10556 [00:00<00:00, 44607.76it/s]100%|| 10556/10556 [00:00<00:00, 48663.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5636/10556 [00:00<00:00, 44245.77it/s]100%|| 10556/10556 [00:00<00:00, 52767.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5757/10556 [00:00<00:00, 57564.84it/s]100%|| 10556/10556 [00:00<00:00, 54185.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5160/10556 [00:00<00:00, 51135.43it/s]100%|| 10556/10556 [00:00<00:00, 56202.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6726/10556 [00:00<00:00, 62379.11it/s]100%|| 10556/10556 [00:00<00:00, 60964.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6088/10556 [00:00<00:00, 60875.56it/s]100%|| 10556/10556 [00:00<00:00, 52385.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7077/10556 [00:00<00:00, 70768.72it/s]100%|| 10556/10556 [00:00<00:00, 74808.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5454/10556 [00:00<00:00, 54536.02it/s]100%|| 10556/10556 [00:00<00:00, 57663.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7834/10556 [00:00<00:00, 78331.30it/s]100%|| 10556/10556 [00:00<00:00, 60576.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115094.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8995/10556 [00:00<00:00, 89941.51it/s]100%|| 10556/10556 [00:00<00:00, 92972.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7637/10556 [00:00<00:00, 76365.70it/s]100%|| 10556/10556 [00:00<00:00, 85096.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110087.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7090/10556 [00:00<00:00, 70894.32it/s]100%|| 10556/10556 [00:00<00:00, 80587.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7884/10556 [00:00<00:00, 78837.26it/s]100%|| 10556/10556 [00:00<00:00, 81940.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7412/10556 [00:00<00:00, 74119.01it/s]100%|| 10556/10556 [00:00<00:00, 82084.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9389/10556 [00:00<00:00, 93880.69it/s]100%|| 10556/10556 [00:00<00:00, 80047.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6377/10556 [00:00<00:00, 63762.16it/s]100%|| 10556/10556 [00:00<00:00, 65193.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7762/10556 [00:00<00:00, 77102.24it/s]100%|| 10556/10556 [00:00<00:00, 68591.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3675/10556 [00:00<00:00, 34466.87it/s] 82%| | 8664/10556 [00:00<00:00, 37989.82it/s]100%|| 10556/10556 [00:00<00:00, 45355.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3422/10556 [00:00<00:00, 34216.04it/s] 93%|| 9862/10556 [00:00<00:00, 39814.04it/s]100%|| 10556/10556 [00:00<00:00, 49822.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119966.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110590.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122592.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122852.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118312.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6108/10556 [00:00<00:00, 60556.69it/s]100%|| 10556/10556 [00:00<00:00, 65286.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8477/10556 [00:00<00:00, 84769.47it/s]100%|| 10556/10556 [00:00<00:00, 78251.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8981/10556 [00:00<00:00, 89804.73it/s]100%|| 10556/10556 [00:00<00:00, 93216.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6514/10556 [00:00<00:00, 65136.49it/s]100%|| 10556/10556 [00:00<00:00, 79261.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9321/10556 [00:00<00:00, 93206.53it/s]100%|| 10556/10556 [00:00<00:00, 85096.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123917.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 102140.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9483/10556 [00:00<00:00, 94829.86it/s]100%|| 10556/10556 [00:00<00:00, 87109.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9477/10556 [00:00<00:00, 90511.97it/s]100%|| 10556/10556 [00:00<00:00, 92943.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10321/10556 [00:00<00:00, 103207.15it/s]100%|| 10556/10556 [00:00<00:00, 102495.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107106.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7669/10556 [00:00<00:00, 76685.69it/s]100%|| 10556/10556 [00:00<00:00, 74575.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8074/10556 [00:00<00:00, 80737.00it/s]100%|| 10556/10556 [00:00<00:00, 76125.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8070/10556 [00:00<00:00, 80699.11it/s]100%|| 10556/10556 [00:00<00:00, 87881.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114086.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8560/10556 [00:00<00:00, 85596.41it/s]100%|| 10556/10556 [00:00<00:00, 85945.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8782/10556 [00:00<00:00, 87812.97it/s]100%|| 10556/10556 [00:00<00:00, 90380.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9363/10556 [00:00<00:00, 93623.39it/s]100%|| 10556/10556 [00:00<00:00, 90558.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10099/10556 [00:00<00:00, 100983.35it/s]100%|| 10556/10556 [00:00<00:00, 81028.44it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4120/10556 [00:00<00:00, 39954.53it/s] 92%|| 9681/10556 [00:00<00:00, 43562.71it/s]100%|| 10556/10556 [00:00<00:00, 48157.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122190.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124134.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123345.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122132.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120922.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9590/10556 [00:00<00:00, 95895.75it/s]100%|| 10556/10556 [00:00<00:00, 97810.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109044.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10325/10556 [00:00<00:00, 102046.50it/s]100%|| 10556/10556 [00:00<00:00, 99937.64it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7921/10556 [00:00<00:00, 79208.00it/s]100%|| 10556/10556 [00:00<00:00, 86548.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10339/10556 [00:00<00:00, 103385.66it/s]100%|| 10556/10556 [00:00<00:00, 103426.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122064.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8214/10556 [00:00<00:00, 82133.03it/s]100%|| 10556/10556 [00:00<00:00, 88364.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118446.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121409.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115599.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9400/10556 [00:00<00:00, 93995.83it/s]100%|| 10556/10556 [00:00<00:00, 95314.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9959/10556 [00:00<00:00, 99582.73it/s]100%|| 10556/10556 [00:00<00:00, 99816.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115768.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117293.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8409/10556 [00:00<00:00, 84089.48it/s]100%|| 10556/10556 [00:00<00:00, 92401.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6793/10556 [00:00<00:00, 61101.83it/s]100%|| 10556/10556 [00:00<00:00, 64420.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|      | 3633/10556 [00:00<00:00, 33031.24it/s]100%|| 10556/10556 [00:00<00:00, 55706.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7607/10556 [00:00<00:00, 76067.35it/s]100%|| 10556/10556 [00:00<00:00, 84341.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110566.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 97124.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|  | 7542/10556 [00:00<00:00, 75418.27it/s]100%|| 10556/10556 [00:00<00:00, 68518.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9101/10556 [00:00<00:00, 91009.44it/s]100%|| 10556/10556 [00:00<00:00, 84650.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5298/10556 [00:00<00:00, 52929.32it/s]100%|| 10556/10556 [00:00<00:00, 54563.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6384/10556 [00:00<00:00, 63836.71it/s]100%|| 10556/10556 [00:00<00:00, 61002.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7463/10556 [00:00<00:00, 70248.95it/s]100%|| 10556/10556 [00:00<00:00, 67231.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5665/10556 [00:00<00:00, 48317.15it/s] 97%|| 10205/10556 [00:00<00:00, 47076.58it/s]100%|| 10556/10556 [00:00<00:00, 46734.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5269/10556 [00:00<00:00, 52689.05it/s] 93%|| 9806/10556 [00:00<00:00, 49722.61it/s]100%|| 10556/10556 [00:00<00:00, 46693.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5294/10556 [00:00<00:00, 43585.95it/s] 95%|| 10059/10556 [00:00<00:00, 44730.42it/s]100%|| 10556/10556 [00:00<00:00, 43266.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6415/10556 [00:00<00:00, 64144.86it/s] 90%| | 9515/10556 [00:00<00:00, 48564.70it/s]100%|| 10556/10556 [00:00<00:00, 50566.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6418/10556 [00:00<00:00, 64177.46it/s]100%|| 10556/10556 [00:00<00:00, 55657.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3783/10556 [00:00<00:00, 36408.86it/s]100%|| 10556/10556 [00:00<00:00, 52017.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9540/10556 [00:00<00:00, 94329.79it/s]100%|| 10556/10556 [00:00<00:00, 89363.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9608/10556 [00:00<00:00, 83728.00it/s]100%|| 10556/10556 [00:00<00:00, 74578.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113935.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5075/10556 [00:00<00:00, 49297.90it/s] 83%| | 8709/10556 [00:00<00:00, 43179.17it/s]100%|| 10556/10556 [00:00<00:00, 38210.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7124/10556 [00:00<00:00, 67840.21it/s]100%|| 10556/10556 [00:00<00:00, 52928.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7255/10556 [00:00<00:00, 72545.23it/s]100%|| 10556/10556 [00:00<00:00, 82853.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5288/10556 [00:00<00:00, 52873.24it/s] 86%| | 9128/10556 [00:00<00:00, 47500.67it/s]100%|| 10556/10556 [00:00<00:00, 38974.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5886/10556 [00:00<00:00, 50633.18it/s]100%|| 10538/10556 [00:00<00:00, 49324.05it/s]100%|| 10556/10556 [00:00<00:00, 48693.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6946/10556 [00:00<00:00, 69458.41it/s]100%|| 10556/10556 [00:00<00:00, 64715.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5847/10556 [00:00<00:00, 57643.67it/s] 83%| | 8805/10556 [00:00<00:00, 42167.15it/s]100%|| 10556/10556 [00:00<00:00, 38568.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5671/10556 [00:00<00:00, 56709.78it/s]100%|| 10556/10556 [00:00<00:00, 73470.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4966/10556 [00:00<00:00, 46730.31it/s] 76%|  | 7993/10556 [00:00<00:00, 40176.11it/s]100%|| 10556/10556 [00:00<00:00, 36589.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8975/10556 [00:00<00:00, 89746.66it/s]100%|| 10556/10556 [00:00<00:00, 88506.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4273/10556 [00:00<00:00, 40345.01it/s] 89%| | 9424/10556 [00:00<00:00, 43150.70it/s]100%|| 10556/10556 [00:00<00:00, 46444.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6633/10556 [00:00<00:00, 66328.64it/s]100%|| 10556/10556 [00:00<00:00, 62837.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5830/10556 [00:00<00:00, 54952.94it/s]100%|| 10556/10556 [00:00<00:00, 50389.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5109/10556 [00:00<00:00, 51086.03it/s] 78%|  | 8202/10556 [00:00<00:00, 42731.71it/s]100%|| 10556/10556 [00:00<00:00, 38621.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3837/10556 [00:00<00:00, 37100.11it/s] 96%|| 10178/10556 [00:00<00:00, 42374.45it/s]100%|| 10556/10556 [00:00<00:00, 51019.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6573/10556 [00:00<00:00, 65724.42it/s]100%|| 10556/10556 [00:00<00:00, 63749.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5166/10556 [00:00<00:00, 51658.32it/s] 95%|| 10066/10556 [00:00<00:00, 50830.78it/s]100%|| 10556/10556 [00:00<00:00, 50162.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4819/10556 [00:00<00:00, 45504.46it/s]100%|| 10556/10556 [00:00<00:00, 68002.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6060/10556 [00:00<00:00, 60128.55it/s] 99%|| 10428/10556 [00:00<00:00, 53724.39it/s]100%|| 10556/10556 [00:00<00:00, 51532.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106433.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7679/10556 [00:00<00:00, 76784.03it/s]100%|| 10556/10556 [00:00<00:00, 85234.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6174/10556 [00:00<00:00, 54122.09it/s]100%|| 10556/10556 [00:00<00:00, 46139.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4919/10556 [00:00<00:00, 45706.81it/s]100%|| 10556/10556 [00:00<00:00, 51163.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8636/10556 [00:00<00:00, 84652.22it/s]100%|| 10556/10556 [00:00<00:00, 81141.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5449/10556 [00:00<00:00, 52141.61it/s]100%|| 10556/10556 [00:00<00:00, 53235.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5852/10556 [00:00<00:00, 58509.45it/s]100%|| 10556/10556 [00:00<00:00, 55066.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6393/10556 [00:00<00:00, 63929.45it/s]100%|| 10556/10556 [00:00<00:00, 54134.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|      | 3964/10556 [00:00<00:00, 39638.34it/s]100%|| 10556/10556 [00:00<00:00, 58899.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10441/10556 [00:00<00:00, 104409.10it/s]100%|| 10556/10556 [00:00<00:00, 104186.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9579/10556 [00:00<00:00, 95785.52it/s]100%|| 10556/10556 [00:00<00:00, 84933.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%| | 8580/10556 [00:00<00:00, 85795.38it/s]100%|| 10556/10556 [00:00<00:00, 90845.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121079.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6906/10556 [00:00<00:00, 69059.90it/s]100%|| 10556/10556 [00:00<00:00, 81376.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10099/10556 [00:00<00:00, 98168.82it/s]100%|| 10556/10556 [00:00<00:00, 92101.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|      | 3557/10556 [00:00<00:00, 29970.63it/s] 84%| | 8839/10556 [00:00<00:00, 34439.40it/s]100%|| 10556/10556 [00:00<00:00, 39539.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4587/10556 [00:00<00:00, 42769.43it/s]100%|| 10556/10556 [00:00<00:00, 67780.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9161/10556 [00:00<00:00, 91605.28it/s]100%|| 10556/10556 [00:00<00:00, 94512.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116370.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6806/10556 [00:00<00:00, 68055.36it/s]100%|| 10556/10556 [00:00<00:00, 76530.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10371/10556 [00:00<00:00, 103704.16it/s]100%|| 10556/10556 [00:00<00:00, 103614.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8478/10556 [00:00<00:00, 84779.88it/s]100%|| 10556/10556 [00:00<00:00, 63368.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10224/10556 [00:00<00:00, 102233.03it/s]100%|| 10556/10556 [00:00<00:00, 102338.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6649/10556 [00:00<00:00, 66487.05it/s]100%|| 10556/10556 [00:00<00:00, 71777.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7721/10556 [00:00<00:00, 77207.13it/s]100%|| 10556/10556 [00:00<00:00, 67422.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5447/10556 [00:00<00:00, 54469.27it/s]100%|| 10556/10556 [00:00<00:00, 54878.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8948/10556 [00:00<00:00, 89472.83it/s]100%|| 10556/10556 [00:00<00:00, 93131.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9068/10556 [00:00<00:00, 90668.85it/s]100%|| 10556/10556 [00:00<00:00, 79594.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7847/10556 [00:00<00:00, 78467.46it/s]100%|| 10556/10556 [00:00<00:00, 86590.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8910/10556 [00:00<00:00, 89094.14it/s]100%|| 10556/10556 [00:00<00:00, 92903.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118172.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5450/10556 [00:00<00:00, 54100.20it/s]100%|| 10556/10556 [00:00<00:00, 70758.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9607/10556 [00:00<00:00, 96069.40it/s]100%|| 10556/10556 [00:00<00:00, 97630.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9323/10556 [00:00<00:00, 93224.98it/s]100%|| 10556/10556 [00:00<00:00, 95581.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117263.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116103.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120831.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115056.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5819/10556 [00:00<00:00, 57860.08it/s]100%|| 10556/10556 [00:00<00:00, 56578.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6972/10556 [00:00<00:00, 66148.85it/s]100%|| 10556/10556 [00:00<00:00, 76555.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8890/10556 [00:00<00:00, 88897.12it/s]100%|| 10556/10556 [00:00<00:00, 88036.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6389/10556 [00:00<00:00, 62540.04it/s]100%|| 10556/10556 [00:00<00:00, 60583.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6099/10556 [00:00<00:00, 60986.42it/s]100%|| 10556/10556 [00:00<00:00, 58726.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9264/10556 [00:00<00:00, 92637.44it/s]100%|| 10556/10556 [00:00<00:00, 95039.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7185/10556 [00:00<00:00, 71845.79it/s]100%|| 10556/10556 [00:00<00:00, 78103.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7188/10556 [00:00<00:00, 70389.80it/s]100%|| 10556/10556 [00:00<00:00, 58729.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9725/10556 [00:00<00:00, 97247.08it/s]100%|| 10556/10556 [00:00<00:00, 98419.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5868/10556 [00:00<00:00, 58674.60it/s] 97%|| 10244/10556 [00:00<00:00, 53231.54it/s]100%|| 10556/10556 [00:00<00:00, 52053.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7268/10556 [00:00<00:00, 66985.73it/s]100%|| 10556/10556 [00:00<00:00, 76157.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5928/10556 [00:00<00:00, 59275.53it/s]100%|| 10556/10556 [00:00<00:00, 74703.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121666.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105742.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7595/10556 [00:00<00:00, 70269.91it/s]100%|| 10556/10556 [00:00<00:00, 66457.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112177.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6757/10556 [00:00<00:00, 67569.26it/s]100%|| 10556/10556 [00:00<00:00, 68829.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7664/10556 [00:00<00:00, 72590.92it/s]100%|| 10556/10556 [00:00<00:00, 54143.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119871.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6581/10556 [00:00<00:00, 63876.25it/s]100%|| 10556/10556 [00:00<00:00, 62003.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7357/10556 [00:00<00:00, 67690.58it/s]100%|| 10556/10556 [00:00<00:00, 77924.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105480.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6705/10556 [00:00<00:00, 67048.79it/s]100%|| 10556/10556 [00:00<00:00, 68054.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5102/10556 [00:00<00:00, 51019.20it/s]100%|| 10556/10556 [00:00<00:00, 66656.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162667.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171484.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170469.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178475.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124839.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157363.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167921.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180250.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128930.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4987/10556 [00:00<00:00, 49867.79it/s]100%|| 10556/10556 [00:00<00:00, 78584.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191080.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182586.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177436.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169198.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106114.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|  | 7535/10556 [00:00<00:00, 75345.04it/s]100%|| 10556/10556 [00:00<00:00, 77978.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6051/10556 [00:00<00:00, 59519.56it/s]100%|| 10556/10556 [00:00<00:00, 58754.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119706.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114713.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133682.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164973.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118251.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128203.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5211/10556 [00:00<00:00, 46539.67it/s]100%|| 10556/10556 [00:00<00:00, 58088.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115538.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8257/10556 [00:00<00:00, 80039.31it/s]100%|| 10556/10556 [00:00<00:00, 66224.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128427.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5045/10556 [00:00<00:00, 49844.21it/s]100%|| 10556/10556 [00:00<00:00, 79359.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140923.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111419.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6451/10556 [00:00<00:00, 55791.21it/s]100%|| 10556/10556 [00:00<00:00, 58504.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5329/10556 [00:00<00:00, 49881.49it/s]100%|| 10556/10556 [00:00<00:00, 56500.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8280/10556 [00:00<00:00, 82795.74it/s]100%|| 10556/10556 [00:00<00:00, 88607.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148477.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122139.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9684/10556 [00:00<00:00, 96586.55it/s]100%|| 10556/10556 [00:00<00:00, 83817.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8037/10556 [00:00<00:00, 79150.63it/s]100%|| 10556/10556 [00:00<00:00, 74667.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153716.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183983.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6869/10556 [00:00<00:00, 57088.71it/s]100%|| 10556/10556 [00:00<00:00, 61719.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145860.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 210688.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9739/10556 [00:00<00:00, 95307.97it/s]100%|| 10556/10556 [00:00<00:00, 88806.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130373.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6938/10556 [00:00<00:00, 69377.25it/s]100%|| 10556/10556 [00:00<00:00, 89766.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186813.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7133/10556 [00:00<00:00, 70709.84it/s]100%|| 10556/10556 [00:00<00:00, 84931.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114385.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10517/10556 [00:00<00:00, 104430.87it/s]100%|| 10556/10556 [00:00<00:00, 103456.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135806.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144179.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7346/10556 [00:00<00:00, 73456.22it/s]100%|| 10556/10556 [00:00<00:00, 82756.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117635.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124533.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7811/10556 [00:00<00:00, 78107.28it/s]100%|| 10556/10556 [00:00<00:00, 82549.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122947.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150313.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160960.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181036.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155681.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172354.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159754.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9743/10556 [00:00<00:00, 97428.93it/s]100%|| 10556/10556 [00:00<00:00, 101133.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181607.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182346.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181743.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176667.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179890.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178591.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7914/10556 [00:00<00:00, 79137.43it/s]100%|| 10556/10556 [00:00<00:00, 81657.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191354.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194272.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177398.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157522.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127027.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182516.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174009.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8857/10556 [00:00<00:00, 88566.07it/s]100%|| 10556/10556 [00:00<00:00, 95626.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152495.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171177.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173628.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8079/10556 [00:00<00:00, 79246.08it/s]100%|| 10556/10556 [00:00<00:00, 78978.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149712.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3339/10556 [00:00<00:00, 31643.50it/s]100%|| 10556/10556 [00:00<00:00, 60791.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126515.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119713.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123645.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177695.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179299.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179191.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174959.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171038.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9086/10556 [00:00<00:00, 86860.52it/s]100%|| 10556/10556 [00:00<00:00, 72168.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6806/10556 [00:00<00:00, 63534.08it/s]100%|| 10556/10556 [00:00<00:00, 64357.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150125.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134430.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155069.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148548.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149707.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132378.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148919.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156417.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149288.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151303.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106415.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141244.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148783.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152774.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153772.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147421.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110656.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107451.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116127.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129269.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159184.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156145.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149436.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146819.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107055.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9497/10556 [00:00<00:00, 93495.53it/s]100%|| 10556/10556 [00:00<00:00, 61754.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5596/10556 [00:00<00:00, 51235.69it/s]100%|| 10556/10556 [00:00<00:00, 56582.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6410/10556 [00:00<00:00, 64097.31it/s]100%|| 10556/10556 [00:00<00:00, 86978.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136033.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8283/10556 [00:00<00:00, 76602.08it/s]100%|| 10556/10556 [00:00<00:00, 73039.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120707.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117825.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5276/10556 [00:00<00:00, 50168.10it/s]100%|| 10556/10556 [00:00<00:00, 66174.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 28%|       | 2955/10556 [00:00<00:00, 29547.70it/s] 74%|  | 7795/10556 [00:00<00:00, 31581.07it/s]100%|| 10556/10556 [00:00<00:00, 36397.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10262/10556 [00:00<00:00, 101782.65it/s]100%|| 10556/10556 [00:00<00:00, 97528.42it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9078/10556 [00:00<00:00, 90773.81it/s]100%|| 10556/10556 [00:00<00:00, 94269.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7002/10556 [00:00<00:00, 70016.90it/s] 88%| | 9271/10556 [00:00<00:00, 40391.36it/s]100%|| 10556/10556 [00:00<00:00, 44202.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120415.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182972.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 97112.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9709/10556 [00:00<00:00, 97087.78it/s]100%|| 10556/10556 [00:00<00:00, 98385.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119566.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121939.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158855.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159665.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179405.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184265.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182747.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187079.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149244.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182024.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181050.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187335.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183500.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182230.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183927.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187825.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191158.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192221.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186510.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132173.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138063.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144415.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6277/10556 [00:00<00:00, 59098.71it/s]100%|| 10556/10556 [00:00<00:00, 78190.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151821.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152625.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146301.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3725/10556 [00:00<00:00, 37248.35it/s] 91%| | 9612/10556 [00:00<00:00, 41370.40it/s]100%|| 10556/10556 [00:00<00:00, 46240.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190128.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184430.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6561/10556 [00:00<00:00, 65605.06it/s]100%|| 10556/10556 [00:00<00:00, 84628.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164057.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183601.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118794.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113790.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5600/10556 [00:00<00:00, 55996.18it/s]100%|| 10556/10556 [00:00<00:00, 75700.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180865.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186078.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185631.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192060.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183248.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182756.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127461.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121465.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154961.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177280.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176016.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182001.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167996.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 9012/10556 [00:00<00:00, 90114.71it/s]100%|| 10556/10556 [00:00<00:00, 83918.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143433.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164384.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183687.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177211.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180994.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7848/10556 [00:00<00:00, 77031.93it/s]100%|| 10556/10556 [00:00<00:00, 78653.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184617.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153320.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124445.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141848.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10330/10556 [00:00<00:00, 103295.67it/s]100%|| 10556/10556 [00:00<00:00, 103328.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 89239.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 26%|       | 2731/10556 [00:00<00:00, 26756.56it/s]100%|| 10556/10556 [00:00<00:00, 59416.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150788.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148093.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174891.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164737.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179303.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7478/10556 [00:00<00:00, 74779.00it/s]100%|| 10556/10556 [00:00<00:00, 77052.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118009.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|    | 5428/10556 [00:00<00:00, 54124.68it/s]100%|| 10556/10556 [00:00<00:00, 73669.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168353.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178965.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190387.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189970.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6435/10556 [00:00<00:00, 64339.17it/s]100%|| 10556/10556 [00:00<00:00, 57563.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107141.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107504.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154425.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127898.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120899.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119374.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132318.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171931.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135729.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108691.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167775.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177401.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188565.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131935.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118448.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189861.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179305.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130585.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147582.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186802.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186859.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177224.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167430.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174948.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175964.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171988.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176032.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179063.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184058.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8368/10556 [00:00<00:00, 82309.34it/s]100%|| 10556/10556 [00:00<00:00, 52852.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8946/10556 [00:00<00:00, 89456.25it/s]100%|| 10556/10556 [00:00<00:00, 91538.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156099.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153183.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181826.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192005.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189178.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136931.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108004.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124186.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132224.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 24%|       | 2509/10556 [00:00<00:00, 25089.31it/s]100%|| 10556/10556 [00:00<00:00, 59664.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6619/10556 [00:00<00:00, 63935.26it/s]100%|| 10556/10556 [00:00<00:00, 58737.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9117/10556 [00:00<00:00, 91167.70it/s]100%|| 10556/10556 [00:00<00:00, 94676.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8749/10556 [00:00<00:00, 87488.83it/s]100%|| 10556/10556 [00:00<00:00, 92172.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|       | 3072/10556 [00:00<00:00, 30602.71it/s]100%|| 10556/10556 [00:00<00:00, 56261.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149788.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8113/10556 [00:00<00:00, 75112.71it/s]100%|| 10556/10556 [00:00<00:00, 82199.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130913.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7697/10556 [00:00<00:00, 76964.57it/s]100%|| 10556/10556 [00:00<00:00, 86557.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7053/10556 [00:00<00:00, 68746.30it/s]100%|| 10556/10556 [00:00<00:00, 59630.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 9995/10556 [00:00<00:00, 98951.22it/s]100%|| 10556/10556 [00:00<00:00, 87454.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7676/10556 [00:00<00:00, 76753.49it/s]100%|| 10556/10556 [00:00<00:00, 70758.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3334/10556 [00:00<00:00, 33339.55it/s]100%|| 10556/10556 [00:00<00:00, 54898.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117499.73it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '7.43796'}; time used = 0.7431910037994385s
epoch 10: {'train_loss': '5.96242'}; time used = 0.6960830688476562s
epoch 15: {'train_loss': '5.09041'}; time used = 0.6650996208190918s
epoch 20: {'train_loss': '4.71107'}; time used = 1.0625965595245361s
epoch 25: {'train_loss': '4.37706'}; time used = 0.6704864501953125s
epoch 30: {'train_loss': '4.43284'}; time used = 1.0164754390716553s
epoch 35: {'train_loss': '4.13933'}; time used = 1.3051095008850098s
epoch 40: {'train_loss': '4.19338'}; time used = 1.1152067184448242s
epoch 45: {'train_loss': '4.13154'}; time used = 0.8561356067657471s
epoch 50: {'train_loss': '4.09780'}; time used = 0.8532023429870605s
epoch 55: {'train_loss': '4.02818'}; time used = 0.7817871570587158s
epoch 60: {'train_loss': '4.03890'}; time used = 0.7555551528930664s
epoch 65: {'train_loss': '3.83259'}; time used = 0.8909792900085449s
epoch 70: {'train_loss': '3.83101'}; time used = 0.8290600776672363s
epoch 75: {'train_loss': '3.86224'}; time used = 1.0543251037597656s
epoch 80: {'train_loss': '3.76444'}; time used = 0.8691468238830566s
epoch 85: {'train_loss': '3.68167'}; time used = 0.6674909591674805s
epoch 90: {'train_loss': '3.57935'}; time used = 0.8851070404052734s
epoch 95: {'train_loss': '3.55875'}; time used = 0.627932071685791s
epoch 100: {'train_loss': '3.53680'}; time used = 0.7162134647369385s
epoch 105: {'train_loss': '3.50647'}; time used = 0.6086883544921875s
epoch 110: {'train_loss': '3.41042'}; time used = 0.6733226776123047s
epoch 115: {'train_loss': '3.38959'}; time used = 0.6445949077606201s
epoch 120: {'train_loss': '3.22307'}; time used = 0.6125204563140869s
epoch 125: {'train_loss': '3.32840'}; time used = 0.6325500011444092s
epoch 130: {'train_loss': '3.26975'}; time used = 0.5438086986541748s
epoch 135: {'train_loss': '3.21646'}; time used = 0.5692851543426514s
epoch 140: {'train_loss': '3.10008'}; time used = 0.8041641712188721s
epoch 145: {'train_loss': '3.14407'}; time used = 0.8168766498565674s
epoch 150: {'train_loss': '3.07804'}; time used = 1.1494078636169434s
epoch 155: {'train_loss': '3.04174'}; time used = 0.8349997997283936s
epoch 160: {'train_loss': '2.91788'}; time used = 1.1648838520050049s
epoch 165: {'train_loss': '2.92039'}; time used = 1.0711162090301514s
epoch 170: {'train_loss': '2.81045'}; time used = 1.1776456832885742s
epoch 175: {'train_loss': '2.88522'}; time used = 0.9095301628112793s
epoch 180: {'train_loss': '2.89038'}; time used = 0.9782071113586426s
epoch 185: {'train_loss': '2.81929'}; time used = 0.8656952381134033s
epoch 190: {'train_loss': '2.76785'}; time used = 0.7917385101318359s
epoch 195: {'train_loss': '2.74693'}; time used = 0.6797389984130859s
epoch 200: {'train_loss': '2.69361'}; time used = 0.8375921249389648s
epoch 205: {'train_loss': '2.69506'}; time used = 0.6313526630401611s
epoch 210: {'train_loss': '2.63244'}; time used = 0.6309926509857178s
epoch 215: {'train_loss': '2.55957'}; time used = 0.6777017116546631s
epoch 220: {'train_loss': '2.51175'}; time used = 0.8795866966247559s
epoch 225: {'train_loss': '2.53784'}; time used = 0.7816064357757568s
epoch 230: {'train_loss': '2.44800'}; time used = 0.7624392509460449s
epoch 235: {'train_loss': '2.40208'}; time used = 0.7228896617889404s
epoch 240: {'train_loss': '2.35857'}; time used = 0.4633810520172119s
epoch 245: {'train_loss': '2.33916'}; time used = 0.3989534378051758s
epoch 250: {'train_loss': '2.27645'}; time used = 0.4164865016937256s
epoch 255: {'train_loss': '2.32027'}; time used = 0.639122724533081s
epoch 260: {'train_loss': '2.30774'}; time used = 0.5519237518310547s
epoch 265: {'train_loss': '2.23712'}; time used = 0.5958178043365479s
epoch 270: {'train_loss': '2.22518'}; time used = 0.6857826709747314s
epoch 275: {'train_loss': '2.21338'}; time used = 0.5140070915222168s
epoch 280: {'train_loss': '2.13202'}; time used = 0.5305745601654053s
epoch 285: {'train_loss': '2.12324'}; time used = 0.5451960563659668s
epoch 290: {'train_loss': '2.09845'}; time used = 0.5011286735534668s
epoch 295: {'train_loss': '2.04473'}; time used = 0.45221471786499023s
epoch 300: {'train_loss': '2.10273'}; time used = 0.39644861221313477s
epoch 305: {'train_loss': '2.03353'}; time used = 0.32339000701904297s
epoch 310: {'train_loss': '1.99455'}; time used = 0.39660143852233887s
epoch 315: {'train_loss': '1.99227'}; time used = 0.43996214866638184s
epoch 320: {'train_loss': '1.97625'}; time used = 0.5388455390930176s
epoch 325: {'train_loss': '1.94445'}; time used = 0.4121420383453369s
epoch 330: {'train_loss': '1.89423'}; time used = 0.534674882888794s
epoch 335: {'train_loss': '1.85757'}; time used = 0.40139126777648926s
epoch 340: {'train_loss': '1.81434'}; time used = 0.3993508815765381s
epoch 345: {'train_loss': '1.82439'}; time used = 0.4171483516693115s
epoch 350: {'train_loss': '1.79321'}; time used = 0.47064971923828125s
epoch 355: {'train_loss': '1.78256'}; time used = 0.39823031425476074s
epoch 360: {'train_loss': '1.72093'}; time used = 0.7610611915588379s
epoch 365: {'train_loss': '1.71538'}; time used = 0.8116543292999268s
epoch 370: {'train_loss': '1.73849'}; time used = 0.6604113578796387s
epoch 375: {'train_loss': '1.71196'}; time used = 0.45449137687683105s
epoch 380: {'train_loss': '1.68884'}; time used = 0.3283829689025879s
epoch 385: {'train_loss': '1.63891'}; time used = 0.31254053115844727s
epoch 390: {'train_loss': '1.58499'}; time used = 0.30799388885498047s
epoch 395: {'train_loss': '1.63767'}; time used = 0.46271848678588867s
epoch 400: {'train_loss': '1.59548'}; time used = 0.5169970989227295s
epoch 405: {'train_loss': '1.59914'}; time used = 0.47303104400634766s
epoch 410: {'train_loss': '1.57741'}; time used = 0.4199225902557373s
epoch 415: {'train_loss': '1.56050'}; time used = 0.39130377769470215s
epoch 420: {'train_loss': '1.50014'}; time used = 0.3963141441345215s
epoch 425: {'train_loss': '1.52697'}; time used = 0.34443044662475586s
epoch 430: {'train_loss': '1.51046'}; time used = 0.45621585845947266s
epoch 435: {'train_loss': '1.48153'}; time used = 0.600592851638794s
epoch 440: {'train_loss': '1.48089'}; time used = 0.4446077346801758s
epoch 445: {'train_loss': '1.44357'}; time used = 0.41376757621765137s
epoch 450: {'train_loss': '1.44258'}; time used = 0.5971002578735352s
epoch 455: {'train_loss': '1.44925'}; time used = 0.4355196952819824s
epoch 460: {'train_loss': '1.41388'}; time used = 0.41283345222473145s
epoch 465: {'train_loss': '1.40345'}; time used = 0.39802002906799316s
epoch 470: {'train_loss': '1.41068'}; time used = 0.34184980392456055s
epoch 475: {'train_loss': '1.38964'}; time used = 0.34108877182006836s
epoch 480: {'train_loss': '1.34791'}; time used = 0.5441453456878662s
epoch 485: {'train_loss': '1.33118'}; time used = 0.4222254753112793s
epoch 490: {'train_loss': '1.32772'}; time used = 0.737985372543335s
epoch 495: {'train_loss': '1.32013'}; time used = 0.6591846942901611s
epoch 500: {'train_loss': '1.30102'}; time used = 0.817002534866333s
Finished training. Time used = 77.43995976448059.
Training classifier using 20.00% nodes...
{'micro': 0.2787263497923396, 'macro': 0.07976258378938536, 'samples': 0.2787263497923396, 'weighted': 0.14983535236671183}

Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6151/10556 [00:00<00:00, 61507.27it/s]100%|| 10556/10556 [00:00<00:00, 76616.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6894/10556 [00:00<00:00, 68938.09it/s]100%|| 10556/10556 [00:00<00:00, 79964.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4197/10556 [00:00<00:00, 41968.84it/s] 88%| | 9336/10556 [00:00<00:00, 44229.17it/s]100%|| 10556/10556 [00:00<00:00, 49991.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8922/10556 [00:00<00:00, 88788.45it/s]100%|| 10556/10556 [00:00<00:00, 90902.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9385/10556 [00:00<00:00, 93843.60it/s]100%|| 10556/10556 [00:00<00:00, 73834.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6532/10556 [00:00<00:00, 65316.17it/s]100%|| 10556/10556 [00:00<00:00, 61502.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5641/10556 [00:00<00:00, 56408.84it/s]100%|| 10556/10556 [00:00<00:00, 58258.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7336/10556 [00:00<00:00, 66614.45it/s]100%|| 10556/10556 [00:00<00:00, 56029.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4976/10556 [00:00<00:00, 47891.13it/s] 80%|  | 8481/10556 [00:00<00:00, 41509.24it/s]100%|| 10556/10556 [00:00<00:00, 41723.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7553/10556 [00:00<00:00, 72437.45it/s]100%|| 10556/10556 [00:00<00:00, 79167.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7243/10556 [00:00<00:00, 72429.72it/s]100%|| 10556/10556 [00:00<00:00, 69464.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4316/10556 [00:00<00:00, 40279.59it/s]100%|| 10556/10556 [00:00<00:00, 59117.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%| | 8581/10556 [00:00<00:00, 85804.56it/s]100%|| 10556/10556 [00:00<00:00, 83726.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10481/10556 [00:00<00:00, 104802.85it/s]100%|| 10556/10556 [00:00<00:00, 104532.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124672.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10354/10556 [00:00<00:00, 103533.68it/s]100%|| 10556/10556 [00:00<00:00, 103562.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8704/10556 [00:00<00:00, 84831.86it/s]100%|| 10556/10556 [00:00<00:00, 83408.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|     | 4355/10556 [00:00<00:00, 43548.38it/s]100%|| 10556/10556 [00:00<00:00, 55762.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6466/10556 [00:00<00:00, 55084.52it/s] 78%|  | 8234/10556 [00:00<00:00, 33694.91it/s]100%|| 10556/10556 [00:00<00:00, 42168.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10433/10556 [00:00<00:00, 104329.10it/s]100%|| 10556/10556 [00:00<00:00, 104287.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4344/10556 [00:00<00:00, 40938.43it/s]100%|| 10556/10556 [00:00<00:00, 52005.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6922/10556 [00:00<00:00, 69216.77it/s]100%|| 10556/10556 [00:00<00:00, 63146.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6126/10556 [00:00<00:00, 61257.72it/s]100%|| 10556/10556 [00:00<00:00, 62953.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5159/10556 [00:00<00:00, 49042.57it/s] 75%|  | 7962/10556 [00:00<00:00, 38469.98it/s] 99%|| 10491/10556 [00:00<00:00, 33267.67it/s]100%|| 10556/10556 [00:00<00:00, 33452.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117849.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106165.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 99039.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7915/10556 [00:00<00:00, 70464.75it/s]100%|| 10556/10556 [00:00<00:00, 59335.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3642/10556 [00:00<00:00, 33372.56it/s] 86%| | 9102/10556 [00:00<00:00, 37777.81it/s]100%|| 10556/10556 [00:00<00:00, 45561.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106504.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6227/10556 [00:00<00:00, 62263.68it/s]100%|| 10556/10556 [00:00<00:00, 55290.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107837.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113318.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4951/10556 [00:00<00:00, 49509.69it/s]100%|| 10556/10556 [00:00<00:00, 66564.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4919/10556 [00:00<00:00, 49188.64it/s] 86%| | 9123/10556 [00:00<00:00, 45423.29it/s]100%|| 10556/10556 [00:00<00:00, 45796.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7112/10556 [00:00<00:00, 63227.45it/s]100%|| 10556/10556 [00:00<00:00, 50180.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8060/10556 [00:00<00:00, 80599.69it/s]100%|| 10556/10556 [00:00<00:00, 88123.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117120.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5128/10556 [00:00<00:00, 51278.09it/s] 85%| | 8968/10556 [00:00<00:00, 46589.69it/s]100%|| 10556/10556 [00:00<00:00, 36793.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6129/10556 [00:00<00:00, 61285.38it/s]100%|| 10556/10556 [00:00<00:00, 77747.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4939/10556 [00:00<00:00, 47687.89it/s] 97%|| 10272/10556 [00:00<00:00, 49250.72it/s]100%|| 10556/10556 [00:00<00:00, 51204.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8918/10556 [00:00<00:00, 89178.60it/s]100%|| 10556/10556 [00:00<00:00, 88929.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7422/10556 [00:00<00:00, 74216.00it/s]100%|| 10556/10556 [00:00<00:00, 69709.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134922.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5402/10556 [00:00<00:00, 54019.79it/s]100%|| 10556/10556 [00:00<00:00, 77735.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 102765.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|      | 3451/10556 [00:00<00:00, 34508.72it/s] 58%|    | 6091/10556 [00:00<00:00, 30002.86it/s] 85%| | 8955/10556 [00:00<00:00, 29338.53it/s]100%|| 10556/10556 [00:00<00:00, 31338.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4900/10556 [00:00<00:00, 45493.98it/s]100%|| 10556/10556 [00:00<00:00, 55800.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 26%|       | 2760/10556 [00:00<00:00, 26228.60it/s] 86%| | 9124/10556 [00:00<00:00, 31844.65it/s]100%|| 10556/10556 [00:00<00:00, 48538.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105451.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120123.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118000.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146706.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4702/10556 [00:00<00:00, 45310.07it/s]100%|| 10556/10556 [00:00<00:00, 71372.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117441.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3408/10556 [00:00<00:00, 29308.37it/s] 65%|   | 6882/10556 [00:00<00:00, 30750.45it/s]100%|| 10556/10556 [00:00<00:00, 40385.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8733/10556 [00:00<00:00, 87325.50it/s]100%|| 10556/10556 [00:00<00:00, 87864.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7462/10556 [00:00<00:00, 74619.72it/s]100%|| 10556/10556 [00:00<00:00, 75712.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8088/10556 [00:00<00:00, 80878.73it/s]100%|| 10556/10556 [00:00<00:00, 77424.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8755/10556 [00:00<00:00, 87539.02it/s]100%|| 10556/10556 [00:00<00:00, 83212.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7938/10556 [00:00<00:00, 79375.53it/s]100%|| 10556/10556 [00:00<00:00, 80727.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5800/10556 [00:00<00:00, 57992.59it/s]100%|| 10556/10556 [00:00<00:00, 55507.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140001.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142034.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142719.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145804.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5844/10556 [00:00<00:00, 54210.90it/s]100%|| 10556/10556 [00:00<00:00, 66665.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129008.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115493.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151710.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132624.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129311.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9975/10556 [00:00<00:00, 99745.81it/s]100%|| 10556/10556 [00:00<00:00, 101256.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5738/10556 [00:00<00:00, 57372.94it/s]100%|| 10556/10556 [00:00<00:00, 57137.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9879/10556 [00:00<00:00, 98785.38it/s]100%|| 10556/10556 [00:00<00:00, 91318.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10139/10556 [00:00<00:00, 101387.92it/s]100%|| 10556/10556 [00:00<00:00, 101882.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8249/10556 [00:00<00:00, 82485.36it/s]100%|| 10556/10556 [00:00<00:00, 83486.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110777.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10195/10556 [00:00<00:00, 101948.88it/s]100%|| 10556/10556 [00:00<00:00, 96971.33it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109026.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10465/10556 [00:00<00:00, 104649.85it/s]100%|| 10556/10556 [00:00<00:00, 103210.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115506.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108912.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120839.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114023.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8147/10556 [00:00<00:00, 81467.36it/s]100%|| 10556/10556 [00:00<00:00, 71131.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150846.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9294/10556 [00:00<00:00, 92938.54it/s]100%|| 10556/10556 [00:00<00:00, 96507.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9734/10556 [00:00<00:00, 97338.00it/s]100%|| 10556/10556 [00:00<00:00, 93822.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128919.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108499.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10012/10556 [00:00<00:00, 100118.66it/s]100%|| 10556/10556 [00:00<00:00, 99182.29it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112414.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 101374.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7951/10556 [00:00<00:00, 79504.77it/s]100%|| 10556/10556 [00:00<00:00, 87247.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145829.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6768/10556 [00:00<00:00, 67678.45it/s]100%|| 10556/10556 [00:00<00:00, 81979.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143961.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7699/10556 [00:00<00:00, 76989.71it/s]100%|| 10556/10556 [00:00<00:00, 85161.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115264.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150391.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9819/10556 [00:00<00:00, 98183.31it/s]100%|| 10556/10556 [00:00<00:00, 87566.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110603.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9586/10556 [00:00<00:00, 95857.81it/s]100%|| 10556/10556 [00:00<00:00, 95815.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132667.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131166.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130166.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106971.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129301.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121100.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3713/10556 [00:00<00:00, 37127.29it/s] 88%| | 9305/10556 [00:00<00:00, 41289.97it/s]100%|| 10556/10556 [00:00<00:00, 46707.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6413/10556 [00:00<00:00, 59021.30it/s]100%|| 10556/10556 [00:00<00:00, 74325.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7064/10556 [00:00<00:00, 70635.69it/s]100%|| 10556/10556 [00:00<00:00, 70272.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6372/10556 [00:00<00:00, 63715.20it/s]100%|| 10556/10556 [00:00<00:00, 62666.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|      | 3509/10556 [00:00<00:00, 35087.19it/s] 80%|  | 8403/10556 [00:00<00:00, 38342.67it/s]100%|| 10556/10556 [00:00<00:00, 45642.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123843.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7740/10556 [00:00<00:00, 77398.41it/s]100%|| 10556/10556 [00:00<00:00, 85340.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123740.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6329/10556 [00:00<00:00, 57268.18it/s]100%|| 10556/10556 [00:00<00:00, 50353.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4204/10556 [00:00<00:00, 39855.55it/s] 63%|   | 6622/10556 [00:00<00:00, 31289.63it/s] 97%|| 10230/10556 [00:00<00:00, 32230.49it/s]100%|| 10556/10556 [00:00<00:00, 32122.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6698/10556 [00:00<00:00, 66977.51it/s]100%|| 10556/10556 [00:00<00:00, 73539.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109779.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6912/10556 [00:00<00:00, 66870.17it/s]100%|| 10556/10556 [00:00<00:00, 76833.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10389/10556 [00:00<00:00, 103882.42it/s]100%|| 10556/10556 [00:00<00:00, 103767.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8538/10556 [00:00<00:00, 85373.97it/s]100%|| 10556/10556 [00:00<00:00, 90977.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122444.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124597.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124187.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7045/10556 [00:00<00:00, 70446.04it/s]100%|| 10556/10556 [00:00<00:00, 65522.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7823/10556 [00:00<00:00, 78225.23it/s]100%|| 10556/10556 [00:00<00:00, 64538.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122454.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7582/10556 [00:00<00:00, 75815.19it/s]100%|| 10556/10556 [00:00<00:00, 69701.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114996.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7099/10556 [00:00<00:00, 70986.51it/s]100%|| 10556/10556 [00:00<00:00, 82724.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118728.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6738/10556 [00:00<00:00, 67377.49it/s]100%|| 10556/10556 [00:00<00:00, 68286.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7432/10556 [00:00<00:00, 73977.37it/s]100%|| 10556/10556 [00:00<00:00, 81262.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7963/10556 [00:00<00:00, 79477.92it/s]100%|| 10556/10556 [00:00<00:00, 86713.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6482/10556 [00:00<00:00, 63069.02it/s]100%|| 10556/10556 [00:00<00:00, 62959.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6673/10556 [00:00<00:00, 66729.75it/s]100%|| 10556/10556 [00:00<00:00, 66535.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3884/10556 [00:00<00:00, 38836.80it/s] 72%|  | 7647/10556 [00:00<00:00, 38466.18it/s]100%|| 10556/10556 [00:00<00:00, 42882.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|      | 3495/10556 [00:00<00:00, 32927.13it/s] 63%|   | 6701/10556 [00:00<00:00, 32572.99it/s] 80%|  | 8461/10556 [00:00<00:00, 25649.51it/s]100%|| 10556/10556 [00:00<00:00, 28016.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3666/10556 [00:00<00:00, 36659.42it/s] 52%|    | 5483/10556 [00:00<00:00, 27583.34it/s] 82%| | 8675/10556 [00:00<00:00, 27160.83it/s]100%|| 10556/10556 [00:00<00:00, 24333.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3327/10556 [00:00<00:00, 29801.98it/s] 77%|  | 8141/10556 [00:00<00:00, 33646.08it/s] 97%|| 10211/10556 [00:00<00:00, 25676.76it/s]100%|| 10556/10556 [00:00<00:00, 30688.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3796/10556 [00:00<00:00, 37958.95it/s] 49%|     | 5147/10556 [00:00<00:00, 23683.54it/s] 84%| | 8843/10556 [00:00<00:00, 26543.91it/s]100%|| 10556/10556 [00:00<00:00, 31790.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 22%|       | 2362/10556 [00:00<00:00, 22154.22it/s] 55%|    | 5793/10556 [00:00<00:00, 24778.71it/s] 79%|  | 8345/10556 [00:00<00:00, 24995.49it/s]100%|| 10556/10556 [00:00<00:00, 29923.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 22%|       | 2340/10556 [00:00<00:00, 23395.67it/s] 49%|     | 5183/10556 [00:00<00:00, 24450.90it/s] 69%|   | 7321/10556 [00:00<00:00, 23440.67it/s]100%|| 10556/10556 [00:00<00:00, 26508.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 30%|       | 3118/10556 [00:00<00:00, 31176.98it/s] 61%|    | 6426/10556 [00:00<00:00, 31724.42it/s] 81%|  | 8514/10556 [00:00<00:00, 26539.61it/s]100%|| 10556/10556 [00:00<00:00, 25625.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|       | 3110/10556 [00:00<00:00, 28092.10it/s] 54%|    | 5674/10556 [00:00<00:00, 27307.56it/s] 67%|   | 7034/10556 [00:00<00:00, 18743.30it/s] 87%| | 9181/10556 [00:00<00:00, 19189.81it/s]100%|| 10556/10556 [00:00<00:00, 20581.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122885.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9531/10556 [00:00<00:00, 95305.32it/s]100%|| 10556/10556 [00:00<00:00, 96996.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7654/10556 [00:00<00:00, 76523.11it/s]100%|| 10556/10556 [00:00<00:00, 78957.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106266.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10316/10556 [00:00<00:00, 103158.38it/s]100%|| 10556/10556 [00:00<00:00, 103177.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9940/10556 [00:00<00:00, 95159.95it/s]100%|| 10556/10556 [00:00<00:00, 90570.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108396.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123231.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108834.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119282.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126018.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115102.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173925.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176048.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190360.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194759.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 209895.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 203732.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127060.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160736.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187728.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193671.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 208084.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197976.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189002.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173796.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4435/10556 [00:00<00:00, 42833.12it/s]100%|| 10556/10556 [00:00<00:00, 75861.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194504.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9475/10556 [00:00<00:00, 91915.47it/s]100%|| 10556/10556 [00:00<00:00, 87531.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164003.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175613.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165409.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181301.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132175.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117298.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189775.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181853.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110214.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7429/10556 [00:00<00:00, 65636.22it/s]100%|| 10556/10556 [00:00<00:00, 67197.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119494.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156591.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151805.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146814.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180039.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179967.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10040/10556 [00:00<00:00, 93879.58it/s]100%|| 10556/10556 [00:00<00:00, 89299.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6190/10556 [00:00<00:00, 55486.02it/s]100%|| 10556/10556 [00:00<00:00, 66906.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6644/10556 [00:00<00:00, 66432.30it/s]100%|| 10556/10556 [00:00<00:00, 75440.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10271/10556 [00:00<00:00, 102708.14it/s]100%|| 10556/10556 [00:00<00:00, 102338.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4343/10556 [00:00<00:00, 43426.62it/s]100%|| 10556/10556 [00:00<00:00, 57783.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135915.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7269/10556 [00:00<00:00, 72688.16it/s]100%|| 10556/10556 [00:00<00:00, 86277.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137108.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9972/10556 [00:00<00:00, 99714.86it/s]100%|| 10556/10556 [00:00<00:00, 98964.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158187.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112672.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9617/10556 [00:00<00:00, 96163.90it/s]100%|| 10556/10556 [00:00<00:00, 98222.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115290.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167997.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185033.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10261/10556 [00:00<00:00, 89702.73it/s]100%|| 10556/10556 [00:00<00:00, 83157.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119634.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 212804.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194793.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175281.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183713.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165396.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7300/10556 [00:00<00:00, 69655.39it/s]100%|| 10556/10556 [00:00<00:00, 77979.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137389.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158964.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169163.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108178.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183638.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170241.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133894.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110636.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112792.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8748/10556 [00:00<00:00, 87475.91it/s]100%|| 10556/10556 [00:00<00:00, 96169.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164115.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7889/10556 [00:00<00:00, 78887.44it/s]100%|| 10556/10556 [00:00<00:00, 80866.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9099/10556 [00:00<00:00, 90984.88it/s]100%|| 10556/10556 [00:00<00:00, 90874.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8342/10556 [00:00<00:00, 83414.71it/s]100%|| 10556/10556 [00:00<00:00, 91737.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126412.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172186.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175023.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177997.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8008/10556 [00:00<00:00, 80074.73it/s]100%|| 10556/10556 [00:00<00:00, 64907.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6440/10556 [00:00<00:00, 64398.99it/s]100%|| 10556/10556 [00:00<00:00, 79736.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157507.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7057/10556 [00:00<00:00, 70559.64it/s]100%|| 10556/10556 [00:00<00:00, 70659.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10246/10556 [00:00<00:00, 102458.63it/s]100%|| 10556/10556 [00:00<00:00, 102210.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9821/10556 [00:00<00:00, 98207.99it/s]100%|| 10556/10556 [00:00<00:00, 98231.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9501/10556 [00:00<00:00, 94998.09it/s]100%|| 10556/10556 [00:00<00:00, 67207.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4790/10556 [00:00<00:00, 47898.33it/s]100%|| 10556/10556 [00:00<00:00, 56649.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117527.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176064.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146698.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130561.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8084/10556 [00:00<00:00, 80836.42it/s]100%|| 10556/10556 [00:00<00:00, 71601.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180790.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183253.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125103.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6392/10556 [00:00<00:00, 63113.07it/s]100%|| 10556/10556 [00:00<00:00, 61754.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122823.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5953/10556 [00:00<00:00, 59523.39it/s]100%|| 10556/10556 [00:00<00:00, 57258.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9085/10556 [00:00<00:00, 85758.13it/s]100%|| 10556/10556 [00:00<00:00, 75346.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122519.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130229.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173476.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8395/10556 [00:00<00:00, 83943.08it/s]100%|| 10556/10556 [00:00<00:00, 61843.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4334/10556 [00:00<00:00, 37922.42it/s] 76%|  | 8034/10556 [00:00<00:00, 37087.23it/s]100%|| 10556/10556 [00:00<00:00, 42562.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7124/10556 [00:00<00:00, 70349.94it/s]100%|| 10556/10556 [00:00<00:00, 53769.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111056.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 205763.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7415/10556 [00:00<00:00, 74145.30it/s]100%|| 10556/10556 [00:00<00:00, 85658.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172274.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173415.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162824.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4147/10556 [00:00<00:00, 41468.16it/s] 99%|| 10451/10556 [00:00<00:00, 46211.51it/s]100%|| 10556/10556 [00:00<00:00, 52477.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177922.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166584.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187731.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8168/10556 [00:00<00:00, 81676.96it/s]100%|| 10556/10556 [00:00<00:00, 93972.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182063.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178879.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186861.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176034.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176080.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142445.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182006.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189002.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179839.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159946.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164533.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172258.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187086.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182564.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194732.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181383.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182476.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172336.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195384.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188002.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 201728.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141791.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106948.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149209.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149012.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151828.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139042.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9531/10556 [00:00<00:00, 95304.18it/s]100%|| 10556/10556 [00:00<00:00, 98317.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118348.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112324.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149069.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5882/10556 [00:00<00:00, 58819.21it/s]100%|| 10556/10556 [00:00<00:00, 68541.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130429.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10321/10556 [00:00<00:00, 103208.13it/s]100%|| 10556/10556 [00:00<00:00, 103654.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125856.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129346.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174301.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139659.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10370/10556 [00:00<00:00, 103693.42it/s]100%|| 10556/10556 [00:00<00:00, 100768.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160103.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140175.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9882/10556 [00:00<00:00, 98819.62it/s]100%|| 10556/10556 [00:00<00:00, 100047.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9616/10556 [00:00<00:00, 96157.11it/s]100%|| 10556/10556 [00:00<00:00, 100765.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176384.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8096/10556 [00:00<00:00, 80954.09it/s]100%|| 10556/10556 [00:00<00:00, 78151.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123587.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9203/10556 [00:00<00:00, 92027.24it/s]100%|| 10556/10556 [00:00<00:00, 96741.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176109.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170533.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171641.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10270/10556 [00:00<00:00, 102694.96it/s]100%|| 10556/10556 [00:00<00:00, 102827.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140602.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179296.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171190.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171059.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184352.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173199.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173837.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167191.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157962.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7404/10556 [00:00<00:00, 74039.89it/s]100%|| 10556/10556 [00:00<00:00, 90025.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188734.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188330.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184351.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9965/10556 [00:00<00:00, 93188.05it/s]100%|| 10556/10556 [00:00<00:00, 83317.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124346.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164949.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132727.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9597/10556 [00:00<00:00, 95958.42it/s]100%|| 10556/10556 [00:00<00:00, 70643.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8754/10556 [00:00<00:00, 85406.50it/s]100%|| 10556/10556 [00:00<00:00, 65391.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117502.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9297/10556 [00:00<00:00, 92914.71it/s]100%|| 10556/10556 [00:00<00:00, 85557.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9840/10556 [00:00<00:00, 98393.76it/s]100%|| 10556/10556 [00:00<00:00, 98561.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10551/10556 [00:00<00:00, 99042.79it/s]100%|| 10556/10556 [00:00<00:00, 98270.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6700/10556 [00:00<00:00, 66995.91it/s]100%|| 10556/10556 [00:00<00:00, 83337.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7610/10556 [00:00<00:00, 76095.54it/s]100%|| 10556/10556 [00:00<00:00, 88050.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8999/10556 [00:00<00:00, 87241.57it/s]100%|| 10556/10556 [00:00<00:00, 65244.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109164.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5443/10556 [00:00<00:00, 53218.32it/s]100%|| 10556/10556 [00:00<00:00, 64205.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148722.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4320/10556 [00:00<00:00, 43195.92it/s]100%|| 10556/10556 [00:00<00:00, 53863.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186547.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153852.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177888.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163982.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124699.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163924.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172988.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178330.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178637.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186555.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193719.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10280/10556 [00:00<00:00, 102781.72it/s]100%|| 10556/10556 [00:00<00:00, 91544.38it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119820.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181404.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185858.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181880.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184455.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185761.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189306.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4221/10556 [00:00<00:00, 39659.67it/s]100%|| 10556/10556 [00:00<00:00, 60339.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184540.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145066.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136885.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6487/10556 [00:00<00:00, 64866.20it/s]100%|| 10556/10556 [00:00<00:00, 81426.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188231.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167165.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8909/10556 [00:00<00:00, 89086.69it/s]100%|| 10556/10556 [00:00<00:00, 97061.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171512.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150415.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145590.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5594/10556 [00:00<00:00, 52909.16it/s]100%|| 10556/10556 [00:00<00:00, 61857.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 104583.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105685.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111260.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152178.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127577.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118039.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 98870.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116739.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123193.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119859.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122104.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117018.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112964.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108658.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106171.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7201/10556 [00:00<00:00, 72009.21it/s]100%|| 10556/10556 [00:00<00:00, 79076.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187908.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174768.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175249.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7352/10556 [00:00<00:00, 73512.36it/s]100%|| 10556/10556 [00:00<00:00, 71978.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9663/10556 [00:00<00:00, 96624.79it/s]100%|| 10556/10556 [00:00<00:00, 83863.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5047/10556 [00:00<00:00, 50468.97it/s] 94%|| 9885/10556 [00:00<00:00, 49823.19it/s]100%|| 10556/10556 [00:00<00:00, 47445.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6774/10556 [00:00<00:00, 67739.74it/s]100%|| 10556/10556 [00:00<00:00, 66414.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6060/10556 [00:00<00:00, 60599.34it/s]100%|| 10556/10556 [00:00<00:00, 59488.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6289/10556 [00:00<00:00, 62887.51it/s]100%|| 10556/10556 [00:00<00:00, 66158.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159641.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137258.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106404.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9620/10556 [00:00<00:00, 96196.42it/s]100%|| 10556/10556 [00:00<00:00, 97962.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160942.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178314.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120735.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9167/10556 [00:00<00:00, 91667.25it/s]100%|| 10556/10556 [00:00<00:00, 97743.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8403/10556 [00:00<00:00, 84023.27it/s]100%|| 10556/10556 [00:00<00:00, 82055.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8033/10556 [00:00<00:00, 80324.71it/s]100%|| 10556/10556 [00:00<00:00, 80110.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112735.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119448.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179323.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161736.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123709.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147677.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170045.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161182.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169264.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135755.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176406.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146773.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123890.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6304/10556 [00:00<00:00, 63034.50it/s]100%|| 10556/10556 [00:00<00:00, 64847.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189005.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178583.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184734.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189776.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183340.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7848/10556 [00:00<00:00, 77287.13it/s]100%|| 10556/10556 [00:00<00:00, 78122.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4823/10556 [00:00<00:00, 46813.57it/s]100%|| 10556/10556 [00:00<00:00, 50454.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5848/10556 [00:00<00:00, 58226.43it/s]100%|| 10556/10556 [00:00<00:00, 69147.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6586/10556 [00:00<00:00, 61543.52it/s]100%|| 10556/10556 [00:00<00:00, 75580.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144303.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 26%|       | 2710/10556 [00:00<00:00, 26631.19it/s]100%|| 10556/10556 [00:00<00:00, 70316.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7097/10556 [00:00<00:00, 70967.02it/s]100%|| 10556/10556 [00:00<00:00, 74486.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120745.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4497/10556 [00:00<00:00, 44874.61it/s] 99%|| 10449/10556 [00:00<00:00, 47770.01it/s]100%|| 10556/10556 [00:00<00:00, 50663.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7896/10556 [00:00<00:00, 78953.86it/s]100%|| 10556/10556 [00:00<00:00, 87079.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5355/10556 [00:00<00:00, 53549.54it/s]100%|| 10556/10556 [00:00<00:00, 72021.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9809/10556 [00:00<00:00, 98087.05it/s]100%|| 10556/10556 [00:00<00:00, 96838.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8982/10556 [00:00<00:00, 89819.87it/s]100%|| 10556/10556 [00:00<00:00, 94086.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8308/10556 [00:00<00:00, 83077.50it/s]100%|| 10556/10556 [00:00<00:00, 87531.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132358.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136261.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5605/10556 [00:00<00:00, 56045.91it/s]100%|| 10556/10556 [00:00<00:00, 69943.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10351/10556 [00:00<00:00, 103508.37it/s]100%|| 10556/10556 [00:00<00:00, 99383.77it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127246.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173711.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170934.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179402.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188897.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7581/10556 [00:00<00:00, 74325.96it/s]100%|| 10556/10556 [00:00<00:00, 68616.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7436/10556 [00:00<00:00, 74175.26it/s]100%|| 10556/10556 [00:00<00:00, 84503.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190034.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193836.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200864.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 204770.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196938.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 203152.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195721.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10501/10556 [00:00<00:00, 105008.35it/s]100%|| 10556/10556 [00:00<00:00, 104722.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119946.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116212.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167566.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169112.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154983.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174940.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182188.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152365.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10438/10556 [00:00<00:00, 104373.88it/s]100%|| 10556/10556 [00:00<00:00, 104440.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166233.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170901.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163505.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182427.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188263.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182292.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165095.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167776.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8337/10556 [00:00<00:00, 81184.22it/s]100%|| 10556/10556 [00:00<00:00, 85325.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8809/10556 [00:00<00:00, 88089.24it/s]100%|| 10556/10556 [00:00<00:00, 92544.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6462/10556 [00:00<00:00, 64618.68it/s]100%|| 10556/10556 [00:00<00:00, 65783.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136790.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179515.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177030.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175985.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8994/10556 [00:00<00:00, 85864.77it/s]100%|| 10556/10556 [00:00<00:00, 81615.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136543.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9154/10556 [00:00<00:00, 85116.62it/s]100%|| 10556/10556 [00:00<00:00, 78753.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5614/10556 [00:00<00:00, 56139.79it/s]100%|| 10556/10556 [00:00<00:00, 83346.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186487.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189565.35it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '5.32355'}; time used = 0.9376449584960938s
epoch 10: {'train_loss': '4.43280'}; time used = 0.9956953525543213s
epoch 15: {'train_loss': '4.22462'}; time used = 0.675647497177124s
epoch 20: {'train_loss': '4.11310'}; time used = 0.995323896408081s
epoch 25: {'train_loss': '3.84561'}; time used = 0.9068841934204102s
epoch 30: {'train_loss': '3.86588'}; time used = 0.8914952278137207s
epoch 35: {'train_loss': '3.52486'}; time used = 0.866633415222168s
epoch 40: {'train_loss': '3.49723'}; time used = 0.9250593185424805s
epoch 45: {'train_loss': '3.36494'}; time used = 0.650277853012085s
epoch 50: {'train_loss': '3.23099'}; time used = 1.0174822807312012s
epoch 55: {'train_loss': '3.09954'}; time used = 0.7059910297393799s
epoch 60: {'train_loss': '3.01299'}; time used = 0.6900403499603271s
epoch 65: {'train_loss': '2.80299'}; time used = 0.5159382820129395s
epoch 70: {'train_loss': '2.72340'}; time used = 0.5371699333190918s
epoch 75: {'train_loss': '2.68171'}; time used = 0.6597230434417725s
epoch 80: {'train_loss': '2.54308'}; time used = 0.5847294330596924s
epoch 85: {'train_loss': '2.44969'}; time used = 0.559821605682373s
epoch 90: {'train_loss': '2.32356'}; time used = 0.5417745113372803s
epoch 95: {'train_loss': '2.25454'}; time used = 0.5555992126464844s
epoch 100: {'train_loss': '2.18885'}; time used = 0.5560455322265625s
epoch 105: {'train_loss': '2.10175'}; time used = 0.5565125942230225s
epoch 110: {'train_loss': '1.99350'}; time used = 0.6285617351531982s
epoch 115: {'train_loss': '1.94534'}; time used = 0.8332948684692383s
epoch 120: {'train_loss': '1.82627'}; time used = 0.9492447376251221s
epoch 125: {'train_loss': '1.83582'}; time used = 0.5830228328704834s
epoch 130: {'train_loss': '1.74384'}; time used = 0.6255419254302979s
epoch 135: {'train_loss': '1.71815'}; time used = 0.6800642013549805s
epoch 140: {'train_loss': '1.60014'}; time used = 0.8868165016174316s
epoch 145: {'train_loss': '1.59562'}; time used = 1.9049978256225586s
epoch 150: {'train_loss': '1.55292'}; time used = 1.5746145248413086s
epoch 155: {'train_loss': '1.49995'}; time used = 0.6135427951812744s
epoch 160: {'train_loss': '1.43706'}; time used = 0.48575663566589355s
epoch 165: {'train_loss': '1.42286'}; time used = 0.30761122703552246s
epoch 170: {'train_loss': '1.34731'}; time used = 0.35149455070495605s
epoch 175: {'train_loss': '1.35900'}; time used = 0.39617252349853516s
epoch 180: {'train_loss': '1.33402'}; time used = 0.39433979988098145s
epoch 185: {'train_loss': '1.29672'}; time used = 0.39196252822875977s
epoch 190: {'train_loss': '1.27532'}; time used = 0.5623490810394287s
epoch 195: {'train_loss': '1.24213'}; time used = 0.5072832107543945s
epoch 200: {'train_loss': '1.21156'}; time used = 0.669755220413208s
epoch 205: {'train_loss': '1.19585'}; time used = 0.5049371719360352s
epoch 210: {'train_loss': '1.15904'}; time used = 0.4725685119628906s
epoch 215: {'train_loss': '1.12253'}; time used = 0.31906938552856445s
epoch 220: {'train_loss': '1.10462'}; time used = 0.5081167221069336s
epoch 225: {'train_loss': '1.09732'}; time used = 0.4485344886779785s
epoch 230: {'train_loss': '1.07477'}; time used = 0.5851156711578369s
epoch 235: {'train_loss': '1.04108'}; time used = 0.4662492275238037s
epoch 240: {'train_loss': '1.02973'}; time used = 0.6007890701293945s
epoch 245: {'train_loss': '1.00295'}; time used = 0.6209080219268799s
epoch 250: {'train_loss': '1.00436'}; time used = 0.4698617458343506s
epoch 255: {'train_loss': '0.98848'}; time used = 0.7262012958526611s
epoch 260: {'train_loss': '0.98591'}; time used = 0.8029613494873047s
epoch 265: {'train_loss': '0.96451'}; time used = 0.4522819519042969s
epoch 270: {'train_loss': '0.95023'}; time used = 0.47939372062683105s
epoch 275: {'train_loss': '0.94044'}; time used = 0.3874623775482178s
epoch 280: {'train_loss': '0.92754'}; time used = 0.3347907066345215s
epoch 285: {'train_loss': '0.92395'}; time used = 0.34223270416259766s
epoch 290: {'train_loss': '0.89898'}; time used = 0.31424856185913086s
epoch 295: {'train_loss': '0.90452'}; time used = 0.3870704174041748s
epoch 300: {'train_loss': '0.91856'}; time used = 0.4527451992034912s
epoch 305: {'train_loss': '0.89605'}; time used = 0.5570635795593262s
epoch 310: {'train_loss': '0.88505'}; time used = 0.4477574825286865s
epoch 315: {'train_loss': '0.87928'}; time used = 0.4633798599243164s
epoch 320: {'train_loss': '0.89317'}; time used = 0.4952561855316162s
epoch 325: {'train_loss': '0.86617'}; time used = 0.39724302291870117s
epoch 330: {'train_loss': '0.85689'}; time used = 0.3309042453765869s
epoch 335: {'train_loss': '0.85359'}; time used = 0.37989330291748047s
epoch 340: {'train_loss': '0.84588'}; time used = 0.6052703857421875s
epoch 345: {'train_loss': '0.85102'}; time used = 0.6533119678497314s
epoch 350: {'train_loss': '0.84423'}; time used = 0.7751941680908203s
epoch 355: {'train_loss': '0.84048'}; time used = 0.477802038192749s
epoch 360: {'train_loss': '0.83007'}; time used = 0.36730360984802246s
epoch 365: {'train_loss': '0.82998'}; time used = 0.4071919918060303s
epoch 370: {'train_loss': '0.83051'}; time used = 0.3148961067199707s
epoch 375: {'train_loss': '0.82711'}; time used = 0.4661099910736084s
epoch 380: {'train_loss': '0.82872'}; time used = 0.46721673011779785s
epoch 385: {'train_loss': '0.81434'}; time used = 0.5556252002716064s
epoch 390: {'train_loss': '0.79541'}; time used = 0.47347044944763184s
epoch 395: {'train_loss': '0.81796'}; time used = 0.5107784271240234s
epoch 400: {'train_loss': '0.80820'}; time used = 0.5204727649688721s
epoch 405: {'train_loss': '0.80827'}; time used = 0.671187162399292s
epoch 410: {'train_loss': '0.81306'}; time used = 0.7100124359130859s
epoch 415: {'train_loss': '0.80147'}; time used = 0.4717979431152344s
epoch 420: {'train_loss': '0.80140'}; time used = 0.6009693145751953s
epoch 425: {'train_loss': '0.80059'}; time used = 0.3750452995300293s
epoch 430: {'train_loss': '0.80604'}; time used = 0.37327098846435547s
epoch 435: {'train_loss': '0.79827'}; time used = 0.44355201721191406s
epoch 440: {'train_loss': '0.80030'}; time used = 0.6601734161376953s
epoch 445: {'train_loss': '0.79740'}; time used = 0.6321196556091309s
epoch 450: {'train_loss': '0.79609'}; time used = 0.7789146900177002s
epoch 455: {'train_loss': '0.79118'}; time used = 0.5921480655670166s
epoch 460: {'train_loss': '0.78971'}; time used = 0.35242748260498047s
epoch 465: {'train_loss': '0.78164'}; time used = 0.46614980697631836s
epoch 470: {'train_loss': '0.78764'}; time used = 0.3485524654388428s
epoch 475: {'train_loss': '0.79340'}; time used = 0.409548282623291s
epoch 480: {'train_loss': '0.77828'}; time used = 0.38624048233032227s
epoch 485: {'train_loss': '0.77494'}; time used = 0.33573269844055176s
epoch 490: {'train_loss': '0.77475'}; time used = 0.577446699142456s
epoch 495: {'train_loss': '0.77718'}; time used = 0.420853853225708s
epoch 500: {'train_loss': '0.77488'}; time used = 0.5003321170806885s
Finished training. Time used = 82.89402174949646.
Training classifier using 20.00% nodes...
{'micro': 0.45869866174434704, 'macro': 0.41379471909655063, 'samples': 0.45869866174434704, 'weighted': 0.44583861613131687}

Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 10.76 GiB total capacity; 0 bytes already allocated; 2.89 GiB free; 0 bytes reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 181709.00it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.018962383270263672 seconds.
Run epoch 1
Epoch 1 ends in 0.018647432327270508 seconds.
5416 sentences created
mode 1: time used = 0.03833293914794922
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '7.08983'}; time used = 0.06084084510803223s
epoch 10: {'train_loss': '5.80515'}; time used = 0.16600465774536133s
epoch 15: {'train_loss': '5.11550'}; time used = 0.05685019493103027s
epoch 20: {'train_loss': '4.66236'}; time used = 0.08276677131652832s
epoch 25: {'train_loss': '4.38909'}; time used = 0.05379962921142578s
epoch 30: {'train_loss': '4.14956'}; time used = 0.059237003326416016s
epoch 35: {'train_loss': '4.07758'}; time used = 0.05124998092651367s
epoch 40: {'train_loss': '3.89288'}; time used = 0.05661344528198242s
epoch 45: {'train_loss': '3.80219'}; time used = 0.05897998809814453s
epoch 50: {'train_loss': '3.69828'}; time used = 0.05108785629272461s
epoch 55: {'train_loss': '3.57984'}; time used = 0.05031633377075195s
epoch 60: {'train_loss': '3.46230'}; time used = 0.05328559875488281s
epoch 65: {'train_loss': '3.32319'}; time used = 0.05763554573059082s
epoch 70: {'train_loss': '3.25630'}; time used = 0.14302897453308105s
epoch 75: {'train_loss': '3.16631'}; time used = 0.046257972717285156s
epoch 80: {'train_loss': '3.12886'}; time used = 0.04304981231689453s
epoch 85: {'train_loss': '3.01250'}; time used = 0.0462641716003418s
epoch 90: {'train_loss': '2.91266'}; time used = 0.044059038162231445s
epoch 95: {'train_loss': '2.84647'}; time used = 0.04533553123474121s
epoch 100: {'train_loss': '2.79610'}; time used = 0.04849362373352051s
epoch 105: {'train_loss': '2.67688'}; time used = 0.04456663131713867s
epoch 110: {'train_loss': '2.60901'}; time used = 0.05400395393371582s
epoch 115: {'train_loss': '2.54617'}; time used = 0.041506052017211914s
epoch 120: {'train_loss': '2.44402'}; time used = 0.04930472373962402s
epoch 125: {'train_loss': '2.38286'}; time used = 0.0373234748840332s
epoch 130: {'train_loss': '2.31667'}; time used = 0.038411617279052734s
epoch 135: {'train_loss': '2.26085'}; time used = 0.045600175857543945s
epoch 140: {'train_loss': '2.20112'}; time used = 0.03674149513244629s
epoch 145: {'train_loss': '2.13532'}; time used = 0.09734821319580078s
epoch 150: {'train_loss': '2.08698'}; time used = 0.20482492446899414s
epoch 155: {'train_loss': '2.00937'}; time used = 0.03593564033508301s
epoch 160: {'train_loss': '1.97193'}; time used = 0.039571285247802734s
epoch 165: {'train_loss': '1.92239'}; time used = 0.3462667465209961s
epoch 170: {'train_loss': '1.88159'}; time used = 0.09128952026367188s
epoch 175: {'train_loss': '1.81379'}; time used = 0.1494431495666504s
epoch 180: {'train_loss': '1.77417'}; time used = 0.20870375633239746s
epoch 185: {'train_loss': '1.72248'}; time used = 0.03719186782836914s
epoch 190: {'train_loss': '1.68459'}; time used = 0.27605485916137695s
epoch 195: {'train_loss': '1.66571'}; time used = 0.17775177955627441s
epoch 200: {'train_loss': '1.61897'}; time used = 0.03984189033508301s
epoch 205: {'train_loss': '1.58429'}; time used = 0.038117170333862305s
epoch 210: {'train_loss': '1.52576'}; time used = 0.21631193161010742s
epoch 215: {'train_loss': '1.49498'}; time used = 0.2674288749694824s
epoch 220: {'train_loss': '1.45231'}; time used = 0.04710221290588379s
epoch 225: {'train_loss': '1.43114'}; time used = 0.0424799919128418s
epoch 230: {'train_loss': '1.40242'}; time used = 0.04245162010192871s
epoch 235: {'train_loss': '1.36614'}; time used = 0.1765732765197754s
epoch 240: {'train_loss': '1.34250'}; time used = 0.1568775177001953s
epoch 245: {'train_loss': '1.32616'}; time used = 0.0440671443939209s
epoch 250: {'train_loss': '1.29212'}; time used = 0.04231882095336914s
epoch 255: {'train_loss': '1.25679'}; time used = 0.045496463775634766s
epoch 260: {'train_loss': '1.23689'}; time used = 0.041947126388549805s
epoch 265: {'train_loss': '1.22522'}; time used = 0.0462794303894043s
epoch 270: {'train_loss': '1.20058'}; time used = 0.04230642318725586s
epoch 275: {'train_loss': '1.17301'}; time used = 0.051043033599853516s
epoch 280: {'train_loss': '1.16131'}; time used = 0.04430031776428223s
epoch 285: {'train_loss': '1.14478'}; time used = 0.04561161994934082s
epoch 290: {'train_loss': '1.12177'}; time used = 0.047530412673950195s
epoch 295: {'train_loss': '1.10096'}; time used = 0.03921675682067871s
epoch 300: {'train_loss': '1.09852'}; time used = 0.03693079948425293s
epoch 305: {'train_loss': '1.07908'}; time used = 0.04185819625854492s
epoch 310: {'train_loss': '1.07040'}; time used = 0.07933616638183594s
epoch 315: {'train_loss': '1.05337'}; time used = 0.042205095291137695s
epoch 320: {'train_loss': '1.03840'}; time used = 0.0369725227355957s
epoch 325: {'train_loss': '1.02420'}; time used = 0.048143863677978516s
epoch 330: {'train_loss': '1.00935'}; time used = 0.0846703052520752s
epoch 335: {'train_loss': '0.99168'}; time used = 0.05029916763305664s
epoch 340: {'train_loss': '0.99274'}; time used = 0.04099464416503906s
epoch 345: {'train_loss': '0.97016'}; time used = 0.04684019088745117s
epoch 350: {'train_loss': '0.96886'}; time used = 0.03984880447387695s
epoch 355: {'train_loss': '0.95103'}; time used = 0.04570317268371582s
epoch 360: {'train_loss': '0.95050'}; time used = 0.04425978660583496s
epoch 365: {'train_loss': '0.93895'}; time used = 0.04552102088928223s
epoch 370: {'train_loss': '0.93653'}; time used = 0.05183839797973633s
epoch 375: {'train_loss': '0.92461'}; time used = 0.041342973709106445s
epoch 380: {'train_loss': '0.91549'}; time used = 0.07063698768615723s
epoch 385: {'train_loss': '0.90453'}; time used = 0.0783383846282959s
epoch 390: {'train_loss': '0.90489'}; time used = 0.1673436164855957s
epoch 395: {'train_loss': '0.89393'}; time used = 0.04729890823364258s
epoch 400: {'train_loss': '0.88699'}; time used = 0.04649066925048828s
epoch 405: {'train_loss': '0.88597'}; time used = 0.041554927825927734s
epoch 410: {'train_loss': '0.87443'}; time used = 0.045801401138305664s
epoch 415: {'train_loss': '0.87137'}; time used = 0.05249285697937012s
epoch 420: {'train_loss': '0.87163'}; time used = 0.05021834373474121s
epoch 425: {'train_loss': '0.86228'}; time used = 0.0431826114654541s
epoch 430: {'train_loss': '0.85772'}; time used = 0.04557228088378906s
epoch 435: {'train_loss': '0.85512'}; time used = 0.04617643356323242s
epoch 440: {'train_loss': '0.84982'}; time used = 0.04575920104980469s
epoch 445: {'train_loss': '0.84979'}; time used = 0.05062246322631836s
epoch 450: {'train_loss': '0.84543'}; time used = 0.048090457916259766s
epoch 455: {'train_loss': '0.84059'}; time used = 0.04205489158630371s
epoch 460: {'train_loss': '0.83218'}; time used = 0.1488642692565918s
epoch 465: {'train_loss': '0.83634'}; time used = 0.045186519622802734s
epoch 470: {'train_loss': '0.82764'}; time used = 0.046991586685180664s
epoch 475: {'train_loss': '0.82261'}; time used = 0.04470634460449219s
epoch 480: {'train_loss': '0.82351'}; time used = 0.0435941219329834s
epoch 485: {'train_loss': '0.81850'}; time used = 0.05569148063659668s

epoch 490: {'train_loss': '0.81791'}; time used = 0.04266476631164551s
epoch 495: {'train_loss': '0.81824'}; time used = 0.04963111877441406s
epoch 500: {'train_loss': '0.80662'}; time used = 0.04520368576049805s
Finished training. Time used = 11.86527156829834.
Training classifier using 20.00% nodes...
{'micro': 0.4430087678818644, 'macro': 0.3446268236964935, 'samples': 0.44300876788186433, 'weighted': 0.3857215696494899}
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 61512.75it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.07765388488769531 seconds.
Run epoch 1
Epoch 1 ends in 0.11186408996582031 seconds.
5416 sentences created
mode 1: time used = 0.10457181930541992
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '6.00780'}; time used = 0.6817994117736816s
epoch 10: {'train_loss': '4.74018'}; time used = 1.5200026035308838s
epoch 15: {'train_loss': '4.28244'}; time used = 1.1580779552459717s
epoch 20: {'train_loss': '3.96059'}; time used = 1.4002432823181152s
epoch 25: {'train_loss': '3.73355'}; time used = 1.3744232654571533s
epoch 30: {'train_loss': '3.48404'}; time used = 1.4454984664916992s
epoch 35: {'train_loss': '3.36562'}; time used = 1.5778861045837402s
epoch 40: {'train_loss': '3.14295'}; time used = 1.2788269519805908s
epoch 45: {'train_loss': '2.98707'}; time used = 1.1505138874053955s
epoch 50: {'train_loss': '2.81898'}; time used = 1.799081563949585s
epoch 55: {'train_loss': '2.65292'}; time used = 1.4951763153076172s
epoch 60: {'train_loss': '2.49312'}; time used = 1.4153356552124023s
epoch 65: {'train_loss': '2.32955'}; time used = 1.4006972312927246s
epoch 70: {'train_loss': '2.21607'}; time used = 1.435887098312378s
epoch 75: {'train_loss': '2.09505'}; time used = 1.1311924457550049s
epoch 80: {'train_loss': '2.01363'}; time used = 1.4767489433288574s
epoch 85: {'train_loss': '1.88770'}; time used = 1.3880064487457275s
epoch 90: {'train_loss': '1.78271'}; time used = 1.1655080318450928s
epoch 95: {'train_loss': '1.70400'}; time used = 1.1784298419952393s
epoch 100: {'train_loss': '1.63454'}; time used = 1.1951837539672852s
epoch 105: {'train_loss': '1.53706'}; time used = 1.3367605209350586s
epoch 110: {'train_loss': '1.47215'}; time used = 1.4439969062805176s
epoch 115: {'train_loss': '1.41314'}; time used = 1.3290274143218994s
epoch 120: {'train_loss': '1.33825'}; time used = 1.0339429378509521s
epoch 125: {'train_loss': '1.28869'}; time used = 1.0969889163970947s
epoch 130: {'train_loss': '1.23640'}; time used = 0.7537214756011963s
epoch 135: {'train_loss': '1.19571'}; time used = 1.0429465770721436s
epoch 140: {'train_loss': '1.16222'}; time used = 1.1568446159362793s
epoch 145: {'train_loss': '1.11718'}; time used = 1.1024434566497803s
epoch 150: {'train_loss': '1.09062'}; time used = 1.0139882564544678s
epoch 155: {'train_loss': '1.05345'}; time used = 1.0859062671661377s
epoch 160: {'train_loss': '1.03356'}; time used = 1.4145636558532715s
epoch 165: {'train_loss': '1.00725'}; time used = 1.138986587524414s
epoch 170: {'train_loss': '0.98933'}; time used = 1.3494138717651367s
epoch 175: {'train_loss': '0.96145'}; time used = 0.9304642677307129s
epoch 180: {'train_loss': '0.94802'}; time used = 1.2280447483062744s
epoch 185: {'train_loss': '0.92857'}; time used = 1.3842089176177979s
epoch 190: {'train_loss': '0.91578'}; time used = 1.4986145496368408s
epoch 195: {'train_loss': '0.91078'}; time used = 0.8744328022003174s
epoch 200: {'train_loss': '0.89442'}; time used = 1.3061823844909668s
epoch 205: {'train_loss': '0.88494'}; time used = 1.1508843898773193s
epoch 210: {'train_loss': '0.87070'}; time used = 1.155949354171753s
epoch 215: {'train_loss': '0.85933'}; time used = 1.0950798988342285s
epoch 220: {'train_loss': '0.84975'}; time used = 1.2069673538208008s
epoch 225: {'train_loss': '0.84416'}; time used = 1.0194897651672363s
epoch 230: {'train_loss': '0.83668'}; time used = 1.0651824474334717s
epoch 235: {'train_loss': '0.83152'}; time used = 1.321019172668457s
epoch 240: {'train_loss': '0.82434'}; time used = 1.106525182723999s
epoch 245: {'train_loss': '0.82257'}; time used = 1.387127161026001s
epoch 250: {'train_loss': '0.81509'}; time used = 0.9964909553527832s
epoch 255: {'train_loss': '0.80706'}; time used = 1.4191575050354004s
epoch 260: {'train_loss': '0.80539'}; time used = 1.3199059963226318s
epoch 265: {'train_loss': '0.80318'}; time used = 1.6388564109802246s
epoch 270: {'train_loss': '0.79797'}; time used = 1.7760112285614014s
epoch 275: {'train_loss': '0.79402'}; time used = 1.3482654094696045s
epoch 280: {'train_loss': '0.79110'}; time used = 1.2322769165039062s
epoch 285: {'train_loss': '0.79120'}; time used = 1.1831133365631104s
epoch 290: {'train_loss': '0.78547'}; time used = 1.0615558624267578s
epoch 295: {'train_loss': '0.78175'}; time used = 1.0466742515563965s
epoch 300: {'train_loss': '0.78433'}; time used = 1.4853293895721436s
epoch 305: {'train_loss': '0.78067'}; time used = 1.1181964874267578s
epoch 310: {'train_loss': '0.77936'}; time used = 1.4260716438293457s
epoch 315: {'train_loss': '0.77445'}; time used = 0.8583440780639648s
epoch 320: {'train_loss': '0.77524'}; time used = 0.5759825706481934s
epoch 325: {'train_loss': '0.77243'}; time used = 0.5965785980224609s
epoch 330: {'train_loss': '0.77036'}; time used = 0.6793906688690186s
epoch 335: {'train_loss': '0.76582'}; time used = 0.8902606964111328s
epoch 340: {'train_loss': '0.76808'}; time used = 0.8457503318786621s
epoch 345: {'train_loss': '0.76392'}; time used = 0.6168279647827148s
epoch 350: {'train_loss': '0.76574'}; time used = 0.5990457534790039s
epoch 355: {'train_loss': '0.76128'}; time used = 0.5756516456604004s
epoch 360: {'train_loss': '0.76287'}; time used = 0.5419986248016357s
epoch 365: {'train_loss': '0.75908'}; time used = 0.6277561187744141s
epoch 370: {'train_loss': '0.75996'}; time used = 0.5376935005187988s
epoch 375: {'train_loss': '0.75838'}; time used = 0.5748748779296875s
epoch 380: {'train_loss': '0.75853'}; time used = 0.4380161762237549s
epoch 385: {'train_loss': '0.75392'}; time used = 0.4615607261657715s
epoch 390: {'train_loss': '0.75514'}; time used = 0.6222178936004639s
epoch 395: {'train_loss': '0.75363'}; time used = 0.4596071243286133s
epoch 400: {'train_loss': '0.75248'}; time used = 0.5508472919464111s
epoch 405: {'train_loss': '0.75354'}; time used = 0.44544100761413574s
epoch 410: {'train_loss': '0.74992'}; time used = 0.6307373046875s
epoch 415: {'train_loss': '0.74797'}; time used = 1.012502908706665s
epoch 420: {'train_loss': '0.75216'}; time used = 0.5074138641357422s
epoch 425: {'train_loss': '0.74906'}; time used = 0.5254213809967041s
epoch 430: {'train_loss': '0.74979'}; time used = 0.6099278926849365s
epoch 435: {'train_loss': '0.75019'}; time used = 0.6180830001831055s
epoch 440: {'train_loss': '0.74825'}; time used = 0.8313961029052734s
epoch 445: {'train_loss': '0.75192'}; time used = 0.8619239330291748s
epoch 450: {'train_loss': '0.74928'}; time used = 0.6773066520690918s
epoch 455: {'train_loss': '0.74799'}; time used = 0.8538169860839844s
epoch 460: {'train_loss': '0.74618'}; time used = 0.6668341159820557s
epoch 465: {'train_loss': '0.74809'}; time used = 0.5504467487335205s
epoch 470: {'train_loss': '0.74517'}; time used = 0.6798906326293945s
epoch 475: {'train_loss': '0.74358'}; time used = 0.6397871971130371s
epoch 480: {'train_loss': '0.74558'}; time used = 0.7388126850128174s
epoch 485: {'train_loss': '0.74426'}; time used = 0.6651456356048584s
epoch 490: {'train_loss': '0.74522'}; time used = 0.6502983570098877s
epoch 495: {'train_loss': '0.74506'}; time used = 0.5572831630706787s

epoch 500: {'train_loss': '0.73959'}; time used = 0.5971062183380127s
Finished training. Time used = 114.22604393959045.
Training classifier using 20.00% nodes...
{'micro': 0.6742039686202123, 'macro': 0.663749036793764, 'samples': 0.6742039686202123, 'weighted': 0.6711776506491368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 150832.97it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 82, in forward
    return self.embed(x)[indices]
RuntimeError: CUDA out of memory. Tried to allocate 76.00 MiB (GPU 0; 10.76 GiB total capacity; 22.05 MiB already allocated; 37.44 MiB free; 38.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.018084287643432617 seconds.
Run epoch 1
Epoch 1 ends in 0.019468069076538086 seconds.
5416 sentences created
mode 1: time used = 0.048636674880981445
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 10.76 GiB total capacity; 0 bytes already allocated; 15.44 MiB free; 0 bytes reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 178419.34it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20826/75824 [00:00<00:00, 208251.26it/s] 55%|    | 41400/75824 [00:00<00:00, 207489.13it/s] 80%|  | 60944/75824 [00:00<00:00, 203719.47it/s]100%|| 75824/75824 [00:00<00:00, 201834.82it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 222, in forward
    self.to(self._device)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 607, in to
    return self._apply(convert)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 376, in _apply
    param_applied = fn(param)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 605, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.76 GiB total capacity; 14.80 MiB already allocated; 15.44 MiB free; 16.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.020586013793945312 seconds.
Run epoch 1
Epoch 1 ends in 0.018393993377685547 seconds.
5416 sentences created
mode 1: time used = 0.043553829193115234
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 178085.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18393/75824 [00:00<00:00, 183925.79it/s] 50%|     | 37960/75824 [00:00<00:00, 187295.67it/s] 76%|  | 57645/75824 [00:00<00:00, 190062.28it/s] 93%|| 70363/75824 [00:00<00:00, 162787.85it/s]100%|| 75824/75824 [00:00<00:00, 167412.98it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 222, in forward
    self.to(self._device)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 607, in to
    return self._apply(convert)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 376, in _apply
    param_applied = fn(param)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 605, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 10.76 GiB total capacity; 14.80 MiB already allocated; 16.44 MiB free; 16.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.018401145935058594 seconds.
Run epoch 1
Epoch 1 ends in 0.02291393280029297 seconds.
5416 sentences created
mode 1: time used = 0.04157614707946777
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 126587.34it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11881/75824 [00:00<00:00, 118807.85it/s] 31%|       | 23334/75824 [00:00<00:00, 117490.57it/s] 47%|     | 35800/75824 [00:00<00:00, 119552.67it/s] 70%|   | 53221/75824 [00:00<00:00, 131974.34it/s] 87%| | 65623/75824 [00:00<00:00, 129480.93it/s]100%|| 75824/75824 [00:00<00:00, 137575.99it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20446/75824 [00:00<00:00, 204452.40it/s] 53%|    | 40491/75824 [00:00<00:00, 203231.52it/s] 73%|  | 55260/75824 [00:00<00:00, 182623.43it/s] 92%|| 69885/75824 [00:00<00:00, 169882.92it/s]100%|| 75824/75824 [00:00<00:00, 146636.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  3%|         | 2494/75824 [00:00<00:02, 24938.83it/s] 16%|        | 11828/75824 [00:00<00:02, 31966.45it/s] 29%|       | 21789/75824 [00:00<00:01, 40144.96it/s] 36%|      | 27104/75824 [00:00<00:01, 41277.73it/s] 43%|     | 32826/75824 [00:00<00:00, 45042.20it/s] 52%|    | 39195/75824 [00:00<00:00, 49149.25it/s] 60%|    | 45723/75824 [00:00<00:00, 53082.54it/s] 70%|   | 52875/75824 [00:00<00:00, 57531.02it/s] 78%|  | 59110/75824 [00:00<00:00, 49585.21it/s] 92%|| 69620/75824 [00:01<00:00, 58922.08it/s]100%|| 75824/75824 [00:01<00:00, 64978.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12547/75824 [00:00<00:00, 125468.03it/s] 24%|       | 18204/75824 [00:00<00:00, 91507.08it/s]  38%|      | 28907/75824 [00:00<00:00, 95668.53it/s] 55%|    | 41724/75824 [00:00<00:00, 103007.35it/s] 66%|   | 49851/75824 [00:00<00:00, 88983.96it/s]  84%| | 63404/75824 [00:00<00:00, 99205.10it/s]100%|| 75824/75824 [00:00<00:00, 104968.70it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18769/75824 [00:00<00:00, 187684.81it/s] 50%|     | 37964/75824 [00:00<00:00, 188944.12it/s] 75%|  | 57208/75824 [00:00<00:00, 189977.25it/s]100%|| 75824/75824 [00:00<00:00, 192285.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11979/75824 [00:00<00:00, 119781.55it/s] 39%|      | 29823/75824 [00:00<00:00, 132886.20it/s] 66%|   | 50138/75824 [00:00<00:00, 148270.20it/s] 92%|| 69918/75824 [00:00<00:00, 160311.82it/s]100%|| 75824/75824 [00:00<00:00, 176745.08it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18906/75824 [00:00<00:00, 189050.26it/s] 51%|     | 38418/75824 [00:00<00:00, 190830.68it/s] 77%|  | 58172/75824 [00:00<00:00, 192793.57it/s]100%|| 75824/75824 [00:00<00:00, 192520.65it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 14936/75824 [00:00<00:00, 149355.16it/s] 39%|      | 29912/75824 [00:00<00:00, 149473.97it/s] 60%|    | 45341/75824 [00:00<00:00, 150884.53it/s] 79%|  | 60132/75824 [00:00<00:00, 149979.07it/s]100%|| 75499/75824 [00:00<00:00, 151065.41it/s]100%|| 75824/75824 [00:00<00:00, 150889.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14468/75824 [00:00<00:00, 141442.77it/s] 32%|      | 24344/75824 [00:00<00:00, 125208.07it/s] 47%|     | 35913/75824 [00:00<00:00, 122189.71it/s] 67%|   | 50665/75824 [00:00<00:00, 128823.84it/s] 91%| | 68927/75824 [00:00<00:00, 141311.01it/s]100%|| 75824/75824 [00:00<00:00, 140428.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|       | 17274/75824 [00:00<00:00, 172737.69it/s] 47%|     | 35613/75824 [00:00<00:00, 175800.11it/s] 68%|   | 51281/75824 [00:00<00:00, 169591.18it/s] 86%| | 65529/75824 [00:00<00:00, 160430.20it/s]100%|| 75824/75824 [00:00<00:00, 166546.00it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16969/75824 [00:00<00:00, 169685.71it/s] 47%|     | 35403/75824 [00:00<00:00, 173830.49it/s] 71%|   | 53929/75824 [00:00<00:00, 177107.67it/s] 87%| | 65853/75824 [00:00<00:00, 143542.10it/s]100%|| 75824/75824 [00:00<00:00, 154492.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|       | 17224/75824 [00:00<00:00, 172238.11it/s] 47%|     | 35566/75824 [00:00<00:00, 175444.74it/s] 71%|   | 53903/75824 [00:00<00:00, 177749.12it/s] 95%|| 72241/75824 [00:00<00:00, 179400.54it/s]100%|| 75824/75824 [00:00<00:00, 180880.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12113/75824 [00:00<00:00, 112068.05it/s] 30%|       | 23081/75824 [00:00<00:00, 111338.07it/s] 47%|     | 35496/75824 [00:00<00:00, 114893.49it/s] 63%|   | 47542/75824 [00:00<00:00, 116507.65it/s] 85%| | 64274/75824 [00:00<00:00, 128185.94it/s]100%|| 75824/75824 [00:00<00:00, 132883.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|       | 17407/75824 [00:00<00:00, 174062.70it/s] 47%|     | 35794/75824 [00:00<00:00, 176891.72it/s] 66%|   | 50244/75824 [00:00<00:00, 165744.97it/s] 88%| | 66776/75824 [00:00<00:00, 165616.94it/s]100%|| 75824/75824 [00:00<00:00, 170369.68it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19258/75824 [00:00<00:00, 192578.35it/s] 51%|     | 38825/75824 [00:00<00:00, 193493.67it/s] 77%|  | 58240/75824 [00:00<00:00, 193690.02it/s]100%|| 75824/75824 [00:00<00:00, 195440.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18438/75824 [00:00<00:00, 184377.10it/s] 46%|     | 35066/75824 [00:00<00:00, 178544.33it/s] 71%|  | 54185/75824 [00:00<00:00, 182157.64it/s] 97%|| 73550/75824 [00:00<00:00, 185458.43it/s]100%|| 75824/75824 [00:00<00:00, 182310.55it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18324/75824 [00:00<00:00, 183232.75it/s] 48%|     | 36524/75824 [00:00<00:00, 182859.65it/s] 74%|  | 56133/75824 [00:00<00:00, 186634.93it/s] 92%|| 69851/75824 [00:00<00:00, 168415.39it/s]100%|| 75824/75824 [00:00<00:00, 170460.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18338/75824 [00:00<00:00, 183378.86it/s] 49%|     | 37446/75824 [00:00<00:00, 185621.34it/s] 77%|  | 58070/75824 [00:00<00:00, 191360.60it/s]100%|| 75824/75824 [00:00<00:00, 194805.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16508/75824 [00:00<00:00, 165078.19it/s] 39%|      | 29755/75824 [00:00<00:00, 153725.97it/s] 63%|   | 47715/75824 [00:00<00:00, 160668.12it/s] 77%|  | 58312/75824 [00:00<00:00, 118066.63it/s] 90%| | 67918/75824 [00:00<00:00, 88787.42it/s] 100%|| 75824/75824 [00:00<00:00, 110761.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12491/75824 [00:00<00:00, 103433.33it/s] 25%|       | 19106/75824 [00:00<00:00, 88472.14it/s]  34%|      | 25819/75824 [00:00<00:00, 77104.13it/s] 55%|    | 41338/75824 [00:00<00:00, 90811.22it/s] 65%|   | 49611/75824 [00:00<00:00, 88153.41it/s] 81%|  | 61456/75824 [00:00<00:00, 95478.80it/s] 97%|| 73797/75824 [00:00<00:00, 102433.88it/s]100%|| 75824/75824 [00:00<00:00, 99906.58it/s] 
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12218/75824 [00:00<00:00, 122171.96it/s] 29%|       | 21696/75824 [00:00<00:00, 112422.50it/s] 36%|      | 27105/75824 [00:00<00:00, 63866.16it/s]  50%|     | 38150/75824 [00:00<00:00, 73117.00it/s] 68%|   | 51601/75824 [00:00<00:00, 84716.58it/s] 94%|| 71233/75824 [00:00<00:00, 102134.14it/s]100%|| 75824/75824 [00:00<00:00, 109475.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18072/75824 [00:00<00:00, 180712.42it/s] 49%|     | 37385/75824 [00:00<00:00, 184266.02it/s] 62%|   | 46974/75824 [00:00<00:00, 132187.34it/s] 90%| | 68316/75824 [00:00<00:00, 149226.13it/s]100%|| 75824/75824 [00:00<00:00, 167282.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|       | 22068/75824 [00:00<00:00, 220673.37it/s] 58%|    | 44024/75824 [00:00<00:00, 220337.61it/s] 88%| | 66705/75824 [00:00<00:00, 222239.33it/s]100%|| 75824/75824 [00:00<00:00, 223145.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18123/75824 [00:00<00:00, 181224.99it/s] 49%|     | 36853/75824 [00:00<00:00, 183004.73it/s] 75%|  | 56499/75824 [00:00<00:00, 186843.28it/s]100%|| 75824/75824 [00:00<00:00, 192316.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21058/75824 [00:00<00:00, 210578.19it/s] 57%|    | 43372/75824 [00:00<00:00, 214193.24it/s] 87%| | 65766/75824 [00:00<00:00, 217025.86it/s]100%|| 75824/75824 [00:00<00:00, 220143.14it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20113/75824 [00:00<00:00, 201121.56it/s] 56%|    | 42597/75824 [00:00<00:00, 207691.66it/s] 76%|  | 57412/75824 [00:00<00:00, 185340.35it/s] 96%|| 72740/75824 [00:00<00:00, 174394.67it/s]100%|| 75824/75824 [00:00<00:00, 182146.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16760/75824 [00:00<00:00, 167592.97it/s] 47%|     | 35350/75824 [00:00<00:00, 172694.54it/s] 72%|  | 54741/75824 [00:00<00:00, 178554.77it/s] 97%|| 73705/75824 [00:00<00:00, 181739.15it/s]100%|| 75824/75824 [00:00<00:00, 181498.90it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 17962/75824 [00:00<00:00, 179616.75it/s] 49%|     | 36786/75824 [00:00<00:00, 182117.39it/s] 73%|  | 55103/75824 [00:00<00:00, 182429.48it/s] 91%| | 69157/75824 [00:00<00:00, 167453.78it/s]100%|| 75824/75824 [00:00<00:00, 168530.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|        | 15913/75824 [00:00<00:00, 159125.22it/s] 44%|     | 33514/75824 [00:00<00:00, 163840.03it/s] 70%|   | 53172/75824 [00:00<00:00, 172456.11it/s] 95%|| 72387/75824 [00:00<00:00, 177925.35it/s]100%|| 75824/75824 [00:00<00:00, 181781.60it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10784/75824 [00:00<00:00, 107832.13it/s] 29%|       | 21667/75824 [00:00<00:00, 108128.37it/s] 43%|     | 32498/75824 [00:00<00:00, 108176.80it/s] 52%|    | 39618/75824 [00:00<00:00, 86087.65it/s]  67%|   | 50750/75824 [00:00<00:00, 92334.61it/s] 82%| | 62495/75824 [00:00<00:00, 98662.32it/s] 98%|| 74603/75824 [00:00<00:00, 104463.09it/s]100%|| 75824/75824 [00:00<00:00, 103557.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12042/75824 [00:00<00:00, 120418.97it/s] 27%|       | 20520/75824 [00:00<00:00, 106928.79it/s] 37%|      | 28125/75824 [00:00<00:00, 95315.15it/s]  50%|     | 37746/75824 [00:00<00:00, 95580.05it/s] 63%|   | 47864/75824 [00:00<00:00, 97192.87it/s] 77%|  | 58749/75824 [00:00<00:00, 100417.45it/s] 91%| | 69088/75824 [00:00<00:00, 101289.15it/s]100%|| 75824/75824 [00:00<00:00, 97843.19it/s] 
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9533/75824 [00:00<00:00, 95323.27it/s] 27%|       | 20433/75824 [00:00<00:00, 99050.11it/s] 41%|     | 31442/75824 [00:00<00:00, 102122.33it/s] 56%|    | 42516/75824 [00:00<00:00, 104561.21it/s] 71%|   | 53650/75824 [00:00<00:00, 106504.04it/s] 85%| | 64791/75824 [00:00<00:00, 107929.58it/s] 98%|| 74498/75824 [00:00<00:00, 85096.42it/s] 100%|| 75824/75824 [00:00<00:00, 96773.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10621/75824 [00:00<00:00, 106199.72it/s] 28%|       | 21073/75824 [00:00<00:00, 105687.90it/s] 42%|     | 32028/75824 [00:00<00:00, 106815.65it/s] 57%|    | 43161/75824 [00:00<00:00, 108131.00it/s] 72%|  | 54337/75824 [00:00<00:00, 109194.43it/s] 84%| | 63657/75824 [00:00<00:00, 103844.46it/s] 96%|| 72852/75824 [00:00<00:00, 90407.52it/s] 100%|| 75824/75824 [00:00<00:00, 99530.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10427/75824 [00:00<00:00, 104264.63it/s] 29%|       | 21792/75824 [00:00<00:00, 106912.01it/s] 40%|      | 30175/75824 [00:00<00:00, 98749.88it/s]  48%|     | 36609/75824 [00:00<00:00, 78794.20it/s] 63%|   | 47624/75824 [00:00<00:00, 86150.25it/s] 78%|  | 59037/75824 [00:00<00:00, 92988.60it/s] 92%|| 69993/75824 [00:00<00:00, 97406.93it/s]100%|| 75824/75824 [00:00<00:00, 98413.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11328/75824 [00:00<00:00, 113278.22it/s] 26%|       | 19673/75824 [00:00<00:00, 102302.19it/s] 37%|      | 28240/75824 [00:00<00:00, 96670.85it/s]  48%|     | 36540/75824 [00:00<00:00, 92116.54it/s] 59%|    | 44576/75824 [00:00<00:00, 88241.52it/s] 68%|   | 51664/75824 [00:00<00:00, 70805.85it/s] 91%| | 69040/75824 [00:00<00:00, 86112.45it/s]100%|| 75824/75824 [00:00<00:00, 93834.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10293/75824 [00:00<00:00, 102929.61it/s] 31%|       | 23319/75824 [00:00<00:00, 109842.40it/s] 51%|     | 38723/75824 [00:00<00:00, 120186.00it/s] 69%|   | 52384/75824 [00:00<00:00, 124682.00it/s] 83%| | 62839/75824 [00:00<00:00, 117289.81it/s] 98%|| 74060/75824 [00:00<00:00, 115717.83it/s]100%|| 75824/75824 [00:00<00:00, 123117.27it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6038/75824 [00:00<00:01, 60376.03it/s] 13%|        | 9753/75824 [00:00<00:01, 48752.45it/s] 19%|        | 14389/75824 [00:00<00:01, 48008.52it/s] 27%|       | 20183/75824 [00:00<00:01, 50304.38it/s] 32%|      | 24568/75824 [00:00<00:01, 48175.95it/s] 38%|      | 28536/75824 [00:00<00:01, 41361.88it/s] 47%|     | 35757/75824 [00:00<00:00, 47442.05it/s] 60%|    | 45245/75824 [00:00<00:00, 55570.61it/s] 74%|  | 56378/75824 [00:00<00:00, 65396.06it/s] 90%| | 67880/75824 [00:01<00:00, 75118.19it/s]100%|| 75824/75824 [00:01<00:00, 68460.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 5908/75824 [00:00<00:01, 57925.90it/s] 16%|        | 12335/75824 [00:00<00:01, 59692.28it/s] 31%|       | 23394/75824 [00:00<00:00, 69254.05it/s] 40%|      | 30680/75824 [00:00<00:00, 69211.07it/s] 48%|     | 36617/75824 [00:00<00:00, 59733.84it/s] 56%|    | 42131/75824 [00:00<00:00, 53874.47it/s] 66%|   | 50417/75824 [00:00<00:00, 60190.88it/s] 75%|  | 56526/75824 [00:00<00:00, 59877.09it/s] 90%| | 68232/75824 [00:00<00:00, 70088.24it/s]100%|| 75824/75824 [00:01<00:00, 73404.81it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12396/75824 [00:00<00:00, 123958.94it/s] 32%|      | 24479/75824 [00:00<00:00, 123002.24it/s] 48%|     | 36668/75824 [00:00<00:00, 122664.45it/s] 65%|   | 49025/75824 [00:00<00:00, 122933.44it/s] 77%|  | 58344/75824 [00:00<00:00, 93387.41it/s]  92%|| 70127/75824 [00:00<00:00, 96313.75it/s]100%|| 75824/75824 [00:00<00:00, 98534.27it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10844/75824 [00:00<00:00, 108434.93it/s] 28%|       | 21250/75824 [00:00<00:00, 103683.12it/s] 37%|      | 28103/75824 [00:00<00:00, 89853.21it/s]  52%|    | 39664/75824 [00:00<00:00, 96288.33it/s] 68%|   | 51634/75824 [00:00<00:00, 102289.64it/s] 84%| | 63828/75824 [00:00<00:00, 107484.92it/s]100%|| 75824/75824 [00:00<00:00, 106947.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 7964/75824 [00:00<00:00, 79634.57it/s] 23%|       | 17645/75824 [00:00<00:00, 84110.09it/s] 35%|      | 26402/75824 [00:00<00:00, 85118.09it/s] 49%|     | 37252/75824 [00:00<00:00, 90999.75it/s] 59%|    | 44589/75824 [00:00<00:00, 76691.02it/s] 69%|   | 52462/75824 [00:00<00:00, 77291.51it/s] 79%|  | 59597/75824 [00:00<00:00, 74149.45it/s] 95%|| 71897/75824 [00:00<00:00, 84178.86it/s]100%|| 75824/75824 [00:00<00:00, 86828.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6193/75824 [00:00<00:01, 54629.11it/s] 15%|        | 11289/75824 [00:00<00:01, 53473.85it/s] 22%|       | 16951/75824 [00:00<00:01, 54379.37it/s] 32%|      | 24465/75824 [00:00<00:00, 59086.84it/s] 41%|     | 31286/75824 [00:00<00:00, 61537.18it/s] 52%|    | 39795/75824 [00:00<00:00, 67109.49it/s] 63%|   | 47694/75824 [00:00<00:00, 69459.82it/s] 72%|  | 54372/75824 [00:00<00:00, 61035.42it/s] 80%|  | 60474/75824 [00:00<00:00, 60676.44it/s] 88%| | 66541/75824 [00:01<00:00, 57805.85it/s] 97%|| 73469/75824 [00:01<00:00, 60827.83it/s]100%|| 75824/75824 [00:01<00:00, 63250.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  5%|         | 3660/75824 [00:00<00:01, 36597.33it/s]  9%|         | 6592/75824 [00:00<00:02, 33244.73it/s] 15%|        | 11176/75824 [00:00<00:01, 35397.76it/s] 19%|        | 14033/75824 [00:00<00:01, 32725.94it/s] 24%|       | 18378/75824 [00:00<00:01, 35342.12it/s] 29%|       | 22212/75824 [00:00<00:01, 36033.34it/s] 35%|      | 26350/75824 [00:00<00:01, 37485.33it/s] 39%|      | 29877/75824 [00:00<00:01, 32368.20it/s] 44%|     | 33083/75824 [00:00<00:01, 29230.68it/s] 48%|     | 36202/75824 [00:01<00:01, 28946.03it/s] 52%|    | 39524/75824 [00:01<00:01, 30107.98it/s] 56%|    | 42565/75824 [00:01<00:01, 29836.68it/s] 60%|    | 45571/75824 [00:01<00:01, 28384.05it/s] 65%|   | 49519/75824 [00:01<00:00, 30996.55it/s] 70%|   | 52712/75824 [00:01<00:00, 30777.79it/s] 74%|  | 55855/75824 [00:01<00:00, 29005.24it/s] 78%|  | 58823/75824 [00:01<00:00, 27283.16it/s] 83%| | 62700/75824 [00:01<00:00, 29944.12it/s] 87%| | 65821/75824 [00:02<00:00, 30266.23it/s] 91%| | 68997/75824 [00:02<00:00, 30314.50it/s] 95%|| 72091/75824 [00:02<00:00, 29615.19it/s]100%|| 75824/75824 [00:02<00:00, 31651.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  5%|         | 3910/75824 [00:00<00:01, 38045.21it/s] 10%|         | 7704/75824 [00:00<00:01, 38012.89it/s] 13%|        | 10061/75824 [00:00<00:02, 31278.45it/s] 18%|        | 13405/75824 [00:00<00:01, 31896.24it/s] 23%|       | 17278/75824 [00:00<00:01, 33678.69it/s] 27%|       | 20817/75824 [00:00<00:01, 33940.07it/s] 33%|      | 24700/75824 [00:00<00:01, 35272.59it/s] 38%|      | 28717/75824 [00:00<00:01, 35609.67it/s] 44%|     | 33287/75824 [00:00<00:01, 37450.46it/s] 49%|     | 37401/75824 [00:01<00:01, 38410.60it/s] 55%|    | 41384/75824 [00:01<00:00, 37819.60it/s] 60%|    | 45128/75824 [00:01<00:00, 37565.78it/s] 65%|   | 49057/75824 [00:01<00:00, 36895.37it/s] 70%|   | 52804/75824 [00:01<00:00, 37033.32it/s] 75%|  | 56497/75824 [00:01<00:00, 36878.82it/s] 80%|  | 60399/75824 [00:01<00:00, 36759.90it/s] 85%| | 64168/75824 [00:01<00:00, 37033.69it/s] 90%| | 67869/75824 [00:01<00:00, 36788.20it/s] 94%|| 71547/75824 [00:01<00:00, 35479.62it/s] 99%|| 75292/75824 [00:02<00:00, 35856.75it/s]100%|| 75824/75824 [00:02<00:00, 36265.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6350/75824 [00:00<00:01, 63498.24it/s] 15%|        | 11662/75824 [00:00<00:01, 59981.11it/s] 23%|       | 17062/75824 [00:00<00:01, 58052.06it/s] 30%|       | 22534/75824 [00:00<00:00, 57009.51it/s] 35%|      | 26744/75824 [00:00<00:01, 46912.06it/s] 40%|      | 30707/75824 [00:00<00:01, 44460.25it/s] 46%|     | 34656/75824 [00:00<00:01, 36000.92it/s] 53%|    | 40330/75824 [00:00<00:00, 40321.35it/s] 61%|   | 46478/75824 [00:00<00:00, 44519.16it/s] 69%|   | 52014/75824 [00:01<00:00, 47198.74it/s] 75%|  | 57121/75824 [00:01<00:00, 48184.56it/s] 83%| | 62977/75824 [00:01<00:00, 49932.67it/s] 91%|| 69238/75824 [00:01<00:00, 52402.93it/s] 99%|| 75362/75824 [00:01<00:00, 54773.98it/s]100%|| 75824/75824 [00:01<00:00, 49917.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10328/75824 [00:00<00:00, 103276.41it/s] 25%|       | 18746/75824 [00:00<00:00, 92646.71it/s]  31%|       | 23156/75824 [00:00<00:00, 69067.48it/s] 36%|      | 27543/75824 [00:00<00:00, 51030.93it/s] 42%|     | 31566/75824 [00:00<00:00, 44650.30it/s] 47%|     | 35419/75824 [00:00<00:01, 36319.23it/s] 52%|    | 39470/75824 [00:00<00:00, 36584.29it/s] 58%|    | 43643/75824 [00:00<00:00, 36276.04it/s] 62%|   | 47205/75824 [00:01<00:00, 35000.24it/s] 68%|   | 51477/75824 [00:01<00:00, 36947.83it/s] 74%|  | 56094/75824 [00:01<00:00, 38229.62it/s] 80%|  | 60597/75824 [00:01<00:00, 39863.16it/s] 87%| | 65937/75824 [00:01<00:00, 43144.10it/s] 93%|| 70837/75824 [00:01<00:00, 44748.25it/s]100%|| 75518/75824 [00:01<00:00, 45346.77it/s]100%|| 75824/75824 [00:01<00:00, 44368.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5561/75824 [00:00<00:01, 51702.56it/s] 13%|        | 9946/75824 [00:00<00:01, 47767.00it/s] 19%|        | 14090/75824 [00:00<00:01, 45297.66it/s] 24%|       | 18241/75824 [00:00<00:01, 44089.59it/s] 30%|       | 22605/75824 [00:00<00:01, 42773.82it/s] 35%|      | 26735/75824 [00:00<00:01, 42319.89it/s] 40%|      | 30609/75824 [00:00<00:01, 41178.06it/s] 45%|     | 34332/75824 [00:00<00:01, 32306.19it/s] 50%|     | 37583/75824 [00:01<00:01, 32094.98it/s] 54%|    | 40807/75824 [00:01<00:01, 32086.77it/s] 58%|    | 44026/75824 [00:01<00:01, 30818.41it/s] 62%|   | 47126/75824 [00:01<00:00, 30283.89it/s] 66%|   | 50300/75824 [00:01<00:00, 30062.66it/s] 71%|   | 53779/75824 [00:01<00:00, 31059.96it/s] 75%|  | 56978/75824 [00:01<00:00, 29951.47it/s] 80%|  | 60374/75824 [00:01<00:00, 30271.01it/s] 84%| | 63802/75824 [00:01<00:00, 31371.04it/s] 88%| | 66960/75824 [00:01<00:00, 31142.75it/s] 92%|| 70089/75824 [00:02<00:00, 30697.14it/s] 97%|| 73388/75824 [00:02<00:00, 30188.57it/s]100%|| 75824/75824 [00:02<00:00, 33700.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7138/75824 [00:00<00:01, 67556.79it/s] 17%|        | 13125/75824 [00:00<00:00, 65050.10it/s] 22%|       | 16340/75824 [00:00<00:01, 44155.36it/s] 26%|       | 19861/75824 [00:00<00:01, 41027.63it/s] 39%|      | 29476/75824 [00:00<00:00, 49549.37it/s] 47%|     | 35903/75824 [00:00<00:00, 50860.12it/s] 58%|    | 43807/75824 [00:00<00:00, 56951.47it/s] 74%|  | 55841/75824 [00:00<00:00, 67639.36it/s] 90%| | 67885/75824 [00:00<00:00, 77881.59it/s]100%|| 75824/75824 [00:01<00:00, 70243.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8556/75824 [00:00<00:00, 85558.86it/s] 18%|        | 13930/75824 [00:00<00:00, 66865.59it/s] 23%|       | 17676/75824 [00:00<00:01, 54118.51it/s] 28%|       | 20988/75824 [00:00<00:01, 43123.10it/s] 41%|      | 30858/75824 [00:00<00:00, 51888.40it/s] 55%|    | 41629/75824 [00:00<00:00, 61440.87it/s] 71%|   | 53985/75824 [00:00<00:00, 72352.38it/s] 87%| | 65926/75824 [00:00<00:00, 82051.79it/s]100%|| 75824/75824 [00:00<00:00, 82625.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6283/75824 [00:00<00:01, 61479.77it/s] 19%|        | 14198/75824 [00:00<00:00, 65892.77it/s] 32%|      | 24038/75824 [00:00<00:00, 73140.96it/s] 47%|     | 35432/75824 [00:00<00:00, 81942.71it/s] 62%|   | 47208/75824 [00:00<00:00, 90168.74it/s] 78%|  | 59313/75824 [00:00<00:00, 97640.99it/s] 93%|| 70812/75824 [00:00<00:00, 102268.81it/s]100%|| 75824/75824 [00:00<00:00, 102001.19it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6839/75824 [00:00<00:01, 68385.50it/s] 20%|        | 14920/75824 [00:00<00:00, 71692.13it/s] 29%|       | 21970/75824 [00:00<00:00, 71249.50it/s] 40%|      | 30195/75824 [00:00<00:00, 74226.64it/s] 54%|    | 40918/75824 [00:00<00:00, 81776.37it/s] 70%|   | 53331/75824 [00:00<00:00, 91101.18it/s] 87%| | 65615/75824 [00:00<00:00, 98755.18it/s]100%|| 75634/75824 [00:00<00:00, 99179.99it/s]100%|| 75824/75824 [00:00<00:00, 94366.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10947/75824 [00:00<00:00, 109469.84it/s] 31%|       | 23142/75824 [00:00<00:00, 112935.57it/s] 46%|     | 34910/75824 [00:00<00:00, 114316.68it/s] 62%|   | 46881/75824 [00:00<00:00, 115881.06it/s] 78%|  | 59080/75824 [00:00<00:00, 117647.33it/s] 94%|| 71157/75824 [00:00<00:00, 118566.16it/s]100%|| 75824/75824 [00:00<00:00, 118399.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12279/75824 [00:00<00:00, 122789.53it/s] 28%|       | 21562/75824 [00:00<00:00, 111947.27it/s] 43%|     | 32654/75824 [00:00<00:00, 111636.89it/s] 54%|    | 40873/75824 [00:00<00:00, 99588.88it/s]  69%|   | 52114/75824 [00:00<00:00, 103115.04it/s] 83%| | 63126/75824 [00:00<00:00, 105119.37it/s] 99%|| 75203/75824 [00:00<00:00, 109371.37it/s]100%|| 75824/75824 [00:00<00:00, 106922.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11611/75824 [00:00<00:00, 116105.96it/s] 22%|       | 17033/75824 [00:00<00:00, 83818.17it/s]  39%|      | 29407/75824 [00:00<00:00, 92800.08it/s] 51%|     | 38832/75824 [00:00<00:00, 93229.12it/s] 65%|   | 49437/75824 [00:00<00:00, 96736.40it/s] 76%|  | 57776/75824 [00:00<00:00, 85192.46it/s] 88%| | 66657/75824 [00:00<00:00, 86245.22it/s] 99%|| 74807/75824 [00:00<00:00, 81542.87it/s]100%|| 75824/75824 [00:00<00:00, 88031.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11774/75824 [00:00<00:00, 117736.18it/s] 31%|      | 23760/75824 [00:00<00:00, 118363.58it/s] 48%|     | 36073/75824 [00:00<00:00, 119752.84it/s] 64%|   | 48343/75824 [00:00<00:00, 120620.86it/s] 80%|  | 60562/75824 [00:00<00:00, 121085.76it/s] 96%|| 72870/75824 [00:00<00:00, 121677.07it/s]100%|| 75824/75824 [00:00<00:00, 121435.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7048/75824 [00:00<00:00, 70472.51it/s] 18%|        | 13368/75824 [00:00<00:00, 68119.27it/s] 26%|       | 19689/75824 [00:00<00:00, 66567.56it/s] 34%|      | 26128/75824 [00:00<00:00, 65897.51it/s] 43%|     | 32403/75824 [00:00<00:00, 64919.41it/s] 52%|    | 39220/75824 [00:00<00:00, 65859.31it/s] 61%|    | 45973/75824 [00:00<00:00, 66349.41it/s] 69%|   | 52686/75824 [00:00<00:00, 66580.89it/s] 78%|  | 59467/75824 [00:00<00:00, 66943.00it/s] 87%| | 66266/75824 [00:01<00:00, 67252.15it/s] 96%|| 73113/75824 [00:01<00:00, 67610.32it/s]100%|| 75824/75824 [00:01<00:00, 66502.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  4%|         | 2830/75824 [00:00<00:02, 28298.48it/s]  5%|         | 4097/75824 [00:00<00:03, 20654.83it/s]  9%|         | 6860/75824 [00:00<00:03, 22346.92it/s] 17%|        | 12779/75824 [00:00<00:02, 27478.00it/s] 24%|       | 18160/75824 [00:00<00:01, 32205.36it/s] 29%|       | 21758/75824 [00:00<00:01, 33125.08it/s] 44%|     | 33390/75824 [00:00<00:01, 42096.14it/s] 60%|    | 45660/75824 [00:00<00:00, 52428.24it/s] 77%|  | 58115/75824 [00:00<00:00, 63450.49it/s] 91%| | 69122/75824 [00:01<00:00, 72685.74it/s]100%|| 75824/75824 [00:01<00:00, 71690.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12131/75824 [00:00<00:00, 121307.80it/s] 32%|      | 24370/75824 [00:00<00:00, 121626.94it/s] 48%|     | 36652/75824 [00:00<00:00, 121981.67it/s] 65%|   | 49071/75824 [00:00<00:00, 122634.18it/s] 81%|  | 61503/75824 [00:00<00:00, 123133.31it/s] 97%|| 73784/75824 [00:00<00:00, 123034.15it/s]100%|| 75824/75824 [00:00<00:00, 122955.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  4%|         | 2713/75824 [00:00<00:03, 22447.09it/s]  9%|         | 6790/75824 [00:00<00:02, 25537.76it/s] 15%|        | 11539/75824 [00:00<00:02, 29649.33it/s] 24%|       | 18113/75824 [00:00<00:01, 35495.30it/s] 33%|      | 25118/75824 [00:00<00:01, 41659.67it/s] 39%|      | 29847/75824 [00:00<00:01, 35344.13it/s] 46%|     | 35177/75824 [00:00<00:01, 39317.17it/s] 52%|    | 39642/75824 [00:00<00:01, 36030.23it/s] 68%|   | 51855/75824 [00:01<00:00, 45694.29it/s] 84%| | 63688/75824 [00:01<00:00, 56008.32it/s] 95%|| 71778/75824 [00:01<00:00, 55659.95it/s]100%|| 75824/75824 [00:01<00:00, 56547.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11161/75824 [00:00<00:00, 111607.71it/s] 31%|       | 23370/75824 [00:00<00:00, 114557.13it/s] 47%|     | 35731/75824 [00:00<00:00, 117128.44it/s] 59%|    | 44441/75824 [00:00<00:00, 103099.30it/s] 69%|   | 52398/75824 [00:00<00:00, 78331.05it/s]  78%|  | 59474/75824 [00:00<00:00, 70383.11it/s] 94%|| 71425/75824 [00:00<00:00, 80283.28it/s]100%|| 75824/75824 [00:00<00:00, 91778.52it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  4%|         | 3200/75824 [00:00<00:02, 31995.91it/s] 10%|         | 7220/75824 [00:00<00:02, 33946.01it/s] 15%|        | 11635/75824 [00:00<00:01, 36474.52it/s] 21%|        | 15750/75824 [00:00<00:01, 36946.67it/s] 26%|       | 19619/75824 [00:00<00:01, 37452.10it/s] 39%|      | 29500/75824 [00:00<00:01, 45780.91it/s] 50%|     | 37892/75824 [00:00<00:00, 53007.73it/s] 66%|   | 50357/75824 [00:00<00:00, 64051.66it/s] 77%|  | 58372/75824 [00:00<00:00, 57391.74it/s] 91%|| 69299/75824 [00:01<00:00, 66922.86it/s]100%|| 75824/75824 [00:01<00:00, 63585.09it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12412/75824 [00:00<00:00, 124119.82it/s] 33%|      | 24754/75824 [00:00<00:00, 123906.32it/s] 49%|     | 37258/75824 [00:00<00:00, 124243.06it/s] 65%|   | 49314/75824 [00:00<00:00, 123113.33it/s] 82%| | 61846/75824 [00:00<00:00, 123766.81it/s] 97%|| 73740/75824 [00:00<00:00, 122276.72it/s]100%|| 75824/75824 [00:00<00:00, 122916.52it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8275/75824 [00:00<00:00, 82748.50it/s] 26%|       | 19982/75824 [00:00<00:00, 90727.82it/s] 41%|      | 31228/75824 [00:00<00:00, 96309.95it/s] 51%|    | 39049/75824 [00:00<00:00, 90055.89it/s] 67%|   | 50864/75824 [00:00<00:00, 96973.12it/s] 81%| | 61796/75824 [00:00<00:00, 100372.12it/s] 98%|| 74152/75824 [00:00<00:00, 106358.66it/s]100%|| 75824/75824 [00:00<00:00, 105992.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12373/75824 [00:00<00:00, 123722.15it/s] 32%|      | 24602/75824 [00:00<00:00, 123283.88it/s] 45%|     | 34414/75824 [00:00<00:00, 114474.42it/s] 57%|    | 43534/75824 [00:00<00:00, 106330.04it/s] 70%|   | 53061/75824 [00:00<00:00, 102749.92it/s] 81%|  | 61426/75824 [00:00<00:00, 84502.52it/s]  96%|| 73142/75824 [00:00<00:00, 92213.03it/s]100%|| 75824/75824 [00:00<00:00, 95725.52it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12012/75824 [00:00<00:00, 120111.24it/s] 24%|       | 18542/75824 [00:00<00:00, 94515.31it/s]  40%|      | 30277/75824 [00:00<00:00, 100373.08it/s] 49%|     | 36889/75824 [00:00<00:00, 86074.50it/s]  65%|   | 49240/75824 [00:00<00:00, 94682.34it/s] 81%|  | 61368/75824 [00:00<00:00, 101348.87it/s] 93%|| 70818/75824 [00:00<00:00, 83265.05it/s] 100%|| 75824/75824 [00:00<00:00, 94004.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11875/75824 [00:00<00:00, 118741.62it/s] 32%|      | 24054/75824 [00:00<00:00, 119637.42it/s] 48%|     | 36102/75824 [00:00<00:00, 119886.34it/s] 64%|   | 48491/75824 [00:00<00:00, 121057.58it/s] 81%|  | 61046/75824 [00:00<00:00, 122370.79it/s] 97%|| 73606/75824 [00:00<00:00, 123320.29it/s]100%|| 75824/75824 [00:00<00:00, 122677.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11964/75824 [00:00<00:00, 119634.41it/s] 22%|       | 16593/75824 [00:00<00:00, 78608.85it/s]  31%|       | 23477/75824 [00:00<00:00, 75397.51it/s] 47%|     | 35610/75824 [00:00<00:00, 85056.68it/s] 62%|   | 47285/75824 [00:00<00:00, 92595.97it/s] 79%|  | 59549/75824 [00:00<00:00, 99939.17it/s] 95%|| 71883/75824 [00:00<00:00, 105969.40it/s]100%|| 75824/75824 [00:00<00:00, 98822.32it/s] 
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6061/75824 [00:00<00:01, 55076.77it/s] 21%|        | 15651/75824 [00:00<00:00, 63139.39it/s] 32%|      | 24017/75824 [00:00<00:00, 68153.82it/s] 47%|     | 35757/75824 [00:00<00:00, 77964.45it/s] 57%|    | 43148/75824 [00:00<00:00, 76701.51it/s] 69%|   | 52666/75824 [00:00<00:00, 81444.22it/s] 84%| | 63572/75824 [00:00<00:00, 88138.24it/s]100%|| 75469/75824 [00:00<00:00, 95567.84it/s]100%|| 75824/75824 [00:00<00:00, 93203.53it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11782/75824 [00:00<00:00, 111284.66it/s] 31%|       | 23360/75824 [00:00<00:00, 112594.72it/s] 47%|     | 35568/75824 [00:00<00:00, 115280.01it/s] 63%|   | 47494/75824 [00:00<00:00, 116444.64it/s] 79%|  | 59779/75824 [00:00<00:00, 118294.55it/s] 95%|| 72203/75824 [00:00<00:00, 120017.18it/s]100%|| 75824/75824 [00:00<00:00, 118630.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12262/75824 [00:00<00:00, 122617.78it/s] 32%|      | 24569/75824 [00:00<00:00, 122750.77it/s] 49%|     | 36960/75824 [00:00<00:00, 123095.06it/s] 65%|   | 49449/75824 [00:00<00:00, 123627.35it/s] 81%| | 61710/75824 [00:00<00:00, 123314.20it/s] 98%|| 74039/75824 [00:00<00:00, 123304.42it/s]100%|| 75824/75824 [00:00<00:00, 123393.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8690/75824 [00:00<00:00, 81265.93it/s] 22%|       | 17053/75824 [00:00<00:00, 81959.87it/s] 32%|      | 24225/75824 [00:00<00:00, 78592.79it/s] 47%|     | 35705/75824 [00:00<00:00, 86804.98it/s] 63%|   | 47513/75824 [00:00<00:00, 94297.53it/s] 78%|  | 59332/75824 [00:00<00:00, 100384.00it/s] 94%|| 71550/75824 [00:00<00:00, 106058.74it/s]100%|| 75824/75824 [00:00<00:00, 102296.71it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12131/75824 [00:00<00:00, 121307.51it/s] 32%|      | 24412/75824 [00:00<00:00, 121752.95it/s] 48%|     | 36592/75824 [00:00<00:00, 121765.27it/s] 63%|   | 48072/75824 [00:00<00:00, 119586.60it/s] 80%|  | 60608/75824 [00:00<00:00, 121261.53it/s] 96%|| 73124/75824 [00:00<00:00, 122403.57it/s]100%|| 75824/75824 [00:00<00:00, 121542.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6430/75824 [00:00<00:01, 64298.38it/s] 22%|       | 16537/75824 [00:00<00:00, 72175.17it/s] 38%|      | 28984/75824 [00:00<00:00, 82583.14it/s] 54%|    | 41321/75824 [00:00<00:00, 91674.35it/s] 71%|   | 53844/75824 [00:00<00:00, 99686.54it/s] 87%| | 66222/75824 [00:00<00:00, 105867.91it/s]100%|| 75824/75824 [00:00<00:00, 111570.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9520/75824 [00:00<00:00, 95199.41it/s] 27%|       | 20149/75824 [00:00<00:00, 95945.50it/s] 36%|      | 27489/75824 [00:00<00:00, 87848.21it/s] 49%|     | 37228/75824 [00:00<00:00, 90507.54it/s] 59%|    | 44959/75824 [00:00<00:00, 86096.46it/s] 73%|  | 55670/75824 [00:00<00:00, 91480.44it/s] 90%| | 68359/75824 [00:00<00:00, 99837.82it/s]100%|| 75824/75824 [00:00<00:00, 98315.86it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11400/75824 [00:00<00:00, 113990.32it/s] 29%|       | 22010/75824 [00:00<00:00, 111502.14it/s] 41%|      | 31085/75824 [00:00<00:00, 104343.02it/s] 50%|     | 37849/75824 [00:00<00:00, 88229.27it/s]  66%|   | 49732/75824 [00:00<00:00, 95615.62it/s] 82%| | 61848/75824 [00:00<00:00, 102071.01it/s] 97%|| 73797/75824 [00:00<00:00, 106737.19it/s]100%|| 75824/75824 [00:00<00:00, 102416.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6737/75824 [00:00<00:01, 67364.28it/s] 24%|       | 18449/75824 [00:00<00:00, 77203.11it/s] 41%|      | 30823/75824 [00:00<00:00, 87020.29it/s] 56%|    | 42455/75824 [00:00<00:00, 94133.19it/s] 72%|  | 54647/75824 [00:00<00:00, 101041.38it/s] 88%| | 66493/75824 [00:00<00:00, 104643.12it/s]100%|| 75824/75824 [00:00<00:00, 100730.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11552/75824 [00:00<00:00, 115514.05it/s] 25%|       | 18834/75824 [00:00<00:00, 98233.10it/s]  38%|      | 28852/75824 [00:00<00:00, 92534.42it/s] 46%|     | 34525/75824 [00:00<00:00, 71594.86it/s] 61%|    | 46127/75824 [00:00<00:00, 80885.89it/s] 77%|  | 58349/75824 [00:00<00:00, 90018.71it/s] 88%| | 67087/75824 [00:00<00:00, 61000.84it/s] 98%|| 74248/75824 [00:01<00:00, 50989.54it/s]100%|| 75824/75824 [00:01<00:00, 68759.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6934/75824 [00:00<00:00, 69335.27it/s] 23%|       | 17180/75824 [00:00<00:00, 76781.85it/s] 31%|       | 23253/75824 [00:00<00:00, 70328.74it/s] 37%|      | 28188/75824 [00:00<00:00, 61022.61it/s] 44%|     | 33042/75824 [00:00<00:00, 53625.69it/s] 50%|     | 37694/75824 [00:00<00:00, 45476.28it/s] 56%|    | 42219/75824 [00:00<00:00, 44088.71it/s] 69%|   | 52416/75824 [00:00<00:00, 53137.17it/s] 77%|  | 58429/75824 [00:01<00:00, 51286.09it/s] 85%| | 64214/75824 [00:01<00:00, 53092.46it/s] 98%|| 74245/75824 [00:01<00:00, 61822.00it/s]100%|| 75824/75824 [00:01<00:00, 60650.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12401/75824 [00:00<00:00, 124005.39it/s] 30%|       | 22659/75824 [00:00<00:00, 116554.15it/s] 37%|      | 28330/75824 [00:00<00:00, 81083.20it/s]  54%|    | 40657/75824 [00:00<00:00, 90358.80it/s] 68%|   | 51873/75824 [00:00<00:00, 95953.53it/s] 84%| | 63879/75824 [00:00<00:00, 102102.52it/s]100%|| 75824/75824 [00:00<00:00, 105327.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11526/75824 [00:00<00:00, 115254.34it/s] 27%|       | 20285/75824 [00:00<00:00, 103997.98it/s] 39%|      | 29934/75824 [00:00<00:00, 101473.84it/s] 48%|     | 36288/75824 [00:00<00:00, 78142.32it/s]  64%|   | 48588/75824 [00:00<00:00, 87740.86it/s] 80%|  | 60929/75824 [00:00<00:00, 96070.93it/s] 96%|| 72884/75824 [00:00<00:00, 102085.14it/s]100%|| 75824/75824 [00:00<00:00, 100774.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10870/75824 [00:00<00:00, 108699.84it/s] 22%|       | 17009/75824 [00:00<00:00, 87662.08it/s]  39%|      | 29291/75824 [00:00<00:00, 95896.17it/s] 55%|    | 41748/75824 [00:00<00:00, 103009.43it/s] 72%|  | 54311/75824 [00:00<00:00, 108889.16it/s] 88%| | 66791/75824 [00:00<00:00, 113218.12it/s]100%|| 75824/75824 [00:00<00:00, 107014.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6219/75824 [00:00<00:01, 62184.72it/s] 16%|        | 12445/75824 [00:00<00:01, 61019.48it/s] 24%|       | 17978/75824 [00:00<00:00, 58053.54it/s] 30%|       | 22889/75824 [00:00<00:00, 55044.68it/s] 39%|      | 29676/75824 [00:00<00:00, 58352.07it/s] 55%|    | 42061/75824 [00:00<00:00, 69355.52it/s] 66%|   | 50028/75824 [00:00<00:00, 72157.89it/s] 82%| | 62230/75824 [00:00<00:00, 82239.30it/s] 98%|| 74069/75824 [00:00<00:00, 90532.09it/s]100%|| 75824/75824 [00:00<00:00, 81767.76it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12362/75824 [00:00<00:00, 123616.58it/s] 33%|      | 24674/75824 [00:00<00:00, 123464.30it/s] 48%|     | 36315/75824 [00:00<00:00, 119833.68it/s] 58%|    | 44082/75824 [00:00<00:00, 91240.28it/s]  75%|  | 56567/75824 [00:00<00:00, 99256.15it/s] 90%| | 68243/75824 [00:00<00:00, 103929.73it/s]100%|| 75824/75824 [00:00<00:00, 108829.55it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9190/75824 [00:00<00:00, 91897.68it/s] 27%|       | 20680/75824 [00:00<00:00, 97768.92it/s] 43%|     | 32455/75824 [00:00<00:00, 103012.86it/s] 58%|    | 43946/75824 [00:00<00:00, 106312.60it/s] 73%|  | 55444/75824 [00:00<00:00, 108771.44it/s] 88%| | 66552/75824 [00:00<00:00, 109453.44it/s]100%|| 75824/75824 [00:00<00:00, 103023.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6091/75824 [00:00<00:01, 60907.44it/s] 16%|        | 12168/75824 [00:00<00:01, 60864.68it/s] 25%|       | 19147/75824 [00:00<00:00, 63292.08it/s] 34%|      | 25812/75824 [00:00<00:00, 64262.43it/s] 48%|     | 36215/75824 [00:00<00:00, 72586.37it/s] 61%|    | 46307/75824 [00:00<00:00, 79261.18it/s] 77%|  | 58231/75824 [00:00<00:00, 88124.12it/s] 90%| | 68161/75824 [00:00<00:00, 91203.42it/s]100%|| 75824/75824 [00:01<00:00, 73687.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8771/75824 [00:00<00:00, 87707.78it/s] 25%|       | 18959/75824 [00:00<00:00, 91526.14it/s] 38%|      | 29010/75824 [00:00<00:00, 94046.79it/s] 52%|    | 39618/75824 [00:00<00:00, 97358.82it/s] 64%|   | 48369/75824 [00:00<00:00, 94178.31it/s] 77%|  | 58337/75824 [00:00<00:00, 93789.95it/s] 88%| | 66732/75824 [00:00<00:00, 86214.37it/s] 99%|| 74785/75824 [00:00<00:00, 79245.73it/s]100%|| 75824/75824 [00:00<00:00, 88937.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11768/75824 [00:00<00:00, 117672.82it/s] 31%|      | 23726/75824 [00:00<00:00, 118236.75it/s] 46%|     | 34940/75824 [00:00<00:00, 116337.80it/s] 62%|   | 46672/75824 [00:00<00:00, 116628.11it/s] 77%|  | 58638/75824 [00:00<00:00, 117520.54it/s] 90%| | 68418/75824 [00:00<00:00, 83520.64it/s] 100%|| 75824/75824 [00:00<00:00, 89023.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6778/75824 [00:00<00:01, 65455.27it/s] 17%|        | 12994/75824 [00:00<00:00, 64429.55it/s] 27%|       | 20726/75824 [00:00<00:00, 67820.75it/s] 42%|     | 31531/75824 [00:00<00:00, 76348.38it/s] 56%|    | 42520/75824 [00:00<00:00, 84042.93it/s] 72%|  | 54707/75824 [00:00<00:00, 92671.37it/s] 86%| | 65134/75824 [00:00<00:00, 95868.55it/s] 98%|| 74662/75824 [00:00<00:00, 95690.77it/s]100%|| 75824/75824 [00:00<00:00, 93239.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10859/75824 [00:00<00:00, 108581.30it/s] 29%|       | 22127/75824 [00:00<00:00, 109776.92it/s] 44%|     | 33432/75824 [00:00<00:00, 110737.63it/s] 60%|    | 45281/75824 [00:00<00:00, 112954.19it/s] 76%|  | 57597/75824 [00:00<00:00, 115831.11it/s] 92%|| 69766/75824 [00:00<00:00, 117527.32it/s]100%|| 75824/75824 [00:00<00:00, 115870.02it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11352/75824 [00:00<00:00, 103262.10it/s] 26%|       | 19796/75824 [00:00<00:00, 95481.41it/s]  41%|     | 31443/75824 [00:00<00:00, 100937.72it/s] 59%|    | 44997/75824 [00:00<00:00, 109307.29it/s] 75%|  | 56697/75824 [00:00<00:00, 111505.71it/s] 88%| | 67037/75824 [00:00<00:00, 108940.21it/s]100%|| 75824/75824 [00:00<00:00, 109654.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11890/75824 [00:00<00:00, 118893.03it/s] 32%|      | 24107/75824 [00:00<00:00, 119855.19it/s] 47%|     | 35763/75824 [00:00<00:00, 118847.10it/s] 63%|   | 48044/75824 [00:00<00:00, 120008.21it/s] 79%|  | 60116/75824 [00:00<00:00, 120218.07it/s] 95%|| 72266/75824 [00:00<00:00, 120599.58it/s]100%|| 75824/75824 [00:00<00:00, 120291.21it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11927/75824 [00:00<00:00, 119261.87it/s] 32%|      | 23967/75824 [00:00<00:00, 119598.36it/s] 47%|     | 35524/75824 [00:00<00:00, 118358.01it/s] 63%|   | 47726/75824 [00:00<00:00, 119433.19it/s] 79%|  | 59695/75824 [00:00<00:00, 119507.76it/s] 94%|| 71548/75824 [00:00<00:00, 119210.89it/s]100%|| 75824/75824 [00:00<00:00, 119147.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7913/75824 [00:00<00:00, 76367.64it/s] 25%|       | 19143/75824 [00:00<00:00, 84474.86it/s] 39%|      | 29706/75824 [00:00<00:00, 89873.60it/s] 55%|    | 41935/75824 [00:00<00:00, 97637.64it/s] 71%|   | 53471/75824 [00:00<00:00, 102353.70it/s] 87%| | 65809/75824 [00:00<00:00, 107868.52it/s]100%|| 75824/75824 [00:00<00:00, 110206.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7217/75824 [00:00<00:00, 72168.18it/s] 19%|        | 14100/75824 [00:00<00:00, 71131.76it/s] 27%|       | 20188/75824 [00:00<00:00, 67710.14it/s] 39%|      | 29619/75824 [00:00<00:00, 73968.14it/s] 47%|     | 35481/75824 [00:00<00:00, 43015.03it/s] 62%|   | 46718/75824 [00:00<00:00, 52789.30it/s] 78%|  | 59071/75824 [00:00<00:00, 63739.42it/s] 94%|| 71483/75824 [00:00<00:00, 74630.74it/s]100%|| 75824/75824 [00:01<00:00, 74436.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7196/75824 [00:00<00:00, 70313.34it/s] 25%|       | 19323/75824 [00:00<00:00, 80454.97it/s] 42%|     | 31611/75824 [00:00<00:00, 89750.79it/s] 57%|    | 43134/75824 [00:00<00:00, 96126.20it/s] 73%|  | 55221/75824 [00:00<00:00, 102415.84it/s] 89%| | 67193/75824 [00:00<00:00, 107057.25it/s]100%|| 75824/75824 [00:00<00:00, 112064.24it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  5%|         | 3881/75824 [00:00<00:01, 38807.26it/s] 20%|        | 14994/75824 [00:00<00:01, 48221.89it/s] 35%|      | 26848/75824 [00:00<00:00, 58661.08it/s] 44%|     | 33309/75824 [00:00<00:00, 51537.01it/s] 55%|    | 41630/75824 [00:00<00:00, 58180.27it/s] 63%|   | 48136/75824 [00:00<00:00, 56211.47it/s] 74%|  | 56011/75824 [00:00<00:00, 61490.08it/s] 90%| | 67933/75824 [00:00<00:00, 71939.92it/s]100%|| 75824/75824 [00:00<00:00, 79445.60it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7354/75824 [00:00<00:00, 73533.23it/s] 14%|        | 10607/75824 [00:00<00:01, 51026.55it/s] 19%|        | 14404/75824 [00:00<00:01, 46253.40it/s] 23%|       | 17250/75824 [00:00<00:01, 35932.56it/s] 29%|       | 21649/75824 [00:00<00:01, 38021.24it/s] 34%|      | 25524/75824 [00:00<00:01, 37950.65it/s] 50%|     | 37552/75824 [00:00<00:00, 47757.15it/s] 57%|    | 43527/75824 [00:00<00:00, 44939.49it/s] 64%|   | 48895/75824 [00:00<00:00, 45432.40it/s] 72%|  | 54802/75824 [00:01<00:00, 48296.38it/s] 81%|  | 61046/75824 [00:01<00:00, 51817.18it/s] 88%| | 66635/75824 [00:01<00:00, 50373.14it/s] 95%|| 71966/75824 [00:01<00:00, 50138.78it/s]100%|| 75824/75824 [00:01<00:00, 51055.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11942/75824 [00:00<00:00, 119415.84it/s] 32%|      | 24224/75824 [00:00<00:00, 120413.77it/s] 48%|     | 36615/75824 [00:00<00:00, 121440.42it/s] 65%|   | 49094/75824 [00:00<00:00, 122425.86it/s] 81%|  | 61588/75824 [00:00<00:00, 123166.67it/s] 98%|| 73993/75824 [00:00<00:00, 123427.66it/s]100%|| 75824/75824 [00:00<00:00, 123303.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10728/75824 [00:00<00:00, 107276.52it/s] 29%|       | 21878/75824 [00:00<00:00, 108508.71it/s] 43%|     | 32631/75824 [00:00<00:00, 108212.95it/s] 59%|    | 44691/75824 [00:00<00:00, 111652.31it/s] 74%|  | 56173/75824 [00:00<00:00, 112583.04it/s] 90%| | 68175/75824 [00:00<00:00, 114713.20it/s]100%|| 75824/75824 [00:00<00:00, 114513.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12289/75824 [00:00<00:00, 122881.62it/s] 31%|      | 23857/75824 [00:00<00:00, 117688.26it/s] 39%|      | 29813/75824 [00:00<00:00, 91033.08it/s]  50%|     | 38012/75824 [00:00<00:00, 88116.56it/s] 64%|   | 48296/75824 [00:00<00:00, 92070.61it/s] 79%|  | 60180/75824 [00:00<00:00, 98742.74it/s] 96%|| 72582/75824 [00:00<00:00, 105173.07it/s]100%|| 75824/75824 [00:00<00:00, 103225.71it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6581/75824 [00:00<00:01, 58452.71it/s] 12%|        | 9428/75824 [00:00<00:01, 44418.80it/s] 20%|        | 15402/75824 [00:00<00:01, 48120.34it/s] 27%|       | 20771/75824 [00:00<00:01, 49570.05it/s] 35%|      | 26377/75824 [00:00<00:00, 49711.07it/s] 46%|     | 35236/75824 [00:00<00:00, 57247.79it/s] 62%|   | 47279/75824 [00:00<00:00, 67940.28it/s] 74%|  | 55912/75824 [00:00<00:00, 72577.63it/s] 84%| | 63991/75824 [00:00<00:00, 74859.40it/s] 96%|| 73132/75824 [00:01<00:00, 79157.45it/s]100%|| 75824/75824 [00:01<00:00, 72153.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6778/75824 [00:00<00:01, 66401.16it/s] 17%|        | 12741/75824 [00:00<00:00, 64212.60it/s] 21%|       | 16206/75824 [00:00<00:01, 51126.23it/s] 37%|      | 28131/75824 [00:00<00:00, 61699.88it/s] 53%|    | 40414/75824 [00:00<00:00, 72527.58it/s] 69%|   | 52127/75824 [00:00<00:00, 81880.87it/s] 81%|  | 61094/75824 [00:00<00:00, 79192.82it/s] 94%|| 71586/75824 [00:00<00:00, 85480.07it/s]100%|| 75824/75824 [00:00<00:00, 85644.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7016/75824 [00:00<00:01, 65210.26it/s] 19%|        | 14062/75824 [00:00<00:00, 66700.41it/s] 33%|      | 25000/75824 [00:00<00:00, 74901.29it/s] 43%|     | 32960/75824 [00:00<00:00, 76251.32it/s] 57%|    | 43266/75824 [00:00<00:00, 82704.42it/s] 69%|   | 52319/75824 [00:00<00:00, 84904.29it/s] 83%| | 62686/75824 [00:00<00:00, 87066.72it/s] 97%|| 73218/75824 [00:00<00:00, 91837.66it/s]100%|| 75824/75824 [00:00<00:00, 89624.79it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8566/75824 [00:00<00:00, 85653.55it/s] 24%|       | 18050/75824 [00:00<00:00, 86803.82it/s] 34%|      | 25807/75824 [00:00<00:00, 83810.18it/s] 47%|     | 35345/75824 [00:00<00:00, 86973.94it/s] 57%|    | 43189/75824 [00:00<00:00, 84224.84it/s] 72%|  | 54948/75824 [00:00<00:00, 92059.75it/s] 86%| | 64924/75824 [00:00<00:00, 94239.97it/s] 97%|| 73834/75824 [00:00<00:00, 92013.10it/s]100%|| 75824/75824 [00:00<00:00, 88178.60it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9993/75824 [00:00<00:00, 99927.71it/s] 29%|       | 21874/75824 [00:00<00:00, 104930.61it/s] 45%|     | 33884/75824 [00:00<00:00, 109062.62it/s] 59%|    | 44615/75824 [00:00<00:00, 108528.60it/s] 75%|  | 56576/75824 [00:00<00:00, 111630.62it/s] 90%| | 68560/75824 [00:00<00:00, 113971.42it/s]100%|| 75824/75824 [00:00<00:00, 115055.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11358/75824 [00:00<00:00, 113570.63it/s] 28%|       | 20898/75824 [00:00<00:00, 107431.02it/s] 43%|     | 32743/75824 [00:00<00:00, 110514.86it/s] 59%|    | 44478/75824 [00:00<00:00, 112477.72it/s] 74%|  | 56241/75824 [00:00<00:00, 113973.59it/s] 90%| | 68139/75824 [00:00<00:00, 115430.10it/s]100%|| 75824/75824 [00:00<00:00, 114503.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12409/75824 [00:00<00:00, 124087.46it/s] 33%|      | 24719/75824 [00:00<00:00, 123787.46it/s] 49%|     | 36858/75824 [00:00<00:00, 123058.01it/s] 65%|   | 49443/75824 [00:00<00:00, 123880.20it/s] 81%| | 61783/75824 [00:00<00:00, 123735.69it/s] 95%|| 72073/75824 [00:00<00:00, 114385.55it/s]100%|| 75824/75824 [00:00<00:00, 117606.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6766/75824 [00:00<00:01, 63618.02it/s] 16%|        | 11879/75824 [00:00<00:01, 59274.01it/s] 22%|       | 16654/75824 [00:00<00:01, 55093.17it/s] 29%|       | 22003/75824 [00:00<00:00, 54514.19it/s] 40%|      | 30402/75824 [00:00<00:00, 60928.53it/s] 52%|    | 39249/75824 [00:00<00:00, 66725.03it/s] 62%|   | 46836/75824 [00:00<00:00, 69226.70it/s] 78%|  | 58831/75824 [00:00<00:00, 79284.39it/s] 92%|| 69804/75824 [00:00<00:00, 86481.46it/s]100%|| 75824/75824 [00:00<00:00, 78800.97it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10932/75824 [00:00<00:00, 109317.24it/s] 20%|        | 15538/75824 [00:00<00:00, 77418.06it/s]  33%|      | 25246/75824 [00:00<00:00, 82426.25it/s] 50%|     | 37702/75824 [00:00<00:00, 91733.91it/s] 66%|   | 50158/75824 [00:00<00:00, 99608.21it/s] 83%| | 62774/75824 [00:00<00:00, 106319.83it/s] 99%|| 75328/75824 [00:00<00:00, 111436.38it/s]100%|| 75824/75824 [00:00<00:00, 107226.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7797/75824 [00:00<00:00, 77963.94it/s] 24%|       | 18151/75824 [00:00<00:00, 84203.68it/s] 33%|      | 24646/75824 [00:00<00:00, 77326.71it/s] 41%|      | 30712/75824 [00:00<00:00, 70356.43it/s] 49%|     | 37241/75824 [00:00<00:00, 67893.33it/s] 58%|    | 43782/75824 [00:00<00:00, 67127.25it/s] 71%|   | 53617/75824 [00:00<00:00, 73487.38it/s] 80%|  | 60607/75824 [00:00<00:00, 70891.31it/s] 96%|| 72958/75824 [00:00<00:00, 81278.99it/s]100%|| 75824/75824 [00:00<00:00, 80448.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10532/75824 [00:00<00:00, 100296.77it/s] 25%|       | 18927/75824 [00:00<00:00, 94760.46it/s]  41%|      | 31152/75824 [00:00<00:00, 101614.69it/s] 57%|    | 43503/75824 [00:00<00:00, 107321.14it/s] 74%|  | 55742/75824 [00:00<00:00, 111435.82it/s] 90%| | 67920/75824 [00:00<00:00, 114348.69it/s]100%|| 75824/75824 [00:00<00:00, 112745.86it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12071/75824 [00:00<00:00, 120701.48it/s] 31%|       | 23397/75824 [00:00<00:00, 118365.82it/s] 46%|     | 34911/75824 [00:00<00:00, 117378.34it/s] 56%|    | 42518/75824 [00:00<00:00, 86261.99it/s]  71%|  | 54047/75824 [00:00<00:00, 93309.20it/s] 86%| | 65166/75824 [00:00<00:00, 98037.77it/s]100%|| 75824/75824 [00:00<00:00, 102622.71it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7632/75824 [00:00<00:01, 64566.28it/s] 21%|        | 15653/75824 [00:00<00:00, 68578.41it/s] 27%|       | 20742/75824 [00:00<00:00, 62101.41it/s] 37%|      | 28373/75824 [00:00<00:00, 65775.24it/s] 53%|    | 40552/75824 [00:00<00:00, 76302.45it/s] 63%|   | 47847/75824 [00:00<00:00, 64409.64it/s] 72%|  | 54371/75824 [00:00<00:00, 48074.18it/s] 80%|  | 60406/75824 [00:00<00:00, 50041.84it/s] 87%| | 65897/75824 [00:01<00:00, 49215.89it/s] 94%|| 71162/75824 [00:01<00:00, 49383.72it/s]100%|| 75824/75824 [00:01<00:00, 60380.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6562/75824 [00:00<00:01, 65610.52it/s] 13%|        | 9595/75824 [00:00<00:01, 48404.13it/s] 17%|        | 12851/75824 [00:00<00:01, 42236.38it/s] 23%|       | 17658/75824 [00:00<00:01, 43831.05it/s] 28%|       | 20901/75824 [00:00<00:01, 39339.21it/s] 36%|      | 27495/75824 [00:00<00:01, 44755.56it/s] 44%|     | 33066/75824 [00:00<00:00, 46045.13it/s] 49%|     | 37511/75824 [00:00<00:00, 42098.76it/s] 58%|    | 44016/75824 [00:00<00:00, 47082.14it/s] 64%|   | 48882/75824 [00:01<00:00, 44798.25it/s] 72%|  | 54547/75824 [00:01<00:00, 46425.94it/s] 80%|  | 60985/75824 [00:01<00:00, 50663.71it/s] 89%| | 67302/75824 [00:01<00:00, 53861.97it/s]100%|| 75824/75824 [00:01<00:00, 51807.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10420/75824 [00:00<00:00, 104192.40it/s] 22%|       | 16833/75824 [00:00<00:00, 87746.49it/s]  31%|       | 23547/75824 [00:00<00:00, 80347.65it/s] 46%|     | 34895/75824 [00:00<00:00, 88060.42it/s] 62%|   | 47092/75824 [00:00<00:00, 96072.39it/s] 78%|  | 58798/75824 [00:00<00:00, 101533.46it/s] 94%|| 71227/75824 [00:00<00:00, 107432.62it/s]100%|| 75824/75824 [00:00<00:00, 101042.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8771/75824 [00:00<00:00, 79302.95it/s] 27%|       | 20409/75824 [00:00<00:00, 87682.71it/s] 43%|     | 32771/75824 [00:00<00:00, 96058.83it/s] 59%|    | 44994/75824 [00:00<00:00, 101335.89it/s] 75%|  | 57126/75824 [00:00<00:00, 106603.12it/s] 92%|| 69478/75824 [00:00<00:00, 111168.53it/s]100%|| 75824/75824 [00:00<00:00, 113621.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12272/75824 [00:00<00:00, 122712.22it/s] 32%|      | 24405/75824 [00:00<00:00, 122291.65it/s] 47%|     | 35779/75824 [00:00<00:00, 119591.45it/s] 62%|   | 46967/75824 [00:00<00:00, 117168.43it/s] 74%|  | 55758/75824 [00:00<00:00, 90457.96it/s]  88%| | 67041/75824 [00:00<00:00, 96179.01it/s]100%|| 75824/75824 [00:00<00:00, 99378.54it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 10997/75824 [00:00<00:00, 109969.84it/s] 30%|       | 22371/75824 [00:00<00:00, 111073.25it/s] 42%|     | 31505/75824 [00:00<00:00, 104309.89it/s] 55%|    | 41970/75824 [00:00<00:00, 104410.01it/s] 71%|   | 53501/75824 [00:00<00:00, 107455.27it/s] 86%| | 65349/75824 [00:00<00:00, 110538.66it/s]100%|| 75824/75824 [00:00<00:00, 110250.19it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5584/75824 [00:00<00:01, 55839.65it/s] 20%|        | 15249/75824 [00:00<00:00, 63939.04it/s] 34%|      | 25657/75824 [00:00<00:00, 72303.92it/s] 47%|     | 35267/75824 [00:00<00:00, 78105.08it/s] 62%|   | 47058/75824 [00:00<00:00, 86905.52it/s] 78%|  | 58995/75824 [00:00<00:00, 92897.60it/s] 93%|| 70889/75824 [00:00<00:00, 99428.66it/s]100%|| 75824/75824 [00:00<00:00, 101129.27it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7202/75824 [00:00<00:00, 72019.21it/s] 24%|       | 17862/75824 [00:00<00:00, 79249.51it/s] 33%|      | 24723/75824 [00:00<00:00, 75722.06it/s] 40%|      | 30013/75824 [00:00<00:00, 59260.29it/s] 47%|     | 35586/75824 [00:00<00:00, 58152.75it/s] 54%|    | 40676/75824 [00:00<00:00, 53883.05it/s] 62%|   | 46797/75824 [00:00<00:00, 55888.00it/s] 69%|   | 52552/75824 [00:00<00:00, 56374.04it/s] 76%|  | 57986/75824 [00:00<00:00, 51934.18it/s] 85%| | 64458/75824 [00:01<00:00, 55205.71it/s] 92%|| 69984/75824 [00:01<00:00, 47511.09it/s]100%|| 75651/75824 [00:01<00:00, 49931.30it/s]100%|| 75824/75824 [00:01<00:00, 56483.55it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6411/75824 [00:00<00:01, 59790.46it/s] 18%|        | 13494/75824 [00:00<00:00, 62721.85it/s] 26%|       | 19648/75824 [00:00<00:00, 62362.31it/s] 33%|      | 24848/75824 [00:00<00:00, 58843.60it/s] 41%|      | 31029/75824 [00:00<00:00, 59702.34it/s] 48%|     | 36087/75824 [00:00<00:00, 56637.48it/s] 55%|    | 42073/75824 [00:00<00:00, 57566.11it/s] 62%|   | 47386/75824 [00:00<00:00, 53378.20it/s] 69%|   | 52474/75824 [00:00<00:00, 45088.80it/s] 84%| | 63558/75824 [00:01<00:00, 54554.26it/s] 94%|| 71132/75824 [00:01<00:00, 59550.83it/s]100%|| 75824/75824 [00:01<00:00, 62098.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6139/75824 [00:00<00:01, 61384.50it/s] 13%|        | 10015/75824 [00:00<00:01, 52234.09it/s] 32%|      | 23926/75824 [00:00<00:00, 64276.22it/s] 56%|    | 42690/75824 [00:00<00:00, 80068.06it/s] 83%| | 62989/75824 [00:00<00:00, 97842.66it/s]100%|| 75824/75824 [00:00<00:00, 134446.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19450/75824 [00:00<00:00, 194499.72it/s] 53%|    | 40124/75824 [00:00<00:00, 198015.56it/s] 79%|  | 60027/75824 [00:00<00:00, 198317.31it/s]100%|| 75824/75824 [00:00<00:00, 203166.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12872/75824 [00:00<00:00, 128714.60it/s] 31%|      | 23844/75824 [00:00<00:00, 122357.27it/s] 53%|    | 39891/75824 [00:00<00:00, 131742.96it/s] 71%|   | 53463/75824 [00:00<00:00, 132908.72it/s] 93%|| 70840/75824 [00:00<00:00, 142994.64it/s]100%|| 75824/75824 [00:00<00:00, 144199.21it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19968/75824 [00:00<00:00, 199675.91it/s] 50%|     | 37953/75824 [00:00<00:00, 193283.63it/s] 67%|   | 50964/75824 [00:00<00:00, 168706.83it/s] 91%| | 68829/75824 [00:00<00:00, 171571.17it/s]100%|| 75824/75824 [00:00<00:00, 174804.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13745/75824 [00:00<00:00, 137438.99it/s] 34%|      | 25626/75824 [00:00<00:00, 131262.42it/s] 59%|    | 44812/75824 [00:00<00:00, 145000.67it/s] 84%| | 63946/75824 [00:00<00:00, 156359.65it/s]100%|| 75824/75824 [00:00<00:00, 165477.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16424/75824 [00:00<00:00, 164235.07it/s] 50%|     | 37551/75824 [00:00<00:00, 175987.13it/s] 79%|  | 60072/75824 [00:00<00:00, 188334.10it/s] 98%|| 74046/75824 [00:00<00:00, 170540.71it/s]100%|| 75824/75824 [00:00<00:00, 183005.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 13007/75824 [00:00<00:00, 130064.23it/s] 37%|      | 27805/75824 [00:00<00:00, 134964.48it/s] 61%|    | 45949/75824 [00:00<00:00, 146198.34it/s] 82%| | 62068/75824 [00:00<00:00, 150394.27it/s]100%|| 75824/75824 [00:00<00:00, 160403.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12247/75824 [00:00<00:00, 122466.32it/s] 43%|     | 32427/75824 [00:00<00:00, 138841.07it/s] 54%|    | 41053/75824 [00:00<00:00, 90182.18it/s]  75%|  | 56537/75824 [00:00<00:00, 103096.02it/s] 90%| | 68214/75824 [00:00<00:00, 105221.32it/s]100%|| 75824/75824 [00:00<00:00, 116371.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 14816/75824 [00:00<00:00, 148158.38it/s] 28%|       | 21387/75824 [00:00<00:00, 105573.38it/s] 42%|     | 31479/75824 [00:00<00:00, 104132.11it/s] 56%|    | 42708/75824 [00:00<00:00, 106449.60it/s] 67%|   | 50650/75824 [00:00<00:00, 80423.31it/s]  81%|  | 61297/75824 [00:00<00:00, 86792.31it/s] 99%|| 75439/75824 [00:00<00:00, 98167.75it/s]100%|| 75824/75824 [00:00<00:00, 99607.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21587/75824 [00:00<00:00, 215861.46it/s] 54%|    | 40978/75824 [00:00<00:00, 208770.25it/s] 79%|  | 59886/75824 [00:00<00:00, 202442.89it/s]100%|| 75824/75824 [00:00<00:00, 196025.79it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 31%|       | 23256/75824 [00:00<00:00, 232553.01it/s] 62%|   | 47197/75824 [00:00<00:00, 234566.93it/s] 92%|| 69554/75824 [00:00<00:00, 231155.30it/s]100%|| 75824/75824 [00:00<00:00, 231433.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 31%|      | 23744/75824 [00:00<00:00, 237437.40it/s] 62%|   | 47315/75824 [00:00<00:00, 236916.42it/s] 92%|| 70020/75824 [00:00<00:00, 233865.96it/s]100%|| 75824/75824 [00:00<00:00, 233327.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 31%|       | 23449/75824 [00:00<00:00, 234484.07it/s] 62%|   | 46654/75824 [00:00<00:00, 233748.07it/s] 92%|| 69638/75824 [00:00<00:00, 232561.50it/s]100%|| 75824/75824 [00:00<00:00, 231541.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 31%|       | 23361/75824 [00:00<00:00, 233601.87it/s] 52%|    | 39244/75824 [00:00<00:00, 204690.88it/s] 65%|   | 48915/75824 [00:00<00:00, 148938.78it/s] 90%| | 68436/75824 [00:00<00:00, 160340.53it/s]100%|| 75824/75824 [00:00<00:00, 167334.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13694/75824 [00:00<00:00, 136933.27it/s] 43%|     | 32439/75824 [00:00<00:00, 148976.31it/s] 65%|   | 49191/75824 [00:00<00:00, 154093.18it/s] 81%|  | 61385/75824 [00:00<00:00, 142796.06it/s] 98%|| 74147/75824 [00:00<00:00, 137874.27it/s]100%|| 75824/75824 [00:00<00:00, 148300.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 15041/75824 [00:00<00:00, 150400.10it/s] 41%|      | 31232/75824 [00:00<00:00, 153675.46it/s] 64%|   | 48221/75824 [00:00<00:00, 158202.98it/s] 87%| | 65919/75824 [00:00<00:00, 163401.64it/s]100%|| 75824/75824 [00:00<00:00, 166229.56it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11474/75824 [00:00<00:00, 114737.65it/s] 42%|     | 31575/75824 [00:00<00:00, 131693.25it/s] 67%|   | 50862/75824 [00:00<00:00, 145542.29it/s] 93%|| 70242/75824 [00:00<00:00, 157286.77it/s]100%|| 75824/75824 [00:00<00:00, 176332.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19168/75824 [00:00<00:00, 191678.35it/s] 47%|     | 35901/75824 [00:00<00:00, 183659.42it/s] 65%|   | 49298/75824 [00:00<00:00, 165267.30it/s] 91%|| 69278/75824 [00:00<00:00, 174303.26it/s]100%|| 75824/75824 [00:00<00:00, 175201.78it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19761/75824 [00:00<00:00, 197601.24it/s] 52%|    | 39449/75824 [00:00<00:00, 197381.54it/s] 78%|  | 59229/75824 [00:00<00:00, 197505.96it/s]100%|| 75824/75824 [00:00<00:00, 197039.17it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12281/75824 [00:00<00:00, 122803.09it/s] 34%|      | 25968/75824 [00:00<00:00, 126709.01it/s] 60%|    | 45251/75824 [00:00<00:00, 141236.93it/s] 88%| | 66735/75824 [00:00<00:00, 157414.85it/s]100%|| 75824/75824 [00:00<00:00, 172091.89it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|        | 15941/75824 [00:00<00:00, 159401.79it/s] 45%|     | 33942/75824 [00:00<00:00, 165069.92it/s] 69%|   | 52136/75824 [00:00<00:00, 169791.29it/s] 93%|| 70360/75824 [00:00<00:00, 173343.28it/s]100%|| 75824/75824 [00:00<00:00, 169502.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 30%|       | 23046/75824 [00:00<00:00, 230456.92it/s] 61%|    | 46383/75824 [00:00<00:00, 231320.95it/s] 92%|| 69695/75824 [00:00<00:00, 231855.17it/s]100%|| 75824/75824 [00:00<00:00, 232597.99it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13846/75824 [00:00<00:00, 138456.50it/s] 45%|     | 33798/75824 [00:00<00:00, 152451.87it/s] 56%|    | 42691/75824 [00:00<00:00, 114746.04it/s] 86%| | 64937/75824 [00:00<00:00, 134245.97it/s]100%|| 75824/75824 [00:00<00:00, 161273.49it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|       | 21691/75824 [00:00<00:00, 216909.17it/s] 47%|     | 35862/75824 [00:00<00:00, 187116.97it/s] 73%|  | 55001/75824 [00:00<00:00, 188377.84it/s] 98%|| 74632/75824 [00:00<00:00, 190686.76it/s]100%|| 75824/75824 [00:00<00:00, 185097.57it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 14867/75824 [00:00<00:00, 144093.09it/s] 25%|       | 19190/75824 [00:00<00:00, 74418.43it/s]  35%|      | 26829/75824 [00:00<00:00, 74998.26it/s] 45%|     | 34437/75824 [00:00<00:00, 75319.45it/s] 59%|    | 44713/75824 [00:00<00:00, 81877.48it/s] 68%|   | 51914/75824 [00:00<00:00, 78521.11it/s] 78%|  | 59105/75824 [00:00<00:00, 60706.25it/s] 91%| | 69177/75824 [00:00<00:00, 68919.30it/s]100%|| 75824/75824 [00:01<00:00, 71821.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 14793/75824 [00:00<00:00, 147928.38it/s] 45%|     | 34435/75824 [00:00<00:00, 159759.13it/s] 60%|    | 45451/75824 [00:00<00:00, 140273.40it/s] 73%|  | 55027/75824 [00:00<00:00, 92341.32it/s]  94%|| 71037/75824 [00:00<00:00, 105769.42it/s]100%|| 75824/75824 [00:00<00:00, 120751.91it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19404/75824 [00:00<00:00, 194031.86it/s] 52%|    | 39364/75824 [00:00<00:00, 195665.76it/s] 75%|  | 56975/75824 [00:00<00:00, 189354.42it/s] 99%|| 74941/75824 [00:00<00:00, 186334.04it/s]100%|| 75824/75824 [00:00<00:00, 187208.08it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|        | 16079/75824 [00:00<00:00, 160781.72it/s] 49%|     | 37232/75824 [00:00<00:00, 173249.16it/s] 78%|  | 59392/75824 [00:00<00:00, 185383.08it/s]100%|| 75824/75824 [00:00<00:00, 199690.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12042/75824 [00:00<00:00, 120418.11it/s] 33%|      | 24684/75824 [00:00<00:00, 122155.64it/s] 49%|     | 37349/75824 [00:00<00:00, 123468.06it/s] 63%|   | 47402/75824 [00:00<00:00, 115554.29it/s] 76%|  | 57930/75824 [00:00<00:00, 112264.38it/s] 89%| | 67229/75824 [00:00<00:00, 88351.56it/s] 100%|| 75509/75824 [00:00<00:00, 85308.61it/s]100%|| 75824/75824 [00:00<00:00, 99111.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20153/75824 [00:00<00:00, 201523.47it/s] 54%|    | 40767/75824 [00:00<00:00, 202884.20it/s] 81%|  | 61200/75824 [00:00<00:00, 203315.70it/s]100%|| 75824/75824 [00:00<00:00, 194051.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19358/75824 [00:00<00:00, 192253.21it/s] 51%|    | 38976/75824 [00:00<00:00, 193412.92it/s] 77%|  | 58044/75824 [00:00<00:00, 192584.08it/s]100%|| 75824/75824 [00:00<00:00, 191958.00it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21228/75824 [00:00<00:00, 212273.62it/s] 56%|    | 42678/75824 [00:00<00:00, 212935.37it/s] 83%| | 62795/75824 [00:00<00:00, 209261.16it/s]100%|| 75824/75824 [00:00<00:00, 210985.44it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20501/75824 [00:00<00:00, 205006.77it/s] 54%|    | 40939/75824 [00:00<00:00, 204817.66it/s] 76%|  | 57347/75824 [00:00<00:00, 190615.06it/s] 92%|| 69575/75824 [00:00<00:00, 162222.58it/s]100%|| 75824/75824 [00:00<00:00, 169615.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 20031/75824 [00:00<00:00, 200303.98it/s] 52%|    | 39741/75824 [00:00<00:00, 199200.12it/s] 78%|  | 59194/75824 [00:00<00:00, 197773.61it/s]100%|| 75824/75824 [00:00<00:00, 194790.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18451/75824 [00:00<00:00, 184506.66it/s] 41%|      | 30757/75824 [00:00<00:00, 160467.19it/s] 64%|   | 48756/75824 [00:00<00:00, 165863.88it/s] 89%| | 67799/75824 [00:00<00:00, 172540.90it/s]100%|| 75824/75824 [00:00<00:00, 171548.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18047/75824 [00:00<00:00, 178224.05it/s] 49%|     | 37172/75824 [00:00<00:00, 181940.70it/s] 75%|  | 56676/75824 [00:00<00:00, 185679.71it/s]100%|| 75824/75824 [00:00<00:00, 192393.24it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14342/75824 [00:00<00:00, 143418.09it/s] 26%|       | 19544/75824 [00:00<00:00, 93914.41it/s]  37%|      | 28220/75824 [00:00<00:00, 91646.66it/s] 58%|    | 43670/75824 [00:00<00:00, 104386.52it/s] 74%|  | 56261/75824 [00:00<00:00, 110028.55it/s] 87%| | 66127/75824 [00:00<00:00, 105615.16it/s]100%|| 75824/75824 [00:00<00:00, 111278.02it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7724/75824 [00:00<00:00, 77236.39it/s] 17%|        | 13224/75824 [00:00<00:00, 64968.18it/s] 28%|       | 21001/75824 [00:00<00:00, 66092.07it/s] 33%|      | 25198/75824 [00:00<00:00, 55754.34it/s] 52%|    | 39387/75824 [00:00<00:00, 68168.82it/s] 69%|   | 52478/75824 [00:00<00:00, 79615.03it/s] 83%| | 62587/75824 [00:00<00:00, 83324.49it/s] 95%|| 71655/75824 [00:00<00:00, 83690.04it/s]100%|| 75824/75824 [00:00<00:00, 86878.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10543/75824 [00:00<00:00, 105428.84it/s] 32%|      | 24155/75824 [00:00<00:00, 113076.86it/s] 40%|      | 30453/75824 [00:00<00:00, 88307.92it/s]  62%|   | 46834/75824 [00:00<00:00, 101801.00it/s] 74%|  | 56243/75824 [00:00<00:00, 99357.68it/s] 100%|| 75824/75824 [00:00<00:00, 124350.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 13027/75824 [00:00<00:00, 130263.60it/s] 39%|      | 29718/75824 [00:00<00:00, 139447.84it/s] 66%|   | 49740/75824 [00:00<00:00, 153416.45it/s] 92%|| 70010/75824 [00:00<00:00, 165485.68it/s]100%|| 75824/75824 [00:00<00:00, 177027.14it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19259/75824 [00:00<00:00, 192581.46it/s] 52%|    | 39632/75824 [00:00<00:00, 195794.48it/s] 79%|  | 60058/75824 [00:00<00:00, 198258.62it/s]100%|| 75824/75824 [00:00<00:00, 204089.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18512/75824 [00:00<00:00, 185111.79it/s] 45%|     | 34284/75824 [00:00<00:00, 175943.50it/s] 71%|   | 53918/75824 [00:00<00:00, 181601.66it/s] 92%|| 69519/75824 [00:00<00:00, 173083.02it/s]100%|| 75824/75824 [00:00<00:00, 167941.20it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19868/75824 [00:00<00:00, 198672.61it/s] 48%|     | 36545/75824 [00:00<00:00, 187889.09it/s] 74%|  | 56211/75824 [00:00<00:00, 190435.44it/s] 93%|| 70508/75824 [00:00<00:00, 173182.91it/s]100%|| 75824/75824 [00:00<00:00, 172996.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|       | 17198/75824 [00:00<00:00, 171977.29it/s] 42%|     | 31800/75824 [00:00<00:00, 163269.17it/s] 64%|   | 48553/75824 [00:00<00:00, 164523.03it/s] 91%| | 68971/75824 [00:00<00:00, 174701.83it/s]100%|| 75824/75824 [00:00<00:00, 174966.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18440/75824 [00:00<00:00, 184395.34it/s] 50%|     | 38263/75824 [00:00<00:00, 188336.90it/s] 76%|  | 57907/75824 [00:00<00:00, 190694.03it/s] 99%|| 75319/75824 [00:00<00:00, 185396.95it/s]100%|| 75824/75824 [00:00<00:00, 188044.81it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16693/75824 [00:00<00:00, 166923.39it/s] 44%|     | 33169/75824 [00:00<00:00, 165787.54it/s] 66%|   | 50005/75824 [00:00<00:00, 166550.80it/s] 86%| | 65257/75824 [00:00<00:00, 162074.63it/s]100%|| 75824/75824 [00:00<00:00, 154932.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 13261/75824 [00:00<00:00, 132599.06it/s] 41%|      | 31008/75824 [00:00<00:00, 143481.38it/s] 66%|   | 50246/75824 [00:00<00:00, 155324.40it/s] 85%| | 64477/75824 [00:00<00:00, 151175.83it/s]100%|| 75824/75824 [00:00<00:00, 165260.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14413/75824 [00:00<00:00, 144125.33it/s] 37%|      | 27763/75824 [00:00<00:00, 140762.62it/s] 60%|    | 45695/75824 [00:00<00:00, 150466.99it/s] 83%| | 63032/75824 [00:00<00:00, 156675.83it/s]100%|| 75824/75824 [00:00<00:00, 158995.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16445/75824 [00:00<00:00, 164443.88it/s] 43%|     | 32885/75824 [00:00<00:00, 164426.76it/s] 58%|    | 43801/75824 [00:00<00:00, 142741.57it/s] 70%|   | 52946/75824 [00:00<00:00, 116205.76it/s] 81%| | 61779/75824 [00:00<00:00, 103867.61it/s] 93%|| 70459/75824 [00:00<00:00, 96765.84it/s] 100%|| 75824/75824 [00:00<00:00, 116467.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18590/75824 [00:00<00:00, 185894.86it/s] 48%|     | 36710/75824 [00:00<00:00, 184458.82it/s] 72%|  | 54742/75824 [00:00<00:00, 183195.15it/s] 96%|| 72792/75824 [00:00<00:00, 182376.14it/s]100%|| 75824/75824 [00:00<00:00, 182229.91it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|        | 16095/75824 [00:00<00:00, 160940.18it/s] 33%|      | 24725/75824 [00:00<00:00, 127782.32it/s] 52%|    | 39485/75824 [00:00<00:00, 133145.00it/s] 77%|  | 58434/75824 [00:00<00:00, 146185.22it/s]100%|| 75824/75824 [00:00<00:00, 155211.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18996/75824 [00:00<00:00, 189953.39it/s] 50%|     | 37926/75824 [00:00<00:00, 189755.18it/s] 69%|   | 52332/75824 [00:00<00:00, 173266.47it/s] 90%| | 67940/75824 [00:00<00:00, 167724.19it/s]100%|| 75824/75824 [00:00<00:00, 174014.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20419/75824 [00:00<00:00, 204185.81it/s] 54%|    | 40974/75824 [00:00<00:00, 204589.87it/s] 68%|   | 51429/75824 [00:00<00:00, 135138.42it/s] 94%|| 71358/75824 [00:00<00:00, 149583.71it/s]100%|| 75824/75824 [00:00<00:00, 160013.09it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9490/75824 [00:00<00:00, 94899.64it/s] 20%|        | 14944/75824 [00:00<00:00, 77657.64it/s] 39%|      | 29852/75824 [00:00<00:00, 90533.91it/s] 49%|     | 36823/75824 [00:00<00:00, 75876.90it/s] 60%|    | 45318/75824 [00:00<00:00, 78386.49it/s] 69%|   | 52439/75824 [00:00<00:00, 73498.07it/s] 91%|| 69229/75824 [00:00<00:00, 88409.93it/s]100%|| 75824/75824 [00:00<00:00, 92499.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6116/75824 [00:00<00:01, 60157.22it/s] 19%|        | 14435/75824 [00:00<00:00, 65605.72it/s] 24%|       | 18194/75824 [00:00<00:01, 47752.13it/s] 39%|      | 29721/75824 [00:00<00:00, 57931.65it/s] 52%|    | 39444/75824 [00:00<00:00, 65924.53it/s] 69%|   | 52061/75824 [00:00<00:00, 76946.88it/s] 80%|  | 60786/75824 [00:00<00:00, 74406.10it/s]100%|| 75824/75824 [00:00<00:00, 91296.71it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 20970/75824 [00:00<00:00, 209695.70it/s] 58%|    | 43874/75824 [00:00<00:00, 215144.29it/s] 85%| | 64605/75824 [00:00<00:00, 212731.34it/s]100%|| 75824/75824 [00:00<00:00, 214698.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21295/75824 [00:00<00:00, 212947.16it/s] 57%|    | 43350/75824 [00:00<00:00, 215171.71it/s] 86%| | 65072/75824 [00:00<00:00, 215781.73it/s]100%|| 75824/75824 [00:00<00:00, 218048.76it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20247/75824 [00:00<00:00, 202468.74it/s] 58%|    | 44077/75824 [00:00<00:00, 212031.30it/s] 90%| | 68159/75824 [00:00<00:00, 219916.92it/s]100%|| 75824/75824 [00:00<00:00, 228265.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 15133/75824 [00:00<00:00, 151327.62it/s] 40%|      | 30321/75824 [00:00<00:00, 151490.58it/s] 59%|    | 44782/75824 [00:00<00:00, 149356.35it/s] 88%| | 67042/75824 [00:00<00:00, 165713.77it/s]100%|| 75824/75824 [00:00<00:00, 173160.54it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 14787/75824 [00:00<00:00, 147868.73it/s] 33%|      | 25325/75824 [00:00<00:00, 131908.78it/s] 60%|    | 45288/75824 [00:00<00:00, 146853.09it/s] 81%| | 61731/75824 [00:00<00:00, 151716.06it/s]100%|| 75824/75824 [00:00<00:00, 161832.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20632/75824 [00:00<00:00, 206313.80it/s] 56%|    | 42780/75824 [00:00<00:00, 210639.19it/s] 84%| | 63499/75824 [00:00<00:00, 209590.68it/s]100%|| 75824/75824 [00:00<00:00, 198896.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18377/75824 [00:00<00:00, 183764.48it/s] 48%|     | 36299/75824 [00:00<00:00, 182375.98it/s] 72%|  | 54592/75824 [00:00<00:00, 182540.71it/s] 97%|| 73606/75824 [00:00<00:00, 184755.74it/s]100%|| 75824/75824 [00:00<00:00, 184730.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21197/75824 [00:00<00:00, 211961.61it/s] 58%|    | 43685/75824 [00:00<00:00, 215678.32it/s] 88%| | 66811/75824 [00:00<00:00, 220127.56it/s]100%|| 75824/75824 [00:00<00:00, 221550.99it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 20928/75824 [00:00<00:00, 205788.33it/s] 56%|    | 42409/75824 [00:00<00:00, 208413.44it/s] 83%| | 63061/75824 [00:00<00:00, 207836.89it/s]100%|| 75824/75824 [00:00<00:00, 181858.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 20982/75824 [00:00<00:00, 209814.20it/s] 56%|    | 42808/75824 [00:00<00:00, 212275.90it/s] 85%| | 64310/75824 [00:00<00:00, 213089.69it/s]100%|| 75824/75824 [00:00<00:00, 214406.91it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20422/75824 [00:00<00:00, 204216.79it/s] 48%|     | 36361/75824 [00:00<00:00, 188322.39it/s] 68%|   | 51764/75824 [00:00<00:00, 176529.22it/s] 93%|| 70578/75824 [00:00<00:00, 179858.70it/s]100%|| 75824/75824 [00:00<00:00, 177706.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19923/75824 [00:00<00:00, 199223.54it/s] 53%|    | 40337/75824 [00:00<00:00, 200672.08it/s] 80%|  | 60753/75824 [00:00<00:00, 201704.51it/s]100%|| 75824/75824 [00:00<00:00, 203208.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20750/75824 [00:00<00:00, 207494.76it/s] 56%|    | 42424/75824 [00:00<00:00, 210183.91it/s] 84%| | 63775/75824 [00:00<00:00, 211168.03it/s]100%|| 75824/75824 [00:00<00:00, 214105.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 15110/75824 [00:00<00:00, 151091.86it/s] 40%|      | 30210/75824 [00:00<00:00, 151062.06it/s] 60%|    | 45479/75824 [00:00<00:00, 151544.57it/s] 80%|  | 61026/75824 [00:00<00:00, 152699.02it/s] 96%|| 72671/75824 [00:00<00:00, 130517.39it/s]100%|| 75824/75824 [00:00<00:00, 139618.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9567/75824 [00:00<00:00, 95668.49it/s] 22%|       | 16917/75824 [00:00<00:00, 87723.62it/s] 28%|       | 21131/75824 [00:00<00:01, 49248.41it/s] 34%|      | 25475/75824 [00:00<00:01, 47348.50it/s] 44%|     | 33187/75824 [00:00<00:00, 53549.48it/s] 50%|     | 38216/75824 [00:00<00:00, 50010.73it/s] 59%|    | 44723/75824 [00:00<00:00, 52388.64it/s] 72%|  | 54787/75824 [00:00<00:00, 61188.86it/s] 94%|| 71491/75824 [00:00<00:00, 75551.28it/s]100%|| 75824/75824 [00:01<00:00, 70775.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11550/75824 [00:00<00:00, 112368.80it/s] 21%|        | 15562/75824 [00:00<00:00, 70811.90it/s]  27%|       | 20726/75824 [00:00<00:00, 63714.46it/s] 40%|      | 30111/75824 [00:00<00:00, 70505.14it/s] 48%|     | 36266/75824 [00:00<00:00, 64272.67it/s] 60%|    | 45678/75824 [00:00<00:00, 71029.33it/s] 80%|  | 60601/75824 [00:00<00:00, 84278.58it/s]100%|| 75824/75824 [00:00<00:00, 94786.70it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18971/75824 [00:00<00:00, 189702.94it/s] 51%|     | 38515/75824 [00:00<00:00, 191387.23it/s] 75%|  | 56993/75824 [00:00<00:00, 189352.84it/s] 93%|| 70194/75824 [00:00<00:00, 167519.39it/s]100%|| 75824/75824 [00:00<00:00, 177199.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20224/75824 [00:00<00:00, 202232.96it/s] 58%|    | 43801/75824 [00:00<00:00, 211245.64it/s] 89%| | 67321/75824 [00:00<00:00, 217902.52it/s]100%|| 75824/75824 [00:00<00:00, 225878.90it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|       | 16120/75824 [00:00<00:00, 161187.47it/s] 32%|      | 24455/75824 [00:00<00:00, 125910.37it/s] 63%|   | 47985/75824 [00:00<00:00, 146316.84it/s] 93%|| 70578/75824 [00:00<00:00, 163612.71it/s]100%|| 75824/75824 [00:00<00:00, 179006.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 30%|       | 22938/75824 [00:00<00:00, 229379.12it/s] 60%|    | 45318/75824 [00:00<00:00, 227673.81it/s] 86%| | 65046/75824 [00:00<00:00, 217613.60it/s]100%|| 75824/75824 [00:00<00:00, 216837.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14280/75824 [00:00<00:00, 142795.71it/s] 45%|     | 34058/75824 [00:00<00:00, 155788.44it/s] 72%|  | 54728/75824 [00:00<00:00, 168216.41it/s] 95%|| 72087/75824 [00:00<00:00, 169792.68it/s]100%|| 75824/75824 [00:00<00:00, 176503.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12585/75824 [00:00<00:00, 125839.92it/s] 34%|      | 25726/75824 [00:00<00:00, 127459.34it/s] 52%|    | 39062/75824 [00:00<00:00, 129172.85it/s] 64%|   | 48403/75824 [00:00<00:00, 115863.17it/s] 75%|  | 57233/75824 [00:00<00:00, 104719.33it/s] 87%| | 65980/75824 [00:00<00:00, 98036.62it/s] 100%|| 75824/75824 [00:00<00:00, 111826.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 31%|       | 23561/75824 [00:00<00:00, 235600.68it/s] 61%|    | 46240/75824 [00:00<00:00, 232885.29it/s] 91%| | 68699/75824 [00:00<00:00, 230330.43it/s]100%|| 75824/75824 [00:00<00:00, 229021.19it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21252/75824 [00:00<00:00, 212519.70it/s] 56%|    | 42383/75824 [00:00<00:00, 212148.85it/s] 87%| | 65995/75824 [00:00<00:00, 218810.82it/s]100%|| 75824/75824 [00:00<00:00, 218930.17it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20096/75824 [00:00<00:00, 200950.61it/s] 43%|     | 32516/75824 [00:00<00:00, 169521.16it/s] 54%|    | 40746/75824 [00:00<00:00, 128622.60it/s] 64%|   | 48777/75824 [00:00<00:00, 106769.31it/s] 80%|  | 60728/75824 [00:00<00:00, 110294.56it/s] 95%|| 71665/75824 [00:00<00:00, 110015.03it/s]100%|| 75824/75824 [00:00<00:00, 118772.45it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  5%|         | 3627/75824 [00:00<00:02, 35086.68it/s]  9%|         | 6663/75824 [00:00<00:02, 33518.69it/s] 13%|        | 9615/75824 [00:00<00:02, 31384.15it/s] 17%|        | 12992/75824 [00:00<00:01, 31698.93it/s] 21%|        | 15901/75824 [00:00<00:01, 30799.12it/s] 27%|       | 20201/75824 [00:00<00:01, 32801.82it/s] 38%|      | 28851/75824 [00:00<00:01, 40308.47it/s] 49%|     | 37385/75824 [00:00<00:00, 47575.39it/s] 62%|   | 47289/75824 [00:00<00:00, 56360.67it/s] 74%|  | 56377/75824 [00:01<00:00, 63608.81it/s] 84%| | 63982/75824 [00:01<00:00, 61253.07it/s] 94%|| 70997/75824 [00:01<00:00, 63617.92it/s]100%|| 75824/75824 [00:01<00:00, 57820.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7274/75824 [00:00<00:00, 72737.29it/s] 24%|       | 18039/75824 [00:00<00:00, 80576.67it/s] 39%|      | 29388/75824 [00:00<00:00, 88252.82it/s] 51%|     | 38612/75824 [00:00<00:00, 89409.85it/s] 61%|    | 46131/75824 [00:00<00:00, 84607.12it/s] 71%|   | 53624/75824 [00:00<00:00, 81169.93it/s] 81%|  | 61124/75824 [00:00<00:00, 79211.30it/s] 90%| | 68602/75824 [00:00<00:00, 75823.45it/s]100%|| 75824/75824 [00:00<00:00, 83689.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11670/75824 [00:00<00:00, 116698.72it/s] 31%|       | 23470/75824 [00:00<00:00, 117082.79it/s] 42%|     | 32003/75824 [00:00<00:00, 105324.77it/s] 56%|    | 42753/75824 [00:00<00:00, 105966.87it/s] 68%|   | 51253/75824 [00:00<00:00, 96156.72it/s]  83%| | 62850/75824 [00:00<00:00, 101351.21it/s] 99%|| 75021/75824 [00:00<00:00, 106704.00it/s]100%|| 75824/75824 [00:00<00:00, 106172.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13424/75824 [00:00<00:00, 134231.17it/s] 27%|       | 20152/75824 [00:00<00:00, 103367.52it/s] 36%|      | 27407/75824 [00:00<00:00, 91604.10it/s]  46%|     | 34698/75824 [00:00<00:00, 85058.74it/s] 61%|   | 46619/75824 [00:00<00:00, 93054.73it/s] 77%|  | 58225/75824 [00:00<00:00, 98936.91it/s] 93%|| 70771/75824 [00:00<00:00, 105635.29it/s]100%|| 75824/75824 [00:00<00:00, 102308.49it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8753/75824 [00:00<00:00, 87529.25it/s] 28%|       | 21148/75824 [00:00<00:00, 95990.15it/s] 44%|     | 33683/75824 [00:00<00:00, 103244.80it/s] 61%|    | 46240/75824 [00:00<00:00, 109061.01it/s] 76%|  | 57955/75824 [00:00<00:00, 111365.85it/s] 93%|| 70491/75824 [00:00<00:00, 115222.35it/s]100%|| 75824/75824 [00:00<00:00, 118024.71it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  3%|         | 2652/75824 [00:00<00:02, 26516.55it/s] 12%|        | 9211/75824 [00:00<00:02, 32286.42it/s] 21%|        | 15660/75824 [00:00<00:01, 37974.87it/s] 32%|      | 23937/75824 [00:00<00:01, 45335.08it/s] 41%|      | 31081/75824 [00:00<00:00, 50916.61it/s] 50%|     | 37856/75824 [00:00<00:00, 55016.27it/s] 58%|    | 43875/75824 [00:00<00:00, 50602.50it/s] 65%|   | 49367/75824 [00:00<00:00, 51114.25it/s] 72%|  | 54782/75824 [00:00<00:00, 47358.59it/s] 79%|  | 59786/75824 [00:01<00:00, 47260.19it/s] 87%| | 65628/75824 [00:01<00:00, 50131.83it/s] 93%|| 70820/75824 [00:01<00:00, 49832.15it/s]100%|| 75824/75824 [00:01<00:00, 55291.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8577/75824 [00:00<00:00, 85766.20it/s] 15%|        | 11234/75824 [00:00<00:01, 48877.78it/s] 21%|       | 16128/75824 [00:00<00:01, 48896.20it/s] 30%|       | 23104/75824 [00:00<00:00, 53715.33it/s] 40%|      | 30022/75824 [00:00<00:00, 57576.55it/s] 51%|     | 38533/75824 [00:00<00:00, 63764.63it/s] 59%|    | 44677/75824 [00:00<00:00, 57650.06it/s] 69%|   | 52078/75824 [00:00<00:00, 61744.28it/s] 83%| | 62670/75824 [00:00<00:00, 70573.81it/s] 93%|| 70631/75824 [00:01<00:00, 73061.66it/s]100%|| 75824/75824 [00:01<00:00, 70167.08it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9914/75824 [00:00<00:00, 99139.39it/s] 18%|        | 13652/75824 [00:00<00:00, 66284.02it/s] 29%|       | 21912/75824 [00:00<00:00, 69275.66it/s] 35%|      | 26478/75824 [00:00<00:00, 54265.76it/s] 41%|      | 30755/75824 [00:00<00:00, 48646.27it/s] 51%|     | 38321/75824 [00:00<00:00, 54481.04it/s] 66%|   | 50250/75824 [00:00<00:00, 65089.37it/s] 76%|  | 57461/75824 [00:00<00:00, 65366.42it/s] 86%| | 65071/75824 [00:00<00:00, 68254.01it/s]100%|| 75824/75824 [00:01<00:00, 73140.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6175/75824 [00:00<00:01, 54096.71it/s] 20%|        | 15129/75824 [00:00<00:00, 60971.66it/s] 32%|      | 23889/75824 [00:00<00:00, 67088.68it/s] 48%|     | 36726/75824 [00:00<00:00, 78302.00it/s] 65%|   | 48968/75824 [00:00<00:00, 87792.97it/s] 77%|  | 58180/75824 [00:00<00:00, 89046.52it/s] 92%|| 69730/75824 [00:00<00:00, 95616.03it/s]100%|| 75824/75824 [00:00<00:00, 96972.09it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5125/75824 [00:00<00:01, 51244.43it/s] 15%|        | 11693/75824 [00:00<00:01, 54859.64it/s] 19%|        | 14740/75824 [00:00<00:01, 43805.91it/s] 27%|       | 20312/75824 [00:00<00:01, 46808.28it/s] 35%|      | 26887/75824 [00:00<00:00, 51236.43it/s] 42%|     | 31513/75824 [00:00<00:00, 47624.62it/s] 49%|     | 37102/75824 [00:00<00:00, 49804.38it/s] 55%|    | 41901/75824 [00:00<00:00, 44264.44it/s] 63%|   | 47560/75824 [00:00<00:00, 47358.38it/s] 71%|  | 54081/75824 [00:01<00:00, 51594.68it/s] 80%|  | 60948/75824 [00:01<00:00, 55751.93it/s] 89%| | 67507/75824 [00:01<00:00, 58376.72it/s] 97%|| 73769/75824 [00:01<00:00, 59587.52it/s]100%|| 75824/75824 [00:01<00:00, 54781.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8546/75824 [00:00<00:00, 85449.08it/s] 20%|        | 14804/75824 [00:00<00:00, 77005.75it/s] 26%|       | 19556/75824 [00:00<00:00, 64918.25it/s] 34%|      | 26143/75824 [00:00<00:00, 65199.23it/s] 42%|     | 31887/75824 [00:00<00:00, 62658.72it/s] 50%|     | 38267/75824 [00:00<00:00, 62996.37it/s] 59%|    | 44872/75824 [00:00<00:00, 63881.35it/s] 68%|   | 51655/75824 [00:00<00:00, 65014.74it/s] 76%|  | 57752/75824 [00:00<00:00, 62338.45it/s] 84%| | 63726/75824 [00:01<00:00, 54163.48it/s] 93%|| 70472/75824 [00:01<00:00, 57566.69it/s]100%|| 75824/75824 [00:01<00:00, 60576.10it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11450/75824 [00:00<00:00, 114497.93it/s] 30%|       | 22881/75824 [00:00<00:00, 114440.53it/s] 45%|     | 34127/75824 [00:00<00:00, 113837.39it/s] 59%|    | 45034/75824 [00:00<00:00, 112363.60it/s] 74%|  | 56401/75824 [00:00<00:00, 112751.27it/s] 89%| | 67370/75824 [00:00<00:00, 111813.17it/s]100%|| 75824/75824 [00:00<00:00, 112492.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12266/75824 [00:00<00:00, 122650.76it/s] 32%|      | 24609/75824 [00:00<00:00, 122880.73it/s] 47%|     | 35961/75824 [00:00<00:00, 119913.10it/s] 64%|   | 48399/75824 [00:00<00:00, 121218.22it/s] 80%|  | 60567/75824 [00:00<00:00, 121354.08it/s] 96%|| 73077/75824 [00:00<00:00, 122451.38it/s]100%|| 75824/75824 [00:00<00:00, 120734.04it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10903/75824 [00:00<00:00, 107115.49it/s] 28%|       | 21080/75824 [00:00<00:00, 105452.27it/s] 44%|     | 32985/75824 [00:00<00:00, 109193.03it/s] 59%|    | 44810/75824 [00:00<00:00, 111758.86it/s] 73%|  | 55429/75824 [00:00<00:00, 110027.69it/s] 89%| | 67757/75824 [00:00<00:00, 113693.23it/s]100%|| 75824/75824 [00:00<00:00, 113481.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11838/75824 [00:00<00:00, 118371.93it/s] 27%|       | 20264/75824 [00:00<00:00, 105550.58it/s] 38%|      | 28957/75824 [00:00<00:00, 99174.75it/s]  48%|     | 36110/75824 [00:00<00:00, 88869.31it/s] 61%|    | 46351/75824 [00:00<00:00, 92172.65it/s] 76%|  | 57833/75824 [00:00<00:00, 97969.09it/s] 93%|| 70665/75824 [00:00<00:00, 105451.09it/s]100%|| 75824/75824 [00:00<00:00, 101825.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12503/75824 [00:00<00:00, 125029.82it/s] 28%|       | 21013/75824 [00:00<00:00, 109599.93it/s] 45%|     | 34177/75824 [00:00<00:00, 115394.20it/s] 58%|    | 43604/75824 [00:00<00:00, 108124.30it/s] 74%|  | 55823/75824 [00:00<00:00, 111544.34it/s] 90%| | 68244/75824 [00:00<00:00, 115063.22it/s]100%|| 75824/75824 [00:00<00:00, 114405.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12304/75824 [00:00<00:00, 123039.82it/s] 32%|      | 24618/75824 [00:00<00:00, 123067.43it/s] 49%|     | 36976/75824 [00:00<00:00, 123217.28it/s] 65%|   | 49426/75824 [00:00<00:00, 123596.54it/s] 82%| | 61957/75824 [00:00<00:00, 124104.26it/s] 98%|| 74630/75824 [00:00<00:00, 124878.67it/s]100%|| 75824/75824 [00:00<00:00, 124323.72it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8177/75824 [00:00<00:00, 81768.13it/s] 25%|       | 19100/75824 [00:00<00:00, 88437.71it/s] 39%|      | 29612/75824 [00:00<00:00, 92858.43it/s] 55%|    | 41460/75824 [00:00<00:00, 99300.24it/s] 70%|   | 53332/75824 [00:00<00:00, 104424.15it/s] 83%| | 62695/75824 [00:00<00:00, 99782.98it/s]  95%|| 71923/75824 [00:00<00:00, 87574.06it/s]100%|| 75824/75824 [00:00<00:00, 94025.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11935/75824 [00:00<00:00, 119348.12it/s] 26%|       | 19476/75824 [00:00<00:00, 101588.70it/s] 42%|     | 31801/75824 [00:00<00:00, 107240.95it/s] 58%|    | 44260/75824 [00:00<00:00, 111914.38it/s] 75%|  | 56543/75824 [00:00<00:00, 114978.50it/s] 91%| | 68796/75824 [00:00<00:00, 117142.40it/s]100%|| 75824/75824 [00:00<00:00, 115417.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11456/75824 [00:00<00:00, 114555.47it/s] 28%|       | 21509/75824 [00:00<00:00, 109952.93it/s] 40%|      | 30357/75824 [00:00<00:00, 102490.83it/s] 55%|    | 41726/75824 [00:00<00:00, 104509.81it/s] 69%|   | 52545/75824 [00:00<00:00, 105585.49it/s] 81%|  | 61252/75824 [00:00<00:00, 81317.38it/s]  94%|| 71126/75824 [00:00<00:00, 85861.93it/s]100%|| 75824/75824 [00:00<00:00, 94071.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9478/75824 [00:00<00:00, 91561.48it/s] 29%|       | 21713/75824 [00:00<00:00, 99036.57it/s] 38%|      | 29051/75824 [00:00<00:00, 89634.11it/s] 50%|     | 38129/75824 [00:00<00:00, 89973.64it/s] 61%|   | 46536/75824 [00:00<00:00, 87047.27it/s] 71%|   | 53867/75824 [00:00<00:00, 77479.18it/s] 80%|  | 60849/75824 [00:00<00:00, 56682.25it/s] 91%| | 69014/75824 [00:00<00:00, 61456.31it/s]100%|| 75462/75824 [00:01<00:00, 56813.65it/s]100%|| 75824/75824 [00:01<00:00, 69040.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7705/75824 [00:00<00:00, 77044.38it/s] 26%|       | 20068/75824 [00:00<00:00, 86863.39it/s] 33%|      | 25395/75824 [00:00<00:00, 70156.45it/s] 45%|     | 34332/75824 [00:00<00:00, 74993.15it/s] 56%|    | 42619/75824 [00:00<00:00, 77193.46it/s] 66%|   | 49977/75824 [00:00<00:00, 76069.62it/s] 75%|  | 57016/75824 [00:00<00:00, 60756.36it/s] 90%| | 68474/75824 [00:00<00:00, 69781.41it/s]100%|| 75824/75824 [00:01<00:00, 69554.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11791/75824 [00:00<00:00, 117905.90it/s] 20%|        | 15329/75824 [00:00<00:00, 68693.65it/s]  27%|       | 20575/75824 [00:00<00:00, 62658.23it/s] 37%|      | 27735/75824 [00:00<00:00, 65096.38it/s] 53%|    | 40205/75824 [00:00<00:00, 75993.02it/s] 69%|   | 52630/75824 [00:00<00:00, 86014.99it/s] 81%|  | 61409/75824 [00:00<00:00, 75174.80it/s] 93%|| 70622/75824 [00:00<00:00, 79566.29it/s]100%|| 75824/75824 [00:00<00:00, 84684.02it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12365/75824 [00:00<00:00, 123645.11it/s] 33%|      | 24720/75824 [00:00<00:00, 123615.27it/s] 49%|     | 36881/75824 [00:00<00:00, 123005.03it/s] 59%|    | 44942/75824 [00:00<00:00, 103122.68it/s] 70%|   | 52831/75824 [00:00<00:00, 90898.84it/s]  86%| | 65133/75824 [00:00<00:00, 98622.67it/s] 98%|| 74185/75824 [00:00<00:00, 92707.30it/s]100%|| 75824/75824 [00:00<00:00, 99212.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12321/75824 [00:00<00:00, 123207.47it/s] 27%|       | 20567/75824 [00:00<00:00, 107299.47it/s] 38%|      | 28478/75824 [00:00<00:00, 96935.35it/s]  52%|    | 39217/75824 [00:00<00:00, 99212.98it/s] 61%|   | 46508/75824 [00:00<00:00, 85499.82it/s] 73%|  | 55579/75824 [00:00<00:00, 86997.28it/s] 90%| | 67956/75824 [00:00<00:00, 95509.12it/s]100%|| 75824/75824 [00:00<00:00, 95233.49it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10390/75824 [00:00<00:00, 103894.40it/s] 24%|       | 17947/75824 [00:00<00:00, 92931.71it/s]  29%|       | 22366/75824 [00:00<00:00, 69297.53it/s] 36%|      | 27431/75824 [00:00<00:00, 60963.81it/s] 45%|     | 33929/75824 [00:00<00:00, 61412.00it/s] 53%|    | 40046/75824 [00:00<00:00, 61338.65it/s] 62%|   | 46755/75824 [00:00<00:00, 62420.68it/s] 70%|   | 53269/75824 [00:00<00:00, 63211.26it/s] 79%|  | 59806/75824 [00:00<00:00, 63842.62it/s] 87%| | 65931/75824 [00:01<00:00, 61915.06it/s] 95%|| 72069/75824 [00:01<00:00, 60898.25it/s]100%|| 75824/75824 [00:01<00:00, 63849.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6998/75824 [00:00<00:00, 69978.06it/s] 16%|        | 12213/75824 [00:00<00:01, 62440.13it/s] 23%|       | 17506/75824 [00:00<00:00, 58633.93it/s] 30%|       | 22807/75824 [00:00<00:00, 56114.94it/s] 38%|      | 28740/75824 [00:00<00:00, 57042.25it/s] 46%|     | 35127/75824 [00:00<00:00, 58931.03it/s] 57%|    | 43346/75824 [00:00<00:00, 64397.61it/s] 67%|   | 50566/75824 [00:00<00:00, 66551.22it/s] 75%|  | 56982/75824 [00:00<00:00, 62360.19it/s] 90%| | 68293/75824 [00:01<00:00, 72054.13it/s]100%|| 75824/75824 [00:01<00:00, 69199.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9321/75824 [00:00<00:00, 93203.20it/s] 26%|       | 19348/75824 [00:00<00:00, 95215.25it/s] 41%|      | 30902/75824 [00:00<00:00, 100519.17it/s] 56%|    | 42533/75824 [00:00<00:00, 104786.79it/s] 72%|  | 54354/75824 [00:00<00:00, 108481.90it/s] 86%| | 65339/75824 [00:00<00:00, 108885.99it/s] 99%|| 75208/75824 [00:00<00:00, 100649.45it/s]100%|| 75824/75824 [00:00<00:00, 104189.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6687/75824 [00:00<00:01, 65571.85it/s] 18%|        | 13843/75824 [00:00<00:00, 67260.01it/s] 35%|      | 26268/75824 [00:00<00:00, 77991.09it/s] 43%|     | 32462/75824 [00:00<00:00, 62096.58it/s] 50%|     | 38061/75824 [00:00<00:00, 55800.50it/s] 63%|   | 47957/75824 [00:00<00:00, 64200.18it/s] 80%|  | 60542/75824 [00:00<00:00, 75259.46it/s] 97%|| 73847/75824 [00:00<00:00, 86534.85it/s]100%|| 75824/75824 [00:00<00:00, 85337.78it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  5%|         | 3576/75824 [00:00<00:02, 31444.88it/s] 13%|        | 9763/75824 [00:00<00:01, 36886.55it/s] 24%|       | 17845/75824 [00:00<00:01, 44073.65it/s] 34%|      | 26115/75824 [00:00<00:00, 51255.56it/s] 48%|     | 36438/75824 [00:00<00:00, 60374.68it/s] 57%|    | 43323/75824 [00:00<00:00, 59352.68it/s] 68%|   | 51602/75824 [00:00<00:00, 64860.80it/s] 81%|  | 61489/75824 [00:00<00:00, 72323.31it/s] 94%|| 71364/75824 [00:00<00:00, 78635.66it/s]100%|| 75824/75824 [00:00<00:00, 78164.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12404/75824 [00:00<00:00, 124030.95it/s] 25%|       | 18653/75824 [00:00<00:00, 93602.72it/s]  35%|      | 26482/75824 [00:00<00:00, 88413.63it/s] 51%|    | 38905/75824 [00:00<00:00, 96783.58it/s] 68%|   | 51372/75824 [00:00<00:00, 103744.71it/s] 84%| | 63968/75824 [00:00<00:00, 109539.20it/s] 98%|| 74051/75824 [00:00<00:00, 99665.90it/s] 100%|| 75824/75824 [00:00<00:00, 101438.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6005/75824 [00:00<00:01, 60045.62it/s] 17%|        | 13000/75824 [00:00<00:01, 61223.06it/s] 26%|       | 19474/75824 [00:00<00:00, 61891.43it/s] 39%|      | 29217/75824 [00:00<00:00, 69494.76it/s] 48%|     | 36611/75824 [00:00<00:00, 70254.54it/s] 59%|    | 44380/75824 [00:00<00:00, 72295.09it/s] 70%|   | 53023/75824 [00:00<00:00, 76024.76it/s] 83%| | 62770/75824 [00:00<00:00, 81396.69it/s] 96%|| 72977/75824 [00:00<00:00, 85916.76it/s]100%|| 75824/75824 [00:00<00:00, 79504.52it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12386/75824 [00:00<00:00, 123854.80it/s] 33%|      | 24817/75824 [00:00<00:00, 123989.63it/s] 49%|     | 37333/75824 [00:00<00:00, 124338.38it/s] 66%|   | 49950/75824 [00:00<00:00, 124879.82it/s] 83%| | 62559/75824 [00:00<00:00, 125238.15it/s] 99%|| 75143/75824 [00:00<00:00, 125416.71it/s]100%|| 75824/75824 [00:00<00:00, 125161.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11334/75824 [00:00<00:00, 113332.00it/s] 26%|       | 19599/75824 [00:00<00:00, 101332.96it/s] 42%|     | 31595/75824 [00:00<00:00, 106281.94it/s] 57%|    | 43125/75824 [00:00<00:00, 108030.26it/s] 72%|  | 54390/75824 [00:00<00:00, 108544.34it/s] 84%| | 63458/75824 [00:00<00:00, 97552.27it/s] 100%|| 75824/75824 [00:00<00:00, 105245.76it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10591/75824 [00:00<00:00, 105907.83it/s] 24%|       | 18301/75824 [00:00<00:00, 95232.36it/s]  41%|     | 31426/75824 [00:00<00:00, 103774.36it/s] 58%|    | 44240/75824 [00:00<00:00, 110051.06it/s] 76%|  | 57287/75824 [00:00<00:00, 115472.12it/s] 93%|| 70424/75824 [00:00<00:00, 119820.55it/s]100%|| 75824/75824 [00:00<00:00, 118222.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6327/75824 [00:00<00:01, 63266.29it/s] 14%|        | 10502/75824 [00:00<00:01, 53769.32it/s] 18%|        | 13754/75824 [00:00<00:01, 43251.81it/s] 33%|      | 25209/75824 [00:00<00:00, 53181.90it/s] 44%|     | 33588/75824 [00:00<00:00, 59726.74it/s] 53%|    | 39810/75824 [00:00<00:00, 58947.16it/s] 61%|    | 46270/75824 [00:00<00:00, 59892.49it/s] 76%|  | 57330/75824 [00:00<00:00, 69443.82it/s] 86%| | 64930/75824 [00:00<00:00, 62053.39it/s] 96%|| 72975/75824 [00:01<00:00, 65428.07it/s]100%|| 75824/75824 [00:01<00:00, 65668.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8204/75824 [00:00<00:00, 82039.49it/s] 27%|       | 20567/75824 [00:00<00:00, 91248.05it/s] 37%|      | 28068/75824 [00:00<00:00, 84156.97it/s] 45%|     | 34008/75824 [00:00<00:00, 72001.89it/s] 52%|    | 39782/75824 [00:00<00:00, 64839.10it/s] 60%|    | 45617/75824 [00:00<00:00, 62336.38it/s] 70%|   | 53059/75824 [00:00<00:00, 65528.27it/s] 87%| | 65707/75824 [00:00<00:00, 76602.43it/s] 98%|| 74575/75824 [00:00<00:00, 78551.40it/s]100%|| 75824/75824 [00:00<00:00, 79486.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5095/75824 [00:00<00:01, 50946.53it/s] 15%|        | 11072/75824 [00:00<00:01, 53111.23it/s] 20%|        | 14839/75824 [00:00<00:01, 46603.70it/s] 26%|       | 19410/75824 [00:00<00:01, 46331.72it/s] 37%|      | 28151/75824 [00:00<00:00, 53935.82it/s] 44%|     | 33240/75824 [00:00<00:00, 46291.64it/s] 51%|     | 38591/75824 [00:00<00:00, 48243.92it/s] 57%|    | 43421/75824 [00:00<00:00, 44110.18it/s] 72%|  | 54950/75824 [00:00<00:00, 54137.34it/s] 89%| | 67407/75824 [00:01<00:00, 65195.63it/s]100%|| 75824/75824 [00:01<00:00, 65523.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6498/75824 [00:00<00:01, 64975.10it/s] 20%|        | 15313/75824 [00:00<00:00, 70538.28it/s] 30%|       | 22884/75824 [00:00<00:00, 72013.24it/s] 41%|     | 31430/75824 [00:00<00:00, 75086.51it/s] 53%|    | 40437/75824 [00:00<00:00, 79029.85it/s] 64%|   | 48753/75824 [00:00<00:00, 80223.75it/s] 77%|  | 58526/75824 [00:00<00:00, 84779.56it/s] 88%| | 66910/75824 [00:00<00:00, 84494.17it/s] 99%|| 75081/75824 [00:00<00:00, 81697.71it/s]100%|| 75824/75824 [00:00<00:00, 82273.49it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4767/75824 [00:00<00:01, 47665.05it/s] 12%|        | 9339/75824 [00:00<00:01, 47063.56it/s] 16%|        | 12097/75824 [00:00<00:01, 37646.82it/s] 19%|        | 14528/75824 [00:00<00:01, 32149.91it/s] 24%|       | 18296/75824 [00:00<00:01, 33022.38it/s] 29%|       | 21641/75824 [00:00<00:01, 33149.10it/s] 33%|      | 24698/75824 [00:00<00:01, 31927.79it/s] 37%|      | 28159/75824 [00:00<00:01, 32687.29it/s] 41%|      | 31251/75824 [00:00<00:01, 31377.54it/s] 47%|     | 35520/75824 [00:01<00:01, 34087.05it/s] 54%|    | 40776/75824 [00:01<00:00, 37756.87it/s] 60%|    | 45737/75824 [00:01<00:00, 40670.98it/s] 67%|   | 50684/75824 [00:01<00:00, 42963.22it/s] 73%|  | 55659/75824 [00:01<00:00, 44796.25it/s] 79%|  | 60255/75824 [00:01<00:00, 44675.40it/s] 85%| | 64804/75824 [00:01<00:00, 40684.94it/s] 94%|| 71226/75824 [00:01<00:00, 45709.13it/s]100%|| 75824/75824 [00:01<00:00, 40623.10it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6555/75824 [00:00<00:01, 58762.71it/s] 23%|       | 17379/75824 [00:00<00:00, 68101.19it/s] 37%|      | 27879/75824 [00:00<00:00, 76126.70it/s] 50%|     | 37943/75824 [00:00<00:00, 82127.03it/s] 63%|   | 47875/75824 [00:00<00:00, 86016.87it/s] 79%|  | 59941/75824 [00:00<00:00, 94123.51it/s] 96%|| 72579/75824 [00:00<00:00, 101926.08it/s]100%|| 75824/75824 [00:00<00:00, 102415.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12568/75824 [00:00<00:00, 125673.53it/s] 33%|      | 25026/75824 [00:00<00:00, 125341.15it/s] 41%|     | 31403/75824 [00:00<00:00, 96339.53it/s]  50%|     | 37744/75824 [00:00<00:00, 79633.07it/s] 58%|    | 43884/75824 [00:00<00:00, 66410.46it/s] 66%|   | 50406/75824 [00:00<00:00, 66048.47it/s] 75%|  | 56888/75824 [00:00<00:00, 65674.09it/s] 83%| | 63012/75824 [00:00<00:00, 63299.62it/s] 99%|| 75303/75824 [00:00<00:00, 74077.48it/s]100%|| 75824/75824 [00:00<00:00, 79689.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8668/75824 [00:00<00:00, 86673.88it/s] 25%|       | 18761/75824 [00:00<00:00, 88997.42it/s] 33%|      | 25194/75824 [00:00<00:00, 79815.24it/s] 40%|      | 30392/75824 [00:00<00:00, 62979.21it/s] 50%|     | 37805/75824 [00:00<00:00, 65954.99it/s] 64%|   | 48815/75824 [00:00<00:00, 74843.40it/s] 74%|  | 56051/75824 [00:00<00:00, 72752.61it/s] 83%| | 63165/75824 [00:00<00:00, 68730.07it/s] 92%|| 69971/75824 [00:00<00:00, 66961.00it/s]100%|| 75824/75824 [00:01<00:00, 71965.09it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11685/75824 [00:00<00:00, 116841.75it/s] 25%|       | 18789/75824 [00:00<00:00, 97904.85it/s]  34%|      | 25743/75824 [00:00<00:00, 86218.30it/s] 46%|     | 35213/75824 [00:00<00:00, 88598.31it/s] 57%|    | 43240/75824 [00:00<00:00, 85922.94it/s] 66%|   | 50201/75824 [00:00<00:00, 78329.08it/s] 80%|  | 60688/75824 [00:00<00:00, 84764.15it/s] 90%| | 68609/75824 [00:00<00:00, 77553.41it/s]100%|| 75824/75824 [00:00<00:00, 79533.91it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12451/75824 [00:00<00:00, 124503.29it/s] 33%|      | 24788/75824 [00:00<00:00, 124160.27it/s] 48%|     | 36414/75824 [00:00<00:00, 121679.01it/s] 64%|   | 48351/75824 [00:00<00:00, 120975.35it/s] 80%|  | 60535/75824 [00:00<00:00, 121232.19it/s] 96%|| 72833/75824 [00:00<00:00, 121751.24it/s]100%|| 75824/75824 [00:00<00:00, 121164.49it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12767/75824 [00:00<00:00, 127668.30it/s] 32%|      | 24486/75824 [00:00<00:00, 124332.01it/s] 43%|     | 32421/75824 [00:00<00:00, 106258.13it/s] 53%|    | 39946/75824 [00:00<00:00, 94566.14it/s]  68%|   | 51711/75824 [00:00<00:00, 100479.71it/s] 85%| | 64226/75824 [00:00<00:00, 106795.24it/s]100%|| 75824/75824 [00:00<00:00, 109587.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10142/75824 [00:00<00:00, 101412.36it/s] 28%|       | 21564/75824 [00:00<00:00, 104942.39it/s] 45%|     | 34402/75824 [00:00<00:00, 111022.86it/s] 59%|    | 44973/75824 [00:00<00:00, 109373.39it/s] 73%|  | 55517/75824 [00:00<00:00, 108162.54it/s] 85%| | 64694/75824 [00:00<00:00, 97510.24it/s]  97%|| 73496/75824 [00:00<00:00, 86753.42it/s]100%|| 75824/75824 [00:00<00:00, 97407.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 13145/75824 [00:00<00:00, 131446.68it/s] 34%|      | 25423/75824 [00:00<00:00, 128719.07it/s] 50%|     | 38238/75824 [00:00<00:00, 128546.66it/s] 67%|   | 50632/75824 [00:00<00:00, 127126.06it/s] 83%| | 63152/75824 [00:00<00:00, 126541.17it/s] 99%|| 75154/75824 [00:00<00:00, 124508.96it/s]100%|| 75824/75824 [00:00<00:00, 125200.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9456/75824 [00:00<00:00, 94556.03it/s] 29%|       | 21840/75824 [00:00<00:00, 101774.18it/s] 44%|     | 33443/75824 [00:00<00:00, 105667.75it/s] 60%|    | 45776/75824 [00:00<00:00, 110409.66it/s] 77%|  | 58180/75824 [00:00<00:00, 114172.70it/s] 90%| | 68152/75824 [00:00<00:00, 91806.12it/s] 100%|| 75824/75824 [00:00<00:00, 103643.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  4%|         | 3389/75824 [00:00<00:02, 33887.12it/s] 17%|        | 12728/75824 [00:00<00:01, 41894.77it/s] 33%|      | 25141/75824 [00:00<00:00, 52286.50it/s] 47%|     | 35939/75824 [00:00<00:00, 61857.54it/s] 57%|    | 43507/75824 [00:00<00:00, 50652.44it/s] 73%|  | 55273/75824 [00:00<00:00, 61089.62it/s] 83%| | 63259/75824 [00:00<00:00, 55689.33it/s]100%|| 75711/75824 [00:00<00:00, 66759.49it/s]100%|| 75824/75824 [00:00<00:00, 76790.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12430/75824 [00:00<00:00, 124290.64it/s] 22%|       | 16358/75824 [00:00<00:00, 75357.79it/s]  32%|      | 24606/75824 [00:00<00:00, 77361.00it/s] 47%|     | 35389/75824 [00:00<00:00, 84524.66it/s] 59%|    | 44441/75824 [00:00<00:00, 80479.31it/s] 68%|   | 51608/75824 [00:00<00:00, 77616.28it/s] 77%|  | 58681/75824 [00:00<00:00, 72610.58it/s] 87%| | 66171/75824 [00:00<00:00, 73282.49it/s] 99%|| 75245/75824 [00:00<00:00, 77769.67it/s]100%|| 75824/75824 [00:00<00:00, 79447.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6757/75824 [00:00<00:01, 63566.45it/s] 17%|        | 13170/75824 [00:00<00:01, 62250.34it/s] 26%|       | 19606/75824 [00:00<00:00, 62867.84it/s] 34%|      | 25972/75824 [00:00<00:00, 63101.86it/s] 48%|     | 36671/75824 [00:00<00:00, 71388.49it/s] 57%|    | 43487/75824 [00:00<00:00, 70387.68it/s] 66%|   | 50040/75824 [00:00<00:00, 65460.08it/s] 77%|  | 58304/75824 [00:00<00:00, 69813.70it/s] 88%| | 66960/75824 [00:00<00:00, 74107.97it/s]100%|| 75824/75824 [00:01<00:00, 74419.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12587/75824 [00:00<00:00, 125862.32it/s] 28%|       | 20894/75824 [00:00<00:00, 109012.85it/s] 40%|      | 30528/75824 [00:00<00:00, 104873.26it/s] 52%|    | 39752/75824 [00:00<00:00, 100732.57it/s] 62%|   | 47059/75824 [00:00<00:00, 79715.50it/s]  71%|   | 53782/75824 [00:00<00:00, 71938.30it/s] 80%|  | 60556/75824 [00:00<00:00, 70624.08it/s] 89%| | 67113/75824 [00:00<00:00, 68729.67it/s]100%|| 75824/75824 [00:00<00:00, 81011.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7018/75824 [00:00<00:00, 70176.39it/s] 15%|        | 11488/75824 [00:00<00:01, 58716.85it/s] 21%|        | 15572/75824 [00:00<00:01, 50536.53it/s] 27%|       | 20597/75824 [00:00<00:01, 50449.81it/s] 37%|      | 28215/75824 [00:00<00:00, 54895.54it/s] 44%|     | 33621/75824 [00:00<00:00, 54641.37it/s] 56%|    | 42381/75824 [00:00<00:00, 61592.51it/s] 67%|   | 50565/75824 [00:00<00:00, 66530.29it/s] 77%|  | 58060/75824 [00:00<00:00, 68850.26it/s] 86%| | 64984/75824 [00:01<00:00, 66712.25it/s] 95%|| 71697/75824 [00:01<00:00, 64890.56it/s]100%|| 75824/75824 [00:01<00:00, 63528.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11004/75824 [00:00<00:00, 110038.27it/s] 26%|       | 19520/75824 [00:00<00:00, 97681.03it/s]  34%|      | 26065/75824 [00:00<00:00, 83399.65it/s] 50%|     | 37842/75824 [00:00<00:00, 91401.33it/s] 66%|   | 50318/75824 [00:00<00:00, 99371.42it/s] 82%| | 62269/75824 [00:00<00:00, 104661.06it/s] 99%|| 74905/75824 [00:00<00:00, 110345.55it/s]100%|| 75824/75824 [00:00<00:00, 104889.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11464/75824 [00:00<00:00, 114637.10it/s] 31%|      | 23836/75824 [00:00<00:00, 117218.50it/s] 42%|     | 31939/75824 [00:00<00:00, 103366.71it/s] 59%|    | 44380/75824 [00:00<00:00, 108890.26it/s] 75%|  | 56661/75824 [00:00<00:00, 112722.93it/s] 91%|| 69313/75824 [00:00<00:00, 116532.83it/s]100%|| 75824/75824 [00:00<00:00, 108676.86it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11068/75824 [00:00<00:00, 110679.58it/s] 29%|       | 22276/75824 [00:00<00:00, 111095.73it/s] 42%|     | 32062/75824 [00:00<00:00, 106761.69it/s] 59%|    | 44576/75824 [00:00<00:00, 111681.14it/s] 70%|   | 53172/75824 [00:00<00:00, 85550.08it/s]  86%| | 65344/75824 [00:00<00:00, 93922.28it/s]100%|| 75824/75824 [00:00<00:00, 101882.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 5861/75824 [00:00<00:01, 58547.80it/s] 20%|        | 14919/75824 [00:00<00:00, 65494.98it/s] 31%|       | 23330/75824 [00:00<00:00, 70152.44it/s] 42%|     | 31496/75824 [00:00<00:00, 73248.96it/s] 56%|    | 42763/75824 [00:00<00:00, 81838.26it/s] 68%|   | 51245/75824 [00:00<00:00, 79416.59it/s] 78%|  | 58854/75824 [00:00<00:00, 75964.21it/s] 87%| | 66249/75824 [00:00<00:00, 73249.16it/s]100%|| 75824/75824 [00:00<00:00, 82011.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4313/75824 [00:00<00:01, 43129.01it/s] 11%|         | 8069/75824 [00:00<00:01, 40923.98it/s] 18%|        | 14001/75824 [00:00<00:01, 44813.55it/s] 31%|       | 23560/75824 [00:00<00:00, 53308.03it/s] 44%|     | 33562/75824 [00:00<00:00, 61993.26it/s] 60%|    | 45811/75824 [00:00<00:00, 72776.08it/s] 77%|  | 58036/75824 [00:00<00:00, 82832.51it/s] 93%|| 70429/75824 [00:00<00:00, 91983.37it/s]100%|| 75824/75824 [00:00<00:00, 89251.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7780/75824 [00:00<00:00, 77794.88it/s] 24%|       | 18184/75824 [00:00<00:00, 82555.70it/s] 37%|      | 28145/75824 [00:00<00:00, 87024.60it/s] 49%|     | 37348/75824 [00:00<00:00, 88466.49it/s] 60%|    | 45244/75824 [00:00<00:00, 84367.07it/s] 73%|  | 55207/75824 [00:00<00:00, 88430.17it/s] 90%| | 68107/75824 [00:00<00:00, 97642.35it/s]100%|| 75824/75824 [00:00<00:00, 97527.27it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10582/75824 [00:00<00:00, 105815.81it/s] 26%|       | 19382/75824 [00:00<00:00, 99755.49it/s]  41%|      | 31108/75824 [00:00<00:00, 104431.21it/s] 54%|    | 40723/75824 [00:00<00:00, 101800.33it/s] 68%|   | 51440/75824 [00:00<00:00, 103352.11it/s] 86%| | 64911/75824 [00:00<00:00, 111110.47it/s] 99%|| 74990/75824 [00:00<00:00, 90022.47it/s] 100%|| 75824/75824 [00:00<00:00, 96609.21it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10816/75824 [00:00<00:00, 108154.17it/s] 30%|       | 23096/75824 [00:00<00:00, 112165.84it/s] 47%|     | 35385/75824 [00:00<00:00, 115180.38it/s] 63%|   | 47710/75824 [00:00<00:00, 117486.84it/s] 79%|  | 59622/75824 [00:00<00:00, 117969.59it/s] 94%|| 71349/75824 [00:00<00:00, 117756.34it/s]100%|| 75824/75824 [00:00<00:00, 119227.83it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7170/75824 [00:00<00:00, 69068.60it/s] 14%|        | 10518/75824 [00:00<00:01, 52365.72it/s] 20%|        | 15487/75824 [00:00<00:01, 51529.11it/s] 26%|       | 20011/75824 [00:00<00:01, 49465.72it/s] 32%|      | 24541/75824 [00:00<00:01, 48136.60it/s] 38%|      | 29067/75824 [00:00<00:00, 47233.35it/s] 44%|     | 33585/75824 [00:00<00:00, 46597.23it/s] 50%|     | 38182/75824 [00:00<00:00, 46403.94it/s] 56%|    | 42738/75824 [00:00<00:00, 46147.20it/s] 63%|   | 47601/75824 [00:01<00:00, 46864.02it/s] 72%|  | 54435/75824 [00:01<00:00, 51741.54it/s] 81%|  | 61224/75824 [00:01<00:00, 55716.66it/s] 89%| | 67576/75824 [00:01<00:00, 57848.62it/s] 97%|| 73468/75824 [00:01<00:00, 57881.44it/s]100%|| 75824/75824 [00:01<00:00, 52247.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  3%|         | 1978/75824 [00:00<00:03, 19778.56it/s]  4%|         | 3340/75824 [00:00<00:04, 16966.72it/s] 12%|        | 9028/75824 [00:00<00:03, 21490.64it/s] 26%|       | 19926/75824 [00:00<00:01, 28308.35it/s] 43%|     | 32323/75824 [00:00<00:01, 36835.59it/s] 58%|    | 44099/75824 [00:00<00:00, 46401.59it/s] 75%|  | 56503/75824 [00:00<00:00, 57128.83it/s] 90%| | 68006/75824 [00:00<00:00, 67289.82it/s]100%|| 75824/75824 [00:00<00:00, 87199.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12313/75824 [00:00<00:00, 123129.24it/s] 32%|      | 24539/75824 [00:00<00:00, 122864.38it/s] 49%|     | 36805/75824 [00:00<00:00, 122802.77it/s] 65%|   | 49221/75824 [00:00<00:00, 123204.05it/s] 81%| | 61665/75824 [00:00<00:00, 123570.09it/s] 95%|| 71954/75824 [00:00<00:00, 91027.76it/s] 100%|| 75824/75824 [00:00<00:00, 104947.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4386/75824 [00:00<00:01, 37113.39it/s] 12%|        | 9300/75824 [00:00<00:01, 38223.43it/s] 17%|        | 12873/75824 [00:00<00:01, 37439.51it/s] 25%|       | 18947/75824 [00:00<00:01, 42308.45it/s] 30%|       | 22684/75824 [00:00<00:01, 40694.85it/s] 46%|     | 35001/75824 [00:00<00:00, 50924.51it/s] 56%|    | 42175/75824 [00:00<00:00, 55779.48it/s] 72%|  | 54229/75824 [00:00<00:00, 66497.04it/s] 82%| | 62402/75824 [00:00<00:00, 67109.86it/s] 96%|| 72874/75824 [00:01<00:00, 74157.58it/s]100%|| 75824/75824 [00:01<00:00, 65420.75it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 5771/75824 [00:00<00:01, 57346.64it/s] 15%|        | 11428/75824 [00:00<00:01, 57110.36it/s] 21%|        | 15799/75824 [00:00<00:01, 52299.50it/s] 26%|       | 20073/75824 [00:00<00:01, 48599.01it/s] 38%|      | 28839/75824 [00:00<00:00, 56097.57it/s] 46%|     | 34873/75824 [00:00<00:00, 57305.35it/s] 53%|    | 40284/75824 [00:00<00:00, 54928.37it/s] 67%|   | 50666/75824 [00:00<00:00, 63964.45it/s] 80%|  | 61006/75824 [00:00<00:00, 72227.49it/s] 92%|| 69917/75824 [00:01<00:00, 76578.92it/s]100%|| 75824/75824 [00:01<00:00, 71665.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8948/75824 [00:00<00:00, 89477.10it/s] 19%|        | 14779/75824 [00:00<00:00, 77111.33it/s] 33%|      | 24938/75824 [00:00<00:00, 83118.39it/s] 49%|     | 37149/75824 [00:00<00:00, 91922.72it/s] 65%|   | 49571/75824 [00:00<00:00, 99698.73it/s] 81%|  | 61358/75824 [00:00<00:00, 104533.20it/s] 96%|| 72948/75824 [00:00<00:00, 107699.92it/s]100%|| 75824/75824 [00:00<00:00, 104655.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10151/75824 [00:00<00:00, 101507.19it/s] 31%|       | 23682/75824 [00:00<00:00, 109729.83it/s] 46%|     | 34839/75824 [00:00<00:00, 110273.17it/s] 56%|    | 42520/75824 [00:00<00:00, 90828.16it/s]  66%|   | 49827/75824 [00:00<00:00, 81040.37it/s] 83%| | 63042/75824 [00:00<00:00, 91676.15it/s]100%|| 75824/75824 [00:00<00:00, 104053.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12609/75824 [00:00<00:00, 126086.51it/s] 31%|       | 23171/75824 [00:00<00:00, 119156.63it/s] 39%|      | 29562/75824 [00:00<00:00, 94615.76it/s]  53%|    | 39909/75824 [00:00<00:00, 97106.60it/s] 62%|   | 47205/75824 [00:00<00:00, 71553.77it/s] 74%|  | 56187/75824 [00:00<00:00, 75945.13it/s] 84%| | 63353/75824 [00:00<00:00, 72151.71it/s] 93%|| 70308/75824 [00:00<00:00, 64698.09it/s]100%|| 75824/75824 [00:01<00:00, 75688.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10218/75824 [00:00<00:00, 102179.61it/s] 28%|       | 21015/75824 [00:00<00:00, 103321.70it/s] 36%|      | 27514/75824 [00:00<00:00, 87786.72it/s]  53%|    | 40059/75824 [00:00<00:00, 96475.95it/s] 65%|   | 49588/75824 [00:00<00:00, 96115.10it/s] 79%|  | 60056/75824 [00:00<00:00, 98533.33it/s] 92%|| 69473/75824 [00:00<00:00, 97182.34it/s]100%|| 75824/75824 [00:00<00:00, 100477.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10329/75824 [00:00<00:00, 103280.74it/s] 28%|       | 21552/75824 [00:00<00:00, 105810.37it/s] 43%|     | 32864/75824 [00:00<00:00, 107901.26it/s] 58%|    | 43686/75824 [00:00<00:00, 107994.09it/s] 69%|   | 52021/75824 [00:00<00:00, 98520.96it/s]  84%| | 63703/75824 [00:00<00:00, 103378.02it/s]100%|| 75824/75824 [00:00<00:00, 113239.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13860/75824 [00:00<00:00, 138591.87it/s] 37%|      | 28232/75824 [00:00<00:00, 140090.53it/s] 56%|    | 42630/75824 [00:00<00:00, 141233.48it/s] 74%|  | 55997/75824 [00:00<00:00, 138873.94it/s] 91%| | 68659/75824 [00:00<00:00, 134954.76it/s]100%|| 75824/75824 [00:00<00:00, 134600.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13795/75824 [00:00<00:00, 137948.16it/s] 37%|      | 28186/75824 [00:00<00:00, 139681.71it/s] 56%|    | 42575/75824 [00:00<00:00, 140916.98it/s] 75%|  | 56836/75824 [00:00<00:00, 141416.98it/s] 89%| | 67671/75824 [00:00<00:00, 103764.38it/s]100%|| 75824/75824 [00:00<00:00, 119653.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11348/75824 [00:00<00:00, 113476.59it/s] 31%|       | 23659/75824 [00:00<00:00, 116203.44it/s] 42%|     | 32116/75824 [00:00<00:00, 104477.75it/s] 53%|    | 40083/75824 [00:00<00:00, 95550.39it/s]  68%|   | 51358/75824 [00:00<00:00, 100132.13it/s] 84%| | 63830/75824 [00:00<00:00, 106426.45it/s] 98%|| 74368/75824 [00:00<00:00, 106108.69it/s]100%|| 75824/75824 [00:00<00:00, 105709.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10692/75824 [00:00<00:00, 104569.09it/s] 20%|        | 15537/75824 [00:00<00:00, 77602.83it/s]  37%|      | 27967/75824 [00:00<00:00, 87459.39it/s] 53%|    | 39860/75824 [00:00<00:00, 95000.41it/s] 69%|   | 52450/75824 [00:00<00:00, 102550.32it/s] 83%| | 63136/75824 [00:00<00:00, 103708.53it/s] 96%|| 72879/75824 [00:00<00:00, 89972.08it/s] 100%|| 75824/75824 [00:00<00:00, 98733.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11560/75824 [00:00<00:00, 115593.22it/s] 32%|      | 24109/75824 [00:00<00:00, 118394.17it/s] 48%|     | 36195/75824 [00:00<00:00, 119121.31it/s] 64%|   | 48758/75824 [00:00<00:00, 121000.77it/s] 80%|  | 60791/75824 [00:00<00:00, 120797.92it/s] 97%|| 73238/75824 [00:00<00:00, 121874.41it/s]100%|| 75824/75824 [00:00<00:00, 122097.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9418/75824 [00:00<00:00, 94178.07it/s] 28%|       | 21275/75824 [00:00<00:00, 100372.43it/s] 43%|     | 32612/75824 [00:00<00:00, 103946.50it/s] 59%|    | 44864/75824 [00:00<00:00, 108897.11it/s] 76%|  | 57307/75824 [00:00<00:00, 113131.98it/s] 91%|| 69225/75824 [00:00<00:00, 114878.52it/s]100%|| 75824/75824 [00:00<00:00, 116196.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9019/75824 [00:00<00:00, 90181.70it/s] 18%|        | 13287/75824 [00:00<00:00, 67607.06it/s] 23%|       | 17493/75824 [00:00<00:01, 52896.93it/s] 28%|       | 21050/75824 [00:00<00:01, 46152.09it/s] 37%|      | 28253/75824 [00:00<00:00, 51431.03it/s] 51%|     | 38398/75824 [00:00<00:00, 60358.36it/s] 67%|   | 50553/75824 [00:00<00:00, 71095.44it/s] 78%|  | 59225/75824 [00:00<00:00, 75157.69it/s] 89%| | 67399/75824 [00:00<00:00, 67017.43it/s]100%|| 75824/75824 [00:01<00:00, 71505.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11004/75824 [00:00<00:00, 110037.22it/s] 30%|       | 22913/75824 [00:00<00:00, 112604.36it/s] 39%|      | 29733/75824 [00:00<00:00, 83429.87it/s]  47%|     | 35412/75824 [00:00<00:00, 72248.93it/s] 54%|    | 41126/75824 [00:00<00:00, 66937.73it/s] 66%|   | 50260/75824 [00:00<00:00, 72582.23it/s] 75%|  | 56928/75824 [00:00<00:00, 68402.66it/s] 88%| | 66713/75824 [00:00<00:00, 75189.06it/s] 98%|| 74182/75824 [00:01<00:00, 64330.19it/s]100%|| 75824/75824 [00:01<00:00, 74730.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6108/75824 [00:00<00:01, 60765.39it/s] 14%|        | 10348/75824 [00:00<00:01, 53776.20it/s] 22%|       | 16605/75824 [00:00<00:01, 56143.36it/s] 37%|      | 27720/75824 [00:00<00:00, 65931.08it/s] 48%|     | 36682/75824 [00:00<00:00, 71608.88it/s] 65%|   | 49016/75824 [00:00<00:00, 81915.53it/s] 81%|  | 61556/75824 [00:00<00:00, 91425.64it/s] 99%|| 75027/75824 [00:00<00:00, 101178.25it/s]100%|| 75824/75824 [00:00<00:00, 94176.76it/s] 
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11830/75824 [00:00<00:00, 118290.52it/s] 31%|       | 23316/75824 [00:00<00:00, 117239.73it/s] 47%|     | 35771/75824 [00:00<00:00, 119338.10it/s] 64%|   | 48230/75824 [00:00<00:00, 120864.02it/s] 80%|  | 60709/75824 [00:00<00:00, 122013.44it/s] 97%|| 73175/75824 [00:00<00:00, 122793.15it/s]100%|| 75824/75824 [00:00<00:00, 121995.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12500/75824 [00:00<00:00, 124996.25it/s] 33%|      | 24921/75824 [00:00<00:00, 124757.30it/s] 49%|     | 37350/75824 [00:00<00:00, 124615.71it/s] 65%|   | 49050/75824 [00:00<00:00, 122226.73it/s] 81%|  | 61479/75824 [00:00<00:00, 122837.22it/s] 98%|| 74032/75824 [00:00<00:00, 123632.44it/s]100%|| 75824/75824 [00:00<00:00, 123340.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10571/75824 [00:00<00:00, 105709.85it/s] 24%|       | 18291/75824 [00:00<00:00, 95165.51it/s]  40%|      | 30311/75824 [00:00<00:00, 101505.88it/s] 55%|    | 41987/75824 [00:00<00:00, 105644.79it/s] 72%|  | 54361/75824 [00:00<00:00, 110489.72it/s] 88%| | 66787/75824 [00:00<00:00, 112007.02it/s]100%|| 75824/75824 [00:00<00:00, 110252.52it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12539/75824 [00:00<00:00, 125382.65it/s] 26%|       | 19640/75824 [00:00<00:00, 101055.15it/s] 35%|      | 26534/75824 [00:00<00:00, 88661.70it/s]  49%|     | 37372/75824 [00:00<00:00, 93779.30it/s] 64%|   | 48452/75824 [00:00<00:00, 98308.31it/s] 78%|  | 59266/75824 [00:00<00:00, 101064.13it/s] 93%|| 70558/75824 [00:00<00:00, 104350.94it/s]100%|| 75824/75824 [00:00<00:00, 101793.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9165/75824 [00:00<00:00, 91648.12it/s] 19%|        | 14349/75824 [00:00<00:00, 74487.46it/s] 24%|       | 17981/75824 [00:00<00:01, 56631.52it/s] 32%|      | 24570/75824 [00:00<00:00, 59123.02it/s] 41%|      | 31002/75824 [00:00<00:00, 60591.07it/s] 48%|     | 36043/75824 [00:00<00:00, 50405.55it/s] 56%|    | 42420/75824 [00:00<00:00, 53787.20it/s] 63%|   | 47564/75824 [00:00<00:00, 51949.10it/s] 69%|   | 52608/75824 [00:00<00:00, 44930.77it/s] 78%|  | 59045/75824 [00:01<00:00, 49406.85it/s] 86%| | 65510/75824 [00:01<00:00, 53166.67it/s] 95%|| 72231/75824 [00:01<00:00, 56722.03it/s]100%|| 75824/75824 [00:01<00:00, 56283.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7488/75824 [00:00<00:00, 72993.75it/s] 26%|       | 19684/75824 [00:00<00:00, 82989.13it/s] 41%|     | 31364/75824 [00:00<00:00, 90880.52it/s] 56%|    | 42644/75824 [00:00<00:00, 95449.21it/s] 71%|   | 53950/75824 [00:00<00:00, 100128.04it/s] 87%| | 65763/75824 [00:00<00:00, 104923.89it/s]100%|| 75824/75824 [00:00<00:00, 110010.57it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12072/75824 [00:00<00:00, 120715.22it/s] 32%|      | 24245/75824 [00:00<00:00, 121017.22it/s] 47%|     | 35710/75824 [00:00<00:00, 119032.90it/s] 63%|   | 47993/75824 [00:00<00:00, 120144.91it/s] 77%|  | 58470/75824 [00:00<00:00, 112317.77it/s] 92%|| 70013/75824 [00:00<00:00, 113233.55it/s]100%|| 75824/75824 [00:00<00:00, 103731.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  5%|         | 4044/75824 [00:00<00:01, 39723.76it/s] 11%|         | 8332/75824 [00:00<00:01, 40620.20it/s] 17%|        | 12520/75824 [00:00<00:01, 40988.80it/s] 22%|       | 16715/75824 [00:00<00:01, 39868.74it/s] 28%|       | 20891/75824 [00:00<00:01, 40416.55it/s] 33%|      | 25333/75824 [00:00<00:01, 41539.14it/s] 44%|     | 33573/75824 [00:00<00:00, 48797.87it/s] 52%|    | 39517/75824 [00:00<00:00, 49011.91it/s] 66%|   | 49932/75824 [00:00<00:00, 58265.14it/s] 80%|  | 60476/75824 [00:01<00:00, 66291.92it/s] 95%|| 72042/75824 [00:01<00:00, 76026.56it/s]100%|| 75824/75824 [00:01<00:00, 64369.34it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 5985/75824 [00:00<00:01, 59849.91it/s] 24%|       | 18206/75824 [00:00<00:00, 70667.21it/s] 40%|      | 30120/75824 [00:00<00:00, 80491.44it/s] 56%|    | 42507/75824 [00:00<00:00, 89940.02it/s] 69%|   | 52674/75824 [00:00<00:00, 93078.09it/s] 81%| | 61755/75824 [00:00<00:00, 82746.48it/s] 98%|| 74019/75824 [00:00<00:00, 91694.16it/s]100%|| 75824/75824 [00:00<00:00, 100648.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10879/75824 [00:00<00:00, 108784.92it/s] 30%|       | 22465/75824 [00:00<00:00, 110814.82it/s] 45%|     | 34409/75824 [00:00<00:00, 113267.17it/s] 62%|   | 46931/75824 [00:00<00:00, 116605.30it/s] 78%|  | 59331/75824 [00:00<00:00, 118727.09it/s] 95%|| 71741/75824 [00:00<00:00, 120287.92it/s]100%|| 75824/75824 [00:00<00:00, 119605.83it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12189/75824 [00:00<00:00, 121881.40it/s] 32%|      | 24478/75824 [00:00<00:00, 122181.49it/s] 47%|     | 35966/75824 [00:00<00:00, 119893.48it/s] 64%|   | 48199/75824 [00:00<00:00, 120613.54it/s] 80%|  | 60542/75824 [00:00<00:00, 121442.01it/s] 94%|| 71647/75824 [00:00<00:00, 118120.59it/s]100%|| 75824/75824 [00:00<00:00, 116477.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6824/75824 [00:00<00:01, 67144.13it/s] 23%|       | 17187/75824 [00:00<00:00, 73156.92it/s] 28%|       | 21372/75824 [00:00<00:01, 53056.37it/s] 40%|      | 30217/75824 [00:00<00:00, 60294.22it/s] 47%|     | 35600/75824 [00:00<00:00, 57288.09it/s] 59%|    | 44842/75824 [00:00<00:00, 64661.82it/s] 75%|  | 56901/75824 [00:00<00:00, 75112.24it/s] 90%| | 68565/75824 [00:00<00:00, 84094.17it/s]100%|| 75824/75824 [00:00<00:00, 76506.71it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5194/75824 [00:00<00:01, 44915.84it/s] 20%|        | 15224/75824 [00:00<00:01, 53833.38it/s] 25%|       | 19177/75824 [00:00<00:01, 43498.69it/s] 32%|      | 24447/75824 [00:00<00:01, 45902.88it/s] 47%|     | 35806/75824 [00:00<00:00, 55894.88it/s] 58%|    | 44271/75824 [00:00<00:00, 62236.18it/s] 68%|   | 51229/75824 [00:00<00:00, 59492.10it/s] 83%| | 62993/75824 [00:00<00:00, 69849.66it/s] 99%|| 74895/75824 [00:00<00:00, 79730.93it/s]100%|| 75824/75824 [00:00<00:00, 77079.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10447/75824 [00:00<00:00, 104469.85it/s] 20%|        | 15219/75824 [00:00<00:00, 76984.00it/s]  27%|       | 20556/75824 [00:00<00:00, 67961.89it/s] 43%|     | 32407/75824 [00:00<00:00, 77933.72it/s] 59%|    | 44654/75824 [00:00<00:00, 87475.67it/s] 75%|  | 56850/75824 [00:00<00:00, 95583.07it/s] 91%| | 69126/75824 [00:00<00:00, 102382.21it/s]100%|| 75824/75824 [00:00<00:00, 100535.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11728/75824 [00:00<00:00, 117273.12it/s] 31%|       | 23224/75824 [00:00<00:00, 116567.22it/s] 41%|      | 31218/75824 [00:00<00:00, 102479.34it/s] 57%|    | 43219/75824 [00:00<00:00, 105715.00it/s] 69%|   | 52303/75824 [00:00<00:00, 100763.85it/s] 85%| | 64658/75824 [00:00<00:00, 106663.68it/s]100%|| 75824/75824 [00:00<00:00, 108479.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10699/75824 [00:00<00:00, 106983.47it/s] 29%|       | 21815/75824 [00:00<00:00, 105985.58it/s] 37%|      | 28136/75824 [00:00<00:00, 88097.34it/s]  53%|    | 39925/75824 [00:00<00:00, 95324.13it/s] 68%|   | 51546/75824 [00:00<00:00, 100755.96it/s] 83%| | 62836/75824 [00:00<00:00, 104115.26it/s] 98%|| 74095/75824 [00:00<00:00, 106519.43it/s]100%|| 75824/75824 [00:00<00:00, 102252.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12271/75824 [00:00<00:00, 122706.31it/s] 31%|       | 23538/75824 [00:00<00:00, 119512.33it/s] 44%|     | 33122/75824 [00:00<00:00, 111264.27it/s] 58%|    | 43715/75824 [00:00<00:00, 109607.88it/s] 72%|  | 54918/75824 [00:00<00:00, 110321.61it/s] 86%| | 65192/75824 [00:00<00:00, 107931.16it/s]100%|| 75824/75824 [00:00<00:00, 110614.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10977/75824 [00:00<00:00, 109765.39it/s] 30%|       | 22537/75824 [00:00<00:00, 111450.09it/s] 44%|     | 33462/75824 [00:00<00:00, 110779.48it/s] 58%|    | 43953/75824 [00:00<00:00, 108950.69it/s] 72%|  | 54353/75824 [00:00<00:00, 107414.74it/s] 84%| | 63314/75824 [00:00<00:00, 101369.44it/s] 95%|| 72239/75824 [00:00<00:00, 86774.05it/s] 100%|| 75824/75824 [00:00<00:00, 98266.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11296/75824 [00:00<00:00, 112952.30it/s] 31%|       | 23555/75824 [00:00<00:00, 115680.53it/s] 47%|     | 35972/75824 [00:00<00:00, 118102.32it/s] 64%|   | 48444/75824 [00:00<00:00, 120012.64it/s] 80%|  | 60941/75824 [00:00<00:00, 121456.31it/s] 97%|| 73471/75824 [00:00<00:00, 122582.83it/s]100%|| 75824/75824 [00:00<00:00, 121133.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6417/75824 [00:00<00:01, 64169.45it/s] 17%|        | 12863/75824 [00:00<00:01, 62493.26it/s] 22%|       | 16797/75824 [00:00<00:01, 53084.43it/s] 35%|      | 26499/75824 [00:00<00:00, 61429.30it/s] 49%|     | 37335/75824 [00:00<00:00, 70601.90it/s] 63%|   | 47834/75824 [00:00<00:00, 78294.75it/s] 74%|  | 55838/75824 [00:00<00:00, 78669.47it/s] 84%| | 63827/75824 [00:00<00:00, 76757.21it/s]100%|| 75824/75824 [00:00<00:00, 82463.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9057/75824 [00:00<00:00, 90565.55it/s] 27%|       | 20749/75824 [00:00<00:00, 96028.88it/s] 43%|     | 32590/75824 [00:00<00:00, 101801.03it/s] 53%|    | 39821/75824 [00:00<00:00, 75572.14it/s]  65%|   | 49540/75824 [00:00<00:00, 80975.45it/s] 75%|  | 56990/75824 [00:00<00:00, 72284.61it/s] 90%| | 68381/75824 [00:00<00:00, 81184.00it/s]100%|| 75824/75824 [00:00<00:00, 89466.53it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11760/75824 [00:00<00:00, 117599.83it/s] 31%|       | 23215/75824 [00:00<00:00, 116665.87it/s] 46%|     | 34516/75824 [00:00<00:00, 115542.27it/s] 60%|    | 45760/75824 [00:00<00:00, 114593.04it/s] 77%|  | 58255/75824 [00:00<00:00, 117513.07it/s] 90%| | 68052/75824 [00:00<00:00, 87700.60it/s] 100%|| 75824/75824 [00:00<00:00, 99875.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13714/75824 [00:00<00:00, 137138.50it/s] 34%|      | 25596/75824 [00:00<00:00, 131075.20it/s] 49%|     | 37159/75824 [00:00<00:00, 126021.78it/s] 65%|   | 48928/75824 [00:00<00:00, 123398.59it/s] 80%|  | 60656/75824 [00:00<00:00, 121495.70it/s] 93%|| 70556/75824 [00:00<00:00, 106689.19it/s]100%|| 75824/75824 [00:00<00:00, 109148.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7544/75824 [00:00<00:00, 75439.35it/s] 26%|       | 19915/75824 [00:00<00:00, 85440.49it/s] 42%|     | 31888/75824 [00:00<00:00, 93470.09it/s] 58%|    | 44279/75824 [00:00<00:00, 100082.95it/s] 75%|  | 56640/75824 [00:00<00:00, 106141.68it/s] 90%| | 68398/75824 [00:00<00:00, 109331.71it/s]100%|| 75824/75824 [00:00<00:00, 114298.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14663/75824 [00:00<00:00, 146628.39it/s] 33%|      | 25133/75824 [00:00<00:00, 130900.88it/s] 49%|     | 37272/75824 [00:00<00:00, 127893.60it/s] 60%|    | 45737/75824 [00:00<00:00, 110895.12it/s] 75%|  | 57031/75824 [00:00<00:00, 111498.67it/s] 90%| | 68585/75824 [00:00<00:00, 112679.85it/s]100%|| 75824/75824 [00:00<00:00, 115221.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11886/75824 [00:00<00:00, 118856.71it/s] 31%|       | 23583/75824 [00:00<00:00, 118283.60it/s] 39%|      | 29589/75824 [00:00<00:00, 90971.54it/s]  47%|     | 35767/75824 [00:00<00:00, 79676.34it/s] 59%|    | 44573/75824 [00:00<00:00, 82017.44it/s] 70%|   | 53028/75824 [00:00<00:00, 82043.27it/s] 82%| | 62289/75824 [00:00<00:00, 84950.03it/s] 98%|| 74566/75824 [00:00<00:00, 93599.41it/s]100%|| 75824/75824 [00:00<00:00, 93048.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7032/75824 [00:00<00:00, 70315.71it/s] 20%|        | 15081/75824 [00:00<00:00, 72575.59it/s] 28%|       | 21221/75824 [00:00<00:00, 68817.56it/s] 37%|      | 27741/75824 [00:00<00:00, 67690.50it/s] 52%|    | 39294/75824 [00:00<00:00, 75789.97it/s] 64%|   | 48488/75824 [00:00<00:00, 78382.02it/s] 74%|  | 55762/75824 [00:00<00:00, 73877.31it/s] 83%| | 62808/75824 [00:00<00:00, 67194.22it/s] 99%|| 75179/75824 [00:00<00:00, 77736.27it/s]100%|| 75824/75824 [00:00<00:00, 78544.49it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11217/75824 [00:00<00:00, 112169.04it/s] 24%|       | 18530/75824 [00:00<00:00, 96684.22it/s]  31%|       | 23669/75824 [00:00<00:00, 76463.76it/s] 47%|     | 35989/75824 [00:00<00:00, 86281.89it/s] 57%|    | 42994/75824 [00:00<00:00, 65310.61it/s] 65%|   | 49148/75824 [00:00<00:00, 54011.08it/s] 78%|  | 58975/75824 [00:00<00:00, 62448.76it/s] 87%| | 65747/75824 [00:00<00:00, 61272.07it/s] 97%|| 73271/75824 [00:01<00:00, 64884.56it/s]100%|| 75824/75824 [00:01<00:00, 67926.14it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 13064/75824 [00:00<00:00, 130634.21it/s] 22%|       | 16984/75824 [00:00<00:00, 72550.74it/s]  29%|       | 22363/75824 [00:00<00:00, 65676.88it/s] 38%|      | 28960/75824 [00:00<00:00, 65763.30it/s] 45%|     | 33937/75824 [00:00<00:00, 55000.10it/s] 56%|    | 42663/75824 [00:00<00:00, 61860.57it/s] 65%|   | 49328/75824 [00:00<00:00, 63017.12it/s] 74%|  | 56081/75824 [00:00<00:00, 63677.66it/s] 83%| | 62640/75824 [00:00<00:00, 64238.40it/s] 91%| | 68968/75824 [00:01<00:00, 61716.74it/s]100%|| 75824/75824 [00:01<00:00, 66599.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10418/75824 [00:00<00:00, 104177.86it/s] 29%|       | 22022/75824 [00:00<00:00, 107471.62it/s] 44%|     | 33599/75824 [00:00<00:00, 109833.21it/s] 61%|    | 45941/75824 [00:00<00:00, 113581.91it/s] 77%|  | 58437/75824 [00:00<00:00, 116770.44it/s] 94%|| 70934/75824 [00:00<00:00, 119114.45it/s]100%|| 75824/75824 [00:00<00:00, 118641.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12478/75824 [00:00<00:00, 124778.33it/s] 24%|       | 18262/75824 [00:00<00:00, 92617.16it/s]  36%|      | 27347/75824 [00:00<00:00, 92079.33it/s] 52%|    | 39698/75824 [00:00<00:00, 99689.76it/s] 68%|   | 51576/75824 [00:00<00:00, 104739.51it/s] 84%| | 63905/75824 [00:00<00:00, 109688.60it/s]100%|| 75824/75824 [00:00<00:00, 108823.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9013/75824 [00:00<00:00, 90124.50it/s] 24%|       | 18066/75824 [00:00<00:00, 90244.44it/s] 39%|      | 29322/75824 [00:00<00:00, 95949.96it/s] 51%|    | 38875/75824 [00:00<00:00, 95822.65it/s] 61%|    | 46363/75824 [00:00<00:00, 77746.23it/s] 73%|  | 55426/75824 [00:00<00:00, 81208.95it/s] 88%| | 67007/75824 [00:00<00:00, 89204.19it/s]100%|| 75824/75824 [00:00<00:00, 93067.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12235/75824 [00:00<00:00, 118016.13it/s] 24%|       | 18002/75824 [00:00<00:00, 85038.58it/s]  33%|      | 24874/75824 [00:00<00:00, 79382.07it/s] 39%|      | 29752/75824 [00:00<00:00, 60376.05it/s] 55%|    | 41927/75824 [00:00<00:00, 71132.92it/s] 64%|   | 48783/75824 [00:00<00:00, 69633.89it/s] 79%|  | 59657/75824 [00:00<00:00, 78054.23it/s] 95%|| 72007/75824 [00:00<00:00, 87738.78it/s]100%|| 75824/75824 [00:00<00:00, 86189.99it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7370/75824 [00:00<00:01, 56592.10it/s] 19%|        | 14769/75824 [00:00<00:01, 60886.26it/s] 35%|      | 26366/75824 [00:00<00:00, 71003.62it/s] 43%|     | 32231/75824 [00:00<00:00, 65582.49it/s] 54%|    | 41061/75824 [00:00<00:00, 71066.98it/s] 70%|   | 53289/75824 [00:00<00:00, 81278.75it/s] 86%| | 65232/75824 [00:00<00:00, 89891.29it/s]100%|| 75824/75824 [00:00<00:00, 91411.70it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12059/75824 [00:00<00:00, 120589.25it/s] 30%|       | 22869/75824 [00:00<00:00, 116548.84it/s] 44%|     | 33557/75824 [00:00<00:00, 113467.49it/s] 58%|    | 44197/75824 [00:00<00:00, 111249.29it/s] 72%|  | 54865/75824 [00:00<00:00, 109835.13it/s] 88%| | 66661/75824 [00:00<00:00, 112152.24it/s]100%|| 75824/75824 [00:00<00:00, 112967.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8948/75824 [00:00<00:00, 89474.11it/s] 26%|       | 19986/75824 [00:00<00:00, 94863.72it/s] 41%|      | 30975/75824 [00:00<00:00, 98919.78it/s] 57%|    | 43267/75824 [00:00<00:00, 105073.28it/s] 73%|  | 55325/75824 [00:00<00:00, 109289.53it/s] 86%| | 64920/75824 [00:00<00:00, 93616.51it/s]  97%|| 73741/75824 [00:00<00:00, 76345.58it/s]100%|| 75824/75824 [00:00<00:00, 88341.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7767/75824 [00:00<00:00, 77664.52it/s] 27%|       | 20403/75824 [00:00<00:00, 87816.10it/s] 43%|     | 32883/75824 [00:00<00:00, 96385.00it/s] 59%|    | 44942/75824 [00:00<00:00, 102560.69it/s] 76%|  | 57432/75824 [00:00<00:00, 108374.99it/s] 92%|| 69550/75824 [00:00<00:00, 111543.14it/s]100%|| 75824/75824 [00:00<00:00, 112811.73it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4635/75824 [00:00<00:01, 45078.71it/s] 13%|        | 9788/75824 [00:00<00:01, 46836.94it/s] 27%|       | 20431/75824 [00:00<00:00, 56018.29it/s] 41%|     | 31398/75824 [00:00<00:00, 65653.84it/s] 50%|     | 38078/75824 [00:00<00:00, 65239.92it/s] 62%|   | 46982/75824 [00:00<00:00, 70927.25it/s] 77%|  | 58728/75824 [00:00<00:00, 80492.76it/s] 93%|| 70576/75824 [00:00<00:00, 89058.67it/s]100%|| 75824/75824 [00:00<00:00, 88939.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10887/75824 [00:00<00:00, 108865.95it/s] 30%|       | 22615/75824 [00:00<00:00, 108755.07it/s] 40%|      | 30047/75824 [00:00<00:00, 95481.44it/s]  55%|    | 41569/75824 [00:00<00:00, 100652.51it/s] 67%|   | 50699/75824 [00:00<00:00, 97651.00it/s]  81%| | 61731/75824 [00:00<00:00, 100355.91it/s] 93%|| 70656/75824 [00:00<00:00, 94340.31it/s] 100%|| 75824/75824 [00:00<00:00, 99537.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12145/75824 [00:00<00:00, 121441.43it/s] 32%|      | 24242/75824 [00:00<00:00, 121297.65it/s] 48%|     | 36542/75824 [00:00<00:00, 121801.00it/s] 64%|   | 48850/75824 [00:00<00:00, 122179.77it/s] 81%|  | 61159/75824 [00:00<00:00, 122450.59it/s] 97%|| 73553/75824 [00:00<00:00, 122893.59it/s]100%|| 75824/75824 [00:00<00:00, 122027.73it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9358/75824 [00:00<00:00, 93573.62it/s] 26%|       | 20086/75824 [00:00<00:00, 97238.43it/s] 36%|      | 27104/75824 [00:00<00:00, 87156.61it/s] 46%|     | 35128/75824 [00:00<00:00, 83229.38it/s] 55%|    | 41398/75824 [00:00<00:00, 75520.65it/s] 69%|   | 52167/75824 [00:00<00:00, 82954.65it/s] 85%| | 64250/75824 [00:00<00:00, 91564.59it/s]100%|| 75824/75824 [00:00<00:00, 93967.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4875/75824 [00:00<00:01, 47342.19it/s] 17%|        | 12552/75824 [00:00<00:01, 53493.66it/s] 32%|      | 24320/75824 [00:00<00:00, 63959.18it/s] 40%|      | 30159/75824 [00:00<00:00, 51560.86it/s] 47%|     | 35311/75824 [00:00<00:00, 48016.14it/s] 62%|   | 47340/75824 [00:00<00:00, 58573.35it/s] 72%|  | 54937/75824 [00:00<00:00, 62893.33it/s] 82%| | 62118/75824 [00:00<00:00, 56538.92it/s] 91%| | 68756/75824 [00:01<00:00, 59169.93it/s] 99%|| 75227/75824 [00:01<00:00, 44860.63it/s]100%|| 75824/75824 [00:01<00:00, 58777.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7316/75824 [00:00<00:00, 73155.71it/s] 17%|        | 12838/75824 [00:00<00:00, 65873.98it/s] 28%|       | 21033/75824 [00:00<00:00, 69992.24it/s] 41%|     | 31295/75824 [00:00<00:00, 77050.58it/s] 50%|     | 37578/75824 [00:00<00:00, 70003.85it/s] 66%|   | 49823/75824 [00:00<00:00, 80324.26it/s] 82%| | 62038/75824 [00:00<00:00, 89519.66it/s] 98%|| 74312/75824 [00:00<00:00, 97429.98it/s]100%|| 75824/75824 [00:00<00:00, 91708.76it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12523/75824 [00:00<00:00, 125226.54it/s] 33%|      | 24882/75824 [00:00<00:00, 124728.56it/s] 46%|     | 35183/75824 [00:00<00:00, 117305.66it/s] 56%|    | 42763/75824 [00:00<00:00, 100753.25it/s] 73%|  | 55015/75824 [00:00<00:00, 106423.72it/s] 87%| | 65624/75824 [00:00<00:00, 106322.34it/s]100%|| 75824/75824 [00:00<00:00, 111010.55it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6883/75824 [00:00<00:01, 68826.95it/s] 17%|        | 12981/75824 [00:00<00:00, 66268.15it/s] 26%|       | 19661/75824 [00:00<00:00, 66425.94it/s] 35%|      | 26176/75824 [00:00<00:00, 66037.19it/s] 43%|     | 32951/75824 [00:00<00:00, 66541.42it/s] 52%|    | 39424/75824 [00:00<00:00, 65985.73it/s] 60%|    | 45220/75824 [00:00<00:00, 62557.24it/s] 68%|   | 51695/75824 [00:00<00:00, 63198.67it/s] 76%|  | 57649/75824 [00:00<00:00, 53709.70it/s] 83%| | 63011/75824 [00:01<00:00, 51599.60it/s] 90%| | 68587/75824 [00:01<00:00, 52780.70it/s] 97%|| 73880/75824 [00:01<00:00, 48233.44it/s]100%|| 75824/75824 [00:01<00:00, 56671.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7357/75824 [00:00<00:00, 73567.79it/s] 26%|       | 19622/75824 [00:00<00:00, 83604.08it/s] 40%|      | 30107/75824 [00:00<00:00, 89014.97it/s] 53%|    | 40117/75824 [00:00<00:00, 91765.05it/s] 63%|   | 47846/75824 [00:00<00:00, 70505.49it/s] 72%|  | 54629/75824 [00:00<00:00, 60105.43it/s] 88%| | 67016/75824 [00:00<00:00, 71082.20it/s]100%|| 75824/75824 [00:00<00:00, 85005.08it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12414/75824 [00:00<00:00, 124136.27it/s] 31%|      | 23834/75824 [00:00<00:00, 120978.40it/s] 48%|     | 36143/75824 [00:00<00:00, 121603.58it/s] 62%|   | 47292/75824 [00:00<00:00, 117485.52it/s] 78%|  | 59438/75824 [00:00<00:00, 118649.90it/s] 91%|| 69247/75824 [00:00<00:00, 98904.56it/s] 100%|| 75824/75824 [00:00<00:00, 109032.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11902/75824 [00:00<00:00, 119011.88it/s] 32%|      | 24221/75824 [00:00<00:00, 120233.53it/s] 48%|     | 36656/75824 [00:00<00:00, 121439.34it/s] 65%|   | 49095/75824 [00:00<00:00, 122309.60it/s] 81%| | 61655/75824 [00:00<00:00, 123277.90it/s] 98%|| 74247/75824 [00:00<00:00, 124056.23it/s]100%|| 75824/75824 [00:00<00:00, 123734.72it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11229/75824 [00:00<00:00, 112289.04it/s] 30%|       | 22691/75824 [00:00<00:00, 112975.55it/s] 46%|     | 34717/75824 [00:00<00:00, 115064.89it/s] 56%|    | 42766/75824 [00:00<00:00, 101927.31it/s] 73%|  | 55204/75824 [00:00<00:00, 107763.13it/s] 89%| | 67537/75824 [00:00<00:00, 112002.68it/s]100%|| 75824/75824 [00:00<00:00, 113644.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12497/75824 [00:00<00:00, 124960.88it/s] 33%|      | 24712/75824 [00:00<00:00, 124101.10it/s] 49%|     | 37044/75824 [00:00<00:00, 123863.36it/s] 62%|   | 46845/75824 [00:00<00:00, 114779.90it/s] 78%|  | 59230/75824 [00:00<00:00, 117357.14it/s] 94%|| 71624/75824 [00:00<00:00, 119256.85it/s]100%|| 75824/75824 [00:00<00:00, 119613.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5308/75824 [00:00<00:01, 53077.77it/s] 22%|       | 16535/75824 [00:00<00:00, 63050.07it/s] 38%|      | 28586/75824 [00:00<00:00, 73573.67it/s] 54%|    | 40949/75824 [00:00<00:00, 83745.70it/s] 70%|   | 53391/75824 [00:00<00:00, 92851.33it/s] 87%| | 65790/75824 [00:00<00:00, 100416.63it/s]100%|| 75824/75824 [00:00<00:00, 89402.67it/s] 
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8225/75824 [00:00<00:00, 82248.12it/s] 21%|        | 15931/75824 [00:00<00:00, 79119.26it/s] 27%|       | 20166/75824 [00:00<00:00, 61438.19it/s] 33%|      | 25101/75824 [00:00<00:00, 56733.44it/s] 48%|     | 36074/75824 [00:00<00:00, 66346.19it/s] 64%|   | 48377/75824 [00:00<00:00, 76986.70it/s] 74%|  | 56434/75824 [00:00<00:00, 64659.09it/s] 84%| | 63486/75824 [00:00<00:00, 62909.91it/s] 93%|| 70198/75824 [00:01<00:00, 52625.78it/s]100%|| 75824/75824 [00:01<00:00, 60998.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12528/75824 [00:00<00:00, 125278.33it/s] 33%|      | 24999/75824 [00:00<00:00, 125104.27it/s] 43%|     | 32574/75824 [00:00<00:00, 104441.67it/s] 52%|    | 39296/75824 [00:00<00:00, 66165.83it/s]  68%|   | 51539/75824 [00:00<00:00, 76746.47it/s] 84%| | 64043/75824 [00:00<00:00, 86803.84it/s]100%|| 75824/75824 [00:00<00:00, 96832.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11598/75824 [00:00<00:00, 115974.58it/s] 29%|       | 22161/75824 [00:00<00:00, 112662.33it/s] 43%|     | 32719/75824 [00:00<00:00, 110438.96it/s] 57%|    | 43590/75824 [00:00<00:00, 109913.92it/s] 73%|  | 55353/75824 [00:00<00:00, 112118.52it/s] 85%| | 64639/75824 [00:00<00:00, 89639.12it/s] 100%|| 75824/75824 [00:00<00:00, 102282.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12306/75824 [00:00<00:00, 123058.36it/s] 26%|       | 19459/75824 [00:00<00:00, 101186.32it/s] 41%|     | 31382/75824 [00:00<00:00, 105998.68it/s] 55%|    | 41820/75824 [00:00<00:00, 104399.90it/s] 66%|   | 49668/75824 [00:00<00:00, 87812.37it/s]  82%| | 62078/75824 [00:00<00:00, 96254.94it/s] 96%|| 72644/75824 [00:00<00:00, 98894.99it/s]100%|| 75824/75824 [00:00<00:00, 100801.75it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9439/75824 [00:00<00:00, 94387.61it/s] 29%|       | 21661/75824 [00:00<00:00, 101308.58it/s] 43%|     | 32698/75824 [00:00<00:00, 103865.88it/s] 58%|    | 44045/75824 [00:00<00:00, 106571.56it/s] 73%|  | 55210/75824 [00:00<00:00, 108045.49it/s] 88%| | 66985/75824 [00:00<00:00, 110782.05it/s]100%|| 75824/75824 [00:00<00:00, 112284.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11326/75824 [00:00<00:00, 113253.09it/s] 29%|       | 22119/75824 [00:00<00:00, 111600.55it/s] 44%|     | 33738/75824 [00:00<00:00, 112937.95it/s] 60%|    | 45336/75824 [00:00<00:00, 113833.62it/s] 72%|  | 54584/75824 [00:00<00:00, 105395.83it/s] 87%| | 66086/75824 [00:00<00:00, 108107.83it/s]100%|| 75673/75824 [00:00<00:00, 98578.47it/s] 100%|| 75824/75824 [00:00<00:00, 104440.52it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7184/75824 [00:00<00:00, 71838.01it/s] 21%|       | 16233/75824 [00:00<00:00, 76572.96it/s] 35%|      | 26290/75824 [00:00<00:00, 80238.74it/s] 45%|     | 34057/75824 [00:00<00:00, 79450.36it/s] 60%|    | 45363/75824 [00:00<00:00, 87229.58it/s] 75%|  | 56915/75824 [00:00<00:00, 94145.12it/s] 90%| | 68287/75824 [00:00<00:00, 99270.87it/s]100%|| 75824/75824 [00:00<00:00, 97825.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9622/75824 [00:00<00:00, 96211.60it/s] 28%|       | 21070/75824 [00:00<00:00, 101049.04it/s] 43%|     | 32493/75824 [00:00<00:00, 104672.23it/s] 58%|    | 44167/75824 [00:00<00:00, 108021.95it/s] 73%|  | 55708/75824 [00:00<00:00, 110134.42it/s] 89%| | 67438/75824 [00:00<00:00, 112189.11it/s]100%|| 75824/75824 [00:00<00:00, 112788.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12065/75824 [00:00<00:00, 120643.79it/s] 32%|      | 24101/75824 [00:00<00:00, 120557.34it/s] 48%|     | 36105/75824 [00:00<00:00, 120397.82it/s] 62%|   | 46685/75824 [00:00<00:00, 115611.35it/s] 78%|  | 59067/75824 [00:00<00:00, 117955.37it/s] 91%| | 68875/75824 [00:00<00:00, 102428.24it/s]100%|| 75824/75824 [00:00<00:00, 102324.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5172/75824 [00:00<00:01, 49516.97it/s] 18%|        | 13610/75824 [00:00<00:01, 56522.69it/s] 33%|      | 25118/75824 [00:00<00:00, 66704.53it/s] 47%|     | 35911/75824 [00:00<00:00, 74754.33it/s] 61%|    | 46252/75824 [00:00<00:00, 81531.44it/s] 75%|  | 56823/75824 [00:00<00:00, 87537.44it/s] 87%| | 65799/75824 [00:00<00:00, 88191.10it/s] 99%|| 74732/75824 [00:00<00:00, 74760.10it/s]100%|| 75824/75824 [00:00<00:00, 85868.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12166/75824 [00:00<00:00, 121656.06it/s] 28%|       | 21552/75824 [00:00<00:00, 109610.90it/s] 37%|      | 28055/75824 [00:00<00:00, 90911.96it/s]  52%|    | 39646/75824 [00:00<00:00, 97200.62it/s] 69%|   | 52048/75824 [00:00<00:00, 103942.84it/s] 82%| | 62245/75824 [00:00<00:00, 103342.60it/s] 97%|| 73808/75824 [00:00<00:00, 105332.07it/s]100%|| 75824/75824 [00:00<00:00, 104289.11it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12388/75824 [00:00<00:00, 123872.14it/s] 32%|      | 24167/75824 [00:00<00:00, 121980.97it/s] 48%|     | 36432/75824 [00:00<00:00, 122178.68it/s] 69%|   | 52244/75824 [00:00<00:00, 131119.47it/s] 93%|| 70375/75824 [00:00<00:00, 142993.01it/s]100%|| 75824/75824 [00:00<00:00, 143352.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20204/75824 [00:00<00:00, 202032.97it/s] 51%|     | 38369/75824 [00:00<00:00, 195452.27it/s] 75%|  | 57077/75824 [00:00<00:00, 192860.16it/s] 99%|| 74783/75824 [00:00<00:00, 187831.52it/s]100%|| 75824/75824 [00:00<00:00, 186784.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|       | 17596/75824 [00:00<00:00, 175955.97it/s] 44%|     | 33527/75824 [00:00<00:00, 170604.42it/s] 60%|    | 45750/75824 [00:00<00:00, 152493.91it/s] 73%|  | 55349/75824 [00:00<00:00, 122538.36it/s] 95%|| 72038/75824 [00:00<00:00, 133154.11it/s]100%|| 75824/75824 [00:00<00:00, 141862.24it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19745/75824 [00:00<00:00, 197445.01it/s] 48%|     | 36736/75824 [00:00<00:00, 188287.06it/s] 73%|  | 55549/75824 [00:00<00:00, 188236.74it/s] 89%| | 67663/75824 [00:00<00:00, 112409.17it/s]100%|| 75824/75824 [00:00<00:00, 109586.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18946/75824 [00:00<00:00, 189446.63it/s] 34%|      | 25788/75824 [00:00<00:00, 123765.16it/s] 55%|    | 41795/75824 [00:00<00:00, 132800.20it/s] 81%|  | 61183/75824 [00:00<00:00, 146659.80it/s] 97%|| 73316/75824 [00:00<00:00, 101410.08it/s]100%|| 75824/75824 [00:00<00:00, 117218.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18340/75824 [00:00<00:00, 183393.18it/s] 35%|      | 26648/75824 [00:00<00:00, 131663.81it/s] 47%|     | 35261/75824 [00:00<00:00, 104275.63it/s] 56%|    | 42309/75824 [00:00<00:00, 91160.93it/s]  85%| | 64534/75824 [00:00<00:00, 110759.57it/s]100%|| 75824/75824 [00:00<00:00, 130782.34it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12493/75824 [00:00<00:00, 124921.78it/s] 27%|       | 20202/75824 [00:00<00:00, 105317.53it/s] 36%|      | 27511/75824 [00:00<00:00, 93013.64it/s]  61%|    | 45924/75824 [00:00<00:00, 109228.75it/s] 85%| | 64788/75824 [00:00<00:00, 125016.68it/s]100%|| 75824/75824 [00:00<00:00, 135991.56it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20288/75824 [00:00<00:00, 202876.81it/s] 43%|     | 32325/75824 [00:00<00:00, 168272.99it/s] 71%|  | 54125/75824 [00:00<00:00, 180633.48it/s]100%|| 75824/75824 [00:00<00:00, 192634.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21165/75824 [00:00<00:00, 211648.69it/s] 57%|    | 43421/75824 [00:00<00:00, 214805.46it/s] 87%| | 66140/75824 [00:00<00:00, 218374.80it/s]100%|| 75824/75824 [00:00<00:00, 221563.02it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|       | 21989/75824 [00:00<00:00, 219886.02it/s] 59%|    | 45024/75824 [00:00<00:00, 222922.68it/s] 89%| | 67634/75824 [00:00<00:00, 223864.62it/s]100%|| 75824/75824 [00:00<00:00, 225902.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19250/75824 [00:00<00:00, 192492.84it/s] 46%|     | 34632/75824 [00:00<00:00, 178989.74it/s] 65%|   | 49426/75824 [00:00<00:00, 168384.13it/s] 84%| | 63770/75824 [00:00<00:00, 160033.14it/s]100%|| 75824/75824 [00:00<00:00, 157921.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19981/75824 [00:00<00:00, 199803.05it/s] 54%|    | 40943/75824 [00:00<00:00, 202649.84it/s] 82%| | 62323/75824 [00:00<00:00, 205868.20it/s]100%|| 75824/75824 [00:00<00:00, 208768.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19779/75824 [00:00<00:00, 197781.70it/s] 43%|     | 32242/75824 [00:00<00:00, 168165.85it/s] 69%|   | 52025/75824 [00:00<00:00, 176086.82it/s] 96%|| 72597/75824 [00:00<00:00, 184038.65it/s]100%|| 75824/75824 [00:00<00:00, 182692.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20201/75824 [00:00<00:00, 202009.23it/s] 54%|    | 40978/75824 [00:00<00:00, 203702.27it/s] 82%| | 62113/75824 [00:00<00:00, 205937.32it/s]100%|| 75824/75824 [00:00<00:00, 208469.86it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21245/75824 [00:00<00:00, 212444.63it/s] 58%|    | 43861/75824 [00:00<00:00, 214713.97it/s] 87%| | 65637/75824 [00:00<00:00, 215616.11it/s]100%|| 75824/75824 [00:00<00:00, 216997.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10985/75824 [00:00<00:00, 109844.87it/s] 35%|      | 26685/75824 [00:00<00:00, 120721.78it/s] 62%|   | 47101/75824 [00:00<00:00, 137591.04it/s] 86%| | 65403/75824 [00:00<00:00, 148659.31it/s]100%|| 75824/75824 [00:00<00:00, 168839.21it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13953/75824 [00:00<00:00, 139526.81it/s] 44%|     | 33159/75824 [00:00<00:00, 151999.02it/s] 69%|   | 52101/75824 [00:00<00:00, 161571.72it/s] 84%| | 63868/75824 [00:00<00:00, 138549.47it/s]100%|| 75824/75824 [00:00<00:00, 162035.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 20030/75824 [00:00<00:00, 200294.46it/s] 53%|    | 39853/75824 [00:00<00:00, 199669.82it/s] 80%|  | 60641/75824 [00:00<00:00, 202062.61it/s]100%|| 75824/75824 [00:00<00:00, 200118.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16455/75824 [00:00<00:00, 164548.98it/s] 42%|     | 32084/75824 [00:00<00:00, 161980.51it/s] 59%|    | 44588/75824 [00:00<00:00, 148791.04it/s] 75%|  | 57228/75824 [00:00<00:00, 141280.93it/s] 95%|| 72361/75824 [00:00<00:00, 144151.53it/s]100%|| 75824/75824 [00:00<00:00, 145090.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11353/75824 [00:00<00:00, 113528.75it/s] 29%|       | 21912/75824 [00:00<00:00, 111022.66it/s] 48%|     | 36242/75824 [00:00<00:00, 119068.07it/s] 59%|    | 44428/75824 [00:00<00:00, 92513.37it/s]  69%|   | 51984/75824 [00:00<00:00, 77574.46it/s] 79%|  | 59979/75824 [00:00<00:00, 78270.93it/s] 89%| | 67263/75824 [00:00<00:00, 75164.10it/s] 98%|| 74426/75824 [00:00<00:00, 64180.83it/s]100%|| 75824/75824 [00:00<00:00, 81102.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9126/75824 [00:00<00:00, 91257.26it/s] 17%|        | 13196/75824 [00:00<00:00, 66481.95it/s] 36%|      | 26994/75824 [00:00<00:00, 78718.67it/s] 55%|    | 41389/75824 [00:00<00:00, 86346.68it/s] 65%|   | 49172/75824 [00:00<00:00, 79172.91it/s] 75%|  | 56609/75824 [00:00<00:00, 69825.01it/s] 90%| | 68430/75824 [00:00<00:00, 79598.10it/s]100%|| 75824/75824 [00:00<00:00, 83763.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11952/75824 [00:00<00:00, 116934.85it/s] 20%|        | 15461/75824 [00:00<00:00, 63419.51it/s]  37%|      | 28180/75824 [00:00<00:00, 74647.05it/s] 56%|    | 42668/75824 [00:00<00:00, 87349.45it/s] 75%|  | 57214/75824 [00:00<00:00, 99242.56it/s] 95%|| 71846/75824 [00:00<00:00, 109843.80it/s]100%|| 75824/75824 [00:00<00:00, 117819.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16365/75824 [00:00<00:00, 163643.13it/s] 45%|     | 34268/75824 [00:00<00:00, 167972.71it/s] 69%|   | 52093/75824 [00:00<00:00, 170929.08it/s] 92%|| 69418/75824 [00:00<00:00, 171618.12it/s]100%|| 75824/75824 [00:00<00:00, 169119.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 15304/75824 [00:00<00:00, 153031.75it/s] 40%|      | 30245/75824 [00:00<00:00, 151925.75it/s] 59%|    | 44424/75824 [00:00<00:00, 148733.88it/s] 78%|  | 59254/75824 [00:00<00:00, 148603.17it/s] 98%|| 74570/75824 [00:00<00:00, 149940.07it/s]100%|| 75824/75824 [00:00<00:00, 149126.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6438/75824 [00:00<00:01, 64379.75it/s] 24%|       | 18373/75824 [00:00<00:00, 74701.05it/s] 40%|      | 30473/75824 [00:00<00:00, 84386.94it/s] 56%|    | 42301/75824 [00:00<00:00, 92322.71it/s] 70%|   | 53196/75824 [00:00<00:00, 96752.04it/s] 85%| | 64340/75824 [00:00<00:00, 100734.46it/s] 98%|| 74139/75824 [00:00<00:00, 79100.26it/s] 100%|| 75824/75824 [00:00<00:00, 93352.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12019/75824 [00:00<00:00, 120182.95it/s] 36%|      | 27032/75824 [00:00<00:00, 127832.16it/s] 56%|    | 42203/75824 [00:00<00:00, 134166.88it/s] 70%|   | 53406/75824 [00:00<00:00, 126654.28it/s] 86%| | 64892/75824 [00:00<00:00, 122866.58it/s] 99%|| 75338/75824 [00:00<00:00, 116695.96it/s]100%|| 75824/75824 [00:00<00:00, 125484.20it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11953/75824 [00:00<00:00, 119522.70it/s] 29%|       | 22072/75824 [00:00<00:00, 113358.67it/s] 44%|     | 33351/75824 [00:00<00:00, 113186.04it/s] 59%|    | 44730/75824 [00:00<00:00, 113364.33it/s] 72%|  | 54968/75824 [00:00<00:00, 109827.10it/s] 85%| | 64160/75824 [00:00<00:00, 102691.78it/s] 96%|| 73150/75824 [00:00<00:00, 85052.73it/s] 100%|| 75824/75824 [00:00<00:00, 94177.24it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6942/75824 [00:00<00:01, 63423.40it/s] 17%|        | 12754/75824 [00:00<00:01, 61691.07it/s] 25%|       | 18794/75824 [00:00<00:00, 61296.40it/s] 32%|      | 23910/75824 [00:00<00:00, 57857.27it/s] 37%|      | 28219/75824 [00:00<00:01, 45197.54it/s] 45%|     | 34120/75824 [00:00<00:00, 47824.65it/s] 53%|    | 40224/75824 [00:00<00:00, 50843.88it/s] 59%|    | 45093/75824 [00:00<00:00, 50090.04it/s] 66%|   | 49954/75824 [00:00<00:00, 48290.67it/s] 74%|  | 55961/75824 [00:01<00:00, 51308.21it/s] 81%|  | 61081/75824 [00:01<00:00, 46988.71it/s] 87%| | 65904/75824 [00:01<00:00, 47138.28it/s] 95%|| 72168/75824 [00:01<00:00, 50917.61it/s]100%|| 75824/75824 [00:01<00:00, 50689.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  4%|         | 3368/75824 [00:00<00:02, 29397.45it/s]  8%|         | 6242/75824 [00:00<00:02, 28486.93it/s] 11%|         | 8370/75824 [00:00<00:02, 25859.14it/s] 15%|        | 11459/75824 [00:00<00:02, 27187.40it/s] 19%|        | 14393/75824 [00:00<00:02, 27799.11it/s] 23%|       | 17549/75824 [00:00<00:02, 28239.89it/s] 27%|       | 20801/75824 [00:00<00:01, 28954.13it/s] 32%|      | 23920/75824 [00:00<00:01, 29430.03it/s] 36%|      | 27147/75824 [00:00<00:01, 29493.41it/s] 41%|      | 30901/75824 [00:01<00:01, 31398.88it/s] 46%|     | 35071/75824 [00:01<00:01, 33911.10it/s] 51%|    | 38951/75824 [00:01<00:01, 34215.17it/s] 57%|    | 42897/75824 [00:01<00:00, 35635.99it/s] 61%|   | 46577/75824 [00:01<00:00, 35976.84it/s] 67%|   | 50566/75824 [00:01<00:00, 36506.59it/s] 72%|  | 54623/75824 [00:01<00:00, 37636.91it/s] 77%|  | 58515/75824 [00:01<00:00, 37477.00it/s] 82%| | 62373/75824 [00:01<00:00, 36614.01it/s] 87%| | 66286/75824 [00:01<00:00, 36631.15it/s] 93%|| 70328/75824 [00:02<00:00, 37309.28it/s] 98%|| 74338/75824 [00:02<00:00, 38104.28it/s]100%|| 75824/75824 [00:02<00:00, 33938.24it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11486/75824 [00:00<00:00, 114856.55it/s] 26%|       | 19659/75824 [00:00<00:00, 102403.31it/s] 39%|      | 29515/75824 [00:00<00:00, 100520.73it/s] 51%|     | 38662/75824 [00:00<00:00, 97620.51it/s]  66%|   | 49910/75824 [00:00<00:00, 101647.62it/s] 80%|  | 60725/75824 [00:00<00:00, 103514.12it/s] 92%|| 69836/75824 [00:00<00:00, 90791.65it/s] 100%|| 75824/75824 [00:00<00:00, 96261.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10828/75824 [00:00<00:00, 108277.01it/s] 30%|       | 22556/75824 [00:00<00:00, 107827.57it/s] 37%|      | 28034/75824 [00:00<00:00, 76833.59it/s]  53%|    | 40233/75824 [00:00<00:00, 86430.46it/s] 67%|   | 50582/75824 [00:00<00:00, 90925.93it/s] 84%| | 63513/75824 [00:00<00:00, 99813.96it/s]100%|| 75824/75824 [00:00<00:00, 104247.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5509/75824 [00:00<00:01, 50428.13it/s] 13%|        | 9671/75824 [00:00<00:01, 46978.56it/s] 20%|        | 15320/75824 [00:00<00:01, 49477.24it/s] 28%|       | 20936/75824 [00:00<00:01, 51308.34it/s] 35%|      | 26468/75824 [00:00<00:00, 52054.21it/s] 42%|     | 32210/75824 [00:00<00:00, 52196.01it/s] 49%|     | 36871/75824 [00:00<00:00, 49267.56it/s] 55%|    | 41441/75824 [00:00<00:00, 45168.13it/s] 60%|    | 45775/75824 [00:00<00:00, 42754.78it/s] 66%|   | 49949/75824 [00:01<00:00, 39345.77it/s] 71%|   | 53866/75824 [00:01<00:00, 35013.50it/s] 76%|  | 57927/75824 [00:01<00:00, 36523.34it/s] 83%| | 62723/75824 [00:01<00:00, 39337.30it/s] 89%| | 67409/75824 [00:01<00:00, 41326.74it/s] 96%|| 72461/75824 [00:01<00:00, 43711.94it/s]100%|| 75824/75824 [00:01<00:00, 43926.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  4%|         | 2995/75824 [00:00<00:02, 29949.31it/s]  9%|         | 6663/75824 [00:00<00:02, 31062.78it/s] 15%|        | 11548/75824 [00:00<00:01, 34541.65it/s] 20%|        | 15485/75824 [00:00<00:01, 35800.51it/s] 28%|       | 21191/75824 [00:00<00:01, 40305.27it/s] 36%|      | 27139/75824 [00:00<00:01, 43814.09it/s] 41%|     | 31440/75824 [00:00<00:01, 41539.73it/s] 48%|     | 36017/75824 [00:00<00:00, 41964.31it/s] 53%|    | 40565/75824 [00:00<00:00, 41829.33it/s] 59%|    | 44816/75824 [00:01<00:00, 42029.93it/s] 65%|   | 49257/75824 [00:01<00:00, 42715.54it/s] 71%|   | 53525/75824 [00:01<00:00, 42197.02it/s] 76%|  | 57795/75824 [00:01<00:00, 42337.49it/s] 82%| | 62399/75824 [00:01<00:00, 43382.78it/s] 88%| | 66743/75824 [00:01<00:00, 36641.60it/s] 94%|| 71032/75824 [00:01<00:00, 38315.52it/s] 99%|| 75012/75824 [00:01<00:00, 37435.91it/s]100%|| 75824/75824 [00:01<00:00, 40909.57it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11454/75824 [00:00<00:00, 114534.37it/s] 25%|       | 19318/75824 [00:00<00:00, 99292.56it/s]  32%|      | 24047/75824 [00:00<00:00, 74659.33it/s] 45%|     | 33831/75824 [00:00<00:00, 80371.17it/s] 56%|    | 42332/75824 [00:00<00:00, 79175.02it/s] 68%|   | 51312/75824 [00:00<00:00, 82088.02it/s] 83%| | 63008/75824 [00:00<00:00, 90150.20it/s] 95%|| 71661/75824 [00:00<00:00, 86185.12it/s]100%|| 75824/75824 [00:00<00:00, 83792.02it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5536/75824 [00:00<00:01, 46252.84it/s] 13%|        | 9582/75824 [00:00<00:01, 43573.74it/s] 16%|        | 12406/75824 [00:00<00:01, 37461.82it/s] 21%|        | 16018/75824 [00:00<00:01, 35662.76it/s] 25%|       | 19114/75824 [00:00<00:01, 31006.38it/s] 29%|       | 21747/75824 [00:00<00:01, 27874.06it/s] 32%|      | 24599/75824 [00:00<00:01, 28064.00it/s] 38%|      | 28548/75824 [00:00<00:01, 29266.14it/s] 42%|     | 31831/75824 [00:01<00:01, 30250.69it/s] 48%|     | 36382/75824 [00:01<00:01, 33633.60it/s] 56%|    | 42159/75824 [00:01<00:00, 37739.48it/s] 61%|    | 46305/75824 [00:01<00:00, 36749.89it/s] 66%|   | 50125/75824 [00:01<00:00, 33591.69it/s] 73%|  | 55215/75824 [00:01<00:00, 36305.36it/s] 80%|  | 60825/75824 [00:01<00:00, 40602.71it/s] 86%| | 65169/75824 [00:01<00:00, 39273.89it/s] 98%|| 74169/75824 [00:01<00:00, 47265.85it/s]100%|| 75824/75824 [00:01<00:00, 39516.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7710/75824 [00:00<00:00, 77098.05it/s] 22%|       | 16598/75824 [00:00<00:00, 80289.33it/s] 33%|      | 25247/75824 [00:00<00:00, 82053.09it/s] 43%|     | 32690/75824 [00:00<00:00, 78104.92it/s] 51%|     | 38713/75824 [00:00<00:00, 68210.09it/s] 60%|    | 45406/75824 [00:00<00:00, 67319.20it/s] 70%|   | 53164/75824 [00:00<00:00, 70098.43it/s] 79%|  | 59703/75824 [00:00<00:00, 61398.24it/s] 90%| | 68116/75824 [00:00<00:00, 66812.66it/s]100%|| 75824/75824 [00:01<00:00, 72142.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4445/75824 [00:00<00:01, 44448.45it/s] 11%|        | 8561/75824 [00:00<00:01, 43407.79it/s] 16%|        | 12500/75824 [00:00<00:01, 42018.37it/s] 22%|       | 16852/75824 [00:00<00:01, 42456.87it/s] 28%|       | 21076/75824 [00:00<00:01, 41398.92it/s] 33%|      | 25313/75824 [00:00<00:01, 41296.60it/s] 39%|      | 29674/75824 [00:00<00:01, 41963.49it/s] 45%|     | 34018/75824 [00:00<00:00, 42394.63it/s] 50%|     | 38039/75824 [00:00<00:00, 41102.46it/s] 56%|    | 42291/75824 [00:01<00:00, 38837.26it/s] 61%|    | 46085/75824 [00:01<00:00, 34354.30it/s] 68%|   | 51684/75824 [00:01<00:00, 38236.16it/s] 74%|  | 56403/75824 [00:01<00:00, 40128.21it/s] 81%|  | 61129/75824 [00:01<00:00, 42030.95it/s] 97%|| 73500/75824 [00:01<00:00, 52412.28it/s]100%|| 75824/75824 [00:01<00:00, 47067.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11081/75824 [00:00<00:00, 110801.92it/s] 31%|       | 23352/75824 [00:00<00:00, 114122.45it/s] 43%|     | 32911/75824 [00:00<00:00, 107847.96it/s] 53%|    | 39985/75824 [00:00<00:00, 91527.06it/s]  68%|   | 51616/75824 [00:00<00:00, 97776.07it/s] 79%|  | 59992/75824 [00:00<00:00, 89474.06it/s] 90%| | 68096/75824 [00:00<00:00, 86328.80it/s]100%|| 75824/75824 [00:00<00:00, 96935.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11253/75824 [00:00<00:00, 112523.13it/s] 31%|      | 23695/75824 [00:00<00:00, 115843.97it/s] 45%|     | 34222/75824 [00:00<00:00, 110784.68it/s] 55%|    | 41505/75824 [00:00<00:00, 87513.99it/s]  68%|   | 51850/75824 [00:00<00:00, 91752.57it/s] 84%| | 63625/75824 [00:00<00:00, 98260.43it/s]100%|| 75824/75824 [00:00<00:00, 104377.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11091/75824 [00:00<00:00, 110907.46it/s] 29%|       | 22235/75824 [00:00<00:00, 111064.58it/s] 44%|     | 33103/75824 [00:00<00:00, 110336.08it/s] 58%|    | 44122/75824 [00:00<00:00, 109207.83it/s] 69%|   | 52384/75824 [00:00<00:00, 86798.08it/s]  84%| | 63616/75824 [00:00<00:00, 93146.09it/s] 96%|| 72527/75824 [00:00<00:00, 91896.13it/s]100%|| 75824/75824 [00:00<00:00, 98034.56it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9506/75824 [00:00<00:00, 83002.10it/s] 19%|        | 14608/75824 [00:00<00:00, 69863.40it/s] 36%|      | 26963/75824 [00:00<00:00, 80335.49it/s] 51%|    | 38901/75824 [00:00<00:00, 89074.67it/s] 64%|   | 48408/75824 [00:00<00:00, 90791.81it/s] 77%|  | 58615/75824 [00:00<00:00, 93904.19it/s] 93%|| 70767/75824 [00:00<00:00, 100774.08it/s]100%|| 75824/75824 [00:00<00:00, 100382.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12021/75824 [00:00<00:00, 120207.82it/s] 27%|       | 20373/75824 [00:00<00:00, 105933.84it/s] 41%|      | 30973/75824 [00:00<00:00, 105952.80it/s] 53%|    | 39873/75824 [00:00<00:00, 100222.05it/s] 62%|   | 47225/75824 [00:00<00:00, 83032.64it/s]  76%|  | 57785/75824 [00:00<00:00, 88720.65it/s] 88%| | 66684/75824 [00:00<00:00, 87834.74it/s] 99%|| 74871/75824 [00:00<00:00, 85102.10it/s]100%|| 75824/75824 [00:00<00:00, 90279.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5227/75824 [00:00<00:01, 52266.69it/s] 21%|        | 15692/75824 [00:00<00:00, 61501.52it/s] 36%|      | 27666/75824 [00:00<00:00, 72008.02it/s] 52%|    | 39579/75824 [00:00<00:00, 81702.79it/s] 68%|   | 51278/75824 [00:00<00:00, 89829.88it/s] 84%| | 63782/75824 [00:00<00:00, 98118.36it/s]100%|| 75760/75824 [00:00<00:00, 103745.23it/s]100%|| 75824/75824 [00:00<00:00, 108176.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12310/75824 [00:00<00:00, 123095.13it/s] 32%|      | 24441/75824 [00:00<00:00, 122552.72it/s] 48%|     | 36456/75824 [00:00<00:00, 120745.29it/s] 63%|   | 47915/75824 [00:00<00:00, 118828.91it/s] 78%|  | 58898/75824 [00:00<00:00, 115976.92it/s] 94%|| 71463/75824 [00:00<00:00, 118716.55it/s]100%|| 75824/75824 [00:00<00:00, 118647.49it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9825/75824 [00:00<00:00, 98246.58it/s] 29%|       | 21772/75824 [00:00<00:00, 103774.66it/s] 44%|     | 33534/75824 [00:00<00:00, 107572.60it/s] 60%|    | 45604/75824 [00:00<00:00, 111199.81it/s] 76%|  | 57546/75824 [00:00<00:00, 113543.49it/s] 92%|| 69381/75824 [00:00<00:00, 114941.82it/s]100%|| 75824/75824 [00:00<00:00, 116063.44it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7941/75824 [00:00<00:00, 79404.59it/s] 27%|       | 20220/75824 [00:00<00:00, 88818.04it/s] 42%|     | 32110/75824 [00:00<00:00, 96112.05it/s] 59%|    | 44360/75824 [00:00<00:00, 102751.37it/s] 75%|  | 56592/75824 [00:00<00:00, 107930.33it/s] 90%| | 67992/75824 [00:00<00:00, 109680.18it/s]100%|| 75824/75824 [00:00<00:00, 114178.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9269/75824 [00:00<00:00, 92684.12it/s] 28%|       | 21389/75824 [00:00<00:00, 99721.45it/s] 42%|     | 32207/75824 [00:00<00:00, 102116.75it/s] 57%|    | 43334/75824 [00:00<00:00, 104699.71it/s] 70%|   | 53033/75824 [00:00<00:00, 96441.97it/s]  81%|  | 61319/75824 [00:00<00:00, 87355.22it/s] 96%|| 72846/75824 [00:00<00:00, 94197.69it/s]100%|| 75824/75824 [00:00<00:00, 99922.71it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12321/75824 [00:00<00:00, 123201.60it/s] 32%|      | 24466/75824 [00:00<00:00, 122669.28it/s] 49%|     | 36805/75824 [00:00<00:00, 122883.94it/s] 65%|   | 49117/75824 [00:00<00:00, 122953.65it/s] 81%| | 61662/75824 [00:00<00:00, 123689.30it/s] 98%|| 74200/75824 [00:00<00:00, 124190.77it/s]100%|| 75824/75824 [00:00<00:00, 123632.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9700/75824 [00:00<00:00, 96997.09it/s] 27%|       | 20271/75824 [00:00<00:00, 99454.55it/s] 40%|      | 30002/75824 [00:00<00:00, 98799.99it/s] 55%|    | 41849/75824 [00:00<00:00, 103978.05it/s] 71%|   | 53948/75824 [00:00<00:00, 108555.14it/s] 88%| | 66347/75824 [00:00<00:00, 112764.28it/s]100%|| 75824/75824 [00:00<00:00, 111503.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12231/75824 [00:00<00:00, 122304.28it/s] 32%|      | 24602/75824 [00:00<00:00, 122721.97it/s] 49%|     | 36913/75824 [00:00<00:00, 122836.93it/s] 65%|   | 49169/75824 [00:00<00:00, 122753.32it/s] 81%|  | 61423/75824 [00:00<00:00, 122686.12it/s] 97%|| 73599/75824 [00:00<00:00, 122404.82it/s]100%|| 75824/75824 [00:00<00:00, 122617.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12152/75824 [00:00<00:00, 121517.22it/s] 32%|      | 24410/75824 [00:00<00:00, 121832.42it/s] 48%|     | 36724/75824 [00:00<00:00, 122220.93it/s] 60%|    | 45707/75824 [00:00<00:00, 107218.57it/s] 71%|   | 53846/75824 [00:00<00:00, 90386.04it/s]  87%| | 65880/75824 [00:00<00:00, 97679.77it/s] 99%|| 74868/75824 [00:00<00:00, 90022.41it/s]100%|| 75824/75824 [00:00<00:00, 100137.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6051/75824 [00:00<00:01, 53363.95it/s] 20%|        | 14938/75824 [00:00<00:01, 60630.66it/s] 27%|       | 20426/75824 [00:00<00:00, 58781.49it/s] 43%|     | 32878/75824 [00:00<00:00, 69842.96it/s] 63%|   | 47620/75824 [00:00<00:00, 82935.07it/s] 79%|  | 59705/75824 [00:00<00:00, 91550.49it/s] 92%|| 69731/75824 [00:00<00:00, 74703.56it/s]100%|| 75824/75824 [00:00<00:00, 88538.73it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7345/75824 [00:00<00:00, 71357.48it/s] 14%|        | 10661/75824 [00:00<00:01, 52396.02it/s] 18%|        | 13663/75824 [00:00<00:01, 41387.12it/s] 28%|       | 21209/75824 [00:00<00:01, 47871.64it/s] 34%|      | 26111/75824 [00:00<00:01, 46731.36it/s] 41%|     | 31334/75824 [00:00<00:00, 45753.11it/s] 47%|     | 35561/75824 [00:00<00:00, 43218.73it/s] 61%|    | 46137/75824 [00:00<00:00, 52539.30it/s] 77%|  | 58570/75824 [00:00<00:00, 63546.98it/s] 94%|| 71012/75824 [00:01<00:00, 74478.03it/s]100%|| 75824/75824 [00:01<00:00, 69324.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9908/75824 [00:00<00:00, 99078.68it/s] 17%|        | 12881/75824 [00:00<00:01, 51495.06it/s] 28%|       | 20984/75824 [00:00<00:00, 57816.20it/s] 34%|      | 25948/75824 [00:00<00:00, 53529.58it/s] 44%|     | 33493/75824 [00:00<00:00, 58640.50it/s] 57%|    | 43210/75824 [00:00<00:00, 66556.54it/s] 66%|   | 49889/75824 [00:00<00:00, 63244.86it/s] 74%|  | 56264/75824 [00:00<00:00, 55826.65it/s] 90%| | 68354/75824 [00:00<00:00, 66576.40it/s]100%|| 75824/75824 [00:01<00:00, 68537.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12199/75824 [00:00<00:00, 121984.30it/s] 32%|      | 24620/75824 [00:00<00:00, 122643.54it/s] 49%|     | 37107/75824 [00:00<00:00, 123301.91it/s] 65%|   | 49549/75824 [00:00<00:00, 123633.94it/s] 82%| | 62087/75824 [00:00<00:00, 124151.61it/s] 98%|| 74624/75824 [00:00<00:00, 124512.46it/s]100%|| 75824/75824 [00:00<00:00, 123531.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12350/75824 [00:00<00:00, 123498.35it/s] 31%|       | 23288/75824 [00:00<00:00, 118891.50it/s] 41%|      | 30729/75824 [00:00<00:00, 100432.16it/s] 55%|    | 41574/75824 [00:00<00:00, 102708.91it/s] 65%|   | 49255/75824 [00:00<00:00, 87883.13it/s]  81%| | 61707/75824 [00:00<00:00, 96390.46it/s] 94%|| 71328/75824 [00:00<00:00, 96335.31it/s]100%|| 75824/75824 [00:00<00:00, 100633.81it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8568/75824 [00:00<00:00, 84093.76it/s] 21%|        | 15834/75824 [00:00<00:00, 80301.90it/s] 37%|      | 27721/75824 [00:00<00:00, 88960.78it/s] 49%|     | 37119/75824 [00:00<00:00, 89882.25it/s] 64%|   | 48385/75824 [00:00<00:00, 95685.06it/s] 78%|  | 59398/75824 [00:00<00:00, 99603.95it/s] 95%|| 71850/75824 [00:00<00:00, 105964.04it/s]100%|| 75824/75824 [00:00<00:00, 103024.83it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11089/75824 [00:00<00:00, 110882.17it/s] 30%|       | 22881/75824 [00:00<00:00, 112903.43it/s] 46%|     | 35176/75824 [00:00<00:00, 112257.90it/s] 62%|   | 47078/75824 [00:00<00:00, 114202.91it/s] 76%|  | 57752/75824 [00:00<00:00, 111856.25it/s] 92%|| 69633/75824 [00:00<00:00, 113853.69it/s]100%|| 75824/75824 [00:00<00:00, 114854.79it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12157/75824 [00:00<00:00, 121564.61it/s] 28%|       | 20985/75824 [00:00<00:00, 109208.59it/s] 41%|      | 31168/75824 [00:00<00:00, 106884.75it/s] 50%|     | 37864/75824 [00:00<00:00, 88158.35it/s]  59%|    | 44429/75824 [00:00<00:00, 73921.29it/s] 67%|   | 50635/75824 [00:00<00:00, 67858.81it/s] 75%|  | 56688/75824 [00:00<00:00, 64957.96it/s] 91%| | 68735/75824 [00:00<00:00, 75377.87it/s]100%|| 75824/75824 [00:00<00:00, 84518.86it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12383/75824 [00:00<00:00, 123824.21it/s] 33%|      | 24697/75824 [00:00<00:00, 123617.21it/s] 48%|     | 36557/75824 [00:00<00:00, 122066.54it/s] 59%|    | 44521/75824 [00:00<00:00, 90157.05it/s]  75%|  | 56990/75824 [00:00<00:00, 98325.43it/s] 92%|| 69426/75824 [00:00<00:00, 104914.19it/s]100%|| 75824/75824 [00:00<00:00, 109361.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12204/75824 [00:00<00:00, 122031.97it/s] 27%|       | 20135/75824 [00:00<00:00, 105052.22it/s] 34%|      | 26129/75824 [00:00<00:00, 85699.70it/s]  43%|     | 32839/75824 [00:00<00:00, 76545.94it/s] 52%|    | 39245/75824 [00:00<00:00, 72317.23it/s] 65%|   | 49370/75824 [00:00<00:00, 79097.40it/s] 81%|  | 61591/75824 [00:00<00:00, 88458.64it/s] 94%|| 71572/75824 [00:00<00:00, 91580.98it/s]100%|| 75824/75824 [00:00<00:00, 89858.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7475/75824 [00:00<00:00, 74747.58it/s] 24%|       | 18282/75824 [00:00<00:00, 82365.54it/s] 38%|      | 28937/75824 [00:00<00:00, 88383.33it/s] 49%|     | 36949/75824 [00:00<00:00, 85729.57it/s] 60%|    | 45684/75824 [00:00<00:00, 86208.59it/s] 73%|  | 55121/75824 [00:00<00:00, 87170.54it/s] 86%| | 65543/75824 [00:00<00:00, 91668.88it/s]100%|| 75824/75824 [00:00<00:00, 96276.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6595/75824 [00:00<00:01, 63817.78it/s] 16%|        | 12374/75824 [00:00<00:01, 61880.35it/s] 29%|       | 21718/75824 [00:00<00:00, 68856.28it/s] 44%|     | 33356/75824 [00:00<00:00, 77546.84it/s] 53%|    | 40122/75824 [00:00<00:00, 73923.31it/s] 70%|   | 52704/75824 [00:00<00:00, 84361.70it/s] 86%| | 65068/75824 [00:00<00:00, 93248.73it/s]100%|| 75824/75824 [00:00<00:00, 94331.02it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8811/75824 [00:00<00:00, 88107.77it/s] 28%|       | 20971/75824 [00:00<00:00, 96042.15it/s] 44%|     | 33122/75824 [00:00<00:00, 102486.04it/s] 60%|    | 45445/75824 [00:00<00:00, 107934.99it/s] 76%|  | 57606/75824 [00:00<00:00, 111702.80it/s] 92%|| 69875/75824 [00:00<00:00, 114783.98it/s]100%|| 75824/75824 [00:00<00:00, 116984.97it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10431/75824 [00:00<00:00, 104308.86it/s] 27%|       | 20563/75824 [00:00<00:00, 103393.80it/s] 43%|     | 32571/75824 [00:00<00:00, 107890.68it/s] 59%|    | 44889/75824 [00:00<00:00, 112061.38it/s] 76%|  | 57419/75824 [00:00<00:00, 115727.28it/s] 91%| | 68895/75824 [00:00<00:00, 115434.01it/s]100%|| 75824/75824 [00:00<00:00, 110408.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10691/75824 [00:00<00:00, 106907.81it/s] 30%|       | 22939/75824 [00:00<00:00, 111146.80it/s] 47%|     | 35325/75824 [00:00<00:00, 114677.83it/s] 60%|    | 45701/75824 [00:00<00:00, 111165.67it/s] 76%|  | 57844/75824 [00:00<00:00, 114055.76it/s] 93%|| 70346/75824 [00:00<00:00, 117136.34it/s]100%|| 75824/75824 [00:00<00:00, 117672.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4828/75824 [00:00<00:01, 48279.01it/s] 17%|        | 13031/75824 [00:00<00:01, 55076.90it/s] 24%|       | 18238/75824 [00:00<00:01, 54138.32it/s] 32%|      | 24100/75824 [00:00<00:00, 55408.18it/s] 42%|     | 31543/75824 [00:00<00:00, 60008.67it/s] 51%|    | 39040/75824 [00:00<00:00, 63800.70it/s] 67%|   | 51159/75824 [00:00<00:00, 74365.23it/s] 83%| | 63113/75824 [00:00<00:00, 83872.97it/s] 99%|| 74713/75824 [00:00<00:00, 91473.18it/s]100%|| 75824/75824 [00:00<00:00, 83365.68it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11625/75824 [00:00<00:00, 116240.97it/s] 24%|       | 18218/75824 [00:00<00:00, 94185.67it/s]  30%|       | 22618/75824 [00:00<00:00, 68313.96it/s] 40%|      | 30154/75824 [00:00<00:00, 69080.74it/s] 49%|     | 37525/75824 [00:00<00:00, 70406.16it/s] 64%|   | 48359/75824 [00:00<00:00, 78669.56it/s] 80%|  | 60395/75824 [00:00<00:00, 87791.65it/s] 95%|| 71866/75824 [00:00<00:00, 94439.53it/s]100%|| 75824/75824 [00:00<00:00, 89721.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11737/75824 [00:00<00:00, 117366.19it/s] 29%|       | 21754/75824 [00:00<00:00, 111616.29it/s] 36%|      | 27224/75824 [00:00<00:00, 79706.81it/s]  43%|     | 32488/75824 [00:00<00:00, 63869.15it/s] 56%|    | 42527/75824 [00:00<00:00, 71693.40it/s] 70%|   | 53229/75824 [00:00<00:00, 79572.02it/s] 83%| | 62644/75824 [00:00<00:00, 83446.26it/s] 99%|| 74946/75824 [00:00<00:00, 92359.39it/s]100%|| 75824/75824 [00:00<00:00, 89991.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6168/75824 [00:00<00:01, 61677.26it/s] 21%|       | 16131/75824 [00:00<00:00, 69634.29it/s] 37%|      | 28187/75824 [00:00<00:00, 79738.96it/s] 53%|    | 40269/75824 [00:00<00:00, 88795.71it/s] 70%|   | 52707/75824 [00:00<00:00, 97131.71it/s] 86%| | 64962/75824 [00:00<00:00, 103575.50it/s]100%|| 75824/75824 [00:00<00:00, 110434.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12038/75824 [00:00<00:00, 120376.67it/s] 31%|       | 23605/75824 [00:00<00:00, 118923.66it/s] 39%|      | 29603/75824 [00:00<00:00, 73906.88it/s]  46%|     | 34979/75824 [00:00<00:00, 64333.17it/s] 57%|    | 43015/75824 [00:00<00:00, 68427.24it/s] 67%|   | 50430/75824 [00:00<00:00, 70048.43it/s] 75%|  | 56913/75824 [00:00<00:00, 67989.53it/s] 85%| | 64353/75824 [00:00<00:00, 69001.19it/s] 94%|| 71010/75824 [00:00<00:00, 67391.16it/s]100%|| 75824/75824 [00:01<00:00, 74909.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6089/75824 [00:00<00:01, 60879.46it/s] 10%|         | 7916/75824 [00:00<00:01, 34893.31it/s] 18%|        | 13729/75824 [00:00<00:01, 39647.09it/s] 23%|       | 17272/75824 [00:00<00:01, 38279.40it/s] 29%|       | 22251/75824 [00:00<00:01, 41131.88it/s] 38%|      | 28754/75824 [00:00<00:01, 46227.39it/s] 44%|     | 33303/75824 [00:00<00:01, 30755.80it/s] 51%|     | 38575/75824 [00:00<00:01, 35148.07it/s] 59%|    | 44978/75824 [00:01<00:00, 40647.50it/s] 68%|   | 51390/75824 [00:01<00:00, 45661.22it/s] 76%|  | 57937/75824 [00:01<00:00, 50218.23it/s] 85%| | 64482/75824 [00:01<00:00, 53985.83it/s] 93%|| 70818/75824 [00:01<00:00, 56493.10it/s]100%|| 75824/75824 [00:01<00:00, 48955.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12255/75824 [00:00<00:00, 122544.27it/s] 32%|      | 24097/75824 [00:00<00:00, 121274.95it/s] 47%|     | 35875/75824 [00:00<00:00, 120204.21it/s] 63%|   | 47863/75824 [00:00<00:00, 120105.25it/s] 78%|  | 59296/75824 [00:00<00:00, 118309.47it/s] 91%|| 69202/75824 [00:00<00:00, 111790.97it/s]100%|| 75824/75824 [00:00<00:00, 115296.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12074/75824 [00:00<00:00, 120732.63it/s] 32%|      | 24379/75824 [00:00<00:00, 121415.57it/s] 48%|     | 36380/75824 [00:00<00:00, 120989.88it/s] 64%|   | 48864/75824 [00:00<00:00, 122119.01it/s] 81%|  | 61321/75824 [00:00<00:00, 122841.64it/s] 97%|| 73836/75824 [00:00<00:00, 123522.67it/s]100%|| 75824/75824 [00:00<00:00, 123052.68it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7439/75824 [00:00<00:00, 68815.04it/s] 18%|        | 13655/75824 [00:00<00:00, 66672.50it/s] 26%|       | 20069/75824 [00:00<00:00, 64894.61it/s] 35%|      | 26544/75824 [00:00<00:00, 64849.83it/s] 43%|     | 32528/75824 [00:00<00:00, 63218.44it/s] 51%|    | 38986/75824 [00:00<00:00, 63619.47it/s] 61%|    | 46233/75824 [00:00<00:00, 66038.16it/s] 69%|   | 52304/75824 [00:00<00:00, 60993.51it/s] 85%| | 64629/75824 [00:00<00:00, 71886.06it/s]100%|| 75824/75824 [00:01<00:00, 74259.65it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10816/75824 [00:00<00:00, 108153.40it/s] 30%|       | 23082/75824 [00:00<00:00, 112130.26it/s] 47%|     | 35299/75824 [00:00<00:00, 114963.49it/s] 63%|   | 47783/75824 [00:00<00:00, 117756.65it/s] 79%|  | 59742/75824 [00:00<00:00, 118299.67it/s] 95%|| 72186/75824 [00:00<00:00, 120074.82it/s]100%|| 75824/75824 [00:00<00:00, 120083.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8589/75824 [00:00<00:00, 85882.92it/s] 23%|       | 17709/75824 [00:00<00:00, 87209.79it/s] 36%|      | 27609/75824 [00:00<00:00, 90440.67it/s] 51%|    | 38873/75824 [00:00<00:00, 96122.81it/s] 66%|   | 50143/75824 [00:00<00:00, 100558.70it/s] 81%|  | 61515/75824 [00:00<00:00, 104175.32it/s] 96%|| 72859/75824 [00:00<00:00, 106791.08it/s]100%|| 75824/75824 [00:00<00:00, 104426.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 5717/75824 [00:00<00:01, 43325.01it/s] 12%|        | 8941/75824 [00:00<00:01, 39273.67it/s] 19%|        | 14723/75824 [00:00<00:01, 43454.76it/s] 23%|       | 17772/75824 [00:00<00:01, 36304.37it/s] 31%|       | 23325/75824 [00:00<00:01, 40512.10it/s] 39%|      | 29610/75824 [00:00<00:01, 45346.34it/s] 50%|     | 38258/75824 [00:00<00:00, 52893.07it/s] 65%|   | 49179/75824 [00:00<00:00, 62572.90it/s] 79%|  | 60151/75824 [00:00<00:00, 71831.78it/s] 94%|| 71194/75824 [00:01<00:00, 80245.21it/s]100%|| 75824/75824 [00:01<00:00, 69580.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  4%|         | 2903/75824 [00:00<00:02, 29027.05it/s]  7%|         | 5570/75824 [00:00<00:02, 28276.09it/s] 14%|        | 10374/75824 [00:00<00:02, 32256.57it/s] 24%|       | 18557/75824 [00:00<00:01, 39420.62it/s] 36%|      | 27275/75824 [00:00<00:01, 47173.28it/s] 52%|    | 39600/75824 [00:00<00:00, 57893.47it/s] 68%|   | 51934/75824 [00:00<00:00, 68853.29it/s] 84%| | 63820/75824 [00:00<00:00, 78798.01it/s]100%|| 75824/75824 [00:00<00:00, 84491.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10767/75824 [00:00<00:00, 97729.61it/s] 20%|        | 15509/75824 [00:00<00:00, 72267.23it/s] 25%|       | 19095/75824 [00:00<00:01, 55393.41it/s] 35%|      | 26876/75824 [00:00<00:00, 60633.53it/s] 43%|     | 32351/75824 [00:00<00:00, 58738.55it/s] 51%|     | 38458/75824 [00:00<00:00, 59416.74it/s] 59%|    | 44625/75824 [00:00<00:00, 60073.83it/s] 66%|   | 50193/75824 [00:00<00:00, 49461.59it/s] 73%|  | 55141/75824 [00:00<00:00, 46207.97it/s] 79%|  | 59807/75824 [00:01<00:00, 43595.87it/s] 85%| | 64354/75824 [00:01<00:00, 42785.87it/s] 92%|| 69853/75824 [00:01<00:00, 45837.44it/s] 99%|| 75139/75824 [00:01<00:00, 47739.27it/s]100%|| 75824/75824 [00:01<00:00, 52219.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12901/75824 [00:00<00:00, 129005.20it/s] 31%|       | 23271/75824 [00:00<00:00, 119160.80it/s] 45%|     | 34090/75824 [00:00<00:00, 115641.99it/s] 61%|    | 46347/75824 [00:00<00:00, 117636.29it/s] 77%|  | 58705/75824 [00:00<00:00, 119357.29it/s] 94%|| 71137/75824 [00:00<00:00, 120801.59it/s]100%|| 75824/75824 [00:00<00:00, 117883.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12545/75824 [00:00<00:00, 125444.74it/s] 33%|      | 24648/75824 [00:00<00:00, 124085.26it/s] 49%|     | 36914/75824 [00:00<00:00, 123652.92it/s] 64%|   | 48797/75824 [00:00<00:00, 122162.41it/s] 81%|  | 61117/75824 [00:00<00:00, 122470.14it/s] 97%|| 73673/75824 [00:00<00:00, 123380.61it/s]100%|| 75824/75824 [00:00<00:00, 122632.89it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12500/75824 [00:00<00:00, 124990.58it/s] 32%|      | 24438/75824 [00:00<00:00, 123250.29it/s] 49%|     | 36853/75824 [00:00<00:00, 123518.43it/s] 65%|   | 49381/75824 [00:00<00:00, 124040.39it/s] 82%| | 61959/75824 [00:00<00:00, 124555.91it/s] 98%|| 73954/75824 [00:00<00:00, 123134.66it/s]100%|| 75824/75824 [00:00<00:00, 123270.79it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9396/75824 [00:00<00:00, 93958.75it/s] 27%|       | 20722/75824 [00:00<00:00, 99018.28it/s] 41%|      | 30760/75824 [00:00<00:00, 99421.59it/s] 49%|     | 37531/75824 [00:00<00:00, 86401.54it/s] 61%|    | 46109/75824 [00:00<00:00, 81328.03it/s] 71%|   | 53962/75824 [00:00<00:00, 80466.81it/s] 86%| | 65347/75824 [00:00<00:00, 88226.39it/s]100%|| 75824/75824 [00:00<00:00, 93255.76it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18245/75824 [00:00<00:00, 182444.52it/s] 43%|     | 32354/75824 [00:00<00:00, 167695.77it/s] 65%|   | 49536/75824 [00:00<00:00, 168911.20it/s] 90%| | 68127/75824 [00:00<00:00, 173673.42it/s]100%|| 75824/75824 [00:00<00:00, 171599.10it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18363/75824 [00:00<00:00, 183625.36it/s] 41%|      | 31053/75824 [00:00<00:00, 161909.89it/s] 63%|   | 47411/75824 [00:00<00:00, 162406.34it/s] 87%| | 66334/75824 [00:00<00:00, 169616.38it/s]100%|| 75824/75824 [00:00<00:00, 159517.09it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 5858/75824 [00:00<00:01, 58575.87it/s] 21%|       | 16124/75824 [00:00<00:00, 67237.24it/s] 47%|     | 35479/75824 [00:00<00:00, 83605.27it/s] 72%|  | 54330/75824 [00:00<00:00, 100360.18it/s] 87%| | 66162/75824 [00:00<00:00, 96406.53it/s] 100%|| 75824/75824 [00:00<00:00, 118497.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11834/75824 [00:00<00:00, 118332.78it/s] 33%|      | 24782/75824 [00:00<00:00, 121467.74it/s] 55%|    | 42028/75824 [00:00<00:00, 133289.72it/s] 75%|  | 56581/75824 [00:00<00:00, 136739.04it/s] 98%|| 74089/75824 [00:00<00:00, 146352.31it/s]100%|| 75824/75824 [00:00<00:00, 149147.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9210/75824 [00:00<00:00, 89862.47it/s] 24%|       | 18332/75824 [00:00<00:00, 90263.64it/s] 31%|      | 23721/75824 [00:00<00:00, 73277.92it/s] 50%|     | 38186/75824 [00:00<00:00, 86009.24it/s] 76%|  | 57363/75824 [00:00<00:00, 103059.93it/s] 92%|| 70030/75824 [00:00<00:00, 109162.21it/s]100%|| 75824/75824 [00:00<00:00, 118557.09it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18450/75824 [00:00<00:00, 184485.66it/s] 32%|      | 23985/75824 [00:00<00:00, 87602.31it/s]  52%|    | 39301/75824 [00:00<00:00, 100507.20it/s] 68%|   | 51538/75824 [00:00<00:00, 106198.09it/s] 90%| | 68607/75824 [00:00<00:00, 119773.37it/s]100%|| 75824/75824 [00:00<00:00, 131248.02it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19182/75824 [00:00<00:00, 191815.61it/s] 51%|     | 38664/75824 [00:00<00:00, 192705.71it/s] 68%|   | 51424/75824 [00:00<00:00, 167122.71it/s] 91%|| 69199/75824 [00:00<00:00, 170173.79it/s]100%|| 75824/75824 [00:00<00:00, 175009.54it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19106/75824 [00:00<00:00, 191057.90it/s] 50%|     | 37828/75824 [00:00<00:00, 189888.93it/s] 74%|  | 56368/75824 [00:00<00:00, 188517.86it/s]100%|| 75460/75824 [00:00<00:00, 189230.44it/s]100%|| 75824/75824 [00:00<00:00, 188487.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20117/75824 [00:00<00:00, 201164.92it/s] 53%|    | 40119/75824 [00:00<00:00, 200818.97it/s] 78%|  | 59314/75824 [00:00<00:00, 198072.44it/s]100%|| 75824/75824 [00:00<00:00, 197071.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18306/75824 [00:00<00:00, 183032.68it/s] 48%|     | 36459/75824 [00:00<00:00, 177050.76it/s] 64%|   | 48754/75824 [00:00<00:00, 156404.25it/s] 91%| | 68683/75824 [00:00<00:00, 167197.64it/s]100%|| 75824/75824 [00:00<00:00, 169981.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 20018/75824 [00:00<00:00, 200173.99it/s] 53%|    | 40053/75824 [00:00<00:00, 200223.95it/s] 78%|  | 59500/75824 [00:00<00:00, 198461.37it/s]100%|| 75824/75824 [00:00<00:00, 199248.75it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|       | 16248/75824 [00:00<00:00, 162473.57it/s] 46%|     | 34999/75824 [00:00<00:00, 169251.61it/s] 72%|  | 54787/75824 [00:00<00:00, 176929.45it/s] 99%|| 75011/75824 [00:00<00:00, 183829.12it/s]100%|| 75824/75824 [00:00<00:00, 187610.74it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19337/75824 [00:00<00:00, 193360.50it/s] 51%|    | 38934/75824 [00:00<00:00, 194135.12it/s] 77%|  | 58654/75824 [00:00<00:00, 195043.35it/s]100%|| 75824/75824 [00:00<00:00, 192932.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 30%|       | 23110/75824 [00:00<00:00, 231098.02it/s] 60%|    | 45791/75824 [00:00<00:00, 229791.92it/s] 89%| | 67484/75824 [00:00<00:00, 225775.22it/s]100%|| 75824/75824 [00:00<00:00, 223203.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18763/75824 [00:00<00:00, 187625.71it/s] 36%|      | 26982/75824 [00:00<00:00, 135480.70it/s] 58%|    | 44022/75824 [00:00<00:00, 144354.57it/s] 87%| | 65811/75824 [00:00<00:00, 160615.97it/s]100%|| 75824/75824 [00:00<00:00, 169720.24it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5595/75824 [00:00<00:01, 55945.79it/s] 20%|        | 15180/75824 [00:00<00:00, 63930.26it/s] 33%|      | 24653/75824 [00:00<00:00, 70837.89it/s] 43%|     | 32370/75824 [00:00<00:00, 72624.84it/s] 51%|     | 38659/75824 [00:00<00:00, 67414.92it/s] 59%|    | 44794/75824 [00:00<00:00, 60996.86it/s] 77%|  | 58432/75824 [00:00<00:00, 73121.74it/s] 91%| | 68876/75824 [00:00<00:00, 80349.78it/s]100%|| 75824/75824 [00:00<00:00, 78487.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20335/75824 [00:00<00:00, 203349.71it/s] 54%|    | 40997/75824 [00:00<00:00, 204317.91it/s] 68%|   | 51466/75824 [00:00<00:00, 128441.76it/s] 83%| | 63014/75824 [00:00<00:00, 124256.17it/s] 97%|| 73827/75824 [00:00<00:00, 118933.35it/s]100%|| 75824/75824 [00:00<00:00, 133417.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11421/75824 [00:00<00:00, 114208.48it/s] 33%|      | 24942/75824 [00:00<00:00, 119790.30it/s] 56%|    | 42435/75824 [00:00<00:00, 132300.26it/s] 82%| | 62208/75824 [00:00<00:00, 146880.23it/s]100%|| 75824/75824 [00:00<00:00, 157433.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 15456/75824 [00:00<00:00, 154555.73it/s] 47%|     | 35345/75824 [00:00<00:00, 165630.22it/s] 66%|   | 49846/75824 [00:00<00:00, 158851.03it/s] 88%| | 66822/75824 [00:00<00:00, 161972.66it/s]100%|| 75824/75824 [00:00<00:00, 171437.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10114/75824 [00:00<00:00, 101132.86it/s] 26%|       | 19806/75824 [00:00<00:00, 99829.23it/s]  39%|      | 29504/75824 [00:00<00:00, 98956.49it/s] 48%|     | 36353/75824 [00:00<00:00, 87303.02it/s] 63%|   | 47651/75824 [00:00<00:00, 93689.26it/s] 80%|  | 60844/75824 [00:00<00:00, 102611.83it/s] 98%|| 74188/75824 [00:00<00:00, 110251.46it/s]100%|| 75824/75824 [00:00<00:00, 106396.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 31%|       | 23290/75824 [00:00<00:00, 232895.78it/s] 58%|    | 44028/75824 [00:00<00:00, 224604.43it/s] 85%| | 64276/75824 [00:00<00:00, 217472.77it/s]100%|| 75824/75824 [00:00<00:00, 214419.19it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 30%|       | 22665/75824 [00:00<00:00, 226640.49it/s] 59%|    | 44887/75824 [00:00<00:00, 225295.56it/s] 85%| | 64115/75824 [00:00<00:00, 214258.12it/s]100%|| 75824/75824 [00:00<00:00, 210552.70it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19305/75824 [00:00<00:00, 193046.50it/s] 50%|     | 38255/75824 [00:00<00:00, 191966.38it/s] 75%|  | 56543/75824 [00:00<00:00, 189142.63it/s] 91%| | 68847/75824 [00:00<00:00, 144295.99it/s]100%|| 75824/75824 [00:00<00:00, 162341.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19748/75824 [00:00<00:00, 197477.83it/s] 51%|     | 38846/75824 [00:00<00:00, 195480.72it/s] 78%|  | 58820/75824 [00:00<00:00, 196738.95it/s]100%|| 75824/75824 [00:00<00:00, 197653.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|        | 16037/75824 [00:00<00:00, 160369.01it/s] 40%|      | 30574/75824 [00:00<00:00, 155554.00it/s] 64%|   | 48834/75824 [00:00<00:00, 162785.40it/s] 91%| | 68703/75824 [00:00<00:00, 172115.56it/s]100%|| 75824/75824 [00:00<00:00, 172891.97it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6623/75824 [00:00<00:01, 66221.06it/s] 31%|      | 23718/75824 [00:00<00:00, 81132.21it/s] 45%|     | 34168/75824 [00:00<00:00, 86964.26it/s] 55%|    | 42064/75824 [00:00<00:00, 84396.29it/s] 83%| | 63135/75824 [00:00<00:00, 102901.79it/s]100%|| 75824/75824 [00:00<00:00, 135986.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 20917/75824 [00:00<00:00, 209166.21it/s] 57%|    | 43517/75824 [00:00<00:00, 213944.61it/s] 83%| | 62938/75824 [00:00<00:00, 207615.47it/s]100%|| 75824/75824 [00:00<00:00, 189324.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10091/75824 [00:00<00:00, 100905.28it/s] 29%|       | 21909/75824 [00:00<00:00, 105531.05it/s] 40%|      | 30174/75824 [00:00<00:00, 97435.42it/s]  49%|     | 37440/75824 [00:00<00:00, 88388.94it/s] 58%|    | 44131/75824 [00:00<00:00, 52531.01it/s] 71%|  | 54089/75824 [00:00<00:00, 61205.58it/s] 85%| | 64469/75824 [00:00<00:00, 69796.80it/s]100%|| 75824/75824 [00:00<00:00, 80190.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14406/75824 [00:00<00:00, 144056.36it/s] 43%|     | 32414/75824 [00:00<00:00, 153250.76it/s] 54%|    | 40842/75824 [00:00<00:00, 117918.60it/s] 65%|   | 49042/75824 [00:00<00:00, 94935.83it/s]  75%|  | 56740/75824 [00:00<00:00, 87878.74it/s] 92%|| 69405/75824 [00:00<00:00, 96765.22it/s]100%|| 75824/75824 [00:00<00:00, 110006.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18980/75824 [00:00<00:00, 189798.82it/s] 52%|    | 39053/75824 [00:00<00:00, 192951.01it/s] 77%|  | 58683/75824 [00:00<00:00, 193943.57it/s]100%|| 75824/75824 [00:00<00:00, 195784.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 15154/75824 [00:00<00:00, 151539.06it/s] 39%|      | 29850/75824 [00:00<00:00, 150134.60it/s] 55%|    | 41798/75824 [00:00<00:00, 139402.34it/s] 81%|  | 61528/75824 [00:00<00:00, 152857.65it/s]100%|| 75824/75824 [00:00<00:00, 160592.11it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14349/75824 [00:00<00:00, 143489.79it/s] 47%|     | 35284/75824 [00:00<00:00, 158442.13it/s] 68%|   | 51193/75824 [00:00<00:00, 158635.19it/s] 83%| | 62867/75824 [00:00<00:00, 143213.93it/s]100%|| 75824/75824 [00:00<00:00, 163605.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20544/75824 [00:00<00:00, 205435.30it/s] 55%|    | 42021/75824 [00:00<00:00, 208147.42it/s] 83%| | 63169/75824 [00:00<00:00, 209134.69it/s]100%|| 75824/75824 [00:00<00:00, 212405.14it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16664/75824 [00:00<00:00, 166612.35it/s] 33%|      | 25110/75824 [00:00<00:00, 128974.93it/s] 58%|    | 44339/75824 [00:00<00:00, 143110.77it/s] 85%| | 64694/75824 [00:00<00:00, 157104.61it/s]100%|| 75824/75824 [00:00<00:00, 166580.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20108/75824 [00:00<00:00, 201074.44it/s] 48%|     | 36641/75824 [00:00<00:00, 188826.37it/s] 67%|   | 50671/75824 [00:00<00:00, 171073.42it/s] 93%|| 70654/75824 [00:00<00:00, 178790.26it/s]100%|| 75824/75824 [00:00<00:00, 178160.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 31%|       | 23435/75824 [00:00<00:00, 234341.84it/s] 62%|   | 46701/75824 [00:00<00:00, 233832.79it/s] 92%|| 69537/75824 [00:00<00:00, 232162.16it/s]100%|| 75824/75824 [00:00<00:00, 221336.97it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21285/75824 [00:00<00:00, 212845.13it/s] 59%|    | 44548/75824 [00:00<00:00, 218416.71it/s] 90%| | 67955/75824 [00:00<00:00, 222886.76it/s]100%|| 75824/75824 [00:00<00:00, 226963.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|       | 22302/75824 [00:00<00:00, 223015.96it/s] 54%|    | 40663/75824 [00:00<00:00, 209524.97it/s] 79%|  | 60260/75824 [00:00<00:00, 205263.04it/s]100%|| 75824/75824 [00:00<00:00, 200284.09it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 20864/75824 [00:00<00:00, 208633.73it/s] 57%|    | 43052/75824 [00:00<00:00, 212436.97it/s] 87%| | 66153/75824 [00:00<00:00, 217685.55it/s]100%|| 75824/75824 [00:00<00:00, 221716.56it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16530/75824 [00:00<00:00, 165287.15it/s] 40%|      | 30339/75824 [00:00<00:00, 156064.17it/s] 69%|   | 52015/75824 [00:00<00:00, 170376.27it/s] 93%|| 70157/75824 [00:00<00:00, 173543.49it/s]100%|| 75824/75824 [00:00<00:00, 178932.71it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14781/75824 [00:00<00:00, 147800.98it/s] 39%|      | 29250/75824 [00:00<00:00, 146851.32it/s] 55%|    | 41776/75824 [00:00<00:00, 139628.94it/s] 73%|  | 55491/75824 [00:00<00:00, 138874.63it/s]100%|| 75824/75824 [00:00<00:00, 153543.99it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20203/75824 [00:00<00:00, 202022.97it/s] 43%|     | 32279/75824 [00:00<00:00, 168086.18it/s] 53%|    | 40145/75824 [00:00<00:00, 120035.71it/s] 63%|   | 47811/75824 [00:00<00:00, 99729.86it/s]  87%| | 66001/75824 [00:00<00:00, 115362.51it/s]100%|| 75824/75824 [00:00<00:00, 132773.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9231/75824 [00:00<00:00, 86232.51it/s] 27%|       | 20710/75824 [00:00<00:00, 93186.57it/s] 46%|     | 35028/75824 [00:00<00:00, 104089.63it/s] 59%|    | 44606/75824 [00:00<00:00, 99442.40it/s]  70%|   | 52890/75824 [00:00<00:00, 67737.57it/s] 88%| | 66814/75824 [00:00<00:00, 80073.25it/s]100%|| 75824/75824 [00:00<00:00, 96921.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 17976/75824 [00:00<00:00, 179755.89it/s] 32%|      | 24325/75824 [00:00<00:00, 116011.62it/s] 45%|     | 34434/75824 [00:00<00:00, 111091.29it/s] 65%|   | 49276/75824 [00:00<00:00, 120157.04it/s] 77%|  | 58635/75824 [00:00<00:00, 98751.63it/s]  92%|| 69957/75824 [00:00<00:00, 102686.75it/s]100%|| 75824/75824 [00:00<00:00, 113293.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19986/75824 [00:00<00:00, 199851.61it/s] 52%|    | 39448/75824 [00:00<00:00, 198250.72it/s] 65%|   | 49484/75824 [00:00<00:00, 148699.93it/s] 85%| | 64609/75824 [00:00<00:00, 149453.81it/s]100%|| 75824/75824 [00:00<00:00, 164995.11it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 30%|       | 22834/75824 [00:00<00:00, 228330.96it/s] 59%|    | 44377/75824 [00:00<00:00, 224298.69it/s] 89%| | 67112/75824 [00:00<00:00, 225203.28it/s]100%|| 75824/75824 [00:00<00:00, 224172.09it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18854/75824 [00:00<00:00, 188536.58it/s] 52%|    | 39593/75824 [00:00<00:00, 193822.13it/s] 80%|  | 60876/75824 [00:00<00:00, 199156.90it/s]100%|| 75824/75824 [00:00<00:00, 202971.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|       | 22077/75824 [00:00<00:00, 220768.63it/s] 59%|    | 44363/75824 [00:00<00:00, 221390.56it/s] 80%|  | 60713/75824 [00:00<00:00, 200131.46it/s] 97%|| 73544/75824 [00:00<00:00, 167639.85it/s]100%|| 75824/75824 [00:00<00:00, 179584.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20718/75824 [00:00<00:00, 207172.79it/s] 56%|    | 42607/75824 [00:00<00:00, 210552.12it/s] 86%| | 64853/75824 [00:00<00:00, 213987.03it/s]100%|| 75824/75824 [00:00<00:00, 214569.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16749/75824 [00:00<00:00, 167488.56it/s] 38%|      | 29003/75824 [00:00<00:00, 150883.59it/s] 67%|   | 51119/75824 [00:00<00:00, 166780.58it/s] 97%|| 73554/75824 [00:00<00:00, 180688.70it/s]100%|| 75824/75824 [00:00<00:00, 184757.45it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|       | 22064/75824 [00:00<00:00, 220634.95it/s] 59%|    | 44363/75824 [00:00<00:00, 221335.97it/s] 87%| | 66309/75824 [00:00<00:00, 220767.50it/s]100%|| 75824/75824 [00:00<00:00, 218520.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|       | 22098/75824 [00:00<00:00, 220974.94it/s] 58%|    | 44218/75824 [00:00<00:00, 221041.84it/s] 85%| | 64727/75824 [00:00<00:00, 216000.60it/s]100%|| 75824/75824 [00:00<00:00, 216572.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20262/75824 [00:00<00:00, 202618.26it/s] 46%|     | 35068/75824 [00:00<00:00, 182446.84it/s] 67%|   | 50879/75824 [00:00<00:00, 174391.15it/s] 94%|| 71139/75824 [00:00<00:00, 181992.39it/s]100%|| 75824/75824 [00:00<00:00, 178351.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10895/75824 [00:00<00:00, 108944.39it/s] 34%|      | 25478/75824 [00:00<00:00, 117888.76it/s] 52%|    | 39365/75824 [00:00<00:00, 123484.22it/s] 64%|   | 48195/75824 [00:00<00:00, 97251.11it/s]  74%|  | 56416/75824 [00:00<00:00, 92188.76it/s] 85%| | 64575/75824 [00:00<00:00, 74416.72it/s] 96%|| 72992/75824 [00:00<00:00, 77095.43it/s]100%|| 75824/75824 [00:00<00:00, 92461.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6379/75824 [00:00<00:01, 63789.15it/s] 25%|       | 18704/75824 [00:00<00:00, 74583.46it/s] 40%|      | 30312/75824 [00:00<00:00, 83541.78it/s] 56%|    | 42289/75824 [00:00<00:00, 91878.98it/s] 71%|  | 54067/75824 [00:00<00:00, 98368.22it/s] 87%| | 65899/75824 [00:00<00:00, 103608.64it/s]100%|| 75824/75824 [00:00<00:00, 110562.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|        | 16086/75824 [00:00<00:00, 160854.40it/s] 50%|     | 38193/75824 [00:00<00:00, 175167.77it/s] 80%|  | 60648/75824 [00:00<00:00, 187539.91it/s]100%|| 75824/75824 [00:00<00:00, 203220.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19829/75824 [00:00<00:00, 198281.68it/s] 48%|     | 36474/75824 [00:00<00:00, 187523.08it/s] 65%|   | 49407/75824 [00:00<00:00, 165217.14it/s] 81%|  | 61556/75824 [00:00<00:00, 149114.50it/s] 99%|| 74729/75824 [00:00<00:00, 143432.29it/s]100%|| 75824/75824 [00:00<00:00, 148977.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10905/75824 [00:00<00:00, 109043.08it/s] 31%|       | 23342/75824 [00:00<00:00, 113228.20it/s] 57%|    | 42861/75824 [00:00<00:00, 129545.30it/s] 70%|   | 52931/75824 [00:00<00:00, 96944.73it/s]  89%| | 67514/75824 [00:00<00:00, 107783.87it/s]100%|| 75824/75824 [00:00<00:00, 121436.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9181/75824 [00:00<00:00, 91808.12it/s] 18%|        | 13729/75824 [00:00<00:00, 69969.07it/s] 25%|       | 19228/75824 [00:00<00:00, 64682.54it/s] 45%|     | 34274/75824 [00:00<00:00, 78027.05it/s] 63%|   | 47482/75824 [00:00<00:00, 88946.01it/s] 75%|  | 56537/75824 [00:00<00:00, 76510.13it/s] 93%|| 70225/75824 [00:00<00:00, 86680.18it/s]100%|| 75824/75824 [00:00<00:00, 92311.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 20914/75824 [00:00<00:00, 209135.21it/s] 54%|    | 40932/75824 [00:00<00:00, 206364.32it/s] 80%|  | 60355/75824 [00:00<00:00, 202567.37it/s]100%|| 75824/75824 [00:00<00:00, 201382.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|       | 17460/75824 [00:00<00:00, 174588.93it/s] 41%|     | 31394/75824 [00:00<00:00, 162271.80it/s] 65%|   | 48935/75824 [00:00<00:00, 165999.88it/s] 92%|| 69776/75824 [00:00<00:00, 176791.61it/s]100%|| 75824/75824 [00:00<00:00, 178135.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 30%|       | 22886/75824 [00:00<00:00, 228858.58it/s] 53%|    | 40354/75824 [00:00<00:00, 209370.90it/s] 72%|  | 54508/75824 [00:00<00:00, 183051.62it/s]100%|| 75824/75824 [00:00<00:00, 194034.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|       | 22029/75824 [00:00<00:00, 220280.76it/s] 60%|    | 45574/75824 [00:00<00:00, 224620.01it/s] 86%| | 64842/75824 [00:00<00:00, 213976.67it/s]100%|| 75824/75824 [00:00<00:00, 211818.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11716/75824 [00:00<00:00, 117156.20it/s] 31%|       | 23303/75824 [00:00<00:00, 116766.46it/s] 48%|     | 36242/75824 [00:00<00:00, 120284.73it/s] 65%|   | 49098/75824 [00:00<00:00, 122653.19it/s] 82%| | 62021/75824 [00:00<00:00, 124554.46it/s] 97%|| 73722/75824 [00:00<00:00, 122189.30it/s]100%|| 75824/75824 [00:00<00:00, 122370.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 15278/75824 [00:00<00:00, 152776.50it/s] 43%|     | 32260/75824 [00:00<00:00, 157517.98it/s] 71%|  | 54210/75824 [00:00<00:00, 172095.88it/s]100%|| 75792/75824 [00:00<00:00, 183232.43it/s]100%|| 75824/75824 [00:00<00:00, 189346.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 20956/75824 [00:00<00:00, 209557.20it/s] 58%|    | 43694/75824 [00:00<00:00, 214602.07it/s] 72%|  | 54916/75824 [00:00<00:00, 161173.95it/s] 95%|| 72340/75824 [00:00<00:00, 164881.53it/s]100%|| 75824/75824 [00:00<00:00, 178188.02it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 30%|       | 23092/75824 [00:00<00:00, 230913.06it/s] 61%|    | 46338/75824 [00:00<00:00, 231374.39it/s] 90%| | 68421/75824 [00:00<00:00, 228106.22it/s]100%|| 75824/75824 [00:00<00:00, 224766.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16351/75824 [00:00<00:00, 163509.38it/s] 44%|     | 33579/75824 [00:00<00:00, 166043.33it/s] 71%|  | 54074/75824 [00:00<00:00, 176069.06it/s] 97%|| 73920/75824 [00:00<00:00, 182236.82it/s]100%|| 75824/75824 [00:00<00:00, 184978.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20787/75824 [00:00<00:00, 207863.26it/s] 54%|    | 41135/75824 [00:00<00:00, 206528.19it/s] 80%|  | 60986/75824 [00:00<00:00, 204052.44it/s] 98%|| 74270/75824 [00:00<00:00, 163508.29it/s]100%|| 75824/75824 [00:00<00:00, 175659.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21260/75824 [00:00<00:00, 212593.61it/s] 56%|    | 42262/75824 [00:00<00:00, 211813.46it/s] 84%| | 63511/75824 [00:00<00:00, 212013.91it/s]100%|| 75824/75824 [00:00<00:00, 213685.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14419/75824 [00:00<00:00, 142058.06it/s] 26%|       | 19772/75824 [00:00<00:00, 94946.34it/s]  50%|     | 38197/75824 [00:00<00:00, 111100.96it/s] 76%|  | 57575/75824 [00:00<00:00, 127408.63it/s] 94%|| 71002/75824 [00:00<00:00, 129391.05it/s]100%|| 75824/75824 [00:00<00:00, 144341.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12721/75824 [00:00<00:00, 127201.63it/s] 24%|       | 18573/75824 [00:00<00:00, 94076.96it/s]  38%|      | 29055/75824 [00:00<00:00, 97059.09it/s] 57%|    | 42947/75824 [00:00<00:00, 106704.13it/s] 76%|  | 57924/75824 [00:00<00:00, 116776.91it/s] 90%| | 68430/75824 [00:00<00:00, 112995.64it/s]100%|| 75824/75824 [00:00<00:00, 114687.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7771/75824 [00:00<00:00, 77705.07it/s] 15%|        | 11410/75824 [00:00<00:01, 56408.46it/s] 23%|       | 17571/75824 [00:00<00:01, 57457.19it/s] 41%|     | 31328/75824 [00:00<00:00, 69619.97it/s] 58%|    | 44092/75824 [00:00<00:00, 80612.62it/s] 70%|   | 53137/75824 [00:00<00:00, 83330.88it/s] 82%| | 61811/75824 [00:00<00:00, 76320.13it/s] 98%|| 74670/75824 [00:00<00:00, 86918.33it/s]100%|| 75824/75824 [00:00<00:00, 87639.95it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.025118350982666016 seconds.
Run epoch 1
Epoch 1 ends in 0.023491859436035156 seconds.
5416 sentences created
mode 1: time used = 0.053023576736450195
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '6.10655'}; time used = 3.500612735748291s
epoch 10: {'train_loss': '5.97822'}; time used = 2.440821647644043s
epoch 15: {'train_loss': '5.86313'}; time used = 2.3002219200134277s
epoch 20: {'train_loss': '5.78356'}; time used = 3.1538848876953125s
epoch 25: {'train_loss': '5.64586'}; time used = 1.9962077140808105s
epoch 30: {'train_loss': '5.55407'}; time used = 3.0061445236206055s
epoch 35: {'train_loss': '5.46477'}; time used = 3.9097161293029785s
epoch 40: {'train_loss': '5.37181'}; time used = 5.1024088859558105s
epoch 45: {'train_loss': '5.28145'}; time used = 10.003884553909302s
epoch 50: {'train_loss': '5.21778'}; time used = 6.52579665184021s
epoch 55: {'train_loss': '5.11256'}; time used = 4.706270694732666s
epoch 60: {'train_loss': '4.98622'}; time used = 5.809245824813843s
epoch 65: {'train_loss': '4.92763'}; time used = 4.490620851516724s
epoch 70: {'train_loss': '4.84395'}; time used = 4.195892810821533s
epoch 75: {'train_loss': '4.75217'}; time used = 4.3119728565216064s
epoch 80: {'train_loss': '4.69546'}; time used = 5.217571020126343s
epoch 85: {'train_loss': '4.63935'}; time used = 4.938434839248657s
epoch 90: {'train_loss': '4.59633'}; time used = 4.318425178527832s
epoch 95: {'train_loss': '4.51443'}; time used = 4.601291179656982s
epoch 100: {'train_loss': '4.44598'}; time used = 5.331473112106323s
epoch 105: {'train_loss': '4.39607'}; time used = 4.652737379074097s
epoch 110: {'train_loss': '4.34894'}; time used = 4.5999016761779785s
epoch 115: {'train_loss': '4.24289'}; time used = 5.502899885177612s
epoch 120: {'train_loss': '4.22762'}; time used = 5.558861970901489s
epoch 125: {'train_loss': '4.15617'}; time used = 2.555457353591919s
epoch 130: {'train_loss': '4.12912'}; time used = 2.9389488697052s
epoch 135: {'train_loss': '4.05130'}; time used = 2.1314938068389893s
epoch 140: {'train_loss': '4.01914'}; time used = 2.345710277557373s
epoch 145: {'train_loss': '3.92520'}; time used = 3.0587158203125s
epoch 150: {'train_loss': '3.94589'}; time used = 2.8356988430023193s
epoch 155: {'train_loss': '3.87773'}; time used = 2.214090347290039s
epoch 160: {'train_loss': '3.84282'}; time used = 3.1837778091430664s
epoch 165: {'train_loss': '3.79403'}; time used = 2.178783416748047s
epoch 170: {'train_loss': '3.77104'}; time used = 2.653954029083252s
epoch 175: {'train_loss': '3.71204'}; time used = 3.3306832313537598s
epoch 180: {'train_loss': '3.68084'}; time used = 2.0520384311676025s
epoch 185: {'train_loss': '3.63465'}; time used = 2.0529680252075195s
epoch 190: {'train_loss': '3.62036'}; time used = 2.9175751209259033s
epoch 195: {'train_loss': '3.59248'}; time used = 2.413578987121582s
epoch 200: {'train_loss': '3.55829'}; time used = 2.7184479236602783s
epoch 205: {'train_loss': '3.52267'}; time used = 5.006992340087891s
epoch 210: {'train_loss': '3.52191'}; time used = 6.463902950286865s
epoch 215: {'train_loss': '3.45072'}; time used = 4.708846569061279s
epoch 220: {'train_loss': '3.46544'}; time used = 4.190319299697876s
epoch 225: {'train_loss': '3.36072'}; time used = 5.368313789367676s
epoch 230: {'train_loss': '3.36826'}; time used = 5.655202627182007s
epoch 235: {'train_loss': '3.35485'}; time used = 4.365568399429321s
epoch 240: {'train_loss': '3.32733'}; time used = 6.814076900482178s
epoch 245: {'train_loss': '3.31187'}; time used = 5.073657989501953s
epoch 250: {'train_loss': '3.33028'}; time used = 4.640805006027222s
epoch 255: {'train_loss': '3.24731'}; time used = 5.637045621871948s
epoch 260: {'train_loss': '3.23816'}; time used = 4.7855565547943115s
epoch 265: {'train_loss': '3.22923'}; time used = 5.267392873764038s
epoch 270: {'train_loss': '3.19143'}; time used = 5.522239923477173s
epoch 275: {'train_loss': '3.20582'}; time used = 3.861757516860962s
epoch 280: {'train_loss': '3.16038'}; time used = 4.753016948699951s
epoch 285: {'train_loss': '3.15251'}; time used = 4.184896945953369s
epoch 290: {'train_loss': '3.15134'}; time used = 5.312887191772461s
epoch 295: {'train_loss': '3.12424'}; time used = 4.609243631362915s
epoch 300: {'train_loss': '3.08149'}; time used = 4.102902889251709s
epoch 305: {'train_loss': '3.06060'}; time used = 4.441374778747559s
epoch 310: {'train_loss': '3.07760'}; time used = 5.390227317810059s
epoch 315: {'train_loss': '3.05471'}; time used = 4.488953590393066s
epoch 320: {'train_loss': '3.02352'}; time used = 4.450295448303223s
epoch 325: {'train_loss': '3.00077'}; time used = 4.888345956802368s
epoch 330: {'train_loss': '3.02693'}; time used = 4.820497751235962s
epoch 335: {'train_loss': '2.99693'}; time used = 4.983212232589722s
epoch 340: {'train_loss': '2.99547'}; time used = 4.275845766067505s
epoch 345: {'train_loss': '2.94105'}; time used = 3.7033121585845947s
epoch 350: {'train_loss': '2.92034'}; time used = 3.149595260620117s
epoch 355: {'train_loss': '2.93436'}; time used = 2.0560100078582764s
epoch 360: {'train_loss': '2.90823'}; time used = 2.176942825317383s
epoch 365: {'train_loss': '2.85675'}; time used = 3.6068975925445557s
epoch 370: {'train_loss': '2.84134'}; time used = 3.763108730316162s
epoch 375: {'train_loss': '2.86218'}; time used = 8.135953187942505s
epoch 380: {'train_loss': '2.86062'}; time used = 8.283852338790894s
epoch 385: {'train_loss': '2.86584'}; time used = 4.439305067062378s
epoch 390: {'train_loss': '2.82055'}; time used = 3.9191834926605225s
epoch 395: {'train_loss': '2.80193'}; time used = 4.135138273239136s
epoch 400: {'train_loss': '2.78691'}; time used = 5.206862211227417s
epoch 405: {'train_loss': '2.80529'}; time used = 4.587562799453735s
epoch 410: {'train_loss': '2.78096'}; time used = 4.377258062362671s
epoch 415: {'train_loss': '2.76601'}; time used = 5.609266996383667s
epoch 420: {'train_loss': '2.72769'}; time used = 4.429435729980469s
epoch 425: {'train_loss': '2.76829'}; time used = 5.317268133163452s
epoch 430: {'train_loss': '2.74591'}; time used = 3.4564285278320312s
epoch 435: {'train_loss': '2.71845'}; time used = 2.7574453353881836s
epoch 440: {'train_loss': '2.70547'}; time used = 2.1655588150024414s
epoch 445: {'train_loss': '2.70519'}; time used = 3.0301103591918945s
epoch 450: {'train_loss': '2.68539'}; time used = 2.5281617641448975s
epoch 455: {'train_loss': '2.69156'}; time used = 2.951517343521118s
epoch 460: {'train_loss': '2.66153'}; time used = 2.630826711654663s
epoch 465: {'train_loss': '2.65061'}; time used = 2.172830104827881s
epoch 470: {'train_loss': '2.64781'}; time used = 2.703707695007324s
epoch 475: {'train_loss': '2.62881'}; time used = 2.4208998680114746s
epoch 480: {'train_loss': '2.63098'}; time used = 2.072957754135132s
epoch 485: {'train_loss': '2.62254'}; time used = 3.266927719116211s
epoch 490: {'train_loss': '2.62990'}; time used = 2.5471935272216797s
epoch 495: {'train_loss': '2.58558'}; time used = 2.381361484527588s
epoch 500: {'train_loss': '2.57047'}; time used = 3.0382630825042725s

Finished training. Time used = 412.9041130542755.
Training classifier using 20.00% nodes...
{'micro': 0.2787263497923396, 'macro': 0.0808247559378781, 'samples': 0.2787263497923396, 'weighted': 0.15065542675621457}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 156366.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|       | 17688/75824 [00:00<00:00, 176871.73it/s] 39%|      | 29921/75824 [00:00<00:00, 156001.02it/s] 64%|   | 48240/75824 [00:00<00:00, 163269.17it/s] 91%| | 68624/75824 [00:00<00:00, 173636.83it/s]100%|| 75824/75824 [00:00<00:00, 175202.65it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 40, in forward
    hx = self.embed(x)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 82, in forward
    return self.embed(x)[indices]
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 18.08 MiB already allocated; 21.44 MiB free; 20.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.02250075340270996 seconds.
Run epoch 1
Epoch 1 ends in 0.021256685256958008 seconds.
5416 sentences created
mode 1: time used = 0.04368329048156738
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 76221.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11448/75824 [00:00<00:00, 114474.92it/s] 31%|       | 23531/75824 [00:00<00:00, 116309.52it/s] 47%|     | 35626/75824 [00:00<00:00, 117661.34it/s] 63%|   | 47830/75824 [00:00<00:00, 118940.71it/s] 79%|  | 60179/75824 [00:00<00:00, 120267.76it/s] 94%|| 70934/75824 [00:00<00:00, 116147.39it/s]100%|| 75824/75824 [00:00<00:00, 118490.74it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 42, in forward
    hneg = self.embed(neg)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 82, in forward
    return self.embed(x)[indices]
RuntimeError: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 10.76 GiB total capacity; 95.41 MiB already allocated; 23.44 MiB free; 114.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.03596305847167969 seconds.
Run epoch 1
Epoch 1 ends in 0.038434505462646484 seconds.
5416 sentences created
mode 1: time used = 0.10413408279418945
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 81063.52it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12207/75824 [00:00<00:00, 122062.26it/s] 32%|      | 24519/75824 [00:00<00:00, 122375.61it/s] 48%|     | 36713/75824 [00:00<00:00, 122242.27it/s] 65%|   | 49111/75824 [00:00<00:00, 122758.14it/s] 79%|  | 60137/75824 [00:00<00:00, 118718.91it/s] 95%|| 72392/75824 [00:00<00:00, 119842.72it/s]100%|| 75824/75824 [00:00<00:00, 118427.29it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 222, in forward
    self.to(self._device)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 607, in to
    return self._apply(convert)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 376, in _apply
    param_applied = fn(param)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 605, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 14.80 MiB already allocated; 16.44 MiB free; 16.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.032207489013671875 seconds.
Run epoch 1
Epoch 1 ends in 0.06663990020751953 seconds.
5416 sentences created
mode 1: time used = 0.11051750183105469
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 177421.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18624/75824 [00:00<00:00, 186237.07it/s] 50%|     | 37816/75824 [00:00<00:00, 187904.64it/s] 74%|  | 56083/75824 [00:00<00:00, 186302.93it/s]100%|| 75615/75824 [00:00<00:00, 188919.20it/s]100%|| 75824/75824 [00:00<00:00, 188859.77it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 76.00 MiB (GPU 0; 10.76 GiB total capacity; 316.17 MiB already allocated; 15.44 MiB free; 344.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7eff2c6d41e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7eff2c92a64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7eff2c92b464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7eff2c92baa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7efccb89c90e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7efcc9cd6949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7efcc9cf0777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7efd04a8cc7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7efd04a8cf97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7efd04b97a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7efd048274f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7efd04829166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7efd0482965d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7efd0482980a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7efd04566eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7efcc9cc5b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7efd043f9530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7efd04be181c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7efd04b3282b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0x2f16968 (0x7efd068b9968 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: <unknown function> + 0xa56530 (0x7efd043f9530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7efd04be181c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: at::Tensor::mul(at::Tensor const&) const + 0x4b (0x7efd04cc7d6b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: torch::autograd::generated::MulBackward0::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x235 (0x7efd066d0da5 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x3375bb7 (0x7efd06d18bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7efd06d14400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7efd06d14fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7efd06d0d119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7eff2d4864ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #29: <unknown function> + 0xbd6df (0x7eff2e5e26df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #30: <unknown function> + 0x76db (0x7eff3263d6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #31: clone + 0x3f (0x7eff3297671f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.022912979125976562 seconds.
Run epoch 1
Epoch 1 ends in 0.020370006561279297 seconds.
5416 sentences created
mode 1: time used = 0.04367256164550781
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 180862.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18752/75824 [00:00<00:00, 187513.47it/s] 46%|     | 34794/75824 [00:00<00:00, 178467.07it/s] 61%|   | 46552/75824 [00:00<00:00, 154465.61it/s] 80%|  | 60347/75824 [00:00<00:00, 149109.91it/s] 99%|| 75241/75824 [00:00<00:00, 149055.74it/s]100%|| 75824/75824 [00:00<00:00, 150475.21it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 222, in forward
    self.to(self._device)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 607, in to
    return self._apply(convert)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 376, in _apply
    param_applied = fn(param)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 605, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 14.80 MiB already allocated; 15.44 MiB free; 16.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'inner', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.01861882209777832 seconds.
Run epoch 1
Epoch 1 ends in 0.01887798309326172 seconds.
5416 sentences created
mode 1: time used = 0.039414167404174805
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.76071'}; time used = 0.06132006645202637s
epoch 10: {'train_loss': '1.53983'}; time used = 0.04005599021911621s
epoch 15: {'train_loss': '1.34781'}; time used = 0.038947105407714844s
epoch 20: {'train_loss': '1.12459'}; time used = 0.03376364707946777s
epoch 25: {'train_loss': '1.00268'}; time used = 0.03360915184020996s
epoch 30: {'train_loss': '0.92170'}; time used = 0.03481245040893555s
epoch 35: {'train_loss': '0.82598'}; time used = 0.03935956954956055s
epoch 40: {'train_loss': '0.75557'}; time used = 0.03864407539367676s
epoch 45: {'train_loss': '0.68838'}; time used = 0.042198896408081055s
epoch 50: {'train_loss': '0.63787'}; time used = 0.03741574287414551s
epoch 55: {'train_loss': '0.59788'}; time used = 0.048062801361083984s
epoch 60: {'train_loss': '0.54270'}; time used = 0.03214836120605469s
epoch 65: {'train_loss': '0.50910'}; time used = 0.03541851043701172s
epoch 70: {'train_loss': '0.47090'}; time used = 0.07588815689086914s
epoch 75: {'train_loss': '0.44436'}; time used = 0.05099678039550781s
epoch 80: {'train_loss': '0.41320'}; time used = 0.043427467346191406s
epoch 85: {'train_loss': '0.39078'}; time used = 0.030841350555419922s
epoch 90: {'train_loss': '0.37118'}; time used = 0.03381013870239258s
epoch 95: {'train_loss': '0.34416'}; time used = 0.031760454177856445s
epoch 100: {'train_loss': '0.32311'}; time used = 0.032781124114990234s
epoch 105: {'train_loss': '0.30388'}; time used = 0.03461909294128418s
epoch 110: {'train_loss': '0.28681'}; time used = 0.03653979301452637s
epoch 115: {'train_loss': '0.26923'}; time used = 0.03445100784301758s
epoch 120: {'train_loss': '0.24672'}; time used = 0.040647029876708984s
epoch 125: {'train_loss': '0.22549'}; time used = 0.036452293395996094s
epoch 130: {'train_loss': '0.19302'}; time used = 0.033705949783325195s
epoch 135: {'train_loss': '0.17496'}; time used = 0.04400134086608887s
epoch 140: {'train_loss': '0.13545'}; time used = 0.047585248947143555s
epoch 145: {'train_loss': '0.11268'}; time used = 0.03811049461364746s
epoch 150: {'train_loss': '0.08464'}; time used = 0.028906822204589844s
epoch 155: {'train_loss': '0.06767'}; time used = 0.030874252319335938s
epoch 160: {'train_loss': '0.05826'}; time used = 0.03245687484741211s
epoch 165: {'train_loss': '0.05247'}; time used = 0.032155752182006836s
epoch 170: {'train_loss': '0.06032'}; time used = 0.03523373603820801s
epoch 175: {'train_loss': '0.04668'}; time used = 0.03131604194641113s
epoch 180: {'train_loss': '0.04493'}; time used = 0.03351879119873047s
epoch 185: {'train_loss': '0.04436'}; time used = 0.03716230392456055s
epoch 190: {'train_loss': '0.03876'}; time used = 0.034209489822387695s
epoch 195: {'train_loss': '0.04669'}; time used = 0.03130221366882324s
epoch 200: {'train_loss': '0.03528'}; time used = 0.030135154724121094s
epoch 205: {'train_loss': '0.03185'}; time used = 0.03206610679626465s
epoch 210: {'train_loss': '0.04924'}; time used = 0.037087440490722656s
epoch 215: {'train_loss': '0.03785'}; time used = 0.033350229263305664s
epoch 220: {'train_loss': '0.03667'}; time used = 0.03270864486694336s
epoch 225: {'train_loss': '0.04328'}; time used = 0.03217291831970215s
epoch 230: {'train_loss': '0.03441'}; time used = 0.032036781311035156s
epoch 235: {'train_loss': '0.04182'}; time used = 0.028832435607910156s
epoch 240: {'train_loss': '0.03965'}; time used = 0.02820730209350586s
epoch 245: {'train_loss': '0.03440'}; time used = 0.027850627899169922s
epoch 250: {'train_loss': '0.03937'}; time used = 0.03347921371459961s
epoch 255: {'train_loss': '0.03690'}; time used = 0.027484416961669922s
epoch 260: {'train_loss': '0.03563'}; time used = 0.027474641799926758s
epoch 265: {'train_loss': '0.04064'}; time used = 0.026526927947998047s
epoch 270: {'train_loss': '0.03377'}; time used = 0.02592015266418457s
epoch 275: {'train_loss': '0.03380'}; time used = 0.039008378982543945s
epoch 280: {'train_loss': '0.03629'}; time used = 0.02846360206604004s
epoch 285: {'train_loss': '0.03152'}; time used = 0.039597511291503906s
epoch 290: {'train_loss': '0.03789'}; time used = 0.05029439926147461s
epoch 295: {'train_loss': '0.03531'}; time used = 0.04634737968444824s
epoch 300: {'train_loss': '0.03497'}; time used = 0.03017711639404297s
epoch 305: {'train_loss': '0.03653'}; time used = 0.02755594253540039s
epoch 310: {'train_loss': '0.03115'}; time used = 0.02640819549560547s
epoch 315: {'train_loss': '0.02934'}; time used = 0.02531886100769043s
epoch 320: {'train_loss': '0.04683'}; time used = 0.026404142379760742s
epoch 325: {'train_loss': '0.03031'}; time used = 0.032750844955444336s
epoch 330: {'train_loss': '0.03443'}; time used = 0.03691554069519043s
epoch 335: {'train_loss': '0.03749'}; time used = 0.030721664428710938s
epoch 340: {'train_loss': '0.03336'}; time used = 0.03321719169616699s
epoch 345: {'train_loss': '0.03930'}; time used = 0.028113365173339844s
epoch 350: {'train_loss': '0.03978'}; time used = 0.029288768768310547s
epoch 355: {'train_loss': '0.03114'}; time used = 0.04062318801879883s
epoch 360: {'train_loss': '0.03170'}; time used = 0.03292226791381836s
epoch 365: {'train_loss': '0.03348'}; time used = 0.03454470634460449s
epoch 370: {'train_loss': '0.03452'}; time used = 0.035376787185668945s
epoch 375: {'train_loss': '0.03877'}; time used = 0.03542065620422363s
epoch 380: {'train_loss': '0.03822'}; time used = 0.03380894660949707s
epoch 385: {'train_loss': '0.03250'}; time used = 0.032880544662475586s
epoch 390: {'train_loss': '0.03502'}; time used = 0.03575253486633301s
epoch 395: {'train_loss': '0.03024'}; time used = 0.04088878631591797s
epoch 400: {'train_loss': '0.03484'}; time used = 0.030744075775146484s
epoch 405: {'train_loss': '0.02923'}; time used = 0.04179048538208008s
epoch 410: {'train_loss': '0.03073'}; time used = 0.044724464416503906s
epoch 415: {'train_loss': '0.04252'}; time used = 0.03414440155029297s
epoch 420: {'train_loss': '0.03602'}; time used = 0.0354154109954834s
epoch 425: {'train_loss': '0.02995'}; time used = 0.028870582580566406s
epoch 430: {'train_loss': '0.03581'}; time used = 0.04269814491271973s
epoch 435: {'train_loss': '0.03277'}; time used = 0.044341087341308594s
epoch 440: {'train_loss': '0.02773'}; time used = 0.02773761749267578s
epoch 445: {'train_loss': '0.03135'}; time used = 0.036539554595947266s
epoch 450: {'train_loss': '0.04071'}; time used = 0.03685569763183594s
epoch 455: {'train_loss': '0.04049'}; time used = 0.03475761413574219s
epoch 460: {'train_loss': '0.03486'}; time used = 0.03891873359680176s
epoch 465: {'train_loss': '0.03281'}; time used = 0.03497457504272461s
epoch 470: {'train_loss': '0.02968'}; time used = 0.03382277488708496s
epoch 475: {'train_loss': '0.04859'}; time used = 0.02845025062561035s
epoch 480: {'train_loss': '0.03088'}; time used = 0.04929399490356445s
epoch 485: {'train_loss': '0.03713'}; time used = 0.036414146423339844s
epoch 490: {'train_loss': '0.03955'}; time used = 0.031304121017456055s
epoch 495: {'train_loss': '0.03776'}; time used = 0.03457307815551758s
epoch 500: {'train_loss': '0.03448'}; time used = 0.04037284851074219s
Finished training. Time used = 12.462036609649658.
Training classifier using 20.00% nodes...
{'micro': 0.41024457775726814, 'macro': 0.3152962195839057, 'samples': 0.41024457775726814, 'weighted': 0.3640176013749602}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 199020.08it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 42, in forward
    hneg = self.embed(neg)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 82, in forward
    return self.embed(x)[indices]
RuntimeError: CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 10.76 GiB total capacity; 324.53 MiB already allocated; 43.44 MiB free; 340.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.019228458404541016 seconds.
Run epoch 1
Epoch 1 ends in 0.01751995086669922 seconds.
5416 sentences created
mode 1: time used = 0.03367328643798828
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 174512.95it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 47, in forward
    loss = self.estimator(self.decoder(hx, hpos), self.decoder(hx, hneg))
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_decoder.py", line 15, in forward
    score = self.layer(x, y)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_decoder.py", line 36, in forward
    score = torch.squeeze(self.bil(x, y), dim=-1)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py", line 172, in forward
    return F.bilinear(input1, input2, self.weight, self.bias)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/functional.py", line 1701, in bilinear
    return torch.bilinear(input1, input2, weight, bias)
RuntimeError: CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 10.76 GiB total capacity; 467.62 MiB already allocated; 14.44 MiB free; 490.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.01995706558227539 seconds.
Run epoch 1
Epoch 1 ends in 0.017540454864501953 seconds.
5416 sentences created
mode 1: time used = 0.03814435005187988
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 131721.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21567/75824 [00:00<00:00, 215663.01it/s] 57%|    | 43390/75824 [00:00<00:00, 216425.11it/s] 85%| | 64569/75824 [00:00<00:00, 215012.07it/s]100%|| 75824/75824 [00:00<00:00, 214792.82it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 1.16 GiB (GPU 0; 10.76 GiB total capacity; 92.07 MiB already allocated; 602.44 MiB free; 102.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fb4c9e751e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7fb4ca0cb64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7fb4ca0cc464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7fb4ca0ccaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7fb2893bf90e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7fb2877f9949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7fb287813777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7fb4cb3c7c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7fb4cb3c7f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7fb4cb4d2a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7fb4cb1624f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7fb4cb164166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7fb4cb16465d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7fb4cb16480a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7fb4caea1eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7fb2877e8b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7fb4cad34530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7fb4cb51c81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7fb4cb46d82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7fb4cafa4952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7fb4cafa5f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7fb4cb5798c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7fb4cb5a308b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7fb4cb4ca337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7fb4cd0d8205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7fb4cb5a308b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7fb4cb4ca337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7fb4cd037f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7fb4cd653bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7fb4cd64f400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7fb4cd64ffa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7fb4cd648119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7fb4dade84ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7fb4dbf446df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7fb4dff9f6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7fb4e02d871f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.03547549247741699 seconds.
Run epoch 1
Epoch 1 ends in 0.0407862663269043 seconds.
5416 sentences created
mode 1: time used = 0.05664420127868652
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 55696.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9077/75824 [00:00<00:00, 90767.06it/s] 25%|       | 18804/75824 [00:00<00:00, 92622.59it/s] 36%|      | 27603/75824 [00:00<00:00, 91181.88it/s] 52%|    | 39211/75824 [00:00<00:00, 96606.18it/s] 62%|   | 46788/75824 [00:00<00:00, 76871.34it/s] 76%|  | 57550/75824 [00:00<00:00, 84076.66it/s] 90%| | 68307/75824 [00:00<00:00, 89970.78it/s]100%|| 75824/75824 [00:00<00:00, 93048.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11381/75824 [00:00<00:00, 113800.34it/s] 24%|       | 17944/75824 [00:00<00:00, 90616.07it/s]  33%|      | 24670/75824 [00:00<00:00, 82066.57it/s] 48%|     | 36118/75824 [00:00<00:00, 89683.76it/s] 63%|   | 47575/75824 [00:00<00:00, 95934.07it/s] 77%|  | 58679/75824 [00:00<00:00, 100013.26it/s] 89%| | 67807/75824 [00:00<00:00, 79834.96it/s] 100%|| 75824/75824 [00:00<00:00, 86763.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10076/75824 [00:00<00:00, 100756.73it/s] 29%|       | 21759/75824 [00:00<00:00, 105092.75it/s] 44%|     | 32986/75824 [00:00<00:00, 106226.30it/s] 59%|    | 44701/75824 [00:00<00:00, 109282.87it/s] 74%|  | 56482/75824 [00:00<00:00, 111705.97it/s] 90%| | 68299/75824 [00:00<00:00, 113567.07it/s]100%|| 75824/75824 [00:00<00:00, 113664.04it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11391/75824 [00:00<00:00, 113908.21it/s] 30%|       | 22982/75824 [00:00<00:00, 114500.10it/s] 46%|     | 34511/75824 [00:00<00:00, 114734.66it/s] 61%|   | 46482/75824 [00:00<00:00, 116183.16it/s] 77%|  | 58315/75824 [00:00<00:00, 116817.45it/s] 92%|| 69679/75824 [00:00<00:00, 114417.16it/s]100%|| 75824/75824 [00:00<00:00, 115516.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11337/75824 [00:00<00:00, 113363.89it/s] 24%|       | 17877/75824 [00:00<00:00, 92916.78it/s]  40%|      | 29967/75824 [00:00<00:00, 99848.42it/s] 53%|    | 40047/75824 [00:00<00:00, 100130.82it/s] 65%|   | 48982/75824 [00:00<00:00, 96631.33it/s]  75%|  | 57046/75824 [00:00<00:00, 85958.58it/s] 88%| | 66675/75824 [00:00<00:00, 88816.45it/s] 99%|| 74951/75824 [00:00<00:00, 78701.99it/s]100%|| 75824/75824 [00:00<00:00, 88317.81it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6590/75824 [00:00<00:01, 65898.33it/s] 13%|        | 9618/75824 [00:00<00:01, 44100.56it/s] 28%|       | 21367/75824 [00:00<00:01, 54270.43it/s] 43%|     | 32907/75824 [00:00<00:00, 64524.32it/s] 59%|    | 44527/75824 [00:00<00:00, 74457.33it/s] 74%|  | 56167/75824 [00:00<00:00, 83480.28it/s] 88%| | 66897/75824 [00:00<00:00, 89436.34it/s]100%|| 75824/75824 [00:00<00:00, 95083.10it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11764/75824 [00:00<00:00, 117637.59it/s] 30%|       | 23038/75824 [00:00<00:00, 116123.56it/s] 38%|      | 28891/75824 [00:00<00:00, 75353.79it/s]  54%|    | 40570/75824 [00:00<00:00, 84328.93it/s] 68%|   | 51927/75824 [00:00<00:00, 91386.99it/s] 84%| | 63381/75824 [00:00<00:00, 97285.23it/s] 99%|| 75003/75824 [00:00<00:00, 102283.21it/s]100%|| 75824/75824 [00:00<00:00, 101261.90it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8563/75824 [00:00<00:00, 85622.94it/s] 26%|       | 19511/75824 [00:00<00:00, 91611.43it/s] 41%|      | 31104/75824 [00:00<00:00, 97762.33it/s] 57%|    | 42889/75824 [00:00<00:00, 103030.62it/s] 71%|   | 53890/75824 [00:00<00:00, 105028.88it/s] 87%| | 65919/75824 [00:00<00:00, 109182.65it/s]100%|| 75824/75824 [00:00<00:00, 111100.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11319/75824 [00:00<00:00, 113182.82it/s] 26%|       | 19622/75824 [00:00<00:00, 102060.97it/s] 41%|      | 31045/75824 [00:00<00:00, 105429.09it/s] 56%|    | 42500/75824 [00:00<00:00, 108008.20it/s] 71%|  | 54106/75824 [00:00<00:00, 110302.24it/s] 84%| | 63342/75824 [00:00<00:00, 91265.63it/s]  99%|| 74766/75824 [00:00<00:00, 97125.35it/s]100%|| 75824/75824 [00:00<00:00, 100932.11it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7166/75824 [00:00<00:01, 65372.22it/s] 21%|        | 15667/75824 [00:00<00:00, 70239.07it/s] 34%|      | 26052/75824 [00:00<00:00, 77570.03it/s] 47%|     | 35823/75824 [00:00<00:00, 82681.42it/s] 57%|    | 42879/75824 [00:00<00:00, 76575.41it/s] 66%|   | 49744/75824 [00:00<00:00, 72778.01it/s] 77%|  | 58610/75824 [00:00<00:00, 76908.19it/s] 87%| | 66003/75824 [00:00<00:00, 75464.24it/s] 97%|| 73347/75824 [00:00<00:00, 70129.61it/s]100%|| 75824/75824 [00:00<00:00, 78168.17it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6403/75824 [00:00<00:01, 59822.40it/s] 16%|        | 12093/75824 [00:00<00:01, 58695.70it/s] 23%|       | 17774/75824 [00:00<00:01, 57946.12it/s] 34%|      | 25955/75824 [00:00<00:00, 63502.16it/s] 45%|     | 34259/75824 [00:00<00:00, 68323.41it/s] 56%|    | 42208/75824 [00:00<00:00, 71329.31it/s] 66%|   | 49752/75824 [00:00<00:00, 72514.52it/s] 75%|  | 57193/75824 [00:00<00:00, 73014.35it/s] 85%| | 64713/75824 [00:00<00:00, 73656.40it/s]100%|| 75824/75824 [00:01<00:00, 75161.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8854/75824 [00:00<00:00, 88534.60it/s] 24%|       | 18334/75824 [00:00<00:00, 90323.68it/s] 35%|      | 26737/75824 [00:00<00:00, 88336.99it/s] 51%|     | 38795/75824 [00:00<00:00, 96039.30it/s] 64%|   | 48863/75824 [00:00<00:00, 97385.45it/s] 76%|  | 57938/75824 [00:00<00:00, 93300.57it/s] 88%| | 66368/75824 [00:00<00:00, 81258.34it/s] 98%|| 74143/75824 [00:00<00:00, 72528.27it/s]100%|| 75824/75824 [00:00<00:00, 83435.74it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6670/75824 [00:00<00:01, 66699.59it/s] 17%|        | 13082/75824 [00:00<00:00, 65070.21it/s] 24%|       | 18318/75824 [00:00<00:00, 60652.97it/s] 30%|       | 22944/75824 [00:00<00:00, 55452.05it/s] 45%|     | 34320/75824 [00:00<00:00, 65527.67it/s] 61%|    | 45921/75824 [00:00<00:00, 75366.34it/s] 75%|  | 57194/75824 [00:00<00:00, 83687.11it/s] 91%| | 69049/75824 [00:00<00:00, 91784.47it/s]100%|| 75824/75824 [00:00<00:00, 87786.19it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7601/75824 [00:00<00:00, 76003.19it/s] 24%|       | 18504/75824 [00:00<00:00, 83598.92it/s] 40%|      | 30040/75824 [00:00<00:00, 91124.92it/s] 55%|    | 41565/75824 [00:00<00:00, 97230.30it/s] 70%|   | 53148/75824 [00:00<00:00, 102150.26it/s] 82%| | 62408/75824 [00:00<00:00, 92448.55it/s]  98%|| 74004/75824 [00:00<00:00, 98435.49it/s]100%|| 75824/75824 [00:00<00:00, 95278.45it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11506/75824 [00:00<00:00, 115059.84it/s] 29%|       | 22301/75824 [00:00<00:00, 112830.23it/s] 37%|      | 28347/75824 [00:00<00:00, 89554.93it/s]  52%|    | 39284/75824 [00:00<00:00, 94701.54it/s] 67%|   | 50908/75824 [00:00<00:00, 100274.50it/s] 83%| | 62607/75824 [00:00<00:00, 104763.56it/s] 98%|| 74373/75824 [00:00<00:00, 108324.23it/s]100%|| 75824/75824 [00:00<00:00, 106382.11it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11639/75824 [00:00<00:00, 116389.83it/s] 31%|       | 23147/75824 [00:00<00:00, 115992.12it/s] 46%|     | 34832/75824 [00:00<00:00, 116247.62it/s] 61%|    | 46237/75824 [00:00<00:00, 113766.32it/s] 75%|  | 56593/75824 [00:00<00:00, 110498.78it/s] 91%| | 69083/75824 [00:00<00:00, 114455.13it/s]100%|| 75824/75824 [00:00<00:00, 107875.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6793/75824 [00:00<00:01, 65002.23it/s] 19%|        | 14292/75824 [00:00<00:00, 67706.24it/s] 34%|      | 25892/75824 [00:00<00:00, 77369.05it/s] 50%|     | 37942/75824 [00:00<00:00, 86676.01it/s] 66%|   | 49959/75824 [00:00<00:00, 94583.51it/s] 82%| | 61925/75824 [00:00<00:00, 100926.85it/s] 95%|| 71871/75824 [00:00<00:00, 95530.63it/s] 100%|| 75824/75824 [00:00<00:00, 99898.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  4%|         | 2881/75824 [00:00<00:02, 25816.53it/s] 11%|         | 8465/75824 [00:00<00:02, 30780.90it/s] 21%|        | 15734/75824 [00:00<00:01, 37217.94it/s] 36%|      | 27341/75824 [00:00<00:01, 46744.37it/s] 44%|     | 33436/75824 [00:00<00:00, 49037.83it/s] 52%|    | 39364/75824 [00:00<00:00, 49338.89it/s] 67%|   | 51080/75824 [00:00<00:00, 59707.42it/s] 77%|  | 58551/75824 [00:00<00:00, 58860.25it/s] 86%| | 65490/75824 [00:00<00:00, 58329.27it/s]100%|| 75824/75824 [00:01<00:00, 69741.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10905/75824 [00:00<00:00, 109046.46it/s] 22%|       | 16997/75824 [00:00<00:00, 88153.40it/s]  32%|      | 24512/75824 [00:00<00:00, 83803.09it/s] 45%|     | 34012/75824 [00:00<00:00, 85680.69it/s] 55%|    | 41608/75824 [00:00<00:00, 82512.16it/s] 71%|   | 53523/75824 [00:00<00:00, 90896.53it/s] 87%| | 65681/75824 [00:00<00:00, 98341.48it/s]100%|| 75824/75824 [00:00<00:00, 95930.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11751/75824 [00:00<00:00, 117500.87it/s] 31%|       | 23163/75824 [00:00<00:00, 116464.09it/s] 46%|     | 34617/75824 [00:00<00:00, 115879.64it/s] 56%|    | 42177/75824 [00:00<00:00, 95953.27it/s]  65%|   | 49524/75824 [00:00<00:00, 71184.50it/s] 79%|  | 59886/75824 [00:00<00:00, 78560.94it/s] 94%|| 71232/75824 [00:00<00:00, 86546.07it/s]100%|| 75824/75824 [00:00<00:00, 91954.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9353/75824 [00:00<00:00, 93527.19it/s] 25%|       | 19233/75824 [00:00<00:00, 92003.16it/s] 35%|      | 26638/75824 [00:00<00:00, 85764.65it/s] 49%|     | 37291/75824 [00:00<00:00, 91090.36it/s] 65%|   | 49042/75824 [00:00<00:00, 97678.44it/s] 80%|  | 60856/75824 [00:00<00:00, 103030.97it/s] 96%|| 72712/75824 [00:00<00:00, 107243.98it/s]100%|| 75824/75824 [00:00<00:00, 102767.76it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6865/75824 [00:00<00:01, 68645.65it/s] 17%|        | 13258/75824 [00:00<00:00, 67157.84it/s] 28%|       | 21168/75824 [00:00<00:00, 70342.71it/s] 43%|     | 32611/75824 [00:00<00:00, 79534.81it/s] 52%|    | 39351/75824 [00:00<00:00, 74112.15it/s] 66%|   | 49927/75824 [00:00<00:00, 81420.93it/s] 81%| | 61690/75824 [00:00<00:00, 89704.73it/s] 95%|| 72195/75824 [00:00<00:00, 93814.11it/s]100%|| 75824/75824 [00:00<00:00, 87620.34it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6411/75824 [00:00<00:01, 64109.14it/s] 24%|       | 17826/75824 [00:00<00:00, 73816.89it/s] 39%|      | 29636/75824 [00:00<00:00, 83171.76it/s] 55%|    | 41607/75824 [00:00<00:00, 91553.50it/s] 70%|   | 53422/75824 [00:00<00:00, 98183.54it/s] 86%| | 65155/75824 [00:00<00:00, 103237.28it/s]100%|| 75824/75824 [00:00<00:00, 109094.76it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9799/75824 [00:00<00:00, 97989.39it/s] 28%|       | 21552/75824 [00:00<00:00, 103132.17it/s] 44%|     | 33456/75824 [00:00<00:00, 107438.58it/s] 60%|    | 45255/75824 [00:00<00:00, 110398.35it/s] 75%|  | 56613/75824 [00:00<00:00, 110410.73it/s] 87%| | 66069/75824 [00:00<00:00, 91864.32it/s] 100%|| 75824/75824 [00:00<00:00, 103959.21it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7569/75824 [00:00<00:00, 75684.66it/s] 25%|       | 18601/75824 [00:00<00:00, 83553.69it/s] 40%|      | 30704/75824 [00:00<00:00, 92109.08it/s] 55%|    | 41821/75824 [00:00<00:00, 97102.34it/s] 69%|   | 52254/75824 [00:00<00:00, 99162.81it/s] 81%|  | 61178/75824 [00:00<00:00, 90193.48it/s] 96%|| 72589/75824 [00:00<00:00, 95758.28it/s]100%|| 75824/75824 [00:00<00:00, 101224.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8535/75824 [00:00<00:00, 77413.80it/s] 17%|        | 12748/75824 [00:00<00:01, 61208.05it/s] 25%|       | 19123/75824 [00:00<00:00, 61947.52it/s] 38%|      | 29009/75824 [00:00<00:00, 69761.12it/s] 53%|    | 40351/75824 [00:00<00:00, 78867.72it/s] 68%|   | 51697/75824 [00:00<00:00, 86806.13it/s] 84%| | 63666/75824 [00:00<00:00, 94603.09it/s] 99%|| 75436/75824 [00:00<00:00, 99695.22it/s]100%|| 75824/75824 [00:00<00:00, 92514.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11110/75824 [00:00<00:00, 111097.19it/s] 29%|       | 21932/75824 [00:00<00:00, 110216.93it/s] 44%|     | 33330/75824 [00:00<00:00, 111317.20it/s] 59%|    | 44607/75824 [00:00<00:00, 111747.70it/s] 74%|  | 56057/75824 [00:00<00:00, 112557.45it/s] 89%| | 67523/75824 [00:00<00:00, 113178.11it/s]100%|| 75824/75824 [00:00<00:00, 112451.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10878/75824 [00:00<00:00, 108773.10it/s] 29%|       | 22348/75824 [00:00<00:00, 110484.20it/s] 45%|     | 34158/75824 [00:00<00:00, 112662.42it/s] 60%|    | 45653/75824 [00:00<00:00, 113337.11it/s] 74%|  | 55927/75824 [00:00<00:00, 109934.86it/s] 90%| | 68072/75824 [00:00<00:00, 113153.06it/s]100%|| 75824/75824 [00:00<00:00, 113420.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8915/75824 [00:00<00:00, 89148.60it/s] 27%|       | 20711/75824 [00:00<00:00, 96196.67it/s] 38%|      | 28715/75824 [00:00<00:00, 90701.87it/s] 46%|     | 34904/75824 [00:00<00:00, 74497.22it/s] 58%|    | 43909/75824 [00:00<00:00, 78521.75it/s] 72%|  | 54326/75824 [00:00<00:00, 84783.04it/s] 86%| | 65258/75824 [00:00<00:00, 90903.30it/s] 99%|| 75322/75824 [00:00<00:00, 93619.05it/s]100%|| 75824/75824 [00:00<00:00, 92189.08it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10185/75824 [00:00<00:00, 101843.78it/s] 28%|       | 20990/75824 [00:00<00:00, 103629.15it/s] 37%|      | 28369/75824 [00:00<00:00, 92417.49it/s]  52%|    | 39782/75824 [00:00<00:00, 98010.42it/s] 63%|   | 47392/75824 [00:00<00:00, 88818.42it/s] 76%|  | 57856/75824 [00:00<00:00, 92621.53it/s] 88%| | 66550/75824 [00:00<00:00, 88787.66it/s] 99%|| 74822/75824 [00:00<00:00, 83571.42it/s]100%|| 75824/75824 [00:00<00:00, 90841.99it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11553/75824 [00:00<00:00, 115520.19it/s] 20%|        | 15399/75824 [00:00<00:00, 72147.27it/s]  33%|      | 25030/75824 [00:00<00:00, 78016.83it/s] 40%|      | 30425/75824 [00:00<00:00, 62095.48it/s] 56%|    | 42325/75824 [00:00<00:00, 72495.27it/s] 71%|   | 54007/75824 [00:00<00:00, 81806.77it/s] 87%| | 65788/75824 [00:00<00:00, 90063.32it/s]100%|| 75824/75824 [00:00<00:00, 93143.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9476/75824 [00:00<00:00, 92846.40it/s] 17%|        | 12896/75824 [00:00<00:01, 61306.26it/s] 32%|      | 24046/75824 [00:00<00:00, 70877.15it/s] 47%|     | 35619/75824 [00:00<00:00, 80200.79it/s] 60%|    | 45234/75824 [00:00<00:00, 83449.42it/s] 70%|   | 53089/75824 [00:00<00:00, 69741.22it/s] 85%| | 64141/75824 [00:00<00:00, 78421.67it/s]100%|| 75824/75824 [00:00<00:00, 88284.76it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11576/75824 [00:00<00:00, 115751.28it/s] 31%|       | 23228/75824 [00:00<00:00, 115980.37it/s] 46%|     | 34945/75824 [00:00<00:00, 116332.60it/s] 60%|    | 45371/75824 [00:00<00:00, 112424.20it/s] 84%| | 63588/75824 [00:00<00:00, 127011.67it/s]100%|| 75824/75824 [00:00<00:00, 134091.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18446/75824 [00:00<00:00, 184459.30it/s] 50%|     | 38180/75824 [00:00<00:00, 188141.42it/s] 77%|  | 58203/75824 [00:00<00:00, 191609.33it/s]100%|| 75824/75824 [00:00<00:00, 194750.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|       | 17805/75824 [00:00<00:00, 178043.38it/s] 43%|     | 32859/75824 [00:00<00:00, 168791.23it/s] 61%|    | 46051/75824 [00:00<00:00, 155731.49it/s] 79%|  | 59819/75824 [00:00<00:00, 149836.36it/s] 93%|| 70765/75824 [00:00<00:00, 125243.54it/s]100%|| 75824/75824 [00:00<00:00, 130008.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9298/75824 [00:00<00:00, 92979.42it/s] 35%|      | 26911/75824 [00:00<00:00, 108320.75it/s] 47%|     | 35325/75824 [00:00<00:00, 99540.70it/s]  63%|   | 48088/75824 [00:00<00:00, 106577.01it/s] 90%| | 68279/75824 [00:00<00:00, 124163.77it/s]100%|| 75824/75824 [00:00<00:00, 140980.70it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12860/75824 [00:00<00:00, 128596.14it/s] 37%|      | 28091/75824 [00:00<00:00, 134894.86it/s] 64%|   | 48491/75824 [00:00<00:00, 150152.85it/s] 91%|| 69351/75824 [00:00<00:00, 163932.35it/s]100%|| 75824/75824 [00:00<00:00, 175813.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19278/75824 [00:00<00:00, 192772.83it/s] 52%|    | 39397/75824 [00:00<00:00, 195220.84it/s] 79%|  | 59853/75824 [00:00<00:00, 197929.53it/s]100%|| 75824/75824 [00:00<00:00, 201881.20it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 14890/75824 [00:00<00:00, 148897.66it/s] 40%|      | 30219/75824 [00:00<00:00, 150188.32it/s] 60%|    | 45657/75824 [00:00<00:00, 151420.82it/s] 81%|  | 61160/75824 [00:00<00:00, 152485.63it/s]100%|| 75824/75824 [00:00<00:00, 153610.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13696/75824 [00:00<00:00, 136959.48it/s] 38%|      | 29129/75824 [00:00<00:00, 141745.56it/s] 59%|    | 44564/75824 [00:00<00:00, 145304.86it/s] 79%|  | 59727/75824 [00:00<00:00, 147146.23it/s] 94%|| 71438/75824 [00:00<00:00, 136631.97it/s]100%|| 75824/75824 [00:00<00:00, 138067.90it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11067/75824 [00:00<00:00, 110667.99it/s] 36%|      | 26969/75824 [00:00<00:00, 121775.90it/s] 59%|    | 45013/75824 [00:00<00:00, 134936.15it/s] 86%| | 65550/75824 [00:00<00:00, 150410.68it/s]100%|| 75824/75824 [00:00<00:00, 168481.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|       | 17807/75824 [00:00<00:00, 178061.68it/s] 50%|     | 37897/75824 [00:00<00:00, 184347.19it/s] 77%|  | 58697/75824 [00:00<00:00, 190857.04it/s]100%|| 75824/75824 [00:00<00:00, 198398.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19279/75824 [00:00<00:00, 192787.89it/s] 52%|    | 39580/75824 [00:00<00:00, 195742.53it/s] 79%|  | 60255/75824 [00:00<00:00, 198918.94it/s]100%|| 75824/75824 [00:00<00:00, 200466.90it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18974/75824 [00:00<00:00, 189733.85it/s] 49%|     | 37052/75824 [00:00<00:00, 186953.36it/s] 75%|  | 57163/75824 [00:00<00:00, 190985.06it/s] 95%|| 72124/75824 [00:00<00:00, 176351.11it/s]100%|| 75824/75824 [00:00<00:00, 162079.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13906/75824 [00:00<00:00, 135543.18it/s] 24%|       | 17973/75824 [00:00<00:00, 76118.32it/s]  36%|      | 27395/75824 [00:00<00:00, 80773.46it/s] 51%|     | 38752/75824 [00:00<00:00, 88434.80it/s] 73%|  | 55404/75824 [00:00<00:00, 102912.17it/s]100%|| 75824/75824 [00:00<00:00, 124752.15it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6618/75824 [00:00<00:01, 62160.52it/s] 28%|       | 21106/75824 [00:00<00:00, 75008.24it/s] 44%|     | 33007/75824 [00:00<00:00, 82479.32it/s] 53%|    | 40187/75824 [00:00<00:00, 71574.41it/s] 69%|   | 52468/75824 [00:00<00:00, 81814.06it/s] 85%| | 64446/75824 [00:00<00:00, 90411.15it/s]100%|| 75824/75824 [00:00<00:00, 105844.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18663/75824 [00:00<00:00, 186626.17it/s] 51%|     | 38448/75824 [00:00<00:00, 189856.57it/s] 77%|  | 58462/75824 [00:00<00:00, 192828.02it/s]100%|| 75824/75824 [00:00<00:00, 197028.79it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18663/75824 [00:00<00:00, 186629.29it/s] 52%|    | 39366/75824 [00:00<00:00, 192314.28it/s] 78%|  | 59234/75824 [00:00<00:00, 194178.90it/s]100%|| 75824/75824 [00:00<00:00, 199352.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 15137/75824 [00:00<00:00, 151363.29it/s] 44%|     | 33281/75824 [00:00<00:00, 159282.35it/s] 71%|   | 53679/75824 [00:00<00:00, 170489.71it/s] 98%|| 74160/75824 [00:00<00:00, 179512.15it/s]100%|| 75824/75824 [00:00<00:00, 185624.57it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19302/75824 [00:00<00:00, 193014.66it/s] 52%|    | 39516/75824 [00:00<00:00, 195663.13it/s] 79%|  | 59704/75824 [00:00<00:00, 197487.25it/s]100%|| 75824/75824 [00:00<00:00, 197157.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18117/75824 [00:00<00:00, 181163.26it/s] 51%|     | 38579/75824 [00:00<00:00, 187614.80it/s] 78%|  | 59295/75824 [00:00<00:00, 193079.62it/s]100%|| 75824/75824 [00:00<00:00, 199762.76it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18704/75824 [00:00<00:00, 187039.29it/s] 51%|    | 38962/75824 [00:00<00:00, 191443.35it/s] 78%|  | 59024/75824 [00:00<00:00, 194104.61it/s]100%|| 75824/75824 [00:00<00:00, 199233.53it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 14829/75824 [00:00<00:00, 148279.89it/s] 40%|      | 30066/75824 [00:00<00:00, 149481.94it/s] 59%|    | 44902/75824 [00:00<00:00, 149142.98it/s] 82%| | 62487/75824 [00:00<00:00, 156260.79it/s]100%|| 75824/75824 [00:00<00:00, 163220.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|        | 15901/75824 [00:00<00:00, 159004.84it/s] 46%|     | 34998/75824 [00:00<00:00, 167409.86it/s] 72%|  | 54807/75824 [00:00<00:00, 175566.91it/s] 99%|| 75369/75824 [00:00<00:00, 183617.33it/s]100%|| 75824/75824 [00:00<00:00, 188381.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 17958/75824 [00:00<00:00, 179574.61it/s] 47%|     | 35592/75824 [00:00<00:00, 178591.24it/s] 59%|    | 44654/75824 [00:00<00:00, 115276.53it/s] 78%|  | 59169/75824 [00:00<00:00, 122290.70it/s] 96%|| 72892/75824 [00:00<00:00, 126417.46it/s]100%|| 75824/75824 [00:00<00:00, 132309.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|        | 15725/75824 [00:00<00:00, 157248.28it/s] 45%|     | 34215/75824 [00:00<00:00, 164633.58it/s] 71%|   | 53503/75824 [00:00<00:00, 172198.18it/s] 97%|| 73354/75824 [00:00<00:00, 179327.56it/s]100%|| 75824/75824 [00:00<00:00, 183804.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16534/75824 [00:00<00:00, 165337.79it/s] 48%|     | 36448/75824 [00:00<00:00, 174207.86it/s] 75%|  | 56634/75824 [00:00<00:00, 181673.40it/s]100%|| 75824/75824 [00:00<00:00, 192234.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 15198/75824 [00:00<00:00, 151979.78it/s] 39%|      | 29690/75824 [00:00<00:00, 149787.50it/s] 56%|    | 42130/75824 [00:00<00:00, 141145.12it/s] 67%|   | 51140/75824 [00:00<00:00, 107530.04it/s] 84%| | 64036/75824 [00:00<00:00, 111926.84it/s] 97%|| 73614/75824 [00:00<00:00, 98163.77it/s] 100%|| 75824/75824 [00:00<00:00, 111808.19it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13877/75824 [00:00<00:00, 138767.15it/s] 44%|     | 33256/75824 [00:00<00:00, 151687.05it/s] 60%|    | 45811/75824 [00:00<00:00, 142768.05it/s] 73%|  | 55687/75824 [00:00<00:00, 97585.87it/s]  91%|| 69238/75824 [00:00<00:00, 106529.17it/s]100%|| 75824/75824 [00:00<00:00, 119471.89it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19599/75824 [00:00<00:00, 195985.51it/s] 52%|    | 39771/75824 [00:00<00:00, 197670.83it/s] 80%|  | 60325/75824 [00:00<00:00, 199966.80it/s]100%|| 75824/75824 [00:00<00:00, 201772.71it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19823/75824 [00:00<00:00, 198224.52it/s] 54%|    | 41316/75824 [00:00<00:00, 202955.53it/s] 84%| | 64065/75824 [00:00<00:00, 209739.33it/s]100%|| 75824/75824 [00:00<00:00, 216994.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 31%|       | 23576/75824 [00:00<00:00, 235759.66it/s] 62%|   | 47331/75824 [00:00<00:00, 236292.98it/s] 81%|  | 61371/75824 [00:00<00:00, 196108.82it/s] 98%|| 74038/75824 [00:00<00:00, 135093.73it/s]100%|| 75824/75824 [00:00<00:00, 157472.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9540/75824 [00:00<00:00, 95396.22it/s] 23%|       | 17406/75824 [00:00<00:00, 89670.34it/s] 39%|      | 29765/75824 [00:00<00:00, 97715.12it/s] 56%|    | 42106/75824 [00:00<00:00, 104223.27it/s] 72%|  | 54605/75824 [00:00<00:00, 109688.95it/s] 85%| | 64260/75824 [00:00<00:00, 100846.28it/s] 97%|| 73565/75824 [00:00<00:00, 94562.21it/s] 100%|| 75824/75824 [00:00<00:00, 99188.04it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10871/75824 [00:00<00:00, 108703.37it/s] 29%|       | 21717/75824 [00:00<00:00, 108627.78it/s] 43%|     | 32780/75824 [00:00<00:00, 109220.67it/s] 58%|    | 43758/75824 [00:00<00:00, 109385.41it/s] 72%|  | 54938/75824 [00:00<00:00, 110097.63it/s] 87%| | 66319/75824 [00:00<00:00, 111184.76it/s]100%|| 75824/75824 [00:00<00:00, 103400.60it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8212/75824 [00:00<00:00, 69021.15it/s] 18%|        | 13555/75824 [00:00<00:00, 63464.84it/s] 34%|      | 25621/75824 [00:00<00:00, 73985.90it/s] 50%|     | 37639/75824 [00:00<00:00, 83626.21it/s] 66%|   | 49735/75824 [00:00<00:00, 92158.68it/s] 81%|  | 61549/75824 [00:00<00:00, 98667.50it/s] 97%|| 73544/75824 [00:00<00:00, 104212.83it/s]100%|| 75824/75824 [00:00<00:00, 102677.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9279/75824 [00:00<00:00, 92782.35it/s] 27%|       | 20523/75824 [00:00<00:00, 97917.40it/s] 39%|      | 29461/75824 [00:00<00:00, 95188.28it/s] 54%|    | 41222/75824 [00:00<00:00, 100961.09it/s] 70%|   | 53028/75824 [00:00<00:00, 105545.49it/s] 84%| | 63810/75824 [00:00<00:00, 106215.94it/s] 97%|| 73450/75824 [00:00<00:00, 87964.24it/s] 100%|| 75824/75824 [00:00<00:00, 94447.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11623/75824 [00:00<00:00, 116222.91it/s] 28%|       | 21200/75824 [00:00<00:00, 109223.78it/s] 42%|     | 31895/75824 [00:00<00:00, 108531.27it/s] 56%|    | 42373/75824 [00:00<00:00, 107377.94it/s] 72%|  | 54300/75824 [00:00<00:00, 110688.76it/s] 87%| | 65801/75824 [00:00<00:00, 111947.72it/s]100%|| 75824/75824 [00:00<00:00, 111858.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10799/75824 [00:00<00:00, 107983.92it/s] 28%|       | 21371/75824 [00:00<00:00, 107294.35it/s] 43%|     | 32983/75824 [00:00<00:00, 109795.92it/s] 57%|    | 43384/75824 [00:00<00:00, 107965.15it/s] 73%|  | 55159/75824 [00:00<00:00, 108975.51it/s] 86%| | 64880/75824 [00:00<00:00, 105156.84it/s]100%|| 75824/75824 [00:00<00:00, 108514.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11666/75824 [00:00<00:00, 116653.44it/s] 31%|       | 23177/75824 [00:00<00:00, 116183.76it/s] 41%|      | 31053/75824 [00:00<00:00, 97556.43it/s]  55%|    | 41756/75824 [00:00<00:00, 100215.75it/s] 71%|   | 53779/75824 [00:00<00:00, 105481.10it/s] 87%| | 65797/75824 [00:00<00:00, 109498.10it/s]100%|| 75824/75824 [00:00<00:00, 108982.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6443/75824 [00:00<00:01, 59175.73it/s] 15%|        | 11538/75824 [00:00<00:01, 55683.81it/s] 28%|       | 21311/75824 [00:00<00:00, 63934.85it/s] 44%|     | 33214/75824 [00:00<00:00, 74243.74it/s] 60%|    | 45310/75824 [00:00<00:00, 83973.08it/s] 76%|  | 57580/75824 [00:00<00:00, 92755.21it/s] 92%|| 69840/75824 [00:00<00:00, 100062.43it/s]100%|| 75824/75824 [00:00<00:00, 99578.93it/s] 
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6151/75824 [00:00<00:01, 60365.87it/s] 14%|        | 10287/75824 [00:00<00:01, 52944.58it/s] 18%|        | 13914/75824 [00:00<00:01, 44754.96it/s] 25%|       | 18595/75824 [00:00<00:01, 45352.10it/s] 32%|      | 24000/75824 [00:00<00:01, 47160.95it/s] 38%|      | 28798/75824 [00:00<00:01, 46414.53it/s] 43%|     | 32861/75824 [00:00<00:01, 40662.57it/s] 50%|     | 38243/75824 [00:00<00:00, 43880.32it/s] 66%|   | 49866/75824 [00:00<00:00, 53955.68it/s] 78%|  | 59113/75824 [00:01<00:00, 61659.70it/s] 89%| | 67313/75824 [00:01<00:00, 66616.68it/s] 99%|| 74887/75824 [00:01<00:00, 68401.25it/s]100%|| 75824/75824 [00:01<00:00, 59969.00it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4218/75824 [00:00<00:01, 42178.03it/s] 10%|         | 7542/75824 [00:00<00:01, 36880.64it/s] 16%|        | 12121/75824 [00:00<00:01, 39166.24it/s] 26%|       | 19410/75824 [00:00<00:01, 45478.20it/s] 35%|      | 26622/75824 [00:00<00:00, 51087.80it/s] 47%|     | 35504/75824 [00:00<00:00, 58548.87it/s] 62%|   | 46889/75824 [00:00<00:00, 67557.37it/s] 75%|  | 56911/75824 [00:00<00:00, 74877.02it/s] 86%| | 65136/75824 [00:00<00:00, 74679.25it/s] 96%|| 73120/75824 [00:01<00:00, 73084.88it/s]100%|| 75824/75824 [00:01<00:00, 70624.08it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11414/75824 [00:00<00:00, 114131.13it/s] 30%|       | 23116/75824 [00:00<00:00, 114982.33it/s] 46%|     | 34679/75824 [00:00<00:00, 115175.82it/s] 61%|   | 46466/75824 [00:00<00:00, 115970.19it/s] 77%|  | 58129/75824 [00:00<00:00, 116164.15it/s] 92%|| 69873/75824 [00:00<00:00, 116543.85it/s]100%|| 75824/75824 [00:00<00:00, 116593.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6455/75824 [00:00<00:01, 63298.96it/s] 16%|        | 11843/75824 [00:00<00:01, 60055.51it/s] 29%|       | 21858/75824 [00:00<00:00, 68252.46it/s] 44%|     | 33142/75824 [00:00<00:00, 77430.49it/s] 59%|    | 44413/75824 [00:00<00:00, 85453.63it/s] 73%|  | 55728/75824 [00:00<00:00, 92225.58it/s] 88%| | 67075/75824 [00:00<00:00, 97712.87it/s]100%|| 75824/75824 [00:00<00:00, 97406.08it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 7995/75824 [00:00<00:00, 79945.88it/s] 22%|       | 16816/75824 [00:00<00:00, 82257.74it/s] 37%|      | 28258/75824 [00:00<00:00, 89831.48it/s] 53%|    | 39865/75824 [00:00<00:00, 96366.62it/s] 68%|   | 51270/75824 [00:00<00:00, 101066.13it/s] 83%| | 62755/75824 [00:00<00:00, 104839.50it/s] 99%|| 74913/75824 [00:00<00:00, 109355.57it/s]100%|| 75824/75824 [00:00<00:00, 106257.14it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11262/75824 [00:00<00:00, 112615.54it/s] 30%|       | 22426/75824 [00:00<00:00, 112319.59it/s] 45%|     | 33761/75824 [00:00<00:00, 112624.45it/s] 60%|    | 45325/75824 [00:00<00:00, 113512.03it/s] 75%|  | 56829/75824 [00:00<00:00, 113965.61it/s] 87%| | 66335/75824 [00:00<00:00, 96345.19it/s]  99%|| 75113/75824 [00:00<00:00, 91111.27it/s]100%|| 75824/75824 [00:00<00:00, 101198.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6871/75824 [00:00<00:01, 68705.32it/s] 19%|        | 14447/75824 [00:00<00:00, 70679.68it/s] 35%|      | 26202/75824 [00:00<00:00, 80282.71it/s] 50%|     | 38236/75824 [00:00<00:00, 89189.04it/s] 66%|   | 50376/75824 [00:00<00:00, 96902.26it/s] 82%| | 62413/75824 [00:00<00:00, 102921.15it/s] 96%|| 72445/75824 [00:00<00:00, 86317.12it/s] 100%|| 75824/75824 [00:00<00:00, 96353.88it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12530/75824 [00:00<00:00, 125294.44it/s] 32%|      | 24470/75824 [00:00<00:00, 123465.84it/s] 44%|     | 33457/75824 [00:00<00:00, 109927.48it/s] 53%|    | 40433/75824 [00:00<00:00, 86814.88it/s]  62%|   | 47063/75824 [00:00<00:00, 78291.52it/s] 74%|  | 56087/75824 [00:00<00:00, 81529.21it/s] 89%| | 67317/75824 [00:00<00:00, 88830.20it/s]100%|| 75824/75824 [00:00<00:00, 92704.72it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5414/75824 [00:00<00:01, 54137.34it/s] 23%|       | 17061/75824 [00:00<00:00, 64491.76it/s] 31%|       | 23414/75824 [00:00<00:00, 63404.03it/s] 46%|     | 34792/75824 [00:00<00:00, 73115.56it/s] 58%|    | 44083/75824 [00:00<00:00, 76440.35it/s] 73%|  | 55722/75824 [00:00<00:00, 85213.70it/s] 85%| | 64422/75824 [00:00<00:00, 77544.13it/s] 96%|| 72479/75824 [00:00<00:00, 78426.57it/s]100%|| 75824/75824 [00:00<00:00, 86461.97it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10272/75824 [00:00<00:00, 102716.67it/s] 24%|       | 18396/75824 [00:00<00:00, 94388.19it/s]  30%|       | 22935/75824 [00:00<00:00, 68827.65it/s] 38%|      | 28665/75824 [00:00<00:00, 63110.62it/s] 47%|     | 35403/75824 [00:00<00:00, 64332.27it/s] 60%|    | 45864/75824 [00:00<00:00, 72732.86it/s] 74%|  | 55981/75824 [00:00<00:00, 79415.57it/s] 88%| | 66983/75824 [00:00<00:00, 86645.13it/s]100%|| 75824/75824 [00:00<00:00, 84332.57it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12044/75824 [00:00<00:00, 120430.93it/s] 31%|      | 23844/75824 [00:00<00:00, 119690.10it/s] 47%|     | 35784/75824 [00:00<00:00, 119600.56it/s] 63%|   | 47845/75824 [00:00<00:00, 119899.09it/s] 75%|  | 56945/75824 [00:00<00:00, 98488.14it/s]  90%| | 68583/75824 [00:00<00:00, 103249.71it/s]100%|| 75824/75824 [00:00<00:00, 109497.19it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10492/75824 [00:00<00:00, 104918.85it/s] 24%|       | 17980/75824 [00:00<00:00, 92538.83it/s]  38%|      | 29122/75824 [00:00<00:00, 97494.14it/s] 54%|    | 40662/75824 [00:00<00:00, 100730.81it/s] 69%|   | 52340/75824 [00:00<00:00, 105061.34it/s] 85%| | 64186/75824 [00:00<00:00, 108751.25it/s]100%|| 75824/75824 [00:00<00:00, 107479.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9114/75824 [00:00<00:00, 91136.39it/s] 28%|       | 21331/75824 [00:00<00:00, 98653.96it/s] 38%|      | 28491/75824 [00:00<00:00, 82056.60it/s] 45%|     | 34164/75824 [00:00<00:00, 65171.59it/s] 52%|    | 39457/75824 [00:00<00:00, 56875.10it/s] 62%|   | 46786/75824 [00:00<00:00, 60970.90it/s] 77%|  | 58506/75824 [00:00<00:00, 71221.75it/s] 93%|| 70245/75824 [00:00<00:00, 80748.30it/s]100%|| 75824/75824 [00:00<00:00, 82565.00it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6281/75824 [00:00<00:01, 57715.14it/s] 16%|        | 12299/75824 [00:00<00:01, 58432.26it/s] 29%|       | 22148/75824 [00:00<00:00, 66551.69it/s] 42%|     | 31826/75824 [00:00<00:00, 71413.84it/s] 50%|     | 37956/75824 [00:00<00:00, 60727.16it/s] 64%|   | 48218/75824 [00:00<00:00, 66290.04it/s] 74%|  | 55909/75824 [00:00<00:00, 66117.58it/s] 82%| | 62416/75824 [00:00<00:00, 62540.59it/s] 91%| | 68637/75824 [00:01<00:00, 61977.34it/s]100%|| 75824/75824 [00:01<00:00, 70338.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10131/75824 [00:00<00:00, 95613.58it/s] 20%|        | 15075/75824 [00:00<00:00, 74333.79it/s] 33%|      | 24907/75824 [00:00<00:00, 79825.53it/s] 40%|      | 30234/75824 [00:00<00:00, 64147.35it/s] 47%|     | 35669/75824 [00:00<00:00, 60689.55it/s] 58%|    | 43773/75824 [00:00<00:00, 62473.80it/s] 67%|   | 50522/75824 [00:00<00:00, 63898.51it/s] 78%|  | 58764/75824 [00:00<00:00, 68452.57it/s] 92%|| 69599/75824 [00:00<00:00, 76952.36it/s]100%|| 75824/75824 [00:01<00:00, 75374.00it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10154/75824 [00:00<00:00, 101531.62it/s] 28%|       | 21240/75824 [00:00<00:00, 104159.52it/s] 39%|      | 29522/75824 [00:00<00:00, 93110.65it/s]  47%|     | 35585/75824 [00:00<00:00, 80217.27it/s] 62%|   | 46979/75824 [00:00<00:00, 88033.79it/s] 77%|  | 58565/75824 [00:00<00:00, 94868.76it/s] 89%| | 67404/75824 [00:00<00:00, 83179.00it/s]100%|| 75824/75824 [00:00<00:00, 92789.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10620/75824 [00:00<00:00, 106193.27it/s] 29%|       | 21708/75824 [00:00<00:00, 107554.94it/s] 44%|     | 33274/75824 [00:00<00:00, 109864.58it/s] 59%|    | 44937/75824 [00:00<00:00, 111809.52it/s] 75%|  | 56545/75824 [00:00<00:00, 113056.70it/s] 90%| | 68323/75824 [00:00<00:00, 114431.63it/s]100%|| 75824/75824 [00:00<00:00, 113281.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10139/75824 [00:00<00:00, 101382.12it/s] 28%|       | 20929/75824 [00:00<00:00, 101345.73it/s] 35%|      | 26905/75824 [00:00<00:00, 83095.69it/s]  44%|     | 32984/75824 [00:00<00:00, 74855.08it/s] 52%|    | 39112/75824 [00:00<00:00, 70189.96it/s] 59%|    | 44905/75824 [00:00<00:00, 64697.54it/s] 67%|   | 50880/75824 [00:00<00:00, 62728.50it/s] 81%|  | 61152/75824 [00:00<00:00, 71022.70it/s] 96%|| 72852/75824 [00:00<00:00, 80514.47it/s]100%|| 75824/75824 [00:00<00:00, 80492.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11022/75824 [00:00<00:00, 110215.90it/s] 28%|       | 21485/75824 [00:00<00:00, 108476.35it/s] 43%|     | 32268/75824 [00:00<00:00, 108281.28it/s] 56%|    | 42811/75824 [00:00<00:00, 107407.67it/s] 69%|   | 52208/75824 [00:00<00:00, 102986.80it/s] 80%|  | 60697/75824 [00:00<00:00, 87411.57it/s]  90%| | 68578/75824 [00:00<00:00, 73831.22it/s]100%|| 75720/75824 [00:00<00:00, 67106.06it/s]100%|| 75824/75824 [00:00<00:00, 83255.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10538/75824 [00:00<00:00, 105370.55it/s] 20%|        | 15517/75824 [00:00<00:00, 75122.66it/s]  34%|      | 25903/75824 [00:00<00:00, 81921.08it/s] 49%|     | 36983/75824 [00:00<00:00, 88869.67it/s] 64%|   | 48176/75824 [00:00<00:00, 94724.29it/s] 76%|  | 57827/75824 [00:00<00:00, 94157.90it/s] 90%| | 68120/75824 [00:00<00:00, 96627.53it/s]100%|| 75824/75824 [00:00<00:00, 92157.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11395/75824 [00:00<00:00, 113943.32it/s] 30%|       | 23006/75824 [00:00<00:00, 114583.44it/s] 46%|     | 34562/75824 [00:00<00:00, 114873.40it/s] 61%|    | 46091/75824 [00:00<00:00, 114997.44it/s] 73%|  | 55225/75824 [00:00<00:00, 106703.32it/s] 89%| | 67676/75824 [00:00<00:00, 111486.02it/s]100%|| 75824/75824 [00:00<00:00, 112138.09it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12108/75824 [00:00<00:00, 121076.94it/s] 31%|       | 23568/75824 [00:00<00:00, 119056.09it/s] 47%|     | 35740/75824 [00:00<00:00, 119841.20it/s] 63%|   | 47900/75824 [00:00<00:00, 120361.55it/s] 78%|  | 59473/75824 [00:00<00:00, 118933.31it/s] 94%|| 71588/75824 [00:00<00:00, 119586.66it/s]100%|| 75824/75824 [00:00<00:00, 118651.08it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8820/75824 [00:00<00:00, 88197.77it/s] 21%|        | 15837/75824 [00:00<00:00, 81886.16it/s] 33%|      | 25048/75824 [00:00<00:00, 84705.42it/s] 48%|     | 36464/75824 [00:00<00:00, 91811.69it/s] 64%|   | 48252/75824 [00:00<00:00, 98334.92it/s] 75%|  | 57053/75824 [00:00<00:00, 94989.48it/s] 88%| | 66911/75824 [00:00<00:00, 93091.94it/s]100%|| 75664/75824 [00:00<00:00, 68143.53it/s]100%|| 75824/75824 [00:00<00:00, 82083.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11934/75824 [00:00<00:00, 119332.72it/s] 29%|       | 22048/75824 [00:00<00:00, 112561.01it/s] 36%|      | 27627/75824 [00:00<00:00, 86233.59it/s]  50%|     | 38192/75824 [00:00<00:00, 91265.01it/s] 64%|   | 48709/75824 [00:00<00:00, 95033.04it/s] 79%|  | 59907/75824 [00:00<00:00, 99551.86it/s] 94%|| 71046/75824 [00:00<00:00, 102829.00it/s]100%|| 75824/75824 [00:00<00:00, 101857.74it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8968/75824 [00:00<00:00, 89679.02it/s] 24%|       | 18349/75824 [00:00<00:00, 88699.42it/s] 33%|      | 24711/75824 [00:00<00:00, 79316.41it/s] 46%|     | 35222/75824 [00:00<00:00, 85618.65it/s] 56%|    | 42832/75824 [00:00<00:00, 81175.12it/s] 68%|   | 51449/75824 [00:00<00:00, 82611.67it/s] 79%|  | 59877/75824 [00:00<00:00, 83104.63it/s] 92%|| 69898/75824 [00:00<00:00, 87588.70it/s]100%|| 75824/75824 [00:00<00:00, 87657.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11215/75824 [00:00<00:00, 112141.55it/s] 28%|       | 20882/75824 [00:00<00:00, 107002.17it/s] 41%|     | 31307/75824 [00:00<00:00, 106161.03it/s] 57%|    | 42923/75824 [00:00<00:00, 108973.53it/s] 70%|   | 53146/75824 [00:00<00:00, 106858.74it/s] 82%| | 62483/75824 [00:00<00:00, 102417.20it/s] 94%|| 71473/75824 [00:00<00:00, 95567.56it/s] 100%|| 75824/75824 [00:00<00:00, 98177.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11199/75824 [00:00<00:00, 111986.37it/s] 30%|       | 22789/75824 [00:00<00:00, 113131.11it/s] 45%|     | 34491/75824 [00:00<00:00, 114268.96it/s] 61%|    | 46210/75824 [00:00<00:00, 115127.23it/s] 77%|  | 58022/75824 [00:00<00:00, 116006.52it/s] 92%|| 69808/75824 [00:00<00:00, 116556.37it/s]100%|| 75824/75824 [00:00<00:00, 116472.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11486/75824 [00:00<00:00, 114854.91it/s] 31%|       | 23180/75824 [00:00<00:00, 115472.05it/s] 46%|     | 34918/75824 [00:00<00:00, 116035.54it/s] 61%|    | 46055/75824 [00:00<00:00, 114592.76it/s] 76%|  | 57916/75824 [00:00<00:00, 115768.05it/s] 92%|| 69706/75824 [00:00<00:00, 116398.13it/s]100%|| 75824/75824 [00:00<00:00, 116407.08it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11218/75824 [00:00<00:00, 112178.50it/s] 31%|       | 23241/75824 [00:00<00:00, 114475.94it/s] 45%|     | 34020/75824 [00:00<00:00, 112383.60it/s] 58%|    | 43866/75824 [00:00<00:00, 107809.22it/s] 74%|  | 56272/75824 [00:00<00:00, 112217.50it/s] 87%| | 65691/75824 [00:00<00:00, 94866.90it/s]  98%|| 74376/75824 [00:00<00:00, 87454.49it/s]100%|| 75824/75824 [00:00<00:00, 99047.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11202/75824 [00:00<00:00, 112017.70it/s] 30%|       | 22479/75824 [00:00<00:00, 112239.97it/s] 44%|     | 33608/75824 [00:00<00:00, 111952.83it/s] 59%|    | 45099/75824 [00:00<00:00, 112823.04it/s] 74%|  | 56114/75824 [00:00<00:00, 112007.23it/s] 89%| | 67676/75824 [00:00<00:00, 113066.37it/s]100%|| 75824/75824 [00:00<00:00, 113262.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8817/75824 [00:00<00:00, 88164.62it/s] 24%|       | 18444/75824 [00:00<00:00, 90448.02it/s] 32%|      | 24281/75824 [00:00<00:00, 77427.23it/s] 41%|      | 30863/75824 [00:00<00:00, 73433.43it/s] 54%|    | 41214/75824 [00:00<00:00, 80445.61it/s] 70%|   | 53362/75824 [00:00<00:00, 89516.46it/s] 87%| | 65851/75824 [00:00<00:00, 97828.76it/s]100%|| 75559/75824 [00:00<00:00, 88310.77it/s]100%|| 75824/75824 [00:00<00:00, 90369.53it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7310/75824 [00:00<00:00, 73094.67it/s] 18%|        | 13668/75824 [00:00<00:00, 68985.72it/s] 27%|       | 20770/75824 [00:00<00:00, 69582.70it/s] 42%|     | 31968/75824 [00:00<00:00, 78497.96it/s] 57%|    | 43521/75824 [00:00<00:00, 86848.41it/s] 69%|   | 52515/75824 [00:00<00:00, 87356.61it/s] 80%|  | 60783/75824 [00:00<00:00, 74558.96it/s] 90%| | 68238/75824 [00:00<00:00, 64151.07it/s] 99%|| 74908/75824 [00:01<00:00, 53915.12it/s]100%|| 75824/75824 [00:01<00:00, 68453.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4846/75824 [00:00<00:01, 44840.16it/s] 14%|        | 10728/75824 [00:00<00:01, 48282.10it/s] 27%|       | 20611/75824 [00:00<00:00, 57033.15it/s] 35%|      | 26861/75824 [00:00<00:00, 58568.92it/s] 45%|     | 33800/75824 [00:00<00:00, 61443.45it/s] 59%|    | 44841/75824 [00:00<00:00, 70872.26it/s] 75%|  | 56664/75824 [00:00<00:00, 80550.57it/s] 90%| | 68554/75824 [00:00<00:00, 89178.99it/s]100%|| 75824/75824 [00:00<00:00, 84590.21it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8600/75824 [00:00<00:00, 85994.55it/s] 26%|       | 19364/75824 [00:00<00:00, 90590.07it/s] 35%|      | 26747/75824 [00:00<00:00, 84812.30it/s] 51%|     | 38420/75824 [00:00<00:00, 92390.80it/s] 64%|   | 48547/75824 [00:00<00:00, 94884.65it/s] 77%|  | 58173/75824 [00:00<00:00, 95291.65it/s] 88%| | 66842/75824 [00:00<00:00, 92065.97it/s]100%|| 75824/75824 [00:00<00:00, 96206.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8930/75824 [00:00<00:00, 89297.53it/s] 27%|       | 20547/75824 [00:00<00:00, 95955.88it/s] 41%|      | 30981/75824 [00:00<00:00, 98324.32it/s] 53%|    | 40393/75824 [00:00<00:00, 96258.47it/s] 63%|   | 47964/75824 [00:00<00:00, 82100.77it/s] 77%|  | 58119/75824 [00:00<00:00, 87105.15it/s] 92%|| 69560/75824 [00:00<00:00, 91980.62it/s]100%|| 75824/75824 [00:00<00:00, 90340.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6591/75824 [00:00<00:01, 65904.88it/s] 20%|        | 15453/75824 [00:00<00:00, 71394.47it/s] 30%|       | 22415/75824 [00:00<00:00, 70850.71it/s] 41%|      | 30756/75824 [00:00<00:00, 72722.09it/s] 52%|    | 39317/75824 [00:00<00:00, 76160.52it/s] 61%|    | 46099/75824 [00:00<00:00, 73448.83it/s] 72%|  | 54734/75824 [00:00<00:00, 76894.99it/s] 82%| | 61986/75824 [00:00<00:00, 73215.73it/s] 91%| | 69038/75824 [00:00<00:00, 69937.78it/s]100%|| 75824/75824 [00:00<00:00, 76731.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5174/75824 [00:00<00:01, 48730.67it/s] 20%|        | 15141/75824 [00:00<00:01, 57140.81it/s] 25%|       | 19115/75824 [00:00<00:01, 50505.86it/s] 33%|      | 24655/75824 [00:00<00:00, 51880.05it/s] 46%|     | 34536/75824 [00:00<00:00, 60398.93it/s] 53%|    | 40557/75824 [00:00<00:00, 58433.70it/s] 61%|    | 46401/75824 [00:00<00:00, 58136.36it/s] 69%|   | 52216/75824 [00:00<00:00, 56461.09it/s] 78%|  | 59238/75824 [00:00<00:00, 59478.01it/s] 93%|| 70489/75824 [00:01<00:00, 69272.74it/s]100%|| 75824/75824 [00:01<00:00, 67731.78it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5469/75824 [00:00<00:01, 53848.62it/s] 23%|       | 17245/75824 [00:00<00:00, 64320.81it/s] 36%|      | 27160/75824 [00:00<00:00, 71897.60it/s] 46%|     | 35025/75824 [00:00<00:00, 73797.44it/s] 59%|    | 45013/75824 [00:00<00:00, 80069.38it/s] 70%|   | 52718/75824 [00:00<00:00, 65654.33it/s] 78%|  | 59499/75824 [00:00<00:00, 64039.81it/s] 93%|| 70505/75824 [00:00<00:00, 73225.15it/s]100%|| 75824/75824 [00:00<00:00, 81851.75it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6911/75824 [00:00<00:01, 66599.05it/s] 24%|       | 17851/75824 [00:00<00:00, 75454.06it/s] 32%|      | 24322/75824 [00:00<00:00, 71873.68it/s] 40%|      | 30634/75824 [00:00<00:00, 69001.55it/s] 53%|    | 40426/75824 [00:00<00:00, 75708.14it/s] 62%|   | 47295/75824 [00:00<00:00, 73456.17it/s] 71%|  | 54130/75824 [00:00<00:00, 68834.26it/s] 80%|  | 60715/75824 [00:00<00:00, 66356.08it/s] 89%| | 67161/75824 [00:00<00:00, 63891.34it/s] 97%|| 73437/75824 [00:01<00:00, 62555.74it/s]100%|| 75824/75824 [00:01<00:00, 69853.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 7999/75824 [00:00<00:00, 74223.40it/s] 18%|        | 13789/75824 [00:00<00:00, 67922.80it/s] 30%|       | 22678/75824 [00:00<00:00, 73094.99it/s] 45%|     | 34049/75824 [00:00<00:00, 81866.69it/s] 56%|    | 42127/75824 [00:00<00:00, 80234.70it/s] 65%|   | 49240/75824 [00:00<00:00, 73630.95it/s] 76%|  | 57374/75824 [00:00<00:00, 75785.66it/s] 90%| | 68553/75824 [00:00<00:00, 83889.67it/s]100%|| 75824/75824 [00:00<00:00, 84817.55it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7217/75824 [00:00<00:00, 72164.39it/s] 17%|        | 12629/75824 [00:00<00:00, 65328.08it/s] 30%|       | 22606/75824 [00:00<00:00, 72874.14it/s] 45%|     | 34131/75824 [00:00<00:00, 81908.35it/s] 60%|    | 45790/75824 [00:00<00:00, 89933.69it/s] 76%|  | 57595/75824 [00:00<00:00, 96852.02it/s] 92%|| 69533/75824 [00:00<00:00, 102663.29it/s]100%|| 75824/75824 [00:00<00:00, 100885.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7250/75824 [00:00<00:00, 72497.65it/s] 21%|        | 15669/75824 [00:00<00:00, 75649.35it/s] 31%|       | 23193/75824 [00:00<00:00, 75525.61it/s] 42%|     | 32189/75824 [00:00<00:00, 79344.33it/s] 57%|    | 43460/75824 [00:00<00:00, 87076.12it/s] 68%|   | 51838/75824 [00:00<00:00, 83604.93it/s] 80%|  | 60368/75824 [00:00<00:00, 84105.82it/s] 90%| | 68338/75824 [00:00<00:00, 78023.04it/s]100%|| 75824/75824 [00:00<00:00, 83124.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11340/75824 [00:00<00:00, 113399.30it/s] 30%|       | 22786/75824 [00:00<00:00, 113715.15it/s] 46%|     | 34585/75824 [00:00<00:00, 114963.87it/s] 61%|    | 46307/75824 [00:00<00:00, 115630.84it/s] 77%|  | 58313/75824 [00:00<00:00, 116924.43it/s] 90%| | 68106/75824 [00:00<00:00, 100674.59it/s]100%|| 75824/75824 [00:00<00:00, 106372.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9363/75824 [00:00<00:00, 93626.29it/s] 22%|       | 16944/75824 [00:00<00:00, 85810.16it/s] 31%|       | 23608/75824 [00:00<00:00, 78992.60it/s] 43%|     | 32411/75824 [00:00<00:00, 79728.28it/s] 53%|    | 39960/75824 [00:00<00:00, 78405.99it/s] 66%|   | 50149/75824 [00:00<00:00, 83585.54it/s] 76%|  | 57572/75824 [00:00<00:00, 70290.68it/s] 88%| | 66804/75824 [00:00<00:00, 75710.04it/s] 98%|| 74288/75824 [00:01<00:00, 62618.84it/s]100%|| 75824/75824 [00:01<00:00, 70887.90it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11508/75824 [00:00<00:00, 115074.07it/s] 22%|       | 16642/75824 [00:00<00:00, 82372.87it/s]  38%|      | 28591/75824 [00:00<00:00, 90837.68it/s] 54%|    | 40609/75824 [00:00<00:00, 98016.54it/s] 66%|   | 50056/75824 [00:00<00:00, 96922.11it/s] 77%|  | 58509/75824 [00:00<00:00, 79835.13it/s] 87%| | 66123/75824 [00:00<00:00, 68170.47it/s] 96%|| 72978/75824 [00:00<00:00, 62829.38it/s]100%|| 75824/75824 [00:00<00:00, 79228.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8207/75824 [00:00<00:00, 80307.99it/s] 19%|        | 14093/75824 [00:00<00:00, 71331.60it/s] 29%|       | 21764/75824 [00:00<00:00, 72050.00it/s] 42%|     | 31693/75824 [00:00<00:00, 78511.04it/s] 50%|     | 37983/75824 [00:00<00:00, 73069.10it/s] 65%|   | 49651/75824 [00:00<00:00, 82296.50it/s] 82%| | 61888/75824 [00:00<00:00, 91261.68it/s] 97%|| 73885/75824 [00:00<00:00, 98318.81it/s]100%|| 75824/75824 [00:00<00:00, 91733.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6322/75824 [00:00<00:01, 61907.03it/s] 24%|       | 18059/75824 [00:00<00:00, 72132.67it/s] 39%|      | 29862/75824 [00:00<00:00, 81657.99it/s] 55%|    | 41785/75824 [00:00<00:00, 90182.35it/s] 72%|  | 54339/75824 [00:00<00:00, 98503.99it/s] 88%| | 66736/75824 [00:00<00:00, 104971.27it/s]100%|| 75824/75824 [00:00<00:00, 110733.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7559/75824 [00:00<00:00, 75587.01it/s] 25%|       | 18829/75824 [00:00<00:00, 83871.48it/s] 38%|      | 28840/75824 [00:00<00:00, 88161.23it/s] 52%|    | 39282/75824 [00:00<00:00, 92480.74it/s] 62%|   | 46952/75824 [00:00<00:00, 77583.71it/s] 71%|   | 54013/75824 [00:00<00:00, 72003.54it/s] 80%|  | 60805/75824 [00:00<00:00, 63427.40it/s] 89%| | 67842/75824 [00:00<00:00, 65361.06it/s] 98%|| 74324/75824 [00:00<00:00, 64619.91it/s]100%|| 75824/75824 [00:01<00:00, 75250.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6895/75824 [00:00<00:00, 68947.11it/s] 24%|       | 17995/75824 [00:00<00:00, 77787.71it/s] 39%|      | 29778/75824 [00:00<00:00, 86618.14it/s] 53%|    | 40463/75824 [00:00<00:00, 91334.29it/s] 65%|   | 49540/75824 [00:00<00:00, 91162.46it/s] 81%|  | 61419/75824 [00:00<00:00, 97998.40it/s] 93%|| 70787/75824 [00:00<00:00, 94577.92it/s]100%|| 75824/75824 [00:00<00:00, 100681.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6063/75824 [00:00<00:01, 60629.19it/s] 16%|        | 12184/75824 [00:00<00:01, 60801.60it/s] 26%|       | 19677/75824 [00:00<00:00, 64445.93it/s] 41%|     | 31463/75824 [00:00<00:00, 74586.60it/s] 53%|    | 39979/75824 [00:00<00:00, 77472.14it/s] 67%|   | 50946/75824 [00:00<00:00, 84954.20it/s] 79%|  | 60026/75824 [00:00<00:00, 86625.66it/s] 95%|| 71939/75824 [00:00<00:00, 94347.23it/s]100%|| 75824/75824 [00:00<00:00, 91016.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6746/75824 [00:00<00:01, 67457.65it/s] 18%|        | 13633/75824 [00:00<00:00, 67873.49it/s] 31%|       | 23598/75824 [00:00<00:00, 75052.63it/s] 41%|      | 30928/75824 [00:00<00:00, 74517.26it/s] 49%|     | 36926/75824 [00:00<00:00, 61818.15it/s] 63%|   | 47913/75824 [00:00<00:00, 71153.06it/s] 78%|  | 58844/75824 [00:00<00:00, 79474.82it/s] 91%| | 69153/75824 [00:00<00:00, 85338.08it/s]100%|| 75824/75824 [00:00<00:00, 78246.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10021/75824 [00:00<00:00, 100192.66it/s] 28%|       | 21534/75824 [00:00<00:00, 104248.26it/s] 44%|     | 33304/75824 [00:00<00:00, 107947.66it/s] 55%|    | 41452/75824 [00:00<00:00, 98360.85it/s]  65%|   | 49092/75824 [00:00<00:00, 84271.42it/s] 74%|  | 56335/75824 [00:00<00:00, 79345.85it/s] 87%| | 65803/75824 [00:00<00:00, 83397.11it/s] 97%|| 73659/75824 [00:00<00:00, 74818.60it/s]100%|| 75824/75824 [00:00<00:00, 86844.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10238/75824 [00:00<00:00, 102377.66it/s] 28%|       | 21127/75824 [00:00<00:00, 104247.03it/s] 42%|     | 32188/75824 [00:00<00:00, 106077.22it/s] 55%|    | 41774/75824 [00:00<00:00, 102789.22it/s] 72%|  | 54826/75824 [00:00<00:00, 109785.85it/s] 88%| | 66551/75824 [00:00<00:00, 111920.72it/s]100%|| 75824/75824 [00:00<00:00, 111665.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 5813/75824 [00:00<00:01, 56460.59it/s] 21%|        | 15898/75824 [00:00<00:00, 65049.79it/s] 36%|      | 27339/75824 [00:00<00:00, 74720.36it/s] 52%|    | 39139/75824 [00:00<00:00, 83958.54it/s] 67%|   | 50602/75824 [00:00<00:00, 91284.51it/s] 80%|  | 60335/75824 [00:00<00:00, 93017.70it/s] 92%|| 69585/75824 [00:00<00:00, 87431.31it/s]100%|| 75824/75824 [00:00<00:00, 96818.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10986/75824 [00:00<00:00, 109850.15it/s] 29%|       | 22177/75824 [00:00<00:00, 110459.98it/s] 44%|     | 33728/75824 [00:00<00:00, 111925.78it/s] 60%|    | 45487/75824 [00:00<00:00, 113565.61it/s] 75%|  | 57156/75824 [00:00<00:00, 114485.17it/s] 91%| | 69107/75824 [00:00<00:00, 115947.15it/s]100%|| 75824/75824 [00:00<00:00, 115502.73it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11602/75824 [00:00<00:00, 116015.96it/s] 31%|       | 23293/75824 [00:00<00:00, 116280.53it/s] 46%|     | 35010/75824 [00:00<00:00, 116545.32it/s] 62%|   | 46670/75824 [00:00<00:00, 116560.75it/s] 77%|  | 58476/75824 [00:00<00:00, 117004.64it/s] 93%|| 70340/75824 [00:00<00:00, 117488.86it/s]100%|| 75824/75824 [00:00<00:00, 116446.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11816/75824 [00:00<00:00, 118159.83it/s] 31%|       | 23462/75824 [00:00<00:00, 117642.77it/s] 47%|     | 35413/75824 [00:00<00:00, 118196.32it/s] 63%|   | 47419/75824 [00:00<00:00, 118749.02it/s] 79%|  | 59524/75824 [00:00<00:00, 119429.69it/s] 94%|| 71575/75824 [00:00<00:00, 119749.90it/s]100%|| 75824/75824 [00:00<00:00, 119333.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12933/75824 [00:00<00:00, 129320.87it/s] 32%|      | 24485/75824 [00:00<00:00, 124842.53it/s] 48%|     | 36089/75824 [00:00<00:00, 122063.97it/s] 63%|   | 47790/75824 [00:00<00:00, 120501.67it/s] 75%|  | 56793/75824 [00:00<00:00, 109393.26it/s] 90%| | 68540/75824 [00:00<00:00, 111694.58it/s]100%|| 75824/75824 [00:00<00:00, 114473.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6865/75824 [00:00<00:01, 65520.94it/s] 25%|       | 18660/75824 [00:00<00:00, 75602.27it/s] 38%|      | 28514/75824 [00:00<00:00, 81277.78it/s] 52%|    | 39458/75824 [00:00<00:00, 88076.42it/s] 68%|   | 51214/75824 [00:00<00:00, 95241.09it/s] 80%|  | 60611/75824 [00:00<00:00, 94855.24it/s] 95%|| 72351/75824 [00:00<00:00, 100653.64it/s]100%|| 75824/75824 [00:00<00:00, 103178.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6979/75824 [00:00<00:00, 69789.07it/s] 17%|        | 12943/75824 [00:00<00:00, 64728.73it/s] 30%|       | 22634/75824 [00:00<00:00, 71889.46it/s] 41%|      | 31011/75824 [00:00<00:00, 75038.96it/s] 54%|    | 40957/75824 [00:00<00:00, 81004.81it/s] 69%|   | 52367/75824 [00:00<00:00, 88723.71it/s] 85%| | 64201/75824 [00:00<00:00, 95925.43it/s] 97%|| 73693/75824 [00:00<00:00, 91584.37it/s]100%|| 75824/75824 [00:00<00:00, 89757.54it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8888/75824 [00:00<00:00, 87656.45it/s] 21%|        | 15763/75824 [00:00<00:00, 80974.26it/s] 36%|      | 27341/75824 [00:00<00:00, 89000.61it/s] 48%|     | 36149/75824 [00:00<00:00, 88721.61it/s] 59%|    | 45012/75824 [00:00<00:00, 86632.21it/s] 71%|   | 53615/75824 [00:00<00:00, 86449.69it/s] 86%| | 64869/75824 [00:00<00:00, 92910.79it/s] 97%|| 73656/75824 [00:00<00:00, 80727.96it/s]100%|| 75824/75824 [00:00<00:00, 85069.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11052/75824 [00:00<00:00, 110516.94it/s] 23%|       | 17647/75824 [00:00<00:00, 91884.92it/s]  32%|      | 24271/75824 [00:00<00:00, 82321.99it/s] 47%|     | 35932/75824 [00:00<00:00, 90285.60it/s] 63%|   | 47813/75824 [00:00<00:00, 97291.02it/s] 79%|  | 59759/75824 [00:00<00:00, 103024.89it/s] 94%|| 70929/75824 [00:00<00:00, 105481.95it/s]100%|| 75824/75824 [00:00<00:00, 97538.24it/s] 
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7883/75824 [00:00<00:01, 64157.88it/s] 18%|        | 13669/75824 [00:00<00:01, 62127.89it/s] 34%|      | 25511/75824 [00:00<00:00, 72460.82it/s] 41%|      | 31222/75824 [00:00<00:00, 57167.85it/s] 54%|    | 40835/75824 [00:00<00:00, 65080.31it/s] 70%|   | 52727/75824 [00:00<00:00, 75308.18it/s] 85%| | 64681/75824 [00:00<00:00, 84711.14it/s]100%|| 75824/75824 [00:00<00:00, 87589.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10677/75824 [00:00<00:00, 106762.21it/s] 22%|       | 16776/75824 [00:00<00:00, 85228.87it/s]  33%|      | 25060/75824 [00:00<00:00, 84496.04it/s] 49%|     | 36982/75824 [00:00<00:00, 92584.23it/s] 65%|   | 49147/75824 [00:00<00:00, 99731.30it/s] 80%|  | 60676/75824 [00:00<00:00, 103937.25it/s] 96%|| 72530/75824 [00:00<00:00, 107923.95it/s]100%|| 75824/75824 [00:00<00:00, 103515.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5200/75824 [00:00<00:01, 51996.70it/s] 17%|        | 12807/75824 [00:00<00:01, 57449.80it/s] 26%|       | 19954/75824 [00:00<00:00, 60764.05it/s] 35%|      | 26161/75824 [00:00<00:00, 61148.66it/s] 46%|     | 35028/75824 [00:00<00:00, 67426.55it/s] 54%|    | 41181/75824 [00:00<00:00, 64242.06it/s] 65%|   | 49387/75824 [00:00<00:00, 68717.19it/s] 74%|  | 56090/75824 [00:00<00:00, 66246.68it/s] 83%| | 62690/75824 [00:00<00:00, 66172.22it/s] 91%|| 69233/75824 [00:01<00:00, 62479.75it/s]100%|| 75824/75824 [00:01<00:00, 69778.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10180/75824 [00:00<00:00, 101790.87it/s] 27%|       | 20301/75824 [00:00<00:00, 101614.99it/s] 41%|     | 31435/75824 [00:00<00:00, 104349.13it/s] 53%|    | 39911/75824 [00:00<00:00, 97582.45it/s]  68%|   | 51736/75824 [00:00<00:00, 102982.13it/s] 84%| | 63481/75824 [00:00<00:00, 106932.02it/s] 99%|| 74821/75824 [00:00<00:00, 107672.93it/s]100%|| 75824/75824 [00:00<00:00, 105111.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11684/75824 [00:00<00:00, 116839.28it/s] 31%|       | 23437/75824 [00:00<00:00, 117043.67it/s] 39%|      | 29417/75824 [00:00<00:00, 90852.69it/s]  47%|     | 35394/75824 [00:00<00:00, 78124.17it/s] 55%|    | 41618/75824 [00:00<00:00, 71554.41it/s] 63%|   | 47927/75824 [00:00<00:00, 68784.46it/s] 71%|   | 53992/75824 [00:00<00:00, 65721.07it/s] 79%|  | 60034/75824 [00:00<00:00, 63683.14it/s] 87%| | 66107/75824 [00:00<00:00, 61931.14it/s] 95%|| 72362/75824 [00:01<00:00, 62115.21it/s]100%|| 75824/75824 [00:01<00:00, 70465.17it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8660/75824 [00:00<00:00, 86598.43it/s] 22%|       | 16565/75824 [00:00<00:00, 83637.54it/s] 30%|       | 22856/75824 [00:00<00:00, 76113.10it/s] 44%|     | 33697/75824 [00:00<00:00, 83579.63it/s] 59%|    | 44907/75824 [00:00<00:00, 90484.29it/s] 75%|  | 56770/75824 [00:00<00:00, 97417.09it/s] 87%| | 65918/75824 [00:00<00:00, 93464.17it/s]100%|| 75824/75824 [00:00<00:00, 95763.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6602/75824 [00:00<00:01, 63512.31it/s] 16%|        | 12469/75824 [00:00<00:01, 61977.50it/s] 24%|       | 17824/75824 [00:00<00:00, 59123.34it/s] 39%|      | 29513/75824 [00:00<00:00, 69414.62it/s] 54%|    | 40714/75824 [00:00<00:00, 78352.63it/s] 69%|   | 52306/75824 [00:00<00:00, 86790.52it/s] 85%| | 64085/75824 [00:00<00:00, 94229.85it/s]100%|| 75824/75824 [00:00<00:00, 94405.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 17059/75824 [00:00<00:00, 170582.44it/s] 46%|     | 34613/75824 [00:00<00:00, 172039.86it/s] 68%|   | 51899/75824 [00:00<00:00, 172282.18it/s] 91%| | 69142/75824 [00:00<00:00, 172324.70it/s]100%|| 75824/75824 [00:00<00:00, 174228.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13392/75824 [00:00<00:00, 133918.85it/s] 43%|     | 32742/75824 [00:00<00:00, 147546.90it/s] 66%|   | 50008/75824 [00:00<00:00, 154276.94it/s] 91%|| 69268/75824 [00:00<00:00, 164069.30it/s]100%|| 75824/75824 [00:00<00:00, 175844.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 17843/75824 [00:00<00:00, 178419.96it/s] 47%|     | 35602/75824 [00:00<00:00, 178168.68it/s] 74%|  | 56366/75824 [00:00<00:00, 186091.67it/s]100%|| 75824/75824 [00:00<00:00, 193182.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19337/75824 [00:00<00:00, 193365.57it/s] 52%|    | 39792/75824 [00:00<00:00, 196587.42it/s] 69%|   | 52095/75824 [00:00<00:00, 166689.01it/s] 94%|| 70976/75824 [00:00<00:00, 172760.36it/s]100%|| 75824/75824 [00:00<00:00, 178886.81it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20401/75824 [00:00<00:00, 204006.79it/s] 51%|     | 38753/75824 [00:00<00:00, 197393.53it/s] 76%|  | 57781/75824 [00:00<00:00, 195202.58it/s]100%|| 75824/75824 [00:00<00:00, 191273.15it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16492/75824 [00:00<00:00, 164911.11it/s] 47%|     | 35842/75824 [00:00<00:00, 172559.12it/s] 74%|  | 56207/75824 [00:00<00:00, 180839.96it/s]100%|| 75824/75824 [00:00<00:00, 195038.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9028/75824 [00:00<00:00, 85304.74it/s] 16%|        | 12253/75824 [00:00<00:01, 56644.20it/s] 21%|        | 15720/75824 [00:00<00:01, 47593.90it/s] 39%|      | 29659/75824 [00:00<00:00, 59311.37it/s] 64%|   | 48289/75824 [00:00<00:00, 74557.51it/s] 90%| | 68486/75824 [00:00<00:00, 91961.52it/s]100%|| 75824/75824 [00:00<00:00, 118097.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8724/75824 [00:00<00:00, 78709.51it/s] 22%|       | 16996/75824 [00:00<00:00, 79869.81it/s] 28%|       | 21131/75824 [00:00<00:00, 57584.37it/s] 42%|     | 32207/75824 [00:00<00:00, 67273.49it/s] 66%|   | 50355/75824 [00:00<00:00, 82929.88it/s] 92%|| 69819/75824 [00:00<00:00, 100178.19it/s]100%|| 75824/75824 [00:00<00:00, 115152.60it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19229/75824 [00:00<00:00, 192289.72it/s] 49%|     | 36920/75824 [00:00<00:00, 187400.23it/s] 70%|   | 53380/75824 [00:00<00:00, 179922.04it/s] 95%|| 72173/75824 [00:00<00:00, 182251.26it/s]100%|| 75824/75824 [00:00<00:00, 181588.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18717/75824 [00:00<00:00, 187162.15it/s] 50%|     | 37887/75824 [00:00<00:00, 188498.85it/s] 75%|  | 57209/75824 [00:00<00:00, 189889.78it/s]100%|| 75824/75824 [00:00<00:00, 190778.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19614/75824 [00:00<00:00, 196137.38it/s] 53%|    | 40023/75824 [00:00<00:00, 198457.10it/s] 79%|  | 60126/75824 [00:00<00:00, 199219.12it/s]100%|| 75824/75824 [00:00<00:00, 201983.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19707/75824 [00:00<00:00, 197064.08it/s] 54%|    | 40575/75824 [00:00<00:00, 200409.17it/s] 80%|  | 60768/75824 [00:00<00:00, 200861.21it/s]100%|| 75824/75824 [00:00<00:00, 203492.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18725/75824 [00:00<00:00, 187247.95it/s] 52%|    | 39074/75824 [00:00<00:00, 191839.10it/s] 77%|  | 58464/75824 [00:00<00:00, 192451.17it/s]100%|| 75824/75824 [00:00<00:00, 196954.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19597/75824 [00:00<00:00, 195964.58it/s] 53%|    | 40061/75824 [00:00<00:00, 198487.93it/s] 79%|  | 60002/75824 [00:00<00:00, 198761.02it/s]100%|| 75824/75824 [00:00<00:00, 201841.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18034/75824 [00:00<00:00, 180332.86it/s] 52%|    | 39370/75824 [00:00<00:00, 189113.11it/s] 79%|  | 59842/75824 [00:00<00:00, 193539.27it/s]100%|| 75824/75824 [00:00<00:00, 201152.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20106/75824 [00:00<00:00, 201059.23it/s] 52%|    | 39605/75824 [00:00<00:00, 199198.34it/s] 75%|  | 57107/75824 [00:00<00:00, 191270.93it/s]100%|| 75824/75824 [00:00<00:00, 194010.09it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16858/75824 [00:00<00:00, 163829.29it/s] 31%|       | 23328/75824 [00:00<00:00, 110337.43it/s] 39%|      | 29846/75824 [00:00<00:00, 91347.98it/s]  48%|     | 36361/75824 [00:00<00:00, 81512.22it/s] 56%|    | 42441/75824 [00:00<00:00, 72715.43it/s] 64%|   | 48350/75824 [00:00<00:00, 67239.53it/s] 72%|  | 54856/75824 [00:00<00:00, 66569.10it/s] 81%|  | 61320/75824 [00:00<00:00, 65977.68it/s] 89%| | 67488/75824 [00:00<00:00, 60233.74it/s] 97%|| 73411/75824 [00:01<00:00, 59928.52it/s]100%|| 75824/75824 [00:01<00:00, 68574.17it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 5796/75824 [00:00<00:01, 52798.87it/s] 19%|        | 14386/75824 [00:00<00:01, 59699.64it/s] 27%|       | 20132/75824 [00:00<00:00, 59008.30it/s] 39%|      | 29544/75824 [00:00<00:00, 66380.21it/s] 51%|    | 38907/75824 [00:00<00:00, 72729.79it/s] 62%|   | 47101/75824 [00:00<00:00, 75267.14it/s] 72%|  | 54379/75824 [00:00<00:00, 72735.35it/s] 81%|  | 61497/75824 [00:00<00:00, 70091.16it/s] 90%| | 68513/75824 [00:00<00:00, 69773.94it/s] 99%|| 75429/75824 [00:01<00:00, 66604.06it/s]100%|| 75824/75824 [00:01<00:00, 71929.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11700/75824 [00:00<00:00, 116995.09it/s] 30%|       | 23087/75824 [00:00<00:00, 116036.86it/s] 46%|     | 35060/75824 [00:00<00:00, 117119.21it/s] 62%|   | 46767/75824 [00:00<00:00, 117103.39it/s] 77%|  | 58667/75824 [00:00<00:00, 116488.99it/s] 93%|| 70829/75824 [00:00<00:00, 117982.20it/s]100%|| 75824/75824 [00:00<00:00, 116354.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13447/75824 [00:00<00:00, 134467.24it/s] 33%|      | 24990/75824 [00:00<00:00, 128125.11it/s] 49%|     | 36982/75824 [00:00<00:00, 125546.02it/s] 65%|   | 48911/75824 [00:00<00:00, 123599.68it/s] 77%|  | 58089/75824 [00:00<00:00, 101239.63it/s] 88%| | 66649/75824 [00:00<00:00, 95554.27it/s]  99%|| 75176/75824 [00:00<00:00, 84227.43it/s]100%|| 75824/75824 [00:00<00:00, 98983.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10332/75824 [00:00<00:00, 103313.94it/s] 28%|       | 21066/75824 [00:00<00:00, 104488.55it/s] 42%|     | 32021/75824 [00:00<00:00, 104288.75it/s] 51%|    | 38909/75824 [00:00<00:00, 65409.69it/s]  64%|   | 48464/75824 [00:00<00:00, 71454.85it/s] 73%|  | 55307/75824 [00:00<00:00, 64331.48it/s] 81%| | 61663/75824 [00:00<00:00, 63427.52it/s] 90%| | 68616/75824 [00:00<00:00, 65141.81it/s]100%|| 75824/75824 [00:01<00:00, 75488.65it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10221/75824 [00:00<00:00, 102201.81it/s] 28%|       | 21564/75824 [00:00<00:00, 105327.72it/s] 44%|     | 33199/75824 [00:00<00:00, 108407.87it/s] 58%|    | 44284/75824 [00:00<00:00, 109127.32it/s] 70%|   | 52772/75824 [00:00<00:00, 84174.34it/s]  85%| | 64291/75824 [00:00<00:00, 91569.69it/s]100%|| 75824/75824 [00:00<00:00, 100773.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9178/75824 [00:00<00:00, 91773.74it/s] 27%|       | 20799/75824 [00:00<00:00, 97951.10it/s] 43%|     | 32619/75824 [00:00<00:00, 103256.39it/s] 59%|    | 44378/75824 [00:00<00:00, 107173.43it/s] 74%|  | 55862/75824 [00:00<00:00, 107789.18it/s] 86%| | 65577/75824 [00:00<00:00, 104358.08it/s] 99%|| 75031/75824 [00:00<00:00, 90959.36it/s] 100%|| 75824/75824 [00:00<00:00, 101457.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  5%|         | 3528/75824 [00:00<00:02, 35277.51it/s] 14%|        | 10898/75824 [00:00<00:01, 41817.82it/s] 30%|       | 22744/75824 [00:00<00:01, 51889.03it/s] 45%|     | 34387/75824 [00:00<00:00, 62239.19it/s] 61%|    | 46174/75824 [00:00<00:00, 72504.41it/s] 77%|  | 58072/75824 [00:00<00:00, 82128.31it/s] 92%|| 69837/75824 [00:00<00:00, 90306.54it/s]100%|| 75824/75824 [00:00<00:00, 100969.60it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6473/75824 [00:00<00:01, 64724.35it/s] 23%|       | 17535/75824 [00:00<00:00, 73925.37it/s] 34%|      | 25923/75824 [00:00<00:00, 72689.92it/s] 42%|     | 32160/75824 [00:00<00:00, 69251.29it/s] 50%|     | 38129/75824 [00:00<00:00, 66074.43it/s] 65%|   | 49158/75824 [00:00<00:00, 75106.46it/s] 80%|  | 60324/75824 [00:00<00:00, 83285.81it/s] 94%|| 71481/75824 [00:00<00:00, 90139.49it/s]100%|| 75824/75824 [00:00<00:00, 88285.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9631/75824 [00:00<00:00, 91556.02it/s] 18%|        | 13344/75824 [00:00<00:00, 63590.37it/s] 32%|      | 24168/75824 [00:00<00:00, 72570.43it/s] 42%|     | 31662/75824 [00:00<00:00, 73264.46it/s] 53%|    | 39810/75824 [00:00<00:00, 75549.31it/s] 66%|   | 50030/75824 [00:00<00:00, 81643.76it/s] 80%|  | 60387/75824 [00:00<00:00, 87178.86it/s] 95%|| 72333/75824 [00:00<00:00, 94868.99it/s]100%|| 75824/75824 [00:00<00:00, 90644.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7417/75824 [00:00<00:00, 74169.89it/s] 25%|       | 19104/75824 [00:00<00:00, 83300.23it/s] 40%|      | 30706/75824 [00:00<00:00, 90998.27it/s] 56%|    | 42470/75824 [00:00<00:00, 97629.39it/s] 72%|  | 54464/75824 [00:00<00:00, 103398.42it/s] 84%| | 63975/75824 [00:00<00:00, 98658.10it/s]  97%|| 73307/75824 [00:00<00:00, 94815.19it/s]100%|| 75824/75824 [00:00<00:00, 101658.97it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6040/75824 [00:00<00:01, 60398.91it/s] 16%|        | 12356/75824 [00:00<00:01, 60065.24it/s] 26%|       | 19689/75824 [00:00<00:00, 62864.16it/s] 34%|      | 25914/75824 [00:00<00:00, 62677.08it/s] 41%|     | 31344/75824 [00:00<00:00, 58974.43it/s] 48%|     | 36289/75824 [00:00<00:00, 52044.12it/s] 60%|    | 45409/75824 [00:00<00:00, 59737.89it/s] 73%|  | 55021/75824 [00:00<00:00, 66822.49it/s] 87%| | 65775/75824 [00:00<00:00, 75384.21it/s]100%|| 75824/75824 [00:01<00:00, 73837.54it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8185/75824 [00:00<00:00, 81849.30it/s] 24%|       | 18469/75824 [00:00<00:00, 87055.61it/s] 39%|      | 29242/75824 [00:00<00:00, 92371.98it/s] 49%|     | 37034/75824 [00:00<00:00, 87502.35it/s] 58%|    | 44190/75824 [00:00<00:00, 82019.27it/s] 71%|   | 53753/75824 [00:00<00:00, 85676.51it/s] 86%| | 65190/75824 [00:00<00:00, 92648.52it/s]100%|| 75627/75824 [00:00<00:00, 95877.77it/s]100%|| 75824/75824 [00:00<00:00, 94487.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12407/75824 [00:00<00:00, 124068.34it/s] 32%|      | 24428/75824 [00:00<00:00, 122883.77it/s] 48%|     | 36467/75824 [00:00<00:00, 122124.36it/s] 63%|   | 47997/75824 [00:00<00:00, 119993.12it/s] 79%|  | 59823/75824 [00:00<00:00, 119466.70it/s] 95%|| 72021/75824 [00:00<00:00, 120209.44it/s]100%|| 75824/75824 [00:00<00:00, 119925.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7652/75824 [00:00<00:00, 76515.15it/s] 20%|        | 14837/75824 [00:00<00:00, 72424.13it/s] 34%|      | 25801/75824 [00:00<00:00, 80635.24it/s] 49%|     | 37418/75824 [00:00<00:00, 88781.24it/s] 64%|   | 48373/75824 [00:00<00:00, 93347.11it/s] 75%|  | 56821/75824 [00:00<00:00, 78114.37it/s] 85%| | 64432/75824 [00:00<00:00, 75871.25it/s] 95%|| 71893/75824 [00:00<00:00, 72541.29it/s]100%|| 75824/75824 [00:00<00:00, 80434.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8231/75824 [00:00<00:00, 82302.03it/s] 25%|       | 18934/75824 [00:00<00:00, 88430.82it/s] 36%|      | 27043/75824 [00:00<00:00, 86091.10it/s] 50%|     | 38148/75824 [00:00<00:00, 92314.67it/s] 65%|   | 49617/75824 [00:00<00:00, 98052.76it/s] 81%| | 61784/75824 [00:00<00:00, 104115.40it/s] 97%|| 73262/75824 [00:00<00:00, 107098.68it/s]100%|| 75824/75824 [00:00<00:00, 104949.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10419/75824 [00:00<00:00, 102494.44it/s] 25%|       | 18727/75824 [00:00<00:00, 95777.22it/s]  40%|      | 30523/75824 [00:00<00:00, 101503.61it/s] 54%|    | 40999/75824 [00:00<00:00, 102458.24it/s] 67%|   | 51067/75824 [00:00<00:00, 99607.90it/s]  78%|  | 59401/75824 [00:00<00:00, 83841.23it/s] 88%| | 67071/75824 [00:00<00:00, 78211.15it/s]100%|| 75824/75824 [00:00<00:00, 90962.11it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6163/75824 [00:00<00:01, 58123.24it/s] 16%|        | 12164/75824 [00:00<00:01, 58676.17it/s] 26%|       | 19374/75824 [00:00<00:00, 62146.09it/s] 39%|      | 29414/75824 [00:00<00:00, 70166.13it/s] 55%|    | 41536/75824 [00:00<00:00, 80313.08it/s] 69%|   | 52213/75824 [00:00<00:00, 86761.42it/s] 85%| | 64436/75824 [00:00<00:00, 95034.28it/s]100%|| 75824/75824 [00:00<00:00, 94683.53it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9747/75824 [00:00<00:00, 97462.42it/s] 28%|       | 21439/75824 [00:00<00:00, 102582.25it/s] 39%|      | 29824/75824 [00:00<00:00, 94424.33it/s]  48%|     | 36102/75824 [00:00<00:00, 78840.99it/s] 59%|    | 44739/75824 [00:00<00:00, 80956.61it/s] 68%|   | 51602/75824 [00:00<00:00, 60992.44it/s] 77%|  | 58033/75824 [00:00<00:00, 61949.73it/s] 85%| | 64138/75824 [00:00<00:00, 61406.60it/s]100%|| 75824/75824 [00:00<00:00, 76300.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11981/75824 [00:00<00:00, 119800.40it/s] 31%|      | 23805/75824 [00:00<00:00, 119325.68it/s] 47%|     | 35747/75824 [00:00<00:00, 119351.01it/s] 57%|    | 43574/75824 [00:00<00:00, 96413.80it/s]  67%|   | 51050/75824 [00:00<00:00, 85540.04it/s] 77%|  | 58315/75824 [00:00<00:00, 68652.88it/s] 92%|| 69907/75824 [00:00<00:00, 78221.45it/s]100%|| 75824/75824 [00:00<00:00, 91151.83it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11301/75824 [00:00<00:00, 113004.72it/s] 25%|       | 19267/75824 [00:00<00:00, 100393.62it/s] 32%|      | 24625/75824 [00:00<00:00, 78637.95it/s]  40%|      | 30256/75824 [00:00<00:00, 69229.46it/s] 53%|    | 40489/75824 [00:00<00:00, 76669.04it/s] 69%|   | 52254/75824 [00:00<00:00, 85614.83it/s] 84%| | 64069/75824 [00:00<00:00, 93323.79it/s]100%|| 75822/75824 [00:00<00:00, 99469.66it/s]100%|| 75824/75824 [00:00<00:00, 93924.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6330/75824 [00:00<00:01, 62783.04it/s] 17%|        | 12614/75824 [00:00<00:01, 62800.09it/s] 24%|       | 18509/75824 [00:00<00:00, 61593.15it/s] 32%|      | 24029/75824 [00:00<00:00, 59523.30it/s] 38%|      | 28493/75824 [00:00<00:00, 48726.41it/s] 44%|     | 33129/75824 [00:00<00:00, 46613.92it/s] 57%|    | 43052/75824 [00:00<00:00, 55431.11it/s] 72%|  | 54971/75824 [00:00<00:00, 66026.88it/s] 84%| | 63494/75824 [00:00<00:00, 70813.04it/s] 98%|| 74099/75824 [00:01<00:00, 78652.56it/s]100%|| 75824/75824 [00:01<00:00, 71812.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9969/75824 [00:00<00:00, 99687.48it/s] 29%|       | 21678/75824 [00:00<00:00, 104339.56it/s] 44%|     | 33039/75824 [00:00<00:00, 103334.08it/s] 53%|    | 39996/75824 [00:00<00:00, 88568.94it/s]  62%|   | 46858/75824 [00:00<00:00, 76115.45it/s] 76%|  | 58000/75824 [00:00<00:00, 84110.29it/s] 92%|| 69540/75824 [00:00<00:00, 91556.75it/s]100%|| 75824/75824 [00:00<00:00, 95820.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11693/75824 [00:00<00:00, 116923.42it/s] 26%|       | 20081/75824 [00:00<00:00, 101403.91it/s] 36%|      | 27299/75824 [00:00<00:00, 86524.34it/s]  43%|     | 32864/75824 [00:00<00:00, 73021.75it/s] 51%|     | 38461/75824 [00:00<00:00, 66905.58it/s] 63%|   | 47586/75824 [00:00<00:00, 72725.11it/s] 74%|  | 55835/75824 [00:00<00:00, 72225.21it/s] 87%| | 66311/75824 [00:00<00:00, 79645.22it/s] 98%|| 74137/75824 [00:00<00:00, 73290.00it/s]100%|| 75824/75824 [00:00<00:00, 77254.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10757/75824 [00:00<00:00, 103753.23it/s] 22%|       | 16928/75824 [00:00<00:00, 83363.80it/s]  30%|       | 22947/75824 [00:00<00:00, 72564.10it/s] 39%|      | 29618/75824 [00:00<00:00, 68956.27it/s] 47%|     | 35746/75824 [00:00<00:00, 66457.55it/s] 60%|    | 45292/75824 [00:00<00:00, 72449.16it/s] 72%|  | 54217/75824 [00:00<00:00, 76784.86it/s] 82%| | 61903/75824 [00:00<00:00, 76806.03it/s] 96%|| 72428/75824 [00:00<00:00, 83581.78it/s]100%|| 75824/75824 [00:00<00:00, 78931.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6569/75824 [00:00<00:01, 65684.27it/s] 22%|       | 16760/75824 [00:00<00:00, 73524.18it/s] 34%|      | 25601/75824 [00:00<00:00, 77435.03it/s] 42%|     | 31472/75824 [00:00<00:00, 70671.02it/s] 49%|     | 37264/75824 [00:00<00:00, 65140.83it/s] 61%|   | 46443/75824 [00:00<00:00, 71354.70it/s] 70%|   | 53192/75824 [00:00<00:00, 58875.73it/s] 81%|  | 61227/75824 [00:00<00:00, 64006.76it/s] 93%|| 70252/75824 [00:00<00:00, 68748.00it/s]100%|| 75824/75824 [00:01<00:00, 73157.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7602/75824 [00:00<00:00, 76017.54it/s] 25%|       | 19116/75824 [00:00<00:00, 84645.09it/s] 41%|      | 31043/75824 [00:00<00:00, 92718.87it/s] 57%|    | 43461/75824 [00:00<00:00, 100343.96it/s] 69%|   | 52166/75824 [00:00<00:00, 88507.64it/s]  81%|  | 61430/75824 [00:00<00:00, 89706.59it/s] 97%|| 73810/75824 [00:00<00:00, 97783.77it/s]100%|| 75824/75824 [00:00<00:00, 102200.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10857/75824 [00:00<00:00, 108564.41it/s] 25%|       | 18620/75824 [00:00<00:00, 96970.16it/s]  40%|      | 30260/75824 [00:00<00:00, 102080.41it/s] 53%|    | 40561/75824 [00:00<00:00, 102355.08it/s] 67%|   | 50989/75824 [00:00<00:00, 102922.75it/s] 80%|  | 60906/75824 [00:00<00:00, 101765.53it/s] 96%|| 72976/75824 [00:00<00:00, 106790.18it/s]100%|| 75824/75824 [00:00<00:00, 102765.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10793/75824 [00:00<00:00, 107918.78it/s] 28%|       | 21458/75824 [00:00<00:00, 107534.40it/s] 43%|     | 32505/75824 [00:00<00:00, 108397.61it/s] 59%|    | 44438/75824 [00:00<00:00, 111458.77it/s] 74%|  | 55997/75824 [00:00<00:00, 112665.89it/s] 90%| | 68150/75824 [00:00<00:00, 115185.33it/s]100%|| 75824/75824 [00:00<00:00, 114095.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11110/75824 [00:00<00:00, 111093.75it/s] 27%|       | 20316/75824 [00:00<00:00, 103799.53it/s] 42%|     | 32029/75824 [00:00<00:00, 107468.20it/s] 53%|    | 39918/75824 [00:00<00:00, 96282.04it/s]  63%|   | 47532/75824 [00:00<00:00, 89201.95it/s] 75%|  | 56946/75824 [00:00<00:00, 90626.13it/s] 86%| | 64922/75824 [00:00<00:00, 66337.84it/s] 97%|| 73639/75824 [00:00<00:00, 71461.02it/s]100%|| 75824/75824 [00:00<00:00, 81366.72it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10748/75824 [00:00<00:00, 107479.33it/s] 29%|       | 21784/75824 [00:00<00:00, 108325.90it/s] 44%|     | 33016/75824 [00:00<00:00, 109491.57it/s] 58%|    | 43802/75824 [00:00<00:00, 108995.71it/s] 69%|   | 52125/75824 [00:00<00:00, 85146.34it/s]  84%| | 63718/75824 [00:00<00:00, 92201.37it/s] 99%|| 75315/75824 [00:00<00:00, 95748.89it/s]100%|| 75824/75824 [00:00<00:00, 98701.60it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8497/75824 [00:00<00:00, 84964.41it/s] 26%|       | 19887/75824 [00:00<00:00, 91972.63it/s] 41%|     | 31361/75824 [00:00<00:00, 97792.92it/s] 57%|    | 43200/75824 [00:00<00:00, 103176.57it/s] 73%|  | 55035/75824 [00:00<00:00, 107301.46it/s] 88%| | 67076/75824 [00:00<00:00, 110923.23it/s]100%|| 75824/75824 [00:00<00:00, 112614.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6534/75824 [00:00<00:01, 65323.71it/s] 22%|       | 16617/75824 [00:00<00:00, 73038.74it/s] 33%|      | 25338/75824 [00:00<00:00, 76781.63it/s] 43%|     | 32735/75824 [00:00<00:00, 75914.52it/s] 55%|    | 41635/75824 [00:00<00:00, 77143.86it/s] 64%|   | 48384/75824 [00:00<00:00, 70078.47it/s] 73%|  | 55506/75824 [00:00<00:00, 68174.39it/s] 82%| | 61949/75824 [00:00<00:00, 66416.15it/s] 97%|| 73361/75824 [00:00<00:00, 75938.31it/s]100%|| 75824/75824 [00:00<00:00, 78408.78it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11498/75824 [00:00<00:00, 114977.37it/s] 30%|       | 22981/75824 [00:00<00:00, 114932.41it/s] 46%|     | 34549/75824 [00:00<00:00, 115153.49it/s] 61%|    | 46089/75824 [00:00<00:00, 115227.20it/s] 76%|  | 57682/75824 [00:00<00:00, 115435.45it/s] 91%|| 69282/75824 [00:00<00:00, 115601.80it/s]100%|| 75824/75824 [00:00<00:00, 115612.70it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6075/75824 [00:00<00:01, 59388.91it/s] 21%|       | 16203/75824 [00:00<00:00, 67801.92it/s] 30%|       | 22429/75824 [00:00<00:00, 65926.63it/s] 38%|      | 28580/75824 [00:00<00:00, 63731.58it/s] 50%|     | 37546/75824 [00:00<00:00, 69784.77it/s] 63%|   | 47883/75824 [00:00<00:00, 76778.65it/s] 76%|  | 57339/75824 [00:00<00:00, 81368.42it/s] 91%|| 69307/75824 [00:00<00:00, 90012.78it/s]100%|| 75824/75824 [00:00<00:00, 87612.89it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6277/75824 [00:00<00:01, 62764.82it/s] 20%|        | 15308/75824 [00:00<00:00, 68512.93it/s] 30%|       | 22835/75824 [00:00<00:00, 70408.97it/s] 41%|     | 31322/75824 [00:00<00:00, 74198.13it/s] 51%|     | 38537/75824 [00:00<00:00, 73570.43it/s] 62%|   | 46700/75824 [00:00<00:00, 75814.55it/s] 72%|  | 54259/75824 [00:00<00:00, 75746.47it/s] 82%| | 62344/75824 [00:00<00:00, 75485.62it/s] 94%|| 71138/75824 [00:00<00:00, 78834.66it/s]100%|| 75824/75824 [00:00<00:00, 78115.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11889/75824 [00:00<00:00, 118888.70it/s] 29%|       | 21972/75824 [00:00<00:00, 112825.56it/s] 36%|      | 27494/75824 [00:00<00:00, 79481.08it/s]  52%|    | 39587/75824 [00:00<00:00, 88589.61it/s] 68%|   | 51554/75824 [00:00<00:00, 96074.31it/s] 84%| | 63603/75824 [00:00<00:00, 102291.70it/s] 99%|| 74871/75824 [00:00<00:00, 105198.78it/s]100%|| 75824/75824 [00:00<00:00, 104485.75it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11672/75824 [00:00<00:00, 116716.22it/s] 37%|      | 28068/75824 [00:00<00:00, 127759.31it/s] 58%|    | 43853/75824 [00:00<00:00, 129569.83it/s] 70%|   | 53032/75824 [00:00<00:00, 109564.32it/s] 95%|| 72245/75824 [00:00<00:00, 125779.23it/s]100%|| 75824/75824 [00:00<00:00, 136941.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12890/75824 [00:00<00:00, 128895.21it/s] 35%|      | 26561/75824 [00:00<00:00, 131142.79it/s] 48%|     | 36290/75824 [00:00<00:00, 118743.31it/s] 58%|    | 43975/75824 [00:00<00:00, 101899.89it/s] 83%| | 62717/75824 [00:00<00:00, 117353.99it/s]100%|| 75824/75824 [00:00<00:00, 130290.70it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18708/75824 [00:00<00:00, 187077.95it/s] 45%|     | 33971/75824 [00:00<00:00, 175210.00it/s] 62%|   | 46830/75824 [00:00<00:00, 158020.60it/s] 88%| | 66820/75824 [00:00<00:00, 168617.07it/s]100%|| 75824/75824 [00:00<00:00, 170387.11it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|       | 17438/75824 [00:00<00:00, 174372.27it/s] 48%|     | 36254/75824 [00:00<00:00, 178290.01it/s] 73%|  | 55141/75824 [00:00<00:00, 181336.35it/s] 98%|| 74049/75824 [00:00<00:00, 183587.61it/s]100%|| 75824/75824 [00:00<00:00, 183366.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14695/75824 [00:00<00:00, 146945.94it/s] 39%|      | 29306/75824 [00:00<00:00, 146692.93it/s] 58%|    | 44213/75824 [00:00<00:00, 147396.53it/s] 80%|  | 60411/75824 [00:00<00:00, 151486.81it/s]100%|| 75824/75824 [00:00<00:00, 157482.78it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14310/75824 [00:00<00:00, 143097.41it/s] 38%|      | 28813/75824 [00:00<00:00, 143671.39it/s] 58%|    | 43928/75824 [00:00<00:00, 145834.73it/s] 78%|  | 59113/75824 [00:00<00:00, 147585.84it/s] 98%|| 74385/75824 [00:00<00:00, 149087.43it/s]100%|| 75824/75824 [00:00<00:00, 148822.49it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12812/75824 [00:00<00:00, 128113.40it/s] 32%|      | 24478/75824 [00:00<00:00, 124445.95it/s] 48%|     | 36181/75824 [00:00<00:00, 122120.71it/s] 67%|   | 51012/75824 [00:00<00:00, 128950.43it/s] 87%| | 65927/75824 [00:00<00:00, 134409.78it/s]100%|| 75824/75824 [00:00<00:00, 137504.37it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6133/75824 [00:00<00:01, 61326.11it/s] 24%|       | 17984/75824 [00:00<00:00, 71520.16it/s] 31%|       | 23207/75824 [00:00<00:00, 64384.64it/s] 45%|     | 34162/75824 [00:00<00:00, 72552.37it/s] 54%|    | 40700/75824 [00:00<00:00, 69318.61it/s] 77%|  | 58251/75824 [00:00<00:00, 84690.66it/s]100%|| 75824/75824 [00:00<00:00, 106534.21it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10155/75824 [00:00<00:00, 101545.50it/s] 26%|       | 19477/75824 [00:00<00:00, 98895.36it/s]  32%|      | 24407/75824 [00:00<00:00, 74514.05it/s] 46%|     | 35224/75824 [00:00<00:00, 82183.97it/s] 60%|    | 45573/75824 [00:00<00:00, 86272.07it/s] 70%|   | 53159/75824 [00:00<00:00, 80179.52it/s] 82%| | 62402/75824 [00:00<00:00, 83499.22it/s]100%|| 75824/75824 [00:00<00:00, 96334.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18483/75824 [00:00<00:00, 184824.01it/s] 49%|     | 37312/75824 [00:00<00:00, 185850.25it/s] 76%|  | 57261/75824 [00:00<00:00, 189740.35it/s]100%|| 75824/75824 [00:00<00:00, 196209.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 20025/75824 [00:00<00:00, 200248.28it/s] 53%|    | 39815/75824 [00:00<00:00, 199536.58it/s] 78%|  | 59412/75824 [00:00<00:00, 198450.38it/s]100%|| 75824/75824 [00:00<00:00, 196198.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 14863/75824 [00:00<00:00, 148624.12it/s] 44%|     | 33247/75824 [00:00<00:00, 157685.34it/s] 66%|   | 50081/75824 [00:00<00:00, 160735.78it/s] 91%| | 68849/75824 [00:00<00:00, 167969.77it/s]100%|| 75824/75824 [00:00<00:00, 174115.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18126/75824 [00:00<00:00, 181252.83it/s] 51%|     | 38467/75824 [00:00<00:00, 187374.95it/s] 77%|  | 58736/75824 [00:00<00:00, 191718.28it/s]100%|| 75824/75824 [00:00<00:00, 196399.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12354/75824 [00:00<00:00, 123532.46it/s] 33%|      | 25138/75824 [00:00<00:00, 124792.83it/s] 50%|     | 38208/75824 [00:00<00:00, 126505.64it/s] 68%|   | 51270/75824 [00:00<00:00, 127711.71it/s] 85%| | 64461/75824 [00:00<00:00, 128941.46it/s]100%|| 75824/75824 [00:00<00:00, 129336.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 14854/75824 [00:00<00:00, 148534.48it/s] 43%|     | 32231/75824 [00:00<00:00, 155299.02it/s] 70%|   | 52989/75824 [00:00<00:00, 167990.43it/s] 87%| | 65866/75824 [00:00<00:00, 153920.13it/s]100%|| 75824/75824 [00:00<00:00, 142350.54it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19617/75824 [00:00<00:00, 196168.78it/s] 53%|    | 40339/75824 [00:00<00:00, 199348.96it/s] 81%|  | 61507/75824 [00:00<00:00, 202893.68it/s]100%|| 75824/75824 [00:00<00:00, 204757.08it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19590/75824 [00:00<00:00, 195895.98it/s] 50%|     | 37618/75824 [00:00<00:00, 190933.37it/s] 66%|   | 50349/75824 [00:00<00:00, 166038.14it/s] 89%| | 67631/75824 [00:00<00:00, 168015.02it/s]100%|| 75824/75824 [00:00<00:00, 171070.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|       | 17501/75824 [00:00<00:00, 175002.66it/s] 46%|     | 34874/75824 [00:00<00:00, 174615.44it/s] 69%|   | 52387/75824 [00:00<00:00, 174768.17it/s] 96%|| 72439/75824 [00:00<00:00, 181769.19it/s]100%|| 75824/75824 [00:00<00:00, 182260.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19001/75824 [00:00<00:00, 190001.57it/s] 52%|    | 39294/75824 [00:00<00:00, 193701.04it/s] 79%|  | 59876/75824 [00:00<00:00, 197182.34it/s]100%|| 75824/75824 [00:00<00:00, 199941.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14751/75824 [00:00<00:00, 147501.00it/s] 40%|      | 30043/75824 [00:00<00:00, 149083.90it/s] 60%|    | 45455/75824 [00:00<00:00, 150557.14it/s] 80%|  | 60861/75824 [00:00<00:00, 151587.89it/s] 96%|| 72485/75824 [00:00<00:00, 131556.25it/s]100%|| 75824/75824 [00:00<00:00, 136901.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14150/75824 [00:00<00:00, 139171.49it/s] 26%|       | 19957/75824 [00:00<00:00, 98075.77it/s]  37%|      | 28102/75824 [00:00<00:00, 90258.43it/s] 45%|     | 34248/75824 [00:00<00:00, 79133.90it/s] 71%|   | 53617/75824 [00:00<00:00, 96202.92it/s] 90%| | 68472/75824 [00:00<00:00, 107573.16it/s]100%|| 75824/75824 [00:00<00:00, 104702.74it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14070/75824 [00:00<00:00, 140689.40it/s] 28%|       | 21249/75824 [00:00<00:00, 109236.49it/s] 41%|      | 30747/75824 [00:00<00:00, 104526.68it/s] 53%|    | 40329/75824 [00:00<00:00, 99903.68it/s]  68%|   | 51511/75824 [00:00<00:00, 103200.60it/s] 87%| | 66242/75824 [00:00<00:00, 113385.94it/s]100%|| 75824/75824 [00:00<00:00, 116065.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19201/75824 [00:00<00:00, 192002.40it/s] 51%|    | 38987/75824 [00:00<00:00, 193720.55it/s] 78%|  | 59252/75824 [00:00<00:00, 196314.89it/s]100%|| 75824/75824 [00:00<00:00, 198305.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19147/75824 [00:00<00:00, 191469.73it/s] 51%|     | 38567/75824 [00:00<00:00, 192280.63it/s] 77%|  | 58590/75824 [00:00<00:00, 194596.12it/s]100%|| 75824/75824 [00:00<00:00, 194860.15it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18852/75824 [00:00<00:00, 188514.79it/s] 49%|     | 36797/75824 [00:00<00:00, 185698.35it/s] 74%|  | 56270/75824 [00:00<00:00, 188317.25it/s]100%|| 75824/75824 [00:00<00:00, 189920.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16590/75824 [00:00<00:00, 165898.18it/s] 46%|     | 35097/75824 [00:00<00:00, 171219.10it/s] 73%|  | 55609/75824 [00:00<00:00, 180150.96it/s]100%|| 75824/75824 [00:00<00:00, 189880.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14328/75824 [00:00<00:00, 143278.43it/s] 39%|      | 29585/75824 [00:00<00:00, 145944.70it/s] 59%|    | 44935/75824 [00:00<00:00, 148131.66it/s] 79%|  | 60000/75824 [00:00<00:00, 148875.69it/s]100%|| 75548/75824 [00:00<00:00, 150795.47it/s]100%|| 75824/75824 [00:00<00:00, 151012.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14728/75824 [00:00<00:00, 147278.74it/s] 40%|      | 30128/75824 [00:00<00:00, 149231.18it/s] 60%|    | 45638/75824 [00:00<00:00, 150942.18it/s] 84%| | 63663/75824 [00:00<00:00, 158681.73it/s]100%|| 75824/75824 [00:00<00:00, 162463.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|        | 16016/75824 [00:00<00:00, 160159.39it/s] 47%|     | 35818/75824 [00:00<00:00, 169904.76it/s] 74%|  | 56371/75824 [00:00<00:00, 179224.37it/s]100%|| 75824/75824 [00:00<00:00, 192488.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14625/75824 [00:00<00:00, 146242.12it/s] 36%|      | 27094/75824 [00:00<00:00, 138370.78it/s] 56%|    | 42264/75824 [00:00<00:00, 142116.31it/s] 75%|  | 56852/75824 [00:00<00:00, 143223.50it/s] 94%|| 71529/75824 [00:00<00:00, 144269.06it/s]100%|| 75824/75824 [00:00<00:00, 143139.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11739/75824 [00:00<00:00, 117381.16it/s] 23%|       | 17079/75824 [00:00<00:00, 86339.98it/s]  33%|      | 24672/75824 [00:00<00:00, 82925.70it/s] 42%|     | 31872/75824 [00:00<00:00, 79312.89it/s] 60%|    | 45772/75824 [00:00<00:00, 91040.55it/s] 79%|  | 59751/75824 [00:00<00:00, 101677.72it/s] 99%|| 74739/75824 [00:00<00:00, 112534.38it/s]100%|| 75824/75824 [00:00<00:00, 107159.75it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11301/75824 [00:00<00:00, 113008.22it/s] 38%|      | 28876/75824 [00:00<00:00, 126562.73it/s] 69%|   | 52156/75824 [00:00<00:00, 146636.85it/s] 97%|| 73342/75824 [00:00<00:00, 161556.28it/s]100%|| 75824/75824 [00:00<00:00, 183830.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 17967/75824 [00:00<00:00, 179666.32it/s] 45%|     | 34110/75824 [00:00<00:00, 173774.76it/s] 70%|   | 53199/75824 [00:00<00:00, 178576.90it/s] 92%|| 69394/75824 [00:00<00:00, 173240.45it/s]100%|| 75824/75824 [00:00<00:00, 168207.14it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12025/75824 [00:00<00:00, 118901.02it/s] 23%|       | 17234/75824 [00:00<00:00, 85861.64it/s]  28%|       | 21294/75824 [00:00<00:00, 58805.14it/s] 39%|      | 29535/75824 [00:00<00:00, 64332.61it/s] 52%|    | 39219/75824 [00:00<00:00, 71535.93it/s] 69%|   | 51941/75824 [00:00<00:00, 82348.81it/s] 96%|| 72589/75824 [00:00<00:00, 100468.47it/s]100%|| 75824/75824 [00:00<00:00, 102051.86it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14090/75824 [00:00<00:00, 140896.10it/s] 31%|      | 23696/75824 [00:00<00:00, 123586.96it/s] 49%|     | 36788/75824 [00:00<00:00, 125698.83it/s] 66%|   | 49860/75824 [00:00<00:00, 127163.98it/s] 92%|| 69558/75824 [00:00<00:00, 142293.49it/s]100%|| 75824/75824 [00:00<00:00, 142163.08it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|       | 17319/75824 [00:00<00:00, 173186.04it/s] 51%|     | 38442/75824 [00:00<00:00, 183076.58it/s] 67%|   | 50486/75824 [00:00<00:00, 158361.45it/s] 81%|  | 61081/75824 [00:00<00:00, 135302.54it/s]100%|| 75824/75824 [00:00<00:00, 157784.60it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20651/75824 [00:00<00:00, 206504.29it/s] 56%|    | 42083/75824 [00:00<00:00, 208785.93it/s] 72%|  | 54959/75824 [00:00<00:00, 175970.37it/s] 88%| | 66569/75824 [00:00<00:00, 152390.58it/s]100%|| 75824/75824 [00:00<00:00, 157787.34it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20721/75824 [00:00<00:00, 207206.74it/s] 55%|    | 42080/75824 [00:00<00:00, 209079.30it/s] 84%| | 63317/75824 [00:00<00:00, 210054.48it/s]100%|| 75824/75824 [00:00<00:00, 209129.11it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18432/75824 [00:00<00:00, 184316.66it/s] 52%|    | 39302/75824 [00:00<00:00, 191009.73it/s] 82%| | 62505/75824 [00:00<00:00, 201707.54it/s]100%|| 75824/75824 [00:00<00:00, 212301.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21524/75824 [00:00<00:00, 215238.67it/s] 58%|    | 43641/75824 [00:00<00:00, 216982.02it/s] 86%| | 65156/75824 [00:00<00:00, 216427.80it/s]100%|| 75824/75824 [00:00<00:00, 219062.27it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21069/75824 [00:00<00:00, 210685.68it/s] 57%|    | 42907/75824 [00:00<00:00, 212935.16it/s] 85%| | 64253/75824 [00:00<00:00, 213090.58it/s]100%|| 75824/75824 [00:00<00:00, 213983.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21344/75824 [00:00<00:00, 213434.10it/s] 54%|    | 41031/75824 [00:00<00:00, 208177.42it/s] 83%| | 62810/75824 [00:00<00:00, 210970.67it/s]100%|| 75824/75824 [00:00<00:00, 211836.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21255/75824 [00:00<00:00, 212545.14it/s] 57%|    | 43444/75824 [00:00<00:00, 215264.80it/s] 86%| | 65347/75824 [00:00<00:00, 216380.45it/s]100%|| 75824/75824 [00:00<00:00, 217853.68it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18925/75824 [00:00<00:00, 189249.28it/s] 53%|    | 40038/75824 [00:00<00:00, 195320.51it/s] 80%|  | 60844/75824 [00:00<00:00, 198974.99it/s]100%|| 75824/75824 [00:00<00:00, 202300.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18308/75824 [00:00<00:00, 183075.37it/s] 51%|     | 38344/75824 [00:00<00:00, 187937.85it/s] 76%|  | 57777/75824 [00:00<00:00, 189809.09it/s]100%|| 75824/75824 [00:00<00:00, 194751.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20267/75824 [00:00<00:00, 202660.53it/s] 52%|    | 39780/75824 [00:00<00:00, 200340.21it/s] 79%|  | 60114/75824 [00:00<00:00, 201229.16it/s]100%|| 75824/75824 [00:00<00:00, 199750.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18505/75824 [00:00<00:00, 185047.97it/s] 49%|     | 37055/75824 [00:00<00:00, 185181.95it/s] 76%|  | 57302/75824 [00:00<00:00, 190047.85it/s] 98%|| 74410/75824 [00:00<00:00, 183927.45it/s]100%|| 75824/75824 [00:00<00:00, 185559.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12675/75824 [00:00<00:00, 126747.70it/s] 23%|       | 17247/75824 [00:00<00:00, 80779.89it/s]  30%|       | 22573/75824 [00:00<00:00, 69938.04it/s] 44%|     | 33692/75824 [00:00<00:00, 77865.61it/s] 59%|    | 44889/75824 [00:00<00:00, 85695.97it/s] 86%| | 64920/75824 [00:00<00:00, 103453.85it/s]100%|| 75824/75824 [00:00<00:00, 114452.78it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10857/75824 [00:00<00:00, 108569.84it/s] 20%|        | 15403/75824 [00:00<00:00, 74500.83it/s]  31%|       | 23378/75824 [00:00<00:00, 76000.08it/s] 45%|     | 34472/75824 [00:00<00:00, 83928.55it/s] 58%|    | 44095/75824 [00:00<00:00, 87274.92it/s] 83%| | 62675/75824 [00:00<00:00, 103784.95it/s]100%|| 75824/75824 [00:00<00:00, 112971.91it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18362/75824 [00:00<00:00, 183610.54it/s] 50%|     | 37709/75824 [00:00<00:00, 186460.64it/s] 76%|  | 57884/75824 [00:00<00:00, 190798.00it/s]100%|| 75824/75824 [00:00<00:00, 195712.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18752/75824 [00:00<00:00, 187519.28it/s] 51%|     | 38543/75824 [00:00<00:00, 190517.27it/s] 78%|  | 59083/75824 [00:00<00:00, 194749.60it/s]100%|| 75824/75824 [00:00<00:00, 197246.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18951/75824 [00:00<00:00, 189502.05it/s] 52%|    | 39109/75824 [00:00<00:00, 192970.34it/s] 75%|  | 57225/75824 [00:00<00:00, 189267.29it/s]100%|| 75824/75824 [00:00<00:00, 194346.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14579/75824 [00:00<00:00, 145780.41it/s] 39%|      | 29947/75824 [00:00<00:00, 148063.41it/s] 60%|    | 45416/75824 [00:00<00:00, 149990.31it/s] 84%| | 63705/75824 [00:00<00:00, 158545.54it/s]100%|| 75824/75824 [00:00<00:00, 165660.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18516/75824 [00:00<00:00, 185154.00it/s] 51%|     | 38406/75824 [00:00<00:00, 189073.74it/s] 77%|  | 58688/75824 [00:00<00:00, 192996.78it/s]100%|| 75824/75824 [00:00<00:00, 197819.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18896/75824 [00:00<00:00, 188956.13it/s] 51%|    | 38907/75824 [00:00<00:00, 192167.32it/s] 78%|  | 58835/75824 [00:00<00:00, 194245.53it/s]100%|| 75824/75824 [00:00<00:00, 198327.53it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 17825/75824 [00:00<00:00, 178242.95it/s] 49%|     | 37246/75824 [00:00<00:00, 182748.13it/s] 75%|  | 56869/75824 [00:00<00:00, 186592.99it/s]100%|| 75824/75824 [00:00<00:00, 191116.71it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|        | 15958/75824 [00:00<00:00, 159575.21it/s] 43%|     | 32670/75824 [00:00<00:00, 161764.27it/s] 66%|   | 49761/75824 [00:00<00:00, 164399.97it/s] 82%| | 61817/75824 [00:00<00:00, 148226.67it/s] 96%|| 73122/75824 [00:00<00:00, 111118.87it/s]100%|| 75824/75824 [00:00<00:00, 130959.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|       | 17322/75824 [00:00<00:00, 173212.73it/s] 48%|     | 36641/75824 [00:00<00:00, 178758.02it/s] 75%|  | 57030/75824 [00:00<00:00, 185621.41it/s]100%|| 75824/75824 [00:00<00:00, 192312.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8991/75824 [00:00<00:00, 87033.86it/s] 25%|       | 18612/75824 [00:00<00:00, 89596.15it/s] 43%|     | 32476/75824 [00:00<00:00, 100232.91it/s] 70%|   | 52978/75824 [00:00<00:00, 118385.11it/s] 97%|| 73475/75824 [00:00<00:00, 135564.27it/s]100%|| 75824/75824 [00:00<00:00, 147303.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11965/75824 [00:00<00:00, 119642.41it/s] 38%|      | 28856/75824 [00:00<00:00, 131114.75it/s] 58%|    | 43939/75824 [00:00<00:00, 136465.93it/s] 76%|  | 57324/75824 [00:00<00:00, 135670.42it/s] 90%| | 68221/75824 [00:00<00:00, 105660.47it/s]100%|| 75824/75824 [00:00<00:00, 128336.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14665/75824 [00:00<00:00, 146648.04it/s] 36%|      | 27187/75824 [00:00<00:00, 139485.57it/s] 58%|    | 43753/75824 [00:00<00:00, 146423.66it/s] 75%|  | 56676/75824 [00:00<00:00, 140661.70it/s] 91%|| 69283/75824 [00:00<00:00, 135941.36it/s]100%|| 75824/75824 [00:00<00:00, 141829.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11946/75824 [00:00<00:00, 119454.70it/s] 35%|      | 26259/75824 [00:00<00:00, 125691.04it/s] 59%|    | 44828/75824 [00:00<00:00, 139181.04it/s] 88%| | 66570/75824 [00:00<00:00, 156024.41it/s]100%|| 75824/75824 [00:00<00:00, 170534.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18558/75824 [00:00<00:00, 185570.89it/s] 51%|    | 39034/75824 [00:00<00:00, 190937.57it/s] 78%|  | 59262/75824 [00:00<00:00, 194202.78it/s]100%|| 75824/75824 [00:00<00:00, 199657.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18838/75824 [00:00<00:00, 188377.04it/s] 52%|    | 39272/75824 [00:00<00:00, 192897.30it/s] 79%|  | 59762/75824 [00:00<00:00, 196345.85it/s]100%|| 75824/75824 [00:00<00:00, 201005.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16859/75824 [00:00<00:00, 168584.53it/s] 48%|     | 36375/75824 [00:00<00:00, 175762.51it/s] 75%|  | 56672/75824 [00:00<00:00, 183125.65it/s]100%|| 75824/75824 [00:00<00:00, 193159.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|       | 16241/75824 [00:00<00:00, 162399.31it/s] 43%|     | 32640/75824 [00:00<00:00, 162871.23it/s] 69%|   | 52497/75824 [00:00<00:00, 172155.57it/s] 93%|| 70796/75824 [00:00<00:00, 175268.56it/s]100%|| 75824/75824 [00:00<00:00, 178822.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 23%|       | 17771/75824 [00:00<00:00, 177704.66it/s] 44%|     | 33503/75824 [00:00<00:00, 171054.33it/s] 70%|   | 52831/75824 [00:00<00:00, 177164.56it/s] 95%|| 72252/75824 [00:00<00:00, 181954.97it/s]100%|| 75824/75824 [00:00<00:00, 181373.14it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18672/75824 [00:00<00:00, 186716.62it/s] 51%|    | 39009/75824 [00:00<00:00, 191417.16it/s] 79%|  | 59550/75824 [00:00<00:00, 195409.25it/s]100%|| 75824/75824 [00:00<00:00, 196584.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14347/75824 [00:00<00:00, 143460.90it/s] 38%|      | 29021/75824 [00:00<00:00, 144427.96it/s] 58%|    | 43649/75824 [00:00<00:00, 144977.54it/s] 80%|  | 60356/75824 [00:00<00:00, 150965.21it/s]100%|| 75824/75824 [00:00<00:00, 159037.04it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18103/75824 [00:00<00:00, 181024.99it/s] 49%|     | 36906/75824 [00:00<00:00, 183068.96it/s] 74%|  | 56204/75824 [00:00<00:00, 185933.11it/s]100%|| 75824/75824 [00:00<00:00, 189911.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13780/75824 [00:00<00:00, 137794.87it/s] 34%|      | 26111/75824 [00:00<00:00, 133100.71it/s] 50%|     | 37771/75824 [00:00<00:00, 127676.73it/s] 66%|   | 50153/75824 [00:00<00:00, 126491.71it/s] 83%| | 63122/75824 [00:00<00:00, 127433.38it/s]100%|| 75705/75824 [00:00<00:00, 126946.75it/s]100%|| 75824/75824 [00:00<00:00, 126091.97it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9861/75824 [00:00<00:00, 98606.10it/s] 24%|       | 18565/75824 [00:00<00:00, 94823.48it/s] 41%|      | 30759/75824 [00:00<00:00, 101600.96it/s] 56%|    | 42526/75824 [00:00<00:00, 105940.24it/s] 72%|  | 54226/75824 [00:00<00:00, 109030.86it/s] 87%| | 65906/75824 [00:00<00:00, 111248.32it/s]100%|| 75824/75824 [00:00<00:00, 94208.93it/s] 
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6989/75824 [00:00<00:00, 69887.40it/s] 15%|        | 11724/75824 [00:00<00:01, 58850.05it/s] 22%|       | 17035/75824 [00:00<00:01, 57001.16it/s] 33%|      | 24811/75824 [00:00<00:00, 61963.10it/s] 48%|     | 36414/75824 [00:00<00:00, 72031.85it/s] 64%|   | 48246/75824 [00:00<00:00, 81608.63it/s] 75%|  | 56584/75824 [00:00<00:00, 81349.31it/s] 86%| | 64843/75824 [00:00<00:00, 76584.43it/s] 96%|| 72973/75824 [00:00<00:00, 76821.76it/s]100%|| 75824/75824 [00:01<00:00, 72086.73it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5143/75824 [00:00<00:01, 43395.52it/s] 22%|       | 16682/75824 [00:00<00:01, 53388.15it/s] 38%|      | 28448/75824 [00:00<00:00, 63851.85it/s] 53%|    | 40309/75824 [00:00<00:00, 74116.46it/s] 69%|   | 52220/75824 [00:00<00:00, 83588.82it/s] 82%| | 62479/75824 [00:00<00:00, 88504.42it/s] 97%|| 73773/75824 [00:00<00:00, 94647.36it/s]100%|| 75824/75824 [00:00<00:00, 101779.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10080/75824 [00:00<00:00, 100796.97it/s] 28%|       | 21262/75824 [00:00<00:00, 103866.97it/s] 48%|     | 36189/75824 [00:00<00:00, 114295.69it/s] 74%|  | 56044/75824 [00:00<00:00, 130967.42it/s] 96%|| 72867/75824 [00:00<00:00, 140286.59it/s]100%|| 75824/75824 [00:00<00:00, 145139.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19231/75824 [00:00<00:00, 192305.14it/s] 53%|    | 40536/75824 [00:00<00:00, 198089.85it/s] 76%|  | 57251/75824 [00:00<00:00, 187664.18it/s] 92%|| 69566/75824 [00:00<00:00, 136055.20it/s]100%|| 75824/75824 [00:00<00:00, 158209.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19767/75824 [00:00<00:00, 197660.29it/s] 54%|    | 41203/75824 [00:00<00:00, 202388.33it/s] 82%| | 62332/75824 [00:00<00:00, 204978.55it/s]100%|| 75824/75824 [00:00<00:00, 209347.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13572/75824 [00:00<00:00, 135718.84it/s] 40%|      | 30449/75824 [00:00<00:00, 144189.96it/s] 69%|   | 52559/75824 [00:00<00:00, 160989.20it/s] 98%|| 73957/75824 [00:00<00:00, 173909.42it/s]100%|| 75824/75824 [00:00<00:00, 185609.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|       | 21738/75824 [00:00<00:00, 217376.58it/s] 56%|    | 42761/75824 [00:00<00:00, 215180.59it/s] 79%|  | 60138/75824 [00:00<00:00, 200822.39it/s]100%|| 75824/75824 [00:00<00:00, 201234.96it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18874/75824 [00:00<00:00, 188735.68it/s] 52%|    | 39284/75824 [00:00<00:00, 193095.75it/s] 79%|  | 60036/75824 [00:00<00:00, 197205.77it/s]100%|| 75824/75824 [00:00<00:00, 198763.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19865/75824 [00:00<00:00, 198641.19it/s] 54%|    | 40763/75824 [00:00<00:00, 201633.72it/s] 82%| | 62061/75824 [00:00<00:00, 204907.25it/s]100%|| 75824/75824 [00:00<00:00, 204785.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18247/75824 [00:00<00:00, 182465.82it/s] 50%|     | 37946/75824 [00:00<00:00, 186592.15it/s] 76%|  | 57820/75824 [00:00<00:00, 190077.06it/s]100%|| 75824/75824 [00:00<00:00, 195326.78it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18806/75824 [00:00<00:00, 188055.25it/s] 53%|    | 40203/75824 [00:00<00:00, 195144.36it/s] 82%| | 62158/75824 [00:00<00:00, 201875.13it/s]100%|| 75824/75824 [00:00<00:00, 207317.72it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19427/75824 [00:00<00:00, 194267.41it/s] 53%|    | 39910/75824 [00:00<00:00, 197317.88it/s] 80%|  | 60714/75824 [00:00<00:00, 200414.77it/s]100%|| 75824/75824 [00:00<00:00, 205010.38it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 20976/75824 [00:00<00:00, 209755.70it/s] 55%|    | 41681/75824 [00:00<00:00, 208935.60it/s] 81%|  | 61548/75824 [00:00<00:00, 205744.31it/s]100%|| 75824/75824 [00:00<00:00, 207246.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 14862/75824 [00:00<00:00, 148616.60it/s] 38%|      | 29084/75824 [00:00<00:00, 146636.00it/s] 53%|    | 40200/75824 [00:00<00:00, 133820.04it/s] 67%|   | 50659/75824 [00:00<00:00, 116765.80it/s] 78%|  | 59314/75824 [00:00<00:00, 99149.41it/s]  96%|| 72694/75824 [00:00<00:00, 107501.05it/s]100%|| 75824/75824 [00:00<00:00, 114796.75it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8392/75824 [00:00<00:00, 83918.28it/s] 37%|      | 28324/75824 [00:00<00:00, 101557.93it/s] 60%|    | 45614/75824 [00:00<00:00, 115903.88it/s] 78%|  | 59118/75824 [00:00<00:00, 121049.30it/s] 93%|| 70594/75824 [00:00<00:00, 103199.79it/s]100%|| 75824/75824 [00:00<00:00, 130611.54it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11609/75824 [00:00<00:00, 116083.75it/s] 33%|      | 25158/75824 [00:00<00:00, 121295.12it/s] 61%|    | 46076/75824 [00:00<00:00, 138787.24it/s] 87%| | 65920/75824 [00:00<00:00, 152543.75it/s]100%|| 75824/75824 [00:00<00:00, 168614.34it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 20902/75824 [00:00<00:00, 209012.23it/s] 59%|    | 44690/75824 [00:00<00:00, 216906.88it/s] 90%| | 68015/75824 [00:00<00:00, 221561.53it/s]100%|| 75824/75824 [00:00<00:00, 223686.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|       | 21719/75824 [00:00<00:00, 217184.51it/s] 56%|    | 42469/75824 [00:00<00:00, 214182.29it/s] 84%| | 63702/75824 [00:00<00:00, 213620.36it/s]100%|| 75824/75824 [00:00<00:00, 212604.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18873/75824 [00:00<00:00, 188721.63it/s] 51%|     | 38843/75824 [00:00<00:00, 191885.14it/s] 77%|  | 58346/75824 [00:00<00:00, 192815.91it/s]100%|| 75824/75824 [00:00<00:00, 197402.04it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14270/75824 [00:00<00:00, 142698.09it/s] 39%|      | 29481/75824 [00:00<00:00, 144428.71it/s] 59%|    | 45070/75824 [00:00<00:00, 147684.19it/s] 84%| | 63996/75824 [00:00<00:00, 158103.21it/s]100%|| 75824/75824 [00:00<00:00, 165567.45it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20137/75824 [00:00<00:00, 201358.19it/s] 52%|    | 39526/75824 [00:00<00:00, 199056.90it/s] 81%| | 61762/75824 [00:00<00:00, 205517.98it/s]100%|| 75824/75824 [00:00<00:00, 207032.68it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 29%|       | 21669/75824 [00:00<00:00, 216683.49it/s] 58%|    | 43988/75824 [00:00<00:00, 218594.25it/s] 87%| | 65852/75824 [00:00<00:00, 218605.22it/s]100%|| 75824/75824 [00:00<00:00, 221988.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21315/75824 [00:00<00:00, 213149.19it/s] 60%|    | 45302/75824 [00:00<00:00, 220516.61it/s] 90%| | 68470/75824 [00:00<00:00, 223748.29it/s]100%|| 75824/75824 [00:00<00:00, 229052.53it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21294/75824 [00:00<00:00, 212935.63it/s] 57%|    | 43148/75824 [00:00<00:00, 214585.99it/s] 82%| | 62013/75824 [00:00<00:00, 206085.47it/s]100%|| 75824/75824 [00:00<00:00, 205228.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14679/75824 [00:00<00:00, 146789.44it/s] 40%|      | 30009/75824 [00:00<00:00, 148681.98it/s] 60%|    | 45417/75824 [00:00<00:00, 150259.72it/s] 81%|  | 61317/75824 [00:00<00:00, 152777.37it/s]100%|| 75824/75824 [00:00<00:00, 160277.60it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7721/75824 [00:00<00:00, 77204.74it/s] 19%|        | 14469/75824 [00:00<00:00, 74002.73it/s] 29%|       | 22104/75824 [00:00<00:00, 74690.12it/s] 40%|      | 30253/75824 [00:00<00:00, 76607.74it/s] 62%|   | 47319/75824 [00:00<00:00, 91782.06it/s] 87%| | 65987/75824 [00:00<00:00, 108297.32it/s]100%|| 75824/75824 [00:00<00:00, 116489.11it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18403/75824 [00:00<00:00, 184022.72it/s] 54%|    | 40578/75824 [00:00<00:00, 193919.07it/s] 82%| | 61919/75824 [00:00<00:00, 199379.91it/s]100%|| 75824/75824 [00:00<00:00, 208057.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19298/75824 [00:00<00:00, 192976.96it/s] 53%|    | 39883/75824 [00:00<00:00, 196664.09it/s] 80%|  | 60975/75824 [00:00<00:00, 200732.61it/s]100%|| 75824/75824 [00:00<00:00, 201128.18it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10976/75824 [00:00<00:00, 109755.13it/s] 28%|       | 21031/75824 [00:00<00:00, 106818.71it/s] 41%|      | 31166/75824 [00:00<00:00, 105114.96it/s] 55%|    | 41916/75824 [00:00<00:00, 105818.13it/s] 71%|   | 54009/75824 [00:00<00:00, 109937.34it/s] 87%| | 66243/75824 [00:00<00:00, 113385.46it/s]100%|| 75824/75824 [00:00<00:00, 111860.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10532/75824 [00:00<00:00, 105314.07it/s] 18%|        | 13692/75824 [00:00<00:01, 54424.15it/s]  28%|       | 21593/75824 [00:00<00:00, 60026.79it/s] 41%|     | 31358/75824 [00:00<00:00, 67870.78it/s] 57%|    | 43060/75824 [00:00<00:00, 77655.34it/s] 73%|  | 55389/75824 [00:00<00:00, 87354.84it/s] 89%| | 67263/75824 [00:00<00:00, 94877.47it/s]100%|| 75824/75824 [00:00<00:00, 93806.56it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7777/75824 [00:00<00:00, 77768.22it/s] 26%|       | 19444/75824 [00:00<00:00, 86411.14it/s] 34%|      | 25869/75824 [00:00<00:00, 74321.78it/s] 41%|      | 31144/75824 [00:00<00:00, 60884.96it/s] 50%|     | 37963/75824 [00:00<00:00, 62906.32it/s] 64%|   | 48319/75824 [00:00<00:00, 70385.71it/s] 73%|  | 55112/75824 [00:00<00:00, 65729.61it/s] 88%| | 66771/75824 [00:00<00:00, 75626.48it/s] 99%|| 74793/75824 [00:00<00:00, 70496.54it/s]100%|| 75824/75824 [00:01<00:00, 74822.34it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10963/75824 [00:00<00:00, 109623.05it/s] 27%|       | 20751/75824 [00:00<00:00, 105811.88it/s] 36%|      | 27594/75824 [00:00<00:00, 90910.98it/s]  52%|    | 39572/75824 [00:00<00:00, 97994.83it/s] 67%|   | 51104/75824 [00:00<00:00, 102617.92it/s] 83%| | 62984/75824 [00:00<00:00, 106989.07it/s] 99%|| 74884/75824 [00:00<00:00, 110329.70it/s]100%|| 75824/75824 [00:00<00:00, 107059.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9308/75824 [00:00<00:00, 93078.76it/s] 27%|       | 20740/75824 [00:00<00:00, 98573.23it/s] 43%|     | 32460/75824 [00:00<00:00, 103506.65it/s] 58%|    | 43602/75824 [00:00<00:00, 105758.58it/s] 71%|   | 53665/75824 [00:00<00:00, 104164.36it/s] 85%| | 64411/75824 [00:00<00:00, 105129.30it/s]100%|| 75824/75824 [00:00<00:00, 108980.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8421/75824 [00:00<00:00, 84206.07it/s] 26%|       | 19894/75824 [00:00<00:00, 91508.96it/s] 41%|     | 31437/75824 [00:00<00:00, 97574.73it/s] 57%|    | 43123/75824 [00:00<00:00, 102656.79it/s] 72%|  | 54824/75824 [00:00<00:00, 106577.04it/s] 88%| | 66486/75824 [00:00<00:00, 109401.17it/s]100%|| 75824/75824 [00:00<00:00, 111574.10it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11284/75824 [00:00<00:00, 112830.69it/s] 30%|       | 23042/75824 [00:00<00:00, 114212.36it/s] 45%|     | 34355/75824 [00:00<00:00, 113882.56it/s] 61%|    | 46196/75824 [00:00<00:00, 115203.89it/s] 77%|  | 58132/75824 [00:00<00:00, 116417.69it/s] 93%|| 70217/75824 [00:00<00:00, 117712.41it/s]100%|| 75824/75824 [00:00<00:00, 117378.53it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11969/75824 [00:00<00:00, 119683.84it/s] 31%|       | 23674/75824 [00:00<00:00, 118880.15it/s] 47%|     | 35501/75824 [00:00<00:00, 118693.92it/s] 63%|   | 47530/75824 [00:00<00:00, 119165.36it/s] 79%|  | 59587/75824 [00:00<00:00, 119582.06it/s] 95%|| 71714/75824 [00:00<00:00, 120081.48it/s]100%|| 75824/75824 [00:00<00:00, 119539.83it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9672/75824 [00:00<00:00, 96717.09it/s] 28%|       | 21336/75824 [00:00<00:00, 101940.71it/s] 44%|     | 33010/75824 [00:00<00:00, 105969.86it/s] 59%|    | 44741/75824 [00:00<00:00, 109133.32it/s] 74%|  | 56462/75824 [00:00<00:00, 111435.80it/s] 89%| | 67824/75824 [00:00<00:00, 112079.93it/s]100%|| 75824/75824 [00:00<00:00, 113420.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8566/75824 [00:00<00:00, 85656.61it/s] 27%|       | 20256/75824 [00:00<00:00, 93122.81it/s] 41%|      | 30898/75824 [00:00<00:00, 96747.66it/s] 51%|     | 38588/75824 [00:00<00:00, 89793.83it/s] 66%|   | 50322/75824 [00:00<00:00, 96596.26it/s] 80%|  | 60305/75824 [00:00<00:00, 97462.26it/s] 91%|| 69255/75824 [00:00<00:00, 91690.09it/s]100%|| 75824/75824 [00:00<00:00, 92173.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9397/75824 [00:00<00:00, 93962.02it/s] 25%|       | 19059/75824 [00:00<00:00, 94687.84it/s] 35%|      | 26169/75824 [00:00<00:00, 86116.71it/s] 49%|     | 37238/75824 [00:00<00:00, 91009.38it/s] 63%|   | 47810/75824 [00:00<00:00, 94973.27it/s] 77%|  | 58665/75824 [00:00<00:00, 98673.83it/s] 92%|| 69995/75824 [00:00<00:00, 102647.69it/s]100%|| 75824/75824 [00:00<00:00, 100422.75it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11430/75824 [00:00<00:00, 114298.75it/s] 31%|       | 23297/75824 [00:00<00:00, 115573.71it/s] 45%|     | 34394/75824 [00:00<00:00, 114151.25it/s] 60%|    | 45834/75824 [00:00<00:00, 114224.08it/s] 75%|  | 56963/75824 [00:00<00:00, 113325.87it/s] 89%| | 67591/75824 [00:00<00:00, 111113.97it/s]100%|| 75824/75824 [00:00<00:00, 112645.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7957/75824 [00:00<00:00, 79568.37it/s] 21%|        | 15774/75824 [00:00<00:00, 79143.54it/s] 36%|      | 27548/75824 [00:00<00:00, 87775.62it/s] 45%|     | 33892/75824 [00:00<00:00, 78434.35it/s] 53%|    | 40448/75824 [00:00<00:00, 74069.55it/s] 68%|   | 51586/75824 [00:00<00:00, 82343.76it/s] 84%| | 63332/75824 [00:00<00:00, 90456.11it/s] 96%|| 72745/75824 [00:00<00:00, 90404.08it/s]100%|| 75824/75824 [00:00<00:00, 88488.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12079/75824 [00:00<00:00, 120786.66it/s] 22%|       | 16578/75824 [00:00<00:00, 74692.74it/s]  31%|      | 23746/75824 [00:00<00:00, 73350.16it/s] 40%|      | 30510/75824 [00:00<00:00, 71538.24it/s] 55%|    | 41358/75824 [00:00<00:00, 79677.80it/s] 64%|   | 48345/75824 [00:00<00:00, 68317.63it/s] 80%|  | 60300/75824 [00:00<00:00, 78395.84it/s] 95%|| 72081/75824 [00:00<00:00, 87141.64it/s]100%|| 75824/75824 [00:00<00:00, 85835.19it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9647/75824 [00:00<00:00, 96464.34it/s] 26%|       | 19905/75824 [00:00<00:00, 98220.63it/s] 35%|      | 26567/75824 [00:00<00:00, 84002.01it/s] 42%|     | 32023/75824 [00:00<00:00, 57321.72it/s] 50%|     | 37897/75824 [00:00<00:00, 57739.36it/s] 63%|   | 47765/75824 [00:00<00:00, 65946.92it/s] 74%|  | 55851/75824 [00:00<00:00, 69091.02it/s] 83%| | 62768/75824 [00:00<00:00, 67417.22it/s] 92%|| 69524/75824 [00:00<00:00, 65246.60it/s]100%|| 75824/75824 [00:01<00:00, 68452.68it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7952/75824 [00:00<00:00, 79516.28it/s] 21%|        | 15997/75824 [00:00<00:00, 79793.80it/s] 35%|      | 26791/75824 [00:00<00:00, 86565.17it/s] 51%|     | 38489/75824 [00:00<00:00, 93886.56it/s] 66%|   | 50268/75824 [00:00<00:00, 99971.27it/s] 82%| | 62080/75824 [00:00<00:00, 104801.44it/s] 97%|| 73856/75824 [00:00<00:00, 108378.07it/s]100%|| 75824/75824 [00:00<00:00, 105780.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11888/75824 [00:00<00:00, 118878.13it/s] 29%|       | 21808/75824 [00:00<00:00, 112200.03it/s] 39%|      | 29430/75824 [00:00<00:00, 98279.49it/s]  52%|    | 39054/75824 [00:00<00:00, 96244.18it/s] 63%|   | 47654/75824 [00:00<00:00, 92920.24it/s] 79%|  | 59694/75824 [00:00<00:00, 99747.32it/s] 91%| | 69042/75824 [00:00<00:00, 97779.34it/s]100%|| 75824/75824 [00:00<00:00, 97133.04it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7162/75824 [00:00<00:00, 71615.12it/s] 23%|       | 17404/75824 [00:00<00:00, 78717.68it/s] 32%|      | 23969/75824 [00:00<00:00, 74279.90it/s] 45%|     | 34360/75824 [00:00<00:00, 81227.52it/s] 58%|    | 44106/75824 [00:00<00:00, 83990.33it/s] 73%|  | 55069/75824 [00:00<00:00, 88758.64it/s] 84%| | 63356/75824 [00:00<00:00, 77945.87it/s] 97%|| 73891/75824 [00:00<00:00, 84542.42it/s]100%|| 75824/75824 [00:00<00:00, 87470.91it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11658/75824 [00:00<00:00, 116577.05it/s] 31%|       | 23460/75824 [00:00<00:00, 114565.09it/s] 39%|      | 29813/75824 [00:00<00:00, 92316.36it/s]  50%|     | 37822/75824 [00:00<00:00, 88269.79it/s] 66%|   | 49717/75824 [00:00<00:00, 95671.03it/s] 78%|  | 58909/75824 [00:00<00:00, 94512.12it/s] 93%|| 70857/75824 [00:00<00:00, 100833.29it/s]100%|| 75824/75824 [00:00<00:00, 101239.60it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7262/75824 [00:00<00:00, 72617.13it/s] 25%|       | 19053/75824 [00:00<00:00, 82075.13it/s] 34%|      | 25745/75824 [00:00<00:00, 76186.35it/s] 41%|     | 31463/75824 [00:00<00:00, 69277.65it/s] 57%|    | 43005/75824 [00:00<00:00, 78717.16it/s] 69%|   | 52006/75824 [00:00<00:00, 81794.74it/s] 82%| | 62066/75824 [00:00<00:00, 86653.15it/s] 93%|| 70580/75824 [00:00<00:00, 76876.94it/s]100%|| 75824/75824 [00:00<00:00, 80988.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7472/75824 [00:00<00:00, 74718.47it/s] 25%|       | 19228/75824 [00:00<00:00, 83888.91it/s] 37%|      | 28160/75824 [00:00<00:00, 85446.92it/s] 50%|     | 38237/75824 [00:00<00:00, 87585.66it/s] 60%|    | 45401/75824 [00:00<00:00, 77079.21it/s] 74%|  | 56014/75824 [00:00<00:00, 83974.15it/s] 90%| | 67904/75824 [00:00<00:00, 92089.25it/s]100%|| 75824/75824 [00:00<00:00, 95424.34it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7240/75824 [00:00<00:00, 72396.10it/s] 17%|        | 13261/75824 [00:00<00:00, 66497.48it/s] 26%|       | 19551/75824 [00:00<00:00, 65374.47it/s] 41%|      | 31160/75824 [00:00<00:00, 75233.87it/s] 56%|    | 42448/75824 [00:00<00:00, 83596.77it/s] 71%|   | 53609/75824 [00:00<00:00, 90402.43it/s] 86%| | 65412/75824 [00:00<00:00, 97228.57it/s]100%|| 75824/75824 [00:00<00:00, 94601.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11541/75824 [00:00<00:00, 115403.78it/s] 30%|       | 22774/75824 [00:00<00:00, 114463.83it/s] 45%|     | 34125/75824 [00:00<00:00, 114175.79it/s] 55%|    | 41586/75824 [00:00<00:00, 93985.99it/s]  65%|   | 49538/75824 [00:00<00:00, 89119.68it/s] 81%|  | 61133/75824 [00:00<00:00, 95766.76it/s] 96%|| 72588/75824 [00:00<00:00, 100719.91it/s]100%|| 75824/75824 [00:00<00:00, 101239.53it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7202/75824 [00:00<00:01, 64540.02it/s] 21%|        | 15741/75824 [00:00<00:00, 69640.03it/s] 35%|      | 26325/75824 [00:00<00:00, 77602.31it/s] 47%|     | 35745/75824 [00:00<00:00, 81933.02it/s] 58%|    | 44223/75824 [00:00<00:00, 81804.98it/s] 70%|   | 53129/75824 [00:00<00:00, 83853.10it/s] 86%| | 64869/75824 [00:00<00:00, 91715.13it/s]100%|| 75824/75824 [00:00<00:00, 93871.90it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11687/75824 [00:00<00:00, 116868.16it/s] 31%|       | 23441/75824 [00:00<00:00, 117067.44it/s] 46%|     | 35233/75824 [00:00<00:00, 117319.60it/s] 62%|   | 47099/75824 [00:00<00:00, 117716.14it/s] 78%|  | 59111/75824 [00:00<00:00, 118426.00it/s] 94%|| 71098/75824 [00:00<00:00, 118854.56it/s]100%|| 75824/75824 [00:00<00:00, 118602.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10826/75824 [00:00<00:00, 108258.81it/s] 29%|       | 22309/75824 [00:00<00:00, 110148.11it/s] 39%|      | 29852/75824 [00:00<00:00, 96369.77it/s]  48%|     | 36093/75824 [00:00<00:00, 78342.78it/s] 56%|    | 42098/75824 [00:00<00:00, 63689.94it/s] 68%|   | 51327/75824 [00:00<00:00, 70216.53it/s] 79%|  | 59876/75824 [00:00<00:00, 74191.95it/s] 88%| | 67090/75824 [00:00<00:00, 68681.22it/s]100%|| 75824/75824 [00:00<00:00, 79875.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8922/75824 [00:00<00:00, 87945.45it/s] 22%|       | 16937/75824 [00:00<00:00, 85450.38it/s] 28%|       | 21189/75824 [00:00<00:00, 60693.59it/s] 37%|      | 28215/75824 [00:00<00:00, 63277.45it/s] 49%|     | 37475/75824 [00:00<00:00, 69814.27it/s] 58%|    | 43701/75824 [00:00<00:00, 65778.45it/s] 69%|   | 52209/75824 [00:00<00:00, 69901.25it/s] 78%|  | 58933/75824 [00:00<00:00, 55917.39it/s] 93%|| 70579/75824 [00:01<00:00, 66249.00it/s]100%|| 75824/75824 [00:01<00:00, 72060.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8774/75824 [00:00<00:00, 87735.27it/s] 25%|       | 19292/75824 [00:00<00:00, 92327.62it/s] 41%|      | 30926/75824 [00:00<00:00, 98420.51it/s] 50%|     | 38077/75824 [00:00<00:00, 88435.61it/s] 59%|    | 45115/75824 [00:00<00:00, 78253.44it/s] 75%|  | 56722/75824 [00:00<00:00, 86729.20it/s] 90%| | 68372/75824 [00:00<00:00, 93929.60it/s]100%|| 75824/75824 [00:00<00:00, 97619.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9293/75824 [00:00<00:00, 92924.11it/s] 20%|        | 15541/75824 [00:00<00:00, 79893.08it/s] 28%|       | 21503/75824 [00:00<00:00, 72496.77it/s] 38%|      | 28486/75824 [00:00<00:00, 71651.79it/s] 47%|     | 35585/75824 [00:00<00:00, 71450.59it/s] 56%|    | 42176/75824 [00:00<00:00, 69692.08it/s] 65%|   | 49150/75824 [00:00<00:00, 69704.83it/s] 74%|  | 56185/75824 [00:00<00:00, 69896.01it/s] 84%| | 63456/75824 [00:00<00:00, 70716.60it/s] 93%|| 70201/75824 [00:01<00:00, 69248.24it/s]100%|| 75824/75824 [00:01<00:00, 69854.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11162/75824 [00:00<00:00, 111612.39it/s] 30%|       | 22561/75824 [00:00<00:00, 112314.43it/s] 45%|     | 34014/75824 [00:00<00:00, 112967.45it/s] 59%|    | 45009/75824 [00:00<00:00, 112042.63it/s] 74%|  | 56154/75824 [00:00<00:00, 111862.61it/s] 89%| | 67534/75824 [00:00<00:00, 112436.26it/s]100%|| 75824/75824 [00:00<00:00, 112880.44it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6819/75824 [00:00<00:01, 67321.08it/s] 20%|        | 14898/75824 [00:00<00:00, 70864.87it/s] 35%|      | 26383/75824 [00:00<00:00, 80063.34it/s] 49%|     | 37443/75824 [00:00<00:00, 87293.47it/s] 65%|   | 49034/75824 [00:00<00:00, 94274.25it/s] 80%|  | 60694/75824 [00:00<00:00, 100018.36it/s] 96%|| 72436/75824 [00:00<00:00, 104670.37it/s]100%|| 75824/75824 [00:00<00:00, 102908.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6563/75824 [00:00<00:01, 65625.99it/s] 16%|        | 12446/75824 [00:00<00:00, 63427.58it/s] 23%|       | 17443/75824 [00:00<00:01, 55009.42it/s] 29%|       | 21892/75824 [00:00<00:01, 51365.80it/s] 35%|      | 26441/75824 [00:00<00:01, 47510.40it/s] 45%|     | 33909/75824 [00:00<00:00, 53330.27it/s] 54%|    | 40887/75824 [00:00<00:00, 57012.26it/s] 61%|   | 46516/75824 [00:00<00:00, 56792.39it/s] 76%|  | 57903/75824 [00:00<00:00, 66843.35it/s] 92%|| 69477/75824 [00:01<00:00, 76544.60it/s]100%|| 75824/75824 [00:01<00:00, 69522.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8980/75824 [00:00<00:00, 89798.59it/s] 27%|       | 20379/75824 [00:00<00:00, 95903.43it/s] 42%|     | 32064/75824 [00:00<00:00, 101352.45it/s] 52%|    | 39332/75824 [00:00<00:00, 90625.37it/s]  67%|   | 50773/75824 [00:00<00:00, 94775.26it/s] 78%|  | 59020/75824 [00:00<00:00, 81351.89it/s] 88%| | 66628/75824 [00:00<00:00, 72380.27it/s]100%|| 75824/75824 [00:00<00:00, 88573.10it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7765/75824 [00:00<00:00, 77646.19it/s] 22%|       | 16674/75824 [00:00<00:00, 80757.86it/s] 37%|      | 28303/75824 [00:00<00:00, 88906.99it/s] 52%|    | 39584/75824 [00:00<00:00, 94940.92it/s] 67%|   | 50783/75824 [00:00<00:00, 99484.47it/s] 82%| | 62296/75824 [00:00<00:00, 103709.95it/s] 95%|| 71990/75824 [00:00<00:00, 99149.77it/s] 100%|| 75824/75824 [00:00<00:00, 102394.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6116/75824 [00:00<00:01, 61158.89it/s] 14%|        | 10827/75824 [00:00<00:01, 56136.01it/s] 21%|        | 15725/75824 [00:00<00:01, 53617.32it/s] 36%|      | 27355/75824 [00:00<00:00, 63958.37it/s] 51%|    | 38910/75824 [00:00<00:00, 73850.09it/s] 66%|   | 50015/75824 [00:00<00:00, 82100.18it/s] 82%| | 61882/75824 [00:00<00:00, 90462.69it/s] 97%|| 73731/75824 [00:00<00:00, 97371.00it/s]100%|| 75824/75824 [00:00<00:00, 92638.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10309/75824 [00:00<00:00, 103088.13it/s] 27%|       | 20710/75824 [00:00<00:00, 103360.65it/s] 34%|      | 25995/75824 [00:00<00:00, 79975.60it/s]  45%|     | 34266/75824 [00:00<00:00, 80775.81it/s] 60%|    | 45802/75824 [00:00<00:00, 88757.48it/s] 76%|  | 57394/75824 [00:00<00:00, 95468.26it/s] 87%| | 66318/75824 [00:00<00:00, 79762.63it/s]100%|| 75824/75824 [00:00<00:00, 90753.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10101/75824 [00:00<00:00, 101007.69it/s] 23%|       | 17068/75824 [00:00<00:00, 88997.03it/s]  31%|       | 23230/75824 [00:00<00:00, 76635.16it/s] 38%|      | 28838/75824 [00:00<00:00, 69042.78it/s] 53%|    | 40527/75824 [00:00<00:00, 78707.98it/s] 65%|   | 48975/75824 [00:00<00:00, 79936.63it/s] 74%|  | 56350/75824 [00:00<00:00, 69732.96it/s] 90%| | 68497/75824 [00:00<00:00, 79948.36it/s]100%|| 75824/75824 [00:00<00:00, 83531.55it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6089/75824 [00:00<00:01, 54591.88it/s] 14%|        | 10403/75824 [00:00<00:01, 50362.95it/s] 19%|        | 14251/75824 [00:00<00:01, 45539.67it/s] 27%|       | 20310/75824 [00:00<00:01, 49205.84it/s] 35%|      | 26431/75824 [00:00<00:00, 52002.97it/s] 46%|     | 35005/75824 [00:00<00:00, 58962.58it/s] 57%|    | 43022/75824 [00:00<00:00, 64044.14it/s] 72%|  | 54477/75824 [00:00<00:00, 73806.44it/s] 88%| | 66569/75824 [00:00<00:00, 83575.07it/s]100%|| 75824/75824 [00:01<00:00, 75261.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6665/75824 [00:00<00:01, 66645.93it/s] 22%|       | 16315/75824 [00:00<00:00, 73463.60it/s] 32%|      | 23955/75824 [00:00<00:00, 74304.95it/s] 45%|     | 34381/75824 [00:00<00:00, 81312.53it/s] 60%|    | 45651/75824 [00:00<00:00, 86393.36it/s] 76%|  | 57580/75824 [00:00<00:00, 94183.69it/s] 88%| | 66632/75824 [00:00<00:00, 86293.65it/s]100%|| 75824/75824 [00:00<00:00, 93271.68it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6905/75824 [00:00<00:00, 69049.24it/s] 24%|       | 18084/75824 [00:00<00:00, 77995.10it/s] 37%|      | 27927/75824 [00:00<00:00, 81690.86it/s] 45%|     | 34216/75824 [00:00<00:00, 74965.48it/s] 54%|    | 40622/75824 [00:00<00:00, 71321.97it/s] 62%|   | 46863/75824 [00:00<00:00, 66826.56it/s] 71%|   | 53875/75824 [00:00<00:00, 67780.44it/s] 79%|  | 60260/75824 [00:00<00:00, 61552.40it/s] 91%|| 69206/75824 [00:00<00:00, 67907.09it/s]100%|| 75824/75824 [00:00<00:00, 76035.78it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10285/75824 [00:00<00:00, 102848.14it/s] 29%|       | 21856/75824 [00:00<00:00, 106395.79it/s] 38%|      | 28997/75824 [00:00<00:00, 92760.71it/s]  46%|     | 35081/75824 [00:00<00:00, 74818.91it/s] 58%|    | 44003/75824 [00:00<00:00, 78626.18it/s] 70%|   | 53036/75824 [00:00<00:00, 81804.79it/s] 80%|  | 60464/75824 [00:00<00:00, 73452.34it/s] 92%|| 69676/75824 [00:00<00:00, 78205.45it/s]100%|| 75824/75824 [00:00<00:00, 84857.56it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 5821/75824 [00:00<00:01, 58204.64it/s] 17%|        | 12666/75824 [00:00<00:01, 60940.67it/s] 24%|       | 18137/75824 [00:00<00:00, 58926.94it/s] 34%|      | 25569/75824 [00:00<00:00, 62830.54it/s] 49%|     | 37030/75824 [00:00<00:00, 72681.23it/s] 64%|   | 48467/75824 [00:00<00:00, 81603.73it/s] 79%|  | 60076/75824 [00:00<00:00, 89586.23it/s] 95%|| 71757/75824 [00:00<00:00, 96318.60it/s]100%|| 75824/75824 [00:00<00:00, 90806.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8022/75824 [00:00<00:00, 80219.50it/s] 26%|       | 19697/75824 [00:00<00:00, 88528.76it/s] 42%|     | 31507/75824 [00:00<00:00, 95717.00it/s] 57%|    | 43108/75824 [00:00<00:00, 101017.50it/s] 72%|  | 54701/75824 [00:00<00:00, 105071.53it/s] 88%| | 66620/75824 [00:00<00:00, 108942.67it/s]100%|| 75824/75824 [00:00<00:00, 112175.35it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11521/75824 [00:00<00:00, 115202.69it/s] 30%|       | 23011/75824 [00:00<00:00, 115108.86it/s] 39%|      | 29259/75824 [00:00<00:00, 91885.21it/s]  46%|     | 35240/75824 [00:00<00:00, 77354.26it/s] 62%|   | 46659/75824 [00:00<00:00, 85641.47it/s] 75%|  | 56549/75824 [00:00<00:00, 87358.02it/s] 85%| | 64579/75824 [00:00<00:00, 76111.21it/s] 97%|| 73920/75824 [00:00<00:00, 80586.90it/s]100%|| 75824/75824 [00:00<00:00, 84693.70it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10552/75824 [00:00<00:00, 105512.05it/s] 24%|       | 18292/75824 [00:00<00:00, 95142.28it/s]  37%|      | 28079/75824 [00:00<00:00, 95944.46it/s] 45%|     | 34192/75824 [00:00<00:00, 78047.67it/s] 53%|    | 40108/75824 [00:00<00:00, 71224.83it/s] 66%|   | 49891/75824 [00:00<00:00, 77550.98it/s] 81%|  | 61487/75824 [00:00<00:00, 86106.76it/s] 94%|| 71286/75824 [00:00<00:00, 87752.68it/s]100%|| 75824/75824 [00:00<00:00, 81862.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11345/75824 [00:00<00:00, 113436.04it/s] 30%|       | 22845/75824 [00:00<00:00, 113898.36it/s] 42%|     | 31721/75824 [00:00<00:00, 104975.74it/s] 51%|     | 38466/75824 [00:00<00:00, 82567.10it/s]  59%|    | 44841/75824 [00:00<00:00, 75844.16it/s] 74%|  | 55827/75824 [00:00<00:00, 83610.21it/s] 87%| | 66149/75824 [00:00<00:00, 88662.93it/s] 98%|| 74677/75824 [00:00<00:00, 78380.21it/s]100%|| 75824/75824 [00:00<00:00, 85980.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  5%|         | 3838/75824 [00:00<00:01, 38377.02it/s] 11%|         | 8220/75824 [00:00<00:01, 39244.38it/s] 19%|        | 14155/75824 [00:00<00:01, 43683.56it/s] 33%|      | 25199/75824 [00:00<00:00, 53359.30it/s] 43%|     | 32322/75824 [00:00<00:00, 57701.34it/s] 53%|    | 40282/75824 [00:00<00:00, 62891.57it/s] 68%|   | 51334/75824 [00:00<00:00, 72228.70it/s] 78%|  | 59277/75824 [00:00<00:00, 66378.25it/s] 94%|| 71334/75824 [00:00<00:00, 76723.48it/s]100%|| 75824/75824 [00:00<00:00, 76702.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 5777/75824 [00:00<00:01, 57767.99it/s] 22%|       | 16783/75824 [00:00<00:00, 67369.85it/s] 38%|      | 28451/75824 [00:00<00:00, 77149.99it/s] 53%|    | 40170/75824 [00:00<00:00, 85960.45it/s] 69%|   | 51992/75824 [00:00<00:00, 93624.26it/s] 84%| | 63763/75824 [00:00<00:00, 99746.63it/s] 99%|| 75413/75824 [00:00<00:00, 104242.92it/s]100%|| 75824/75824 [00:00<00:00, 107751.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12081/75824 [00:00<00:00, 120802.05it/s] 26%|       | 19978/75824 [00:00<00:00, 104236.04it/s] 38%|      | 28993/75824 [00:00<00:00, 99567.97it/s]  54%|    | 40681/75824 [00:00<00:00, 104196.75it/s] 69%|   | 52449/75824 [00:00<00:00, 107903.95it/s] 85%| | 64078/75824 [00:00<00:00, 110288.79it/s]100%|| 75824/75824 [00:00<00:00, 108477.54it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10828/75824 [00:00<00:00, 108275.97it/s] 31%|       | 23607/75824 [00:00<00:00, 113473.82it/s] 47%|     | 35455/75824 [00:00<00:00, 114929.68it/s] 63%|   | 47627/75824 [00:00<00:00, 116884.54it/s] 75%|  | 56760/75824 [00:00<00:00, 104482.81it/s] 90%| | 68574/75824 [00:00<00:00, 108235.04it/s]100%|| 75824/75824 [00:00<00:00, 113817.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7042/75824 [00:00<00:00, 70418.72it/s] 17%|        | 13096/75824 [00:00<00:00, 65406.37it/s] 24%|       | 18517/75824 [00:00<00:00, 61261.33it/s] 30%|       | 22830/75824 [00:00<00:00, 53611.98it/s] 36%|      | 27279/75824 [00:00<00:00, 49780.22it/s] 42%|     | 31565/75824 [00:00<00:00, 47479.47it/s] 47%|     | 35670/75824 [00:00<00:00, 45008.35it/s] 53%|    | 40055/75824 [00:00<00:00, 44652.21it/s] 58%|    | 44273/75824 [00:00<00:00, 43118.43it/s] 64%|   | 48557/75824 [00:01<00:00, 43033.30it/s] 70%|   | 52723/75824 [00:01<00:00, 42216.91it/s] 75%|  | 56852/75824 [00:01<00:00, 41909.70it/s] 83%| | 63285/75824 [00:01<00:00, 46695.55it/s] 90%| | 68084/75824 [00:01<00:00, 45246.37it/s]100%|| 75824/75824 [00:01<00:00, 49467.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10924/75824 [00:00<00:00, 109232.81it/s] 29%|       | 21689/75824 [00:00<00:00, 108749.44it/s] 44%|     | 33170/75824 [00:00<00:00, 110496.79it/s] 59%|    | 44839/75824 [00:00<00:00, 112283.48it/s] 75%|  | 56674/75824 [00:00<00:00, 114036.59it/s] 90%| | 68347/75824 [00:00<00:00, 114829.65it/s]100%|| 75824/75824 [00:00<00:00, 114251.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12104/75824 [00:00<00:00, 121034.34it/s] 32%|      | 24413/75824 [00:00<00:00, 121642.20it/s] 48%|     | 36672/75824 [00:00<00:00, 121922.34it/s] 64%|   | 48268/75824 [00:00<00:00, 120065.12it/s] 80%|  | 60308/75824 [00:00<00:00, 120163.02it/s] 93%|| 70295/75824 [00:00<00:00, 96712.84it/s] 100%|| 75824/75824 [00:00<00:00, 100501.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9589/75824 [00:00<00:00, 95888.26it/s] 25%|       | 18803/75824 [00:00<00:00, 92536.23it/s] 38%|      | 28985/75824 [00:00<00:00, 95137.74it/s] 54%|    | 40736/75824 [00:00<00:00, 100899.86it/s] 69%|   | 52499/75824 [00:00<00:00, 105395.08it/s] 85%| | 64299/75824 [00:00<00:00, 108882.16it/s]100%|| 75824/75824 [00:00<00:00, 107544.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6732/75824 [00:00<00:01, 60866.03it/s] 17%|        | 13074/75824 [00:00<00:01, 61610.20it/s] 30%|       | 23058/75824 [00:00<00:00, 69605.08it/s] 45%|     | 34365/75824 [00:00<00:00, 78677.53it/s] 58%|    | 43893/75824 [00:00<00:00, 83016.74it/s] 73%|  | 55427/75824 [00:00<00:00, 90557.92it/s] 85%| | 64329/75824 [00:00<00:00, 83206.78it/s] 96%|| 72659/75824 [00:00<00:00, 78193.04it/s]100%|| 75824/75824 [00:00<00:00, 85411.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6000/75824 [00:00<00:01, 59995.91it/s] 19%|        | 14077/75824 [00:00<00:00, 65010.93it/s] 29%|       | 21854/75824 [00:00<00:00, 68177.73it/s] 44%|     | 33560/75824 [00:00<00:00, 77941.73it/s] 53%|    | 40492/75824 [00:00<00:00, 66243.76it/s] 68%|   | 51379/75824 [00:00<00:00, 75059.55it/s] 81%|  | 61553/75824 [00:00<00:00, 81120.28it/s] 92%|| 69937/75824 [00:00<00:00, 79033.04it/s]100%|| 75824/75824 [00:00<00:00, 83526.57it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11650/75824 [00:00<00:00, 116499.00it/s] 31%|       | 23204/75824 [00:00<00:00, 116208.91it/s] 46%|     | 34815/75824 [00:00<00:00, 116177.43it/s] 61%|   | 46474/75824 [00:00<00:00, 116300.43it/s] 77%|  | 58225/75824 [00:00<00:00, 116657.89it/s] 92%|| 69887/75824 [00:00<00:00, 116644.14it/s]100%|| 75824/75824 [00:00<00:00, 116497.86it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6886/75824 [00:00<00:01, 66696.79it/s] 24%|       | 18066/75824 [00:00<00:00, 75880.45it/s] 39%|      | 29389/75824 [00:00<00:00, 82831.29it/s] 54%|    | 41177/75824 [00:00<00:00, 90941.92it/s] 65%|   | 49256/75824 [00:00<00:00, 80417.64it/s] 75%|  | 56811/75824 [00:00<00:00, 72638.98it/s] 89%| | 67267/75824 [00:00<00:00, 79961.40it/s]100%|| 75824/75824 [00:00<00:00, 90501.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6784/75824 [00:00<00:01, 67481.60it/s] 17%|        | 12831/75824 [00:00<00:00, 65211.84it/s] 24%|       | 18482/75824 [00:00<00:00, 62111.00it/s] 32%|      | 24444/75824 [00:00<00:00, 61341.00it/s] 41%|      | 30987/75824 [00:00<00:00, 62511.92it/s] 56%|    | 42654/75824 [00:00<00:00, 72625.32it/s] 71%|  | 54183/75824 [00:00<00:00, 81694.43it/s] 86%| | 65527/75824 [00:00<00:00, 89180.34it/s]100%|| 75824/75824 [00:00<00:00, 84992.24it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6776/75824 [00:00<00:01, 64248.99it/s] 17%|        | 13127/75824 [00:00<00:00, 64024.91it/s] 33%|      | 24996/75824 [00:00<00:00, 74288.47it/s] 49%|     | 36851/75824 [00:00<00:00, 83658.04it/s] 61%|   | 46512/75824 [00:00<00:00, 87161.93it/s] 76%|  | 57519/75824 [00:00<00:00, 92964.96it/s] 91%| | 68728/75824 [00:00<00:00, 92738.90it/s]100%|| 75824/75824 [00:00<00:00, 90815.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7647/75824 [00:00<00:00, 76465.52it/s] 20%|        | 15432/75824 [00:00<00:00, 76874.38it/s] 35%|      | 26856/75824 [00:00<00:00, 85237.00it/s] 51%|     | 38771/75824 [00:00<00:00, 93193.52it/s] 67%|   | 50777/75824 [00:00<00:00, 99896.11it/s] 82%| | 62334/75824 [00:00<00:00, 103568.95it/s] 98%|| 74398/75824 [00:00<00:00, 108158.72it/s]100%|| 75824/75824 [00:00<00:00, 106242.91it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4674/75824 [00:00<00:01, 43973.79it/s] 10%|         | 7753/75824 [00:00<00:01, 38186.80it/s] 18%|        | 13908/75824 [00:00<00:01, 42380.04it/s] 27%|       | 20838/75824 [00:00<00:01, 47970.16it/s] 35%|      | 26883/75824 [00:00<00:00, 50114.72it/s] 48%|     | 36078/75824 [00:00<00:00, 58035.44it/s] 63%|   | 47680/75824 [00:00<00:00, 68271.17it/s] 78%|  | 59503/75824 [00:00<00:00, 78180.87it/s] 93%|| 70801/75824 [00:00<00:00, 86140.14it/s]100%|| 75824/75824 [00:00<00:00, 78170.41it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8713/75824 [00:00<00:00, 81729.94it/s] 20%|        | 14830/75824 [00:00<00:00, 74242.17it/s] 27%|       | 20775/75824 [00:00<00:00, 68124.64it/s] 36%|      | 26919/75824 [00:00<00:00, 65917.24it/s] 50%|     | 38165/75824 [00:00<00:00, 75260.66it/s] 66%|   | 50001/75824 [00:00<00:00, 84489.33it/s] 82%| | 61798/75824 [00:00<00:00, 92351.54it/s] 97%|| 73668/75824 [00:00<00:00, 98940.18it/s]100%|| 75824/75824 [00:00<00:00, 91457.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11718/75824 [00:00<00:00, 117177.88it/s] 31%|      | 23735/75824 [00:00<00:00, 118058.62it/s] 47%|     | 35623/75824 [00:00<00:00, 118302.61it/s] 62%|   | 47335/75824 [00:00<00:00, 117942.98it/s] 78%|  | 58999/75824 [00:00<00:00, 117546.62it/s] 94%|| 71041/75824 [00:00<00:00, 118392.08it/s]100%|| 75824/75824 [00:00<00:00, 118626.34it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6315/75824 [00:00<00:01, 59834.71it/s] 24%|       | 17841/75824 [00:00<00:00, 69921.55it/s] 39%|      | 29453/75824 [00:00<00:00, 79397.46it/s] 50%|     | 38138/75824 [00:00<00:00, 81495.13it/s] 64%|   | 48569/75824 [00:00<00:00, 87217.78it/s] 80%|  | 60295/75824 [00:00<00:00, 94478.30it/s] 95%|| 72153/75824 [00:00<00:00, 100611.53it/s]100%|| 75824/75824 [00:00<00:00, 102946.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9962/75824 [00:00<00:00, 99615.34it/s] 28%|       | 21232/75824 [00:00<00:00, 103208.68it/s] 44%|     | 33158/75824 [00:00<00:00, 107550.37it/s] 59%|    | 45100/75824 [00:00<00:00, 110855.33it/s] 74%|  | 56485/75824 [00:00<00:00, 111736.93it/s] 90%| | 68493/75824 [00:00<00:00, 114112.77it/s]100%|| 75824/75824 [00:00<00:00, 114783.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8524/75824 [00:00<00:00, 85234.19it/s] 19%|        | 14709/75824 [00:00<00:00, 75704.22it/s] 27%|       | 20364/75824 [00:00<00:00, 68440.55it/s] 36%|      | 27024/75824 [00:00<00:00, 67877.61it/s] 49%|     | 37126/75824 [00:00<00:00, 75287.64it/s] 62%|   | 47122/75824 [00:00<00:00, 81307.56it/s] 77%|  | 58109/75824 [00:00<00:00, 88183.69it/s] 92%|| 69750/75824 [00:00<00:00, 95101.15it/s]100%|| 75824/75824 [00:00<00:00, 86003.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7492/75824 [00:00<00:00, 74917.57it/s] 25%|       | 19165/75824 [00:00<00:00, 83935.72it/s] 38%|      | 29160/75824 [00:00<00:00, 87452.17it/s] 47%|     | 35621/75824 [00:00<00:00, 78105.28it/s] 55%|    | 42019/75824 [00:00<00:00, 71329.42it/s] 67%|   | 50868/75824 [00:00<00:00, 75734.15it/s] 82%| | 62096/75824 [00:00<00:00, 83929.42it/s] 97%|| 73892/75824 [00:00<00:00, 91880.82it/s]100%|| 75824/75824 [00:00<00:00, 91239.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6260/75824 [00:00<00:01, 62456.36it/s] 14%|        | 10670/75824 [00:00<00:01, 55522.69it/s] 22%|       | 16889/75824 [00:00<00:01, 57367.58it/s] 31%|       | 23371/75824 [00:00<00:00, 59250.89it/s] 43%|     | 32847/75824 [00:00<00:00, 66754.74it/s] 53%|    | 40331/75824 [00:00<00:00, 68954.89it/s] 65%|   | 49395/75824 [00:00<00:00, 74286.32it/s] 79%|  | 59782/75824 [00:00<00:00, 79566.99it/s] 95%|| 71846/75824 [00:00<00:00, 88617.68it/s]100%|| 75824/75824 [00:00<00:00, 80359.52it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9171/75824 [00:00<00:00, 91709.87it/s] 24%|       | 18318/75824 [00:00<00:00, 91637.21it/s] 38%|      | 28472/75824 [00:00<00:00, 94070.93it/s] 48%|     | 36218/75824 [00:00<00:00, 88383.12it/s] 57%|    | 42936/75824 [00:00<00:00, 72928.39it/s] 65%|   | 49193/75824 [00:00<00:00, 66368.14it/s] 80%|  | 60444/75824 [00:00<00:00, 75678.37it/s] 95%|| 72145/75824 [00:00<00:00, 84648.28it/s]100%|| 75824/75824 [00:00<00:00, 86526.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11447/75824 [00:00<00:00, 114465.20it/s] 31%|       | 23320/75824 [00:00<00:00, 115711.50it/s] 47%|     | 35393/75824 [00:00<00:00, 117171.02it/s] 63%|   | 47670/75824 [00:00<00:00, 118795.06it/s] 79%|  | 59939/75824 [00:00<00:00, 119937.11it/s] 95%|| 72061/75824 [00:00<00:00, 120318.38it/s]100%|| 75824/75824 [00:00<00:00, 120012.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4753/75824 [00:00<00:01, 47529.93it/s] 15%|        | 11369/75824 [00:00<00:01, 50937.21it/s] 22%|       | 16461/75824 [00:00<00:01, 49990.38it/s] 29%|       | 21662/75824 [00:00<00:01, 48867.53it/s] 40%|      | 29970/75824 [00:00<00:00, 55755.38it/s] 49%|     | 36883/75824 [00:00<00:00, 59189.59it/s] 62%|   | 47301/75824 [00:00<00:00, 67998.67it/s] 77%|  | 58088/75824 [00:00<00:00, 73940.79it/s] 88%| | 66581/75824 [00:00<00:00, 76926.32it/s]100%|| 75824/75824 [00:01<00:00, 74214.91it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9369/75824 [00:00<00:00, 93689.42it/s] 26%|       | 19997/75824 [00:00<00:00, 97139.25it/s] 39%|      | 29729/75824 [00:00<00:00, 97191.21it/s] 54%|    | 41263/75824 [00:00<00:00, 102006.39it/s] 70%|   | 53186/75824 [00:00<00:00, 106627.20it/s] 86%| | 65168/75824 [00:00<00:00, 110267.28it/s]100%|| 75824/75824 [00:00<00:00, 109839.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|        | 8698/75824 [00:00<00:00, 86621.97it/s] 23%|       | 17264/75824 [00:00<00:00, 85843.89it/s] 33%|      | 25324/75824 [00:00<00:00, 84199.34it/s] 43%|     | 32450/75824 [00:00<00:00, 79848.31it/s] 54%|    | 40962/75824 [00:00<00:00, 81359.09it/s] 65%|   | 49103/75824 [00:00<00:00, 81374.15it/s] 80%|  | 60657/75824 [00:00<00:00, 89294.02it/s] 96%|| 72440/75824 [00:00<00:00, 96287.89it/s]100%|| 75824/75824 [00:00<00:00, 91263.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6111/75824 [00:00<00:01, 61105.25it/s] 22%|       | 16593/75824 [00:00<00:00, 69843.20it/s] 37%|      | 28144/75824 [00:00<00:00, 79240.92it/s] 52%|    | 39607/75824 [00:00<00:00, 87327.36it/s] 68%|   | 51271/75824 [00:00<00:00, 94447.57it/s] 83%| | 63301/75824 [00:00<00:00, 100954.42it/s] 99%|| 74924/75824 [00:00<00:00, 105097.61it/s]100%|| 75824/75824 [00:00<00:00, 107045.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11069/75824 [00:00<00:00, 110686.94it/s] 23%|       | 17489/75824 [00:00<00:00, 90083.39it/s]  35%|      | 26632/75824 [00:00<00:00, 89576.75it/s] 47%|     | 35591/75824 [00:00<00:00, 89580.62it/s] 62%|   | 46945/75824 [00:00<00:00, 94546.16it/s] 74%|  | 55833/75824 [00:00<00:00, 92771.00it/s] 89%| | 67301/75824 [00:00<00:00, 96743.74it/s]100%|| 75824/75824 [00:00<00:00, 89744.54it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11381/75824 [00:00<00:00, 113808.75it/s] 33%|      | 24783/75824 [00:00<00:00, 119200.98it/s] 48%|     | 36486/75824 [00:00<00:00, 118540.37it/s] 59%|    | 44485/75824 [00:00<00:00, 90601.89it/s]  73%|  | 55613/75824 [00:00<00:00, 95950.38it/s] 85%| | 64099/75824 [00:00<00:00, 84406.10it/s] 95%|| 72016/75824 [00:00<00:00, 64100.80it/s]100%|| 75824/75824 [00:00<00:00, 82084.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11936/75824 [00:00<00:00, 119354.99it/s] 31%|      | 23810/75824 [00:00<00:00, 119167.81it/s] 47%|     | 35964/75824 [00:00<00:00, 119867.69it/s] 59%|    | 45081/75824 [00:00<00:00, 109521.08it/s] 70%|   | 53342/75824 [00:00<00:00, 93442.42it/s]  86%| | 65507/75824 [00:00<00:00, 100426.77it/s]100%|| 75824/75824 [00:00<00:00, 107827.46it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11373/75824 [00:00<00:00, 113729.84it/s] 29%|       | 21802/75824 [00:00<00:00, 110721.21it/s] 42%|     | 31812/75824 [00:00<00:00, 107302.80it/s] 51%|     | 38677/75824 [00:00<00:00, 87128.34it/s]  60%|    | 45300/75824 [00:00<00:00, 77646.90it/s] 68%|   | 51794/75824 [00:00<00:00, 72706.43it/s] 84%| | 63724/75824 [00:00<00:00, 82355.33it/s] 95%|| 71814/75824 [00:00<00:00, 73378.98it/s]100%|| 75824/75824 [00:00<00:00, 81448.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6437/75824 [00:00<00:01, 64131.69it/s] 24%|       | 18011/75824 [00:00<00:00, 74034.71it/s] 36%|      | 27506/75824 [00:00<00:00, 78817.51it/s] 47%|     | 35287/75824 [00:00<00:00, 78510.68it/s] 62%|   | 47325/75824 [00:00<00:00, 86163.73it/s] 74%|  | 56081/75824 [00:00<00:00, 86577.82it/s] 89%| | 67436/75824 [00:00<00:00, 93216.28it/s]100%|| 75824/75824 [00:00<00:00, 96600.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11922/75824 [00:00<00:00, 119213.29it/s] 31%|       | 23679/75824 [00:00<00:00, 118714.85it/s] 47%|     | 35642/75824 [00:00<00:00, 118986.35it/s] 63%|   | 47688/75824 [00:00<00:00, 119423.49it/s] 79%|  | 59820/75824 [00:00<00:00, 119984.02it/s] 94%|| 71612/75824 [00:00<00:00, 119355.57it/s]100%|| 75824/75824 [00:00<00:00, 119240.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9721/75824 [00:00<00:00, 97207.54it/s] 26%|       | 19480/75824 [00:00<00:00, 97319.84it/s] 42%|     | 31579/75824 [00:00<00:00, 103387.50it/s] 58%|    | 43766/75824 [00:00<00:00, 108313.66it/s] 74%|  | 56139/75824 [00:00<00:00, 112517.43it/s] 90%| | 68434/75824 [00:00<00:00, 115454.70it/s]100%|| 75824/75824 [00:00<00:00, 114834.72it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14719/75824 [00:00<00:00, 147178.91it/s] 35%|      | 26672/75824 [00:00<00:00, 137627.69it/s] 51%|     | 38660/75824 [00:00<00:00, 131773.05it/s] 67%|   | 50764/75824 [00:00<00:00, 128357.61it/s] 82%| | 62322/75824 [00:00<00:00, 124234.28it/s] 98%|| 74062/75824 [00:00<00:00, 122101.65it/s]100%|| 75824/75824 [00:00<00:00, 122759.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9897/75824 [00:00<00:00, 98964.67it/s] 23%|       | 17470/75824 [00:00<00:00, 90622.07it/s] 31%|       | 23320/75824 [00:00<00:00, 77225.20it/s] 44%|     | 33164/75824 [00:00<00:00, 82270.11it/s] 52%|    | 39414/75824 [00:00<00:00, 74444.89it/s] 60%|    | 45617/75824 [00:00<00:00, 67102.94it/s] 68%|   | 51596/75824 [00:00<00:00, 64168.71it/s] 76%|  | 57528/75824 [00:00<00:00, 62053.98it/s] 92%|| 69603/75824 [00:00<00:00, 72647.86it/s]100%|| 75824/75824 [00:01<00:00, 75657.83it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11639/75824 [00:00<00:00, 116386.23it/s] 30%|       | 22851/75824 [00:00<00:00, 115071.50it/s] 46%|     | 34756/75824 [00:00<00:00, 116235.34it/s] 61%|   | 46594/75824 [00:00<00:00, 116868.26it/s] 77%|  | 58657/75824 [00:00<00:00, 117969.63it/s] 94%|| 71206/75824 [00:00<00:00, 120127.84it/s]100%|| 75824/75824 [00:00<00:00, 118713.57it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10702/75824 [00:00<00:00, 107016.02it/s] 29%|       | 21828/75824 [00:00<00:00, 108253.12it/s] 38%|      | 28788/75824 [00:00<00:00, 92792.01it/s]  53%|    | 39939/75824 [00:00<00:00, 94962.29it/s] 68%|   | 51737/75824 [00:00<00:00, 100865.33it/s] 82%| | 62230/75824 [00:00<00:00, 102050.03it/s] 96%|| 73111/75824 [00:00<00:00, 103987.18it/s]100%|| 75824/75824 [00:00<00:00, 103209.76it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11540/75824 [00:00<00:00, 115397.08it/s] 25%|       | 19083/75824 [00:00<00:00, 99569.62it/s]  41%|      | 31036/75824 [00:00<00:00, 104820.68it/s] 56%|    | 42493/75824 [00:00<00:00, 107565.93it/s] 72%|  | 54482/75824 [00:00<00:00, 110986.39it/s] 84%| | 63849/75824 [00:00<00:00, 101202.70it/s]100%|| 75824/75824 [00:00<00:00, 106574.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10429/75824 [00:00<00:00, 104283.88it/s] 30%|       | 22410/75824 [00:00<00:00, 108500.94it/s] 45%|     | 33793/75824 [00:00<00:00, 110044.34it/s] 60%|    | 45804/75824 [00:00<00:00, 112881.22it/s] 72%|  | 54632/75824 [00:00<00:00, 95605.31it/s]  83%| | 62925/75824 [00:00<00:00, 86549.15it/s] 99%|| 74902/75824 [00:00<00:00, 94403.04it/s]100%|| 75824/75824 [00:00<00:00, 99196.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11350/75824 [00:00<00:00, 113494.43it/s] 31%|       | 23183/75824 [00:00<00:00, 114901.52it/s] 41%|      | 30929/75824 [00:00<00:00, 100346.88it/s] 57%|    | 42897/75824 [00:00<00:00, 105455.87it/s] 72%|  | 54448/75824 [00:00<00:00, 108282.20it/s] 87%| | 65701/75824 [00:00<00:00, 109405.60it/s]100%|| 75471/75824 [00:00<00:00, 102492.92it/s]100%|| 75824/75824 [00:00<00:00, 106374.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6943/75824 [00:00<00:00, 69424.94it/s] 17%|        | 13149/75824 [00:00<00:00, 67037.57it/s] 27%|       | 20739/75824 [00:00<00:00, 69470.34it/s] 40%|      | 30450/75824 [00:00<00:00, 75266.64it/s] 48%|     | 36475/75824 [00:00<00:00, 68402.55it/s] 64%|   | 48529/75824 [00:00<00:00, 78600.71it/s] 79%|  | 60077/75824 [00:00<00:00, 86927.93it/s] 95%|| 71654/75824 [00:00<00:00, 93948.42it/s]100%|| 75824/75824 [00:00<00:00, 89633.91it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7085/75824 [00:00<00:01, 66073.55it/s] 24%|       | 18145/75824 [00:00<00:00, 73784.61it/s] 32%|      | 24413/75824 [00:00<00:00, 70060.12it/s] 40%|      | 30690/75824 [00:00<00:00, 67700.03it/s] 48%|     | 36060/75824 [00:00<00:00, 58485.09it/s] 54%|    | 41151/75824 [00:00<00:00, 50526.22it/s] 64%|   | 48466/75824 [00:00<00:00, 55693.16it/s] 79%|  | 60126/75824 [00:00<00:00, 66041.88it/s] 94%|| 71367/75824 [00:00<00:00, 75367.50it/s]100%|| 75824/75824 [00:01<00:00, 75173.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10420/75824 [00:00<00:00, 104191.65it/s] 29%|       | 21687/75824 [00:00<00:00, 106597.61it/s] 36%|      | 27283/75824 [00:00<00:00, 83837.34it/s]  44%|     | 33105/75824 [00:00<00:00, 74059.75it/s] 51%|     | 38841/75824 [00:00<00:00, 65791.38it/s] 60%|    | 45633/75824 [00:00<00:00, 66415.37it/s] 74%|  | 55973/75824 [00:00<00:00, 74354.55it/s] 83%| | 63198/75824 [00:00<00:00, 66725.63it/s] 95%|| 71814/75824 [00:00<00:00, 69907.27it/s]100%|| 75824/75824 [00:00<00:00, 76454.64it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11602/75824 [00:00<00:00, 116010.98it/s] 29%|       | 22152/75824 [00:00<00:00, 112643.67it/s] 44%|     | 33645/75824 [00:00<00:00, 113318.48it/s] 60%|    | 45393/75824 [00:00<00:00, 114534.40it/s] 75%|  | 57238/75824 [00:00<00:00, 115680.20it/s] 92%|| 69404/75824 [00:00<00:00, 117410.56it/s]100%|| 75824/75824 [00:00<00:00, 116306.74it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11568/75824 [00:00<00:00, 115675.42it/s] 29%|       | 22265/75824 [00:00<00:00, 112916.21it/s] 45%|     | 33956/75824 [00:00<00:00, 114083.12it/s] 60%|    | 45738/75824 [00:00<00:00, 115178.93it/s] 72%|  | 54491/75824 [00:00<00:00, 100930.83it/s] 83%| | 62968/75824 [00:00<00:00, 85016.89it/s]  96%|| 72764/75824 [00:00<00:00, 88524.29it/s]100%|| 75824/75824 [00:00<00:00, 97965.73it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6901/75824 [00:00<00:01, 63314.16it/s] 13%|        | 9773/75824 [00:00<00:01, 46507.84it/s] 25%|       | 18738/75824 [00:00<00:01, 54354.89it/s] 31%|       | 23356/75824 [00:00<00:01, 50727.95it/s] 40%|      | 30578/75824 [00:00<00:00, 55700.04it/s] 52%|    | 39413/75824 [00:00<00:00, 62249.66it/s] 60%|    | 45597/75824 [00:00<00:00, 57270.11it/s] 75%|  | 56870/75824 [00:00<00:00, 67185.85it/s] 91%| | 68817/75824 [00:00<00:00, 77339.72it/s]100%|| 75824/75824 [00:01<00:00, 75613.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5063/75824 [00:00<00:01, 43503.78it/s] 11%|        | 8680/75824 [00:00<00:01, 39842.32it/s] 24%|       | 18429/75824 [00:00<00:01, 48231.67it/s] 33%|      | 24779/75824 [00:00<00:01, 50939.69it/s] 41%|      | 31166/75824 [00:00<00:00, 53044.03it/s] 53%|    | 39961/75824 [00:00<00:00, 60212.30it/s] 63%|   | 47646/75824 [00:00<00:00, 62547.25it/s] 73%|  | 55413/75824 [00:00<00:00, 66426.05it/s] 88%| | 66358/75824 [00:00<00:00, 75037.32it/s] 99%|| 75393/75824 [00:01<00:00, 79000.59it/s]100%|| 75824/75824 [00:01<00:00, 71146.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8293/75824 [00:00<00:00, 82926.52it/s] 23%|       | 17452/75824 [00:00<00:00, 85348.30it/s] 38%|      | 29023/75824 [00:00<00:00, 92640.81it/s] 52%|    | 39673/75824 [00:00<00:00, 96402.84it/s] 63%|   | 47498/75824 [00:00<00:00, 80339.77it/s] 72%|  | 54796/75824 [00:00<00:00, 77979.69it/s] 85%| | 64829/75824 [00:00<00:00, 82033.15it/s]100%|| 75599/75824 [00:00<00:00, 88348.95it/s]100%|| 75824/75824 [00:00<00:00, 89737.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10813/75824 [00:00<00:00, 108125.98it/s] 29%|       | 22101/75824 [00:00<00:00, 109509.18it/s] 41%|      | 30773/75824 [00:00<00:00, 101504.51it/s] 56%|    | 42257/75824 [00:00<00:00, 105168.04it/s] 70%|   | 53219/75824 [00:00<00:00, 106462.78it/s] 86%| | 65233/75824 [00:00<00:00, 110227.07it/s] 99%|| 75078/75824 [00:00<00:00, 101708.53it/s]100%|| 75824/75824 [00:00<00:00, 102314.32it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 4942/75824 [00:00<00:01, 46036.18it/s] 18%|        | 13391/75824 [00:00<00:01, 53315.69it/s] 28%|       | 21174/75824 [00:00<00:00, 58879.12it/s] 43%|     | 32949/75824 [00:00<00:00, 69268.30it/s] 59%|    | 45003/75824 [00:00<00:00, 79399.17it/s] 75%|  | 56814/75824 [00:00<00:00, 88057.31it/s] 91%| | 68792/75824 [00:00<00:00, 95656.84it/s]100%|| 75824/75824 [00:00<00:00, 98480.69it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11698/75824 [00:00<00:00, 116977.04it/s] 25%|       | 19025/75824 [00:00<00:00, 98199.47it/s]  40%|      | 30494/75824 [00:00<00:00, 102625.10it/s] 50%|     | 37918/75824 [00:00<00:00, 91761.11it/s]  59%|    | 44788/75824 [00:00<00:00, 75597.52it/s] 68%|   | 51205/75824 [00:00<00:00, 66830.10it/s] 76%|  | 57275/75824 [00:00<00:00, 60226.48it/s] 83%| | 62992/75824 [00:00<00:00, 57247.42it/s] 90%| | 68534/75824 [00:01<00:00, 51275.22it/s] 97%|| 73651/75824 [00:01<00:00, 50589.09it/s]100%|| 75824/75824 [00:01<00:00, 63900.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8142/75824 [00:00<00:00, 81414.64it/s] 23%|       | 17461/75824 [00:00<00:00, 84621.18it/s] 37%|      | 28430/75824 [00:00<00:00, 90848.68it/s] 50%|     | 37839/75824 [00:00<00:00, 91796.00it/s] 60%|    | 45173/75824 [00:00<00:00, 80663.43it/s] 69%|   | 52193/75824 [00:00<00:00, 76800.51it/s] 85%| | 64507/75824 [00:00<00:00, 86573.65it/s]100%|| 75824/75824 [00:00<00:00, 93319.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10234/75824 [00:00<00:00, 102337.41it/s] 23%|       | 17644/75824 [00:00<00:00, 91234.60it/s]  37%|      | 28005/75824 [00:00<00:00, 94624.56it/s] 53%|    | 39998/75824 [00:00<00:00, 101018.23it/s] 68%|   | 51885/75824 [00:00<00:00, 105782.95it/s] 80%|  | 60979/75824 [00:00<00:00, 100221.32it/s] 92%|| 70023/75824 [00:00<00:00, 96830.86it/s] 100%|| 75824/75824 [00:00<00:00, 99503.56it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11749/75824 [00:00<00:00, 117487.31it/s] 31%|       | 23224/75824 [00:00<00:00, 116649.82it/s] 40%|      | 30194/75824 [00:00<00:00, 95993.04it/s]  53%|    | 40048/75824 [00:00<00:00, 96741.19it/s] 66%|   | 50160/75824 [00:00<00:00, 98013.43it/s] 77%|  | 58289/75824 [00:00<00:00, 77576.00it/s] 87%| | 66285/75824 [00:00<00:00, 78274.84it/s]100%|| 75824/75824 [00:00<00:00, 90450.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4721/75824 [00:00<00:01, 47117.70it/s] 13%|        | 9600/75824 [00:00<00:01, 47128.54it/s] 19%|        | 14605/75824 [00:00<00:01, 47968.38it/s] 27%|       | 20339/75824 [00:00<00:01, 49372.55it/s] 40%|      | 30603/75824 [00:00<00:00, 58476.19it/s] 56%|    | 42463/75824 [00:00<00:00, 68963.86it/s] 71%|   | 53863/75824 [00:00<00:00, 78235.88it/s] 87%| | 65969/75824 [00:00<00:00, 87524.04it/s]100%|| 75824/75824 [00:00<00:00, 84758.91it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11450/75824 [00:00<00:00, 114499.56it/s] 30%|       | 22861/75824 [00:00<00:00, 114382.20it/s] 46%|     | 34698/75824 [00:00<00:00, 115549.43it/s] 61%|    | 46138/75824 [00:00<00:00, 115201.47it/s] 77%|  | 58120/75824 [00:00<00:00, 116547.29it/s] 93%|| 70164/75824 [00:00<00:00, 117685.82it/s]100%|| 75824/75824 [00:00<00:00, 117154.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8071/75824 [00:00<00:00, 80705.84it/s] 26%|       | 19889/75824 [00:00<00:00, 89189.66it/s] 41%|      | 30897/75824 [00:00<00:00, 94573.76it/s] 57%|    | 42961/75824 [00:00<00:00, 101126.83it/s] 73%|  | 55051/75824 [00:00<00:00, 106343.51it/s] 88%| | 67027/75824 [00:00<00:00, 110041.58it/s]100%|| 75824/75824 [00:00<00:00, 112602.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6320/75824 [00:00<00:01, 63195.09it/s] 15%|        | 11563/75824 [00:00<00:01, 59526.85it/s] 22%|       | 16858/75824 [00:00<00:01, 56162.74it/s] 34%|      | 25605/75824 [00:00<00:00, 62568.44it/s] 43%|     | 32453/75824 [00:00<00:00, 62825.74it/s] 51%|     | 38583/75824 [00:00<00:00, 60876.02it/s] 65%|   | 49237/75824 [00:00<00:00, 69858.47it/s] 80%|  | 60509/75824 [00:00<00:00, 78853.07it/s] 94%|| 70917/75824 [00:00<00:00, 85036.19it/s]100%|| 75824/75824 [00:00<00:00, 78311.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11674/75824 [00:00<00:00, 116737.33it/s] 30%|       | 22722/75824 [00:00<00:00, 114785.19it/s] 45%|     | 34384/75824 [00:00<00:00, 115327.13it/s] 61%|   | 46471/75824 [00:00<00:00, 116934.93it/s] 76%|  | 57833/75824 [00:00<00:00, 115918.57it/s] 92%|| 69837/75824 [00:00<00:00, 117122.39it/s]100%|| 75824/75824 [00:00<00:00, 115771.66it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 7995/75824 [00:00<00:00, 79943.79it/s] 22%|       | 16634/75824 [00:00<00:00, 81664.93it/s] 33%|      | 25249/75824 [00:00<00:00, 82959.80it/s] 48%|     | 36718/75824 [00:00<00:00, 90467.73it/s] 64%|   | 48500/75824 [00:00<00:00, 97239.67it/s] 75%|  | 57170/75824 [00:00<00:00, 86046.28it/s] 86%| | 65274/75824 [00:00<00:00, 66620.11it/s]100%|| 75824/75824 [00:00<00:00, 83921.90it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7744/75824 [00:00<00:00, 77435.83it/s] 26%|       | 19603/75824 [00:00<00:00, 86434.10it/s] 34%|      | 25666/75824 [00:00<00:00, 74779.96it/s] 44%|     | 33196/75824 [00:00<00:00, 74934.39it/s] 58%|    | 44057/75824 [00:00<00:00, 82618.38it/s] 73%|  | 55376/75824 [00:00<00:00, 89901.57it/s] 88%| | 66721/75824 [00:00<00:00, 93854.08it/s]100%|| 75824/75824 [00:00<00:00, 92574.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9809/75824 [00:00<00:00, 98087.05it/s] 26%|       | 19885/75824 [00:00<00:00, 97796.10it/s] 39%|      | 29904/75824 [00:00<00:00, 98501.58it/s] 55%|    | 41997/75824 [00:00<00:00, 104304.22it/s] 71%|  | 54084/75824 [00:00<00:00, 108776.40it/s] 84%| | 63429/75824 [00:00<00:00, 102088.60it/s] 98%|| 74331/75824 [00:00<00:00, 104071.78it/s]100%|| 75824/75824 [00:00<00:00, 105126.47it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11502/75824 [00:00<00:00, 115015.45it/s] 27%|       | 20370/75824 [00:00<00:00, 105027.92it/s] 34%|      | 25406/75824 [00:00<00:00, 79043.27it/s]  49%|     | 36983/75824 [00:00<00:00, 87357.03it/s] 60%|    | 45228/75824 [00:00<00:00, 85823.48it/s] 69%|   | 52597/75824 [00:00<00:00, 74148.17it/s] 85%| | 64099/75824 [00:00<00:00, 82994.35it/s] 97%|| 73473/75824 [00:00<00:00, 85714.19it/s]100%|| 75824/75824 [00:00<00:00, 83508.58it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11831/75824 [00:00<00:00, 118307.57it/s] 24%|       | 18025/75824 [00:00<00:00, 92466.14it/s]  32%|      | 24581/75824 [00:00<00:00, 82327.04it/s] 45%|     | 34124/75824 [00:00<00:00, 85595.64it/s] 53%|    | 40449/75824 [00:00<00:00, 69156.77it/s] 61%|   | 46482/75824 [00:00<00:00, 66247.77it/s] 69%|   | 52394/75824 [00:00<00:00, 63862.23it/s] 83%| | 63062/75824 [00:00<00:00, 72604.34it/s] 93%|| 70397/75824 [00:00<00:00, 70546.47it/s]100%|| 75824/75824 [00:01<00:00, 68655.07it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8350/75824 [00:00<00:00, 80607.53it/s] 26%|       | 19566/75824 [00:00<00:00, 88037.17it/s] 41%|      | 30924/75824 [00:00<00:00, 94404.78it/s] 56%|    | 42393/75824 [00:00<00:00, 99692.72it/s] 71%|   | 53842/75824 [00:00<00:00, 103712.16it/s] 85%| | 64677/75824 [00:00<00:00, 105058.76it/s]100%|| 75824/75824 [00:00<00:00, 108532.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10299/75824 [00:00<00:00, 102985.92it/s] 23%|       | 17572/75824 [00:00<00:00, 91558.78it/s]  31%|       | 23183/75824 [00:00<00:00, 76970.31it/s] 38%|      | 28788/75824 [00:00<00:00, 67598.98it/s] 47%|     | 35959/75824 [00:00<00:00, 68780.34it/s] 61%|    | 46145/75824 [00:00<00:00, 76204.42it/s] 70%|   | 53101/75824 [00:00<00:00, 73319.74it/s] 79%|  | 59992/75824 [00:00<00:00, 67850.32it/s] 88%| | 66549/75824 [00:00<00:00, 61716.47it/s]100%|| 75824/75824 [00:01<00:00, 72078.17it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11123/75824 [00:00<00:00, 111226.13it/s] 24%|       | 18289/75824 [00:00<00:00, 95418.60it/s]  39%|      | 29765/75824 [00:00<00:00, 100499.85it/s] 49%|     | 37386/75824 [00:00<00:00, 91727.94it/s]  65%|   | 48944/75824 [00:00<00:00, 97780.08it/s] 75%|  | 57238/75824 [00:00<00:00, 90396.05it/s] 91%| | 68861/75824 [00:00<00:00, 94119.39it/s]100%|| 75824/75824 [00:00<00:00, 94598.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9516/75824 [00:00<00:00, 95151.47it/s] 18%|        | 13898/75824 [00:00<00:00, 65742.08it/s] 29%|       | 22046/75824 [00:00<00:00, 67491.56it/s] 38%|      | 28839/75824 [00:00<00:00, 67077.90it/s] 53%|    | 40151/75824 [00:00<00:00, 76123.98it/s] 64%|   | 48475/75824 [00:00<00:00, 78126.39it/s] 77%|  | 58375/75824 [00:00<00:00, 83139.30it/s] 89%| | 67541/75824 [00:00<00:00, 85524.19it/s]100%|| 75824/75824 [00:00<00:00, 83956.24it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12062/75824 [00:00<00:00, 120616.38it/s] 31%|      | 23849/75824 [00:00<00:00, 115951.73it/s] 40%|      | 30080/75824 [00:00<00:00, 90564.76it/s]  55%|    | 41562/75824 [00:00<00:00, 96691.91it/s] 68%|   | 51476/75824 [00:00<00:00, 97411.73it/s] 84%| | 63544/75824 [00:00<00:00, 103392.20it/s] 96%|| 72926/75824 [00:00<00:00, 92662.67it/s] 100%|| 75824/75824 [00:00<00:00, 99110.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 13239/75824 [00:00<00:00, 132385.71it/s] 33%|      | 24903/75824 [00:00<00:00, 127230.75it/s] 48%|     | 36032/75824 [00:00<00:00, 121985.87it/s] 63%|   | 47857/75824 [00:00<00:00, 120838.73it/s] 79%|  | 59706/75824 [00:00<00:00, 120121.64it/s] 93%|| 70829/75824 [00:00<00:00, 117308.06it/s]100%|| 75824/75824 [00:00<00:00, 118040.74it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10639/75824 [00:00<00:00, 106383.00it/s] 24%|       | 18493/75824 [00:00<00:00, 96153.88it/s]  40%|      | 30089/75824 [00:00<00:00, 101344.94it/s] 56%|    | 42520/75824 [00:00<00:00, 107289.61it/s] 73%|  | 54980/75824 [00:00<00:00, 111953.82it/s] 85%| | 64607/75824 [00:00<00:00, 105920.18it/s]100%|| 75824/75824 [00:00<00:00, 108019.01it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11966/75824 [00:00<00:00, 119659.26it/s] 25%|       | 19098/75824 [00:00<00:00, 96534.19it/s]  35%|      | 26720/75824 [00:00<00:00, 89386.64it/s] 50%|     | 38077/75824 [00:00<00:00, 95486.19it/s] 66%|   | 49993/75824 [00:00<00:00, 101536.88it/s] 78%|  | 59384/75824 [00:00<00:00, 99121.79it/s]  95%|| 71870/75824 [00:00<00:00, 105653.81it/s]100%|| 75824/75824 [00:00<00:00, 102601.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9815/75824 [00:00<00:00, 98145.41it/s] 24%|       | 18139/75824 [00:00<00:00, 87357.10it/s] 33%|      | 24797/75824 [00:00<00:00, 79876.57it/s] 48%|     | 36756/75824 [00:00<00:00, 88713.99it/s] 62%|   | 46928/75824 [00:00<00:00, 92251.11it/s] 73%|  | 55431/75824 [00:00<00:00, 89956.57it/s] 95%|| 72128/75824 [00:00<00:00, 104402.71it/s]100%|| 75824/75824 [00:00<00:00, 102776.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19121/75824 [00:00<00:00, 191207.45it/s] 52%|    | 39394/75824 [00:00<00:00, 194523.02it/s] 70%|   | 53352/75824 [00:00<00:00, 173973.17it/s] 94%|| 70959/75824 [00:00<00:00, 174595.27it/s]100%|| 75824/75824 [00:00<00:00, 179230.79it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 20032/75824 [00:00<00:00, 200315.42it/s] 54%|    | 41198/75824 [00:00<00:00, 203586.69it/s] 82%| | 62409/75824 [00:00<00:00, 206070.22it/s]100%|| 75824/75824 [00:00<00:00, 200545.02it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 15424/75824 [00:00<00:00, 154235.37it/s] 48%|     | 36457/75824 [00:00<00:00, 167648.14it/s] 76%|  | 57823/75824 [00:00<00:00, 179225.26it/s]100%|| 75824/75824 [00:00<00:00, 198005.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 22%|       | 16443/75824 [00:00<00:00, 164421.53it/s] 47%|     | 36008/75824 [00:00<00:00, 172689.64it/s] 75%|  | 57166/75824 [00:00<00:00, 182766.89it/s]100%|| 75824/75824 [00:00<00:00, 195299.79it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19683/75824 [00:00<00:00, 196827.37it/s] 51%|     | 38345/75824 [00:00<00:00, 193648.43it/s] 75%|  | 56958/75824 [00:00<00:00, 191327.13it/s]100%|| 75824/75824 [00:00<00:00, 190963.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19334/75824 [00:00<00:00, 193336.50it/s] 53%|    | 39912/75824 [00:00<00:00, 196906.78it/s] 80%|  | 60379/75824 [00:00<00:00, 199171.59it/s]100%|| 75824/75824 [00:00<00:00, 197552.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11931/75824 [00:00<00:00, 119304.14it/s] 32%|      | 24300/75824 [00:00<00:00, 120586.84it/s] 52%|    | 39231/75824 [00:00<00:00, 127970.27it/s] 71%|   | 53882/75824 [00:00<00:00, 133018.81it/s] 90%| | 68108/75824 [00:00<00:00, 135662.36it/s]100%|| 75824/75824 [00:00<00:00, 139200.21it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14617/75824 [00:00<00:00, 146163.17it/s] 39%|      | 29943/75824 [00:00<00:00, 148220.74it/s] 59%|    | 45053/75824 [00:00<00:00, 149070.97it/s] 77%|  | 58474/75824 [00:00<00:00, 144276.16it/s] 95%|| 72300/75824 [00:00<00:00, 142413.73it/s]100%|| 75824/75824 [00:00<00:00, 145064.21it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14574/75824 [00:00<00:00, 145739.79it/s] 39%|      | 29485/75824 [00:00<00:00, 146732.41it/s] 58%|    | 44196/75824 [00:00<00:00, 146845.11it/s] 77%|  | 58445/75824 [00:00<00:00, 145510.39it/s] 92%|| 69501/75824 [00:00<00:00, 132110.16it/s]100%|| 75824/75824 [00:00<00:00, 141578.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18385/75824 [00:00<00:00, 183844.04it/s] 51%|     | 38429/75824 [00:00<00:00, 188524.30it/s] 78%|  | 59120/75824 [00:00<00:00, 193685.90it/s]100%|| 75824/75824 [00:00<00:00, 199502.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6649/75824 [00:00<00:01, 64414.93it/s] 34%|      | 25589/75824 [00:00<00:00, 80314.63it/s] 59%|    | 45070/75824 [00:00<00:00, 97506.64it/s] 76%|  | 57935/75824 [00:00<00:00, 105141.73it/s]100%|| 75824/75824 [00:00<00:00, 151708.04it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 15460/75824 [00:00<00:00, 154593.14it/s] 34%|      | 25446/75824 [00:00<00:00, 132759.87it/s] 58%|    | 44274/75824 [00:00<00:00, 145642.99it/s] 84%| | 63468/75824 [00:00<00:00, 157001.53it/s]100%|| 75824/75824 [00:00<00:00, 152236.36it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|        | 15977/75824 [00:00<00:00, 159765.96it/s] 47%|     | 35908/75824 [00:00<00:00, 169876.72it/s] 66%|   | 50136/75824 [00:00<00:00, 160531.62it/s] 83%| | 63038/75824 [00:00<00:00, 149570.92it/s]100%|| 75824/75824 [00:00<00:00, 163694.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14717/75824 [00:00<00:00, 147168.74it/s] 40%|      | 30267/75824 [00:00<00:00, 149571.45it/s] 60%|    | 45862/75824 [00:00<00:00, 151429.38it/s] 81%|  | 61536/75824 [00:00<00:00, 152984.11it/s]100%|| 75824/75824 [00:00<00:00, 159560.71it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14268/75824 [00:00<00:00, 142679.12it/s] 39%|      | 29647/75824 [00:00<00:00, 145838.93it/s] 60%|    | 45134/75824 [00:00<00:00, 148433.28it/s] 79%|  | 60062/75824 [00:00<00:00, 148683.89it/s]100%|| 75578/75824 [00:00<00:00, 150566.78it/s]100%|| 75824/75824 [00:00<00:00, 151082.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14486/75824 [00:00<00:00, 144859.79it/s] 39%|      | 29315/75824 [00:00<00:00, 145872.01it/s] 58%|    | 43801/75824 [00:00<00:00, 145564.98it/s] 78%|  | 58834/75824 [00:00<00:00, 146960.86it/s] 97%|| 73901/75824 [00:00<00:00, 148052.97it/s]100%|| 75824/75824 [00:00<00:00, 147999.03it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 18%|        | 13508/75824 [00:00<00:00, 135074.65it/s] 37%|      | 28293/75824 [00:00<00:00, 138667.73it/s] 57%|    | 43206/75824 [00:00<00:00, 141648.42it/s] 77%|  | 58232/75824 [00:00<00:00, 144125.19it/s] 93%|| 70532/75824 [00:00<00:00, 137059.91it/s]100%|| 75824/75824 [00:00<00:00, 141906.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18753/75824 [00:00<00:00, 187520.79it/s] 51%|     | 38498/75824 [00:00<00:00, 190392.36it/s] 76%|  | 57575/75824 [00:00<00:00, 190503.10it/s] 95%|| 71827/75824 [00:00<00:00, 173026.19it/s]100%|| 75824/75824 [00:00<00:00, 177239.16it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 19%|        | 14130/75824 [00:00<00:00, 141299.12it/s] 33%|      | 24923/75824 [00:00<00:00, 129302.13it/s] 52%|    | 39189/75824 [00:00<00:00, 133039.10it/s] 77%|  | 58119/75824 [00:00<00:00, 146061.45it/s]100%|| 75824/75824 [00:00<00:00, 156189.68it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 20%|        | 14830/75824 [00:00<00:00, 148288.83it/s] 38%|      | 29187/75824 [00:00<00:00, 146838.50it/s] 59%|    | 44705/75824 [00:00<00:00, 149244.77it/s] 79%|  | 60218/75824 [00:00<00:00, 150960.33it/s]100%|| 75567/75824 [00:00<00:00, 151708.65it/s]100%|| 75824/75824 [00:00<00:00, 151038.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18216/75824 [00:00<00:00, 182148.88it/s] 49%|     | 37505/75824 [00:00<00:00, 185242.38it/s] 75%|  | 56855/75824 [00:00<00:00, 187641.77it/s]100%|| 75824/75824 [00:00<00:00, 190577.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18432/75824 [00:00<00:00, 184316.66it/s] 45%|     | 33780/75824 [00:00<00:00, 173836.92it/s] 58%|    | 44294/75824 [00:00<00:00, 140693.11it/s] 70%|   | 53148/75824 [00:00<00:00, 87923.95it/s]  80%|  | 60753/75824 [00:00<00:00, 77976.11it/s] 90%| | 67927/75824 [00:00<00:00, 74620.49it/s]100%|| 75824/75824 [00:00<00:00, 95911.70it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12247/75824 [00:00<00:00, 122469.53it/s] 32%|      | 24551/75824 [00:00<00:00, 122638.05it/s] 50%|     | 37704/75824 [00:00<00:00, 125174.78it/s] 61%|    | 46034/75824 [00:00<00:00, 71456.76it/s]  74%|  | 56255/75824 [00:00<00:00, 78545.45it/s] 91%|| 69334/75824 [00:00<00:00, 89239.37it/s]100%|| 75824/75824 [00:00<00:00, 96875.21it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10096/75824 [00:00<00:00, 100954.08it/s] 24%|       | 18527/75824 [00:00<00:00, 95306.75it/s]  36%|      | 27171/75824 [00:00<00:00, 92301.44it/s] 47%|     | 35662/75824 [00:00<00:00, 89870.70it/s] 58%|    | 44147/75824 [00:00<00:00, 88301.44it/s] 74%|  | 55822/75824 [00:00<00:00, 95263.60it/s] 89%| | 67253/75824 [00:00<00:00, 100273.65it/s]100%|| 75824/75824 [00:00<00:00, 98534.36it/s] 
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11650/75824 [00:00<00:00, 116494.28it/s] 30%|       | 23089/75824 [00:00<00:00, 115852.34it/s] 46%|     | 34954/75824 [00:00<00:00, 116676.57it/s] 62%|   | 46998/75824 [00:00<00:00, 117780.13it/s] 78%|  | 59000/75824 [00:00<00:00, 118441.62it/s] 94%|| 70985/75824 [00:00<00:00, 118859.67it/s]100%|| 75824/75824 [00:00<00:00, 118470.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11360/75824 [00:00<00:00, 113590.63it/s] 28%|       | 21433/75824 [00:00<00:00, 109399.28it/s] 36%|      | 27455/75824 [00:00<00:00, 87869.70it/s]  50%|     | 37636/75824 [00:00<00:00, 91491.15it/s] 60%|    | 45166/75824 [00:00<00:00, 85945.91it/s] 74%|  | 56166/75824 [00:00<00:00, 91978.96it/s] 85%| | 64454/75824 [00:00<00:00, 87242.61it/s]100%|| 75824/75824 [00:00<00:00, 94547.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12105/75824 [00:00<00:00, 121043.48it/s] 31%|       | 23336/75824 [00:00<00:00, 118283.66it/s] 43%|     | 32965/75824 [00:00<00:00, 110697.20it/s] 56%|    | 42147/75824 [00:00<00:00, 98754.13it/s]  66%|   | 50236/75824 [00:00<00:00, 92615.63it/s] 76%|  | 57763/75824 [00:00<00:00, 78443.48it/s] 85%| | 64766/75824 [00:00<00:00, 64933.42it/s] 94%|| 71058/75824 [00:00<00:00, 56153.46it/s]100%|| 75824/75824 [00:01<00:00, 74177.17it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12017/75824 [00:00<00:00, 120164.67it/s] 28%|       | 20891/75824 [00:00<00:00, 108623.87it/s] 44%|     | 33003/75824 [00:00<00:00, 112092.24it/s] 59%|    | 45095/75824 [00:00<00:00, 114601.53it/s] 74%|  | 56268/75824 [00:00<00:00, 113722.82it/s] 89%| | 67547/75824 [00:00<00:00, 113439.68it/s]100%|| 75824/75824 [00:00<00:00, 113089.57it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11779/75824 [00:00<00:00, 117785.06it/s] 31%|       | 23543/75824 [00:00<00:00, 117739.09it/s] 47%|     | 35564/75824 [00:00<00:00, 118468.00it/s] 63%|   | 47546/75824 [00:00<00:00, 118868.14it/s] 78%|  | 59402/75824 [00:00<00:00, 118774.46it/s] 94%|| 71394/75824 [00:00<00:00, 119113.73it/s]100%|| 75824/75824 [00:00<00:00, 119153.77it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12138/75824 [00:00<00:00, 121370.28it/s] 32%|      | 24582/75824 [00:00<00:00, 122272.29it/s] 47%|     | 35505/75824 [00:00<00:00, 118040.63it/s] 64%|   | 48752/75824 [00:00<00:00, 122026.65it/s] 79%|  | 60074/75824 [00:00<00:00, 119241.07it/s] 92%|| 70013/75824 [00:00<00:00, 108273.77it/s]100%|| 75824/75824 [00:00<00:00, 115900.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9501/75824 [00:00<00:00, 95004.65it/s] 27%|       | 20372/75824 [00:00<00:00, 98737.76it/s] 41%|     | 31423/75824 [00:00<00:00, 101996.94it/s] 53%|    | 39937/75824 [00:00<00:00, 96275.19it/s]  70%|   | 52885/75824 [00:00<00:00, 104298.69it/s] 85%| | 64444/75824 [00:00<00:00, 107447.28it/s]100%|| 75824/75824 [00:00<00:00, 108962.52it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8816/75824 [00:00<00:00, 88157.35it/s] 24%|       | 18501/75824 [00:00<00:00, 90596.61it/s] 37%|      | 27770/75824 [00:00<00:00, 91213.50it/s] 46%|     | 34599/75824 [00:00<00:00, 82866.23it/s] 60%|    | 45227/75824 [00:00<00:00, 88729.09it/s] 76%|  | 57727/75824 [00:00<00:00, 97188.07it/s] 93%|| 70269/75824 [00:00<00:00, 104224.74it/s]100%|| 75824/75824 [00:00<00:00, 101871.22it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9678/75824 [00:00<00:00, 94975.82it/s] 24%|       | 18202/75824 [00:00<00:00, 91827.55it/s] 35%|      | 26845/75824 [00:00<00:00, 90137.01it/s] 47%|     | 35414/75824 [00:00<00:00, 88754.29it/s] 59%|    | 44795/75824 [00:00<00:00, 90212.68it/s] 71%|  | 54200/75824 [00:00<00:00, 91329.86it/s] 85%| | 64443/75824 [00:00<00:00, 94397.15it/s]100%|| 75824/75824 [00:00<00:00, 95280.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11908/75824 [00:00<00:00, 119072.16it/s] 31%|      | 23857/75824 [00:00<00:00, 119195.03it/s] 47%|     | 35852/75824 [00:00<00:00, 119418.69it/s] 63%|   | 47831/75824 [00:00<00:00, 119528.85it/s] 79%|  | 60042/75824 [00:00<00:00, 120289.83it/s] 95%|| 72181/75824 [00:00<00:00, 120615.59it/s]100%|| 75824/75824 [00:00<00:00, 120304.59it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8880/75824 [00:00<00:00, 88796.49it/s] 28%|       | 20943/75824 [00:00<00:00, 94030.73it/s] 36%|      | 27276/75824 [00:00<00:00, 82091.50it/s] 43%|     | 32771/75824 [00:00<00:00, 69856.06it/s] 50%|     | 38233/75824 [00:00<00:00, 59304.64it/s] 57%|    | 43330/75824 [00:00<00:00, 54639.54it/s] 72%|  | 54679/75824 [00:00<00:00, 64704.74it/s] 83%| | 63285/75824 [00:00<00:00, 69908.51it/s] 93%|| 70677/75824 [00:00<00:00, 63763.12it/s]100%|| 75824/75824 [00:01<00:00, 70413.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7555/75824 [00:00<00:00, 75547.37it/s] 18%|        | 13603/75824 [00:00<00:00, 70291.96it/s] 27%|       | 20169/75824 [00:00<00:00, 68834.89it/s] 35%|      | 26844/75824 [00:00<00:00, 65380.32it/s] 44%|     | 33333/75824 [00:00<00:00, 65230.87it/s] 56%|    | 42527/75824 [00:00<00:00, 71362.20it/s] 69%|   | 52369/75824 [00:00<00:00, 76826.72it/s] 79%|  | 59696/75824 [00:00<00:00, 73898.00it/s] 89%| | 67761/75824 [00:00<00:00, 75800.42it/s]100%|| 75824/75824 [00:01<00:00, 75787.63it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6844/75824 [00:00<00:01, 68438.27it/s] 13%|        | 10081/75824 [00:00<00:01, 47540.94it/s] 20%|        | 14913/75824 [00:00<00:01, 47485.53it/s] 34%|      | 25521/75824 [00:00<00:00, 56916.82it/s] 45%|     | 34276/75824 [00:00<00:00, 63591.75it/s] 60%|    | 45720/75824 [00:00<00:00, 73371.88it/s] 76%|  | 57753/75824 [00:00<00:00, 83100.61it/s] 92%|| 69811/75824 [00:00<00:00, 91645.56it/s]100%|| 75824/75824 [00:00<00:00, 84289.54it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7209/75824 [00:00<00:00, 70784.68it/s] 25%|       | 18976/75824 [00:00<00:00, 80393.58it/s] 34%|      | 25697/75824 [00:00<00:00, 75182.64it/s] 48%|     | 36279/75824 [00:00<00:00, 82333.20it/s] 58%|    | 43975/75824 [00:00<00:00, 80643.37it/s] 72%|  | 54597/75824 [00:00<00:00, 86921.87it/s] 88%| | 66353/75824 [00:00<00:00, 94111.81it/s]100%|| 75824/75824 [00:00<00:00, 96956.43it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11806/75824 [00:00<00:00, 118056.45it/s] 29%|       | 21675/75824 [00:00<00:00, 107270.69it/s] 42%|     | 31770/75824 [00:00<00:00, 105291.13it/s] 57%|    | 43383/75824 [00:00<00:00, 108322.67it/s] 72%|  | 54799/75824 [00:00<00:00, 110009.41it/s] 87%| | 66325/75824 [00:00<00:00, 111532.15it/s]100%|| 75824/75824 [00:00<00:00, 109208.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4662/75824 [00:00<00:01, 46619.49it/s] 17%|        | 12563/75824 [00:00<00:01, 53156.94it/s] 32%|      | 24083/75824 [00:00<00:00, 63400.54it/s] 47%|     | 35510/75824 [00:00<00:00, 73172.50it/s] 62%|   | 47253/75824 [00:00<00:00, 82499.66it/s] 78%|  | 59091/75824 [00:00<00:00, 90750.33it/s] 94%|| 71072/75824 [00:00<00:00, 97870.91it/s]100%|| 75824/75824 [00:00<00:00, 102430.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9012/75824 [00:00<00:00, 90118.80it/s] 25%|       | 18786/75824 [00:00<00:00, 92276.34it/s] 40%|      | 30694/75824 [00:00<00:00, 98958.32it/s] 56%|    | 42652/75824 [00:00<00:00, 104355.61it/s] 72%|  | 54635/75824 [00:00<00:00, 108558.93it/s] 88%| | 66619/75824 [00:00<00:00, 111713.50it/s]100%|| 75824/75824 [00:00<00:00, 111182.05it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11766/75824 [00:00<00:00, 117659.55it/s] 31%|      | 23774/75824 [00:00<00:00, 118374.33it/s] 46%|     | 35122/75824 [00:00<00:00, 116860.41it/s] 62%|   | 47086/75824 [00:00<00:00, 117679.25it/s] 78%|  | 59170/75824 [00:00<00:00, 118609.10it/s] 93%|| 70536/75824 [00:00<00:00, 117079.56it/s]100%|| 75824/75824 [00:00<00:00, 117690.15it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11486/75824 [00:00<00:00, 114859.01it/s] 27%|       | 20727/75824 [00:00<00:00, 106492.77it/s] 37%|      | 28027/75824 [00:00<00:00, 93605.74it/s]  51%|    | 39009/75824 [00:00<00:00, 97942.40it/s] 67%|   | 50587/75824 [00:00<00:00, 102687.26it/s] 81%| | 61753/75824 [00:00<00:00, 105222.32it/s] 97%|| 73469/75824 [00:00<00:00, 108538.15it/s]100%|| 75824/75824 [00:00<00:00, 104438.26it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11630/75824 [00:00<00:00, 116292.07it/s] 24%|       | 18012/75824 [00:00<00:00, 89721.60it/s]  34%|      | 25876/75824 [00:00<00:00, 85907.37it/s] 47%|     | 35869/75824 [00:00<00:00, 89682.57it/s] 60%|    | 45339/75824 [00:00<00:00, 90081.63it/s] 70%|   | 53024/75824 [00:00<00:00, 84878.00it/s] 80%|  | 61000/75824 [00:00<00:00, 83274.40it/s] 95%|| 72267/75824 [00:00<00:00, 90344.59it/s]100%|| 75824/75824 [00:00<00:00, 89659.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11329/75824 [00:00<00:00, 113279.84it/s] 32%|      | 23977/75824 [00:00<00:00, 116940.34it/s] 46%|     | 34857/75824 [00:00<00:00, 114369.82it/s] 61%|    | 45953/75824 [00:00<00:00, 113323.45it/s] 76%|  | 57466/75824 [00:00<00:00, 113858.90it/s] 88%| | 66967/75824 [00:00<00:00, 97218.22it/s] 100%|| 75824/75824 [00:00<00:00, 106907.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7530/75824 [00:00<00:00, 74855.50it/s] 19%|        | 14113/75824 [00:00<00:00, 71897.89it/s] 35%|      | 26579/75824 [00:00<00:00, 82354.55it/s] 51%|     | 38642/75824 [00:00<00:00, 91017.54it/s] 66%|   | 50318/75824 [00:00<00:00, 97462.16it/s] 82%| | 62472/75824 [00:00<00:00, 103619.67it/s] 98%|| 74656/75824 [00:00<00:00, 108486.66it/s]100%|| 75824/75824 [00:00<00:00, 106720.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6616/75824 [00:00<00:01, 66157.85it/s] 17%|        | 12707/75824 [00:00<00:01, 63094.91it/s] 26%|       | 19829/75824 [00:00<00:00, 65330.72it/s] 42%|     | 31725/75824 [00:00<00:00, 75548.25it/s] 53%|    | 40409/75824 [00:00<00:00, 78613.52it/s] 69%|   | 52300/75824 [00:00<00:00, 87509.09it/s] 85%| | 64260/75824 [00:00<00:00, 95169.54it/s]100%|| 75824/75824 [00:00<00:00, 94482.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  4%|         | 2873/75824 [00:00<00:02, 28075.71it/s] 18%|        | 13378/75824 [00:00<00:01, 35985.94it/s] 33%|      | 25290/75824 [00:00<00:01, 45515.20it/s] 42%|     | 31482/75824 [00:00<00:00, 46731.10it/s] 49%|     | 37312/75824 [00:00<00:00, 47928.27it/s] 61%|    | 46341/75824 [00:00<00:00, 55777.35it/s] 72%|  | 54887/75824 [00:00<00:00, 62265.24it/s] 83%| | 63260/75824 [00:00<00:00, 67452.51it/s] 98%|| 74350/75824 [00:00<00:00, 76435.92it/s]100%|| 75824/75824 [00:00<00:00, 79505.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10292/75824 [00:00<00:00, 102912.98it/s] 22%|       | 16473/75824 [00:00<00:00, 85538.91it/s]  29%|       | 22180/75824 [00:00<00:00, 74403.68it/s] 45%|     | 34016/75824 [00:00<00:00, 83732.09it/s] 61%|    | 45984/75824 [00:00<00:00, 92023.68it/s] 72%|  | 54272/75824 [00:00<00:00, 71585.22it/s] 81%|  | 61488/75824 [00:00<00:00, 68730.90it/s] 90%| | 68426/75824 [00:00<00:00, 64797.89it/s]100%|| 75824/75824 [00:01<00:00, 75587.81it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10994/75824 [00:00<00:00, 109933.81it/s] 30%|       | 22879/75824 [00:00<00:00, 112463.93it/s] 46%|     | 34873/75824 [00:00<00:00, 114604.79it/s] 62%|   | 47381/75824 [00:00<00:00, 117556.27it/s] 79%|  | 59768/75824 [00:00<00:00, 119380.23it/s] 95%|| 72213/75824 [00:00<00:00, 120855.27it/s]100%|| 75824/75824 [00:00<00:00, 120470.83it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 9222/75824 [00:00<00:00, 92219.65it/s] 25%|       | 19095/75824 [00:00<00:00, 94078.43it/s] 37%|      | 28385/75824 [00:00<00:00, 93720.99it/s] 53%|    | 40304/75824 [00:00<00:00, 100139.28it/s] 69%|   | 52440/75824 [00:00<00:00, 105681.91it/s] 85%| | 64511/75824 [00:00<00:00, 109781.86it/s]100%|| 75824/75824 [00:00<00:00, 108689.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5491/75824 [00:00<00:01, 47019.25it/s] 15%|        | 11541/75824 [00:00<00:01, 50386.75it/s] 21%|        | 15959/75824 [00:00<00:01, 48347.86it/s] 28%|       | 21373/75824 [00:00<00:01, 49378.02it/s] 38%|      | 28993/75824 [00:00<00:00, 55207.24it/s] 52%|    | 39173/75824 [00:00<00:00, 63993.84it/s] 68%|   | 51640/75824 [00:00<00:00, 74934.23it/s] 85%| | 64510/75824 [00:00<00:00, 85670.08it/s]100%|| 75824/75824 [00:00<00:00, 83747.82it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10961/75824 [00:00<00:00, 109604.62it/s] 30%|       | 22510/75824 [00:00<00:00, 111304.38it/s] 44%|     | 33545/75824 [00:00<00:00, 111014.77it/s] 58%|    | 43609/75824 [00:00<00:00, 107681.79it/s] 72%|  | 54948/75824 [00:00<00:00, 109330.90it/s] 88%| | 66999/75824 [00:00<00:00, 112458.70it/s]100%|| 75824/75824 [00:00<00:00, 112565.81it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6533/75824 [00:00<00:01, 62503.74it/s] 24%|       | 18473/75824 [00:00<00:00, 72928.89it/s] 36%|      | 27457/75824 [00:00<00:00, 76282.34it/s] 48%|     | 36635/75824 [00:00<00:00, 80351.23it/s] 61%|    | 46272/75824 [00:00<00:00, 84568.16it/s] 71%|  | 54045/75824 [00:00<00:00, 82391.84it/s] 83%| | 62613/75824 [00:00<00:00, 83102.75it/s] 95%|| 71927/75824 [00:00<00:00, 85878.87it/s]100%|| 75824/75824 [00:00<00:00, 90015.17it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 12%|        | 8934/75824 [00:00<00:00, 84261.83it/s] 21%|        | 15749/75824 [00:00<00:00, 78680.27it/s] 36%|      | 27139/75824 [00:00<00:00, 86723.60it/s] 53%|    | 39869/75824 [00:00<00:00, 95892.59it/s] 68%|   | 51577/75824 [00:00<00:00, 101395.11it/s] 83%| | 63100/75824 [00:00<00:00, 105182.24it/s] 99%|| 74803/75824 [00:00<00:00, 108475.24it/s]100%|| 75824/75824 [00:00<00:00, 106015.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11544/75824 [00:00<00:00, 115433.50it/s] 31%|       | 23362/75824 [00:00<00:00, 116242.03it/s] 44%|     | 33453/75824 [00:00<00:00, 109844.86it/s] 53%|    | 40552/75824 [00:00<00:00, 89109.11it/s]  62%|   | 47378/75824 [00:00<00:00, 79146.22it/s] 71%|  | 54039/75824 [00:00<00:00, 72260.50it/s] 80%|  | 60504/75824 [00:00<00:00, 69527.90it/s] 88%| | 66946/75824 [00:00<00:00, 64368.30it/s]100%|| 75824/75824 [00:00<00:00, 81033.33it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 5590/75824 [00:00<00:01, 55332.52it/s] 20%|        | 15510/75824 [00:00<00:00, 63795.38it/s] 29%|       | 21713/75824 [00:00<00:00, 61812.51it/s] 43%|     | 32668/75824 [00:00<00:00, 71108.18it/s] 57%|    | 43074/75824 [00:00<00:00, 78572.08it/s] 70%|   | 53341/75824 [00:00<00:00, 84523.08it/s] 84%| | 63458/75824 [00:00<00:00, 88695.60it/s] 96%|| 72729/75824 [00:00<00:00, 87064.38it/s]100%|| 75824/75824 [00:00<00:00, 88551.28it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12094/75824 [00:00<00:00, 120932.91it/s] 32%|      | 23990/75824 [00:00<00:00, 120332.58it/s] 47%|     | 35876/75824 [00:00<00:00, 119885.90it/s] 63%|   | 47898/75824 [00:00<00:00, 119985.45it/s] 79%|  | 59912/75824 [00:00<00:00, 120029.58it/s] 95%|| 71941/75824 [00:00<00:00, 120104.88it/s]100%|| 75824/75824 [00:00<00:00, 119889.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9809/75824 [00:00<00:00, 98082.38it/s] 23%|       | 17305/75824 [00:00<00:00, 89772.76it/s] 32%|      | 24135/75824 [00:00<00:00, 78840.18it/s] 41%|      | 30749/75824 [00:00<00:00, 72593.63it/s] 48%|     | 36640/75824 [00:00<00:00, 66031.81it/s] 57%|    | 42967/75824 [00:00<00:00, 64878.66it/s] 66%|   | 49824/75824 [00:00<00:00, 65942.85it/s] 74%|  | 55789/75824 [00:00<00:00, 61994.62it/s] 82%| | 61889/75824 [00:00<00:00, 60083.42it/s] 90%| | 68183/75824 [00:01<00:00, 59532.74it/s] 98%|| 74630/75824 [00:01<00:00, 60931.92it/s]100%|| 75824/75824 [00:01<00:00, 64369.62it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 5720/75824 [00:00<00:01, 57199.92it/s] 15%|        | 11702/75824 [00:00<00:01, 57960.66it/s] 21%|       | 16116/75824 [00:00<00:01, 52983.35it/s] 33%|      | 25096/75824 [00:00<00:00, 60413.78it/s] 41%|      | 31085/75824 [00:00<00:00, 60255.44it/s] 48%|     | 36444/75824 [00:00<00:00, 57042.79it/s] 57%|    | 43137/75824 [00:00<00:00, 59687.33it/s] 70%|   | 53042/75824 [00:00<00:00, 67765.91it/s] 83%| | 62949/75824 [00:00<00:00, 74861.86it/s] 97%|| 73577/75824 [00:01<00:00, 81991.61it/s]100%|| 75824/75824 [00:01<00:00, 72730.14it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 7102/75824 [00:00<00:01, 66890.20it/s] 17%|        | 12559/75824 [00:00<00:01, 62646.22it/s] 24%|       | 18151/75824 [00:00<00:00, 60463.32it/s] 32%|      | 23935/75824 [00:00<00:00, 59650.32it/s] 39%|      | 29593/75824 [00:00<00:00, 57273.98it/s] 45%|     | 34245/75824 [00:00<00:00, 47115.66it/s] 59%|    | 44643/75824 [00:00<00:00, 56362.43it/s] 69%|   | 51974/75824 [00:00<00:00, 59799.98it/s] 84%| | 63392/75824 [00:00<00:00, 69767.03it/s] 97%|| 73239/75824 [00:01<00:00, 76451.99it/s]100%|| 75824/75824 [00:01<00:00, 70175.51it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 7979/75824 [00:00<00:00, 79062.09it/s] 22%|       | 16628/75824 [00:00<00:00, 81151.46it/s] 35%|      | 26883/75824 [00:00<00:00, 86568.66it/s] 49%|     | 37182/75824 [00:00<00:00, 89616.89it/s] 64%|   | 48193/75824 [00:00<00:00, 94914.47it/s] 76%|  | 57877/75824 [00:00<00:00, 95483.60it/s] 89%| | 67612/75824 [00:00<00:00, 96031.79it/s]100%|| 75824/75824 [00:00<00:00, 93432.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10294/75824 [00:00<00:00, 102935.44it/s] 27%|       | 20445/75824 [00:00<00:00, 101161.02it/s] 41%|      | 30938/75824 [00:00<00:00, 102260.65it/s] 57%|    | 43034/75824 [00:00<00:00, 107233.02it/s] 73%|  | 55041/75824 [00:00<00:00, 110785.28it/s] 85%| | 64468/75824 [00:00<00:00, 102003.58it/s] 97%|| 73650/75824 [00:00<00:00, 89249.85it/s] 100%|| 75824/75824 [00:00<00:00, 99054.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 17%|        | 12751/75824 [00:00<00:00, 127500.09it/s] 28%|       | 21551/75824 [00:00<00:00, 111278.32it/s] 40%|      | 30071/75824 [00:00<00:00, 101919.24it/s] 51%|     | 38851/75824 [00:00<00:00, 96757.84it/s]  65%|   | 49037/75824 [00:00<00:00, 98108.42it/s] 76%|  | 57316/75824 [00:00<00:00, 92947.45it/s] 86%| | 65339/75824 [00:00<00:00, 79084.16it/s]100%|| 75824/75824 [00:00<00:00, 92238.17it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9530/75824 [00:00<00:00, 95293.27it/s] 29%|       | 22059/75824 [00:00<00:00, 102667.20it/s] 46%|     | 34865/75824 [00:00<00:00, 109159.42it/s] 63%|   | 47736/75824 [00:00<00:00, 114370.27it/s] 80%|  | 60560/75824 [00:00<00:00, 118203.15it/s] 94%|| 70968/75824 [00:00<00:00, 112477.12it/s]100%|| 75824/75824 [00:00<00:00, 117682.09it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7394/75824 [00:00<00:00, 73936.37it/s] 21%|       | 16191/75824 [00:00<00:00, 77384.04it/s] 33%|      | 24877/75824 [00:00<00:00, 80001.51it/s] 45%|     | 33831/75824 [00:00<00:00, 82640.69it/s] 60%|    | 45713/75824 [00:00<00:00, 90947.69it/s] 76%|  | 57659/75824 [00:00<00:00, 97960.77it/s] 92%|| 69696/75824 [00:00<00:00, 103754.87it/s]100%|| 75824/75824 [00:00<00:00, 100810.85it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8222/75824 [00:00<00:00, 82219.88it/s] 22%|       | 16555/75824 [00:00<00:00, 82549.59it/s] 36%|      | 27021/75824 [00:00<00:00, 88134.17it/s] 50%|     | 37927/75824 [00:00<00:00, 93516.75it/s] 65%|   | 48963/75824 [00:00<00:00, 98003.39it/s] 80%|  | 60500/75824 [00:00<00:00, 102637.15it/s] 95%|| 72288/75824 [00:00<00:00, 106778.37it/s]100%|| 75824/75824 [00:00<00:00, 103835.83it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11991/75824 [00:00<00:00, 119909.26it/s] 32%|      | 23956/75824 [00:00<00:00, 119830.97it/s] 45%|     | 33962/75824 [00:00<00:00, 110985.46it/s] 60%|    | 45442/75824 [00:00<00:00, 112102.89it/s] 75%|  | 56811/75824 [00:00<00:00, 109248.85it/s] 87%| | 65803/75824 [00:00<00:00, 95864.67it/s] 100%|| 75824/75824 [00:00<00:00, 104675.48it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11229/75824 [00:00<00:00, 112282.34it/s] 30%|       | 22739/75824 [00:00<00:00, 113113.00it/s] 45%|     | 34127/75824 [00:00<00:00, 113341.72it/s] 60%|    | 45398/75824 [00:00<00:00, 113148.57it/s] 75%|  | 56627/75824 [00:00<00:00, 112887.14it/s] 90%| | 67883/75824 [00:00<00:00, 112788.02it/s]100%|| 75824/75824 [00:00<00:00, 112962.80it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6972/75824 [00:00<00:00, 69716.41it/s] 17%|        | 13143/75824 [00:00<00:00, 67103.91it/s] 31%|       | 23462/75824 [00:00<00:00, 74968.39it/s] 46%|     | 35017/75824 [00:00<00:00, 83555.85it/s] 62%|   | 47135/75824 [00:00<00:00, 92137.67it/s] 78%|  | 59205/75824 [00:00<00:00, 99178.43it/s] 94%|| 71233/75824 [00:00<00:00, 104688.25it/s]100%|| 75824/75824 [00:00<00:00, 102585.30it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  3%|         | 2506/75824 [00:00<00:02, 24940.92it/s] 12%|        | 9428/75824 [00:00<00:02, 30863.75it/s] 30%|       | 22581/75824 [00:00<00:01, 40062.16it/s] 44%|     | 33370/75824 [00:00<00:00, 49373.86it/s] 58%|    | 44288/75824 [00:00<00:00, 59082.72it/s] 73%|  | 55530/75824 [00:00<00:00, 68887.05it/s] 88%| | 66777/75824 [00:00<00:00, 77947.78it/s]100%|| 75824/75824 [00:00<00:00, 90285.84it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10362/75824 [00:00<00:00, 102942.94it/s] 23%|       | 17403/75824 [00:00<00:00, 90409.37it/s]  38%|      | 29177/75824 [00:00<00:00, 97174.75it/s] 51%|     | 38432/75824 [00:00<00:00, 95739.18it/s] 61%|    | 46339/75824 [00:00<00:00, 90043.88it/s] 76%|  | 57469/75824 [00:00<00:00, 95514.61it/s] 87%| | 66067/75824 [00:00<00:00, 91394.63it/s] 98%|| 74577/75824 [00:00<00:00, 64166.71it/s]100%|| 75824/75824 [00:00<00:00, 80687.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4711/75824 [00:00<00:01, 47106.68it/s] 13%|        | 9642/75824 [00:00<00:01, 44413.21it/s] 18%|        | 13562/75824 [00:00<00:01, 42503.82it/s] 25%|       | 18838/75824 [00:00<00:01, 44700.06it/s] 33%|      | 25261/75824 [00:00<00:01, 49186.59it/s] 41%|      | 31027/75824 [00:00<00:00, 51453.89it/s] 47%|     | 35937/75824 [00:00<00:00, 50723.81it/s] 59%|    | 44736/75824 [00:00<00:00, 58106.30it/s] 74%|  | 56222/75824 [00:00<00:00, 68218.42it/s] 84%| | 63865/75824 [00:01<00:00, 70266.73it/s] 94%|| 71482/75824 [00:01<00:00, 70453.22it/s]100%|| 75824/75824 [00:01<00:00, 62371.17it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7391/75824 [00:00<00:00, 73909.72it/s] 18%|        | 13352/75824 [00:00<00:00, 67136.10it/s] 26%|       | 19356/75824 [00:00<00:00, 64835.25it/s] 31%|       | 23423/75824 [00:00<00:00, 55026.00it/s] 36%|      | 27478/75824 [00:00<00:01, 44380.02it/s] 42%|     | 31807/75824 [00:00<00:00, 44046.57it/s] 50%|     | 38107/75824 [00:00<00:00, 48415.84it/s] 62%|   | 46709/75824 [00:00<00:00, 54967.05it/s] 70%|   | 52808/75824 [00:00<00:00, 56355.32it/s] 77%|  | 58747/75824 [00:01<00:00, 56766.11it/s] 85%| | 64796/75824 [00:01<00:00, 57366.08it/s] 93%|| 70864/75824 [00:01<00:00, 58297.10it/s]100%|| 75824/75824 [00:01<00:00, 56686.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 5925/75824 [00:00<00:01, 59249.35it/s] 11%|        | 8708/75824 [00:00<00:01, 42324.29it/s] 19%|        | 14161/75824 [00:00<00:01, 45130.31it/s] 30%|       | 22446/75824 [00:00<00:01, 52268.73it/s] 42%|     | 31641/75824 [00:00<00:00, 60041.72it/s] 58%|    | 44024/75824 [00:00<00:00, 71015.98it/s] 74%|  | 55743/75824 [00:00<00:00, 80534.35it/s] 89%| | 67171/75824 [00:00<00:00, 88361.83it/s]100%|| 75824/75824 [00:00<00:00, 85620.81it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10059/75824 [00:00<00:00, 100588.18it/s] 26%|       | 19468/75824 [00:00<00:00, 98544.28it/s]  44%|     | 33197/75824 [00:00<00:00, 107658.00it/s] 57%|    | 42875/75824 [00:00<00:00, 104144.40it/s] 67%|   | 51080/75824 [00:00<00:00, 71596.89it/s]  77%|  | 58066/75824 [00:00<00:00, 59996.20it/s] 85%| | 64262/75824 [00:00<00:00, 59098.36it/s] 95%|| 72043/75824 [00:00<00:00, 63692.29it/s]100%|| 75824/75824 [00:00<00:00, 75856.92it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 10023/75824 [00:00<00:00, 100227.94it/s] 27%|       | 20422/75824 [00:00<00:00, 97993.95it/s]  41%|      | 30954/75824 [00:00<00:00, 100081.81it/s] 57%|    | 42969/75824 [00:00<00:00, 105360.07it/s] 71%|   | 54017/75824 [00:00<00:00, 106844.89it/s] 83%| | 63083/75824 [00:00<00:00, 97972.33it/s]  99%|| 75155/75824 [00:00<00:00, 103841.62it/s]100%|| 75824/75824 [00:00<00:00, 104159.93it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 11%|         | 8063/75824 [00:00<00:00, 80628.15it/s] 24%|       | 18155/75824 [00:00<00:00, 85802.98it/s] 39%|      | 29907/75824 [00:00<00:00, 93360.60it/s] 55%|    | 41747/75824 [00:00<00:00, 99683.05it/s] 71%|   | 53658/75824 [00:00<00:00, 104811.33it/s] 86%| | 65495/75824 [00:00<00:00, 106849.51it/s]100%|| 75824/75824 [00:00<00:00, 109107.56it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6502/75824 [00:00<00:01, 61089.85it/s] 22%|       | 16521/75824 [00:00<00:00, 69190.32it/s] 37%|      | 28219/75824 [00:00<00:00, 78853.85it/s] 46%|     | 34731/75824 [00:00<00:00, 73508.51it/s] 56%|    | 42685/75824 [00:00<00:00, 75219.59it/s] 72%|  | 54563/75824 [00:00<00:00, 84517.45it/s] 88%| | 66589/75824 [00:00<00:00, 92789.88it/s]100%|| 75824/75824 [00:00<00:00, 96526.25it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 11915/75824 [00:00<00:00, 119144.72it/s] 31%|      | 23879/75824 [00:00<00:00, 119290.86it/s] 47%|     | 35945/75824 [00:00<00:00, 119697.34it/s] 60%|    | 45558/75824 [00:00<00:00, 111495.39it/s] 76%|  | 57264/75824 [00:00<00:00, 113106.89it/s] 90%| | 68040/75824 [00:00<00:00, 109269.02it/s]100%|| 75824/75824 [00:00<00:00, 112622.61it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 10%|         | 7205/75824 [00:00<00:00, 72046.12it/s] 25%|       | 18999/75824 [00:00<00:00, 81567.18it/s] 35%|      | 26797/75824 [00:00<00:00, 80454.67it/s] 43%|     | 32691/75824 [00:00<00:00, 70763.44it/s] 59%|    | 44796/75824 [00:00<00:00, 80836.68it/s] 72%|  | 54643/75824 [00:00<00:00, 85425.04it/s] 83%| | 62966/75824 [00:00<00:00, 75718.53it/s] 93%|| 70588/75824 [00:01<00:00, 51756.72it/s]100%|| 75824/75824 [00:01<00:00, 63970.95it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  7%|         | 4968/75824 [00:00<00:01, 49674.48it/s] 13%|        | 9676/75824 [00:00<00:01, 48865.93it/s] 18%|        | 13351/75824 [00:00<00:01, 44121.79it/s] 26%|       | 19520/75824 [00:00<00:01, 48243.33it/s] 34%|      | 25885/75824 [00:00<00:00, 50991.45it/s] 43%|     | 32329/75824 [00:00<00:00, 53260.69it/s] 49%|     | 37368/75824 [00:00<00:00, 51444.60it/s] 58%|    | 43717/75824 [00:00<00:00, 52943.32it/s] 66%|   | 49855/75824 [00:00<00:00, 55219.42it/s] 74%|  | 55816/75824 [00:01<00:00, 56135.69it/s] 82%| | 61862/75824 [00:01<00:00, 57105.84it/s] 89%| | 67707/75824 [00:01<00:00, 57498.36it/s] 97%|| 73424/75824 [00:01<00:00, 56172.13it/s]100%|| 75824/75824 [00:01<00:00, 54492.98it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  6%|         | 4761/75824 [00:00<00:01, 47609.48it/s] 13%|        | 9721/75824 [00:00<00:01, 47158.94it/s] 18%|        | 13456/75824 [00:00<00:01, 43708.22it/s] 23%|       | 17682/75824 [00:00<00:01, 42841.34it/s] 28%|       | 21491/75824 [00:00<00:01, 41294.21it/s] 33%|      | 24860/75824 [00:00<00:01, 38254.33it/s] 37%|      | 28395/75824 [00:00<00:01, 37333.46it/s] 42%|     | 31794/75824 [00:00<00:01, 35673.12it/s] 49%|     | 37261/75824 [00:00<00:00, 39824.43it/s] 57%|    | 43144/75824 [00:01<00:00, 44098.05it/s] 63%|   | 48117/75824 [00:01<00:00, 45648.03it/s] 70%|   | 52796/75824 [00:01<00:00, 41691.01it/s] 76%|  | 57622/75824 [00:01<00:00, 43218.19it/s] 82%| | 62223/75824 [00:01<00:00, 44019.03it/s] 88%| | 66711/75824 [00:01<00:00, 43361.06it/s] 94%|| 71110/75824 [00:01<00:00, 41019.89it/s] 99%|| 75438/75824 [00:01<00:00, 40175.60it/s]100%|| 75824/75824 [00:01<00:00, 41946.50it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6133/75824 [00:00<00:01, 58411.37it/s] 16%|        | 11796/75824 [00:00<00:01, 57864.60it/s] 23%|       | 17217/75824 [00:00<00:01, 56716.67it/s] 30%|       | 22524/75824 [00:00<00:00, 54761.26it/s] 37%|      | 28095/75824 [00:00<00:00, 54673.89it/s] 45%|     | 34441/75824 [00:00<00:00, 57043.10it/s] 52%|    | 39494/75824 [00:00<00:00, 54895.90it/s] 59%|    | 44545/75824 [00:00<00:00, 51434.81it/s] 65%|   | 49426/75824 [00:00<00:00, 49091.95it/s] 71%|  | 54174/75824 [00:01<00:00, 46710.25it/s] 77%|  | 58757/75824 [00:01<00:00, 44920.90it/s] 83%| | 63202/75824 [00:01<00:00, 37527.95it/s] 89%| | 67127/75824 [00:01<00:00, 33904.87it/s] 94%|| 70983/75824 [00:01<00:00, 34881.40it/s] 98%|| 74610/75824 [00:01<00:00, 34866.52it/s]100%|| 75824/75824 [00:01<00:00, 43814.13it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6111/75824 [00:00<00:01, 57710.94it/s] 13%|        | 9512/75824 [00:00<00:01, 46462.86it/s] 21%|        | 16042/75824 [00:00<00:01, 49808.72it/s] 28%|       | 21290/75824 [00:00<00:01, 50580.95it/s] 35%|      | 26564/75824 [00:00<00:00, 51209.00it/s] 41%|      | 30873/75824 [00:00<00:00, 47975.57it/s] 47%|     | 35943/75824 [00:00<00:00, 48761.10it/s] 55%|    | 41713/75824 [00:00<00:00, 51136.50it/s] 61%|   | 46619/75824 [00:00<00:00, 48548.07it/s] 68%|   | 51344/75824 [00:01<00:00, 43316.56it/s] 73%|  | 55690/75824 [00:01<00:00, 40015.68it/s] 80%|  | 60756/75824 [00:01<00:00, 42079.01it/s] 86%| | 65034/75824 [00:01<00:00, 40973.91it/s] 91%| | 69187/75824 [00:01<00:00, 41137.51it/s] 99%|| 75150/75824 [00:01<00:00, 45357.18it/s]100%|| 75824/75824 [00:01<00:00, 46462.11it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6235/75824 [00:00<00:01, 62348.72it/s] 13%|        | 10205/75824 [00:00<00:01, 52551.34it/s] 19%|        | 14692/75824 [00:00<00:01, 49983.02it/s] 24%|       | 18010/75824 [00:00<00:01, 42399.79it/s] 30%|       | 22649/75824 [00:00<00:01, 43521.95it/s] 35%|      | 26783/75824 [00:00<00:01, 41281.76it/s] 44%|     | 33086/75824 [00:00<00:00, 44910.42it/s] 52%|    | 39539/75824 [00:00<00:00, 47538.35it/s] 61%|    | 45896/75824 [00:00<00:00, 51429.12it/s] 67%|   | 51023/75824 [00:01<00:00, 47805.05it/s] 83%| | 63029/75824 [00:01<00:00, 58337.18it/s] 92%|| 70005/75824 [00:01<00:00, 60172.30it/s]100%|| 75824/75824 [00:01<00:00, 54921.94it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6631/75824 [00:00<00:01, 66305.79it/s] 19%|        | 14356/75824 [00:00<00:00, 68426.61it/s] 35%|      | 26205/75824 [00:00<00:00, 78358.22it/s] 49%|     | 37338/75824 [00:00<00:00, 85540.47it/s] 59%|    | 44860/75824 [00:00<00:00, 77956.20it/s] 69%|   | 52064/75824 [00:00<00:00, 72705.27it/s] 83%| | 63107/75824 [00:00<00:00, 81007.24it/s]100%|| 75688/75824 [00:00<00:00, 90696.51it/s]100%|| 75824/75824 [00:00<00:00, 89844.92it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.037229299545288086 seconds.
Run epoch 1
Epoch 1 ends in 0.03591036796569824 seconds.
5416 sentences created
mode 1: time used = 0.12029242515563965
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
epoch 5: {'train_loss': '2.24093'}; time used = 4.818035364151001s
epoch 10: {'train_loss': '1.46271'}; time used = 4.9644455909729s
epoch 15: {'train_loss': '1.36172'}; time used = 4.766639471054077s
epoch 20: {'train_loss': '1.31262'}; time used = 5.038311719894409s
epoch 25: {'train_loss': '1.20971'}; time used = 4.658287048339844s
epoch 30: {'train_loss': '1.12305'}; time used = 4.536711692810059s
epoch 35: {'train_loss': '1.06083'}; time used = 3.2211413383483887s
epoch 40: {'train_loss': '1.00281'}; time used = 2.533111333847046s
epoch 45: {'train_loss': '0.94679'}; time used = 2.734494209289551s
epoch 50: {'train_loss': '0.89754'}; time used = 2.0419931411743164s
epoch 55: {'train_loss': '0.85165'}; time used = 2.388721466064453s
epoch 60: {'train_loss': '0.80442'}; time used = 2.696516752243042s
epoch 65: {'train_loss': '0.76387'}; time used = 4.176488637924194s
epoch 70: {'train_loss': '0.72321'}; time used = 4.894222974777222s
epoch 75: {'train_loss': '0.68804'}; time used = 4.8665611743927s
epoch 80: {'train_loss': '0.65276'}; time used = 4.937970399856567s
epoch 85: {'train_loss': '0.62507'}; time used = 5.423994064331055s
epoch 90: {'train_loss': '0.59556'}; time used = 4.809283256530762s
epoch 95: {'train_loss': '0.56884'}; time used = 4.830663442611694s
epoch 100: {'train_loss': '0.54693'}; time used = 4.50493597984314s
epoch 105: {'train_loss': '0.52394'}; time used = 5.535891056060791s
epoch 110: {'train_loss': '0.50208'}; time used = 5.5021748542785645s
epoch 115: {'train_loss': '0.48284'}; time used = 5.064079761505127s
epoch 120: {'train_loss': '0.46498'}; time used = 5.010346174240112s
epoch 125: {'train_loss': '0.45016'}; time used = 4.9903576374053955s
epoch 130: {'train_loss': '0.43354'}; time used = 4.674177169799805s
epoch 135: {'train_loss': '0.41476'}; time used = 5.091585874557495s
epoch 140: {'train_loss': '0.40472'}; time used = 4.063321113586426s
epoch 145: {'train_loss': '0.39241'}; time used = 2.498950242996216s
epoch 150: {'train_loss': '0.37815'}; time used = 2.323237895965576s
epoch 155: {'train_loss': '0.36713'}; time used = 2.8334710597991943s
epoch 160: {'train_loss': '0.35757'}; time used = 4.966489791870117s
epoch 165: {'train_loss': '0.34563'}; time used = 4.81331205368042s
epoch 170: {'train_loss': '0.33667'}; time used = 5.071289777755737s
epoch 175: {'train_loss': '0.32514'}; time used = 5.346790790557861s
epoch 180: {'train_loss': '0.31433'}; time used = 5.76185941696167s
epoch 185: {'train_loss': '0.30632'}; time used = 4.692907333374023s
epoch 190: {'train_loss': '0.29535'}; time used = 4.852548837661743s
epoch 195: {'train_loss': '0.28195'}; time used = 3.056302547454834s
epoch 200: {'train_loss': '0.26623'}; time used = 3.2355120182037354s
epoch 205: {'train_loss': '0.24706'}; time used = 2.399056911468506s
epoch 210: {'train_loss': '0.22101'}; time used = 2.3768906593322754s
epoch 215: {'train_loss': '0.19043'}; time used = 2.8628640174865723s
epoch 220: {'train_loss': '0.15639'}; time used = 2.2713825702667236s
epoch 225: {'train_loss': '0.12956'}; time used = 3.095878839492798s
epoch 230: {'train_loss': '0.10762'}; time used = 2.3970799446105957s
epoch 235: {'train_loss': '0.09725'}; time used = 1.9017112255096436s
epoch 240: {'train_loss': '0.08713'}; time used = 2.6383373737335205s
epoch 245: {'train_loss': '0.08075'}; time used = 2.106597661972046s
epoch 250: {'train_loss': '0.07563'}; time used = 2.374516487121582s
epoch 255: {'train_loss': '0.06896'}; time used = 2.4310221672058105s
epoch 260: {'train_loss': '0.06964'}; time used = 2.287566900253296s
epoch 265: {'train_loss': '0.06518'}; time used = 4.330794811248779s
epoch 270: {'train_loss': '0.06571'}; time used = 2.2901053428649902s
epoch 275: {'train_loss': '0.06210'}; time used = 2.0364654064178467s
epoch 280: {'train_loss': '0.05854'}; time used = 2.6628105640411377s
epoch 285: {'train_loss': '0.05949'}; time used = 2.0653743743896484s
epoch 290: {'train_loss': '0.05893'}; time used = 2.324799060821533s
epoch 295: {'train_loss': '0.05733'}; time used = 4.3563525676727295s
epoch 300: {'train_loss': '0.05779'}; time used = 4.304962635040283s
epoch 305: {'train_loss': '0.05738'}; time used = 4.822924375534058s
epoch 310: {'train_loss': '0.05556'}; time used = 5.038336753845215s
epoch 315: {'train_loss': '0.05726'}; time used = 4.827148675918579s
epoch 320: {'train_loss': '0.05401'}; time used = 5.3097758293151855s
epoch 325: {'train_loss': '0.05156'}; time used = 5.032068729400635s
epoch 330: {'train_loss': '0.05492'}; time used = 5.316173791885376s
epoch 335: {'train_loss': '0.05391'}; time used = 5.08559513092041s
epoch 340: {'train_loss': '0.05115'}; time used = 5.298715353012085s
epoch 345: {'train_loss': '0.05097'}; time used = 5.287992000579834s
epoch 350: {'train_loss': '0.05202'}; time used = 5.08168625831604s
epoch 355: {'train_loss': '0.04764'}; time used = 4.806299686431885s
epoch 360: {'train_loss': '0.05173'}; time used = 4.840218782424927s
epoch 365: {'train_loss': '0.04952'}; time used = 4.909482479095459s
epoch 370: {'train_loss': '0.04980'}; time used = 4.9861016273498535s
epoch 375: {'train_loss': '0.04958'}; time used = 4.504236698150635s
epoch 380: {'train_loss': '0.04537'}; time used = 4.335201978683472s
epoch 385: {'train_loss': '0.04909'}; time used = 4.988292694091797s
epoch 390: {'train_loss': '0.04743'}; time used = 5.076983451843262s
epoch 395: {'train_loss': '0.04960'}; time used = 5.224625110626221s
epoch 400: {'train_loss': '0.04678'}; time used = 4.5865490436553955s
epoch 405: {'train_loss': '0.04610'}; time used = 4.952899694442749s
epoch 410: {'train_loss': '0.04745'}; time used = 5.106051921844482s
epoch 415: {'train_loss': '0.04543'}; time used = 3.3581817150115967s
epoch 420: {'train_loss': '0.04580'}; time used = 2.2771060466766357s
epoch 425: {'train_loss': '0.04611'}; time used = 2.550785541534424s
epoch 430: {'train_loss': '0.04755'}; time used = 2.6762776374816895s
epoch 435: {'train_loss': '0.04620'}; time used = 2.917849063873291s
epoch 440: {'train_loss': '0.04509'}; time used = 4.857768297195435s
epoch 445: {'train_loss': '0.04577'}; time used = 4.306220531463623s
epoch 450: {'train_loss': '0.04376'}; time used = 5.3366310596466064s
epoch 455: {'train_loss': '0.04902'}; time used = 4.345924615859985s
epoch 460: {'train_loss': '0.04555'}; time used = 4.658796787261963s
epoch 465: {'train_loss': '0.04594'}; time used = 5.0847132205963135s
epoch 470: {'train_loss': '0.04276'}; time used = 4.96773362159729s
epoch 475: {'train_loss': '0.04385'}; time used = 5.5930092334747314s
epoch 480: {'train_loss': '0.04398'}; time used = 4.4269561767578125s
epoch 485: {'train_loss': '0.04234'}; time used = 4.728389501571655s
epoch 490: {'train_loss': '0.04309'}; time used = 6.0674824714660645s
epoch 495: {'train_loss': '0.04534'}; time used = 5.6748762130737305s
epoch 500: {'train_loss': '0.04382'}; time used = 8.545434951782227s

Finished training. Time used = 424.767582654953.
Training classifier using 20.00% nodes...
{'micro': 0.5002307337332718, 'macro': 0.3973020017026056, 'samples': 0.5002307337332718, 'weighted': 0.448143571440481}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 179483.67it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 19131/75824 [00:00<00:00, 191306.53it/s] 48%|     | 36226/75824 [00:00<00:00, 184705.00it/s] 66%|   | 50095/75824 [00:00<00:00, 167983.12it/s] 90%| | 68401/75824 [00:00<00:00, 172236.65it/s]100%|| 75824/75824 [00:00<00:00, 174134.75it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 1.16 GiB (GPU 0; 10.76 GiB total capacity; 92.07 MiB already allocated; 523.44 MiB free; 102.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f8fba36e1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f8fca5e764b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f8fca5e8464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f8fca5e8aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f8d6955990e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f8d67993949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f8d679ad777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f8da2749c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f8da2749f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f8da2854a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f8da24e44f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f8da24e6166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f8da24e665d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f8da24e680a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f8da2223eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f8d67982b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f8da20b6530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f8da289e81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f8da27ef82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f8da2326952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f8da2327f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f8da28fb8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f8da292508b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f8da284c337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f8da445a205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f8da292508b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f8da284c337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f8da43b9f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f8da49d5bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f8da49d1400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f8da49d1fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f8da49ca119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f8fcb1434ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f8fcc29f6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f8fd02fa6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f8fd063371f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.019809484481811523 seconds.
Run epoch 1
Epoch 1 ends in 0.019710302352905273 seconds.
5416 sentences created
mode 1: time used = 0.040091753005981445
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 214998.87it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21442/75824 [00:00<00:00, 214419.18it/s] 58%|    | 43678/75824 [00:00<00:00, 216739.02it/s] 87%| | 65825/75824 [00:00<00:00, 218134.71it/s]100%|| 75824/75824 [00:00<00:00, 218803.04it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 222, in forward
    self.to(self._device)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 607, in to
    return self._apply(convert)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 376, in _apply
    param_applied = fn(param)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 605, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 14.80 MiB already allocated; 10.44 MiB free; 16.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.01567840576171875 seconds.
Run epoch 1
Epoch 1 ends in 0.015289306640625 seconds.
5416 sentences created
mode 1: time used = 0.03162527084350586
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 186007.49it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 28%|       | 21129/75824 [00:00<00:00, 211288.69it/s] 57%|    | 43114/75824 [00:00<00:00, 213784.52it/s] 87%| | 65727/75824 [00:00<00:00, 217342.23it/s]100%|| 75824/75824 [00:00<00:00, 220647.62it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 222, in forward
    self.to(self._device)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 607, in to
    return self._apply(convert)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 354, in _apply
    module._apply(fn)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 376, in _apply
    param_applied = fn(param)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 605, in convert
    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 10.76 GiB total capacity; 14.80 MiB already allocated; 11.44 MiB free; 16.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.01872873306274414 seconds.
Run epoch 1
Epoch 1 ends in 0.01804804801940918 seconds.
5416 sentences created
mode 1: time used = 0.03642678260803223
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 176230.99it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 26%|       | 19825/75824 [00:00<00:00, 198244.52it/s] 52%|    | 39335/75824 [00:00<00:00, 197289.34it/s] 80%|  | 60876/75824 [00:00<00:00, 202395.97it/s]100%|| 75824/75824 [00:00<00:00, 204694.22it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 18.51 GiB (GPU 0; 10.76 GiB total capacity; 316.42 MiB already allocated; 553.44 MiB free; 344.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f200ea0b1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f200ec6164b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f200ec62464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f200ec62aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f1dcdf5590e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f1dcc38f949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f1dcc3a9777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f200ff5dc7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f200ff5df97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f2010068a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f200fcf84f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f200fcfa166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f200fcfa65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f200fcfa80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f200fa37eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f1dcc37eb40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f200f8ca530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f20100b281c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f201000382b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f200fb3a952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f200fb3bf4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f201010f8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f201013908b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f2010060337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f2011c6e205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f201013908b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f2010060337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f2011bcdf78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f20121e9bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f20121e5400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f20121e5fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f20121de119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f201f97e4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f2020ada6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f2024b356db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f2024e6e71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.0191347599029541 seconds.
Run epoch 1
Epoch 1 ends in 0.018274545669555664 seconds.
5416 sentences created
mode 1: time used = 0.03809857368469238
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 10.76 GiB total capacity; 0 bytes already allocated; 148.44 MiB free; 0 bytes reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 202450.39it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 21%|        | 15744/75824 [00:00<00:00, 157430.39it/s] 37%|      | 27957/75824 [00:00<00:00, 144868.25it/s] 53%|    | 40235/75824 [00:00<00:00, 137449.63it/s] 69%|   | 52535/75824 [00:00<00:00, 132767.58it/s] 86%| | 65027/75824 [00:00<00:00, 130308.91it/s]100%|| 75824/75824 [00:00<00:00, 129436.42it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 18.51 GiB (GPU 0; 10.76 GiB total capacity; 316.42 MiB already allocated; 346.44 MiB free; 344.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f052c8d31e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f052cb2964b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f052cb2a464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f052cb2aaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f02ebe1d90e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f02ea257949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f02ea271777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f052de25c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f052de25f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f052df30a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f052dbc04f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f052dbc2166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f052dbc265d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f052dbc280a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f052d8ffeb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f02ea246b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f052d792530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f052df7a81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f052decb82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f052da02952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f052da03f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f052dfd78c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f052e00108b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f052df28337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f052fb36205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f052e00108b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f052df28337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f052fa95f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f05300b1bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f05300ad400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f05300adfa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f05300a6119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f053d8464ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f053e9a26df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f05429fd6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f0542d3671f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.01728200912475586 seconds.
Run epoch 1
Epoch 1 ends in 0.01697087287902832 seconds.
5416 sentences created
mode 1: time used = 0.03365802764892578
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5408/5416 [00:00<00:00, 50343.90it/s]100%|| 5416/5416 [00:00<00:00, 50071.42it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  9%|         | 6768/75824 [00:00<00:01, 64095.47it/s] 16%|        | 12480/75824 [00:00<00:01, 61814.73it/s] 26%|       | 19515/75824 [00:00<00:00, 63466.36it/s] 36%|      | 27074/75824 [00:00<00:00, 65973.53it/s] 43%|     | 32361/75824 [00:00<00:00, 61012.73it/s] 54%|    | 41012/75824 [00:00<00:00, 66929.77it/s] 62%|   | 47197/75824 [00:00<00:00, 60991.63it/s] 78%|  | 58957/75824 [00:00<00:00, 71285.33it/s] 89%| | 67422/75824 [00:00<00:00, 74828.05it/s]100%|| 75824/75824 [00:01<00:00, 73901.40it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 18.51 GiB (GPU 0; 10.76 GiB total capacity; 316.42 MiB already allocated; 1.54 GiB free; 344.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f51eb6a71e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f51eb8fd64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f51eb8fe464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f51eb8feaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f4faabf190e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f4fa902b949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f4fa9045777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f51ecbf9c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f51ecbf9f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f51ecd04a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f51ec9944f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f51ec996166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f51ec99665d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f51ec99680a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f51ec6d3eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f4fa901ab40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f51ec566530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f51ecd4e81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f51ecc9f82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f51ec7d6952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f51ec7d7f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f51ecdab8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f51ecdd508b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f51eccfc337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f51ee90a205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f51ecdd508b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f51eccfc337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f51ee869f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f51eee85bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f51eee81400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f51eee81fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f51eee7a119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f51fc61a4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f51fd7766df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f52017d16db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f5201b0a71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.04631948471069336 seconds.
Run epoch 1
Epoch 1 ends in 0.08651423454284668 seconds.
5416 sentences created
mode 1: time used = 0.15902280807495117
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 79117.97it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 14%|        | 10581/75824 [00:00<00:00, 105803.29it/s] 30%|       | 22555/75824 [00:00<00:00, 109629.14it/s] 46%|     | 35102/75824 [00:00<00:00, 113944.83it/s] 63%|   | 47548/75824 [00:00<00:00, 116905.96it/s] 80%|  | 60443/75824 [00:00<00:00, 120273.67it/s] 97%|| 73269/75824 [00:00<00:00, 122563.02it/s]100%|| 75824/75824 [00:00<00:00, 122189.01it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 18.51 GiB (GPU 0; 10.76 GiB total capacity; 316.42 MiB already allocated; 1.34 GiB free; 344.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fc2d18ef1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7fc2d1b4564b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7fc2d1b46464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7fc2d1b46aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7fc070ab790e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7fc06eef1949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7fc06ef0b777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7fc0a9ca7c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7fc0a9ca7f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7fc0a9db2a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7fc0a9a424f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7fc0a9a44166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7fc0a9a4465d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7fc0a9a4480a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7fc0a9781eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7fc06eee0b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7fc0a9614530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7fc0a9dfc81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7fc0a9d4d82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7fc0a9884952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7fc0a9885f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7fc0a9e598c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7fc0a9e8308b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7fc0a9daa337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7fc0ab9b8205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7fc0a9e8308b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7fc0a9daa337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7fc0ab917f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7fc0abf33bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7fc0abf2f400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7fc0abf2ffa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7fc0abf28119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7fc2d26a14ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7fc2d37fd6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7fc2d78586db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7fc2d7b9171f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.019591569900512695 seconds.
Run epoch 1
Epoch 1 ends in 0.025757312774658203 seconds.
5416 sentences created
mode 1: time used = 0.08272290229797363
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 84260.40it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 5783/75824 [00:00<00:01, 53553.13it/s] 22%|       | 16491/75824 [00:00<00:00, 63000.07it/s] 36%|      | 27335/75824 [00:00<00:00, 72058.28it/s] 51%|     | 38496/75824 [00:00<00:00, 80629.16it/s] 66%|   | 50233/75824 [00:00<00:00, 88985.58it/s] 81%|  | 61108/75824 [00:00<00:00, 94116.70it/s] 95%|| 71978/75824 [00:00<00:00, 98062.92it/s]100%|| 75824/75824 [00:00<00:00, 102112.54it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 18.51 GiB (GPU 0; 10.76 GiB total capacity; 316.42 MiB already allocated; 697.44 MiB free; 344.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f0d326171e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f0d3286d64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f0d3286e464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f0d3286eaa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f0af1b6190e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f0aeff9b949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f0aeffb5777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f0d33b69c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f0d33b69f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f0d33c74a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f0d339044f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f0d33906166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f0d3390665d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f0d3390680a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f0d33643eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f0aeff8ab40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f0d334d6530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f0d33cbe81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f0d33c0f82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f0d33746952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f0d33747f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f0d33d1b8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f0d33d4508b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f0d33c6c337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f0d3587a205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f0d33d4508b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f0d33c6c337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f0d357d9f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f0d35df5bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f0d35df1400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f0d35df1fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f0d35dea119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f0d4358a4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f0d446e66df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f0d487416db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f0d48a7a71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.03600335121154785 seconds.
Run epoch 1
Epoch 1 ends in 0.035253047943115234 seconds.
5416 sentences created
mode 1: time used = 0.08664107322692871
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: all CUDA-capable devices are busy or unavailable
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 209442.57it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 16%|        | 12331/75824 [00:00<00:00, 123302.18it/s] 33%|      | 25170/75824 [00:00<00:00, 124783.98it/s] 50%|     | 37916/75824 [00:00<00:00, 125572.56it/s] 67%|   | 50525/75824 [00:00<00:00, 125726.75it/s] 83%| | 62897/75824 [00:00<00:00, 125115.70it/s]100%|| 75824/75824 [00:00<00:00, 126723.12it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 18.51 GiB (GPU 0; 10.76 GiB total capacity; 316.42 MiB already allocated; 777.44 MiB free; 344.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7ff0a6b4e1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7ff0a6da464b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7ff0a6da5464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7ff0a6da5aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7fee6609890e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7fee644d2949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7fee644ec777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7ff0a80a0c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7ff0a80a0f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7ff0a81aba1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7ff0a7e3b4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7ff0a7e3d166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7ff0a7e3d65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7ff0a7e3d80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7ff0a7b7aeb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7fee644c1b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7ff0a7a0d530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7ff0a81f581c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7ff0a814682b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7ff0a7c7d952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7ff0a7c7ef4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7ff0a82528c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7ff0a827c08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7ff0a81a3337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7ff0a9db1205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7ff0a827c08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7ff0a81a3337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7ff0a9d10f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7ff0aa32cbb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7ff0aa328400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7ff0aa328fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7ff0aa321119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7ff0b7ac14ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7ff0b8c1d6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7ff0bcc786db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7ff0bcfb171f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.016791820526123047 seconds.
Run epoch 1
Epoch 1 ends in 0.015803098678588867 seconds.
5416 sentences created
mode 1: time used = 0.0327606201171875
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 182235.23it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 25%|       | 18804/75824 [00:00<00:00, 188039.73it/s] 48%|     | 36610/75824 [00:00<00:00, 184928.56it/s] 74%|  | 56406/75824 [00:00<00:00, 188653.63it/s] 99%|| 74977/75824 [00:00<00:00, 187758.67it/s]100%|| 75824/75824 [00:00<00:00, 187356.31it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 151, in evaluate
    loss = self.model(x, pos, neg)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 41, in forward
    hpos = self.embed(pos)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_model.py", line 37, in embed
    return self.encoder(x)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_encoder.py", line 82, in forward
    return self.embed(x)[indices]
RuntimeError: CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 10.76 GiB total capacity; 176.43 MiB already allocated; 99.44 MiB free; 190.00 MiB reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.02096390724182129 seconds.
Run epoch 1
Epoch 1 ends in 0.01993846893310547 seconds.
5416 sentences created
mode 1: time used = 0.03775453567504883
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 181863.20it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 24%|       | 18548/75824 [00:00<00:00, 185471.78it/s] 51%|     | 38659/75824 [00:00<00:00, 189901.19it/s] 78%|  | 59062/75824 [00:00<00:00, 193928.22it/s]100%|| 75824/75824 [00:00<00:00, 191637.71it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 74.05 GiB (GPU 0; 10.76 GiB total capacity; 616.01 MiB already allocated; 373.44 MiB free; 642.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f22a04871e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f22b08af64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f22b08b0464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f22b08b0aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f204e67090e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f204caaa949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f204cac4777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f2087860c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f2087860f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f208796ba1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f20875fb4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f20875fd166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f20875fd65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f20875fd80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f208733aeb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f204ca99b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f20871cd530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f20879b581c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f208790682b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f208743d952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f208743ef4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f2087a128c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f2087a3c08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f2087963337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f2089571205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f2087a3c08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f2087963337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f20894d0f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f2089aecbb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f2089ae8400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f2089ae8fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f2089ae1119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f212120e4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f22b13b66df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f22b54116db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f22b574a71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.01761651039123535 seconds.
Run epoch 1
Epoch 1 ends in 0.01835155487060547 seconds.
5416 sentences created
mode 1: time used = 0.037270545959472656
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 88290.15it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 13%|        | 9828/75824 [00:00<00:00, 98278.69it/s] 24%|       | 18473/75824 [00:00<00:00, 93641.30it/s] 39%|      | 29833/75824 [00:00<00:00, 98851.20it/s] 54%|    | 41315/75824 [00:00<00:00, 103154.51it/s] 71%|   | 53650/75824 [00:00<00:00, 108482.20it/s] 83%| | 63008/75824 [00:00<00:00, 101780.25it/s] 95%|| 72227/75824 [00:00<00:00, 97141.40it/s] 100%|| 75824/75824 [00:00<00:00, 99335.92it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 74.05 GiB (GPU 0; 10.76 GiB total capacity; 616.01 MiB already allocated; 1.02 GiB free; 642.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f09611531e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f097157b64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f097157c464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f097157caa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f070f33c90e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f070d776949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f070d790777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f074852cc7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f074852cf97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f0748637a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f07482c74f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f07482c9166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f07482c965d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f07482c980a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f0748006eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f070d765b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f0747e99530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f074868181c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f07485d282b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f0748109952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f074810af4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f07486de8c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f074870808b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f074862f337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f074a23d205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f074870808b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f074862f337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f074a19cf78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f074a7b8bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f074a7b4400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f074a7b4fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f074a7ad119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f0814ee04ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f09720826df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f09760dd6db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f097641671f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.04391884803771973 seconds.
Run epoch 1
Epoch 1 ends in 0.049566030502319336 seconds.
5416 sentences created
mode 1: time used = 0.08362269401550293
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 87951.06it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 15%|        | 11529/75824 [00:00<00:00, 108246.58it/s] 29%|       | 21841/75824 [00:00<00:00, 106654.09it/s] 41%|     | 31278/75824 [00:00<00:00, 102644.76it/s] 54%|    | 41038/75824 [00:00<00:00, 101076.39it/s] 71%|   | 53470/75824 [00:00<00:00, 107081.54it/s] 86%| | 65484/75824 [00:00<00:00, 110689.90it/s] 99%|| 75393/75824 [00:00<00:00, 101599.54it/s]100%|| 75824/75824 [00:00<00:00, 104366.01it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 74.05 GiB (GPU 0; 10.76 GiB total capacity; 616.01 MiB already allocated; 533.44 MiB free; 642.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f6f662191e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f6f6646f64b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f6f66470464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f6f66470aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f6d155a290e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f6d139dc949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f6d139f6777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f6e9d342c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f6e9d342f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f6e9d44da1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f6e9d0dd4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f6e9d0df166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f6e9d0df65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f6e9d0df80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f6e9ce1ceb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f6d139cbb40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f6e9ccaf530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f6e9d49781c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f6e9d3e882b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f6e9cf1f952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f6e9cf20f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f6e9d4f48c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f6e9d51e08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f6e9d445337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f6e9f053205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f6e9d51e08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f6e9d445337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f6e9efb2f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f6e9f5cebb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f6e9f5ca400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f6e9f5cafa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f6e9f5c3119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f6f66fcb4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f6f681276df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f6f6c1826db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f6f6c4bb71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.03408479690551758 seconds.
Run epoch 1
Epoch 1 ends in 0.046308040618896484 seconds.
5416 sentences created
mode 1: time used = 0.08575439453125
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 55976.70it/s]
  0%|          | 0/75824 [00:00<?, ?it/s]  8%|         | 6103/75824 [00:00<00:01, 57023.47it/s] 17%|        | 12898/75824 [00:00<00:01, 59912.79it/s] 32%|      | 24014/75824 [00:00<00:00, 68810.90it/s] 47%|     | 35820/75824 [00:00<00:00, 78653.52it/s] 63%|   | 47862/75824 [00:00<00:00, 87786.97it/s] 75%|  | 56612/75824 [00:00<00:00, 82495.44it/s] 86%| | 64990/75824 [00:00<00:00, 82875.85it/s]100%|| 75824/75824 [00:00<00:00, 91455.55it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 74.05 GiB (GPU 0; 10.76 GiB total capacity; 616.01 MiB already allocated; 917.44 MiB free; 642.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f95845fc1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f958485264b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f9584853464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f9584853aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f9343b4690e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f9341f80949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f9341f9a777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f9585b4ec7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f9585b4ef97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f9585c59a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f95858e94f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f95858eb166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f95858eb65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f95858eb80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f9585628eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f9341f6fb40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f95854bb530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f9585ca381c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f9585bf482b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f958572b952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f958572cf4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f9585d008c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f9585d2a08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f9585c51337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f958785f205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f9585d2a08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f9585c51337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f95877bef78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f9587ddabb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f9587dd6400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f9587dd6fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f9587dcf119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f959556f4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f95966cb6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f959a7266db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f959aa5f71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.034392595291137695 seconds.
Run epoch 1
Epoch 1 ends in 0.04145407676696777 seconds.
5416 sentences created
mode 1: time used = 0.12631940841674805
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 202609.29it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 27%|       | 20471/75824 [00:00<00:00, 204709.22it/s] 53%|    | 39811/75824 [00:00<00:00, 201178.24it/s] 83%| | 62620/75824 [00:00<00:00, 208560.00it/s]100%|| 75824/75824 [00:00<00:00, 210099.11it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 74.05 GiB (GPU 0; 10.76 GiB total capacity; 616.01 MiB already allocated; 2.71 GiB free; 642.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7fe24821d1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7fe24847364b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7fe248474464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7fe248474aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7fe00776790e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7fe005ba1949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7fe005bbb777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7fe24976fc7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7fe24976ff97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7fe24987aa1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7fe24950a4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7fe24950c166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7fe24950c65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7fe24950c80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7fe249249eb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7fe005b90b40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7fe2490dc530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7fe2498c481c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7fe24981582b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7fe24934c952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7fe24934df4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7fe2499218c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7fe24994b08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7fe249872337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7fe24b480205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7fe24994b08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7fe249872337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7fe24b3dff78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7fe24b9fbbb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7fe24b9f7400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7fe24b9f7fa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7fe24b9f0119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7fe2591904ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7fe25a2ec6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7fe25e3476db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7fe25e68071f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.018131256103515625 seconds.
Run epoch 1
Epoch 1 ends in 0.016836881637573242 seconds.
5416 sentences created
mode 1: time used = 0.03394818305969238
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 215343.31it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 30%|       | 22513/75824 [00:00<00:00, 225128.07it/s] 61%|    | 46020/75824 [00:00<00:00, 228020.64it/s] 90%| | 67903/75824 [00:00<00:00, 225181.81it/s]100%|| 75824/75824 [00:00<00:00, 226685.04it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 74.05 GiB (GPU 0; 10.76 GiB total capacity; 616.01 MiB already allocated; 160.44 MiB free; 642.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f42c5b491e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f42cdf5364b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f42cdf54464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f42cdf54aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f4073d3290e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f407216c949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f4072186777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f40acf22c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f40acf22f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f40ad02da1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f40accbd4f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f40accbf166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f40accbf65d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f40accbf80a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f40ac9fceb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f407215bb40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f40ac88f530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f40ad07781c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f40acfc882b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f40acaff952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f40acb00f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f40ad0d48c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f40ad0fe08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f40ad025337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f40aec33205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f40ad0fe08b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f40ad025337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f40aeb92f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f40af1aebb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f40af1aa400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f40af1aafa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f40af1a3119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f429a8f84ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f42d6a786df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f42daad36db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f42dae0c71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.015403032302856445 seconds.
Run epoch 1
Epoch 1 ends in 0.01499176025390625 seconds.
5416 sentences created
mode 1: time used = 0.03148055076599121
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/5416 [00:00<?, ?it/s]100%|| 5416/5416 [00:00<00:00, 208380.12it/s]
  0%|          | 0/75824 [00:00<?, ?it/s] 30%|       | 22850/75824 [00:00<00:00, 228489.87it/s] 48%|     | 36506/75824 [00:00<00:00, 190093.50it/s] 78%|  | 58777/75824 [00:00<00:00, 198827.25it/s]100%|| 75824/75824 [00:00<00:00, 202352.23it/s]
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 111, in train_model
    output, train_loss, __ = self.evaluate()
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 153, in evaluate
    loss.backward()
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 74.05 GiB (GPU 0; 10.76 GiB total capacity; 616.01 MiB already allocated; 214.44 MiB free; 642.00 MiB reserved in total by PyTorch)
Exception raised from malloc at /pytorch/c10/cuda/CUDACachingAllocator.cpp:272 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7f10e612c1e2 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0x1e64b (0x7f10f655464b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #2: <unknown function> + 0x1f464 (0x7f10f6555464 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1faa1 (0x7f10f6555aa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libc10_cuda.so)
frame #4: at::native::empty_cuda(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0x11e (0x7f0e9431590e in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #5: <unknown function> + 0xf33949 (0x7f0e9274f949 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #6: <unknown function> + 0xf4d777 (0x7f0e92769777 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #7: <unknown function> + 0x10e9c7d (0x7f0ecd505c7d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #8: <unknown function> + 0x10e9f97 (0x7f0ecd505f97 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #9: at::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) + 0xfa (0x7f0ecd610a1a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #10: at::TensorIterator::allocate_outputs() + 0x378 (0x7f0ecd2a04f8 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #11: at::TensorIterator::build(at::TensorIteratorConfig&) + 0x1e6 (0x7f0ecd2a2166 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #12: at::TensorIterator::TensorIterator(at::TensorIteratorConfig&) + 0xdd (0x7f0ecd2a265d in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #13: at::TensorIterator::binary_op(at::Tensor&, at::Tensor const&, at::Tensor const&, bool) + 0x14a (0x7f0ecd2a280a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #14: at::native::mul(at::Tensor const&, at::Tensor const&) + 0x47 (0x7f0eccfdfeb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #15: <unknown function> + 0xf22b40 (0x7f0e9273eb40 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cuda.so)
frame #16: <unknown function> + 0xa56530 (0x7f0ecce72530 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #17: at::Tensor c10::Dispatcher::call<at::Tensor, at::Tensor const&, at::Tensor const&>(c10::TypedOperatorHandle<at::Tensor (at::Tensor const&, at::Tensor const&)> const&, at::Tensor const&, at::Tensor const&) const + 0xbc (0x7f0ecd65a81c in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #18: at::mul(at::Tensor const&, at::Tensor const&) + 0x4b (0x7f0ecd5ab82b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #19: <unknown function> + 0xcc6952 (0x7f0ecd0e2952 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #20: at::native::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0xdba (0x7f0ecd0e3f4a in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #21: <unknown function> + 0x129b8c0 (0x7f0ecd6b78c0 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #22: <unknown function> + 0x12c508b (0x7f0ecd6e108b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #23: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f0ecd608337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #24: <unknown function> + 0x2dfa205 (0x7f0ecf216205 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #25: <unknown function> + 0x12c508b (0x7f0ecd6e108b in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #26: at::_trilinear(at::Tensor const&, at::Tensor const&, at::Tensor const&, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, c10::ArrayRef<long>, long) + 0x1d7 (0x7f0ecd608337 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #27: torch::autograd::generated::TrilinearBackward::apply(std::vector<at::Tensor, std::allocator<at::Tensor> >&&) + 0x6a8 (0x7f0ecf175f78 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #28: <unknown function> + 0x3375bb7 (0x7f0ecf791bb7 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #29: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&, std::shared_ptr<torch::autograd::ReadyQueue> const&) + 0x1400 (0x7f0ecf78d400 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #30: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&) + 0x451 (0x7f0ecf78dfa1 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #31: torch::autograd::Engine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x89 (0x7f0ecf786119 in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_cpu.so)
frame #32: torch::autograd::python::PythonEngine::thread_init(int, std::shared_ptr<torch::autograd::ReadyQueue> const&, bool) + 0x4a (0x7f1032ecb4ba in /home/duyufeng/.local/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
frame #33: <unknown function> + 0xbd6df (0x7f10f705b6df in /usr/lib/x86_64-linux-gnu/libstdc++.so.6)
frame #34: <unknown function> + 0x76db (0x7f10fb0b66db in /lib/x86_64-linux-gnu/libpthread.so.0)
frame #35: clone + 0x3f (0x7f10fb3ef71f in /lib/x86_64-linux-gnu/libc.so.6)

actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'bilinear', 'sampler': 'node-rand_walk-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
generating anchors and positive samples...
5 2 2
Walk iteration:
Run epoch 0
Epoch 0 ends in 0.01833963394165039 seconds.
Run epoch 1
Epoch 1 ends in 0.015474557876586914 seconds.
5416 sentences created
mode 1: time used = 0.03199315071105957
anchors and positive samples of len 75824 generated
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 75824 75824 75824
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.50555'}; time used = 0.03690814971923828s
epoch 10: {'train_loss': '1.38852'}; time used = 0.03206777572631836s
epoch 15: {'train_loss': '1.34590'}; time used = 0.026117563247680664s
epoch 20: {'train_loss': '1.32748'}; time used = 0.027484893798828125s
epoch 25: {'train_loss': '1.30669'}; time used = 0.034102439880371094s
epoch 30: {'train_loss': '1.28902'}; time used = 0.033611297607421875s
epoch 35: {'train_loss': '1.27227'}; time used = 0.028925657272338867s
epoch 40: {'train_loss': '1.25750'}; time used = 0.0327603816986084s
epoch 45: {'train_loss': '1.25708'}; time used = 0.024011611938476562s
epoch 50: {'train_loss': '1.24879'}; time used = 0.028629064559936523s
epoch 55: {'train_loss': '1.25060'}; time used = 0.025727272033691406s
epoch 60: {'train_loss': '1.24543'}; time used = 0.029775619506835938s
epoch 65: {'train_loss': '1.24745'}; time used = 0.02506399154663086s
epoch 70: {'train_loss': '1.24601'}; time used = 0.031548500061035156s
epoch 75: {'train_loss': '1.24635'}; time used = 0.06452751159667969s
epoch 80: {'train_loss': '1.24384'}; time used = 0.025170326232910156s
epoch 85: {'train_loss': '1.24353'}; time used = 0.027756929397583008s
epoch 90: {'train_loss': '1.24333'}; time used = 0.02705097198486328s
epoch 95: {'train_loss': '1.23961'}; time used = 0.031690359115600586s
epoch 100: {'train_loss': '1.24502'}; time used = 0.024675846099853516s
epoch 105: {'train_loss': '1.23892'}; time used = 0.023380041122436523s
epoch 110: {'train_loss': '1.24640'}; time used = 0.02665233612060547s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 3.514590263366699.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06508785332314744, 'samples': 0.29487771112136596, 'weighted': 0.13435070046813036}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.36382'}; time used = 0.051789045333862305s
epoch 10: {'train_loss': '1.33265'}; time used = 0.022960901260375977s
epoch 15: {'train_loss': '1.28526'}; time used = 0.020026206970214844s
epoch 20: {'train_loss': '1.26045'}; time used = 0.0309450626373291s
epoch 25: {'train_loss': '1.24907'}; time used = 0.02057504653930664s
epoch 30: {'train_loss': '1.24469'}; time used = 0.019877910614013672s
epoch 35: {'train_loss': '1.24081'}; time used = 0.01915764808654785s
epoch 40: {'train_loss': '1.23354'}; time used = 0.020058393478393555s
epoch 45: {'train_loss': '1.23514'}; time used = 0.020174026489257812s
epoch 50: {'train_loss': '1.22786'}; time used = 0.019740819931030273s
epoch 55: {'train_loss': '1.23087'}; time used = 0.019788026809692383s
epoch 60: {'train_loss': '1.22912'}; time used = 0.02021169662475586s
epoch 65: {'train_loss': '1.23328'}; time used = 0.023035764694213867s
epoch 70: {'train_loss': '1.23032'}; time used = 0.02101302146911621s
epoch 75: {'train_loss': '1.23205'}; time used = 0.01977086067199707s
epoch 80: {'train_loss': '1.22845'}; time used = 0.04257607460021973s
epoch 85: {'train_loss': '1.22931'}; time used = 0.03308725357055664s
epoch 90: {'train_loss': '1.22893'}; time used = 0.027034521102905273s
epoch 95: {'train_loss': '1.22529'}; time used = 0.02083134651184082s
epoch 100: {'train_loss': '1.23123'}; time used = 0.01930546760559082s
epoch 105: {'train_loss': '1.22557'}; time used = 0.020244598388671875s
epoch 110: {'train_loss': '1.23485'}; time used = 0.019988059997558594s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 5.852839231491089.
Training classifier using 20.00% nodes...
{'micro': 0.29441624365482233, 'macro': 0.06517186781755964, 'samples': 0.29441624365482233, 'weighted': 0.13452411848082338}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.70804'}; time used = 0.02933788299560547s
epoch 10: {'train_loss': '1.68172'}; time used = 0.01935720443725586s
epoch 15: {'train_loss': '1.64542'}; time used = 0.0190274715423584s
epoch 20: {'train_loss': '1.61318'}; time used = 0.030966520309448242s
epoch 25: {'train_loss': '1.59124'}; time used = 0.023506641387939453s
epoch 30: {'train_loss': '1.56626'}; time used = 0.025768280029296875s
epoch 35: {'train_loss': '1.53799'}; time used = 0.025637388229370117s
epoch 40: {'train_loss': '1.51915'}; time used = 0.028435945510864258s
epoch 45: {'train_loss': '1.50112'}; time used = 0.0205690860748291s
epoch 50: {'train_loss': '1.49273'}; time used = 0.020593881607055664s
epoch 55: {'train_loss': '1.47523'}; time used = 0.02045273780822754s
epoch 60: {'train_loss': '1.46341'}; time used = 0.024290084838867188s
epoch 65: {'train_loss': '1.44856'}; time used = 0.01964402198791504s
epoch 70: {'train_loss': '1.43533'}; time used = 0.024274587631225586s
epoch 75: {'train_loss': '1.43405'}; time used = 0.02081608772277832s
epoch 80: {'train_loss': '1.41818'}; time used = 0.02576589584350586s
epoch 85: {'train_loss': '1.41372'}; time used = 0.020195722579956055s
epoch 90: {'train_loss': '1.39902'}; time used = 0.020194292068481445s
epoch 95: {'train_loss': '1.39553'}; time used = 0.02323126792907715s
epoch 100: {'train_loss': '1.38879'}; time used = 0.022315502166748047s
epoch 105: {'train_loss': '1.38387'}; time used = 0.03207588195800781s
epoch 110: {'train_loss': '1.38179'}; time used = 0.03803420066833496s
epoch 115: {'train_loss': '1.37246'}; time used = 0.02708292007446289s
epoch 120: {'train_loss': '1.36661'}; time used = 0.029117345809936523s
epoch 125: {'train_loss': '1.36115'}; time used = 0.026090145111083984s
epoch 130: {'train_loss': '1.35610'}; time used = 0.02998208999633789s
epoch 135: {'train_loss': '1.35292'}; time used = 0.03259539604187012s
epoch 140: {'train_loss': '1.35402'}; time used = 0.026793718338012695s
epoch 145: {'train_loss': '1.34713'}; time used = 0.023294448852539062s
epoch 150: {'train_loss': '1.34496'}; time used = 0.023270130157470703s
epoch 155: {'train_loss': '1.34212'}; time used = 0.020790576934814453s
epoch 160: {'train_loss': '1.33694'}; time used = 0.019281387329101562s
epoch 165: {'train_loss': '1.33341'}; time used = 0.02455282211303711s
epoch 170: {'train_loss': '1.33341'}; time used = 0.02317667007446289s
epoch 175: {'train_loss': '1.32504'}; time used = 0.02415633201599121s
epoch 180: {'train_loss': '1.32266'}; time used = 0.025829792022705078s
epoch 185: {'train_loss': '1.32160'}; time used = 0.023438692092895508s
epoch 190: {'train_loss': '1.32042'}; time used = 0.027566909790039062s
epoch 195: {'train_loss': '1.31643'}; time used = 0.017192840576171875s
epoch 200: {'train_loss': '1.31154'}; time used = 0.01699995994567871s
epoch 205: {'train_loss': '1.30940'}; time used = 0.016897916793823242s
epoch 210: {'train_loss': '1.30846'}; time used = 0.022994518280029297s
epoch 215: {'train_loss': '1.30819'}; time used = 0.018227815628051758s
epoch 220: {'train_loss': '1.30507'}; time used = 0.018204450607299805s
epoch 225: {'train_loss': '1.30175'}; time used = 0.03094029426574707s
epoch 230: {'train_loss': '1.29637'}; time used = 0.02427363395690918s
epoch 235: {'train_loss': '1.29968'}; time used = 0.031148433685302734s
epoch 240: {'train_loss': '1.29011'}; time used = 0.024274110794067383s
epoch 245: {'train_loss': '1.28606'}; time used = 0.05625438690185547s
epoch 250: {'train_loss': '1.28795'}; time used = 0.023851633071899414s
epoch 255: {'train_loss': '1.28520'}; time used = 0.01938176155090332s
epoch 260: {'train_loss': '1.28231'}; time used = 0.024013519287109375s
epoch 265: {'train_loss': '1.28171'}; time used = 0.024161338806152344s
epoch 270: {'train_loss': '1.28058'}; time used = 0.023513317108154297s
epoch 275: {'train_loss': '1.27309'}; time used = 0.023448705673217773s
epoch 280: {'train_loss': '1.27555'}; time used = 0.020250558853149414s
epoch 285: {'train_loss': '1.27254'}; time used = 0.029727697372436523s
epoch 290: {'train_loss': '1.27710'}; time used = 0.020372390747070312s
epoch 295: {'train_loss': '1.27676'}; time used = 0.019974470138549805s
epoch 300: {'train_loss': '1.26715'}; time used = 0.024764299392700195s
epoch 305: {'train_loss': '1.26774'}; time used = 0.019887924194335938s
epoch 310: {'train_loss': '1.26395'}; time used = 0.02046036720275879s
epoch 315: {'train_loss': '1.26623'}; time used = 0.023076534271240234s
epoch 320: {'train_loss': '1.26731'}; time used = 0.020130634307861328s
epoch 325: {'train_loss': '1.26083'}; time used = 0.019825220108032227s
epoch 330: {'train_loss': '1.26405'}; time used = 0.027557849884033203s
epoch 335: {'train_loss': '1.26201'}; time used = 0.020534038543701172s
epoch 340: {'train_loss': '1.25891'}; time used = 0.02042412757873535s
epoch 345: {'train_loss': '1.26120'}; time used = 0.024973630905151367s
epoch 350: {'train_loss': '1.25716'}; time used = 0.02021193504333496s
epoch 355: {'train_loss': '1.25988'}; time used = 0.020105600357055664s
epoch 360: {'train_loss': '1.26054'}; time used = 0.023201942443847656s
epoch 365: {'train_loss': '1.25629'}; time used = 0.020235776901245117s
epoch 370: {'train_loss': '1.25797'}; time used = 0.030283689498901367s
epoch 375: {'train_loss': '1.25661'}; time used = 0.024216890335083008s
epoch 380: {'train_loss': '1.25752'}; time used = 0.02393484115600586s
epoch 385: {'train_loss': '1.24490'}; time used = 0.027872323989868164s
epoch 390: {'train_loss': '1.25154'}; time used = 0.023677825927734375s
epoch 395: {'train_loss': '1.25145'}; time used = 0.024361848831176758s
epoch 400: {'train_loss': '1.25141'}; time used = 0.02823615074157715s
epoch 405: {'train_loss': '1.24782'}; time used = 0.023668766021728516s
epoch 410: {'train_loss': '1.24480'}; time used = 0.030159711837768555s
epoch 415: {'train_loss': '1.25066'}; time used = 0.02537369728088379s
epoch 420: {'train_loss': '1.25569'}; time used = 0.02973628044128418s
epoch 425: {'train_loss': '1.25408'}; time used = 0.02963399887084961s
epoch 430: {'train_loss': '1.25196'}; time used = 0.024245023727416992s
epoch 435: {'train_loss': '1.24818'}; time used = 0.0618135929107666s
epoch 440: {'train_loss': '1.24896'}; time used = 0.02158355712890625s
epoch 445: {'train_loss': '1.24801'}; time used = 0.029033899307250977s
epoch 450: {'train_loss': '1.25184'}; time used = 0.02432394027709961s
epoch 455: {'train_loss': '1.24996'}; time used = 0.031054019927978516s
epoch 460: {'train_loss': '1.24653'}; time used = 0.02768421173095703s
epoch 465: {'train_loss': '1.24657'}; time used = 0.031023263931274414s
epoch 470: {'train_loss': '1.24814'}; time used = 0.025722265243530273s
epoch 475: {'train_loss': '1.24705'}; time used = 0.03245997428894043s
epoch 480: {'train_loss': '1.25017'}; time used = 0.024904489517211914s
epoch 485: {'train_loss': '1.24693'}; time used = 0.02409648895263672s
epoch 490: {'train_loss': '1.24831'}; time used = 0.033341407775878906s
epoch 495: {'train_loss': '1.24514'}; time used = 0.023958444595336914s
epoch 500: {'train_loss': '1.24479'}; time used = 0.02673935890197754s
Finished training. Time used = 5.669227838516235.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 10.76 GiB total capacity; 0 bytes already allocated; 9.44 MiB free; 0 bytes reserved in total by PyTorch)
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.40130'}; time used = 0.03598737716674805s
epoch 10: {'train_loss': '1.34031'}; time used = 0.02895069122314453s
epoch 15: {'train_loss': '1.31336'}; time used = 0.028512954711914062s
epoch 20: {'train_loss': '1.27880'}; time used = 0.02050042152404785s
epoch 25: {'train_loss': '1.25946'}; time used = 0.028306245803833008s
epoch 30: {'train_loss': '1.25286'}; time used = 0.019438982009887695s
epoch 35: {'train_loss': '1.24936'}; time used = 0.02128887176513672s
epoch 40: {'train_loss': '1.24251'}; time used = 0.026118993759155273s
epoch 45: {'train_loss': '1.24409'}; time used = 0.027915239334106445s
epoch 50: {'train_loss': '1.23584'}; time used = 0.027398347854614258s
epoch 55: {'train_loss': '1.23682'}; time used = 0.03233671188354492s
epoch 60: {'train_loss': '1.23217'}; time used = 0.02902507781982422s
epoch 65: {'train_loss': '1.23493'}; time used = 0.030030488967895508s
epoch 70: {'train_loss': '1.23204'}; time used = 0.028063058853149414s
epoch 75: {'train_loss': '1.23262'}; time used = 0.03471708297729492s
epoch 80: {'train_loss': '1.22851'}; time used = 0.02504444122314453s
epoch 85: {'train_loss': '1.22901'}; time used = 0.028248310089111328s
epoch 90: {'train_loss': '1.22893'}; time used = 0.027087926864624023s
epoch 95: {'train_loss': '1.22523'}; time used = 0.030347585678100586s
epoch 100: {'train_loss': '1.23054'}; time used = 0.024623394012451172s
epoch 105: {'train_loss': '1.22526'}; time used = 0.02570056915283203s
epoch 110: {'train_loss': '1.23434'}; time used = 0.028760671615600586s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 3.70599627494812.
Training classifier using 20.00% nodes...
{'micro': 0.29441624365482233, 'macro': 0.06507879838833068, 'samples': 0.29441624365482233, 'weighted': 0.13433200977895854}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.70804'}; time used = 0.055647850036621094s
epoch 10: {'train_loss': '1.68172'}; time used = 0.020092248916625977s
epoch 15: {'train_loss': '1.64542'}; time used = 0.01981973648071289s
epoch 20: {'train_loss': '1.61318'}; time used = 0.01933765411376953s
epoch 25: {'train_loss': '1.59124'}; time used = 0.01951146125793457s
epoch 30: {'train_loss': '1.56626'}; time used = 0.01951432228088379s
epoch 35: {'train_loss': '1.53799'}; time used = 0.03496813774108887s
epoch 40: {'train_loss': '1.51915'}; time used = 0.0199429988861084s
epoch 45: {'train_loss': '1.50112'}; time used = 0.01968860626220703s
epoch 50: {'train_loss': '1.49273'}; time used = 0.019472599029541016s
epoch 55: {'train_loss': '1.47523'}; time used = 0.019524097442626953s
epoch 60: {'train_loss': '1.46341'}; time used = 0.01986217498779297s
epoch 65: {'train_loss': '1.44856'}; time used = 0.01975107192993164s
epoch 70: {'train_loss': '1.43533'}; time used = 0.021184682846069336s
epoch 75: {'train_loss': '1.43405'}; time used = 0.01957082748413086s
epoch 80: {'train_loss': '1.41818'}; time used = 0.02418661117553711s
epoch 85: {'train_loss': '1.41372'}; time used = 0.01933765411376953s
epoch 90: {'train_loss': '1.39902'}; time used = 0.019400358200073242s
epoch 95: {'train_loss': '1.39553'}; time used = 0.04219508171081543s
epoch 100: {'train_loss': '1.38879'}; time used = 0.02213263511657715s
epoch 105: {'train_loss': '1.38387'}; time used = 0.02052021026611328s
epoch 110: {'train_loss': '1.38179'}; time used = 0.0254209041595459s
epoch 115: {'train_loss': '1.37246'}; time used = 0.020296573638916016s
epoch 120: {'train_loss': '1.36661'}; time used = 0.021155834197998047s
epoch 125: {'train_loss': '1.36115'}; time used = 0.021983623504638672s
epoch 130: {'train_loss': '1.35610'}; time used = 0.019838809967041016s
epoch 135: {'train_loss': '1.35292'}; time used = 0.021604299545288086s
epoch 140: {'train_loss': '1.35402'}; time used = 0.019649982452392578s
epoch 145: {'train_loss': '1.34713'}; time used = 0.019744157791137695s
epoch 150: {'train_loss': '1.34496'}; time used = 0.021480321884155273s
epoch 155: {'train_loss': '1.34212'}; time used = 0.020606517791748047s
epoch 160: {'train_loss': '1.33694'}; time used = 0.02424168586730957s
epoch 165: {'train_loss': '1.33341'}; time used = 0.02234029769897461s
epoch 170: {'train_loss': '1.33341'}; time used = 0.020960569381713867s
epoch 175: {'train_loss': '1.32504'}; time used = 0.02110457420349121s
epoch 180: {'train_loss': '1.32266'}; time used = 0.022089242935180664s
epoch 185: {'train_loss': '1.32160'}; time used = 0.0221407413482666s
epoch 190: {'train_loss': '1.32042'}; time used = 0.020895957946777344s
epoch 195: {'train_loss': '1.31643'}; time used = 0.02092742919921875s
epoch 200: {'train_loss': '1.31154'}; time used = 0.0279233455657959s
epoch 205: {'train_loss': '1.30940'}; time used = 0.027450084686279297s
epoch 210: {'train_loss': '1.30846'}; time used = 0.0273895263671875s
epoch 215: {'train_loss': '1.30819'}; time used = 0.027025222778320312s
epoch 220: {'train_loss': '1.30507'}; time used = 0.025328397750854492s
epoch 225: {'train_loss': '1.30175'}; time used = 0.02615070343017578s
epoch 230: {'train_loss': '1.29637'}; time used = 0.0505986213684082s
epoch 235: {'train_loss': '1.29968'}; time used = 0.020041942596435547s
epoch 240: {'train_loss': '1.29011'}; time used = 0.020862579345703125s
epoch 245: {'train_loss': '1.28606'}; time used = 0.020802736282348633s
epoch 250: {'train_loss': '1.28795'}; time used = 0.019372940063476562s
epoch 255: {'train_loss': '1.28520'}; time used = 0.020158767700195312s
epoch 260: {'train_loss': '1.28231'}; time used = 0.0211789608001709s
epoch 265: {'train_loss': '1.28171'}; time used = 0.021082401275634766s
epoch 270: {'train_loss': '1.28058'}; time used = 0.020920991897583008s
epoch 275: {'train_loss': '1.27309'}; time used = 0.02087259292602539s
epoch 280: {'train_loss': '1.27555'}; time used = 0.021033287048339844s
epoch 285: {'train_loss': '1.27254'}; time used = 0.021049976348876953s
epoch 290: {'train_loss': '1.27710'}; time used = 0.06444096565246582s
epoch 295: {'train_loss': '1.27676'}; time used = 0.026190757751464844s
epoch 300: {'train_loss': '1.26715'}; time used = 0.03063368797302246s
epoch 305: {'train_loss': '1.26774'}; time used = 0.01975083351135254s
epoch 310: {'train_loss': '1.26395'}; time used = 0.023099184036254883s
epoch 315: {'train_loss': '1.26623'}; time used = 0.02300858497619629s
epoch 320: {'train_loss': '1.26731'}; time used = 0.019533872604370117s
epoch 325: {'train_loss': '1.26083'}; time used = 0.01952338218688965s
epoch 330: {'train_loss': '1.26405'}; time used = 0.019699573516845703s
epoch 335: {'train_loss': '1.26201'}; time used = 0.01947951316833496s
epoch 340: {'train_loss': '1.25891'}; time used = 0.04150819778442383s
epoch 345: {'train_loss': '1.26120'}; time used = 0.019842863082885742s
epoch 350: {'train_loss': '1.25716'}; time used = 0.019977092742919922s
epoch 355: {'train_loss': '1.25988'}; time used = 0.03153657913208008s
epoch 360: {'train_loss': '1.26054'}; time used = 0.021532535552978516s
epoch 365: {'train_loss': '1.25629'}; time used = 0.022557973861694336s
epoch 370: {'train_loss': '1.25797'}; time used = 0.024692773818969727s
epoch 375: {'train_loss': '1.25661'}; time used = 0.02063727378845215s
epoch 380: {'train_loss': '1.25752'}; time used = 0.019485950469970703s
epoch 385: {'train_loss': '1.24490'}; time used = 0.019518613815307617s
epoch 390: {'train_loss': '1.25154'}; time used = 0.019628286361694336s
epoch 395: {'train_loss': '1.25145'}; time used = 0.025269269943237305s
epoch 400: {'train_loss': '1.25141'}; time used = 0.019367456436157227s
epoch 405: {'train_loss': '1.24782'}; time used = 0.0276033878326416s
epoch 410: {'train_loss': '1.24480'}; time used = 0.02093505859375s
epoch 415: {'train_loss': '1.25066'}; time used = 0.030900239944458008s
epoch 420: {'train_loss': '1.25569'}; time used = 0.019841909408569336s
epoch 425: {'train_loss': '1.25408'}; time used = 0.03102421760559082s
epoch 430: {'train_loss': '1.25196'}; time used = 0.021799564361572266s
epoch 435: {'train_loss': '1.24818'}; time used = 0.021308183670043945s
epoch 440: {'train_loss': '1.24896'}; time used = 0.01962876319885254s
epoch 445: {'train_loss': '1.24801'}; time used = 0.019864797592163086s
epoch 450: {'train_loss': '1.25184'}; time used = 0.021555662155151367s
epoch 455: {'train_loss': '1.24996'}; time used = 0.019708633422851562s
epoch 460: {'train_loss': '1.24653'}; time used = 0.01996445655822754s
epoch 465: {'train_loss': '1.24657'}; time used = 0.022185325622558594s
epoch 470: {'train_loss': '1.24814'}; time used = 0.04569745063781738s
epoch 475: {'train_loss': '1.24705'}; time used = 0.020976543426513672s
epoch 480: {'train_loss': '1.25017'}; time used = 0.02103567123413086s
epoch 485: {'train_loss': '1.24693'}; time used = 0.032380104064941406s
epoch 490: {'train_loss': '1.24831'}; time used = 0.03524947166442871s
epoch 495: {'train_loss': '1.24514'}; time used = 0.05084943771362305s
epoch 500: {'train_loss': '1.24479'}; time used = 0.045891523361206055s
Finished training. Time used = 7.846122980117798.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.50555'}; time used = 0.05524253845214844s
epoch 10: {'train_loss': '1.38852'}; time used = 0.022714614868164062s
epoch 15: {'train_loss': '1.34590'}; time used = 0.022309303283691406s
epoch 20: {'train_loss': '1.32748'}; time used = 0.020777225494384766s
epoch 25: {'train_loss': '1.30669'}; time used = 0.02064037322998047s
epoch 30: {'train_loss': '1.28902'}; time used = 0.020742416381835938s
epoch 35: {'train_loss': '1.27227'}; time used = 0.02326798439025879s
epoch 40: {'train_loss': '1.25750'}; time used = 0.021734237670898438s
epoch 45: {'train_loss': '1.25708'}; time used = 0.020566225051879883s
epoch 50: {'train_loss': '1.24879'}; time used = 0.020465373992919922s
epoch 55: {'train_loss': '1.25060'}; time used = 0.020855188369750977s
epoch 60: {'train_loss': '1.24543'}; time used = 0.021747589111328125s
epoch 65: {'train_loss': '1.24745'}; time used = 0.02079486846923828s
epoch 70: {'train_loss': '1.24601'}; time used = 0.02068614959716797s
epoch 75: {'train_loss': '1.24635'}; time used = 0.027788639068603516s
epoch 80: {'train_loss': '1.24384'}; time used = 0.02063894271850586s
epoch 85: {'train_loss': '1.24353'}; time used = 0.01997208595275879s
epoch 90: {'train_loss': '1.24333'}; time used = 0.020030498504638672s
epoch 95: {'train_loss': '1.23961'}; time used = 0.03571152687072754s
epoch 100: {'train_loss': '1.24502'}; time used = 0.025362253189086914s
epoch 105: {'train_loss': '1.23892'}; time used = 0.01998305320739746s
epoch 110: {'train_loss': '1.24640'}; time used = 0.021200895309448242s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 6.071439266204834.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06508785332314744, 'samples': 0.29487771112136596, 'weighted': 0.13435070046813036}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.40130'}; time used = 0.032361507415771484s
epoch 10: {'train_loss': '1.34031'}; time used = 0.02646946907043457s
epoch 15: {'train_loss': '1.31336'}; time used = 0.02914118766784668s
epoch 20: {'train_loss': '1.27880'}; time used = 0.06545495986938477s
epoch 25: {'train_loss': '1.25946'}; time used = 0.028862714767456055s
epoch 30: {'train_loss': '1.25286'}; time used = 0.027457475662231445s
epoch 35: {'train_loss': '1.24936'}; time used = 0.027567625045776367s
epoch 40: {'train_loss': '1.24251'}; time used = 0.028828144073486328s
epoch 45: {'train_loss': '1.24409'}; time used = 0.027987003326416016s
epoch 50: {'train_loss': '1.23584'}; time used = 0.02421259880065918s
epoch 55: {'train_loss': '1.23682'}; time used = 0.024921417236328125s
epoch 60: {'train_loss': '1.23217'}; time used = 0.02633833885192871s
epoch 65: {'train_loss': '1.23493'}; time used = 0.02500128746032715s
epoch 70: {'train_loss': '1.23204'}; time used = 0.03749895095825195s
epoch 75: {'train_loss': '1.23262'}; time used = 0.02406454086303711s
epoch 80: {'train_loss': '1.22851'}; time used = 0.022451400756835938s
epoch 85: {'train_loss': '1.22901'}; time used = 0.02309393882751465s
epoch 90: {'train_loss': '1.22893'}; time used = 0.022114038467407227s
epoch 95: {'train_loss': '1.22523'}; time used = 0.019522428512573242s
epoch 100: {'train_loss': '1.23054'}; time used = 0.02138996124267578s
epoch 105: {'train_loss': '1.22526'}; time used = 0.018355846405029297s
epoch 110: {'train_loss': '1.23434'}; time used = 0.01780080795288086s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 3.725564956665039.
Training classifier using 20.00% nodes...
{'micro': 0.29441624365482233, 'macro': 0.06507879838833068, 'samples': 0.29441624365482233, 'weighted': 0.13433200977895854}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.72464'}; time used = 0.056349992752075195s
epoch 10: {'train_loss': '1.66588'}; time used = 0.01607990264892578s
epoch 15: {'train_loss': '1.63003'}; time used = 0.022001981735229492s
epoch 20: {'train_loss': '1.58155'}; time used = 0.015662670135498047s
epoch 25: {'train_loss': '1.55239'}; time used = 0.015362262725830078s
epoch 30: {'train_loss': '1.52077'}; time used = 0.020621776580810547s
epoch 35: {'train_loss': '1.49828'}; time used = 0.014134407043457031s
epoch 40: {'train_loss': '1.46950'}; time used = 0.013863563537597656s
epoch 45: {'train_loss': '1.45994'}; time used = 0.015976905822753906s
epoch 50: {'train_loss': '1.43342'}; time used = 0.0324399471282959s
epoch 55: {'train_loss': '1.42815'}; time used = 0.02249431610107422s
epoch 60: {'train_loss': '1.41492'}; time used = 0.024425745010375977s
epoch 65: {'train_loss': '1.40278'}; time used = 0.02899479866027832s
epoch 70: {'train_loss': '1.39321'}; time used = 0.027608394622802734s
epoch 75: {'train_loss': '1.38752'}; time used = 0.029672622680664062s
epoch 80: {'train_loss': '1.37513'}; time used = 0.02553844451904297s
epoch 85: {'train_loss': '1.36246'}; time used = 0.028895854949951172s
epoch 90: {'train_loss': '1.36229'}; time used = 0.025301456451416016s
epoch 95: {'train_loss': '1.35365'}; time used = 0.028540849685668945s
epoch 100: {'train_loss': '1.34917'}; time used = 0.025819778442382812s
epoch 105: {'train_loss': '1.34213'}; time used = 0.027081966400146484s
epoch 110: {'train_loss': '1.33865'}; time used = 0.02962803840637207s
epoch 115: {'train_loss': '1.33188'}; time used = 0.02379608154296875s
epoch 120: {'train_loss': '1.32918'}; time used = 0.020067930221557617s
epoch 125: {'train_loss': '1.32243'}; time used = 0.023280858993530273s
epoch 130: {'train_loss': '1.32002'}; time used = 0.030922889709472656s
epoch 135: {'train_loss': '1.31393'}; time used = 0.021036386489868164s
epoch 140: {'train_loss': '1.31469'}; time used = 0.02283477783203125s
epoch 145: {'train_loss': '1.30329'}; time used = 0.02987957000732422s
epoch 150: {'train_loss': '1.30781'}; time used = 0.029123306274414062s
epoch 155: {'train_loss': '1.30011'}; time used = 0.0286405086517334s
epoch 160: {'train_loss': '1.29276'}; time used = 0.024883747100830078s
epoch 165: {'train_loss': '1.29310'}; time used = 0.027301549911499023s
epoch 170: {'train_loss': '1.28985'}; time used = 0.025394916534423828s
epoch 175: {'train_loss': '1.28985'}; time used = 0.02474808692932129s
epoch 180: {'train_loss': '1.28128'}; time used = 0.02855992317199707s
epoch 185: {'train_loss': '1.28566'}; time used = 0.02576160430908203s
epoch 190: {'train_loss': '1.27669'}; time used = 0.03084850311279297s
epoch 195: {'train_loss': '1.27535'}; time used = 0.028920650482177734s
epoch 200: {'train_loss': '1.27225'}; time used = 0.03191423416137695s
epoch 205: {'train_loss': '1.27418'}; time used = 0.027076005935668945s
epoch 210: {'train_loss': '1.26324'}; time used = 0.028465986251831055s
epoch 215: {'train_loss': '1.26737'}; time used = 0.03329777717590332s
epoch 220: {'train_loss': '1.26474'}; time used = 0.028435945510864258s
epoch 225: {'train_loss': '1.26573'}; time used = 0.02930736541748047s
epoch 230: {'train_loss': '1.25567'}; time used = 0.02629828453063965s
epoch 235: {'train_loss': '1.25833'}; time used = 0.02595686912536621s
epoch 240: {'train_loss': '1.25655'}; time used = 0.023096084594726562s
epoch 245: {'train_loss': '1.25388'}; time used = 0.02494525909423828s
epoch 250: {'train_loss': '1.25100'}; time used = 0.02756667137145996s
epoch 255: {'train_loss': '1.24922'}; time used = 0.024509906768798828s
epoch 260: {'train_loss': '1.25475'}; time used = 0.028041362762451172s
epoch 265: {'train_loss': '1.25458'}; time used = 0.02179551124572754s
epoch 270: {'train_loss': '1.25619'}; time used = 0.022571563720703125s
epoch 275: {'train_loss': '1.24189'}; time used = 0.027692556381225586s
epoch 280: {'train_loss': '1.24583'}; time used = 0.023461580276489258s
epoch 285: {'train_loss': '1.24854'}; time used = 0.028181076049804688s
epoch 290: {'train_loss': '1.24902'}; time used = 0.023081064224243164s
epoch 295: {'train_loss': '1.24935'}; time used = 0.020821571350097656s
epoch 300: {'train_loss': '1.24851'}; time used = 0.031286001205444336s
epoch 305: {'train_loss': '1.24379'}; time used = 0.029211044311523438s
epoch 310: {'train_loss': '1.24898'}; time used = 0.03410983085632324s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 5.1599061489105225.
Training classifier using 20.00% nodes...
{'micro': 0.2884171665897554, 'macro': 0.06807193855959415, 'samples': 0.2884171665897554, 'weighted': 0.13708092281065093}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.46735'}; time used = 0.06204390525817871s
epoch 10: {'train_loss': '1.35668'}; time used = 0.021640539169311523s
epoch 15: {'train_loss': '1.32547'}; time used = 0.02294635772705078s
epoch 20: {'train_loss': '1.29923'}; time used = 0.020270347595214844s
epoch 25: {'train_loss': '1.28288'}; time used = 0.022275686264038086s
epoch 30: {'train_loss': '1.26040'}; time used = 0.024331331253051758s
epoch 35: {'train_loss': '1.25663'}; time used = 0.01909017562866211s
epoch 40: {'train_loss': '1.24885'}; time used = 0.01910257339477539s
epoch 45: {'train_loss': '1.24790'}; time used = 0.01918196678161621s
epoch 50: {'train_loss': '1.24188'}; time used = 0.019286394119262695s
epoch 55: {'train_loss': '1.24596'}; time used = 0.019125699996948242s
epoch 60: {'train_loss': '1.24858'}; time used = 0.01891160011291504s
epoch 65: {'train_loss': '1.24568'}; time used = 0.018980979919433594s
epoch 70: {'train_loss': '1.24655'}; time used = 0.023485183715820312s
epoch 75: {'train_loss': '1.23997'}; time used = 0.022476911544799805s
epoch 80: {'train_loss': '1.24074'}; time used = 0.023080825805664062s
epoch 85: {'train_loss': '1.23499'}; time used = 0.020746469497680664s
epoch 90: {'train_loss': '1.23201'}; time used = 0.02162647247314453s
epoch 95: {'train_loss': '1.23090'}; time used = 0.01946282386779785s
epoch 100: {'train_loss': '1.23179'}; time used = 0.019016027450561523s
epoch 105: {'train_loss': '1.22699'}; time used = 0.018955469131469727s
epoch 110: {'train_loss': '1.22855'}; time used = 0.032535552978515625s
epoch 115: {'train_loss': '1.22862'}; time used = 0.024626731872558594s
epoch 120: {'train_loss': '1.22814'}; time used = 0.03228497505187988s
epoch 125: {'train_loss': '1.22684'}; time used = 0.0279388427734375s
epoch 130: {'train_loss': '1.22803'}; time used = 0.0448603630065918s
epoch 135: {'train_loss': '1.22938'}; time used = 0.019799470901489258s
epoch 140: {'train_loss': '1.22905'}; time used = 0.019588232040405273s
epoch 145: {'train_loss': '1.22009'}; time used = 0.01947474479675293s
epoch 150: {'train_loss': '1.23337'}; time used = 0.019607067108154297s
epoch 155: {'train_loss': '1.22862'}; time used = 0.023569822311401367s
epoch 160: {'train_loss': '1.22422'}; time used = 0.03897285461425781s
epoch 165: {'train_loss': '1.22698'}; time used = 0.028299570083618164s
epoch 170: {'train_loss': '1.22835'}; time used = 0.024328947067260742s
epoch 175: {'train_loss': '1.23392'}; time used = 0.024279356002807617s
epoch 180: {'train_loss': '1.22442'}; time used = 0.023389101028442383s
epoch 185: {'train_loss': '1.23199'}; time used = 0.02376413345336914s
epoch 190: {'train_loss': '1.23004'}; time used = 0.024048805236816406s
epoch 195: {'train_loss': '1.22661'}; time used = 0.02393794059753418s
epoch 200: {'train_loss': '1.22859'}; time used = 0.021683931350708008s
epoch 205: {'train_loss': '1.23722'}; time used = 0.02494192123413086s
epoch 210: {'train_loss': '1.22042'}; time used = 0.021963834762573242s
epoch 215: {'train_loss': '1.23075'}; time used = 0.023852825164794922s
epoch 220: {'train_loss': '1.22925'}; time used = 0.024422883987426758s
epoch 225: {'train_loss': '1.23267'}; time used = 0.021767854690551758s
epoch 230: {'train_loss': '1.22277'}; time used = 0.021114587783813477s
epoch 235: {'train_loss': '1.22789'}; time used = 0.02356433868408203s
epoch 240: {'train_loss': '1.22686'}; time used = 0.01996755599975586s
epoch 245: {'train_loss': '1.22865'}; time used = 0.019669294357299805s
epoch 250: {'train_loss': '1.22364'}; time used = 0.022567272186279297s
epoch 255: {'train_loss': '1.22335'}; time used = 0.02834486961364746s
epoch 260: {'train_loss': '1.23253'}; time used = 0.0350947380065918s
epoch 265: {'train_loss': '1.23205'}; time used = 0.03660321235656738s
epoch 270: {'train_loss': '1.23328'}; time used = 0.02071523666381836s
epoch 275: {'train_loss': '1.21900'}; time used = 0.02066659927368164s
epoch 280: {'train_loss': '1.22269'}; time used = 0.0366511344909668s
epoch 285: {'train_loss': '1.22768'}; time used = 0.031189918518066406s
epoch 290: {'train_loss': '1.23039'}; time used = 0.022753000259399414s
epoch 295: {'train_loss': '1.23216'}; time used = 0.03228259086608887s
epoch 300: {'train_loss': '1.23103'}; time used = 0.03610706329345703s
epoch 305: {'train_loss': '1.22367'}; time used = 0.03433799743652344s
epoch 310: {'train_loss': '1.23138'}; time used = 0.02930426597595215s
epoch 315: {'train_loss': '1.22968'}; time used = 0.02013254165649414s
epoch 320: {'train_loss': '1.22921'}; time used = 0.022347688674926758s
epoch 325: {'train_loss': '1.23148'}; time used = 0.022999286651611328s
epoch 330: {'train_loss': '1.22797'}; time used = 0.02199697494506836s
epoch 335: {'train_loss': '1.22958'}; time used = 0.02158379554748535s
epoch 340: {'train_loss': '1.23366'}; time used = 0.022966623306274414s
epoch 345: {'train_loss': '1.22866'}; time used = 0.03271222114562988s
epoch 350: {'train_loss': '1.22718'}; time used = 0.02800774574279785s
epoch 355: {'train_loss': '1.22388'}; time used = 0.02210688591003418s
epoch 360: {'train_loss': '1.22881'}; time used = 0.0211334228515625s
epoch 365: {'train_loss': '1.22539'}; time used = 0.021468639373779297s
epoch 370: {'train_loss': '1.22613'}; time used = 0.021099090576171875s
epoch 375: {'train_loss': '1.22398'}; time used = 0.03142380714416504s
epoch 380: {'train_loss': '1.22630'}; time used = 0.021834373474121094s
epoch 385: {'train_loss': '1.23101'}; time used = 0.028927326202392578s
epoch 390: {'train_loss': '1.23018'}; time used = 0.02614140510559082s
epoch 395: {'train_loss': '1.22879'}; time used = 0.02506232261657715s
epoch 400: {'train_loss': '1.22627'}; time used = 0.025251388549804688s
epoch 405: {'train_loss': '1.23449'}; time used = 0.024500370025634766s
epoch 410: {'train_loss': '1.22626'}; time used = 0.025707006454467773s
epoch 415: {'train_loss': '1.23228'}; time used = 0.024454593658447266s
epoch 420: {'train_loss': '1.22836'}; time used = 0.026453495025634766s
epoch 425: {'train_loss': '1.22899'}; time used = 0.02586650848388672s
epoch 430: {'train_loss': '1.22556'}; time used = 0.026061534881591797s
epoch 435: {'train_loss': '1.22728'}; time used = 0.027007102966308594s
epoch 440: {'train_loss': '1.22796'}; time used = 0.025646209716796875s
epoch 445: {'train_loss': '1.22821'}; time used = 0.026059389114379883s
epoch 450: {'train_loss': '1.23455'}; time used = 0.025058984756469727s
epoch 455: {'train_loss': '1.23080'}; time used = 0.025220870971679688s
epoch 460: {'train_loss': '1.22825'}; time used = 0.02855682373046875s
epoch 465: {'train_loss': '1.22615'}; time used = 0.02689647674560547s
epoch 470: {'train_loss': '1.22912'}; time used = 0.0498046875s
epoch 475: {'train_loss': '1.22932'}; time used = 0.06662368774414062s
epoch 480: {'train_loss': '1.22352'}; time used = 0.05276203155517578s
epoch 485: {'train_loss': '1.22317'}; time used = 0.026208162307739258s
epoch 490: {'train_loss': '1.23052'}; time used = 0.02837538719177246s
epoch 495: {'train_loss': '1.21942'}; time used = 0.024647951126098633s
epoch 500: {'train_loss': '1.22877'}; time used = 0.05139303207397461s
Finished training. Time used = 6.117507219314575.
Training classifier using 20.00% nodes...
{'micro': 0.28887863405629904, 'macro': 0.0720163622360754, 'samples': 0.28887863405629904, 'weighted': 0.14169724223080254}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.35566'}; time used = 0.03232312202453613s
epoch 10: {'train_loss': '1.30508'}; time used = 0.0253598690032959s
epoch 15: {'train_loss': '1.26292'}; time used = 0.025220394134521484s
epoch 20: {'train_loss': '1.24540'}; time used = 0.026113033294677734s
epoch 25: {'train_loss': '1.24691'}; time used = 0.025780677795410156s
epoch 30: {'train_loss': '1.23603'}; time used = 0.028250694274902344s
epoch 35: {'train_loss': '1.23660'}; time used = 0.025568008422851562s
epoch 40: {'train_loss': '1.23158'}; time used = 0.026270389556884766s
epoch 45: {'train_loss': '1.23388'}; time used = 0.026810407638549805s
epoch 50: {'train_loss': '1.22572'}; time used = 0.02544116973876953s
epoch 55: {'train_loss': '1.23276'}; time used = 0.025838136672973633s
epoch 60: {'train_loss': '1.23808'}; time used = 0.02678203582763672s
epoch 65: {'train_loss': '1.23500'}; time used = 0.03158402442932129s
epoch 70: {'train_loss': '1.23600'}; time used = 0.02692389488220215s
epoch 75: {'train_loss': '1.23151'}; time used = 0.026104211807250977s
epoch 80: {'train_loss': '1.23376'}; time used = 0.025682687759399414s
epoch 85: {'train_loss': '1.22978'}; time used = 0.026341676712036133s
epoch 90: {'train_loss': '1.22786'}; time used = 0.0270688533782959s
epoch 95: {'train_loss': '1.22920'}; time used = 0.026103973388671875s
epoch 100: {'train_loss': '1.23106'}; time used = 0.025326967239379883s
epoch 105: {'train_loss': '1.22664'}; time used = 0.06606364250183105s
epoch 110: {'train_loss': '1.23047'}; time used = 0.02136683464050293s
epoch 115: {'train_loss': '1.22999'}; time used = 0.025211572647094727s
epoch 120: {'train_loss': '1.22926'}; time used = 0.025028705596923828s
epoch 125: {'train_loss': '1.22890'}; time used = 0.024290084838867188s
epoch 130: {'train_loss': '1.23003'}; time used = 0.023402690887451172s
epoch 135: {'train_loss': '1.23071'}; time used = 0.03227400779724121s
epoch 140: {'train_loss': '1.23093'}; time used = 0.02706146240234375s
epoch 145: {'train_loss': '1.22188'}; time used = 0.026082515716552734s
epoch 150: {'train_loss': '1.23479'}; time used = 0.025246381759643555s
epoch 155: {'train_loss': '1.23169'}; time used = 0.025562047958374023s
epoch 160: {'train_loss': '1.22792'}; time used = 0.027970552444458008s
epoch 165: {'train_loss': '1.22868'}; time used = 0.025699615478515625s
epoch 170: {'train_loss': '1.23092'}; time used = 0.02681756019592285s
epoch 175: {'train_loss': '1.23717'}; time used = 0.025681018829345703s
epoch 180: {'train_loss': '1.22632'}; time used = 0.028391122817993164s
epoch 185: {'train_loss': '1.23535'}; time used = 0.023347854614257812s
epoch 190: {'train_loss': '1.23285'}; time used = 0.022486209869384766s
epoch 195: {'train_loss': '1.22914'}; time used = 0.025046110153198242s
epoch 200: {'train_loss': '1.23058'}; time used = 0.02601003646850586s
epoch 205: {'train_loss': '1.24062'}; time used = 0.022919893264770508s
epoch 210: {'train_loss': '1.22247'}; time used = 0.023705720901489258s
epoch 215: {'train_loss': '1.23472'}; time used = 0.027906417846679688s
epoch 220: {'train_loss': '1.23505'}; time used = 0.024862289428710938s
epoch 225: {'train_loss': '1.23527'}; time used = 0.023495197296142578s
epoch 230: {'train_loss': '1.22436'}; time used = 0.02418231964111328s
epoch 235: {'train_loss': '1.23002'}; time used = 0.024533748626708984s
epoch 240: {'train_loss': '1.22855'}; time used = 0.023512840270996094s
epoch 245: {'train_loss': '1.23210'}; time used = 0.024953842163085938s
epoch 250: {'train_loss': '1.22634'}; time used = 0.022275209426879883s
epoch 255: {'train_loss': '1.22576'}; time used = 0.02455306053161621s
epoch 260: {'train_loss': '1.23535'}; time used = 0.026845693588256836s
epoch 265: {'train_loss': '1.23352'}; time used = 0.024823665618896484s
epoch 270: {'train_loss': '1.23533'}; time used = 0.025679588317871094s
epoch 275: {'train_loss': '1.22424'}; time used = 0.026789426803588867s
epoch 280: {'train_loss': '1.22564'}; time used = 0.026683568954467773s
epoch 285: {'train_loss': '1.23068'}; time used = 0.026058673858642578s
epoch 290: {'train_loss': '1.23423'}; time used = 0.026192665100097656s
epoch 295: {'train_loss': '1.23650'}; time used = 0.026723623275756836s
epoch 300: {'train_loss': '1.23345'}; time used = 0.03486776351928711s
epoch 305: {'train_loss': '1.22703'}; time used = 0.023012161254882812s
epoch 310: {'train_loss': '1.23510'}; time used = 0.025264263153076172s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 5.464789867401123.
Training classifier using 20.00% nodes...
{'micro': 0.2911859713890171, 'macro': 0.07307726037007804, 'samples': 0.2911859713890171, 'weighted': 0.14320213663119688}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.72464'}; time used = 0.04586958885192871s
epoch 10: {'train_loss': '1.66588'}; time used = 0.02883744239807129s
epoch 15: {'train_loss': '1.63003'}; time used = 0.028339385986328125s
epoch 20: {'train_loss': '1.58155'}; time used = 0.037781715393066406s
epoch 25: {'train_loss': '1.55239'}; time used = 0.033960580825805664s
epoch 30: {'train_loss': '1.52077'}; time used = 0.05270743370056152s
epoch 35: {'train_loss': '1.49828'}; time used = 0.025751829147338867s
epoch 40: {'train_loss': '1.46950'}; time used = 0.025847911834716797s
epoch 45: {'train_loss': '1.45994'}; time used = 0.03780531883239746s
epoch 50: {'train_loss': '1.43342'}; time used = 0.02542853355407715s
epoch 55: {'train_loss': '1.42815'}; time used = 0.025099515914916992s
epoch 60: {'train_loss': '1.41492'}; time used = 0.033763885498046875s
epoch 65: {'train_loss': '1.40278'}; time used = 0.0260465145111084s
epoch 70: {'train_loss': '1.39321'}; time used = 0.03199958801269531s
epoch 75: {'train_loss': '1.38752'}; time used = 0.03561568260192871s
epoch 80: {'train_loss': '1.37513'}; time used = 0.025114059448242188s
epoch 85: {'train_loss': '1.36246'}; time used = 0.026125669479370117s
epoch 90: {'train_loss': '1.36229'}; time used = 0.025640010833740234s
epoch 95: {'train_loss': '1.35365'}; time used = 0.025243759155273438s
epoch 100: {'train_loss': '1.34917'}; time used = 0.03125882148742676s
epoch 105: {'train_loss': '1.34213'}; time used = 0.023890256881713867s
epoch 110: {'train_loss': '1.33865'}; time used = 0.03077983856201172s
epoch 115: {'train_loss': '1.33188'}; time used = 0.026330232620239258s
epoch 120: {'train_loss': '1.32918'}; time used = 0.027064800262451172s
epoch 125: {'train_loss': '1.32243'}; time used = 0.037096261978149414s
epoch 130: {'train_loss': '1.32002'}; time used = 0.02521681785583496s
epoch 135: {'train_loss': '1.31393'}; time used = 0.02602386474609375s
epoch 140: {'train_loss': '1.31469'}; time used = 0.026074647903442383s
epoch 145: {'train_loss': '1.30329'}; time used = 0.025986671447753906s
epoch 150: {'train_loss': '1.30781'}; time used = 0.034333229064941406s
epoch 155: {'train_loss': '1.30011'}; time used = 0.029633760452270508s
epoch 160: {'train_loss': '1.29276'}; time used = 0.029338598251342773s
epoch 165: {'train_loss': '1.29310'}; time used = 0.02506113052368164s
epoch 170: {'train_loss': '1.28985'}; time used = 0.02140951156616211s
epoch 175: {'train_loss': '1.28985'}; time used = 0.029948949813842773s
epoch 180: {'train_loss': '1.28128'}; time used = 0.02150726318359375s
epoch 185: {'train_loss': '1.28566'}; time used = 0.02249455451965332s
epoch 190: {'train_loss': '1.27669'}; time used = 0.021294355392456055s
epoch 195: {'train_loss': '1.27535'}; time used = 0.021503686904907227s
epoch 200: {'train_loss': '1.27225'}; time used = 0.03032398223876953s
epoch 205: {'train_loss': '1.27418'}; time used = 0.05867147445678711s
epoch 210: {'train_loss': '1.26324'}; time used = 0.01921701431274414s
epoch 215: {'train_loss': '1.26737'}; time used = 0.019834041595458984s
epoch 220: {'train_loss': '1.26474'}; time used = 0.027937650680541992s
epoch 225: {'train_loss': '1.26573'}; time used = 0.0186154842376709s
epoch 230: {'train_loss': '1.25567'}; time used = 0.02293539047241211s
epoch 235: {'train_loss': '1.25833'}; time used = 0.02360701560974121s
epoch 240: {'train_loss': '1.25655'}; time used = 0.022722959518432617s
epoch 245: {'train_loss': '1.25388'}; time used = 0.023526906967163086s
epoch 250: {'train_loss': '1.25100'}; time used = 0.047748565673828125s
epoch 255: {'train_loss': '1.24922'}; time used = 0.02922201156616211s
epoch 260: {'train_loss': '1.25475'}; time used = 0.02211761474609375s
epoch 265: {'train_loss': '1.25458'}; time used = 0.030377626419067383s
epoch 270: {'train_loss': '1.25619'}; time used = 0.027551889419555664s
epoch 275: {'train_loss': '1.24189'}; time used = 0.019698381423950195s
epoch 280: {'train_loss': '1.24583'}; time used = 0.019692182540893555s
epoch 285: {'train_loss': '1.24854'}; time used = 0.020211219787597656s
epoch 290: {'train_loss': '1.24902'}; time used = 0.020467281341552734s
epoch 295: {'train_loss': '1.24935'}; time used = 0.019652605056762695s
epoch 300: {'train_loss': '1.24851'}; time used = 0.030236244201660156s
epoch 305: {'train_loss': '1.24379'}; time used = 0.024625539779663086s
epoch 310: {'train_loss': '1.24898'}; time used = 0.02535104751586914s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 4.933344602584839.
Training classifier using 20.00% nodes...
{'micro': 0.2884171665897554, 'macro': 0.06807193855959415, 'samples': 0.2884171665897554, 'weighted': 0.13708092281065093}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.46735'}; time used = 0.03702950477600098s
epoch 10: {'train_loss': '1.35668'}; time used = 0.03326725959777832s
epoch 15: {'train_loss': '1.32547'}; time used = 0.02449178695678711s
epoch 20: {'train_loss': '1.29923'}; time used = 0.03337979316711426s
epoch 25: {'train_loss': '1.28288'}; time used = 0.0245361328125s
epoch 30: {'train_loss': '1.26040'}; time used = 0.022387981414794922s
epoch 35: {'train_loss': '1.25663'}; time used = 0.03368949890136719s
epoch 40: {'train_loss': '1.24885'}; time used = 0.03619885444641113s
epoch 45: {'train_loss': '1.24790'}; time used = 0.034331321716308594s
epoch 50: {'train_loss': '1.24188'}; time used = 0.04278087615966797s
epoch 55: {'train_loss': '1.24596'}; time used = 0.03815793991088867s
epoch 60: {'train_loss': '1.24858'}; time used = 0.06758737564086914s
epoch 65: {'train_loss': '1.24568'}; time used = 0.02538323402404785s
epoch 70: {'train_loss': '1.24655'}; time used = 0.033203125s
epoch 75: {'train_loss': '1.23997'}; time used = 0.02428436279296875s
epoch 80: {'train_loss': '1.24074'}; time used = 0.032466888427734375s
epoch 85: {'train_loss': '1.23499'}; time used = 0.024679899215698242s
epoch 90: {'train_loss': '1.23201'}; time used = 0.02418828010559082s
epoch 95: {'train_loss': '1.23090'}; time used = 0.0328829288482666s
epoch 100: {'train_loss': '1.23179'}; time used = 0.023768901824951172s
epoch 105: {'train_loss': '1.22699'}; time used = 0.0322566032409668s
epoch 110: {'train_loss': '1.22855'}; time used = 0.0248260498046875s
epoch 115: {'train_loss': '1.22862'}; time used = 0.030814647674560547s
epoch 120: {'train_loss': '1.22814'}; time used = 0.025620698928833008s
epoch 125: {'train_loss': '1.22684'}; time used = 0.033130645751953125s
epoch 130: {'train_loss': '1.22803'}; time used = 0.029041528701782227s
epoch 135: {'train_loss': '1.22938'}; time used = 0.022836923599243164s
epoch 140: {'train_loss': '1.22905'}; time used = 0.029743671417236328s
epoch 145: {'train_loss': '1.22009'}; time used = 0.02274155616760254s
epoch 150: {'train_loss': '1.23337'}; time used = 0.0309598445892334s
epoch 155: {'train_loss': '1.22862'}; time used = 0.022087574005126953s
epoch 160: {'train_loss': '1.22422'}; time used = 0.02295994758605957s
epoch 165: {'train_loss': '1.22698'}; time used = 0.030337810516357422s
epoch 170: {'train_loss': '1.22835'}; time used = 0.02241992950439453s
epoch 175: {'train_loss': '1.23392'}; time used = 0.03032684326171875s
epoch 180: {'train_loss': '1.22442'}; time used = 0.02134418487548828s
epoch 185: {'train_loss': '1.23199'}; time used = 0.023270368576049805s
epoch 190: {'train_loss': '1.23004'}; time used = 0.027669906616210938s
epoch 195: {'train_loss': '1.22661'}; time used = 0.02318859100341797s
epoch 200: {'train_loss': '1.22859'}; time used = 0.029572248458862305s
epoch 205: {'train_loss': '1.23722'}; time used = 0.02165055274963379s
epoch 210: {'train_loss': '1.22042'}; time used = 0.022667884826660156s
epoch 215: {'train_loss': '1.23075'}; time used = 0.028944015502929688s
epoch 220: {'train_loss': '1.22925'}; time used = 0.02227640151977539s
epoch 225: {'train_loss': '1.23267'}; time used = 0.029731035232543945s
epoch 230: {'train_loss': '1.22277'}; time used = 0.022294998168945312s
epoch 235: {'train_loss': '1.22789'}; time used = 0.02634453773498535s
epoch 240: {'train_loss': '1.22686'}; time used = 0.031194448471069336s
epoch 245: {'train_loss': '1.22865'}; time used = 0.02312755584716797s
epoch 250: {'train_loss': '1.22364'}; time used = 0.026126861572265625s
epoch 255: {'train_loss': '1.22335'}; time used = 0.027323007583618164s
epoch 260: {'train_loss': '1.23253'}; time used = 0.0234377384185791s
epoch 265: {'train_loss': '1.23205'}; time used = 0.03170299530029297s
epoch 270: {'train_loss': '1.23328'}; time used = 0.023387908935546875s
epoch 275: {'train_loss': '1.21900'}; time used = 0.030689716339111328s
epoch 280: {'train_loss': '1.22269'}; time used = 0.023787975311279297s
epoch 285: {'train_loss': '1.22768'}; time used = 0.023300647735595703s
epoch 290: {'train_loss': '1.23039'}; time used = 0.030182600021362305s
epoch 295: {'train_loss': '1.23216'}; time used = 0.023842573165893555s
epoch 300: {'train_loss': '1.23103'}; time used = 0.024921417236328125s
epoch 305: {'train_loss': '1.22367'}; time used = 0.054669857025146484s
epoch 310: {'train_loss': '1.23138'}; time used = 0.023510456085205078s
epoch 315: {'train_loss': '1.22968'}; time used = 0.033808231353759766s
epoch 320: {'train_loss': '1.22921'}; time used = 0.024111032485961914s
epoch 325: {'train_loss': '1.23148'}; time used = 0.024162769317626953s
epoch 330: {'train_loss': '1.22797'}; time used = 0.030674219131469727s
epoch 335: {'train_loss': '1.22958'}; time used = 0.02454662322998047s
epoch 340: {'train_loss': '1.23366'}; time used = 0.024546146392822266s
epoch 345: {'train_loss': '1.22866'}; time used = 0.03133416175842285s
epoch 350: {'train_loss': '1.22718'}; time used = 0.024271249771118164s
epoch 355: {'train_loss': '1.22388'}; time used = 0.027738094329833984s
epoch 360: {'train_loss': '1.22881'}; time used = 0.032706499099731445s
epoch 365: {'train_loss': '1.22539'}; time used = 0.02526068687438965s
epoch 370: {'train_loss': '1.22613'}; time used = 0.024827241897583008s
epoch 375: {'train_loss': '1.22398'}; time used = 0.030797243118286133s
epoch 380: {'train_loss': '1.22630'}; time used = 0.02512669563293457s
epoch 385: {'train_loss': '1.23101'}; time used = 0.024574995040893555s
epoch 390: {'train_loss': '1.23018'}; time used = 0.0346827507019043s
epoch 395: {'train_loss': '1.22879'}; time used = 0.025663375854492188s
epoch 400: {'train_loss': '1.22627'}; time used = 0.025151729583740234s
epoch 405: {'train_loss': '1.23449'}; time used = 0.024477720260620117s
epoch 410: {'train_loss': '1.22626'}; time used = 0.024930238723754883s
epoch 415: {'train_loss': '1.23228'}; time used = 0.03130173683166504s
epoch 420: {'train_loss': '1.22836'}; time used = 0.024545669555664062s
epoch 425: {'train_loss': '1.22899'}; time used = 0.02510833740234375s
epoch 430: {'train_loss': '1.22556'}; time used = 0.031078100204467773s
epoch 435: {'train_loss': '1.22728'}; time used = 0.025004863739013672s
epoch 440: {'train_loss': '1.22796'}; time used = 0.024718284606933594s
epoch 445: {'train_loss': '1.22821'}; time used = 0.024858951568603516s
epoch 450: {'train_loss': '1.23455'}; time used = 0.0324397087097168s
epoch 455: {'train_loss': '1.23080'}; time used = 0.024487972259521484s
epoch 460: {'train_loss': '1.22825'}; time used = 0.024947404861450195s
epoch 465: {'train_loss': '1.22615'}; time used = 0.03397870063781738s
epoch 470: {'train_loss': '1.22912'}; time used = 0.027237415313720703s
epoch 475: {'train_loss': '1.22932'}; time used = 0.02354598045349121s
epoch 480: {'train_loss': '1.22352'}; time used = 0.031795501708984375s
epoch 485: {'train_loss': '1.22317'}; time used = 0.02663445472717285s
epoch 490: {'train_loss': '1.23052'}; time used = 0.03478193283081055s
epoch 495: {'train_loss': '1.21942'}; time used = 0.049509525299072266s
epoch 500: {'train_loss': '1.22877'}; time used = 0.024024009704589844s
Finished training. Time used = 6.065928220748901.
Training classifier using 20.00% nodes...
{'micro': 0.28887863405629904, 'macro': 0.0720163622360754, 'samples': 0.28887863405629904, 'weighted': 0.14169724223080254}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.37492'}; time used = 0.05714893341064453s
epoch 10: {'train_loss': '1.32405'}; time used = 0.023979902267456055s
epoch 15: {'train_loss': '1.28415'}; time used = 0.03014659881591797s
epoch 20: {'train_loss': '1.25824'}; time used = 0.02920055389404297s
epoch 25: {'train_loss': '1.25545'}; time used = 0.03227686882019043s
epoch 30: {'train_loss': '1.24337'}; time used = 0.024704694747924805s
epoch 35: {'train_loss': '1.23960'}; time used = 0.019199848175048828s
epoch 40: {'train_loss': '1.23473'}; time used = 0.019616365432739258s
epoch 45: {'train_loss': '1.23406'}; time used = 0.0191805362701416s
epoch 50: {'train_loss': '1.22613'}; time used = 0.01926445960998535s
epoch 55: {'train_loss': '1.23187'}; time used = 0.019277334213256836s
epoch 60: {'train_loss': '1.23688'}; time used = 0.019160747528076172s
epoch 65: {'train_loss': '1.23348'}; time used = 0.01911020278930664s
epoch 70: {'train_loss': '1.23489'}; time used = 0.019262075424194336s
epoch 75: {'train_loss': '1.23117'}; time used = 0.01927018165588379s
epoch 80: {'train_loss': '1.23275'}; time used = 0.019377708435058594s
epoch 85: {'train_loss': '1.22838'}; time used = 0.019101619720458984s
epoch 90: {'train_loss': '1.22626'}; time used = 0.019050121307373047s
epoch 95: {'train_loss': '1.22779'}; time used = 0.019346952438354492s
epoch 100: {'train_loss': '1.22891'}; time used = 0.01931619644165039s
epoch 105: {'train_loss': '1.22617'}; time used = 0.01914691925048828s
epoch 110: {'train_loss': '1.22880'}; time used = 0.0191500186920166s
epoch 115: {'train_loss': '1.22863'}; time used = 0.019209623336791992s
epoch 120: {'train_loss': '1.22889'}; time used = 0.019263267517089844s
epoch 125: {'train_loss': '1.22774'}; time used = 0.019131898880004883s
epoch 130: {'train_loss': '1.22960'}; time used = 0.01904916763305664s
epoch 135: {'train_loss': '1.23025'}; time used = 0.019147634506225586s
epoch 140: {'train_loss': '1.23068'}; time used = 0.01939988136291504s
epoch 145: {'train_loss': '1.22078'}; time used = 0.019290924072265625s
epoch 150: {'train_loss': '1.23414'}; time used = 0.019170284271240234s
epoch 155: {'train_loss': '1.23072'}; time used = 0.0191195011138916s
epoch 160: {'train_loss': '1.22640'}; time used = 0.020377159118652344s
epoch 165: {'train_loss': '1.22781'}; time used = 0.021797895431518555s
epoch 170: {'train_loss': '1.23026'}; time used = 0.021001338958740234s
epoch 175: {'train_loss': '1.23583'}; time used = 0.021051883697509766s
epoch 180: {'train_loss': '1.22584'}; time used = 0.0232698917388916s
epoch 185: {'train_loss': '1.23413'}; time used = 0.02212667465209961s
epoch 190: {'train_loss': '1.23089'}; time used = 0.0214385986328125s
epoch 195: {'train_loss': '1.22823'}; time used = 0.019644737243652344s
epoch 200: {'train_loss': '1.22992'}; time used = 0.04230022430419922s
epoch 205: {'train_loss': '1.23954'}; time used = 0.019579172134399414s
epoch 210: {'train_loss': '1.22073'}; time used = 0.019583463668823242s
epoch 215: {'train_loss': '1.23223'}; time used = 0.01957106590270996s
epoch 220: {'train_loss': '1.23137'}; time used = 0.034635066986083984s
epoch 225: {'train_loss': '1.23459'}; time used = 0.019699811935424805s
epoch 230: {'train_loss': '1.22398'}; time used = 0.021086931228637695s
epoch 235: {'train_loss': '1.22878'}; time used = 0.021350860595703125s
epoch 240: {'train_loss': '1.22766'}; time used = 0.01951456069946289s
epoch 245: {'train_loss': '1.23009'}; time used = 0.022044658660888672s
epoch 250: {'train_loss': '1.22534'}; time used = 0.024014711380004883s
epoch 255: {'train_loss': '1.22442'}; time used = 0.02291417121887207s
epoch 260: {'train_loss': '1.23456'}; time used = 0.023872852325439453s
epoch 265: {'train_loss': '1.23269'}; time used = 0.03835773468017578s
epoch 270: {'train_loss': '1.23501'}; time used = 0.02057957649230957s
epoch 275: {'train_loss': '1.22019'}; time used = 0.020282745361328125s
epoch 280: {'train_loss': '1.22406'}; time used = 0.020412445068359375s
epoch 285: {'train_loss': '1.22838'}; time used = 0.022982358932495117s
epoch 290: {'train_loss': '1.23292'}; time used = 0.020427942276000977s
epoch 295: {'train_loss': '1.23384'}; time used = 0.022896528244018555s
epoch 300: {'train_loss': '1.23224'}; time used = 0.03255057334899902s
epoch 305: {'train_loss': '1.22558'}; time used = 0.019133329391479492s
epoch 310: {'train_loss': '1.23335'}; time used = 0.020007610321044922s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 6.269249677658081.
Training classifier using 20.00% nodes...
{'micro': 0.28887863405629904, 'macro': 0.07144741381552987, 'samples': 0.28887863405629904, 'weighted': 0.14112591039073677}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.35566'}; time used = 0.09033870697021484s
epoch 10: {'train_loss': '1.30508'}; time used = 0.02418375015258789s
epoch 15: {'train_loss': '1.26292'}; time used = 0.03232216835021973s
epoch 20: {'train_loss': '1.24540'}; time used = 0.033416032791137695s
epoch 25: {'train_loss': '1.24691'}; time used = 0.03272533416748047s
epoch 30: {'train_loss': '1.23603'}; time used = 0.023006439208984375s
epoch 35: {'train_loss': '1.23660'}; time used = 0.023853778839111328s
epoch 40: {'train_loss': '1.23158'}; time used = 0.031542062759399414s
epoch 45: {'train_loss': '1.23388'}; time used = 0.02368760108947754s
epoch 50: {'train_loss': '1.22572'}; time used = 0.028416156768798828s
epoch 55: {'train_loss': '1.23276'}; time used = 0.02424931526184082s
epoch 60: {'train_loss': '1.23808'}; time used = 0.02261185646057129s
epoch 65: {'train_loss': '1.23500'}; time used = 0.03314685821533203s
epoch 70: {'train_loss': '1.23600'}; time used = 0.023918628692626953s
epoch 75: {'train_loss': '1.23151'}; time used = 0.033490657806396484s
epoch 80: {'train_loss': '1.23376'}; time used = 0.025159835815429688s
epoch 85: {'train_loss': '1.22978'}; time used = 0.037784576416015625s
epoch 90: {'train_loss': '1.22786'}; time used = 0.024693012237548828s
epoch 95: {'train_loss': '1.22920'}; time used = 0.031093835830688477s
epoch 100: {'train_loss': '1.23106'}; time used = 0.024405956268310547s
epoch 105: {'train_loss': '1.22664'}; time used = 0.025665998458862305s
epoch 110: {'train_loss': '1.23047'}; time used = 0.02881932258605957s
epoch 115: {'train_loss': '1.22999'}; time used = 0.023598670959472656s
epoch 120: {'train_loss': '1.22926'}; time used = 0.0332484245300293s
epoch 125: {'train_loss': '1.22890'}; time used = 0.024031639099121094s
epoch 130: {'train_loss': '1.23003'}; time used = 0.03290581703186035s
epoch 135: {'train_loss': '1.23071'}; time used = 0.024416685104370117s
epoch 140: {'train_loss': '1.23093'}; time used = 0.03301215171813965s
epoch 145: {'train_loss': '1.22188'}; time used = 0.024059057235717773s
epoch 150: {'train_loss': '1.23479'}; time used = 0.02410745620727539s
epoch 155: {'train_loss': '1.23169'}; time used = 0.03148341178894043s
epoch 160: {'train_loss': '1.22792'}; time used = 0.029430389404296875s
epoch 165: {'train_loss': '1.22868'}; time used = 0.03278303146362305s
epoch 170: {'train_loss': '1.23092'}; time used = 0.024066925048828125s
epoch 175: {'train_loss': '1.23717'}; time used = 0.03425431251525879s
epoch 180: {'train_loss': '1.22632'}; time used = 0.035537004470825195s
epoch 185: {'train_loss': '1.23535'}; time used = 0.024209260940551758s
epoch 190: {'train_loss': '1.23285'}; time used = 0.025628089904785156s
epoch 195: {'train_loss': '1.22914'}; time used = 0.032167673110961914s
epoch 200: {'train_loss': '1.23058'}; time used = 0.025738239288330078s
epoch 205: {'train_loss': '1.24062'}; time used = 0.02452254295349121s
epoch 210: {'train_loss': '1.22247'}; time used = 0.03313136100769043s
epoch 215: {'train_loss': '1.23472'}; time used = 0.02461862564086914s
epoch 220: {'train_loss': '1.23505'}; time used = 0.024785757064819336s
epoch 225: {'train_loss': '1.23527'}; time used = 0.030712604522705078s
epoch 230: {'train_loss': '1.22436'}; time used = 0.03475522994995117s
epoch 235: {'train_loss': '1.23002'}; time used = 0.022652387619018555s
epoch 240: {'train_loss': '1.22855'}; time used = 0.03174614906311035s
epoch 245: {'train_loss': '1.23210'}; time used = 0.024755477905273438s
epoch 250: {'train_loss': '1.22634'}; time used = 0.02515578269958496s
epoch 255: {'train_loss': '1.22576'}; time used = 0.024263381958007812s
epoch 260: {'train_loss': '1.23535'}; time used = 0.0329744815826416s
epoch 265: {'train_loss': '1.23352'}; time used = 0.025053977966308594s
epoch 270: {'train_loss': '1.23533'}; time used = 0.02548813819885254s
epoch 275: {'train_loss': '1.22424'}; time used = 0.0335383415222168s
epoch 280: {'train_loss': '1.22564'}; time used = 0.025021076202392578s
epoch 285: {'train_loss': '1.23068'}; time used = 0.024248123168945312s
epoch 290: {'train_loss': '1.23423'}; time used = 0.032793283462524414s
epoch 295: {'train_loss': '1.23650'}; time used = 0.024779558181762695s
epoch 300: {'train_loss': '1.23345'}; time used = 0.025238037109375s
epoch 305: {'train_loss': '1.22703'}; time used = 0.035489797592163086s
epoch 310: {'train_loss': '1.23510'}; time used = 0.025484323501586914s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 5.013165235519409.
Training classifier using 20.00% nodes...
{'micro': 0.2911859713890171, 'macro': 0.07307726037007804, 'samples': 0.2911859713890171, 'weighted': 0.14320213663119688}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.72464'}; time used = 0.05427193641662598s
epoch 10: {'train_loss': '1.66588'}; time used = 0.020303010940551758s
epoch 15: {'train_loss': '1.63003'}; time used = 0.02057480812072754s
epoch 20: {'train_loss': '1.58155'}; time used = 0.020436525344848633s
epoch 25: {'train_loss': '1.55239'}; time used = 0.02015376091003418s
epoch 30: {'train_loss': '1.52077'}; time used = 0.020827054977416992s
epoch 35: {'train_loss': '1.49828'}; time used = 0.01953887939453125s
epoch 40: {'train_loss': '1.46950'}; time used = 0.019565343856811523s
epoch 45: {'train_loss': '1.45994'}; time used = 0.019693851470947266s
epoch 50: {'train_loss': '1.43342'}; time used = 0.019481420516967773s
epoch 55: {'train_loss': '1.42815'}; time used = 0.019739389419555664s
epoch 60: {'train_loss': '1.41492'}; time used = 0.025352954864501953s
epoch 65: {'train_loss': '1.40278'}; time used = 0.05487203598022461s
epoch 70: {'train_loss': '1.39321'}; time used = 0.019884347915649414s
epoch 75: {'train_loss': '1.38752'}; time used = 0.019753694534301758s
epoch 80: {'train_loss': '1.37513'}; time used = 0.01980900764465332s
epoch 85: {'train_loss': '1.36246'}; time used = 0.020053625106811523s
epoch 90: {'train_loss': '1.36229'}; time used = 0.03403425216674805s
epoch 95: {'train_loss': '1.35365'}; time used = 0.034546852111816406s
epoch 100: {'train_loss': '1.34917'}; time used = 0.029717683792114258s
epoch 105: {'train_loss': '1.34213'}; time used = 0.02957606315612793s
epoch 110: {'train_loss': '1.33865'}; time used = 0.03519105911254883s
epoch 115: {'train_loss': '1.33188'}; time used = 0.04289841651916504s
epoch 120: {'train_loss': '1.32918'}; time used = 0.03411054611206055s
epoch 125: {'train_loss': '1.32243'}; time used = 0.023382902145385742s
epoch 130: {'train_loss': '1.32002'}; time used = 0.023495197296142578s
epoch 135: {'train_loss': '1.31393'}; time used = 0.023913860321044922s
epoch 140: {'train_loss': '1.31469'}; time used = 0.023697853088378906s
epoch 145: {'train_loss': '1.30329'}; time used = 0.021900177001953125s
epoch 150: {'train_loss': '1.30781'}; time used = 0.02165365219116211s
epoch 155: {'train_loss': '1.30011'}; time used = 0.021534442901611328s
epoch 160: {'train_loss': '1.29276'}; time used = 0.02170872688293457s
epoch 165: {'train_loss': '1.29310'}; time used = 0.023303508758544922s
epoch 170: {'train_loss': '1.28985'}; time used = 0.023988962173461914s
epoch 175: {'train_loss': '1.28985'}; time used = 0.02356696128845215s
epoch 180: {'train_loss': '1.28128'}; time used = 0.023352384567260742s
epoch 185: {'train_loss': '1.28566'}; time used = 0.02355337142944336s
epoch 190: {'train_loss': '1.27669'}; time used = 0.023631572723388672s
epoch 195: {'train_loss': '1.27535'}; time used = 0.023469209671020508s
epoch 200: {'train_loss': '1.27225'}; time used = 0.023454904556274414s
epoch 205: {'train_loss': '1.27418'}; time used = 0.022837400436401367s
epoch 210: {'train_loss': '1.26324'}; time used = 0.01726245880126953s
epoch 215: {'train_loss': '1.26737'}; time used = 0.017938613891601562s
epoch 220: {'train_loss': '1.26474'}; time used = 0.017176389694213867s
epoch 225: {'train_loss': '1.26573'}; time used = 0.03174400329589844s
epoch 230: {'train_loss': '1.25567'}; time used = 0.042383670806884766s
epoch 235: {'train_loss': '1.25833'}; time used = 0.022173643112182617s
epoch 240: {'train_loss': '1.25655'}; time used = 0.020714521408081055s
epoch 245: {'train_loss': '1.25388'}; time used = 0.020882129669189453s
epoch 250: {'train_loss': '1.25100'}; time used = 0.020610809326171875s
epoch 255: {'train_loss': '1.24922'}; time used = 0.020615577697753906s
epoch 260: {'train_loss': '1.25475'}; time used = 0.02073383331298828s
epoch 265: {'train_loss': '1.25458'}; time used = 0.020766258239746094s
epoch 270: {'train_loss': '1.25619'}; time used = 0.020768404006958008s
epoch 275: {'train_loss': '1.24189'}; time used = 0.0207979679107666s
epoch 280: {'train_loss': '1.24583'}; time used = 0.020726919174194336s
epoch 285: {'train_loss': '1.24854'}; time used = 0.020595073699951172s
epoch 290: {'train_loss': '1.24902'}; time used = 0.02061939239501953s
epoch 295: {'train_loss': '1.24935'}; time used = 0.02067112922668457s
epoch 300: {'train_loss': '1.24851'}; time used = 0.020590782165527344s
epoch 305: {'train_loss': '1.24379'}; time used = 0.020621776580810547s
epoch 310: {'train_loss': '1.24898'}; time used = 0.02062249183654785s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 7.127552509307861.
Training classifier using 20.00% nodes...
{'micro': 0.2884171665897554, 'macro': 0.06807193855959415, 'samples': 0.2884171665897554, 'weighted': 0.13708092281065093}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.46735'}; time used = 0.04321742057800293s
epoch 10: {'train_loss': '1.35668'}; time used = 0.02504110336303711s
epoch 15: {'train_loss': '1.32547'}; time used = 0.035454511642456055s
epoch 20: {'train_loss': '1.29923'}; time used = 0.02419877052307129s
epoch 25: {'train_loss': '1.28288'}; time used = 0.02532505989074707s
epoch 30: {'train_loss': '1.26040'}; time used = 0.03792524337768555s
epoch 35: {'train_loss': '1.25663'}; time used = 0.026610851287841797s
epoch 40: {'train_loss': '1.24885'}; time used = 0.031047821044921875s
epoch 45: {'train_loss': '1.24790'}; time used = 0.02542400360107422s
epoch 50: {'train_loss': '1.24188'}; time used = 0.034050703048706055s
epoch 55: {'train_loss': '1.24596'}; time used = 0.025322914123535156s
epoch 60: {'train_loss': '1.24858'}; time used = 0.033475637435913086s
epoch 65: {'train_loss': '1.24568'}; time used = 0.025939464569091797s
epoch 70: {'train_loss': '1.24655'}; time used = 0.025220155715942383s
epoch 75: {'train_loss': '1.23997'}; time used = 0.0322270393371582s
epoch 80: {'train_loss': '1.24074'}; time used = 0.024676799774169922s
epoch 85: {'train_loss': '1.23499'}; time used = 0.034032583236694336s
epoch 90: {'train_loss': '1.23201'}; time used = 0.025819063186645508s
epoch 95: {'train_loss': '1.23090'}; time used = 0.025041818618774414s
epoch 100: {'train_loss': '1.23179'}; time used = 0.03908038139343262s
epoch 105: {'train_loss': '1.22699'}; time used = 0.02335953712463379s
epoch 110: {'train_loss': '1.22855'}; time used = 0.03314924240112305s
epoch 115: {'train_loss': '1.22862'}; time used = 0.0243532657623291s
epoch 120: {'train_loss': '1.22814'}; time used = 0.03004002571105957s
epoch 125: {'train_loss': '1.22684'}; time used = 0.02497267723083496s
epoch 130: {'train_loss': '1.22803'}; time used = 0.033559560775756836s
epoch 135: {'train_loss': '1.22938'}; time used = 0.02480769157409668s
epoch 140: {'train_loss': '1.22905'}; time used = 0.024755239486694336s
epoch 145: {'train_loss': '1.22009'}; time used = 0.03214311599731445s
epoch 150: {'train_loss': '1.23337'}; time used = 0.024752140045166016s
epoch 155: {'train_loss': '1.22862'}; time used = 0.03097081184387207s
epoch 160: {'train_loss': '1.22422'}; time used = 0.024549484252929688s
epoch 165: {'train_loss': '1.22698'}; time used = 0.02467632293701172s
epoch 170: {'train_loss': '1.22835'}; time used = 0.03259444236755371s
epoch 175: {'train_loss': '1.23392'}; time used = 0.03191733360290527s
epoch 180: {'train_loss': '1.22442'}; time used = 0.030521631240844727s
epoch 185: {'train_loss': '1.23199'}; time used = 0.02517223358154297s
epoch 190: {'train_loss': '1.23004'}; time used = 0.02471637725830078s
epoch 195: {'train_loss': '1.22661'}; time used = 0.03256106376647949s
epoch 200: {'train_loss': '1.22859'}; time used = 0.02459859848022461s
epoch 205: {'train_loss': '1.23722'}; time used = 0.03172636032104492s
epoch 210: {'train_loss': '1.22042'}; time used = 0.024587631225585938s
epoch 215: {'train_loss': '1.23075'}; time used = 0.024785757064819336s
epoch 220: {'train_loss': '1.22925'}; time used = 0.03307819366455078s
epoch 225: {'train_loss': '1.23267'}; time used = 0.025111913681030273s
epoch 230: {'train_loss': '1.22277'}; time used = 0.0321958065032959s
epoch 235: {'train_loss': '1.22789'}; time used = 0.02542853355407715s
epoch 240: {'train_loss': '1.22686'}; time used = 0.0326540470123291s
epoch 245: {'train_loss': '1.22865'}; time used = 0.025762319564819336s
epoch 250: {'train_loss': '1.22364'}; time used = 0.024837732315063477s
epoch 255: {'train_loss': '1.22335'}; time used = 0.06985092163085938s
epoch 260: {'train_loss': '1.23253'}; time used = 0.03026747703552246s
epoch 265: {'train_loss': '1.23205'}; time used = 0.022721052169799805s
epoch 270: {'train_loss': '1.23328'}; time used = 0.02389240264892578s
epoch 275: {'train_loss': '1.21900'}; time used = 0.032331228256225586s
epoch 280: {'train_loss': '1.22269'}; time used = 0.02769923210144043s
epoch 285: {'train_loss': '1.22768'}; time used = 0.028583765029907227s
epoch 290: {'train_loss': '1.23039'}; time used = 0.024689674377441406s
epoch 295: {'train_loss': '1.23216'}; time used = 0.03172945976257324s
epoch 300: {'train_loss': '1.23103'}; time used = 0.03587532043457031s
epoch 305: {'train_loss': '1.22367'}; time used = 0.03212475776672363s
epoch 310: {'train_loss': '1.23138'}; time used = 0.02437138557434082s
epoch 315: {'train_loss': '1.22968'}; time used = 0.024259328842163086s
epoch 320: {'train_loss': '1.22921'}; time used = 0.033919572830200195s
epoch 325: {'train_loss': '1.23148'}; time used = 0.027509689331054688s
epoch 330: {'train_loss': '1.22797'}; time used = 0.03197908401489258s
epoch 335: {'train_loss': '1.22958'}; time used = 0.02410435676574707s
epoch 340: {'train_loss': '1.23366'}; time used = 0.031403541564941406s
epoch 345: {'train_loss': '1.22866'}; time used = 0.030512094497680664s
epoch 350: {'train_loss': '1.22718'}; time used = 0.02942633628845215s
epoch 355: {'train_loss': '1.22388'}; time used = 0.027803659439086914s
epoch 360: {'train_loss': '1.22881'}; time used = 0.03461289405822754s
epoch 365: {'train_loss': '1.22539'}; time used = 0.02732396125793457s
epoch 370: {'train_loss': '1.22613'}; time used = 0.03491330146789551s
epoch 375: {'train_loss': '1.22398'}; time used = 0.027758359909057617s
epoch 380: {'train_loss': '1.22630'}; time used = 0.03436589241027832s
epoch 385: {'train_loss': '1.23101'}; time used = 0.026688337326049805s
epoch 390: {'train_loss': '1.23018'}; time used = 0.033536672592163086s
epoch 395: {'train_loss': '1.22879'}; time used = 0.027708768844604492s
epoch 400: {'train_loss': '1.22627'}; time used = 0.035424232482910156s
epoch 405: {'train_loss': '1.23449'}; time used = 0.027296781539916992s
epoch 410: {'train_loss': '1.22626'}; time used = 0.0410304069519043s
epoch 415: {'train_loss': '1.23228'}; time used = 0.02745509147644043s
epoch 420: {'train_loss': '1.22836'}; time used = 0.03166937828063965s
epoch 425: {'train_loss': '1.22899'}; time used = 0.024363040924072266s
epoch 430: {'train_loss': '1.22556'}; time used = 0.030921220779418945s
epoch 435: {'train_loss': '1.22728'}; time used = 0.025017499923706055s
epoch 440: {'train_loss': '1.22796'}; time used = 0.02617955207824707s
epoch 445: {'train_loss': '1.22821'}; time used = 0.02832961082458496s
epoch 450: {'train_loss': '1.23455'}; time used = 0.023783445358276367s
epoch 455: {'train_loss': '1.23080'}; time used = 0.029361724853515625s
epoch 460: {'train_loss': '1.22825'}; time used = 0.021528244018554688s
epoch 465: {'train_loss': '1.22615'}; time used = 0.029626131057739258s
epoch 470: {'train_loss': '1.22912'}; time used = 0.023274898529052734s
epoch 475: {'train_loss': '1.22932'}; time used = 0.023422718048095703s
epoch 480: {'train_loss': '1.22352'}; time used = 0.030840158462524414s
epoch 485: {'train_loss': '1.22317'}; time used = 0.030120849609375s
epoch 490: {'train_loss': '1.23052'}; time used = 0.03174138069152832s
epoch 495: {'train_loss': '1.21942'}; time used = 0.02407050132751465s
epoch 500: {'train_loss': '1.22877'}; time used = 0.03147411346435547s
Finished training. Time used = 5.670036792755127.
Training classifier using 20.00% nodes...
{'micro': 0.28887863405629904, 'macro': 0.0720163622360754, 'samples': 0.28887863405629904, 'weighted': 0.14169724223080254}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.35566'}; time used = 0.09733748435974121s
epoch 10: {'train_loss': '1.30508'}; time used = 0.027281522750854492s
epoch 15: {'train_loss': '1.26292'}; time used = 0.027816057205200195s
epoch 20: {'train_loss': '1.24540'}; time used = 0.03933119773864746s
epoch 25: {'train_loss': '1.24691'}; time used = 0.02726292610168457s
epoch 30: {'train_loss': '1.23603'}; time used = 0.035772085189819336s
epoch 35: {'train_loss': '1.23660'}; time used = 0.029067039489746094s
epoch 40: {'train_loss': '1.23158'}; time used = 0.03055119514465332s
epoch 45: {'train_loss': '1.23388'}; time used = 0.04412126541137695s
epoch 50: {'train_loss': '1.22572'}; time used = 0.026127099990844727s
epoch 55: {'train_loss': '1.23276'}; time used = 0.030614614486694336s
epoch 60: {'train_loss': '1.23808'}; time used = 0.030750513076782227s
epoch 65: {'train_loss': '1.23500'}; time used = 0.0342097282409668s
epoch 70: {'train_loss': '1.23600'}; time used = 0.023937702178955078s
epoch 75: {'train_loss': '1.23151'}; time used = 0.026187419891357422s
epoch 80: {'train_loss': '1.23376'}; time used = 0.030098438262939453s
epoch 85: {'train_loss': '1.22978'}; time used = 0.022770166397094727s
epoch 90: {'train_loss': '1.22786'}; time used = 0.023732423782348633s
epoch 95: {'train_loss': '1.22920'}; time used = 0.03478860855102539s
epoch 100: {'train_loss': '1.23106'}; time used = 0.026535987854003906s
epoch 105: {'train_loss': '1.22664'}; time used = 0.05363011360168457s
epoch 110: {'train_loss': '1.23047'}; time used = 0.02490854263305664s
epoch 115: {'train_loss': '1.22999'}; time used = 0.024587392807006836s
epoch 120: {'train_loss': '1.22926'}; time used = 0.06232905387878418s
epoch 125: {'train_loss': '1.22890'}; time used = 0.03318905830383301s
epoch 130: {'train_loss': '1.23003'}; time used = 0.0236966609954834s
epoch 135: {'train_loss': '1.23071'}; time used = 0.024672985076904297s
epoch 140: {'train_loss': '1.23093'}; time used = 0.024129390716552734s
epoch 145: {'train_loss': '1.22188'}; time used = 0.023905277252197266s
epoch 150: {'train_loss': '1.23479'}; time used = 0.022030115127563477s
epoch 155: {'train_loss': '1.23169'}; time used = 0.023493051528930664s
epoch 160: {'train_loss': '1.22792'}; time used = 0.024132966995239258s
epoch 165: {'train_loss': '1.22868'}; time used = 0.023245811462402344s
epoch 170: {'train_loss': '1.23092'}; time used = 0.022961854934692383s
epoch 175: {'train_loss': '1.23717'}; time used = 0.02487349510192871s
epoch 180: {'train_loss': '1.22632'}; time used = 0.02702021598815918s
epoch 185: {'train_loss': '1.23535'}; time used = 0.03634929656982422s
epoch 190: {'train_loss': '1.23285'}; time used = 0.041567087173461914s
epoch 195: {'train_loss': '1.22914'}; time used = 0.0344393253326416s
epoch 200: {'train_loss': '1.23058'}; time used = 0.030039548873901367s
epoch 205: {'train_loss': '1.24062'}; time used = 0.030807971954345703s
epoch 210: {'train_loss': '1.22247'}; time used = 0.037949562072753906s
epoch 215: {'train_loss': '1.23472'}; time used = 0.029439687728881836s
epoch 220: {'train_loss': '1.23505'}; time used = 0.03339886665344238s
epoch 225: {'train_loss': '1.23527'}; time used = 0.023236751556396484s
epoch 230: {'train_loss': '1.22436'}; time used = 0.02724289894104004s
epoch 235: {'train_loss': '1.23002'}; time used = 0.02481365203857422s
epoch 240: {'train_loss': '1.22855'}; time used = 0.028067588806152344s
epoch 245: {'train_loss': '1.23210'}; time used = 0.05378150939941406s
epoch 250: {'train_loss': '1.22634'}; time used = 0.023525238037109375s
epoch 255: {'train_loss': '1.22576'}; time used = 0.02020740509033203s
epoch 260: {'train_loss': '1.23535'}; time used = 0.020377397537231445s
epoch 265: {'train_loss': '1.23352'}; time used = 0.03175616264343262s
epoch 270: {'train_loss': '1.23533'}; time used = 0.027308225631713867s
epoch 275: {'train_loss': '1.22424'}; time used = 0.03986549377441406s
epoch 280: {'train_loss': '1.22564'}; time used = 0.021739959716796875s
epoch 285: {'train_loss': '1.23068'}; time used = 0.021777868270874023s
epoch 290: {'train_loss': '1.23423'}; time used = 0.02178478240966797s
epoch 295: {'train_loss': '1.23650'}; time used = 0.04430341720581055s
epoch 300: {'train_loss': '1.23345'}; time used = 0.0372314453125s
epoch 305: {'train_loss': '1.22703'}; time used = 0.02273726463317871s
epoch 310: {'train_loss': '1.23510'}; time used = 0.03470134735107422s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 5.85598349571228.
Training classifier using 20.00% nodes...
{'micro': 0.2911859713890171, 'macro': 0.07307726037007804, 'samples': 0.2911859713890171, 'weighted': 0.14320213663119688}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.72464'}; time used = 0.03384566307067871s
epoch 10: {'train_loss': '1.66588'}; time used = 0.03573036193847656s
epoch 15: {'train_loss': '1.63003'}; time used = 0.030177593231201172s
epoch 20: {'train_loss': '1.58155'}; time used = 0.024507522583007812s
epoch 25: {'train_loss': '1.55239'}; time used = 0.034894704818725586s
epoch 30: {'train_loss': '1.52077'}; time used = 0.02414417266845703s
epoch 35: {'train_loss': '1.49828'}; time used = 0.025900840759277344s
epoch 40: {'train_loss': '1.46950'}; time used = 0.034249067306518555s
epoch 45: {'train_loss': '1.45994'}; time used = 0.025756120681762695s
epoch 50: {'train_loss': '1.43342'}; time used = 0.025421619415283203s
epoch 55: {'train_loss': '1.42815'}; time used = 0.03321051597595215s
epoch 60: {'train_loss': '1.41492'}; time used = 0.025617599487304688s
epoch 65: {'train_loss': '1.40278'}; time used = 0.03279232978820801s
epoch 70: {'train_loss': '1.39321'}; time used = 0.026346683502197266s
epoch 75: {'train_loss': '1.38752'}; time used = 0.03319239616394043s
epoch 80: {'train_loss': '1.37513'}; time used = 0.025531530380249023s
epoch 85: {'train_loss': '1.36246'}; time used = 0.03296923637390137s
epoch 90: {'train_loss': '1.36229'}; time used = 0.025801658630371094s
epoch 95: {'train_loss': '1.35365'}; time used = 0.03693723678588867s
epoch 100: {'train_loss': '1.34917'}; time used = 0.025031566619873047s
epoch 105: {'train_loss': '1.34213'}; time used = 0.024744272232055664s
epoch 110: {'train_loss': '1.33865'}; time used = 0.0315852165222168s
epoch 115: {'train_loss': '1.33188'}; time used = 0.024948596954345703s
epoch 120: {'train_loss': '1.32918'}; time used = 0.03253006935119629s
epoch 125: {'train_loss': '1.32243'}; time used = 0.024832963943481445s
epoch 130: {'train_loss': '1.32002'}; time used = 0.03112959861755371s
epoch 135: {'train_loss': '1.31393'}; time used = 0.02443385124206543s
epoch 140: {'train_loss': '1.31469'}; time used = 0.03267407417297363s
epoch 145: {'train_loss': '1.30329'}; time used = 0.024434804916381836s
epoch 150: {'train_loss': '1.30781'}; time used = 0.033659934997558594s
epoch 155: {'train_loss': '1.30011'}; time used = 0.027843236923217773s
epoch 160: {'train_loss': '1.29276'}; time used = 0.03891634941101074s
epoch 165: {'train_loss': '1.29310'}; time used = 0.024099349975585938s
epoch 170: {'train_loss': '1.28985'}; time used = 0.03301811218261719s
epoch 175: {'train_loss': '1.28985'}; time used = 0.024616718292236328s
epoch 180: {'train_loss': '1.28128'}; time used = 0.02396678924560547s
epoch 185: {'train_loss': '1.28566'}; time used = 0.033275604248046875s
epoch 190: {'train_loss': '1.27669'}; time used = 0.024477481842041016s
epoch 195: {'train_loss': '1.27535'}; time used = 0.03267717361450195s
epoch 200: {'train_loss': '1.27225'}; time used = 0.024578571319580078s
epoch 205: {'train_loss': '1.27418'}; time used = 0.03106093406677246s
epoch 210: {'train_loss': '1.26324'}; time used = 0.02889537811279297s
epoch 215: {'train_loss': '1.26737'}; time used = 0.032807111740112305s
epoch 220: {'train_loss': '1.26474'}; time used = 0.02656245231628418s
epoch 225: {'train_loss': '1.26573'}; time used = 0.03658318519592285s
epoch 230: {'train_loss': '1.25567'}; time used = 0.03361678123474121s
epoch 235: {'train_loss': '1.25833'}; time used = 0.02455592155456543s
epoch 240: {'train_loss': '1.25655'}; time used = 0.023944616317749023s
epoch 245: {'train_loss': '1.25388'}; time used = 0.03479933738708496s
epoch 250: {'train_loss': '1.25100'}; time used = 0.024081945419311523s
epoch 255: {'train_loss': '1.24922'}; time used = 0.03283834457397461s
epoch 260: {'train_loss': '1.25475'}; time used = 0.023875951766967773s
epoch 265: {'train_loss': '1.25458'}; time used = 0.03278613090515137s
epoch 270: {'train_loss': '1.25619'}; time used = 0.024447202682495117s
epoch 275: {'train_loss': '1.24189'}; time used = 0.03160429000854492s
epoch 280: {'train_loss': '1.24583'}; time used = 0.023860931396484375s
epoch 285: {'train_loss': '1.24854'}; time used = 0.032296180725097656s
epoch 290: {'train_loss': '1.24902'}; time used = 0.024529218673706055s
epoch 295: {'train_loss': '1.24935'}; time used = 0.024445295333862305s
epoch 300: {'train_loss': '1.24851'}; time used = 0.040627241134643555s
epoch 305: {'train_loss': '1.24379'}; time used = 0.0247194766998291s
epoch 310: {'train_loss': '1.24898'}; time used = 0.025400638580322266s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 4.958216667175293.
Training classifier using 20.00% nodes...
{'micro': 0.2884171665897554, 'macro': 0.06807193855959415, 'samples': 0.2884171665897554, 'weighted': 0.13708092281065093}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.46735'}; time used = 0.04904294013977051s
epoch 10: {'train_loss': '1.35668'}; time used = 0.026641130447387695s
epoch 15: {'train_loss': '1.32547'}; time used = 0.022317171096801758s
epoch 20: {'train_loss': '1.29923'}; time used = 0.023148775100708008s
epoch 25: {'train_loss': '1.28288'}; time used = 0.022578001022338867s
epoch 30: {'train_loss': '1.26040'}; time used = 0.022607088088989258s
epoch 35: {'train_loss': '1.25663'}; time used = 0.02309894561767578s
epoch 40: {'train_loss': '1.24885'}; time used = 0.02277660369873047s
epoch 45: {'train_loss': '1.24790'}; time used = 0.05156588554382324s
epoch 50: {'train_loss': '1.24188'}; time used = 0.024672746658325195s
epoch 55: {'train_loss': '1.24596'}; time used = 0.022414445877075195s
epoch 60: {'train_loss': '1.24858'}; time used = 0.02272176742553711s
epoch 65: {'train_loss': '1.24568'}; time used = 0.023592233657836914s
epoch 70: {'train_loss': '1.24655'}; time used = 0.027437925338745117s
epoch 75: {'train_loss': '1.23997'}; time used = 0.06012845039367676s
epoch 80: {'train_loss': '1.24074'}; time used = 0.019428014755249023s
epoch 85: {'train_loss': '1.23499'}; time used = 0.02251601219177246s
epoch 90: {'train_loss': '1.23201'}; time used = 0.028150320053100586s
epoch 95: {'train_loss': '1.23090'}; time used = 0.04796576499938965s
epoch 100: {'train_loss': '1.23179'}; time used = 0.05014944076538086s
epoch 105: {'train_loss': '1.22699'}; time used = 0.04758048057556152s
epoch 110: {'train_loss': '1.22855'}; time used = 0.05370759963989258s
epoch 115: {'train_loss': '1.22862'}; time used = 0.033521175384521484s
epoch 120: {'train_loss': '1.22814'}; time used = 0.0352025032043457s
epoch 125: {'train_loss': '1.22684'}; time used = 0.026058197021484375s
epoch 130: {'train_loss': '1.22803'}; time used = 0.0216519832611084s
epoch 135: {'train_loss': '1.22938'}; time used = 0.021343231201171875s
epoch 140: {'train_loss': '1.22905'}; time used = 0.026294231414794922s
epoch 145: {'train_loss': '1.22009'}; time used = 0.03149986267089844s
epoch 150: {'train_loss': '1.23337'}; time used = 0.023049116134643555s
epoch 155: {'train_loss': '1.22862'}; time used = 0.02755117416381836s
epoch 160: {'train_loss': '1.22422'}; time used = 0.02222609519958496s
epoch 165: {'train_loss': '1.22698'}; time used = 0.0302584171295166s
epoch 170: {'train_loss': '1.22835'}; time used = 0.023158550262451172s
epoch 175: {'train_loss': '1.23392'}; time used = 0.023591995239257812s
epoch 180: {'train_loss': '1.22442'}; time used = 0.023705244064331055s
epoch 185: {'train_loss': '1.23199'}; time used = 0.04830312728881836s
epoch 190: {'train_loss': '1.23004'}; time used = 0.024865150451660156s
epoch 195: {'train_loss': '1.22661'}; time used = 0.02548360824584961s
epoch 200: {'train_loss': '1.22859'}; time used = 0.024562358856201172s
epoch 205: {'train_loss': '1.23722'}; time used = 0.024443864822387695s
epoch 210: {'train_loss': '1.22042'}; time used = 0.03498101234436035s
epoch 215: {'train_loss': '1.23075'}; time used = 0.04459095001220703s
epoch 220: {'train_loss': '1.22925'}; time used = 0.026192903518676758s
epoch 225: {'train_loss': '1.23267'}; time used = 0.030312299728393555s
epoch 230: {'train_loss': '1.22277'}; time used = 0.029320240020751953s
epoch 235: {'train_loss': '1.22789'}; time used = 0.04602861404418945s
epoch 240: {'train_loss': '1.22686'}; time used = 0.046376943588256836s
epoch 245: {'train_loss': '1.22865'}; time used = 0.0302276611328125s
epoch 250: {'train_loss': '1.22364'}; time used = 0.03632092475891113s
epoch 255: {'train_loss': '1.22335'}; time used = 0.05008864402770996s
epoch 260: {'train_loss': '1.23253'}; time used = 0.02422189712524414s
epoch 265: {'train_loss': '1.23205'}; time used = 0.04346871376037598s
epoch 270: {'train_loss': '1.23328'}; time used = 0.0436406135559082s
epoch 275: {'train_loss': '1.21900'}; time used = 0.028753995895385742s
epoch 280: {'train_loss': '1.22269'}; time used = 0.022861719131469727s
epoch 285: {'train_loss': '1.22768'}; time used = 0.022759437561035156s
epoch 290: {'train_loss': '1.23039'}; time used = 0.02089095115661621s
epoch 295: {'train_loss': '1.23216'}; time used = 0.02068161964416504s
epoch 300: {'train_loss': '1.23103'}; time used = 0.020975589752197266s
epoch 305: {'train_loss': '1.22367'}; time used = 0.019884109497070312s
epoch 310: {'train_loss': '1.23138'}; time used = 0.019831180572509766s
epoch 315: {'train_loss': '1.22968'}; time used = 0.019208908081054688s
epoch 320: {'train_loss': '1.22921'}; time used = 0.019208669662475586s
epoch 325: {'train_loss': '1.23148'}; time used = 0.019418001174926758s
epoch 330: {'train_loss': '1.22797'}; time used = 0.02069401741027832s
epoch 335: {'train_loss': '1.22958'}; time used = 0.01985764503479004s
epoch 340: {'train_loss': '1.23366'}; time used = 0.02061009407043457s
epoch 345: {'train_loss': '1.22866'}; time used = 0.019511938095092773s
epoch 350: {'train_loss': '1.22718'}; time used = 0.019320011138916016s
epoch 355: {'train_loss': '1.22388'}; time used = 0.01937079429626465s
epoch 360: {'train_loss': '1.22881'}; time used = 0.019248485565185547s
epoch 365: {'train_loss': '1.22539'}; time used = 0.020846128463745117s
epoch 370: {'train_loss': '1.22613'}; time used = 0.019934892654418945s
epoch 375: {'train_loss': '1.22398'}; time used = 0.020232677459716797s
epoch 380: {'train_loss': '1.22630'}; time used = 0.019443035125732422s
epoch 385: {'train_loss': '1.23101'}; time used = 0.01934337615966797s
epoch 390: {'train_loss': '1.23018'}; time used = 0.019488811492919922s
epoch 395: {'train_loss': '1.22879'}; time used = 0.020534515380859375s
epoch 400: {'train_loss': '1.22627'}; time used = 0.020503759384155273s
epoch 405: {'train_loss': '1.23449'}; time used = 0.01995110511779785s
epoch 410: {'train_loss': '1.22626'}; time used = 0.019197463989257812s
epoch 415: {'train_loss': '1.23228'}; time used = 0.02039027214050293s
epoch 420: {'train_loss': '1.22836'}; time used = 0.020096778869628906s
epoch 425: {'train_loss': '1.22899'}; time used = 0.019985198974609375s
epoch 430: {'train_loss': '1.22556'}; time used = 0.019922733306884766s
epoch 435: {'train_loss': '1.22728'}; time used = 0.020746707916259766s
epoch 440: {'train_loss': '1.22796'}; time used = 0.019594907760620117s
epoch 445: {'train_loss': '1.22821'}; time used = 0.020067214965820312s
epoch 450: {'train_loss': '1.23455'}; time used = 0.01988530158996582s
epoch 455: {'train_loss': '1.23080'}; time used = 0.019550323486328125s
epoch 460: {'train_loss': '1.22825'}; time used = 0.02587103843688965s
epoch 465: {'train_loss': '1.22615'}; time used = 0.021960735321044922s
epoch 470: {'train_loss': '1.22912'}; time used = 0.019483089447021484s
epoch 475: {'train_loss': '1.22932'}; time used = 0.02036118507385254s
epoch 480: {'train_loss': '1.22352'}; time used = 0.019433021545410156s
epoch 485: {'train_loss': '1.22317'}; time used = 0.019365310668945312s
epoch 490: {'train_loss': '1.23052'}; time used = 0.019582271575927734s
epoch 495: {'train_loss': '1.21942'}; time used = 0.01927328109741211s
epoch 500: {'train_loss': '1.22877'}; time used = 0.025817155838012695s
Finished training. Time used = 7.1622889041900635.
Training classifier using 20.00% nodes...
{'micro': 0.28887863405629904, 'macro': 0.0720163622360754, 'samples': 0.28887863405629904, 'weighted': 0.14169724223080254}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.37492'}; time used = 0.032527923583984375s
epoch 10: {'train_loss': '1.32405'}; time used = 0.02415156364440918s
epoch 15: {'train_loss': '1.28415'}; time used = 0.024976253509521484s
epoch 20: {'train_loss': '1.25824'}; time used = 0.024763107299804688s
epoch 25: {'train_loss': '1.25545'}; time used = 0.023668289184570312s
epoch 30: {'train_loss': '1.24337'}; time used = 0.05246305465698242s
epoch 35: {'train_loss': '1.23960'}; time used = 0.04271197319030762s
epoch 40: {'train_loss': '1.23473'}; time used = 0.024280309677124023s
epoch 45: {'train_loss': '1.23406'}; time used = 0.025345802307128906s
epoch 50: {'train_loss': '1.22613'}; time used = 0.0318906307220459s
epoch 55: {'train_loss': '1.23187'}; time used = 0.026875019073486328s
epoch 60: {'train_loss': '1.23688'}; time used = 0.026926040649414062s
epoch 65: {'train_loss': '1.23348'}; time used = 0.033769845962524414s
epoch 70: {'train_loss': '1.23489'}; time used = 0.02904057502746582s
epoch 75: {'train_loss': '1.23117'}; time used = 0.030068397521972656s
epoch 80: {'train_loss': '1.23275'}; time used = 0.03174948692321777s
epoch 85: {'train_loss': '1.22838'}; time used = 0.029651880264282227s
epoch 90: {'train_loss': '1.22626'}; time used = 0.0292966365814209s
epoch 95: {'train_loss': '1.22779'}; time used = 0.027980327606201172s
epoch 100: {'train_loss': '1.22891'}; time used = 0.029981613159179688s
epoch 105: {'train_loss': '1.22617'}; time used = 0.029386520385742188s
epoch 110: {'train_loss': '1.22880'}; time used = 0.028753995895385742s
epoch 115: {'train_loss': '1.22863'}; time used = 0.030908584594726562s
epoch 120: {'train_loss': '1.22889'}; time used = 0.03590202331542969s
epoch 125: {'train_loss': '1.22774'}; time used = 0.03415226936340332s
epoch 130: {'train_loss': '1.22960'}; time used = 0.03020620346069336s
epoch 135: {'train_loss': '1.23025'}; time used = 0.03367447853088379s
epoch 140: {'train_loss': '1.23068'}; time used = 0.03399825096130371s
epoch 145: {'train_loss': '1.22078'}; time used = 0.030855655670166016s
epoch 150: {'train_loss': '1.23414'}; time used = 0.028969764709472656s
epoch 155: {'train_loss': '1.23072'}; time used = 0.03163337707519531s
epoch 160: {'train_loss': '1.22640'}; time used = 0.031207799911499023s
epoch 165: {'train_loss': '1.22781'}; time used = 0.03683114051818848s
epoch 170: {'train_loss': '1.23026'}; time used = 0.03004002571105957s
epoch 175: {'train_loss': '1.23583'}; time used = 0.02937912940979004s
epoch 180: {'train_loss': '1.22584'}; time used = 0.02841806411743164s
epoch 185: {'train_loss': '1.23413'}; time used = 0.032944679260253906s
epoch 190: {'train_loss': '1.23089'}; time used = 0.05081772804260254s
epoch 195: {'train_loss': '1.22823'}; time used = 0.02415943145751953s
epoch 200: {'train_loss': '1.22992'}; time used = 0.02553272247314453s
epoch 205: {'train_loss': '1.23954'}; time used = 0.02300882339477539s
epoch 210: {'train_loss': '1.22073'}; time used = 0.023328065872192383s
epoch 215: {'train_loss': '1.23223'}; time used = 0.02368021011352539s
epoch 220: {'train_loss': '1.23137'}; time used = 0.02371835708618164s
epoch 225: {'train_loss': '1.23459'}; time used = 0.023545503616333008s
epoch 230: {'train_loss': '1.22398'}; time used = 0.02429366111755371s
epoch 235: {'train_loss': '1.22878'}; time used = 0.024957895278930664s
epoch 240: {'train_loss': '1.22766'}; time used = 0.025209903717041016s
epoch 245: {'train_loss': '1.23009'}; time used = 0.024022340774536133s
epoch 250: {'train_loss': '1.22534'}; time used = 0.023763179779052734s
epoch 255: {'train_loss': '1.22442'}; time used = 0.025037527084350586s
epoch 260: {'train_loss': '1.23456'}; time used = 0.023755311965942383s
epoch 265: {'train_loss': '1.23269'}; time used = 0.023195266723632812s
epoch 270: {'train_loss': '1.23501'}; time used = 0.023805618286132812s
epoch 275: {'train_loss': '1.22019'}; time used = 0.02345561981201172s
epoch 280: {'train_loss': '1.22406'}; time used = 0.02446579933166504s
epoch 285: {'train_loss': '1.22838'}; time used = 0.023489713668823242s
epoch 290: {'train_loss': '1.23292'}; time used = 0.022969484329223633s
epoch 295: {'train_loss': '1.23384'}; time used = 0.03371739387512207s
epoch 300: {'train_loss': '1.23224'}; time used = 0.0319828987121582s
epoch 305: {'train_loss': '1.22558'}; time used = 0.025157690048217773s
epoch 310: {'train_loss': '1.23335'}; time used = 0.024636030197143555s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 5.988241910934448.
Training classifier using 20.00% nodes...
{'micro': 0.28887863405629904, 'macro': 0.07144741381552987, 'samples': 0.28887863405629904, 'weighted': 0.14112591039073677}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 128, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [128, 128, 128], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.35566'}; time used = 0.0345616340637207s
epoch 10: {'train_loss': '1.30508'}; time used = 0.03336215019226074s
epoch 15: {'train_loss': '1.26292'}; time used = 0.0269927978515625s
epoch 20: {'train_loss': '1.24540'}; time used = 0.04800152778625488s
epoch 25: {'train_loss': '1.24691'}; time used = 0.025505781173706055s
epoch 30: {'train_loss': '1.23603'}; time used = 0.03663492202758789s
epoch 35: {'train_loss': '1.23660'}; time used = 0.026990652084350586s
epoch 40: {'train_loss': '1.23158'}; time used = 0.04270648956298828s
epoch 45: {'train_loss': '1.23388'}; time used = 0.022683143615722656s
epoch 50: {'train_loss': '1.22572'}; time used = 0.02107977867126465s
epoch 55: {'train_loss': '1.23276'}; time used = 0.03409385681152344s
epoch 60: {'train_loss': '1.23808'}; time used = 0.02637457847595215s
epoch 65: {'train_loss': '1.23500'}; time used = 0.034944772720336914s
epoch 70: {'train_loss': '1.23600'}; time used = 0.02607893943786621s
epoch 75: {'train_loss': '1.23151'}; time used = 0.03280806541442871s
epoch 80: {'train_loss': '1.23376'}; time used = 0.026321887969970703s
epoch 85: {'train_loss': '1.22978'}; time used = 0.0330805778503418s
epoch 90: {'train_loss': '1.22786'}; time used = 0.02633213996887207s
epoch 95: {'train_loss': '1.22920'}; time used = 0.03272294998168945s
epoch 100: {'train_loss': '1.23106'}; time used = 0.026309490203857422s
epoch 105: {'train_loss': '1.22664'}; time used = 0.0343472957611084s
epoch 110: {'train_loss': '1.23047'}; time used = 0.029959678649902344s
epoch 115: {'train_loss': '1.22999'}; time used = 0.030435800552368164s
epoch 120: {'train_loss': '1.22926'}; time used = 0.023096323013305664s
epoch 125: {'train_loss': '1.22890'}; time used = 0.021091938018798828s
epoch 130: {'train_loss': '1.23003'}; time used = 0.02859807014465332s
epoch 135: {'train_loss': '1.23071'}; time used = 0.022397518157958984s
epoch 140: {'train_loss': '1.23093'}; time used = 0.020886898040771484s
epoch 145: {'train_loss': '1.22188'}; time used = 0.03069758415222168s
epoch 150: {'train_loss': '1.23479'}; time used = 0.02111220359802246s
epoch 155: {'train_loss': '1.23169'}; time used = 0.0335080623626709s
epoch 160: {'train_loss': '1.22792'}; time used = 0.022167444229125977s
epoch 165: {'train_loss': '1.22868'}; time used = 0.028505325317382812s
epoch 170: {'train_loss': '1.23092'}; time used = 0.022533178329467773s
epoch 175: {'train_loss': '1.23717'}; time used = 0.02160334587097168s
epoch 180: {'train_loss': '1.22632'}; time used = 0.033020734786987305s
epoch 185: {'train_loss': '1.23535'}; time used = 0.03204655647277832s
epoch 190: {'train_loss': '1.23285'}; time used = 0.03113698959350586s
epoch 195: {'train_loss': '1.22914'}; time used = 0.0262296199798584s
epoch 200: {'train_loss': '1.23058'}; time used = 0.03321552276611328s
epoch 205: {'train_loss': '1.24062'}; time used = 0.0248565673828125s
epoch 210: {'train_loss': '1.22247'}; time used = 0.0400238037109375s
epoch 215: {'train_loss': '1.23472'}; time used = 0.026198863983154297s
epoch 220: {'train_loss': '1.23505'}; time used = 0.025582075119018555s
epoch 225: {'train_loss': '1.23527'}; time used = 0.03265261650085449s
epoch 230: {'train_loss': '1.22436'}; time used = 0.025165319442749023s
epoch 235: {'train_loss': '1.23002'}; time used = 0.03436732292175293s
epoch 240: {'train_loss': '1.22855'}; time used = 0.025642871856689453s
epoch 245: {'train_loss': '1.23210'}; time used = 0.03394794464111328s
epoch 250: {'train_loss': '1.22634'}; time used = 0.025527238845825195s
epoch 255: {'train_loss': '1.22576'}; time used = 0.031691551208496094s
epoch 260: {'train_loss': '1.23535'}; time used = 0.025079965591430664s
epoch 265: {'train_loss': '1.23352'}; time used = 0.03331494331359863s
epoch 270: {'train_loss': '1.23533'}; time used = 0.031403303146362305s
epoch 275: {'train_loss': '1.22424'}; time used = 0.03291630744934082s
epoch 280: {'train_loss': '1.22564'}; time used = 0.027619361877441406s
epoch 285: {'train_loss': '1.23068'}; time used = 0.03565692901611328s
epoch 290: {'train_loss': '1.23423'}; time used = 0.026909351348876953s
epoch 295: {'train_loss': '1.23650'}; time used = 0.03169560432434082s
epoch 300: {'train_loss': '1.23345'}; time used = 0.029209136962890625s
epoch 305: {'train_loss': '1.22703'}; time used = 0.025568008422851562s
epoch 310: {'train_loss': '1.23510'}; time used = 0.032973527908325195s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 5.207515239715576.
Training classifier using 20.00% nodes...
{'micro': 0.2911859713890171, 'macro': 0.07307726037007804, 'samples': 0.2911859713890171, 'weighted': 0.14320213663119688}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.76899'}; time used = 0.055329322814941406s
epoch 10: {'train_loss': '1.69323'}; time used = 0.020144939422607422s
epoch 15: {'train_loss': '1.62283'}; time used = 0.0327303409576416s
epoch 20: {'train_loss': '1.56586'}; time used = 0.02014017105102539s
epoch 25: {'train_loss': '1.52213'}; time used = 0.07344245910644531s
epoch 30: {'train_loss': '1.48343'}; time used = 0.024290800094604492s
epoch 35: {'train_loss': '1.45855'}; time used = 0.025485515594482422s
epoch 40: {'train_loss': '1.42118'}; time used = 0.032209157943725586s
epoch 45: {'train_loss': '1.40755'}; time used = 0.024456501007080078s
epoch 50: {'train_loss': '1.39208'}; time used = 0.03158998489379883s
epoch 55: {'train_loss': '1.37785'}; time used = 0.024437427520751953s
epoch 60: {'train_loss': '1.35926'}; time used = 0.030908823013305664s
epoch 65: {'train_loss': '1.35607'}; time used = 0.024120807647705078s
epoch 70: {'train_loss': '1.34291'}; time used = 0.02470564842224121s
epoch 75: {'train_loss': '1.33780'}; time used = 0.03305983543395996s
epoch 80: {'train_loss': '1.33039'}; time used = 0.023714065551757812s
epoch 85: {'train_loss': '1.32341'}; time used = 0.030659914016723633s
epoch 90: {'train_loss': '1.32037'}; time used = 0.026137113571166992s
epoch 95: {'train_loss': '1.31670'}; time used = 0.04386281967163086s
epoch 100: {'train_loss': '1.30501'}; time used = 0.030790328979492188s
epoch 105: {'train_loss': '1.30254'}; time used = 0.03095722198486328s
epoch 110: {'train_loss': '1.29976'}; time used = 0.03055548667907715s
epoch 115: {'train_loss': '1.29417'}; time used = 0.030692338943481445s
epoch 120: {'train_loss': '1.28860'}; time used = 0.02545619010925293s
epoch 125: {'train_loss': '1.28040'}; time used = 0.03856015205383301s
epoch 130: {'train_loss': '1.27909'}; time used = 0.0274507999420166s
epoch 135: {'train_loss': '1.27272'}; time used = 0.047067880630493164s
epoch 140: {'train_loss': '1.27444'}; time used = 0.03010416030883789s
epoch 145: {'train_loss': '1.27028'}; time used = 0.033405303955078125s
epoch 150: {'train_loss': '1.26563'}; time used = 0.02775430679321289s
epoch 155: {'train_loss': '1.26416'}; time used = 0.034670352935791016s
epoch 160: {'train_loss': '1.26378'}; time used = 0.03115081787109375s
epoch 165: {'train_loss': '1.25984'}; time used = 0.0313568115234375s
epoch 170: {'train_loss': '1.25917'}; time used = 0.03739428520202637s
epoch 175: {'train_loss': '1.25821'}; time used = 0.03342556953430176s
epoch 180: {'train_loss': '1.25138'}; time used = 0.024195432662963867s
epoch 185: {'train_loss': '1.25007'}; time used = 0.034461259841918945s
epoch 190: {'train_loss': '1.24774'}; time used = 0.024040937423706055s
epoch 195: {'train_loss': '1.24850'}; time used = 0.031084060668945312s
epoch 200: {'train_loss': '1.24925'}; time used = 0.024681806564331055s
epoch 205: {'train_loss': '1.24940'}; time used = 0.024296045303344727s
epoch 210: {'train_loss': '1.25034'}; time used = 0.033312320709228516s
epoch 215: {'train_loss': '1.25113'}; time used = 0.02415633201599121s
epoch 220: {'train_loss': '1.23953'}; time used = 0.034349918365478516s
epoch 225: {'train_loss': '1.23525'}; time used = 0.02576422691345215s
epoch 230: {'train_loss': '1.24245'}; time used = 0.03397631645202637s
epoch 235: {'train_loss': '1.24413'}; time used = 0.0223391056060791s
epoch 240: {'train_loss': '1.24908'}; time used = 0.03403306007385254s
epoch 245: {'train_loss': '1.24438'}; time used = 0.021735668182373047s
epoch 250: {'train_loss': '1.23561'}; time used = 0.023732423782348633s
epoch 255: {'train_loss': '1.23998'}; time used = 0.03231930732727051s
epoch 260: {'train_loss': '1.23602'}; time used = 0.02576160430908203s
epoch 265: {'train_loss': '1.24147'}; time used = 0.026898860931396484s
epoch 270: {'train_loss': '1.23914'}; time used = 0.018155574798583984s
epoch 275: {'train_loss': '1.24002'}; time used = 0.03084588050842285s
epoch 280: {'train_loss': '1.23712'}; time used = 0.03582024574279785s
epoch 285: {'train_loss': '1.24214'}; time used = 0.02353191375732422s
epoch 290: {'train_loss': '1.23454'}; time used = 0.03126716613769531s
epoch 295: {'train_loss': '1.23716'}; time used = 0.022747516632080078s
epoch 300: {'train_loss': '1.24010'}; time used = 0.03019237518310547s
epoch 305: {'train_loss': '1.24109'}; time used = 0.031250715255737305s
epoch 310: {'train_loss': '1.24250'}; time used = 0.03910684585571289s
epoch 315: {'train_loss': '1.24172'}; time used = 0.03097820281982422s
epoch 320: {'train_loss': '1.23869'}; time used = 0.028375625610351562s
epoch 325: {'train_loss': '1.23668'}; time used = 0.03814196586608887s
epoch 330: {'train_loss': '1.23463'}; time used = 0.026112794876098633s
epoch 335: {'train_loss': '1.23741'}; time used = 0.02578282356262207s
epoch 340: {'train_loss': '1.23494'}; time used = 0.023401260375976562s
epoch 345: {'train_loss': '1.23496'}; time used = 0.025508880615234375s
epoch 350: {'train_loss': '1.23079'}; time used = 0.02310466766357422s
epoch 355: {'train_loss': '1.23298'}; time used = 0.026193857192993164s
epoch 360: {'train_loss': '1.23575'}; time used = 0.0210874080657959s
epoch 365: {'train_loss': '1.23419'}; time used = 0.021830320358276367s
epoch 370: {'train_loss': '1.23462'}; time used = 0.02241826057434082s
epoch 375: {'train_loss': '1.23477'}; time used = 0.0215909481048584s
epoch 380: {'train_loss': '1.23470'}; time used = 0.02042555809020996s
epoch 385: {'train_loss': '1.23121'}; time used = 0.019527673721313477s
epoch 390: {'train_loss': '1.23620'}; time used = 0.021919727325439453s
epoch 395: {'train_loss': '1.23081'}; time used = 0.0174405574798584s
epoch 400: {'train_loss': '1.23625'}; time used = 0.019059419631958008s
epoch 405: {'train_loss': '1.23580'}; time used = 0.019339799880981445s
epoch 410: {'train_loss': '1.22849'}; time used = 0.018792152404785156s
epoch 415: {'train_loss': '1.23390'}; time used = 0.022358179092407227s
epoch 420: {'train_loss': '1.22903'}; time used = 0.021283626556396484s
epoch 425: {'train_loss': '1.23380'}; time used = 0.020355701446533203s
epoch 430: {'train_loss': '1.23254'}; time used = 0.02138805389404297s
epoch 435: {'train_loss': '1.23200'}; time used = 0.021229267120361328s
epoch 440: {'train_loss': '1.23166'}; time used = 0.029335498809814453s
epoch 445: {'train_loss': '1.22962'}; time used = 0.019566059112548828s
epoch 450: {'train_loss': '1.23168'}; time used = 0.020261049270629883s
epoch 455: {'train_loss': '1.22529'}; time used = 0.021197795867919922s
epoch 460: {'train_loss': '1.23056'}; time used = 0.02053046226501465s
epoch 465: {'train_loss': '1.23077'}; time used = 0.02087092399597168s
epoch 470: {'train_loss': '1.22833'}; time used = 0.026540517807006836s
epoch 475: {'train_loss': '1.22687'}; time used = 0.020751237869262695s
epoch 480: {'train_loss': '1.23369'}; time used = 0.022459030151367188s
epoch 485: {'train_loss': '1.23572'}; time used = 0.01959991455078125s
epoch 490: {'train_loss': '1.22496'}; time used = 0.03830122947692871s
epoch 495: {'train_loss': '1.22870'}; time used = 0.02036905288696289s
epoch 500: {'train_loss': '1.22871'}; time used = 0.026558876037597656s
Finished training. Time used = 21.67109203338623.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.41421'}; time used = 0.04425930976867676s
epoch 10: {'train_loss': '1.33374'}; time used = 0.038745880126953125s
epoch 15: {'train_loss': '1.30530'}; time used = 0.041258811950683594s
epoch 20: {'train_loss': '1.27773'}; time used = 0.03766918182373047s
epoch 25: {'train_loss': '1.25650'}; time used = 0.027456998825073242s
epoch 30: {'train_loss': '1.25248'}; time used = 0.03705644607543945s
epoch 35: {'train_loss': '1.24986'}; time used = 0.04455304145812988s
epoch 40: {'train_loss': '1.23787'}; time used = 0.03613615036010742s
epoch 45: {'train_loss': '1.24397'}; time used = 0.02639627456665039s
epoch 50: {'train_loss': '1.23894'}; time used = 0.04228663444519043s
epoch 55: {'train_loss': '1.23742'}; time used = 0.02651834487915039s
epoch 60: {'train_loss': '1.23594'}; time used = 0.03513813018798828s
epoch 65: {'train_loss': '1.23197'}; time used = 0.026829242706298828s
epoch 70: {'train_loss': '1.22985'}; time used = 0.02691364288330078s
epoch 75: {'train_loss': '1.23801'}; time used = 0.03404641151428223s
epoch 80: {'train_loss': '1.22471'}; time used = 0.026564836502075195s
epoch 85: {'train_loss': '1.23413'}; time used = 0.03427863121032715s
epoch 90: {'train_loss': '1.23198'}; time used = 0.04028654098510742s
epoch 95: {'train_loss': '1.23616'}; time used = 0.032503366470336914s
epoch 100: {'train_loss': '1.22565'}; time used = 0.035768747329711914s
epoch 105: {'train_loss': '1.22827'}; time used = 0.027270078659057617s
epoch 110: {'train_loss': '1.23499'}; time used = 0.027317523956298828s
epoch 115: {'train_loss': '1.22964'}; time used = 0.03393244743347168s
epoch 120: {'train_loss': '1.23190'}; time used = 0.027122974395751953s
epoch 125: {'train_loss': '1.22476'}; time used = 0.026511430740356445s
epoch 130: {'train_loss': '1.23132'}; time used = 0.037535667419433594s
epoch 135: {'train_loss': '1.22672'}; time used = 0.026451587677001953s
epoch 140: {'train_loss': '1.22740'}; time used = 0.0351107120513916s
epoch 145: {'train_loss': '1.23353'}; time used = 0.026976346969604492s
epoch 150: {'train_loss': '1.23235'}; time used = 0.02650761604309082s
epoch 155: {'train_loss': '1.23023'}; time used = 0.046328067779541016s
epoch 160: {'train_loss': '1.23155'}; time used = 0.028898954391479492s
epoch 165: {'train_loss': '1.23308'}; time used = 0.02958536148071289s
epoch 170: {'train_loss': '1.23347'}; time used = 0.035361289978027344s
epoch 175: {'train_loss': '1.23264'}; time used = 0.026152610778808594s
epoch 180: {'train_loss': '1.22921'}; time used = 0.026350021362304688s
epoch 185: {'train_loss': '1.22472'}; time used = 0.030797719955444336s
epoch 190: {'train_loss': '1.22986'}; time used = 0.024564743041992188s
epoch 195: {'train_loss': '1.23140'}; time used = 0.02459859848022461s
epoch 200: {'train_loss': '1.23306'}; time used = 0.033177852630615234s
epoch 205: {'train_loss': '1.23224'}; time used = 0.023923158645629883s
epoch 210: {'train_loss': '1.23400'}; time used = 0.022814512252807617s
epoch 215: {'train_loss': '1.23736'}; time used = 0.03156161308288574s
epoch 220: {'train_loss': '1.22550'}; time used = 0.02328181266784668s
epoch 225: {'train_loss': '1.22178'}; time used = 0.03469228744506836s
epoch 230: {'train_loss': '1.22874'}; time used = 0.03427386283874512s
epoch 235: {'train_loss': '1.23146'}; time used = 0.024927616119384766s
epoch 240: {'train_loss': '1.23673'}; time used = 0.028113365173339844s
epoch 245: {'train_loss': '1.23305'}; time used = 0.03229522705078125s
epoch 250: {'train_loss': '1.22389'}; time used = 0.02718377113342285s
epoch 255: {'train_loss': '1.22689'}; time used = 0.026332855224609375s
epoch 260: {'train_loss': '1.22551'}; time used = 0.03299140930175781s
epoch 265: {'train_loss': '1.23029'}; time used = 0.029406309127807617s
epoch 270: {'train_loss': '1.22862'}; time used = 0.023853778839111328s
epoch 275: {'train_loss': '1.22813'}; time used = 0.03176450729370117s
epoch 280: {'train_loss': '1.22708'}; time used = 0.02544569969177246s
epoch 285: {'train_loss': '1.23261'}; time used = 0.025387287139892578s
epoch 290: {'train_loss': '1.22520'}; time used = 0.032347917556762695s
epoch 295: {'train_loss': '1.22848'}; time used = 0.03027820587158203s
epoch 300: {'train_loss': '1.23070'}; time used = 0.02580428123474121s
epoch 305: {'train_loss': '1.23478'}; time used = 0.03438258171081543s
epoch 310: {'train_loss': '1.23657'}; time used = 0.03636884689331055s
epoch 315: {'train_loss': '1.23591'}; time used = 0.030111074447631836s
epoch 320: {'train_loss': '1.23022'}; time used = 0.03162360191345215s
epoch 325: {'train_loss': '1.22972'}; time used = 0.02450847625732422s
epoch 330: {'train_loss': '1.22705'}; time used = 0.024266719818115234s
epoch 335: {'train_loss': '1.23098'}; time used = 0.0341336727142334s
epoch 340: {'train_loss': '1.22807'}; time used = 0.026085853576660156s
epoch 345: {'train_loss': '1.22737'}; time used = 0.025659799575805664s
epoch 350: {'train_loss': '1.22516'}; time used = 0.03574967384338379s
epoch 355: {'train_loss': '1.22703'}; time used = 0.02520012855529785s
epoch 360: {'train_loss': '1.22961'}; time used = 0.033826589584350586s
epoch 365: {'train_loss': '1.22997'}; time used = 0.030362606048583984s
epoch 370: {'train_loss': '1.22871'}; time used = 0.02311539649963379s
epoch 375: {'train_loss': '1.23089'}; time used = 0.025000810623168945s
epoch 380: {'train_loss': '1.22849'}; time used = 0.03494596481323242s
epoch 385: {'train_loss': '1.22701'}; time used = 0.025475740432739258s
epoch 390: {'train_loss': '1.23112'}; time used = 0.025313138961791992s
epoch 395: {'train_loss': '1.22689'}; time used = 0.04278254508972168s
epoch 400: {'train_loss': '1.23242'}; time used = 0.02434706687927246s
epoch 405: {'train_loss': '1.23288'}; time used = 0.03484153747558594s
epoch 410: {'train_loss': '1.22368'}; time used = 0.026237010955810547s
epoch 415: {'train_loss': '1.23046'}; time used = 0.025077342987060547s
epoch 420: {'train_loss': '1.22570'}; time used = 0.03463411331176758s
epoch 425: {'train_loss': '1.22929'}; time used = 0.024935245513916016s
epoch 430: {'train_loss': '1.22995'}; time used = 0.03289675712585449s
epoch 435: {'train_loss': '1.22885'}; time used = 0.0681309700012207s
epoch 440: {'train_loss': '1.23015'}; time used = 0.023585081100463867s
epoch 445: {'train_loss': '1.22786'}; time used = 0.02536487579345703s
epoch 450: {'train_loss': '1.23021'}; time used = 0.03158974647521973s
epoch 455: {'train_loss': '1.22221'}; time used = 0.02489757537841797s
epoch 460: {'train_loss': '1.22936'}; time used = 0.04240536689758301s
epoch 465: {'train_loss': '1.22918'}; time used = 0.028247594833374023s
epoch 470: {'train_loss': '1.22642'}; time used = 0.025922536849975586s
epoch 475: {'train_loss': '1.22593'}; time used = 0.034729719161987305s
epoch 480: {'train_loss': '1.23287'}; time used = 0.02539205551147461s
epoch 485: {'train_loss': '1.23661'}; time used = 0.03176546096801758s
epoch 490: {'train_loss': '1.22518'}; time used = 0.024712562561035156s
epoch 495: {'train_loss': '1.22828'}; time used = 0.03325653076171875s
epoch 500: {'train_loss': '1.22857'}; time used = 0.027942895889282227s
Finished training. Time used = 6.895817995071411.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.76899'}; time used = 0.07878637313842773s
epoch 10: {'train_loss': '1.69323'}; time used = 0.02157282829284668s
epoch 15: {'train_loss': '1.62283'}; time used = 0.021300792694091797s
epoch 20: {'train_loss': '1.56586'}; time used = 0.02134251594543457s
epoch 25: {'train_loss': '1.52213'}; time used = 0.023888349533081055s
epoch 30: {'train_loss': '1.48343'}; time used = 0.02574777603149414s
epoch 35: {'train_loss': '1.45855'}; time used = 0.020437955856323242s
epoch 40: {'train_loss': '1.42118'}; time used = 0.020473957061767578s
epoch 45: {'train_loss': '1.40755'}; time used = 0.022380828857421875s
epoch 50: {'train_loss': '1.39208'}; time used = 0.04380297660827637s
epoch 55: {'train_loss': '1.37785'}; time used = 0.021556854248046875s
epoch 60: {'train_loss': '1.35926'}; time used = 0.06034374237060547s
epoch 65: {'train_loss': '1.35607'}; time used = 0.02313089370727539s
epoch 70: {'train_loss': '1.34291'}; time used = 0.025598526000976562s
epoch 75: {'train_loss': '1.33780'}; time used = 0.02422642707824707s
epoch 80: {'train_loss': '1.33039'}; time used = 0.02364635467529297s
epoch 85: {'train_loss': '1.32341'}; time used = 0.020190715789794922s
epoch 90: {'train_loss': '1.32037'}; time used = 0.02864837646484375s
epoch 95: {'train_loss': '1.31670'}; time used = 0.03675436973571777s
epoch 100: {'train_loss': '1.30501'}; time used = 0.019776582717895508s
epoch 105: {'train_loss': '1.30254'}; time used = 0.01993870735168457s
epoch 110: {'train_loss': '1.29976'}; time used = 0.020418405532836914s
epoch 115: {'train_loss': '1.29417'}; time used = 0.02724289894104004s
epoch 120: {'train_loss': '1.28860'}; time used = 0.026945829391479492s
epoch 125: {'train_loss': '1.28040'}; time used = 0.021181583404541016s
epoch 130: {'train_loss': '1.27909'}; time used = 0.02056574821472168s
epoch 135: {'train_loss': '1.27272'}; time used = 0.019449472427368164s
epoch 140: {'train_loss': '1.27444'}; time used = 0.030597925186157227s
epoch 145: {'train_loss': '1.27028'}; time used = 0.024155378341674805s
epoch 150: {'train_loss': '1.26563'}; time used = 0.021419048309326172s
epoch 155: {'train_loss': '1.26416'}; time used = 0.02167820930480957s
epoch 160: {'train_loss': '1.26378'}; time used = 0.026962757110595703s
epoch 165: {'train_loss': '1.25984'}; time used = 0.03433561325073242s
epoch 170: {'train_loss': '1.25917'}; time used = 0.03641557693481445s
epoch 175: {'train_loss': '1.25821'}; time used = 0.056360483169555664s
epoch 180: {'train_loss': '1.25138'}; time used = 0.0516660213470459s
epoch 185: {'train_loss': '1.25007'}; time used = 0.04340958595275879s
epoch 190: {'train_loss': '1.24774'}; time used = 0.044974327087402344s
epoch 195: {'train_loss': '1.24850'}; time used = 0.04397273063659668s
epoch 200: {'train_loss': '1.24925'}; time used = 0.04785346984863281s
epoch 205: {'train_loss': '1.24940'}; time used = 0.04851984977722168s
epoch 210: {'train_loss': '1.25034'}; time used = 0.03947281837463379s
epoch 215: {'train_loss': '1.25113'}; time used = 0.026699304580688477s
epoch 220: {'train_loss': '1.23953'}; time used = 0.026155471801757812s
epoch 225: {'train_loss': '1.23525'}; time used = 0.04136991500854492s
epoch 230: {'train_loss': '1.24245'}; time used = 0.03000164031982422s
epoch 235: {'train_loss': '1.24413'}; time used = 0.0347743034362793s
epoch 240: {'train_loss': '1.24908'}; time used = 0.028738975524902344s
epoch 245: {'train_loss': '1.24438'}; time used = 0.04044914245605469s
epoch 250: {'train_loss': '1.23561'}; time used = 0.08757901191711426s
epoch 255: {'train_loss': '1.23998'}; time used = 0.06803345680236816s
epoch 260: {'train_loss': '1.23602'}; time used = 0.04663515090942383s
epoch 265: {'train_loss': '1.24147'}; time used = 0.04220128059387207s
epoch 270: {'train_loss': '1.23914'}; time used = 0.025708436965942383s
epoch 275: {'train_loss': '1.24002'}; time used = 0.025394678115844727s
epoch 280: {'train_loss': '1.23712'}; time used = 0.020282745361328125s
epoch 285: {'train_loss': '1.24214'}; time used = 0.03802609443664551s
epoch 290: {'train_loss': '1.23454'}; time used = 0.026132822036743164s
epoch 295: {'train_loss': '1.23716'}; time used = 0.025293588638305664s
epoch 300: {'train_loss': '1.24010'}; time used = 0.019819974899291992s
epoch 305: {'train_loss': '1.24109'}; time used = 0.02160811424255371s
epoch 310: {'train_loss': '1.24250'}; time used = 0.030379533767700195s
epoch 315: {'train_loss': '1.24172'}; time used = 0.0248873233795166s
epoch 320: {'train_loss': '1.23869'}; time used = 0.02198171615600586s
epoch 325: {'train_loss': '1.23668'}; time used = 0.04398918151855469s
epoch 330: {'train_loss': '1.23463'}; time used = 0.026611328125s
epoch 335: {'train_loss': '1.23741'}; time used = 0.05138421058654785s
epoch 340: {'train_loss': '1.23494'}; time used = 0.037819862365722656s
epoch 345: {'train_loss': '1.23496'}; time used = 0.06030893325805664s
epoch 350: {'train_loss': '1.23079'}; time used = 0.02420186996459961s
epoch 355: {'train_loss': '1.23298'}; time used = 0.05593061447143555s
epoch 360: {'train_loss': '1.23575'}; time used = 0.023647546768188477s
epoch 365: {'train_loss': '1.23419'}; time used = 0.02253866195678711s
epoch 370: {'train_loss': '1.23462'}; time used = 0.028561830520629883s
epoch 375: {'train_loss': '1.23477'}; time used = 0.02365732192993164s
epoch 380: {'train_loss': '1.23470'}; time used = 0.02837681770324707s
epoch 385: {'train_loss': '1.23121'}; time used = 0.03254961967468262s
epoch 390: {'train_loss': '1.23620'}; time used = 0.023813962936401367s
epoch 395: {'train_loss': '1.23081'}; time used = 0.02427816390991211s
epoch 400: {'train_loss': '1.23625'}; time used = 0.0274965763092041s
epoch 405: {'train_loss': '1.23580'}; time used = 0.023446083068847656s
epoch 410: {'train_loss': '1.22849'}; time used = 0.05230355262756348s
epoch 415: {'train_loss': '1.23390'}; time used = 0.036754608154296875s
epoch 420: {'train_loss': '1.22903'}; time used = 0.02012038230895996s
epoch 425: {'train_loss': '1.23380'}; time used = 0.019794940948486328s
epoch 430: {'train_loss': '1.23254'}; time used = 0.023639678955078125s
epoch 435: {'train_loss': '1.23200'}; time used = 0.019776344299316406s
epoch 440: {'train_loss': '1.23166'}; time used = 0.020005464553833008s
epoch 445: {'train_loss': '1.22962'}; time used = 0.019790172576904297s
epoch 450: {'train_loss': '1.23168'}; time used = 0.019916057586669922s
epoch 455: {'train_loss': '1.22529'}; time used = 0.01967644691467285s
epoch 460: {'train_loss': '1.23056'}; time used = 0.019572019577026367s
epoch 465: {'train_loss': '1.23077'}; time used = 0.028402090072631836s
epoch 470: {'train_loss': '1.22833'}; time used = 0.019635677337646484s
epoch 475: {'train_loss': '1.22687'}; time used = 0.020958662033081055s
epoch 480: {'train_loss': '1.23369'}; time used = 0.027205705642700195s
epoch 485: {'train_loss': '1.23572'}; time used = 0.036073923110961914s
epoch 490: {'train_loss': '1.22496'}; time used = 0.024271249771118164s
epoch 495: {'train_loss': '1.22870'}; time used = 0.03147006034851074s
epoch 500: {'train_loss': '1.22871'}; time used = 0.03807783126831055s
Finished training. Time used = 7.720165014266968.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.41421'}; time used = 0.05231070518493652s
epoch 10: {'train_loss': '1.33374'}; time used = 0.046874284744262695s
epoch 15: {'train_loss': '1.30530'}; time used = 0.043680667877197266s
epoch 20: {'train_loss': '1.27773'}; time used = 0.032835960388183594s
epoch 25: {'train_loss': '1.25650'}; time used = 0.04206991195678711s
epoch 30: {'train_loss': '1.25248'}; time used = 0.04239511489868164s
epoch 35: {'train_loss': '1.24986'}; time used = 0.05637764930725098s
epoch 40: {'train_loss': '1.23787'}; time used = 0.02740764617919922s
epoch 45: {'train_loss': '1.24397'}; time used = 0.046957969665527344s
epoch 50: {'train_loss': '1.23894'}; time used = 0.02968907356262207s
epoch 55: {'train_loss': '1.23742'}; time used = 0.026696443557739258s
epoch 60: {'train_loss': '1.23594'}; time used = 0.038152456283569336s
epoch 65: {'train_loss': '1.23197'}; time used = 0.027267932891845703s
epoch 70: {'train_loss': '1.22985'}; time used = 0.027376890182495117s
epoch 75: {'train_loss': '1.23801'}; time used = 0.03451204299926758s
epoch 80: {'train_loss': '1.22471'}; time used = 0.027220726013183594s
epoch 85: {'train_loss': '1.23413'}; time used = 0.026320457458496094s
epoch 90: {'train_loss': '1.23198'}; time used = 0.03415679931640625s
epoch 95: {'train_loss': '1.23616'}; time used = 0.04326462745666504s
epoch 100: {'train_loss': '1.22565'}; time used = 0.03963661193847656s
epoch 105: {'train_loss': '1.22827'}; time used = 0.0445554256439209s
epoch 110: {'train_loss': '1.23499'}; time used = 0.05006146430969238s
epoch 115: {'train_loss': '1.22964'}; time used = 0.041115522384643555s
epoch 120: {'train_loss': '1.23190'}; time used = 0.03592181205749512s
epoch 125: {'train_loss': '1.22476'}; time used = 0.03322863578796387s
epoch 130: {'train_loss': '1.23132'}; time used = 0.027730226516723633s
epoch 135: {'train_loss': '1.22672'}; time used = 0.08350682258605957s
epoch 140: {'train_loss': '1.22740'}; time used = 0.03483176231384277s
epoch 145: {'train_loss': '1.23353'}; time used = 0.028923749923706055s
epoch 150: {'train_loss': '1.23235'}; time used = 0.04685664176940918s
epoch 155: {'train_loss': '1.23023'}; time used = 0.025413036346435547s
epoch 160: {'train_loss': '1.23155'}; time used = 0.03288006782531738s
epoch 165: {'train_loss': '1.23308'}; time used = 0.029789447784423828s
epoch 170: {'train_loss': '1.23347'}; time used = 0.04246854782104492s
epoch 175: {'train_loss': '1.23264'}; time used = 0.07112503051757812s
epoch 180: {'train_loss': '1.22921'}; time used = 0.02696967124938965s
epoch 185: {'train_loss': '1.22472'}; time used = 0.049498558044433594s
epoch 190: {'train_loss': '1.22986'}; time used = 0.02680683135986328s
epoch 195: {'train_loss': '1.23140'}; time used = 0.03140974044799805s
epoch 200: {'train_loss': '1.23306'}; time used = 0.0295865535736084s
epoch 205: {'train_loss': '1.23224'}; time used = 0.03730154037475586s
epoch 210: {'train_loss': '1.23400'}; time used = 0.026655197143554688s
epoch 215: {'train_loss': '1.23736'}; time used = 0.026589155197143555s
epoch 220: {'train_loss': '1.22550'}; time used = 0.04650616645812988s
epoch 225: {'train_loss': '1.22178'}; time used = 0.02276921272277832s
epoch 230: {'train_loss': '1.22874'}; time used = 0.032499074935913086s
epoch 235: {'train_loss': '1.23146'}; time used = 0.025408029556274414s
epoch 240: {'train_loss': '1.23673'}; time used = 0.026500940322875977s
epoch 245: {'train_loss': '1.23305'}; time used = 0.02545762062072754s
epoch 250: {'train_loss': '1.22389'}; time used = 0.06134366989135742s
epoch 255: {'train_loss': '1.22689'}; time used = 0.04188060760498047s
epoch 260: {'train_loss': '1.22551'}; time used = 0.033837318420410156s
epoch 265: {'train_loss': '1.23029'}; time used = 0.03251934051513672s
epoch 270: {'train_loss': '1.22862'}; time used = 0.034926652908325195s
epoch 275: {'train_loss': '1.22813'}; time used = 0.023923873901367188s
epoch 280: {'train_loss': '1.22708'}; time used = 0.02436995506286621s
epoch 285: {'train_loss': '1.23261'}; time used = 0.06248354911804199s
epoch 290: {'train_loss': '1.22520'}; time used = 0.03576159477233887s
epoch 295: {'train_loss': '1.22848'}; time used = 0.032692670822143555s
epoch 300: {'train_loss': '1.23070'}; time used = 0.04030418395996094s
epoch 305: {'train_loss': '1.23478'}; time used = 0.02574324607849121s
epoch 310: {'train_loss': '1.23657'}; time used = 0.03313875198364258s
epoch 315: {'train_loss': '1.23591'}; time used = 0.023700475692749023s
epoch 320: {'train_loss': '1.23022'}; time used = 0.024706602096557617s
epoch 325: {'train_loss': '1.22972'}; time used = 0.032042503356933594s
epoch 330: {'train_loss': '1.22705'}; time used = 0.023856401443481445s
epoch 335: {'train_loss': '1.23098'}; time used = 0.023085594177246094s
epoch 340: {'train_loss': '1.22807'}; time used = 0.02272176742553711s
epoch 345: {'train_loss': '1.22737'}; time used = 0.03663325309753418s
epoch 350: {'train_loss': '1.22516'}; time used = 0.02614736557006836s
epoch 355: {'train_loss': '1.22703'}; time used = 0.033466339111328125s
epoch 360: {'train_loss': '1.22961'}; time used = 0.02703571319580078s
epoch 365: {'train_loss': '1.22997'}; time used = 0.03129315376281738s
epoch 370: {'train_loss': '1.22871'}; time used = 0.019886493682861328s
epoch 375: {'train_loss': '1.23089'}; time used = 0.028269529342651367s
epoch 380: {'train_loss': '1.22849'}; time used = 0.03824615478515625s
epoch 385: {'train_loss': '1.22701'}; time used = 0.04082441329956055s
epoch 390: {'train_loss': '1.23112'}; time used = 0.024675846099853516s
epoch 395: {'train_loss': '1.22689'}; time used = 0.03719305992126465s
epoch 400: {'train_loss': '1.23242'}; time used = 0.0391690731048584s
epoch 405: {'train_loss': '1.23288'}; time used = 0.025635957717895508s
epoch 410: {'train_loss': '1.22368'}; time used = 0.026471376419067383s
epoch 415: {'train_loss': '1.23046'}; time used = 0.04143261909484863s
epoch 420: {'train_loss': '1.22570'}; time used = 0.024470090866088867s
epoch 425: {'train_loss': '1.22929'}; time used = 0.03744053840637207s
epoch 430: {'train_loss': '1.22995'}; time used = 0.04374098777770996s
epoch 435: {'train_loss': '1.22885'}; time used = 0.026300430297851562s
epoch 440: {'train_loss': '1.23015'}; time used = 0.02927875518798828s
epoch 445: {'train_loss': '1.22786'}; time used = 0.031810760498046875s
epoch 450: {'train_loss': '1.23021'}; time used = 0.028466224670410156s
epoch 455: {'train_loss': '1.22221'}; time used = 0.02753901481628418s
epoch 460: {'train_loss': '1.22936'}; time used = 0.03477883338928223s
epoch 465: {'train_loss': '1.22918'}; time used = 0.026297807693481445s
epoch 470: {'train_loss': '1.22642'}; time used = 0.02569293975830078s
epoch 475: {'train_loss': '1.22593'}; time used = 0.032776832580566406s
epoch 480: {'train_loss': '1.23287'}; time used = 0.027456283569335938s
epoch 485: {'train_loss': '1.23661'}; time used = 0.036063432693481445s
epoch 490: {'train_loss': '1.22518'}; time used = 0.06680560111999512s
epoch 495: {'train_loss': '1.22828'}; time used = 0.042000770568847656s
epoch 500: {'train_loss': '1.22857'}; time used = 0.03139352798461914s
Finished training. Time used = 8.850760698318481.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.35320'}; time used = 0.041205406188964844s
epoch 10: {'train_loss': '1.29338'}; time used = 0.022716045379638672s
epoch 15: {'train_loss': '1.25770'}; time used = 0.023257017135620117s
epoch 20: {'train_loss': '1.25332'}; time used = 0.03134870529174805s
epoch 25: {'train_loss': '1.24102'}; time used = 0.021962642669677734s
epoch 30: {'train_loss': '1.23900'}; time used = 0.022679567337036133s
epoch 35: {'train_loss': '1.24036'}; time used = 0.04388833045959473s
epoch 40: {'train_loss': '1.22967'}; time used = 0.031632184982299805s
epoch 45: {'train_loss': '1.23629'}; time used = 0.01996755599975586s
epoch 50: {'train_loss': '1.23373'}; time used = 0.026972293853759766s
epoch 55: {'train_loss': '1.23502'}; time used = 0.054402828216552734s
epoch 60: {'train_loss': '1.23692'}; time used = 0.03149867057800293s
epoch 65: {'train_loss': '1.23321'}; time used = 0.019564390182495117s
epoch 70: {'train_loss': '1.23311'}; time used = 0.020521879196166992s
epoch 75: {'train_loss': '1.24074'}; time used = 0.03819012641906738s
epoch 80: {'train_loss': '1.22839'}; time used = 0.030098676681518555s
epoch 85: {'train_loss': '1.23951'}; time used = 0.022617340087890625s
epoch 90: {'train_loss': '1.23757'}; time used = 0.020441055297851562s
epoch 95: {'train_loss': '1.24071'}; time used = 0.01926565170288086s
epoch 100: {'train_loss': '1.22918'}; time used = 0.01921820640563965s
epoch 105: {'train_loss': '1.23391'}; time used = 0.02200770378112793s
epoch 110: {'train_loss': '1.23995'}; time used = 0.02057790756225586s
epoch 115: {'train_loss': '1.23564'}; time used = 0.024673938751220703s
epoch 120: {'train_loss': '1.23522'}; time used = 0.03953695297241211s
epoch 125: {'train_loss': '1.23025'}; time used = 0.03885054588317871s
epoch 130: {'train_loss': '1.23524'}; time used = 0.023081541061401367s
epoch 135: {'train_loss': '1.23122'}; time used = 0.041213274002075195s
epoch 140: {'train_loss': '1.23151'}; time used = 0.028596878051757812s
epoch 145: {'train_loss': '1.23728'}; time used = 0.02774524688720703s
epoch 150: {'train_loss': '1.23719'}; time used = 0.02860283851623535s
epoch 155: {'train_loss': '1.23903'}; time used = 0.021014690399169922s
epoch 160: {'train_loss': '1.23814'}; time used = 0.03059530258178711s
epoch 165: {'train_loss': '1.23837'}; time used = 0.019135236740112305s
epoch 170: {'train_loss': '1.23819'}; time used = 0.07389521598815918s
epoch 175: {'train_loss': '1.23566'}; time used = 0.03733253479003906s
epoch 180: {'train_loss': '1.23542'}; time used = 0.03278493881225586s
epoch 185: {'train_loss': '1.22986'}; time used = 0.019081830978393555s
epoch 190: {'train_loss': '1.23474'}; time used = 0.01900935173034668s
epoch 195: {'train_loss': '1.23529'}; time used = 0.018855810165405273s
epoch 200: {'train_loss': '1.23828'}; time used = 0.01842975616455078s
epoch 205: {'train_loss': '1.23567'}; time used = 0.019255399703979492s
epoch 210: {'train_loss': '1.23683'}; time used = 0.01943373680114746s
epoch 215: {'train_loss': '1.24254'}; time used = 0.018735408782958984s
epoch 220: {'train_loss': '1.23084'}; time used = 0.028607606887817383s
epoch 225: {'train_loss': '1.22800'}; time used = 0.023664236068725586s
epoch 230: {'train_loss': '1.23246'}; time used = 0.02719736099243164s
epoch 235: {'train_loss': '1.23634'}; time used = 0.02230525016784668s
epoch 240: {'train_loss': '1.23994'}; time used = 0.023410797119140625s
epoch 245: {'train_loss': '1.24039'}; time used = 0.028051137924194336s
epoch 250: {'train_loss': '1.22907'}; time used = 0.03177642822265625s
epoch 255: {'train_loss': '1.23114'}; time used = 0.028528690338134766s
epoch 260: {'train_loss': '1.23161'}; time used = 0.027025938034057617s
epoch 265: {'train_loss': '1.23693'}; time used = 0.018514394760131836s
epoch 270: {'train_loss': '1.23328'}; time used = 0.018576622009277344s
epoch 275: {'train_loss': '1.23277'}; time used = 0.018989086151123047s
epoch 280: {'train_loss': '1.23089'}; time used = 0.018247365951538086s
epoch 285: {'train_loss': '1.23683'}; time used = 0.018499374389648438s
epoch 290: {'train_loss': '1.23089'}; time used = 0.03458452224731445s
epoch 295: {'train_loss': '1.23156'}; time used = 0.03842616081237793s
epoch 300: {'train_loss': '1.23565'}; time used = 0.06721949577331543s
epoch 305: {'train_loss': '1.23889'}; time used = 0.025734901428222656s
epoch 310: {'train_loss': '1.23944'}; time used = 0.019577503204345703s
epoch 315: {'train_loss': '1.23893'}; time used = 0.018947601318359375s
epoch 320: {'train_loss': '1.23474'}; time used = 0.01905536651611328s
epoch 325: {'train_loss': '1.23448'}; time used = 0.0189208984375s
epoch 330: {'train_loss': '1.23034'}; time used = 0.01920008659362793s
epoch 335: {'train_loss': '1.23583'}; time used = 0.01892876625061035s
epoch 340: {'train_loss': '1.23384'}; time used = 0.018964052200317383s
epoch 345: {'train_loss': '1.23698'}; time used = 0.019028902053833008s
epoch 350: {'train_loss': '1.23028'}; time used = 0.01890397071838379s
epoch 355: {'train_loss': '1.23054'}; time used = 0.019037723541259766s
epoch 360: {'train_loss': '1.23742'}; time used = 0.01904010772705078s
epoch 365: {'train_loss': '1.23188'}; time used = 0.01878952980041504s
epoch 370: {'train_loss': '1.23394'}; time used = 0.018952608108520508s
epoch 375: {'train_loss': '1.23454'}; time used = 0.018641948699951172s
epoch 380: {'train_loss': '1.23226'}; time used = 0.02903270721435547s
epoch 385: {'train_loss': '1.22906'}; time used = 0.018702983856201172s
epoch 390: {'train_loss': '1.23443'}; time used = 0.019089460372924805s
epoch 395: {'train_loss': '1.22981'}; time used = 0.019257068634033203s
epoch 400: {'train_loss': '1.23573'}; time used = 0.018546342849731445s
epoch 405: {'train_loss': '1.23584'}; time used = 0.02251601219177246s
epoch 410: {'train_loss': '1.22713'}; time used = 0.029195547103881836s
epoch 415: {'train_loss': '1.23344'}; time used = 0.030592679977416992s
epoch 420: {'train_loss': '1.23032'}; time used = 0.02535867691040039s
epoch 425: {'train_loss': '1.23581'}; time used = 0.019169092178344727s
epoch 430: {'train_loss': '1.23648'}; time used = 0.01976919174194336s
epoch 435: {'train_loss': '1.23315'}; time used = 0.024779319763183594s
epoch 440: {'train_loss': '1.23539'}; time used = 0.021843433380126953s
epoch 445: {'train_loss': '1.23118'}; time used = 0.02003169059753418s
epoch 450: {'train_loss': '1.23489'}; time used = 0.018800020217895508s
epoch 455: {'train_loss': '1.22738'}; time used = 0.01865410804748535s
epoch 460: {'train_loss': '1.23443'}; time used = 0.021448612213134766s
epoch 465: {'train_loss': '1.23810'}; time used = 0.049767255783081055s
epoch 470: {'train_loss': '1.23483'}; time used = 0.02555227279663086s
epoch 475: {'train_loss': '1.23185'}; time used = 0.01945805549621582s
epoch 480: {'train_loss': '1.23776'}; time used = 0.018560171127319336s
epoch 485: {'train_loss': '1.24165'}; time used = 0.0188596248626709s
epoch 490: {'train_loss': '1.22944'}; time used = 0.018928050994873047s
epoch 495: {'train_loss': '1.23209'}; time used = 0.01930403709411621s
epoch 500: {'train_loss': '1.23288'}; time used = 0.018498897552490234s
Finished training. Time used = 9.017369747161865.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.76899'}; time used = 0.0397028923034668s
epoch 10: {'train_loss': '1.69323'}; time used = 0.03255176544189453s
epoch 15: {'train_loss': '1.62283'}; time used = 0.037047386169433594s
epoch 20: {'train_loss': '1.56586'}; time used = 0.0541994571685791s
epoch 25: {'train_loss': '1.52213'}; time used = 0.046520233154296875s
epoch 30: {'train_loss': '1.48343'}; time used = 0.04427337646484375s
epoch 35: {'train_loss': '1.45855'}; time used = 0.05321907997131348s
epoch 40: {'train_loss': '1.42118'}; time used = 0.04432344436645508s
epoch 45: {'train_loss': '1.40755'}; time used = 0.03390026092529297s
epoch 50: {'train_loss': '1.39208'}; time used = 0.02596735954284668s
epoch 55: {'train_loss': '1.37785'}; time used = 0.02427530288696289s
epoch 60: {'train_loss': '1.35926'}; time used = 0.03202509880065918s
epoch 65: {'train_loss': '1.35607'}; time used = 0.03758955001831055s
epoch 70: {'train_loss': '1.34291'}; time used = 0.03296518325805664s
epoch 75: {'train_loss': '1.33780'}; time used = 0.031777143478393555s
epoch 80: {'train_loss': '1.33039'}; time used = 0.02669072151184082s
epoch 85: {'train_loss': '1.32341'}; time used = 0.02514028549194336s
epoch 90: {'train_loss': '1.32037'}; time used = 0.03413081169128418s
epoch 95: {'train_loss': '1.31670'}; time used = 0.028133869171142578s
epoch 100: {'train_loss': '1.30501'}; time used = 0.029247283935546875s
epoch 105: {'train_loss': '1.30254'}; time used = 0.028456687927246094s
epoch 110: {'train_loss': '1.29976'}; time used = 0.02358841896057129s
epoch 115: {'train_loss': '1.29417'}; time used = 0.02802729606628418s
epoch 120: {'train_loss': '1.28860'}; time used = 0.020802021026611328s
epoch 125: {'train_loss': '1.28040'}; time used = 0.025389909744262695s
epoch 130: {'train_loss': '1.27909'}; time used = 0.025329113006591797s
epoch 135: {'train_loss': '1.27272'}; time used = 0.02511453628540039s
epoch 140: {'train_loss': '1.27444'}; time used = 0.02514362335205078s
epoch 145: {'train_loss': '1.27028'}; time used = 0.02493762969970703s
epoch 150: {'train_loss': '1.26563'}; time used = 0.025035858154296875s
epoch 155: {'train_loss': '1.26416'}; time used = 0.021397113800048828s
epoch 160: {'train_loss': '1.26378'}; time used = 0.025473833084106445s
epoch 165: {'train_loss': '1.25984'}; time used = 0.025107145309448242s
epoch 170: {'train_loss': '1.25917'}; time used = 0.03467702865600586s
epoch 175: {'train_loss': '1.25821'}; time used = 0.025320053100585938s
epoch 180: {'train_loss': '1.25138'}; time used = 0.02487349510192871s
epoch 185: {'train_loss': '1.25007'}; time used = 0.02432990074157715s
epoch 190: {'train_loss': '1.24774'}; time used = 0.024872303009033203s
epoch 195: {'train_loss': '1.24850'}; time used = 0.022475719451904297s
epoch 200: {'train_loss': '1.24925'}; time used = 0.02434563636779785s
epoch 205: {'train_loss': '1.24940'}; time used = 0.023346424102783203s
epoch 210: {'train_loss': '1.25034'}; time used = 0.0225679874420166s
epoch 215: {'train_loss': '1.25113'}; time used = 0.024790525436401367s
epoch 220: {'train_loss': '1.23953'}; time used = 0.024280786514282227s
epoch 225: {'train_loss': '1.23525'}; time used = 0.06691527366638184s
epoch 230: {'train_loss': '1.24245'}; time used = 0.019826412200927734s
epoch 235: {'train_loss': '1.24413'}; time used = 0.031026363372802734s
epoch 240: {'train_loss': '1.24908'}; time used = 0.021764039993286133s
epoch 245: {'train_loss': '1.24438'}; time used = 0.024043560028076172s
epoch 250: {'train_loss': '1.23561'}; time used = 0.029591798782348633s
epoch 255: {'train_loss': '1.23998'}; time used = 0.03988218307495117s
epoch 260: {'train_loss': '1.23602'}; time used = 0.024925708770751953s
epoch 265: {'train_loss': '1.24147'}; time used = 0.023970603942871094s
epoch 270: {'train_loss': '1.23914'}; time used = 0.031183958053588867s
epoch 275: {'train_loss': '1.24002'}; time used = 0.021728992462158203s
epoch 280: {'train_loss': '1.23712'}; time used = 0.020923137664794922s
epoch 285: {'train_loss': '1.24214'}; time used = 0.021216154098510742s
epoch 290: {'train_loss': '1.23454'}; time used = 0.028700590133666992s
epoch 295: {'train_loss': '1.23716'}; time used = 0.02130293846130371s
epoch 300: {'train_loss': '1.24010'}; time used = 0.022380590438842773s
epoch 305: {'train_loss': '1.24109'}; time used = 0.022461891174316406s
epoch 310: {'train_loss': '1.24250'}; time used = 0.02980518341064453s
epoch 315: {'train_loss': '1.24172'}; time used = 0.02402782440185547s
epoch 320: {'train_loss': '1.23869'}; time used = 0.03142547607421875s
epoch 325: {'train_loss': '1.23668'}; time used = 0.0220181941986084s
epoch 330: {'train_loss': '1.23463'}; time used = 0.023743867874145508s
epoch 335: {'train_loss': '1.23741'}; time used = 0.042253732681274414s
epoch 340: {'train_loss': '1.23494'}; time used = 0.03296661376953125s
epoch 345: {'train_loss': '1.23496'}; time used = 0.02378249168395996s
epoch 350: {'train_loss': '1.23079'}; time used = 0.03013300895690918s
epoch 355: {'train_loss': '1.23298'}; time used = 0.02424478530883789s
epoch 360: {'train_loss': '1.23575'}; time used = 0.024307966232299805s
epoch 365: {'train_loss': '1.23419'}; time used = 0.03400874137878418s
epoch 370: {'train_loss': '1.23462'}; time used = 0.025751590728759766s
epoch 375: {'train_loss': '1.23477'}; time used = 0.02579641342163086s
epoch 380: {'train_loss': '1.23470'}; time used = 0.04776716232299805s
epoch 385: {'train_loss': '1.23121'}; time used = 0.0396876335144043s
epoch 390: {'train_loss': '1.23620'}; time used = 0.035080671310424805s
epoch 395: {'train_loss': '1.23081'}; time used = 0.024651527404785156s
epoch 400: {'train_loss': '1.23625'}; time used = 0.03992462158203125s
epoch 405: {'train_loss': '1.23580'}; time used = 0.025244474411010742s
epoch 410: {'train_loss': '1.22849'}; time used = 0.03288078308105469s
epoch 415: {'train_loss': '1.23390'}; time used = 0.02737569808959961s
epoch 420: {'train_loss': '1.22903'}; time used = 0.024711132049560547s
epoch 425: {'train_loss': '1.23380'}; time used = 0.03420901298522949s
epoch 430: {'train_loss': '1.23254'}; time used = 0.02541971206665039s
epoch 435: {'train_loss': '1.23200'}; time used = 0.02503657341003418s
epoch 440: {'train_loss': '1.23166'}; time used = 0.03215909004211426s
epoch 445: {'train_loss': '1.22962'}; time used = 0.024767637252807617s
epoch 450: {'train_loss': '1.23168'}; time used = 0.025982379913330078s
epoch 455: {'train_loss': '1.22529'}; time used = 0.03459453582763672s
epoch 460: {'train_loss': '1.23056'}; time used = 0.023788928985595703s
epoch 465: {'train_loss': '1.23077'}; time used = 0.022526025772094727s
epoch 470: {'train_loss': '1.22833'}; time used = 0.02526116371154785s
epoch 475: {'train_loss': '1.22687'}; time used = 0.04947185516357422s
epoch 480: {'train_loss': '1.23369'}; time used = 0.04839920997619629s
epoch 485: {'train_loss': '1.23572'}; time used = 0.027498960494995117s
epoch 490: {'train_loss': '1.22496'}; time used = 0.027315855026245117s
epoch 495: {'train_loss': '1.22870'}; time used = 0.028162479400634766s
epoch 500: {'train_loss': '1.22871'}; time used = 0.045484304428100586s
Finished training. Time used = 7.425847291946411.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.41421'}; time used = 0.049096107482910156s
epoch 10: {'train_loss': '1.33374'}; time used = 0.025232315063476562s
epoch 15: {'train_loss': '1.30530'}; time used = 0.026905059814453125s
epoch 20: {'train_loss': '1.27773'}; time used = 0.03892159461975098s
epoch 25: {'train_loss': '1.25650'}; time used = 0.03462958335876465s
epoch 30: {'train_loss': '1.25248'}; time used = 0.02413034439086914s
epoch 35: {'train_loss': '1.24986'}; time used = 0.023911237716674805s
epoch 40: {'train_loss': '1.23787'}; time used = 0.02430105209350586s
epoch 45: {'train_loss': '1.24397'}; time used = 0.02718353271484375s
epoch 50: {'train_loss': '1.23894'}; time used = 0.024038076400756836s
epoch 55: {'train_loss': '1.23742'}; time used = 0.023739337921142578s
epoch 60: {'train_loss': '1.23594'}; time used = 0.024031877517700195s
epoch 65: {'train_loss': '1.23197'}; time used = 0.024055004119873047s
epoch 70: {'train_loss': '1.22985'}; time used = 0.02408742904663086s
epoch 75: {'train_loss': '1.23801'}; time used = 0.02413201332092285s
epoch 80: {'train_loss': '1.22471'}; time used = 0.02406454086303711s
epoch 85: {'train_loss': '1.23413'}; time used = 0.024061203002929688s
epoch 90: {'train_loss': '1.23198'}; time used = 0.023979902267456055s
epoch 95: {'train_loss': '1.23616'}; time used = 0.02400827407836914s
epoch 100: {'train_loss': '1.22565'}; time used = 0.02409815788269043s
epoch 105: {'train_loss': '1.22827'}; time used = 0.0635690689086914s
epoch 110: {'train_loss': '1.23499'}; time used = 0.022797107696533203s
epoch 115: {'train_loss': '1.22964'}; time used = 0.021423816680908203s
epoch 120: {'train_loss': '1.23190'}; time used = 0.02055191993713379s
epoch 125: {'train_loss': '1.22476'}; time used = 0.02036142349243164s
epoch 130: {'train_loss': '1.23132'}; time used = 0.025665760040283203s
epoch 135: {'train_loss': '1.22672'}; time used = 0.025112628936767578s
epoch 140: {'train_loss': '1.22740'}; time used = 0.03261828422546387s
epoch 145: {'train_loss': '1.23353'}; time used = 0.03870749473571777s
epoch 150: {'train_loss': '1.23235'}; time used = 0.022943496704101562s
epoch 155: {'train_loss': '1.23023'}; time used = 0.0371856689453125s
epoch 160: {'train_loss': '1.23155'}; time used = 0.027362346649169922s
epoch 165: {'train_loss': '1.23308'}; time used = 0.023380517959594727s
epoch 170: {'train_loss': '1.23347'}; time used = 0.024605751037597656s
epoch 175: {'train_loss': '1.23264'}; time used = 0.02591109275817871s
epoch 180: {'train_loss': '1.22921'}; time used = 0.021779775619506836s
epoch 185: {'train_loss': '1.22472'}; time used = 0.027041912078857422s
epoch 190: {'train_loss': '1.22986'}; time used = 0.02819991111755371s
epoch 195: {'train_loss': '1.23140'}; time used = 0.019094228744506836s
epoch 200: {'train_loss': '1.23306'}; time used = 0.0207974910736084s
epoch 205: {'train_loss': '1.23224'}; time used = 0.020603656768798828s
epoch 210: {'train_loss': '1.23400'}; time used = 0.028105974197387695s
epoch 215: {'train_loss': '1.23736'}; time used = 0.023926734924316406s
epoch 220: {'train_loss': '1.22550'}; time used = 0.0209195613861084s
epoch 225: {'train_loss': '1.22178'}; time used = 0.020803213119506836s
epoch 230: {'train_loss': '1.22874'}; time used = 0.020546436309814453s
epoch 235: {'train_loss': '1.23146'}; time used = 0.020903587341308594s
epoch 240: {'train_loss': '1.23673'}; time used = 0.020768404006958008s
epoch 245: {'train_loss': '1.23305'}; time used = 0.020459651947021484s
epoch 250: {'train_loss': '1.22389'}; time used = 0.02043914794921875s
epoch 255: {'train_loss': '1.22689'}; time used = 0.020058393478393555s
epoch 260: {'train_loss': '1.22551'}; time used = 0.023175716400146484s
epoch 265: {'train_loss': '1.23029'}; time used = 0.028690099716186523s
epoch 270: {'train_loss': '1.22862'}; time used = 0.020383834838867188s
epoch 275: {'train_loss': '1.22813'}; time used = 0.019988536834716797s
epoch 280: {'train_loss': '1.22708'}; time used = 0.019876956939697266s
epoch 285: {'train_loss': '1.23261'}; time used = 0.02460479736328125s
epoch 290: {'train_loss': '1.22520'}; time used = 0.02510380744934082s
epoch 295: {'train_loss': '1.22848'}; time used = 0.023849964141845703s
epoch 300: {'train_loss': '1.23070'}; time used = 0.021135330200195312s
epoch 305: {'train_loss': '1.23478'}; time used = 0.026904821395874023s
epoch 310: {'train_loss': '1.23657'}; time used = 0.021979808807373047s
epoch 315: {'train_loss': '1.23591'}; time used = 0.01990818977355957s
epoch 320: {'train_loss': '1.23022'}; time used = 0.01994609832763672s
epoch 325: {'train_loss': '1.22972'}; time used = 0.023638010025024414s
epoch 330: {'train_loss': '1.22705'}; time used = 0.023865699768066406s
epoch 335: {'train_loss': '1.23098'}; time used = 0.020441055297851562s
epoch 340: {'train_loss': '1.22807'}; time used = 0.019565582275390625s
epoch 345: {'train_loss': '1.22737'}; time used = 0.020051956176757812s
epoch 350: {'train_loss': '1.22516'}; time used = 0.025379180908203125s
epoch 355: {'train_loss': '1.22703'}; time used = 0.019646644592285156s
epoch 360: {'train_loss': '1.22961'}; time used = 0.04185080528259277s
epoch 365: {'train_loss': '1.22997'}; time used = 0.02480459213256836s
epoch 370: {'train_loss': '1.22871'}; time used = 0.025080204010009766s
epoch 375: {'train_loss': '1.23089'}; time used = 0.021782636642456055s
epoch 380: {'train_loss': '1.22849'}; time used = 0.028034448623657227s
epoch 385: {'train_loss': '1.22701'}; time used = 0.027321815490722656s
epoch 390: {'train_loss': '1.23112'}; time used = 0.02978038787841797s
epoch 395: {'train_loss': '1.22689'}; time used = 0.026804685592651367s
epoch 400: {'train_loss': '1.23242'}; time used = 0.02861762046813965s
epoch 405: {'train_loss': '1.23288'}; time used = 0.02030158042907715s
epoch 410: {'train_loss': '1.22368'}; time used = 0.020328760147094727s
epoch 415: {'train_loss': '1.23046'}; time used = 0.02007913589477539s
epoch 420: {'train_loss': '1.22570'}; time used = 0.02048325538635254s
epoch 425: {'train_loss': '1.22929'}; time used = 0.03027796745300293s
epoch 430: {'train_loss': '1.22995'}; time used = 0.030439138412475586s
epoch 435: {'train_loss': '1.22885'}; time used = 0.02839493751525879s
epoch 440: {'train_loss': '1.23015'}; time used = 0.020244598388671875s
epoch 445: {'train_loss': '1.22786'}; time used = 0.020375967025756836s
epoch 450: {'train_loss': '1.23021'}; time used = 0.020372867584228516s
epoch 455: {'train_loss': '1.22221'}; time used = 0.020044803619384766s
epoch 460: {'train_loss': '1.22936'}; time used = 0.020117521286010742s
epoch 465: {'train_loss': '1.22918'}; time used = 0.02009892463684082s
epoch 470: {'train_loss': '1.22642'}; time used = 0.020081281661987305s
epoch 475: {'train_loss': '1.22593'}; time used = 0.0200345516204834s
epoch 480: {'train_loss': '1.23287'}; time used = 0.040572166442871094s
epoch 485: {'train_loss': '1.23661'}; time used = 0.02002859115600586s
epoch 490: {'train_loss': '1.22518'}; time used = 0.01968669891357422s
epoch 495: {'train_loss': '1.22828'}; time used = 0.019527673721313477s
epoch 500: {'train_loss': '1.22857'}; time used = 0.020047426223754883s
Finished training. Time used = 10.816949367523193.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.35009'}; time used = 0.04115939140319824s
epoch 10: {'train_loss': '1.30897'}; time used = 0.03684544563293457s
epoch 15: {'train_loss': '1.26906'}; time used = 0.04880332946777344s
epoch 20: {'train_loss': '1.25395'}; time used = 0.033158063888549805s
epoch 25: {'train_loss': '1.24082'}; time used = 0.03612327575683594s
epoch 30: {'train_loss': '1.23866'}; time used = 0.03797316551208496s
epoch 35: {'train_loss': '1.23810'}; time used = 0.0401766300201416s
epoch 40: {'train_loss': '1.22798'}; time used = 0.03431344032287598s
epoch 45: {'train_loss': '1.23497'}; time used = 0.03327536582946777s
epoch 50: {'train_loss': '1.23155'}; time used = 0.026778459548950195s
epoch 55: {'train_loss': '1.23339'}; time used = 0.027811527252197266s
epoch 60: {'train_loss': '1.23487'}; time used = 0.026632070541381836s
epoch 65: {'train_loss': '1.23192'}; time used = 0.027560710906982422s
epoch 70: {'train_loss': '1.23085'}; time used = 0.029124736785888672s
epoch 75: {'train_loss': '1.23891'}; time used = 0.02788519859313965s
epoch 80: {'train_loss': '1.22632'}; time used = 0.027823448181152344s
epoch 85: {'train_loss': '1.23679'}; time used = 0.026412248611450195s
epoch 90: {'train_loss': '1.23470'}; time used = 0.038529396057128906s
epoch 95: {'train_loss': '1.23756'}; time used = 0.027083396911621094s
epoch 100: {'train_loss': '1.22704'}; time used = 0.030810117721557617s
epoch 105: {'train_loss': '1.23123'}; time used = 0.04879593849182129s
epoch 110: {'train_loss': '1.23764'}; time used = 0.02843928337097168s
epoch 115: {'train_loss': '1.23341'}; time used = 0.03316688537597656s
epoch 120: {'train_loss': '1.23356'}; time used = 0.03310036659240723s
epoch 125: {'train_loss': '1.22837'}; time used = 0.02831292152404785s
epoch 130: {'train_loss': '1.23398'}; time used = 0.03455996513366699s
epoch 135: {'train_loss': '1.22993'}; time used = 0.050096750259399414s
epoch 140: {'train_loss': '1.23061'}; time used = 0.04525303840637207s
epoch 145: {'train_loss': '1.23568'}; time used = 0.03469133377075195s
epoch 150: {'train_loss': '1.23455'}; time used = 0.03995490074157715s
epoch 155: {'train_loss': '1.23260'}; time used = 0.02399444580078125s
epoch 160: {'train_loss': '1.23482'}; time used = 0.023687362670898438s
epoch 165: {'train_loss': '1.23634'}; time used = 0.023322343826293945s
epoch 170: {'train_loss': '1.23511'}; time used = 0.024135351181030273s
epoch 175: {'train_loss': '1.23412'}; time used = 0.025237560272216797s
epoch 180: {'train_loss': '1.23125'}; time used = 0.025425195693969727s
epoch 185: {'train_loss': '1.22755'}; time used = 0.02545022964477539s
epoch 190: {'train_loss': '1.23213'}; time used = 0.02494955062866211s
epoch 195: {'train_loss': '1.23362'}; time used = 0.025379180908203125s
epoch 200: {'train_loss': '1.23566'}; time used = 0.02643132209777832s
epoch 205: {'train_loss': '1.23448'}; time used = 0.024441003799438477s
epoch 210: {'train_loss': '1.23582'}; time used = 0.024590253829956055s
epoch 215: {'train_loss': '1.23954'}; time used = 0.029227733612060547s
epoch 220: {'train_loss': '1.22947'}; time used = 0.02580094337463379s
epoch 225: {'train_loss': '1.22574'}; time used = 0.03940129280090332s
epoch 230: {'train_loss': '1.23186'}; time used = 0.025995492935180664s
epoch 235: {'train_loss': '1.23377'}; time used = 0.03495454788208008s
epoch 240: {'train_loss': '1.23822'}; time used = 0.02929067611694336s
epoch 245: {'train_loss': '1.23543'}; time used = 0.024993896484375s
epoch 250: {'train_loss': '1.22824'}; time used = 0.024416685104370117s
epoch 255: {'train_loss': '1.22964'}; time used = 0.02557682991027832s
epoch 260: {'train_loss': '1.22949'}; time used = 0.02436518669128418s
epoch 265: {'train_loss': '1.23273'}; time used = 0.0315098762512207s
epoch 270: {'train_loss': '1.23200'}; time used = 0.02801036834716797s
epoch 275: {'train_loss': '1.23069'}; time used = 0.024486541748046875s
epoch 280: {'train_loss': '1.22882'}; time used = 0.032534122467041016s
epoch 285: {'train_loss': '1.23528'}; time used = 0.026918411254882812s
epoch 290: {'train_loss': '1.22735'}; time used = 0.03376269340515137s
epoch 295: {'train_loss': '1.23015'}; time used = 0.05305671691894531s
epoch 300: {'train_loss': '1.23280'}; time used = 0.028354883193969727s
epoch 305: {'train_loss': '1.23650'}; time used = 0.03056621551513672s
epoch 310: {'train_loss': '1.23760'}; time used = 0.033327579498291016s
epoch 315: {'train_loss': '1.23745'}; time used = 0.02422022819519043s
epoch 320: {'train_loss': '1.23317'}; time used = 0.023237228393554688s
epoch 325: {'train_loss': '1.23296'}; time used = 0.023199796676635742s
epoch 330: {'train_loss': '1.22912'}; time used = 0.022884845733642578s
epoch 335: {'train_loss': '1.23531'}; time used = 0.02509140968322754s
epoch 340: {'train_loss': '1.23225'}; time used = 0.024875164031982422s
epoch 345: {'train_loss': '1.22948'}; time used = 0.023700952529907227s
epoch 350: {'train_loss': '1.22771'}; time used = 0.0248568058013916s
epoch 355: {'train_loss': '1.22900'}; time used = 0.02457571029663086s
epoch 360: {'train_loss': '1.23299'}; time used = 0.023799657821655273s
epoch 365: {'train_loss': '1.23048'}; time used = 0.02393054962158203s
epoch 370: {'train_loss': '1.23283'}; time used = 0.03334403038024902s
epoch 375: {'train_loss': '1.23316'}; time used = 0.028375864028930664s
epoch 380: {'train_loss': '1.23087'}; time used = 0.020725488662719727s
epoch 385: {'train_loss': '1.22826'}; time used = 0.02128434181213379s
epoch 390: {'train_loss': '1.23352'}; time used = 0.020059585571289062s
epoch 395: {'train_loss': '1.22898'}; time used = 0.021892547607421875s
epoch 400: {'train_loss': '1.23476'}; time used = 0.08286046981811523s
epoch 405: {'train_loss': '1.23565'}; time used = 0.0261991024017334s
epoch 410: {'train_loss': '1.22605'}; time used = 0.026445865631103516s
epoch 415: {'train_loss': '1.23275'}; time used = 0.02493429183959961s
epoch 420: {'train_loss': '1.22766'}; time used = 0.026005268096923828s
epoch 425: {'train_loss': '1.23147'}; time used = 0.022858619689941406s
epoch 430: {'train_loss': '1.23159'}; time used = 0.022327423095703125s
epoch 435: {'train_loss': '1.23132'}; time used = 0.021297931671142578s
epoch 440: {'train_loss': '1.23203'}; time used = 0.021299123764038086s
epoch 445: {'train_loss': '1.22919'}; time used = 0.021515846252441406s
epoch 450: {'train_loss': '1.23184'}; time used = 0.02101278305053711s
epoch 455: {'train_loss': '1.22443'}; time used = 0.03247332572937012s
epoch 460: {'train_loss': '1.23114'}; time used = 0.024611473083496094s
epoch 465: {'train_loss': '1.23271'}; time used = 0.028853178024291992s
epoch 470: {'train_loss': '1.22942'}; time used = 0.024113178253173828s
epoch 475: {'train_loss': '1.22805'}; time used = 0.023514747619628906s
epoch 480: {'train_loss': '1.23405'}; time used = 0.042236328125s
epoch 485: {'train_loss': '1.23925'}; time used = 0.05749845504760742s
epoch 490: {'train_loss': '1.22685'}; time used = 0.029022216796875s
epoch 495: {'train_loss': '1.23048'}; time used = 0.0297243595123291s
epoch 500: {'train_loss': '1.23169'}; time used = 0.03718304634094238s
Finished training. Time used = 9.79556655883789.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.41421'}; time used = 0.05510067939758301s
epoch 10: {'train_loss': '1.33374'}; time used = 0.029291152954101562s
epoch 15: {'train_loss': '1.30530'}; time used = 0.03647971153259277s
epoch 20: {'train_loss': '1.27773'}; time used = 0.03885483741760254s
epoch 25: {'train_loss': '1.25650'}; time used = 0.036594390869140625s
epoch 30: {'train_loss': '1.25248'}; time used = 0.03980588912963867s
epoch 35: {'train_loss': '1.24986'}; time used = 0.0294344425201416s
epoch 40: {'train_loss': '1.23787'}; time used = 0.029842615127563477s
epoch 45: {'train_loss': '1.24397'}; time used = 0.025046586990356445s
epoch 50: {'train_loss': '1.23894'}; time used = 0.02286696434020996s
epoch 55: {'train_loss': '1.23742'}; time used = 0.03311324119567871s
epoch 60: {'train_loss': '1.23594'}; time used = 0.02321004867553711s
epoch 65: {'train_loss': '1.23197'}; time used = 0.02427053451538086s
epoch 70: {'train_loss': '1.22985'}; time used = 0.032691001892089844s
epoch 75: {'train_loss': '1.23801'}; time used = 0.021701812744140625s
epoch 80: {'train_loss': '1.22471'}; time used = 0.027086734771728516s
epoch 85: {'train_loss': '1.23413'}; time used = 0.017633914947509766s
epoch 90: {'train_loss': '1.23198'}; time used = 0.01776719093322754s
epoch 95: {'train_loss': '1.23616'}; time used = 0.02697443962097168s
epoch 100: {'train_loss': '1.22565'}; time used = 0.017816781997680664s
epoch 105: {'train_loss': '1.22827'}; time used = 0.018514394760131836s
epoch 110: {'train_loss': '1.23499'}; time used = 0.018672704696655273s
epoch 115: {'train_loss': '1.22964'}; time used = 0.030397653579711914s
epoch 120: {'train_loss': '1.23190'}; time used = 0.0391087532043457s
epoch 125: {'train_loss': '1.22476'}; time used = 0.027100086212158203s
epoch 130: {'train_loss': '1.23132'}; time used = 0.024271488189697266s
epoch 135: {'train_loss': '1.22672'}; time used = 0.031865596771240234s
epoch 140: {'train_loss': '1.22740'}; time used = 0.025168180465698242s
epoch 145: {'train_loss': '1.23353'}; time used = 0.0322263240814209s
epoch 150: {'train_loss': '1.23235'}; time used = 0.023986101150512695s
epoch 155: {'train_loss': '1.23023'}; time used = 0.0330042839050293s
epoch 160: {'train_loss': '1.23155'}; time used = 0.0706946849822998s
epoch 165: {'train_loss': '1.23308'}; time used = 0.028366565704345703s
epoch 170: {'train_loss': '1.23347'}; time used = 0.033393144607543945s
epoch 175: {'train_loss': '1.23264'}; time used = 0.03158235549926758s
epoch 180: {'train_loss': '1.22921'}; time used = 0.048009395599365234s
epoch 185: {'train_loss': '1.22472'}; time used = 0.03300976753234863s
epoch 190: {'train_loss': '1.22986'}; time used = 0.02624344825744629s
epoch 195: {'train_loss': '1.23140'}; time used = 0.03546905517578125s
epoch 200: {'train_loss': '1.23306'}; time used = 0.027914047241210938s
epoch 205: {'train_loss': '1.23224'}; time used = 0.034444332122802734s
epoch 210: {'train_loss': '1.23400'}; time used = 0.028174638748168945s
epoch 215: {'train_loss': '1.23736'}; time used = 0.037642478942871094s
epoch 220: {'train_loss': '1.22550'}; time used = 0.027338027954101562s
epoch 225: {'train_loss': '1.22178'}; time used = 0.035305023193359375s
epoch 230: {'train_loss': '1.22874'}; time used = 0.03569531440734863s
epoch 235: {'train_loss': '1.23146'}; time used = 0.03426623344421387s
epoch 240: {'train_loss': '1.23673'}; time used = 0.0263519287109375s
epoch 245: {'train_loss': '1.23305'}; time used = 0.044773101806640625s
epoch 250: {'train_loss': '1.22389'}; time used = 0.027491331100463867s
epoch 255: {'train_loss': '1.22689'}; time used = 0.026978492736816406s
epoch 260: {'train_loss': '1.22551'}; time used = 0.03666377067565918s
epoch 265: {'train_loss': '1.23029'}; time used = 0.02645254135131836s
epoch 270: {'train_loss': '1.22862'}; time used = 0.03550577163696289s
epoch 275: {'train_loss': '1.22813'}; time used = 0.027453899383544922s
epoch 280: {'train_loss': '1.22708'}; time used = 0.027901172637939453s
epoch 285: {'train_loss': '1.23261'}; time used = 0.033429622650146484s
epoch 290: {'train_loss': '1.22520'}; time used = 0.02691340446472168s
epoch 295: {'train_loss': '1.22848'}; time used = 0.03382420539855957s
epoch 300: {'train_loss': '1.23070'}; time used = 0.02716827392578125s
epoch 305: {'train_loss': '1.23478'}; time used = 0.033968210220336914s
epoch 310: {'train_loss': '1.23657'}; time used = 0.03570294380187988s
epoch 315: {'train_loss': '1.23591'}; time used = 0.024539709091186523s
epoch 320: {'train_loss': '1.23022'}; time used = 0.0325930118560791s
epoch 325: {'train_loss': '1.22972'}; time used = 0.0261075496673584s
epoch 330: {'train_loss': '1.22705'}; time used = 0.024459362030029297s
epoch 335: {'train_loss': '1.23098'}; time used = 0.03226447105407715s
epoch 340: {'train_loss': '1.22807'}; time used = 0.0258023738861084s
epoch 345: {'train_loss': '1.22737'}; time used = 0.02605581283569336s
epoch 350: {'train_loss': '1.22516'}; time used = 0.033976078033447266s
epoch 355: {'train_loss': '1.22703'}; time used = 0.026250123977661133s
epoch 360: {'train_loss': '1.22961'}; time used = 0.02581167221069336s
epoch 365: {'train_loss': '1.22997'}; time used = 0.03311038017272949s
epoch 370: {'train_loss': '1.22871'}; time used = 0.026570796966552734s
epoch 375: {'train_loss': '1.23089'}; time used = 0.026372671127319336s
epoch 380: {'train_loss': '1.22849'}; time used = 0.044595956802368164s
epoch 385: {'train_loss': '1.22701'}; time used = 0.025965452194213867s
epoch 390: {'train_loss': '1.23112'}; time used = 0.03109002113342285s
epoch 395: {'train_loss': '1.22689'}; time used = 0.021561861038208008s
epoch 400: {'train_loss': '1.23242'}; time used = 0.022426605224609375s
epoch 405: {'train_loss': '1.23288'}; time used = 0.026618003845214844s
epoch 410: {'train_loss': '1.22368'}; time used = 0.031183719635009766s
epoch 415: {'train_loss': '1.23046'}; time used = 0.022858619689941406s
epoch 420: {'train_loss': '1.22570'}; time used = 0.02548837661743164s
epoch 425: {'train_loss': '1.22929'}; time used = 0.03331732749938965s
epoch 430: {'train_loss': '1.22995'}; time used = 0.036522626876831055s
epoch 435: {'train_loss': '1.22885'}; time used = 0.031194448471069336s
epoch 440: {'train_loss': '1.23015'}; time used = 0.022327184677124023s
epoch 445: {'train_loss': '1.22786'}; time used = 0.02414727210998535s
epoch 450: {'train_loss': '1.23021'}; time used = 0.038567543029785156s
epoch 455: {'train_loss': '1.22221'}; time used = 0.027620792388916016s
epoch 460: {'train_loss': '1.22936'}; time used = 0.026005029678344727s
epoch 465: {'train_loss': '1.22918'}; time used = 0.03347039222717285s
epoch 470: {'train_loss': '1.22642'}; time used = 0.024984121322631836s
epoch 475: {'train_loss': '1.22593'}; time used = 0.02406907081604004s
epoch 480: {'train_loss': '1.23287'}; time used = 0.036527395248413086s
epoch 485: {'train_loss': '1.23661'}; time used = 0.025202512741088867s
epoch 490: {'train_loss': '1.22518'}; time used = 0.02417731285095215s
epoch 495: {'train_loss': '1.22828'}; time used = 0.0333094596862793s
epoch 500: {'train_loss': '1.22857'}; time used = 0.02389216423034668s
Finished training. Time used = 6.106476068496704.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.35009'}; time used = 0.0839226245880127s
epoch 10: {'train_loss': '1.30897'}; time used = 0.026608943939208984s
epoch 15: {'train_loss': '1.26906'}; time used = 0.04152989387512207s
epoch 20: {'train_loss': '1.25395'}; time used = 0.035906076431274414s
epoch 25: {'train_loss': '1.24082'}; time used = 0.027010440826416016s
epoch 30: {'train_loss': '1.23866'}; time used = 0.0247957706451416s
epoch 35: {'train_loss': '1.23810'}; time used = 0.034647464752197266s
epoch 40: {'train_loss': '1.22798'}; time used = 0.03794455528259277s
epoch 45: {'train_loss': '1.23497'}; time used = 0.034850120544433594s
epoch 50: {'train_loss': '1.23155'}; time used = 0.04447436332702637s
epoch 55: {'train_loss': '1.23339'}; time used = 0.023040771484375s
epoch 60: {'train_loss': '1.23487'}; time used = 0.02013707160949707s
epoch 65: {'train_loss': '1.23192'}; time used = 0.020158052444458008s
epoch 70: {'train_loss': '1.23085'}; time used = 0.020310163497924805s
epoch 75: {'train_loss': '1.23891'}; time used = 0.02020120620727539s
epoch 80: {'train_loss': '1.22632'}; time used = 0.020541667938232422s
epoch 85: {'train_loss': '1.23679'}; time used = 0.02027726173400879s
epoch 90: {'train_loss': '1.23470'}; time used = 0.023461580276489258s
epoch 95: {'train_loss': '1.23756'}; time used = 0.030713796615600586s
epoch 100: {'train_loss': '1.22704'}; time used = 0.020298242568969727s
epoch 105: {'train_loss': '1.23123'}; time used = 0.019919395446777344s
epoch 110: {'train_loss': '1.23764'}; time used = 0.01974320411682129s
epoch 115: {'train_loss': '1.23341'}; time used = 0.02111077308654785s
epoch 120: {'train_loss': '1.23356'}; time used = 0.023757219314575195s
epoch 125: {'train_loss': '1.22837'}; time used = 0.020896434783935547s
epoch 130: {'train_loss': '1.23398'}; time used = 0.03212332725524902s
epoch 135: {'train_loss': '1.22993'}; time used = 0.01911759376525879s
epoch 140: {'train_loss': '1.23061'}; time used = 0.01933455467224121s
epoch 145: {'train_loss': '1.23568'}; time used = 0.01911020278930664s
epoch 150: {'train_loss': '1.23455'}; time used = 0.02025580406188965s
epoch 155: {'train_loss': '1.23260'}; time used = 0.03210639953613281s
epoch 160: {'train_loss': '1.23482'}; time used = 0.019555330276489258s
epoch 165: {'train_loss': '1.23634'}; time used = 0.02352309226989746s
epoch 170: {'train_loss': '1.23511'}; time used = 0.030936717987060547s
epoch 175: {'train_loss': '1.23412'}; time used = 0.020280122756958008s
epoch 180: {'train_loss': '1.23125'}; time used = 0.021207094192504883s
epoch 185: {'train_loss': '1.22755'}; time used = 0.020899295806884766s
epoch 190: {'train_loss': '1.23213'}; time used = 0.021671772003173828s
epoch 195: {'train_loss': '1.23362'}; time used = 0.02010321617126465s
epoch 200: {'train_loss': '1.23566'}; time used = 0.024547338485717773s
epoch 205: {'train_loss': '1.23448'}; time used = 0.030724048614501953s
epoch 210: {'train_loss': '1.23582'}; time used = 0.03157472610473633s
epoch 215: {'train_loss': '1.23954'}; time used = 0.020905733108520508s
epoch 220: {'train_loss': '1.22947'}; time used = 0.02050018310546875s
epoch 225: {'train_loss': '1.22574'}; time used = 0.020579099655151367s
epoch 230: {'train_loss': '1.23186'}; time used = 0.020535707473754883s
epoch 235: {'train_loss': '1.23377'}; time used = 0.02053093910217285s
epoch 240: {'train_loss': '1.23822'}; time used = 0.021364450454711914s
epoch 245: {'train_loss': '1.23543'}; time used = 0.021654844284057617s
epoch 250: {'train_loss': '1.22824'}; time used = 0.01746654510498047s
epoch 255: {'train_loss': '1.22964'}; time used = 0.019599437713623047s
epoch 260: {'train_loss': '1.22949'}; time used = 0.02058720588684082s
epoch 265: {'train_loss': '1.23273'}; time used = 0.02012181282043457s
epoch 270: {'train_loss': '1.23200'}; time used = 0.020186662673950195s
epoch 275: {'train_loss': '1.23069'}; time used = 0.020226240158081055s
epoch 280: {'train_loss': '1.22882'}; time used = 0.019841670989990234s
epoch 285: {'train_loss': '1.23528'}; time used = 0.02210235595703125s
epoch 290: {'train_loss': '1.22735'}; time used = 0.028717756271362305s
epoch 295: {'train_loss': '1.23015'}; time used = 0.029415369033813477s
epoch 300: {'train_loss': '1.23280'}; time used = 0.029875755310058594s
epoch 305: {'train_loss': '1.23650'}; time used = 0.029303789138793945s
epoch 310: {'train_loss': '1.23760'}; time used = 0.029144287109375s
epoch 315: {'train_loss': '1.23745'}; time used = 0.05199122428894043s
epoch 320: {'train_loss': '1.23317'}; time used = 0.029202699661254883s
epoch 325: {'train_loss': '1.23296'}; time used = 0.030189990997314453s
epoch 330: {'train_loss': '1.22912'}; time used = 0.030257225036621094s
epoch 335: {'train_loss': '1.23531'}; time used = 0.03215622901916504s
epoch 340: {'train_loss': '1.23225'}; time used = 0.024381160736083984s
epoch 345: {'train_loss': '1.22948'}; time used = 0.020018339157104492s
epoch 350: {'train_loss': '1.22771'}; time used = 0.01989889144897461s
epoch 355: {'train_loss': '1.22900'}; time used = 0.01979351043701172s
epoch 360: {'train_loss': '1.23299'}; time used = 0.020382404327392578s
epoch 365: {'train_loss': '1.23048'}; time used = 0.01999211311340332s
epoch 370: {'train_loss': '1.23283'}; time used = 0.020112037658691406s
epoch 375: {'train_loss': '1.23316'}; time used = 0.020345687866210938s
epoch 380: {'train_loss': '1.23087'}; time used = 0.020137786865234375s
epoch 385: {'train_loss': '1.22826'}; time used = 0.023457765579223633s
epoch 390: {'train_loss': '1.23352'}; time used = 0.019272327423095703s
epoch 395: {'train_loss': '1.22898'}; time used = 0.019800424575805664s
epoch 400: {'train_loss': '1.23476'}; time used = 0.019528865814208984s
epoch 405: {'train_loss': '1.23565'}; time used = 0.01937389373779297s
epoch 410: {'train_loss': '1.22605'}; time used = 0.01947188377380371s
epoch 415: {'train_loss': '1.23275'}; time used = 0.017805099487304688s
epoch 420: {'train_loss': '1.22766'}; time used = 0.028165102005004883s
epoch 425: {'train_loss': '1.23147'}; time used = 0.0292508602142334s
epoch 430: {'train_loss': '1.23159'}; time used = 0.030154705047607422s
epoch 435: {'train_loss': '1.23132'}; time used = 0.030986309051513672s
epoch 440: {'train_loss': '1.23203'}; time used = 0.03026866912841797s
epoch 445: {'train_loss': '1.22919'}; time used = 0.02977299690246582s
epoch 450: {'train_loss': '1.23184'}; time used = 0.0296323299407959s
epoch 455: {'train_loss': '1.22443'}; time used = 0.030381441116333008s
epoch 460: {'train_loss': '1.23114'}; time used = 0.01881885528564453s
epoch 465: {'train_loss': '1.23271'}; time used = 0.021960735321044922s
epoch 470: {'train_loss': '1.22942'}; time used = 0.02221226692199707s
epoch 475: {'train_loss': '1.22805'}; time used = 0.022275447845458984s
epoch 480: {'train_loss': '1.23405'}; time used = 0.022329092025756836s
epoch 485: {'train_loss': '1.23925'}; time used = 0.025768518447875977s
epoch 490: {'train_loss': '1.22685'}; time used = 0.020550012588500977s
epoch 495: {'train_loss': '1.23048'}; time used = 0.028203964233398438s
epoch 500: {'train_loss': '1.23169'}; time used = 0.019106626510620117s
Finished training. Time used = 23.903491020202637.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 256, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [256, 256, 256], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 512, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [512, 512, 512], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-random', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with random...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.36307'}; time used = 0.046154022216796875s
epoch 10: {'train_loss': '1.28706'}; time used = 0.028178691864013672s
epoch 15: {'train_loss': '1.25478'}; time used = 0.04365706443786621s
epoch 20: {'train_loss': '1.25585'}; time used = 0.0347902774810791s
epoch 25: {'train_loss': '1.24980'}; time used = 0.03442788124084473s
epoch 30: {'train_loss': '1.24802'}; time used = 0.031001567840576172s
epoch 35: {'train_loss': '1.24865'}; time used = 0.027016162872314453s
epoch 40: {'train_loss': '1.23800'}; time used = 0.02924060821533203s
epoch 45: {'train_loss': '1.24366'}; time used = 0.027907848358154297s
epoch 50: {'train_loss': '1.24037'}; time used = 0.028102397918701172s
epoch 55: {'train_loss': '1.24280'}; time used = 0.027721405029296875s
epoch 60: {'train_loss': '1.23638'}; time used = 0.02757096290588379s
epoch 65: {'train_loss': '1.23774'}; time used = 0.02664804458618164s
epoch 70: {'train_loss': '1.24527'}; time used = 0.02190566062927246s
epoch 75: {'train_loss': '1.23954'}; time used = 0.07862424850463867s
epoch 80: {'train_loss': '1.24703'}; time used = 0.02996540069580078s
epoch 85: {'train_loss': '1.24078'}; time used = 0.0296480655670166s
epoch 90: {'train_loss': '1.23959'}; time used = 0.02987384796142578s
epoch 95: {'train_loss': '1.24213'}; time used = 0.04172253608703613s
epoch 100: {'train_loss': '1.24160'}; time used = 0.026655912399291992s
epoch 105: {'train_loss': '1.24360'}; time used = 0.02747821807861328s
epoch 110: {'train_loss': '1.24526'}; time used = 0.027100086212158203s
epoch 115: {'train_loss': '1.23687'}; time used = 0.02680206298828125s
epoch 120: {'train_loss': '1.25049'}; time used = 0.023772001266479492s
epoch 125: {'train_loss': '1.23658'}; time used = 0.028437376022338867s
epoch 130: {'train_loss': '1.24022'}; time used = 0.026093721389770508s
epoch 135: {'train_loss': '1.24314'}; time used = 0.02373051643371582s
epoch 140: {'train_loss': '1.24428'}; time used = 0.02664923667907715s
epoch 145: {'train_loss': '1.23910'}; time used = 0.024199247360229492s
epoch 150: {'train_loss': '1.24051'}; time used = 0.026290178298950195s
epoch 155: {'train_loss': '1.24166'}; time used = 0.022124290466308594s
epoch 160: {'train_loss': '1.23780'}; time used = 0.022944211959838867s
epoch 165: {'train_loss': '1.23627'}; time used = 0.0218350887298584s
epoch 170: {'train_loss': '1.23858'}; time used = 0.02783966064453125s
epoch 175: {'train_loss': '1.25125'}; time used = 0.03422880172729492s
epoch 180: {'train_loss': '1.25213'}; time used = 0.022909879684448242s
epoch 185: {'train_loss': '1.23412'}; time used = 0.022586345672607422s
epoch 190: {'train_loss': '1.23891'}; time used = 0.023172378540039062s
epoch 195: {'train_loss': '1.23685'}; time used = 0.024395465850830078s
epoch 200: {'train_loss': '1.24165'}; time used = 0.024713516235351562s
epoch 205: {'train_loss': '1.24366'}; time used = 0.025061845779418945s
epoch 210: {'train_loss': '1.24419'}; time used = 0.021872520446777344s
epoch 215: {'train_loss': '1.23906'}; time used = 0.024439334869384766s
epoch 220: {'train_loss': '1.24608'}; time used = 0.02223348617553711s
epoch 225: {'train_loss': '1.24081'}; time used = 0.023818254470825195s
epoch 230: {'train_loss': '1.24235'}; time used = 0.02450847625732422s
epoch 235: {'train_loss': '1.24082'}; time used = 0.026256561279296875s
epoch 240: {'train_loss': '1.24682'}; time used = 0.026323318481445312s
epoch 245: {'train_loss': '1.25348'}; time used = 0.025943279266357422s
epoch 250: {'train_loss': '1.24013'}; time used = 0.030048131942749023s
epoch 255: {'train_loss': '1.24221'}; time used = 0.02532172203063965s
epoch 260: {'train_loss': '1.24389'}; time used = 0.027489185333251953s
epoch 265: {'train_loss': '1.24459'}; time used = 0.026147842407226562s
epoch 270: {'train_loss': '1.23628'}; time used = 0.02434539794921875s
epoch 275: {'train_loss': '1.24361'}; time used = 0.03416752815246582s
epoch 280: {'train_loss': '1.23861'}; time used = 0.030069828033447266s
epoch 285: {'train_loss': '1.24798'}; time used = 0.024511337280273438s
epoch 290: {'train_loss': '1.24227'}; time used = 0.02407360076904297s
epoch 295: {'train_loss': '1.23961'}; time used = 0.02631831169128418s
epoch 300: {'train_loss': '1.24050'}; time used = 0.027037620544433594s
epoch 305: {'train_loss': '1.24954'}; time used = 0.029671192169189453s
epoch 310: {'train_loss': '1.25030'}; time used = 0.04425954818725586s
epoch 315: {'train_loss': '1.24554'}; time used = 0.03816866874694824s
epoch 320: {'train_loss': '1.24225'}; time used = 0.02430248260498047s
epoch 325: {'train_loss': '1.24103'}; time used = 0.02532362937927246s
epoch 330: {'train_loss': '1.23869'}; time used = 0.028553485870361328s
epoch 335: {'train_loss': '1.24880'}; time used = 0.030779123306274414s
epoch 340: {'train_loss': '1.24903'}; time used = 0.030445575714111328s
epoch 345: {'train_loss': '1.24127'}; time used = 0.031205415725708008s
epoch 350: {'train_loss': '1.24178'}; time used = 0.02843499183654785s
epoch 355: {'train_loss': '1.24017'}; time used = 0.04450726509094238s
epoch 360: {'train_loss': '1.23892'}; time used = 0.027221202850341797s
epoch 365: {'train_loss': '1.24596'}; time used = 0.028537511825561523s
epoch 370: {'train_loss': '1.24065'}; time used = 0.028119802474975586s
epoch 375: {'train_loss': '1.24367'}; time used = 0.029498577117919922s
epoch 380: {'train_loss': '1.24560'}; time used = 0.030746936798095703s
epoch 385: {'train_loss': '1.23969'}; time used = 0.028228759765625s
epoch 390: {'train_loss': '1.22762'}; time used = 0.026068925857543945s
epoch 395: {'train_loss': '1.24386'}; time used = 0.02449798583984375s
epoch 400: {'train_loss': '1.23291'}; time used = 0.02782893180847168s
epoch 405: {'train_loss': '1.24451'}; time used = 0.028624296188354492s
epoch 410: {'train_loss': '1.24569'}; time used = 0.025931835174560547s
epoch 415: {'train_loss': '1.24379'}; time used = 0.026945829391479492s
epoch 420: {'train_loss': '1.23417'}; time used = 0.024997711181640625s
epoch 425: {'train_loss': '1.23186'}; time used = 0.025412321090698242s
epoch 430: {'train_loss': '1.24743'}; time used = 0.0354464054107666s
epoch 435: {'train_loss': '1.23609'}; time used = 0.02350330352783203s
epoch 440: {'train_loss': '1.24350'}; time used = 0.021265029907226562s
epoch 445: {'train_loss': '1.23925'}; time used = 0.037036895751953125s
epoch 450: {'train_loss': '1.23430'}; time used = 0.022702693939208984s
epoch 455: {'train_loss': '1.23980'}; time used = 0.022916316986083984s
epoch 460: {'train_loss': '1.23533'}; time used = 0.022204875946044922s
epoch 465: {'train_loss': '1.24452'}; time used = 0.022499561309814453s
epoch 470: {'train_loss': '1.23622'}; time used = 0.026442527770996094s
epoch 475: {'train_loss': '1.24867'}; time used = 0.020650148391723633s
epoch 480: {'train_loss': '1.23422'}; time used = 0.022001028060913086s
epoch 485: {'train_loss': '1.23746'}; time used = 0.023106098175048828s
epoch 490: {'train_loss': '1.23699'}; time used = 0.02541947364807129s
epoch 495: {'train_loss': '1.23846'}; time used = 0.025610923767089844s
epoch 500: {'train_loss': '1.23553'}; time used = 0.025822162628173828s
Finished training. Time used = 7.4255969524383545.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150641.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140850.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146996.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132370.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135641.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131219.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147364.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147219.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146695.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145509.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137784.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133073.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143039.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141716.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145406.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146650.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148582.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146600.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128795.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151413.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149292.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149354.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151016.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148112.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148546.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148627.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148877.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150743.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148704.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147789.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148004.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149085.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149019.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136637.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149198.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145586.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144784.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145628.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146821.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148115.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147664.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147128.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147023.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146765.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148553.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147651.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141557.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148831.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138011.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149271.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147302.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183360.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179768.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 204815.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195743.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168952.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6577/10556 [00:00<00:00, 65764.73it/s]100%|| 10556/10556 [00:00<00:00, 66715.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145644.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185290.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 203430.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191492.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196164.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195415.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200673.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108538.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145402.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195300.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193060.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187582.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191753.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129846.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120730.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168932.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187321.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186219.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185890.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190409.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176349.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184007.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163117.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124220.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 205459.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 210431.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 225908.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 209211.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184762.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 204351.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 211669.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190320.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189159.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197962.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200559.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202702.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185581.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198546.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193082.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173083.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185929.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196893.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195443.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186470.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186482.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189371.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195458.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202312.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198756.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142969.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146473.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146762.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147329.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148477.91it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.50555'}; time used = 0.43569445610046387s
epoch 10: {'train_loss': '1.38852'}; time used = 0.39266538619995117s
epoch 15: {'train_loss': '1.34590'}; time used = 0.406848669052124s
epoch 20: {'train_loss': '1.32748'}; time used = 0.39237475395202637s
epoch 25: {'train_loss': '1.30669'}; time used = 0.3770010471343994s
epoch 30: {'train_loss': '1.28902'}; time used = 0.376054048538208s
epoch 35: {'train_loss': '1.27227'}; time used = 0.3874669075012207s
epoch 40: {'train_loss': '1.25750'}; time used = 0.3875772953033447s
epoch 45: {'train_loss': '1.25708'}; time used = 0.38663697242736816s
epoch 50: {'train_loss': '1.24879'}; time used = 0.3914358615875244s
epoch 55: {'train_loss': '1.25060'}; time used = 0.3153064250946045s
epoch 60: {'train_loss': '1.24543'}; time used = 0.4556279182434082s
epoch 65: {'train_loss': '1.24745'}; time used = 0.3748612403869629s
epoch 70: {'train_loss': '1.24601'}; time used = 0.3239006996154785s
epoch 75: {'train_loss': '1.24635'}; time used = 0.3463594913482666s
epoch 80: {'train_loss': '1.24384'}; time used = 0.36212635040283203s
epoch 85: {'train_loss': '1.24353'}; time used = 0.2849850654602051s
epoch 90: {'train_loss': '1.24333'}; time used = 0.2897169589996338s
epoch 95: {'train_loss': '1.23961'}; time used = 0.2936058044433594s
epoch 100: {'train_loss': '1.24502'}; time used = 0.32128047943115234s
epoch 105: {'train_loss': '1.23892'}; time used = 0.3006858825683594s
epoch 110: {'train_loss': '1.24640'}; time used = 0.3876185417175293s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.538431167602539.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06508785332314744, 'samples': 0.29487771112136596, 'weighted': 0.13435070046813036}
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183747.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175005.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175863.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171610.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177375.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164069.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176062.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179618.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176497.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176715.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174039.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173129.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178596.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125118.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156489.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174740.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178412.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181132.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182806.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181180.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9714/10556 [00:00<00:00, 97130.83it/s]100%|| 10556/10556 [00:00<00:00, 86024.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125270.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131715.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140921.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132055.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167572.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191438.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193454.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191555.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150448.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143686.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139119.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137962.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130757.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8634/10556 [00:00<00:00, 86338.44it/s]100%|| 10556/10556 [00:00<00:00, 83242.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7834/10556 [00:00<00:00, 78337.09it/s]100%|| 10556/10556 [00:00<00:00, 84618.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125669.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141060.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142838.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144910.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142480.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141513.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144033.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140866.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142182.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141403.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143059.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142029.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140920.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142545.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141578.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135295.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142981.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141485.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113466.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127987.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145709.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202299.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 220586.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 210188.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193681.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161488.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143782.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139260.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140369.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140462.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142544.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111750.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160264.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140233.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144908.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143174.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144460.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146382.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157474.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177115.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164466.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175766.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176251.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185820.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181686.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179223.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176493.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174812.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179150.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178780.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180479.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181041.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180550.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166980.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122375.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180116.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192919.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202140.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188753.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172563.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186178.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 203786.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184793.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122893.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122020.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197264.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 199435.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193274.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 199692.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 201936.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 212328.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202386.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202416.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193616.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181408.38it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.40130'}; time used = 0.34670186042785645s
epoch 10: {'train_loss': '1.34031'}; time used = 0.3288455009460449s
epoch 15: {'train_loss': '1.31336'}; time used = 0.36307811737060547s
epoch 20: {'train_loss': '1.27880'}; time used = 0.39284753799438477s
epoch 25: {'train_loss': '1.25946'}; time used = 0.4573097229003906s
epoch 30: {'train_loss': '1.25286'}; time used = 0.33802294731140137s
epoch 35: {'train_loss': '1.24936'}; time used = 0.526207447052002s
epoch 40: {'train_loss': '1.24251'}; time used = 0.40627169609069824s
epoch 45: {'train_loss': '1.24409'}; time used = 0.3978846073150635s
epoch 50: {'train_loss': '1.23584'}; time used = 0.4005448818206787s
epoch 55: {'train_loss': '1.23682'}; time used = 0.43337488174438477s
epoch 60: {'train_loss': '1.23217'}; time used = 0.3038311004638672s
epoch 65: {'train_loss': '1.23493'}; time used = 0.3924574851989746s
epoch 70: {'train_loss': '1.23204'}; time used = 0.41190147399902344s
epoch 75: {'train_loss': '1.23262'}; time used = 0.37850093841552734s
epoch 80: {'train_loss': '1.22851'}; time used = 0.3270454406738281s
epoch 85: {'train_loss': '1.22901'}; time used = 0.3239717483520508s
epoch 90: {'train_loss': '1.22893'}; time used = 0.35152506828308105s
epoch 95: {'train_loss': '1.22523'}; time used = 0.3036487102508545s
epoch 100: {'train_loss': '1.23054'}; time used = 0.36852574348449707s
epoch 105: {'train_loss': '1.22526'}; time used = 0.2903473377227783s
epoch 110: {'train_loss': '1.23434'}; time used = 0.28809499740600586s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.450518131256104.
Training classifier using 20.00% nodes...
{'micro': 0.29441624365482233, 'macro': 0.06507879838833068, 'samples': 0.29441624365482233, 'weighted': 0.13433200977895854}
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 224100.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 205957.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 205200.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179414.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150265.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157114.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145377.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159137.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154562.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135473.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157419.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153813.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152184.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152746.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135771.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146356.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152559.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151353.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154051.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151430.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147312.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154085.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145889.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152789.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155992.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153911.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152419.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153804.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151082.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154785.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149044.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139813.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145566.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145980.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136368.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127402.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118426.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147659.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153945.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152603.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149979.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154045.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8317/10556 [00:00<00:00, 83160.36it/s]100%|| 10556/10556 [00:00<00:00, 82438.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117963.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 209164.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 219582.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 216963.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197463.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202488.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 204540.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185048.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 199529.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191667.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 203681.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186110.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197593.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 199344.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 205358.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188764.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185152.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169711.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113808.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150883.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177519.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196478.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198232.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 211982.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170652.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198467.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 210663.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 216848.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 212651.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 219876.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 203291.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 210897.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 212227.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 219603.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 219846.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193720.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 226870.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 229637.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 221749.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 214407.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191972.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200822.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190484.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198230.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 201489.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 199535.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193933.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188958.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185452.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192679.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190698.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184948.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188475.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190136.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188248.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194328.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194407.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197378.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195067.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195240.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192609.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192072.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190578.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191683.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200194.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192195.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 201596.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178189.39it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.36382'}; time used = 0.34287476539611816s
epoch 10: {'train_loss': '1.33265'}; time used = 0.38149595260620117s
epoch 15: {'train_loss': '1.28526'}; time used = 0.39459919929504395s
epoch 20: {'train_loss': '1.26045'}; time used = 0.38254714012145996s
epoch 25: {'train_loss': '1.24907'}; time used = 0.36982107162475586s
epoch 30: {'train_loss': '1.24469'}; time used = 0.37418103218078613s
epoch 35: {'train_loss': '1.24081'}; time used = 0.4288961887359619s
epoch 40: {'train_loss': '1.23354'}; time used = 0.40453290939331055s
epoch 45: {'train_loss': '1.23514'}; time used = 0.4358651638031006s
epoch 50: {'train_loss': '1.22786'}; time used = 0.2853884696960449s
epoch 55: {'train_loss': '1.23087'}; time used = 0.3052506446838379s
epoch 60: {'train_loss': '1.22912'}; time used = 0.3034188747406006s
epoch 65: {'train_loss': '1.23328'}; time used = 0.37326550483703613s
epoch 70: {'train_loss': '1.23032'}; time used = 0.2902853488922119s
epoch 75: {'train_loss': '1.23205'}; time used = 0.2753441333770752s
epoch 80: {'train_loss': '1.22845'}; time used = 0.2903635501861572s
epoch 85: {'train_loss': '1.22931'}; time used = 0.2883598804473877s
epoch 90: {'train_loss': '1.22893'}; time used = 0.2989845275878906s
epoch 95: {'train_loss': '1.22529'}; time used = 0.316861629486084s
epoch 100: {'train_loss': '1.23123'}; time used = 0.3007197380065918s
epoch 105: {'train_loss': '1.22557'}; time used = 0.30118703842163086s
epoch 110: {'train_loss': '1.23485'}; time used = 0.2959010601043701s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.156195640563965.
Training classifier using 20.00% nodes...
{'micro': 0.29441624365482233, 'macro': 0.06517186781755964, 'samples': 0.29441624365482233, 'weighted': 0.13452411848082338}
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200598.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184675.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177354.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186970.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186525.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176246.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200497.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188364.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198259.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 203794.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 205106.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189246.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202164.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189949.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187794.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 199021.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184258.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188094.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185089.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132628.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152487.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147065.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126020.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9323/10556 [00:00<00:00, 93227.64it/s]100%|| 10556/10556 [00:00<00:00, 97647.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110697.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10433/10556 [00:00<00:00, 104324.13it/s]100%|| 10556/10556 [00:00<00:00, 103740.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 205147.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 213584.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189070.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159906.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129122.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202864.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121129.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152911.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147099.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156801.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153883.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132793.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8208/10556 [00:00<00:00, 82078.12it/s]100%|| 10556/10556 [00:00<00:00, 83364.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8730/10556 [00:00<00:00, 87292.80it/s]100%|| 10556/10556 [00:00<00:00, 88418.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 201444.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 213638.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186592.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179403.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184295.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 210408.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 204388.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 203232.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175290.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182487.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171161.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176309.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183959.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183056.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192520.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180366.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185198.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163166.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 201119.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183909.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182941.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179486.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180977.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163989.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184388.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191052.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180137.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175315.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175944.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145945.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 199430.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196245.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184183.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184594.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188346.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184600.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186201.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143442.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119898.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123982.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179152.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180305.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172772.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187500.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177416.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188872.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188900.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185340.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188837.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190024.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183275.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189543.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137627.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148197.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146276.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145506.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144330.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146675.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144112.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143544.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144750.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133889.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9303/10556 [00:00<00:00, 93028.98it/s]100%|| 10556/10556 [00:00<00:00, 97562.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147565.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148153.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142704.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144685.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136631.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6322/10556 [00:00<00:00, 63218.25it/s]100%|| 10556/10556 [00:00<00:00, 78319.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114906.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146610.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150271.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147617.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145752.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144812.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143921.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145573.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146001.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145936.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145149.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143746.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146563.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141702.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135437.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135821.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145258.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141355.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144664.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146975.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136719.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146213.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135640.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145775.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143756.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129597.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148032.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145295.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143973.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146399.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143896.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110112.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10499/10556 [00:00<00:00, 104989.10it/s]100%|| 10556/10556 [00:00<00:00, 104660.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113010.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 209298.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126706.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123122.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144977.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10000/10556 [00:00<00:00, 99993.90it/s]100%|| 10556/10556 [00:00<00:00, 99954.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8755/10556 [00:00<00:00, 87549.04it/s]100%|| 10556/10556 [00:00<00:00, 76156.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 226174.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 214146.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158833.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7725/10556 [00:00<00:00, 77249.15it/s]100%|| 10556/10556 [00:00<00:00, 92718.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189670.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196320.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195268.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198586.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194693.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188561.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193604.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197206.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198449.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198826.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193719.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184329.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197276.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180337.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194771.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181774.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190852.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188048.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188968.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166665.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186234.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192305.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192003.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195044.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193637.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190229.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192076.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194472.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197712.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197132.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 201740.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198936.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196567.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167969.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191250.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198926.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202798.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200106.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189824.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187250.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176523.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183127.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181502.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183128.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185978.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143795.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106317.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106675.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106170.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9863/10556 [00:00<00:00, 98628.45it/s]100%|| 10556/10556 [00:00<00:00, 97040.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8508/10556 [00:00<00:00, 85079.88it/s]100%|| 10556/10556 [00:00<00:00, 87528.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10373/10556 [00:00<00:00, 103724.91it/s]100%|| 10556/10556 [00:00<00:00, 103017.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10409/10556 [00:00<00:00, 104085.14it/s]100%|| 10556/10556 [00:00<00:00, 103896.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124080.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185694.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171036.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192512.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182908.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185792.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186377.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185804.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181686.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181920.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189563.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182967.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193462.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141965.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118485.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151247.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147071.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145400.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149847.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140638.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114274.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135810.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163760.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 207344.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188178.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188072.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184495.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184277.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187664.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191666.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188307.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186783.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187083.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189510.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189915.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185726.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182130.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168473.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164959.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158498.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166553.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149985.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129303.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124754.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131366.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118327.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134686.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145935.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151921.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147055.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145463.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143040.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147019.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148883.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150120.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146789.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8440/10556 [00:00<00:00, 84396.66it/s]100%|| 10556/10556 [00:00<00:00, 91099.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128864.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137122.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149586.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 220820.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 211700.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 209187.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 212283.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126308.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150184.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 168478.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179119.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196549.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195213.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200249.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197131.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191215.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198419.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189395.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124478.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174954.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166357.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175066.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111642.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114029.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143662.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145812.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195894.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189093.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193746.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196778.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183637.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194173.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191301.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188607.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142959.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147843.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146632.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145632.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140854.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7510/10556 [00:00<00:00, 75090.94it/s]100%|| 10556/10556 [00:00<00:00, 73630.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189053.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172489.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185705.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197203.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191801.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 173877.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187847.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190966.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120971.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187275.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186176.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187888.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186424.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186241.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178246.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189183.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188241.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191124.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106579.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185399.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185595.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187482.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182621.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184586.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185598.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179841.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186980.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186408.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196381.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185490.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182748.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188005.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187104.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186752.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194696.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 165819.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177476.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177350.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185395.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189815.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183552.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181703.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181598.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177882.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183596.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 172703.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 174122.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 167082.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 210183.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 213206.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169791.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157139.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183487.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141450.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148819.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139044.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147011.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9176/10556 [00:00<00:00, 91759.65it/s]100%|| 10556/10556 [00:00<00:00, 96682.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146514.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150019.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134427.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10328/10556 [00:00<00:00, 103272.47it/s]100%|| 10556/10556 [00:00<00:00, 103457.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119474.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7354/10556 [00:00<00:00, 71712.51it/s]100%|| 10556/10556 [00:00<00:00, 74452.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147424.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147184.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135176.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9219/10556 [00:00<00:00, 92186.35it/s]100%|| 10556/10556 [00:00<00:00, 98965.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181317.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175121.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140635.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147556.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143517.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149376.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151801.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151826.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147957.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150052.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149087.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139346.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148356.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150333.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148713.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131650.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 205244.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7112/10556 [00:00<00:00, 71116.17it/s]100%|| 10556/10556 [00:00<00:00, 86077.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148211.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149317.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138855.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 143543.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 144368.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127229.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8791/10556 [00:00<00:00, 87909.04it/s]100%|| 10556/10556 [00:00<00:00, 94814.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148061.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150569.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148495.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147498.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150026.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148764.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149368.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147302.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146305.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149737.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146309.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136801.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114945.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8433/10556 [00:00<00:00, 84322.44it/s]100%|| 10556/10556 [00:00<00:00, 84089.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8544/10556 [00:00<00:00, 85431.53it/s]100%|| 10556/10556 [00:00<00:00, 85257.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8461/10556 [00:00<00:00, 84603.83it/s]100%|| 10556/10556 [00:00<00:00, 84956.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124667.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164138.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139160.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178289.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183219.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182087.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180498.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179382.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184901.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179068.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184870.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184891.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176110.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 162440.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 175771.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181031.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178758.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180053.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180554.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181547.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179469.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176257.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191843.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 182068.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181140.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179417.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197494.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184734.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183287.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180930.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178897.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192335.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188125.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188781.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183283.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189988.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186514.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187754.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 206050.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200125.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 207467.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196347.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 203987.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196925.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185501.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185495.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191838.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191461.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190270.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185709.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105952.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142414.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129415.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139689.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150238.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141642.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133528.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6323/10556 [00:00<00:00, 63227.35it/s]100%|| 10556/10556 [00:00<00:00, 85163.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 217326.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 216192.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 207748.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 208725.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200550.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 208573.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 204996.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197980.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200568.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195367.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 201206.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185488.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180950.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166619.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178889.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169845.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157980.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153093.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 158098.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160131.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 170845.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177143.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 169581.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8862/10556 [00:00<00:00, 88611.63it/s]100%|| 10556/10556 [00:00<00:00, 94999.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142600.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191298.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200876.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 208103.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 206081.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 176027.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110214.59it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.70804'}; time used = 0.3335409164428711s
epoch 10: {'train_loss': '1.68172'}; time used = 0.29373979568481445s
epoch 15: {'train_loss': '1.64542'}; time used = 0.2976114749908447s
epoch 20: {'train_loss': '1.61318'}; time used = 0.35054540634155273s
epoch 25: {'train_loss': '1.59124'}; time used = 0.5181272029876709s
epoch 30: {'train_loss': '1.56626'}; time used = 0.326718807220459s
epoch 35: {'train_loss': '1.53799'}; time used = 0.37515687942504883s
epoch 40: {'train_loss': '1.51915'}; time used = 0.477205753326416s
epoch 45: {'train_loss': '1.50112'}; time used = 0.30116939544677734s
epoch 50: {'train_loss': '1.49273'}; time used = 0.3136734962463379s
epoch 55: {'train_loss': '1.47523'}; time used = 0.32178211212158203s
epoch 60: {'train_loss': '1.46341'}; time used = 0.3162813186645508s
epoch 65: {'train_loss': '1.44856'}; time used = 0.3257734775543213s
epoch 70: {'train_loss': '1.43533'}; time used = 0.3308072090148926s
epoch 75: {'train_loss': '1.43405'}; time used = 0.30599451065063477s
epoch 80: {'train_loss': '1.41818'}; time used = 0.443742036819458s
epoch 85: {'train_loss': '1.41372'}; time used = 0.3274650573730469s
epoch 90: {'train_loss': '1.39902'}; time used = 0.31464052200317383s
epoch 95: {'train_loss': '1.39553'}; time used = 0.37784886360168457s
epoch 100: {'train_loss': '1.38879'}; time used = 0.3990139961242676s
epoch 105: {'train_loss': '1.38387'}; time used = 0.45121049880981445s
epoch 110: {'train_loss': '1.38179'}; time used = 0.4922325611114502s
epoch 115: {'train_loss': '1.37246'}; time used = 0.3880949020385742s
epoch 120: {'train_loss': '1.36661'}; time used = 0.3965458869934082s
epoch 125: {'train_loss': '1.36115'}; time used = 0.41777515411376953s
epoch 130: {'train_loss': '1.35610'}; time used = 0.4039170742034912s
epoch 135: {'train_loss': '1.35292'}; time used = 0.4125962257385254s
epoch 140: {'train_loss': '1.35402'}; time used = 0.41842031478881836s
epoch 145: {'train_loss': '1.34713'}; time used = 0.4843473434448242s
epoch 150: {'train_loss': '1.34496'}; time used = 0.43933844566345215s
epoch 155: {'train_loss': '1.34212'}; time used = 0.3795955181121826s
epoch 160: {'train_loss': '1.33694'}; time used = 0.29620361328125s
epoch 165: {'train_loss': '1.33341'}; time used = 0.2933804988861084s
epoch 170: {'train_loss': '1.33341'}; time used = 0.333240270614624s
epoch 175: {'train_loss': '1.32504'}; time used = 0.31600284576416016s
epoch 180: {'train_loss': '1.32266'}; time used = 0.30039215087890625s
epoch 185: {'train_loss': '1.32160'}; time used = 0.2913172245025635s
epoch 190: {'train_loss': '1.32042'}; time used = 0.3173539638519287s
epoch 195: {'train_loss': '1.31643'}; time used = 0.3173840045928955s
epoch 200: {'train_loss': '1.31154'}; time used = 0.4164130687713623s
epoch 205: {'train_loss': '1.30940'}; time used = 0.5843296051025391s
epoch 210: {'train_loss': '1.30846'}; time used = 0.34586286544799805s
epoch 215: {'train_loss': '1.30819'}; time used = 0.3136880397796631s
epoch 220: {'train_loss': '1.30507'}; time used = 0.3627283573150635s
epoch 225: {'train_loss': '1.30175'}; time used = 0.4009246826171875s
epoch 230: {'train_loss': '1.29637'}; time used = 0.40390729904174805s
epoch 235: {'train_loss': '1.29968'}; time used = 0.3107938766479492s
epoch 240: {'train_loss': '1.29011'}; time used = 0.31032705307006836s
epoch 245: {'train_loss': '1.28606'}; time used = 0.338580846786499s
epoch 250: {'train_loss': '1.28795'}; time used = 0.4285886287689209s
epoch 255: {'train_loss': '1.28520'}; time used = 0.4154090881347656s
epoch 260: {'train_loss': '1.28231'}; time used = 0.3922863006591797s
epoch 265: {'train_loss': '1.28171'}; time used = 0.45387935638427734s
epoch 270: {'train_loss': '1.28058'}; time used = 0.3113698959350586s
epoch 275: {'train_loss': '1.27309'}; time used = 0.3345818519592285s
epoch 280: {'train_loss': '1.27555'}; time used = 0.29994750022888184s
epoch 285: {'train_loss': '1.27254'}; time used = 0.41043663024902344s
epoch 290: {'train_loss': '1.27710'}; time used = 0.3979926109313965s
epoch 295: {'train_loss': '1.27676'}; time used = 0.3063347339630127s
epoch 300: {'train_loss': '1.26715'}; time used = 0.3859713077545166s
epoch 305: {'train_loss': '1.26774'}; time used = 0.46506643295288086s
epoch 310: {'train_loss': '1.26395'}; time used = 0.31362152099609375s
epoch 315: {'train_loss': '1.26623'}; time used = 0.3528876304626465s
epoch 320: {'train_loss': '1.26731'}; time used = 0.3159348964691162s
epoch 325: {'train_loss': '1.26083'}; time used = 0.37961745262145996s
epoch 330: {'train_loss': '1.26405'}; time used = 0.31641674041748047s
epoch 335: {'train_loss': '1.26201'}; time used = 0.30790209770202637s
epoch 340: {'train_loss': '1.25891'}; time used = 0.32236313819885254s
epoch 345: {'train_loss': '1.26120'}; time used = 0.3123478889465332s
epoch 350: {'train_loss': '1.25716'}; time used = 0.3447086811065674s
epoch 355: {'train_loss': '1.25988'}; time used = 0.32296228408813477s
epoch 360: {'train_loss': '1.26054'}; time used = 0.44383764266967773s
epoch 365: {'train_loss': '1.25629'}; time used = 0.43887925148010254s
epoch 370: {'train_loss': '1.25797'}; time used = 0.5105443000793457s
epoch 375: {'train_loss': '1.25661'}; time used = 0.36887645721435547s
epoch 380: {'train_loss': '1.25752'}; time used = 0.3764171600341797s
epoch 385: {'train_loss': '1.24490'}; time used = 0.39730310440063477s
epoch 390: {'train_loss': '1.25154'}; time used = 0.4674975872039795s
epoch 395: {'train_loss': '1.25145'}; time used = 0.4575080871582031s
epoch 400: {'train_loss': '1.25141'}; time used = 0.38178348541259766s
epoch 405: {'train_loss': '1.24782'}; time used = 0.38079142570495605s
epoch 410: {'train_loss': '1.24480'}; time used = 0.5314006805419922s
epoch 415: {'train_loss': '1.25066'}; time used = 0.4386250972747803s
epoch 420: {'train_loss': '1.25569'}; time used = 0.31389641761779785s
epoch 425: {'train_loss': '1.25408'}; time used = 0.3214690685272217s
epoch 430: {'train_loss': '1.25196'}; time used = 0.34390687942504883s
epoch 435: {'train_loss': '1.24818'}; time used = 0.3193826675415039s
epoch 440: {'train_loss': '1.24896'}; time used = 0.31624937057495117s
epoch 445: {'train_loss': '1.24801'}; time used = 0.3144965171813965s
epoch 450: {'train_loss': '1.25184'}; time used = 0.30803442001342773s
epoch 455: {'train_loss': '1.24996'}; time used = 0.2859315872192383s
epoch 460: {'train_loss': '1.24653'}; time used = 0.30533385276794434s
epoch 465: {'train_loss': '1.24657'}; time used = 0.4309673309326172s
epoch 470: {'train_loss': '1.24814'}; time used = 0.42966532707214355s
epoch 475: {'train_loss': '1.24705'}; time used = 0.2729027271270752s
epoch 480: {'train_loss': '1.25017'}; time used = 0.28328943252563477s
epoch 485: {'train_loss': '1.24693'}; time used = 0.3305497169494629s
epoch 490: {'train_loss': '1.24831'}; time used = 0.35512304306030273s
epoch 495: {'train_loss': '1.24514'}; time used = 0.38458704948425293s
epoch 500: {'train_loss': '1.24479'}; time used = 0.32999444007873535s
Finished training. Time used = 40.25092053413391.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}

  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5931/10556 [00:00<00:00, 57195.32it/s]100%|| 10556/10556 [00:00<00:00, 73677.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8848/10556 [00:00<00:00, 88474.60it/s]100%|| 10556/10556 [00:00<00:00, 91809.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7557/10556 [00:00<00:00, 75564.31it/s]100%|| 10556/10556 [00:00<00:00, 84260.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8068/10556 [00:00<00:00, 79737.52it/s]100%|| 10556/10556 [00:00<00:00, 80347.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4817/10556 [00:00<00:00, 46891.52it/s]100%|| 10556/10556 [00:00<00:00, 56742.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10373/10556 [00:00<00:00, 103722.93it/s]100%|| 10556/10556 [00:00<00:00, 103713.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6679/10556 [00:00<00:00, 66785.92it/s]100%|| 10556/10556 [00:00<00:00, 63257.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107851.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6104/10556 [00:00<00:00, 57239.51it/s]100%|| 10556/10556 [00:00<00:00, 62543.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6378/10556 [00:00<00:00, 62226.87it/s]100%|| 10556/10556 [00:00<00:00, 59652.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6638/10556 [00:00<00:00, 63662.97it/s]100%|| 10556/10556 [00:00<00:00, 75199.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6076/10556 [00:00<00:00, 60755.86it/s]100%|| 10556/10556 [00:00<00:00, 76358.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114752.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6632/10556 [00:00<00:00, 64217.60it/s]100%|| 10556/10556 [00:00<00:00, 75485.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109385.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6453/10556 [00:00<00:00, 64524.52it/s]100%|| 10556/10556 [00:00<00:00, 74418.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112542.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6297/10556 [00:00<00:00, 62968.86it/s]100%|| 10556/10556 [00:00<00:00, 76711.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115893.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5781/10556 [00:00<00:00, 57806.33it/s]100%|| 10556/10556 [00:00<00:00, 74899.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117096.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6514/10556 [00:00<00:00, 62010.20it/s]100%|| 10556/10556 [00:00<00:00, 75440.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115930.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6867/10556 [00:00<00:00, 67489.96it/s]100%|| 10556/10556 [00:00<00:00, 79251.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116315.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6400/10556 [00:00<00:00, 63996.55it/s]100%|| 10556/10556 [00:00<00:00, 77108.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 28%|       | 2934/10556 [00:00<00:00, 29336.67it/s]100%|| 10556/10556 [00:00<00:00, 58768.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7856/10556 [00:00<00:00, 78558.76it/s]100%|| 10556/10556 [00:00<00:00, 86170.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7791/10556 [00:00<00:00, 77904.50it/s]100%|| 10556/10556 [00:00<00:00, 61276.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8684/10556 [00:00<00:00, 86833.87it/s]100%|| 10556/10556 [00:00<00:00, 91564.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6613/10556 [00:00<00:00, 66125.02it/s]100%|| 10556/10556 [00:00<00:00, 74439.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7796/10556 [00:00<00:00, 77611.64it/s]100%|| 10556/10556 [00:00<00:00, 79075.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9383/10556 [00:00<00:00, 93821.81it/s]100%|| 10556/10556 [00:00<00:00, 95436.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6638/10556 [00:00<00:00, 62631.13it/s]100%|| 10556/10556 [00:00<00:00, 49113.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 5993/10556 [00:00<00:00, 59856.70it/s]100%|| 10556/10556 [00:00<00:00, 60239.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107338.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115149.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6546/10556 [00:00<00:00, 62980.95it/s]100%|| 10556/10556 [00:00<00:00, 70239.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10289/10556 [00:00<00:00, 102887.40it/s]100%|| 10556/10556 [00:00<00:00, 102961.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117789.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117520.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117479.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108093.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116789.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117743.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119462.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119013.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118002.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117625.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118500.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118591.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118138.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110700.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|   | 6483/10556 [00:00<00:00, 64825.73it/s]100%|| 10556/10556 [00:00<00:00, 65971.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7617/10556 [00:00<00:00, 76167.71it/s]100%|| 10556/10556 [00:00<00:00, 79513.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|  | 7536/10556 [00:00<00:00, 75357.56it/s]100%|| 10556/10556 [00:00<00:00, 79647.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 5979/10556 [00:00<00:00, 59230.70it/s]100%|| 10556/10556 [00:00<00:00, 65409.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9347/10556 [00:00<00:00, 93463.40it/s]100%|| 10556/10556 [00:00<00:00, 95722.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5838/10556 [00:00<00:00, 56348.23it/s]100%|| 10556/10556 [00:00<00:00, 58737.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6066/10556 [00:00<00:00, 60656.59it/s]100%|| 10556/10556 [00:00<00:00, 59244.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10341/10556 [00:00<00:00, 103407.63it/s]100%|| 10556/10556 [00:00<00:00, 103410.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6541/10556 [00:00<00:00, 65409.28it/s]100%|| 10556/10556 [00:00<00:00, 61168.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6587/10556 [00:00<00:00, 65865.19it/s]100%|| 10556/10556 [00:00<00:00, 72353.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117023.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118307.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117262.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|  | 7522/10556 [00:00<00:00, 75218.10it/s]100%|| 10556/10556 [00:00<00:00, 83914.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117461.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118083.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117463.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 28%|       | 2961/10556 [00:00<00:00, 29539.25it/s] 93%|| 9799/10556 [00:00<00:00, 35606.36it/s]100%|| 10556/10556 [00:00<00:00, 50985.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7207/10556 [00:00<00:00, 72068.69it/s]100%|| 10556/10556 [00:00<00:00, 82096.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107961.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6406/10556 [00:00<00:00, 64059.60it/s]100%|| 10556/10556 [00:00<00:00, 72680.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9961/10556 [00:00<00:00, 99605.82it/s]100%|| 10556/10556 [00:00<00:00, 100322.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7875/10556 [00:00<00:00, 78745.38it/s]100%|| 10556/10556 [00:00<00:00, 86808.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110586.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7878/10556 [00:00<00:00, 78779.14it/s]100%|| 10556/10556 [00:00<00:00, 85321.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7831/10556 [00:00<00:00, 77743.81it/s]100%|| 10556/10556 [00:00<00:00, 77076.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5667/10556 [00:00<00:00, 55099.68it/s]100%|| 10556/10556 [00:00<00:00, 59209.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5047/10556 [00:00<00:00, 48969.09it/s] 99%|| 10500/10556 [00:00<00:00, 49415.70it/s]100%|| 10556/10556 [00:00<00:00, 49801.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7169/10556 [00:00<00:00, 71686.48it/s]100%|| 10556/10556 [00:00<00:00, 63780.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6034/10556 [00:00<00:00, 60338.19it/s]100%|| 10556/10556 [00:00<00:00, 58818.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 5992/10556 [00:00<00:00, 59916.06it/s]100%|| 10556/10556 [00:00<00:00, 58537.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5622/10556 [00:00<00:00, 56218.04it/s]100%|| 10556/10556 [00:00<00:00, 51803.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6201/10556 [00:00<00:00, 56600.10it/s]100%|| 10556/10556 [00:00<00:00, 54532.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9668/10556 [00:00<00:00, 91427.22it/s]100%|| 10556/10556 [00:00<00:00, 86485.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8208/10556 [00:00<00:00, 82078.51it/s]100%|| 10556/10556 [00:00<00:00, 87992.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 5991/10556 [00:00<00:00, 57163.31it/s]100%|| 10556/10556 [00:00<00:00, 60701.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113002.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6448/10556 [00:00<00:00, 64477.45it/s]100%|| 10556/10556 [00:00<00:00, 60861.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9869/10556 [00:00<00:00, 98688.21it/s]100%|| 10556/10556 [00:00<00:00, 99384.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8523/10556 [00:00<00:00, 85225.00it/s]100%|| 10556/10556 [00:00<00:00, 83825.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6594/10556 [00:00<00:00, 65937.55it/s]100%|| 10556/10556 [00:00<00:00, 72374.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117579.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118277.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117564.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117235.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6210/10556 [00:00<00:00, 61381.36it/s]100%|| 10556/10556 [00:00<00:00, 73692.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7213/10556 [00:00<00:00, 72125.25it/s]100%|| 10556/10556 [00:00<00:00, 75301.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8166/10556 [00:00<00:00, 81655.60it/s]100%|| 10556/10556 [00:00<00:00, 87310.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5036/10556 [00:00<00:00, 49423.84it/s]100%|| 10556/10556 [00:00<00:00, 61747.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10511/10556 [00:00<00:00, 105103.84it/s]100%|| 10556/10556 [00:00<00:00, 104840.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5236/10556 [00:00<00:00, 52356.93it/s]100%|| 10556/10556 [00:00<00:00, 52974.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5513/10556 [00:00<00:00, 52774.74it/s]100%|| 10556/10556 [00:00<00:00, 54115.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6166/10556 [00:00<00:00, 57585.18it/s]100%|| 10556/10556 [00:00<00:00, 57819.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6241/10556 [00:00<00:00, 61059.97it/s]100%|| 10556/10556 [00:00<00:00, 54374.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 7984/10556 [00:00<00:00, 79835.51it/s]100%|| 10556/10556 [00:00<00:00, 85683.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10510/10556 [00:00<00:00, 105093.59it/s]100%|| 10556/10556 [00:00<00:00, 104831.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6519/10556 [00:00<00:00, 65189.29it/s]100%|| 10556/10556 [00:00<00:00, 68213.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105975.74it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.50555'}; time used = 0.747722864151001s
epoch 10: {'train_loss': '1.38852'}; time used = 0.8191184997558594s
epoch 15: {'train_loss': '1.34590'}; time used = 0.6656570434570312s
epoch 20: {'train_loss': '1.32748'}; time used = 0.6254534721374512s
epoch 25: {'train_loss': '1.30669'}; time used = 0.660797119140625s
epoch 30: {'train_loss': '1.28902'}; time used = 0.8090300559997559s
epoch 35: {'train_loss': '1.27227'}; time used = 0.8352775573730469s
epoch 40: {'train_loss': '1.25750'}; time used = 0.5718772411346436s
epoch 45: {'train_loss': '1.25708'}; time used = 0.48401856422424316s
epoch 50: {'train_loss': '1.24879'}; time used = 0.4724388122558594s
epoch 55: {'train_loss': '1.25060'}; time used = 0.686819314956665s
epoch 60: {'train_loss': '1.24543'}; time used = 0.8026680946350098s
epoch 65: {'train_loss': '1.24745'}; time used = 0.6351227760314941s
epoch 70: {'train_loss': '1.24601'}; time used = 0.6436934471130371s
epoch 75: {'train_loss': '1.24635'}; time used = 0.6794462203979492s
epoch 80: {'train_loss': '1.24384'}; time used = 0.8389911651611328s
epoch 85: {'train_loss': '1.24353'}; time used = 0.9753665924072266s
epoch 90: {'train_loss': '1.24333'}; time used = 0.7482128143310547s
epoch 95: {'train_loss': '1.23961'}; time used = 0.6141211986541748s
epoch 100: {'train_loss': '1.24502'}; time used = 0.6326949596405029s
epoch 105: {'train_loss': '1.23892'}; time used = 0.920018196105957s
epoch 110: {'train_loss': '1.24640'}; time used = 0.7400994300842285s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.416626930236816.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06508785332314744, 'samples': 0.29487771112136596, 'weighted': 0.13435070046813036}
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 134079.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122302.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136413.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135005.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137173.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131989.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140805.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133800.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123181.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 137913.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119685.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156634.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155142.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153094.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8547/10556 [00:00<00:00, 85328.69it/s]100%|| 10556/10556 [00:00<00:00, 76513.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5874/10556 [00:00<00:00, 58735.85it/s]100%|| 10556/10556 [00:00<00:00, 59070.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6463/10556 [00:00<00:00, 63438.37it/s]100%|| 10556/10556 [00:00<00:00, 63448.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7590/10556 [00:00<00:00, 75895.19it/s]100%|| 10556/10556 [00:00<00:00, 67547.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7013/10556 [00:00<00:00, 69023.21it/s]100%|| 10556/10556 [00:00<00:00, 67170.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6631/10556 [00:00<00:00, 64230.16it/s]100%|| 10556/10556 [00:00<00:00, 63337.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6641/10556 [00:00<00:00, 66409.75it/s]100%|| 10556/10556 [00:00<00:00, 79356.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118622.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|      | 3636/10556 [00:00<00:00, 30790.35it/s] 82%| | 8659/10556 [00:00<00:00, 33440.82it/s]100%|| 10556/10556 [00:00<00:00, 33181.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4679/10556 [00:00<00:00, 46786.59it/s] 74%|  | 7829/10556 [00:00<00:00, 40839.53it/s]100%|| 10556/10556 [00:00<00:00, 40037.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 5992/10556 [00:00<00:00, 55742.71it/s]100%|| 10556/10556 [00:00<00:00, 59146.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8763/10556 [00:00<00:00, 87629.46it/s]100%|| 10556/10556 [00:00<00:00, 90144.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6764/10556 [00:00<00:00, 65724.72it/s]100%|| 10556/10556 [00:00<00:00, 65082.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126060.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126915.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129788.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116440.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127807.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126995.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128007.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9904/10556 [00:00<00:00, 99037.97it/s]100%|| 10556/10556 [00:00<00:00, 100247.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117809.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7028/10556 [00:00<00:00, 69134.66it/s]100%|| 10556/10556 [00:00<00:00, 74625.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6111/10556 [00:00<00:00, 61107.87it/s] 96%|| 10096/10556 [00:00<00:00, 52677.12it/s]100%|| 10556/10556 [00:00<00:00, 50940.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5814/10556 [00:00<00:00, 58139.09it/s]100%|| 10556/10556 [00:00<00:00, 58985.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6544/10556 [00:00<00:00, 64823.86it/s]100%|| 10556/10556 [00:00<00:00, 65255.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7551/10556 [00:00<00:00, 72342.84it/s]100%|| 10556/10556 [00:00<00:00, 72728.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5401/10556 [00:00<00:00, 54007.99it/s] 80%|  | 8474/10556 [00:00<00:00, 44005.90it/s]100%|| 10556/10556 [00:00<00:00, 42326.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6146/10556 [00:00<00:00, 61244.39it/s]100%|| 10556/10556 [00:00<00:00, 67316.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7663/10556 [00:00<00:00, 76628.43it/s]100%|| 10556/10556 [00:00<00:00, 80903.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110783.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106651.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6952/10556 [00:00<00:00, 69516.59it/s]100%|| 10556/10556 [00:00<00:00, 59645.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5308/10556 [00:00<00:00, 46862.15it/s]100%|| 10556/10556 [00:00<00:00, 49577.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110278.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4964/10556 [00:00<00:00, 49638.86it/s]100%|| 10556/10556 [00:00<00:00, 64310.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119898.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9774/10556 [00:00<00:00, 97738.23it/s]100%|| 10556/10556 [00:00<00:00, 99367.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9235/10556 [00:00<00:00, 92348.99it/s]100%|| 10556/10556 [00:00<00:00, 93130.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6326/10556 [00:00<00:00, 63258.85it/s] 89%| | 9415/10556 [00:00<00:00, 47779.44it/s]100%|| 10556/10556 [00:00<00:00, 41624.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3729/10556 [00:00<00:00, 37289.59it/s] 82%| | 8702/10556 [00:00<00:00, 40314.95it/s]100%|| 10556/10556 [00:00<00:00, 46327.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6676/10556 [00:00<00:00, 66750.36it/s]100%|| 10556/10556 [00:00<00:00, 66526.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5193/10556 [00:00<00:00, 51928.44it/s] 95%|| 10074/10556 [00:00<00:00, 50950.73it/s]100%|| 10556/10556 [00:00<00:00, 50887.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4455/10556 [00:00<00:00, 44546.75it/s] 89%| | 9435/10556 [00:00<00:00, 46001.56it/s]100%|| 10556/10556 [00:00<00:00, 45034.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|      | 3559/10556 [00:00<00:00, 34577.51it/s] 85%| | 8950/10556 [00:00<00:00, 38744.89it/s]100%|| 10556/10556 [00:00<00:00, 46054.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5163/10556 [00:00<00:00, 51624.14it/s]100%|| 10556/10556 [00:00<00:00, 52793.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 21%|       | 2246/10556 [00:00<00:00, 21754.23it/s] 37%|      | 3931/10556 [00:00<00:00, 20006.81it/s] 78%|  | 8201/10556 [00:00<00:00, 23801.63it/s]100%|| 10556/10556 [00:00<00:00, 31020.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 27%|       | 2859/10556 [00:00<00:00, 24369.43it/s] 59%|    | 6259/10556 [00:00<00:00, 26631.94it/s] 82%| | 8673/10556 [00:00<00:00, 25831.89it/s]100%|| 10556/10556 [00:00<00:00, 27896.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5350/10556 [00:00<00:00, 52852.61it/s]100%|| 10556/10556 [00:00<00:00, 58905.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5248/10556 [00:00<00:00, 52479.17it/s]100%|| 10556/10556 [00:00<00:00, 70891.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122484.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114111.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124217.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125557.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123378.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 26%|       | 2757/10556 [00:00<00:00, 27449.41it/s] 58%|    | 6131/10556 [00:00<00:00, 29075.44it/s] 91%|| 9647/10556 [00:00<00:00, 30030.56it/s]100%|| 10556/10556 [00:00<00:00, 32092.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 28%|       | 2981/10556 [00:00<00:00, 28481.01it/s] 59%|    | 6221/10556 [00:00<00:00, 28666.19it/s]100%|| 10556/10556 [00:00<00:00, 34008.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6063/10556 [00:00<00:00, 59780.87it/s]100%|| 10556/10556 [00:00<00:00, 58941.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|      | 3962/10556 [00:00<00:00, 39614.84it/s] 92%|| 9668/10556 [00:00<00:00, 43614.51it/s]100%|| 10556/10556 [00:00<00:00, 49456.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3835/10556 [00:00<00:00, 38344.28it/s] 95%|| 9980/10556 [00:00<00:00, 43218.52it/s]100%|| 10556/10556 [00:00<00:00, 50563.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5630/10556 [00:00<00:00, 56290.26it/s]100%|| 10556/10556 [00:00<00:00, 60083.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6393/10556 [00:00<00:00, 63923.81it/s]100%|| 10556/10556 [00:00<00:00, 62353.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6441/10556 [00:00<00:00, 63380.84it/s]100%|| 10556/10556 [00:00<00:00, 63510.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117804.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7757/10556 [00:00<00:00, 73254.25it/s]100%|| 10556/10556 [00:00<00:00, 68024.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8831/10556 [00:00<00:00, 88307.77it/s]100%|| 10556/10556 [00:00<00:00, 90063.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5368/10556 [00:00<00:00, 52630.28it/s]100%|| 10556/10556 [00:00<00:00, 67417.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8648/10556 [00:00<00:00, 86478.85it/s]100%|| 10556/10556 [00:00<00:00, 87601.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4936/10556 [00:00<00:00, 49355.10it/s] 87%| | 9178/10556 [00:00<00:00, 47047.32it/s]100%|| 10556/10556 [00:00<00:00, 43040.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5313/10556 [00:00<00:00, 53127.39it/s] 90%| | 9473/10556 [00:00<00:00, 49048.47it/s]100%|| 10556/10556 [00:00<00:00, 46386.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4476/10556 [00:00<00:00, 39990.94it/s] 79%|  | 8345/10556 [00:00<00:00, 39108.22it/s]100%|| 10556/10556 [00:00<00:00, 40609.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118113.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124974.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117522.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6445/10556 [00:00<00:00, 64443.45it/s]100%|| 10556/10556 [00:00<00:00, 60021.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8348/10556 [00:00<00:00, 83478.29it/s]100%|| 10556/10556 [00:00<00:00, 76349.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7205/10556 [00:00<00:00, 72048.52it/s]100%|| 10556/10556 [00:00<00:00, 68971.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6661/10556 [00:00<00:00, 66607.05it/s]100%|| 10556/10556 [00:00<00:00, 73974.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107398.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5680/10556 [00:00<00:00, 54560.18it/s]100%|| 10556/10556 [00:00<00:00, 72127.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118200.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7050/10556 [00:00<00:00, 70495.03it/s]100%|| 10556/10556 [00:00<00:00, 77389.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126762.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6946/10556 [00:00<00:00, 67502.25it/s]100%|| 10556/10556 [00:00<00:00, 80173.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121258.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7162/10556 [00:00<00:00, 71618.36it/s]100%|| 10556/10556 [00:00<00:00, 78390.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10303/10556 [00:00<00:00, 103020.76it/s]100%|| 10556/10556 [00:00<00:00, 98594.79it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6757/10556 [00:00<00:00, 67568.45it/s]100%|| 10556/10556 [00:00<00:00, 77467.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126451.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6627/10556 [00:00<00:00, 66267.22it/s]100%|| 10556/10556 [00:00<00:00, 80531.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7181/10556 [00:00<00:00, 71389.49it/s]100%|| 10556/10556 [00:00<00:00, 68597.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7145/10556 [00:00<00:00, 66929.83it/s]100%|| 10556/10556 [00:00<00:00, 65968.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126714.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7639/10556 [00:00<00:00, 70897.98it/s]100%|| 10556/10556 [00:00<00:00, 69018.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117734.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7092/10556 [00:00<00:00, 70914.83it/s]100%|| 10556/10556 [00:00<00:00, 63167.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127437.42it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.40130'}; time used = 0.4779796600341797s
epoch 10: {'train_loss': '1.34031'}; time used = 0.4766254425048828s
epoch 15: {'train_loss': '1.31336'}; time used = 0.6013367176055908s
epoch 20: {'train_loss': '1.27880'}; time used = 0.8735451698303223s
epoch 25: {'train_loss': '1.25946'}; time used = 1.0737650394439697s
epoch 30: {'train_loss': '1.25286'}; time used = 0.5716307163238525s
epoch 35: {'train_loss': '1.24936'}; time used = 0.48503684997558594s
epoch 40: {'train_loss': '1.24251'}; time used = 0.9276206493377686s
epoch 45: {'train_loss': '1.24409'}; time used = 0.8207097053527832s
epoch 50: {'train_loss': '1.23584'}; time used = 0.8106653690338135s
epoch 55: {'train_loss': '1.23682'}; time used = 0.9358100891113281s
epoch 60: {'train_loss': '1.23217'}; time used = 1.322801113128662s
epoch 65: {'train_loss': '1.23493'}; time used = 0.9925992488861084s
epoch 70: {'train_loss': '1.23204'}; time used = 0.9845006465911865s
epoch 75: {'train_loss': '1.23262'}; time used = 1.036391019821167s
epoch 80: {'train_loss': '1.22851'}; time used = 0.7497823238372803s
epoch 85: {'train_loss': '1.22901'}; time used = 1.0246224403381348s
epoch 90: {'train_loss': '1.22893'}; time used = 0.6911182403564453s
epoch 95: {'train_loss': '1.22523'}; time used = 0.6788597106933594s
epoch 100: {'train_loss': '1.23054'}; time used = 0.6046023368835449s
epoch 105: {'train_loss': '1.22526'}; time used = 0.7377369403839111s
epoch 110: {'train_loss': '1.23434'}; time used = 0.6380834579467773s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.158422708511353.
Training classifier using 20.00% nodes...
{'micro': 0.29441624365482233, 'macro': 0.06507879838833068, 'samples': 0.29441624365482233, 'weighted': 0.13433200977895854}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125217.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8066/10556 [00:00<00:00, 80518.59it/s]100%|| 10556/10556 [00:00<00:00, 79647.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6554/10556 [00:00<00:00, 63978.69it/s]100%|| 10556/10556 [00:00<00:00, 60469.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6297/10556 [00:00<00:00, 62969.01it/s]100%|| 10556/10556 [00:00<00:00, 66863.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112200.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8810/10556 [00:00<00:00, 88096.09it/s]100%|| 10556/10556 [00:00<00:00, 92617.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125705.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6138/10556 [00:00<00:00, 61375.96it/s]100%|| 10556/10556 [00:00<00:00, 60822.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|  | 7545/10556 [00:00<00:00, 72714.21it/s]100%|| 10556/10556 [00:00<00:00, 81421.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121047.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8362/10556 [00:00<00:00, 83614.70it/s]100%|| 10556/10556 [00:00<00:00, 89882.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127262.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7763/10556 [00:00<00:00, 77627.85it/s]100%|| 10556/10556 [00:00<00:00, 86688.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10192/10556 [00:00<00:00, 101916.45it/s]100%|| 10556/10556 [00:00<00:00, 102479.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126913.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125372.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6701/10556 [00:00<00:00, 67005.91it/s] 97%|| 10205/10556 [00:00<00:00, 52606.30it/s]100%|| 10556/10556 [00:00<00:00, 49102.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6587/10556 [00:00<00:00, 65868.81it/s]100%|| 10556/10556 [00:00<00:00, 66501.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6811/10556 [00:00<00:00, 66165.93it/s]100%|| 10556/10556 [00:00<00:00, 70019.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7786/10556 [00:00<00:00, 77855.25it/s]100%|| 10556/10556 [00:00<00:00, 86807.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 5973/10556 [00:00<00:00, 59729.06it/s]100%|| 10556/10556 [00:00<00:00, 65672.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126767.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125239.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125900.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125186.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111343.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7598/10556 [00:00<00:00, 75974.28it/s]100%|| 10556/10556 [00:00<00:00, 69858.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110505.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6635/10556 [00:00<00:00, 65778.27it/s]100%|| 10556/10556 [00:00<00:00, 64433.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106910.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125727.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109087.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8361/10556 [00:00<00:00, 76180.06it/s]100%|| 10556/10556 [00:00<00:00, 73122.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7032/10556 [00:00<00:00, 70315.54it/s]100%|| 10556/10556 [00:00<00:00, 82360.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110688.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110206.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113321.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7165/10556 [00:00<00:00, 71649.90it/s]100%|| 10556/10556 [00:00<00:00, 65765.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7066/10556 [00:00<00:00, 70527.90it/s]100%|| 10556/10556 [00:00<00:00, 66645.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5919/10556 [00:00<00:00, 59185.82it/s]100%|| 10556/10556 [00:00<00:00, 76101.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9458/10556 [00:00<00:00, 94573.55it/s]100%|| 10556/10556 [00:00<00:00, 96153.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9081/10556 [00:00<00:00, 90803.59it/s]100%|| 10556/10556 [00:00<00:00, 94117.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9207/10556 [00:00<00:00, 92063.06it/s]100%|| 10556/10556 [00:00<00:00, 94864.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123517.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127970.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127076.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7161/10556 [00:00<00:00, 71162.32it/s]100%|| 10556/10556 [00:00<00:00, 80568.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10192/10556 [00:00<00:00, 101581.76it/s]100%|| 10556/10556 [00:00<00:00, 99004.42it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5666/10556 [00:00<00:00, 56654.65it/s]100%|| 10556/10556 [00:00<00:00, 60779.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4406/10556 [00:00<00:00, 44053.95it/s]100%|| 10556/10556 [00:00<00:00, 53009.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|      | 4013/10556 [00:00<00:00, 40126.31it/s] 79%|  | 8347/10556 [00:00<00:00, 41038.63it/s]100%|| 10556/10556 [00:00<00:00, 45378.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6401/10556 [00:00<00:00, 64000.91it/s]100%|| 10556/10556 [00:00<00:00, 62707.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6507/10556 [00:00<00:00, 65066.49it/s]100%|| 10556/10556 [00:00<00:00, 65980.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4299/10556 [00:00<00:00, 38349.48it/s] 75%|  | 7881/10556 [00:00<00:00, 37553.66it/s]100%|| 10556/10556 [00:00<00:00, 36561.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4108/10556 [00:00<00:00, 41076.61it/s] 85%| | 8978/10556 [00:00<00:00, 43100.06it/s]100%|| 10556/10556 [00:00<00:00, 46669.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6297/10556 [00:00<00:00, 62966.61it/s]100%|| 10556/10556 [00:00<00:00, 78701.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7628/10556 [00:00<00:00, 76274.80it/s]100%|| 10556/10556 [00:00<00:00, 78141.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109281.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125273.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6863/10556 [00:00<00:00, 68628.59it/s]100%|| 10556/10556 [00:00<00:00, 81740.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123377.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116296.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7375/10556 [00:00<00:00, 73745.15it/s]100%|| 10556/10556 [00:00<00:00, 83999.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124389.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6416/10556 [00:00<00:00, 64158.23it/s]100%|| 10556/10556 [00:00<00:00, 79070.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113894.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8374/10556 [00:00<00:00, 83118.03it/s]100%|| 10556/10556 [00:00<00:00, 76904.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6108/10556 [00:00<00:00, 61077.73it/s]100%|| 10556/10556 [00:00<00:00, 60872.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4213/10556 [00:00<00:00, 37264.82it/s]100%|| 10556/10556 [00:00<00:00, 64388.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8985/10556 [00:00<00:00, 89844.73it/s]100%|| 10556/10556 [00:00<00:00, 85207.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4089/10556 [00:00<00:00, 40887.80it/s]100%|| 10556/10556 [00:00<00:00, 69434.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6514/10556 [00:00<00:00, 60061.68it/s]100%|| 10556/10556 [00:00<00:00, 73089.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6883/10556 [00:00<00:00, 65700.51it/s]100%|| 10556/10556 [00:00<00:00, 70019.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6857/10556 [00:00<00:00, 68568.27it/s]100%|| 10556/10556 [00:00<00:00, 64947.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9388/10556 [00:00<00:00, 93874.05it/s]100%|| 10556/10556 [00:00<00:00, 96573.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9550/10556 [00:00<00:00, 95496.22it/s]100%|| 10556/10556 [00:00<00:00, 97446.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5239/10556 [00:00<00:00, 51504.08it/s]100%|| 10556/10556 [00:00<00:00, 67094.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108953.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6723/10556 [00:00<00:00, 67221.57it/s]100%|| 10556/10556 [00:00<00:00, 67618.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|       | 3072/10556 [00:00<00:00, 29657.55it/s] 64%|   | 6800/10556 [00:00<00:00, 31431.87it/s]100%|| 10556/10556 [00:00<00:00, 38579.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5892/10556 [00:00<00:00, 58917.95it/s]100%|| 10556/10556 [00:00<00:00, 55728.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4249/10556 [00:00<00:00, 42489.13it/s] 87%| | 9236/10556 [00:00<00:00, 44462.09it/s]100%|| 10556/10556 [00:00<00:00, 47941.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6104/10556 [00:00<00:00, 61033.80it/s]100%|| 10556/10556 [00:00<00:00, 63446.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6799/10556 [00:00<00:00, 67984.07it/s]100%|| 10556/10556 [00:00<00:00, 67684.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6196/10556 [00:00<00:00, 61953.86it/s]100%|| 10556/10556 [00:00<00:00, 63641.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6736/10556 [00:00<00:00, 67357.01it/s]100%|| 10556/10556 [00:00<00:00, 65019.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6845/10556 [00:00<00:00, 66596.64it/s]100%|| 10556/10556 [00:00<00:00, 68732.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6945/10556 [00:00<00:00, 69445.76it/s]100%|| 10556/10556 [00:00<00:00, 81619.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112608.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7139/10556 [00:00<00:00, 71388.54it/s]100%|| 10556/10556 [00:00<00:00, 60175.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107005.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6717/10556 [00:00<00:00, 67164.94it/s]100%|| 10556/10556 [00:00<00:00, 65469.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 130019.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7479/10556 [00:00<00:00, 72285.59it/s]100%|| 10556/10556 [00:00<00:00, 79893.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7374/10556 [00:00<00:00, 70170.72it/s]100%|| 10556/10556 [00:00<00:00, 80651.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9503/10556 [00:00<00:00, 95028.50it/s]100%|| 10556/10556 [00:00<00:00, 97232.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122027.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123565.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105936.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7885/10556 [00:00<00:00, 78846.50it/s]100%|| 10556/10556 [00:00<00:00, 86544.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108843.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121416.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7496/10556 [00:00<00:00, 74956.14it/s]100%|| 10556/10556 [00:00<00:00, 84721.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124065.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6509/10556 [00:00<00:00, 65087.27it/s]100%|| 10556/10556 [00:00<00:00, 76001.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9954/10556 [00:00<00:00, 95962.25it/s]100%|| 10556/10556 [00:00<00:00, 96865.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123145.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9424/10556 [00:00<00:00, 94237.84it/s]100%|| 10556/10556 [00:00<00:00, 96640.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10277/10556 [00:00<00:00, 100342.34it/s]100%|| 10556/10556 [00:00<00:00, 97734.45it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115839.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121372.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122677.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7494/10556 [00:00<00:00, 74934.71it/s]100%|| 10556/10556 [00:00<00:00, 74528.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6809/10556 [00:00<00:00, 68086.33it/s]100%|| 10556/10556 [00:00<00:00, 54544.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|    | 5420/10556 [00:00<00:00, 54196.69it/s]100%|| 10556/10556 [00:00<00:00, 53643.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6995/10556 [00:00<00:00, 69949.73it/s]100%|| 10556/10556 [00:00<00:00, 56477.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10391/10556 [00:00<00:00, 103909.36it/s]100%|| 10556/10556 [00:00<00:00, 103755.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6876/10556 [00:00<00:00, 67044.59it/s]100%|| 10556/10556 [00:00<00:00, 71771.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114504.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10236/10556 [00:00<00:00, 102359.61it/s]100%|| 10556/10556 [00:00<00:00, 102430.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6276/10556 [00:00<00:00, 56591.56it/s]100%|| 10556/10556 [00:00<00:00, 68930.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10216/10556 [00:00<00:00, 102157.17it/s]100%|| 10556/10556 [00:00<00:00, 91834.13it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126957.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117332.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127455.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6777/10556 [00:00<00:00, 66985.75it/s]100%|| 10556/10556 [00:00<00:00, 80190.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117249.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6757/10556 [00:00<00:00, 66664.42it/s]100%|| 10556/10556 [00:00<00:00, 77324.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10522/10556 [00:00<00:00, 103502.83it/s]100%|| 10556/10556 [00:00<00:00, 97236.05it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5910/10556 [00:00<00:00, 57313.01it/s]100%|| 10556/10556 [00:00<00:00, 73043.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6817/10556 [00:00<00:00, 64853.85it/s]100%|| 10556/10556 [00:00<00:00, 56657.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6746/10556 [00:00<00:00, 65839.31it/s]100%|| 10556/10556 [00:00<00:00, 62057.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7120/10556 [00:00<00:00, 71194.98it/s]100%|| 10556/10556 [00:00<00:00, 68145.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5964/10556 [00:00<00:00, 59036.09it/s]100%|| 10556/10556 [00:00<00:00, 51743.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7180/10556 [00:00<00:00, 71797.50it/s]100%|| 10556/10556 [00:00<00:00, 64304.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6680/10556 [00:00<00:00, 64838.51it/s]100%|| 10556/10556 [00:00<00:00, 71178.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120320.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10130/10556 [00:00<00:00, 101294.06it/s]100%|| 10556/10556 [00:00<00:00, 101883.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123935.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114780.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122242.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7803/10556 [00:00<00:00, 78028.03it/s]100%|| 10556/10556 [00:00<00:00, 86379.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123056.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6827/10556 [00:00<00:00, 65813.15it/s]100%|| 10556/10556 [00:00<00:00, 77949.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7277/10556 [00:00<00:00, 72764.34it/s]100%|| 10556/10556 [00:00<00:00, 66489.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6830/10556 [00:00<00:00, 68299.58it/s]100%|| 10556/10556 [00:00<00:00, 69883.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7000/10556 [00:00<00:00, 69994.56it/s]100%|| 10556/10556 [00:00<00:00, 61957.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9188/10556 [00:00<00:00, 91876.80it/s]100%|| 10556/10556 [00:00<00:00, 94521.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|    | 5427/10556 [00:00<00:00, 53388.20it/s]100%|| 10556/10556 [00:00<00:00, 56850.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119752.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7845/10556 [00:00<00:00, 78447.27it/s]100%|| 10556/10556 [00:00<00:00, 70244.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7703/10556 [00:00<00:00, 77026.77it/s]100%|| 10556/10556 [00:00<00:00, 85648.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6189/10556 [00:00<00:00, 61888.14it/s] 98%|| 10380/10556 [00:00<00:00, 51483.27it/s]100%|| 10556/10556 [00:00<00:00, 48612.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8053/10556 [00:00<00:00, 80525.28it/s]100%|| 10556/10556 [00:00<00:00, 88131.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 5968/10556 [00:00<00:00, 58548.53it/s]100%|| 10556/10556 [00:00<00:00, 60068.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113476.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9178/10556 [00:00<00:00, 91779.43it/s]100%|| 10556/10556 [00:00<00:00, 95145.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8702/10556 [00:00<00:00, 87016.35it/s]100%|| 10556/10556 [00:00<00:00, 91582.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113823.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7252/10556 [00:00<00:00, 72516.27it/s]100%|| 10556/10556 [00:00<00:00, 61749.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106692.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6606/10556 [00:00<00:00, 66059.75it/s]100%|| 10556/10556 [00:00<00:00, 66608.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6998/10556 [00:00<00:00, 69978.73it/s]100%|| 10556/10556 [00:00<00:00, 81430.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10397/10556 [00:00<00:00, 103963.41it/s]100%|| 10556/10556 [00:00<00:00, 97069.55it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6021/10556 [00:00<00:00, 60205.89it/s]100%|| 10556/10556 [00:00<00:00, 51199.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4811/10556 [00:00<00:00, 46834.74it/s]100%|| 10556/10556 [00:00<00:00, 54560.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5647/10556 [00:00<00:00, 56469.52it/s]100%|| 10556/10556 [00:00<00:00, 62035.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7409/10556 [00:00<00:00, 73388.78it/s]100%|| 10556/10556 [00:00<00:00, 73228.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5077/10556 [00:00<00:00, 50766.90it/s] 87%| | 9134/10556 [00:00<00:00, 47206.51it/s]100%|| 10556/10556 [00:00<00:00, 44728.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4086/10556 [00:00<00:00, 39457.58it/s]100%|| 10556/10556 [00:00<00:00, 56130.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110973.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10209/10556 [00:00<00:00, 102087.42it/s]100%|| 10556/10556 [00:00<00:00, 102227.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10360/10556 [00:00<00:00, 103593.68it/s]100%|| 10556/10556 [00:00<00:00, 103494.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8799/10556 [00:00<00:00, 87984.63it/s]100%|| 10556/10556 [00:00<00:00, 82362.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6616/10556 [00:00<00:00, 66156.12it/s]100%|| 10556/10556 [00:00<00:00, 60057.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5810/10556 [00:00<00:00, 54689.20it/s]100%|| 10556/10556 [00:00<00:00, 55749.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8866/10556 [00:00<00:00, 88655.22it/s]100%|| 10556/10556 [00:00<00:00, 91226.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7035/10556 [00:00<00:00, 70347.55it/s]100%|| 10556/10556 [00:00<00:00, 69003.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7826/10556 [00:00<00:00, 78256.34it/s]100%|| 10556/10556 [00:00<00:00, 86154.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121961.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106798.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6662/10556 [00:00<00:00, 63553.67it/s]100%|| 10556/10556 [00:00<00:00, 65532.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9758/10556 [00:00<00:00, 97578.93it/s]100%|| 10556/10556 [00:00<00:00, 98680.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7120/10556 [00:00<00:00, 71195.65it/s]100%|| 10556/10556 [00:00<00:00, 67349.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122792.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6199/10556 [00:00<00:00, 61985.48it/s]100%|| 10556/10556 [00:00<00:00, 69956.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109368.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7429/10556 [00:00<00:00, 74288.83it/s]100%|| 10556/10556 [00:00<00:00, 83940.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118302.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10155/10556 [00:00<00:00, 101543.56it/s]100%|| 10556/10556 [00:00<00:00, 102026.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123788.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7130/10556 [00:00<00:00, 69161.08it/s]100%|| 10556/10556 [00:00<00:00, 67263.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7049/10556 [00:00<00:00, 69525.66it/s]100%|| 10556/10556 [00:00<00:00, 67008.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122501.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 7972/10556 [00:00<00:00, 79717.04it/s]100%|| 10556/10556 [00:00<00:00, 79774.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8847/10556 [00:00<00:00, 88468.82it/s]100%|| 10556/10556 [00:00<00:00, 92668.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7662/10556 [00:00<00:00, 76616.24it/s]100%|| 10556/10556 [00:00<00:00, 84834.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7297/10556 [00:00<00:00, 72967.63it/s]100%|| 10556/10556 [00:00<00:00, 64580.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7179/10556 [00:00<00:00, 71786.47it/s]100%|| 10556/10556 [00:00<00:00, 65438.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6750/10556 [00:00<00:00, 67496.36it/s]100%|| 10556/10556 [00:00<00:00, 66188.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5875/10556 [00:00<00:00, 57454.08it/s]100%|| 10556/10556 [00:00<00:00, 61387.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8476/10556 [00:00<00:00, 84759.27it/s]100%|| 10556/10556 [00:00<00:00, 89061.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9095/10556 [00:00<00:00, 90944.88it/s]100%|| 10556/10556 [00:00<00:00, 93449.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8031/10556 [00:00<00:00, 80305.48it/s]100%|| 10556/10556 [00:00<00:00, 86223.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8218/10556 [00:00<00:00, 82176.94it/s]100%|| 10556/10556 [00:00<00:00, 87407.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5765/10556 [00:00<00:00, 57184.46it/s]100%|| 10556/10556 [00:00<00:00, 59513.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5667/10556 [00:00<00:00, 56369.41it/s]100%|| 10556/10556 [00:00<00:00, 59048.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108766.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123888.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123620.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8791/10556 [00:00<00:00, 87909.46it/s]100%|| 10556/10556 [00:00<00:00, 92462.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9730/10556 [00:00<00:00, 97293.37it/s]100%|| 10556/10556 [00:00<00:00, 98863.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117478.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122187.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6875/10556 [00:00<00:00, 68749.57it/s]100%|| 10556/10556 [00:00<00:00, 77826.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7611/10556 [00:00<00:00, 76104.63it/s]100%|| 10556/10556 [00:00<00:00, 85320.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6822/10556 [00:00<00:00, 66710.98it/s]100%|| 10556/10556 [00:00<00:00, 62304.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4609/10556 [00:00<00:00, 46086.97it/s]100%|| 10556/10556 [00:00<00:00, 60783.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6825/10556 [00:00<00:00, 68246.49it/s]100%|| 10556/10556 [00:00<00:00, 64439.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122964.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6917/10556 [00:00<00:00, 69166.11it/s]100%|| 10556/10556 [00:00<00:00, 77841.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5886/10556 [00:00<00:00, 53086.63it/s]100%|| 10556/10556 [00:00<00:00, 69205.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7124/10556 [00:00<00:00, 71237.52it/s]100%|| 10556/10556 [00:00<00:00, 69879.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6721/10556 [00:00<00:00, 65980.22it/s]100%|| 10556/10556 [00:00<00:00, 64671.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7553/10556 [00:00<00:00, 75529.35it/s]100%|| 10556/10556 [00:00<00:00, 84715.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123874.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123490.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7809/10556 [00:00<00:00, 78087.10it/s]100%|| 10556/10556 [00:00<00:00, 86889.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110246.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7225/10556 [00:00<00:00, 72245.76it/s]100%|| 10556/10556 [00:00<00:00, 82306.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109551.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8275/10556 [00:00<00:00, 82745.94it/s]100%|| 10556/10556 [00:00<00:00, 83478.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109300.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123101.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122428.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115226.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6585/10556 [00:00<00:00, 59876.67it/s]100%|| 10556/10556 [00:00<00:00, 57659.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4875/10556 [00:00<00:00, 48749.70it/s]100%|| 10556/10556 [00:00<00:00, 71674.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4592/10556 [00:00<00:00, 44843.20it/s] 74%|  | 7848/10556 [00:00<00:00, 39788.36it/s]100%|| 10556/10556 [00:00<00:00, 42844.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121373.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114856.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124251.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123553.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119820.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125982.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112770.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7466/10556 [00:00<00:00, 74654.20it/s]100%|| 10556/10556 [00:00<00:00, 67343.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7234/10556 [00:00<00:00, 70622.29it/s]100%|| 10556/10556 [00:00<00:00, 70138.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|  | 7529/10556 [00:00<00:00, 69954.16it/s]100%|| 10556/10556 [00:00<00:00, 71590.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122231.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112280.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109547.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9812/10556 [00:00<00:00, 98118.22it/s]100%|| 10556/10556 [00:00<00:00, 99014.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124392.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106552.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116778.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114760.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125904.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122328.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125702.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128739.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6443/10556 [00:00<00:00, 64427.30it/s]100%|| 10556/10556 [00:00<00:00, 76698.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6453/10556 [00:00<00:00, 57617.79it/s]100%|| 10556/10556 [00:00<00:00, 69649.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7181/10556 [00:00<00:00, 68320.19it/s]100%|| 10556/10556 [00:00<00:00, 66541.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6585/10556 [00:00<00:00, 65846.92it/s]100%|| 10556/10556 [00:00<00:00, 64108.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6426/10556 [00:00<00:00, 64259.14it/s]100%|| 10556/10556 [00:00<00:00, 76591.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119928.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8204/10556 [00:00<00:00, 82036.75it/s]100%|| 10556/10556 [00:00<00:00, 86455.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|  | 7545/10556 [00:00<00:00, 75446.47it/s]100%|| 10556/10556 [00:00<00:00, 69263.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4341/10556 [00:00<00:00, 38610.90it/s]100%|| 10556/10556 [00:00<00:00, 50739.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7731/10556 [00:00<00:00, 75759.06it/s]100%|| 10556/10556 [00:00<00:00, 71281.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6817/10556 [00:00<00:00, 64455.02it/s]100%|| 10556/10556 [00:00<00:00, 63423.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6496/10556 [00:00<00:00, 63757.96it/s]100%|| 10556/10556 [00:00<00:00, 63092.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5923/10556 [00:00<00:00, 59227.80it/s]100%|| 10556/10556 [00:00<00:00, 60737.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8396/10556 [00:00<00:00, 83347.44it/s]100%|| 10556/10556 [00:00<00:00, 86165.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122295.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116551.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9347/10556 [00:00<00:00, 93462.51it/s]100%|| 10556/10556 [00:00<00:00, 96026.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9699/10556 [00:00<00:00, 96986.16it/s]100%|| 10556/10556 [00:00<00:00, 90786.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5382/10556 [00:00<00:00, 50097.41it/s]100%|| 10556/10556 [00:00<00:00, 51512.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10126/10556 [00:00<00:00, 101252.37it/s]100%|| 10556/10556 [00:00<00:00, 101942.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10518/10556 [00:00<00:00, 105177.34it/s]100%|| 10556/10556 [00:00<00:00, 104792.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110995.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9433/10556 [00:00<00:00, 94326.94it/s]100%|| 10556/10556 [00:00<00:00, 93195.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6265/10556 [00:00<00:00, 62645.13it/s]100%|| 10556/10556 [00:00<00:00, 61731.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107252.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7496/10556 [00:00<00:00, 69344.46it/s]100%|| 10556/10556 [00:00<00:00, 79108.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112007.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9678/10556 [00:00<00:00, 96775.48it/s]100%|| 10556/10556 [00:00<00:00, 98621.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7002/10556 [00:00<00:00, 63957.92it/s]100%|| 10556/10556 [00:00<00:00, 75732.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115750.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9388/10556 [00:00<00:00, 93874.94it/s]100%|| 10556/10556 [00:00<00:00, 96275.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106522.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7955/10556 [00:00<00:00, 79546.28it/s]100%|| 10556/10556 [00:00<00:00, 87153.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7175/10556 [00:00<00:00, 71745.79it/s]100%|| 10556/10556 [00:00<00:00, 64757.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5810/10556 [00:00<00:00, 54968.24it/s]100%|| 10556/10556 [00:00<00:00, 53144.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108372.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6979/10556 [00:00<00:00, 68294.50it/s]100%|| 10556/10556 [00:00<00:00, 73411.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9412/10556 [00:00<00:00, 94118.97it/s]100%|| 10556/10556 [00:00<00:00, 96552.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122401.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6229/10556 [00:00<00:00, 62289.91it/s]100%|| 10556/10556 [00:00<00:00, 77965.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117235.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6943/10556 [00:00<00:00, 69426.09it/s]100%|| 10556/10556 [00:00<00:00, 69138.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9385/10556 [00:00<00:00, 93842.48it/s]100%|| 10556/10556 [00:00<00:00, 92173.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8985/10556 [00:00<00:00, 86963.94it/s]100%|| 10556/10556 [00:00<00:00, 81945.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6596/10556 [00:00<00:00, 63595.49it/s]100%|| 10556/10556 [00:00<00:00, 62778.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10350/10556 [00:00<00:00, 103495.66it/s]100%|| 10556/10556 [00:00<00:00, 103577.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7776/10556 [00:00<00:00, 69626.89it/s]100%|| 10556/10556 [00:00<00:00, 67302.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123582.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9199/10556 [00:00<00:00, 91986.36it/s]100%|| 10556/10556 [00:00<00:00, 95049.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8430/10556 [00:00<00:00, 84298.87it/s]100%|| 10556/10556 [00:00<00:00, 85368.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 31%|      | 3320/10556 [00:00<00:00, 33198.29it/s]100%|| 10556/10556 [00:00<00:00, 52899.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105784.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7613/10556 [00:00<00:00, 76127.35it/s]100%|| 10556/10556 [00:00<00:00, 82069.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9587/10556 [00:00<00:00, 90608.32it/s]100%|| 10556/10556 [00:00<00:00, 92648.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7168/10556 [00:00<00:00, 71676.82it/s]100%|| 10556/10556 [00:00<00:00, 73550.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3958/10556 [00:00<00:00, 38351.13it/s] 71%|   | 7504/10556 [00:00<00:00, 36512.02it/s]100%|| 10556/10556 [00:00<00:00, 38917.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8518/10556 [00:00<00:00, 85175.82it/s]100%|| 10556/10556 [00:00<00:00, 90258.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118651.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7342/10556 [00:00<00:00, 73417.44it/s]100%|| 10556/10556 [00:00<00:00, 65567.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5743/10556 [00:00<00:00, 55996.73it/s]100%|| 10556/10556 [00:00<00:00, 68281.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10488/10556 [00:00<00:00, 104874.60it/s]100%|| 10556/10556 [00:00<00:00, 104579.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119098.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5654/10556 [00:00<00:00, 51450.90it/s]100%|| 10556/10556 [00:00<00:00, 54950.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8820/10556 [00:00<00:00, 88193.57it/s]100%|| 10556/10556 [00:00<00:00, 92029.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9366/10556 [00:00<00:00, 93656.07it/s]100%|| 10556/10556 [00:00<00:00, 95767.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126556.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114279.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116700.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9726/10556 [00:00<00:00, 97258.47it/s]100%|| 10556/10556 [00:00<00:00, 98824.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6993/10556 [00:00<00:00, 69926.23it/s]100%|| 10556/10556 [00:00<00:00, 65330.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120863.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5327/10556 [00:00<00:00, 48542.11it/s] 82%| | 8677/10556 [00:00<00:00, 42596.13it/s]100%|| 10556/10556 [00:00<00:00, 42716.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6262/10556 [00:00<00:00, 62618.57it/s]100%|| 10556/10556 [00:00<00:00, 67091.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3371/10556 [00:00<00:00, 33709.63it/s]100%|| 10556/10556 [00:00<00:00, 66490.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118861.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 214658.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197116.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 201137.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194564.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147170.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194994.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181471.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190823.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188406.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111367.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198099.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186215.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197333.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193934.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198572.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196866.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171787.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5599/10556 [00:00<00:00, 55989.79it/s]100%|| 10556/10556 [00:00<00:00, 84955.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192943.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186157.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190324.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191952.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192497.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192790.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177670.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152492.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164428.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188577.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185818.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193410.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188591.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189418.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186360.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198469.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198167.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194243.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190569.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189326.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191011.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 191069.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 184496.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 187211.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196086.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194471.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 193781.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194038.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190606.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178585.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189025.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178350.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190935.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179854.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 195803.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196938.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 199421.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197827.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132108.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147560.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156759.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153367.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150813.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145193.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153725.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148195.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154826.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153447.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131670.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150767.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 157121.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149272.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 145063.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149585.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153046.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151930.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 150617.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142803.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152308.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151900.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 151913.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 142991.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148849.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153468.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149980.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153324.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154555.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154316.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154072.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 146243.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152977.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149993.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 147462.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141385.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127377.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128625.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 138059.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181157.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183704.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190887.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198128.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189053.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 163479.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171638.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 166797.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171696.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136954.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139752.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110056.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 132408.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136215.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110554.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 149394.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154608.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148408.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135939.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109700.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10497/10556 [00:00<00:00, 104963.59it/s]100%|| 10556/10556 [00:00<00:00, 104696.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115014.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127667.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113537.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7519/10556 [00:00<00:00, 75185.23it/s]100%|| 10556/10556 [00:00<00:00, 66591.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6977/10556 [00:00<00:00, 69767.24it/s]100%|| 10556/10556 [00:00<00:00, 79741.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7182/10556 [00:00<00:00, 71817.33it/s]100%|| 10556/10556 [00:00<00:00, 77299.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116295.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7038/10556 [00:00<00:00, 70378.22it/s]100%|| 10556/10556 [00:00<00:00, 74968.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8341/10556 [00:00<00:00, 78270.25it/s]100%|| 10556/10556 [00:00<00:00, 78355.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6656/10556 [00:00<00:00, 66558.64it/s]100%|| 10556/10556 [00:00<00:00, 64792.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4965/10556 [00:00<00:00, 45360.96it/s]100%|| 10556/10556 [00:00<00:00, 58195.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7019/10556 [00:00<00:00, 66588.30it/s]100%|| 10556/10556 [00:00<00:00, 65616.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6906/10556 [00:00<00:00, 63870.96it/s]100%|| 10556/10556 [00:00<00:00, 74312.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6950/10556 [00:00<00:00, 64501.34it/s]100%|| 10556/10556 [00:00<00:00, 56214.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10389/10556 [00:00<00:00, 103887.37it/s]100%|| 10556/10556 [00:00<00:00, 103940.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7022/10556 [00:00<00:00, 67670.58it/s]100%|| 10556/10556 [00:00<00:00, 69881.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6822/10556 [00:00<00:00, 65751.65it/s]100%|| 10556/10556 [00:00<00:00, 67675.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6402/10556 [00:00<00:00, 64017.62it/s]100%|| 10556/10556 [00:00<00:00, 78674.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10434/10556 [00:00<00:00, 104334.13it/s]100%|| 10556/10556 [00:00<00:00, 104335.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106275.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7257/10556 [00:00<00:00, 70668.69it/s]100%|| 10556/10556 [00:00<00:00, 81417.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9042/10556 [00:00<00:00, 90416.42it/s]100%|| 10556/10556 [00:00<00:00, 93821.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115969.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117443.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6806/10556 [00:00<00:00, 66075.73it/s]100%|| 10556/10556 [00:00<00:00, 67919.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9755/10556 [00:00<00:00, 97548.93it/s]100%|| 10556/10556 [00:00<00:00, 99027.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117015.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8513/10556 [00:00<00:00, 85129.88it/s]100%|| 10556/10556 [00:00<00:00, 82098.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6512/10556 [00:00<00:00, 65115.09it/s]100%|| 10556/10556 [00:00<00:00, 65129.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6690/10556 [00:00<00:00, 66895.12it/s]100%|| 10556/10556 [00:00<00:00, 75718.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119908.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123594.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10368/10556 [00:00<00:00, 103677.63it/s]100%|| 10556/10556 [00:00<00:00, 97876.83it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107994.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115055.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111376.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122356.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6923/10556 [00:00<00:00, 69227.10it/s]100%|| 10556/10556 [00:00<00:00, 78994.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119541.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7460/10556 [00:00<00:00, 71952.07it/s]100%|| 10556/10556 [00:00<00:00, 81698.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106922.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9449/10556 [00:00<00:00, 94487.39it/s]100%|| 10556/10556 [00:00<00:00, 96639.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121186.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116675.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10052/10556 [00:00<00:00, 100517.70it/s]100%|| 10556/10556 [00:00<00:00, 101405.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119106.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121339.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124777.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10466/10556 [00:00<00:00, 104655.61it/s]100%|| 10556/10556 [00:00<00:00, 104480.25it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.70804'}; time used = 0.7738723754882812s
epoch 10: {'train_loss': '1.68172'}; time used = 0.6615579128265381s
epoch 15: {'train_loss': '1.64542'}; time used = 0.5391159057617188s
epoch 20: {'train_loss': '1.61318'}; time used = 0.8677542209625244s
epoch 25: {'train_loss': '1.59124'}; time used = 0.45531702041625977s
epoch 30: {'train_loss': '1.56626'}; time used = 0.6679134368896484s
epoch 35: {'train_loss': '1.53799'}; time used = 0.6341350078582764s
epoch 40: {'train_loss': '1.51915'}; time used = 0.7431042194366455s
epoch 45: {'train_loss': '1.50112'}; time used = 0.5258867740631104s
epoch 50: {'train_loss': '1.49273'}; time used = 0.9504079818725586s
epoch 55: {'train_loss': '1.47523'}; time used = 1.0653924942016602s
epoch 60: {'train_loss': '1.46341'}; time used = 0.5992746353149414s
epoch 65: {'train_loss': '1.44856'}; time used = 0.6029837131500244s
epoch 70: {'train_loss': '1.43533'}; time used = 0.8266878128051758s
epoch 75: {'train_loss': '1.43405'}; time used = 0.74560546875s
epoch 80: {'train_loss': '1.41818'}; time used = 0.9306252002716064s
epoch 85: {'train_loss': '1.41372'}; time used = 0.9159717559814453s
epoch 90: {'train_loss': '1.39902'}; time used = 0.7208786010742188s
epoch 95: {'train_loss': '1.39553'}; time used = 0.6760492324829102s
epoch 100: {'train_loss': '1.38879'}; time used = 0.5492091178894043s
epoch 105: {'train_loss': '1.38387'}; time used = 0.6272540092468262s
epoch 110: {'train_loss': '1.38179'}; time used = 0.5503778457641602s
epoch 115: {'train_loss': '1.37246'}; time used = 0.8684418201446533s
epoch 120: {'train_loss': '1.36661'}; time used = 0.6901845932006836s
epoch 125: {'train_loss': '1.36115'}; time used = 0.5439352989196777s
epoch 130: {'train_loss': '1.35610'}; time used = 0.7298583984375s
epoch 135: {'train_loss': '1.35292'}; time used = 0.89312744140625s
epoch 140: {'train_loss': '1.35402'}; time used = 0.5055599212646484s
epoch 145: {'train_loss': '1.34713'}; time used = 0.7189030647277832s
epoch 150: {'train_loss': '1.34496'}; time used = 0.7807984352111816s
epoch 155: {'train_loss': '1.34212'}; time used = 0.7958023548126221s
epoch 160: {'train_loss': '1.33694'}; time used = 0.643700361251831s
epoch 165: {'train_loss': '1.33341'}; time used = 0.854515552520752s
epoch 170: {'train_loss': '1.33341'}; time used = 0.9429111480712891s
epoch 175: {'train_loss': '1.32504'}; time used = 0.772533655166626s
epoch 180: {'train_loss': '1.32266'}; time used = 0.6352152824401855s
epoch 185: {'train_loss': '1.32160'}; time used = 0.7228522300720215s
epoch 190: {'train_loss': '1.32042'}; time used = 0.5552775859832764s
epoch 195: {'train_loss': '1.31643'}; time used = 0.7141604423522949s
epoch 200: {'train_loss': '1.31154'}; time used = 0.8660092353820801s
epoch 205: {'train_loss': '1.30940'}; time used = 0.7008874416351318s
epoch 210: {'train_loss': '1.30846'}; time used = 0.625225305557251s
epoch 215: {'train_loss': '1.30819'}; time used = 0.6159818172454834s
epoch 220: {'train_loss': '1.30507'}; time used = 0.7829220294952393s
epoch 225: {'train_loss': '1.30175'}; time used = 0.7298014163970947s
epoch 230: {'train_loss': '1.29637'}; time used = 0.5836246013641357s
epoch 235: {'train_loss': '1.29968'}; time used = 0.5342099666595459s
epoch 240: {'train_loss': '1.29011'}; time used = 0.8508086204528809s
epoch 245: {'train_loss': '1.28606'}; time used = 0.4839355945587158s
epoch 250: {'train_loss': '1.28795'}; time used = 0.7182016372680664s
epoch 255: {'train_loss': '1.28520'}; time used = 0.5397200584411621s
epoch 260: {'train_loss': '1.28231'}; time used = 0.4766049385070801s
epoch 265: {'train_loss': '1.28171'}; time used = 0.8367810249328613s
epoch 270: {'train_loss': '1.28058'}; time used = 0.781376838684082s
epoch 275: {'train_loss': '1.27309'}; time used = 0.7744629383087158s
epoch 280: {'train_loss': '1.27555'}; time used = 0.6844508647918701s
epoch 285: {'train_loss': '1.27254'}; time used = 0.6414387226104736s
epoch 290: {'train_loss': '1.27710'}; time used = 0.6343278884887695s
epoch 295: {'train_loss': '1.27676'}; time used = 0.7407376766204834s
epoch 300: {'train_loss': '1.26715'}; time used = 0.6354212760925293s
epoch 305: {'train_loss': '1.26774'}; time used = 0.7335245609283447s
epoch 310: {'train_loss': '1.26395'}; time used = 0.639350414276123s
epoch 315: {'train_loss': '1.26623'}; time used = 0.7612700462341309s
epoch 320: {'train_loss': '1.26731'}; time used = 0.8668301105499268s
epoch 325: {'train_loss': '1.26083'}; time used = 0.668708086013794s
epoch 330: {'train_loss': '1.26405'}; time used = 0.6270744800567627s
epoch 335: {'train_loss': '1.26201'}; time used = 0.8546772003173828s
epoch 340: {'train_loss': '1.25891'}; time used = 0.3056802749633789s
epoch 345: {'train_loss': '1.26120'}; time used = 0.3537566661834717s
epoch 350: {'train_loss': '1.25716'}; time used = 0.3353462219238281s
epoch 355: {'train_loss': '1.25988'}; time used = 0.38942766189575195s
epoch 360: {'train_loss': '1.26054'}; time used = 0.3094620704650879s
epoch 365: {'train_loss': '1.25629'}; time used = 0.3401618003845215s
epoch 370: {'train_loss': '1.25797'}; time used = 0.30159640312194824s
epoch 375: {'train_loss': '1.25661'}; time used = 0.3059213161468506s
epoch 380: {'train_loss': '1.25752'}; time used = 0.30687689781188965s
epoch 385: {'train_loss': '1.24490'}; time used = 0.3163766860961914s
epoch 390: {'train_loss': '1.25154'}; time used = 0.3042726516723633s
epoch 395: {'train_loss': '1.25145'}; time used = 0.3730001449584961s
epoch 400: {'train_loss': '1.25141'}; time used = 0.37924885749816895s
epoch 405: {'train_loss': '1.24782'}; time used = 0.3859260082244873s
epoch 410: {'train_loss': '1.24480'}; time used = 0.38273143768310547s
epoch 415: {'train_loss': '1.25066'}; time used = 0.38783788681030273s
epoch 420: {'train_loss': '1.25569'}; time used = 0.3770883083343506s
epoch 425: {'train_loss': '1.25408'}; time used = 0.39078474044799805s
epoch 430: {'train_loss': '1.25196'}; time used = 0.4487583637237549s
epoch 435: {'train_loss': '1.24818'}; time used = 0.3329353332519531s
epoch 440: {'train_loss': '1.24896'}; time used = 0.3999760150909424s
epoch 445: {'train_loss': '1.24801'}; time used = 0.4891626834869385s
epoch 450: {'train_loss': '1.25184'}; time used = 0.44977664947509766s
epoch 455: {'train_loss': '1.24996'}; time used = 0.5717446804046631s
epoch 460: {'train_loss': '1.24653'}; time used = 0.6774780750274658s
epoch 465: {'train_loss': '1.24657'}; time used = 0.8998401165008545s
epoch 470: {'train_loss': '1.24814'}; time used = 0.7077937126159668s
epoch 475: {'train_loss': '1.24705'}; time used = 0.6103677749633789s
epoch 480: {'train_loss': '1.25017'}; time used = 0.7179410457611084s
epoch 485: {'train_loss': '1.24693'}; time used = 0.5675041675567627s
epoch 490: {'train_loss': '1.24831'}; time used = 0.5529334545135498s
epoch 495: {'train_loss': '1.24514'}; time used = 0.5734198093414307s
epoch 500: {'train_loss': '1.24479'}; time used = 0.5254502296447754s
Finished training. Time used = 67.45935606956482.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}

  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6890/10556 [00:00<00:00, 68899.90it/s]100%|| 10556/10556 [00:00<00:00, 77279.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8553/10556 [00:00<00:00, 85525.19it/s]100%|| 10556/10556 [00:00<00:00, 91588.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108294.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122333.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122258.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7118/10556 [00:00<00:00, 71179.56it/s]100%|| 10556/10556 [00:00<00:00, 82546.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119034.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139679.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107754.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8681/10556 [00:00<00:00, 86382.94it/s]100%|| 10556/10556 [00:00<00:00, 86961.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8529/10556 [00:00<00:00, 85289.06it/s]100%|| 10556/10556 [00:00<00:00, 90612.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9114/10556 [00:00<00:00, 91139.22it/s]100%|| 10556/10556 [00:00<00:00, 91546.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6958/10556 [00:00<00:00, 68966.42it/s]100%|| 10556/10556 [00:00<00:00, 63153.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114760.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9632/10556 [00:00<00:00, 96316.42it/s]100%|| 10556/10556 [00:00<00:00, 87921.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124007.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121331.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108479.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6430/10556 [00:00<00:00, 64297.61it/s]100%|| 10556/10556 [00:00<00:00, 61305.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10404/10556 [00:00<00:00, 104038.61it/s]100%|| 10556/10556 [00:00<00:00, 103868.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110357.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7013/10556 [00:00<00:00, 70125.72it/s]100%|| 10556/10556 [00:00<00:00, 67977.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124392.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122797.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123493.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125128.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123987.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113892.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122143.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123610.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6600/10556 [00:00<00:00, 65237.77it/s]100%|| 10556/10556 [00:00<00:00, 79353.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125953.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6124/10556 [00:00<00:00, 58425.42it/s]100%|| 10556/10556 [00:00<00:00, 60239.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8628/10556 [00:00<00:00, 86279.88it/s]100%|| 10556/10556 [00:00<00:00, 87906.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7785/10556 [00:00<00:00, 77843.21it/s]100%|| 10556/10556 [00:00<00:00, 80330.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 9997/10556 [00:00<00:00, 99961.99it/s]100%|| 10556/10556 [00:00<00:00, 97080.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7001/10556 [00:00<00:00, 70007.23it/s]100%|| 10556/10556 [00:00<00:00, 73064.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 34%|      | 3625/10556 [00:00<00:00, 34553.30it/s] 62%|   | 6540/10556 [00:00<00:00, 32070.93it/s]100%|| 10556/10556 [00:00<00:00, 35095.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8260/10556 [00:00<00:00, 82581.57it/s]100%|| 10556/10556 [00:00<00:00, 78910.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8124/10556 [00:00<00:00, 81234.27it/s]100%|| 10556/10556 [00:00<00:00, 79867.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6902/10556 [00:00<00:00, 69018.58it/s]100%|| 10556/10556 [00:00<00:00, 69254.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7551/10556 [00:00<00:00, 75503.23it/s]100%|| 10556/10556 [00:00<00:00, 81120.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9822/10556 [00:00<00:00, 98217.99it/s]100%|| 10556/10556 [00:00<00:00, 95306.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9198/10556 [00:00<00:00, 91976.80it/s]100%|| 10556/10556 [00:00<00:00, 95173.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118142.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|  | 7545/10556 [00:00<00:00, 75447.55it/s]100%|| 10556/10556 [00:00<00:00, 83897.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118897.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107515.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114531.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 164620.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 178132.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189987.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 202697.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186385.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190642.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 190821.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181505.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 131063.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148973.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 206992.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 205622.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 211735.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 210745.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 218562.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 222545.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 181280.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127587.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198985.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 224432.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 236378.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 210794.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 232915.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 244024.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 208185.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 215537.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 216717.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 205738.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 208042.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 214395.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 219197.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 218470.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 218412.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 218948.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 209860.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 192032.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 201255.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 214587.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 218234.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197427.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 140343.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 183379.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 152626.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109090.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 161674.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 188811.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 205861.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 220543.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 217879.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 222136.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141276.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155877.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154239.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9614/10556 [00:00<00:00, 96134.59it/s]100%|| 10556/10556 [00:00<00:00, 92882.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 135044.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128456.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154602.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 153118.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 154227.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155808.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 155670.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 156769.21it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.40130'}; time used = 0.5936083793640137s
epoch 10: {'train_loss': '1.34031'}; time used = 0.5504672527313232s
epoch 15: {'train_loss': '1.31336'}; time used = 0.6590557098388672s
epoch 20: {'train_loss': '1.27880'}; time used = 0.6254904270172119s
epoch 25: {'train_loss': '1.25946'}; time used = 0.5375800132751465s
epoch 30: {'train_loss': '1.25286'}; time used = 0.510725736618042s
epoch 35: {'train_loss': '1.24936'}; time used = 0.6955792903900146s
epoch 40: {'train_loss': '1.24251'}; time used = 0.9397406578063965s
epoch 45: {'train_loss': '1.24409'}; time used = 0.6327085494995117s
epoch 50: {'train_loss': '1.23584'}; time used = 0.43054938316345215s
epoch 55: {'train_loss': '1.23682'}; time used = 0.31456613540649414s
epoch 60: {'train_loss': '1.23217'}; time used = 0.3424656391143799s
epoch 65: {'train_loss': '1.23493'}; time used = 0.28020524978637695s
epoch 70: {'train_loss': '1.23204'}; time used = 0.30931615829467773s
epoch 75: {'train_loss': '1.23262'}; time used = 0.2670478820800781s
epoch 80: {'train_loss': '1.22851'}; time used = 0.2760756015777588s
epoch 85: {'train_loss': '1.22901'}; time used = 0.2831146717071533s
epoch 90: {'train_loss': '1.22893'}; time used = 0.32196998596191406s
epoch 95: {'train_loss': '1.22523'}; time used = 0.3817617893218994s
epoch 100: {'train_loss': '1.23054'}; time used = 0.32090139389038086s
epoch 105: {'train_loss': '1.22526'}; time used = 0.4583699703216553s
epoch 110: {'train_loss': '1.23434'}; time used = 0.37122392654418945s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.547877311706543.
Training classifier using 20.00% nodes...
{'micro': 0.29441624365482233, 'macro': 0.06507879838833068, 'samples': 0.29441624365482233, 'weighted': 0.13433200977895854}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 265, in <module>
    main(parse_args())
  File "/home/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/home/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 35, in train
    res = model(graph, **self.train_kwargs())
  File "/home/duyufeng/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/home/duyufeng/OpenNE/src/openne/models/ss_nodemodel.py", line 93, in build
    features = torch.from_numpy(graph.features()).to(self._device)
RuntimeError: CUDA error: out of memory
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.03, 'early_stopping': 20, 'hiddens': [64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119785.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8281/10556 [00:00<00:00, 82804.16it/s]100%|| 10556/10556 [00:00<00:00, 85532.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6345/10556 [00:00<00:00, 63447.49it/s]100%|| 10556/10556 [00:00<00:00, 61846.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6362/10556 [00:00<00:00, 63617.03it/s]100%|| 10556/10556 [00:00<00:00, 78383.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9949/10556 [00:00<00:00, 98897.55it/s]100%|| 10556/10556 [00:00<00:00, 95112.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6580/10556 [00:00<00:00, 65799.75it/s]100%|| 10556/10556 [00:00<00:00, 66682.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6709/10556 [00:00<00:00, 65253.63it/s]100%|| 10556/10556 [00:00<00:00, 68962.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6414/10556 [00:00<00:00, 58577.04it/s]100%|| 10556/10556 [00:00<00:00, 67086.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4681/10556 [00:00<00:00, 45311.23it/s] 87%| | 9151/10556 [00:00<00:00, 44495.08it/s]100%|| 10556/10556 [00:00<00:00, 45456.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5248/10556 [00:00<00:00, 49535.98it/s] 90%| | 9545/10556 [00:00<00:00, 47364.25it/s]100%|| 10556/10556 [00:00<00:00, 44191.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123529.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 141718.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120784.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119192.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116492.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116038.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108342.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 30%|       | 3194/10556 [00:00<00:00, 31774.28it/s] 99%|| 10423/10556 [00:00<00:00, 38168.48it/s]100%|| 10556/10556 [00:00<00:00, 50729.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119206.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114065.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6621/10556 [00:00<00:00, 66201.54it/s]100%|| 10556/10556 [00:00<00:00, 72573.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6801/10556 [00:00<00:00, 68008.44it/s]100%|| 10556/10556 [00:00<00:00, 67171.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8652/10556 [00:00<00:00, 86518.02it/s]100%|| 10556/10556 [00:00<00:00, 90945.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4294/10556 [00:00<00:00, 42843.00it/s] 88%| | 9336/10556 [00:00<00:00, 43935.51it/s]100%|| 10556/10556 [00:00<00:00, 45292.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7799/10556 [00:00<00:00, 77985.80it/s]100%|| 10556/10556 [00:00<00:00, 85510.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8429/10556 [00:00<00:00, 84284.65it/s]100%|| 10556/10556 [00:00<00:00, 83899.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 7996/10556 [00:00<00:00, 79957.79it/s]100%|| 10556/10556 [00:00<00:00, 80824.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6701/10556 [00:00<00:00, 64721.37it/s]100%|| 10556/10556 [00:00<00:00, 63104.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3725/10556 [00:00<00:00, 37201.52it/s] 75%|  | 7946/10556 [00:00<00:00, 37268.12it/s]100%|| 10556/10556 [00:00<00:00, 40155.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118310.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122264.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121245.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120698.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108698.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112598.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108253.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111360.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4171/10556 [00:00<00:00, 39792.38it/s]100%|| 10556/10556 [00:00<00:00, 53545.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117704.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114705.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6927/10556 [00:00<00:00, 69126.19it/s]100%|| 10556/10556 [00:00<00:00, 64256.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113399.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9421/10556 [00:00<00:00, 94207.84it/s]100%|| 10556/10556 [00:00<00:00, 95956.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7000/10556 [00:00<00:00, 69994.06it/s]100%|| 10556/10556 [00:00<00:00, 55671.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120988.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106463.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6299/10556 [00:00<00:00, 58463.18it/s]100%|| 10556/10556 [00:00<00:00, 57514.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6313/10556 [00:00<00:00, 63127.05it/s]100%|| 10556/10556 [00:00<00:00, 60545.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10162/10556 [00:00<00:00, 101609.92it/s]100%|| 10556/10556 [00:00<00:00, 96258.53it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7166/10556 [00:00<00:00, 71659.04it/s]100%|| 10556/10556 [00:00<00:00, 74095.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8855/10556 [00:00<00:00, 88545.86it/s]100%|| 10556/10556 [00:00<00:00, 91963.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6294/10556 [00:00<00:00, 62938.11it/s]100%|| 10556/10556 [00:00<00:00, 66621.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5076/10556 [00:00<00:00, 50759.08it/s]100%|| 10556/10556 [00:00<00:00, 56907.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|    | 5415/10556 [00:00<00:00, 52844.41it/s]100%|| 10556/10556 [00:00<00:00, 69083.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119739.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5498/10556 [00:00<00:00, 46083.70it/s]100%|| 10556/10556 [00:00<00:00, 66231.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118962.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118978.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128750.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119704.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115825.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6978/10556 [00:00<00:00, 69774.41it/s]100%|| 10556/10556 [00:00<00:00, 78371.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7794/10556 [00:00<00:00, 77935.43it/s]100%|| 10556/10556 [00:00<00:00, 84229.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8670/10556 [00:00<00:00, 83866.15it/s]100%|| 10556/10556 [00:00<00:00, 81401.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110754.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111961.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7081/10556 [00:00<00:00, 68940.87it/s]100%|| 10556/10556 [00:00<00:00, 74883.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6703/10556 [00:00<00:00, 66877.79it/s]100%|| 10556/10556 [00:00<00:00, 80412.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117659.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6730/10556 [00:00<00:00, 67297.66it/s]100%|| 10556/10556 [00:00<00:00, 58501.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5822/10556 [00:00<00:00, 58219.78it/s]100%|| 10556/10556 [00:00<00:00, 75426.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121432.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9947/10556 [00:00<00:00, 99465.35it/s]100%|| 10556/10556 [00:00<00:00, 99823.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7329/10556 [00:00<00:00, 73284.30it/s]100%|| 10556/10556 [00:00<00:00, 73887.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7575/10556 [00:00<00:00, 75745.38it/s]100%|| 10556/10556 [00:00<00:00, 84852.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9150/10556 [00:00<00:00, 91498.12it/s]100%|| 10556/10556 [00:00<00:00, 91586.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8150/10556 [00:00<00:00, 75983.26it/s]100%|| 10556/10556 [00:00<00:00, 82026.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113428.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111604.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8337/10556 [00:00<00:00, 83367.10it/s]100%|| 10556/10556 [00:00<00:00, 89257.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9149/10556 [00:00<00:00, 91485.94it/s]100%|| 10556/10556 [00:00<00:00, 94690.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6310/10556 [00:00<00:00, 62368.32it/s]100%|| 10556/10556 [00:00<00:00, 58461.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5616/10556 [00:00<00:00, 51092.58it/s]100%|| 10556/10556 [00:00<00:00, 56965.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122795.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114050.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107246.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7316/10556 [00:00<00:00, 71502.20it/s]100%|| 10556/10556 [00:00<00:00, 75373.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112948.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120073.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4710/10556 [00:00<00:00, 43582.90it/s]100%|| 10556/10556 [00:00<00:00, 63795.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8853/10556 [00:00<00:00, 86191.13it/s]100%|| 10556/10556 [00:00<00:00, 90299.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110083.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7819/10556 [00:00<00:00, 78186.53it/s]100%|| 10556/10556 [00:00<00:00, 83209.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6533/10556 [00:00<00:00, 54317.50it/s]100%|| 10556/10556 [00:00<00:00, 62241.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9253/10556 [00:00<00:00, 92526.34it/s]100%|| 10556/10556 [00:00<00:00, 95114.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8058/10556 [00:00<00:00, 80573.74it/s]100%|| 10556/10556 [00:00<00:00, 83707.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7246/10556 [00:00<00:00, 71376.73it/s]100%|| 10556/10556 [00:00<00:00, 69494.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115462.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119106.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121685.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119325.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9631/10556 [00:00<00:00, 94133.55it/s]100%|| 10556/10556 [00:00<00:00, 76663.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4426/10556 [00:00<00:00, 44258.46it/s] 69%|   | 7300/10556 [00:00<00:00, 38087.03it/s]100%|| 10556/10556 [00:00<00:00, 38586.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5026/10556 [00:00<00:00, 44773.40it/s] 96%|| 10088/10556 [00:00<00:00, 46379.37it/s]100%|| 10556/10556 [00:00<00:00, 47029.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 32%|      | 3361/10556 [00:00<00:00, 31714.84it/s] 66%|   | 6965/10556 [00:00<00:00, 32898.87it/s]100%|| 10556/10556 [00:00<00:00, 35821.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6935/10556 [00:00<00:00, 68708.25it/s]100%|| 10556/10556 [00:00<00:00, 80572.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6324/10556 [00:00<00:00, 63237.04it/s]100%|| 10556/10556 [00:00<00:00, 60232.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6548/10556 [00:00<00:00, 65475.22it/s]100%|| 10556/10556 [00:00<00:00, 54804.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4261/10556 [00:00<00:00, 41337.48it/s] 90%| | 9481/10556 [00:00<00:00, 43891.16it/s]100%|| 10556/10556 [00:00<00:00, 47565.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6039/10556 [00:00<00:00, 54541.27it/s]100%|| 10556/10556 [00:00<00:00, 59030.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6398/10556 [00:00<00:00, 61837.29it/s] 96%|| 10136/10556 [00:00<00:00, 49376.29it/s]100%|| 10556/10556 [00:00<00:00, 47190.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6106/10556 [00:00<00:00, 55667.32it/s]100%|| 10556/10556 [00:00<00:00, 51044.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5930/10556 [00:00<00:00, 52816.13it/s]100%|| 10556/10556 [00:00<00:00, 50478.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5221/10556 [00:00<00:00, 52209.30it/s] 94%|| 9930/10556 [00:00<00:00, 50376.04it/s]100%|| 10556/10556 [00:00<00:00, 50001.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5889/10556 [00:00<00:00, 50148.83it/s] 98%|| 10345/10556 [00:00<00:00, 47883.09it/s]100%|| 10556/10556 [00:00<00:00, 46631.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5468/10556 [00:00<00:00, 54678.88it/s] 98%|| 10369/10556 [00:00<00:00, 52843.89it/s]100%|| 10556/10556 [00:00<00:00, 48342.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5316/10556 [00:00<00:00, 52975.77it/s]100%|| 10556/10556 [00:00<00:00, 49349.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4842/10556 [00:00<00:00, 42803.98it/s] 94%|| 9927/10556 [00:00<00:00, 44936.15it/s]100%|| 10556/10556 [00:00<00:00, 46373.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5111/10556 [00:00<00:00, 47664.35it/s] 98%|| 10301/10556 [00:00<00:00, 47909.21it/s]100%|| 10556/10556 [00:00<00:00, 47599.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5736/10556 [00:00<00:00, 53994.34it/s] 99%|| 10481/10556 [00:00<00:00, 51848.43it/s]100%|| 10556/10556 [00:00<00:00, 50951.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5152/10556 [00:00<00:00, 51518.82it/s] 93%|| 9805/10556 [00:00<00:00, 49912.18it/s]100%|| 10556/10556 [00:00<00:00, 48733.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5439/10556 [00:00<00:00, 48249.85it/s] 97%|| 10269/10556 [00:00<00:00, 48263.83it/s]100%|| 10556/10556 [00:00<00:00, 47647.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5227/10556 [00:00<00:00, 52268.43it/s] 92%|| 9756/10556 [00:00<00:00, 49957.91it/s]100%|| 10556/10556 [00:00<00:00, 46461.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6074/10556 [00:00<00:00, 60737.31it/s] 96%|| 10113/10556 [00:00<00:00, 51841.32it/s]100%|| 10556/10556 [00:00<00:00, 48293.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5495/10556 [00:00<00:00, 49709.48it/s] 95%|| 10027/10556 [00:00<00:00, 47186.87it/s]100%|| 10556/10556 [00:00<00:00, 46380.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5343/10556 [00:00<00:00, 53428.01it/s] 96%|| 10177/10556 [00:00<00:00, 51792.33it/s]100%|| 10556/10556 [00:00<00:00, 48761.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5443/10556 [00:00<00:00, 54427.85it/s] 92%|| 9691/10556 [00:00<00:00, 50049.93it/s]100%|| 10556/10556 [00:00<00:00, 48303.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4664/10556 [00:00<00:00, 46626.37it/s] 94%|| 9915/10556 [00:00<00:00, 44097.96it/s]100%|| 10556/10556 [00:00<00:00, 41316.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 31%|       | 3254/10556 [00:00<00:00, 30250.36it/s] 72%|  | 7559/10556 [00:00<00:00, 33212.38it/s]100%|| 10556/10556 [00:00<00:00, 38601.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5244/10556 [00:00<00:00, 49591.07it/s] 97%|| 10255/10556 [00:00<00:00, 49744.43it/s]100%|| 10556/10556 [00:00<00:00, 47483.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4991/10556 [00:00<00:00, 49482.15it/s]100%|| 10556/10556 [00:00<00:00, 61113.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5391/10556 [00:00<00:00, 51475.16it/s]100%|| 10556/10556 [00:00<00:00, 51246.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4875/10556 [00:00<00:00, 44186.35it/s] 98%|| 10351/10556 [00:00<00:00, 45852.98it/s]100%|| 10556/10556 [00:00<00:00, 46694.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5494/10556 [00:00<00:00, 50268.77it/s] 91%| | 9609/10556 [00:00<00:00, 46599.80it/s]100%|| 10556/10556 [00:00<00:00, 41589.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5561/10556 [00:00<00:00, 55609.52it/s]100%|| 10556/10556 [00:00<00:00, 49159.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5205/10556 [00:00<00:00, 52046.08it/s] 99%|| 10428/10556 [00:00<00:00, 50103.00it/s]100%|| 10556/10556 [00:00<00:00, 49164.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5598/10556 [00:00<00:00, 55976.45it/s]100%|| 10556/10556 [00:00<00:00, 49143.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5300/10556 [00:00<00:00, 51657.83it/s]100%|| 10556/10556 [00:00<00:00, 49221.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4992/10556 [00:00<00:00, 49237.19it/s] 93%|| 9801/10556 [00:00<00:00, 48679.21it/s]100%|| 10556/10556 [00:00<00:00, 48222.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4999/10556 [00:00<00:00, 49904.97it/s] 94%|| 9912/10556 [00:00<00:00, 49669.51it/s]100%|| 10556/10556 [00:00<00:00, 49015.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5315/10556 [00:00<00:00, 50625.02it/s]100%|| 10556/10556 [00:00<00:00, 49481.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6971/10556 [00:00<00:00, 68283.29it/s]100%|| 10556/10556 [00:00<00:00, 65207.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5500/10556 [00:00<00:00, 49980.66it/s]100%|| 10556/10556 [00:00<00:00, 52932.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4905/10556 [00:00<00:00, 49047.36it/s] 96%|| 10083/10556 [00:00<00:00, 48101.22it/s]100%|| 10556/10556 [00:00<00:00, 47438.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5575/10556 [00:00<00:00, 55747.53it/s]100%|| 10556/10556 [00:00<00:00, 49027.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5271/10556 [00:00<00:00, 51396.20it/s] 96%|| 10166/10556 [00:00<00:00, 50636.50it/s]100%|| 10556/10556 [00:00<00:00, 49569.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|    | 5415/10556 [00:00<00:00, 52016.34it/s]100%|| 10556/10556 [00:00<00:00, 49383.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4574/10556 [00:00<00:00, 43283.95it/s] 70%|   | 7377/10556 [00:00<00:00, 37208.44it/s] 94%|| 9965/10556 [00:00<00:00, 32822.14it/s]100%|| 10556/10556 [00:00<00:00, 31752.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4120/10556 [00:00<00:00, 40594.27it/s] 99%|| 10477/10556 [00:00<00:00, 45006.82it/s]100%|| 10556/10556 [00:00<00:00, 50595.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5888/10556 [00:00<00:00, 58593.54it/s]100%|| 10556/10556 [00:00<00:00, 60852.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5185/10556 [00:00<00:00, 51849.55it/s] 95%|| 10063/10556 [00:00<00:00, 50887.79it/s]100%|| 10556/10556 [00:00<00:00, 49109.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5692/10556 [00:00<00:00, 55854.71it/s]100%|| 10556/10556 [00:00<00:00, 56040.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6942/10556 [00:00<00:00, 69345.17it/s]100%|| 10556/10556 [00:00<00:00, 63303.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5854/10556 [00:00<00:00, 56846.70it/s]100%|| 10556/10556 [00:00<00:00, 56285.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7431/10556 [00:00<00:00, 74304.22it/s]100%|| 10556/10556 [00:00<00:00, 57234.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7293/10556 [00:00<00:00, 72927.11it/s]100%|| 10556/10556 [00:00<00:00, 51435.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 36%|      | 3797/10556 [00:00<00:00, 35302.19it/s] 69%|   | 7262/10556 [00:00<00:00, 34165.29it/s]100%|| 10556/10556 [00:00<00:00, 40017.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6693/10556 [00:00<00:00, 66927.99it/s]100%|| 10556/10556 [00:00<00:00, 52474.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 5005/10556 [00:00<00:00, 50049.69it/s] 98%|| 10310/10556 [00:00<00:00, 50912.85it/s]100%|| 10556/10556 [00:00<00:00, 48356.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6818/10556 [00:00<00:00, 68178.11it/s]100%|| 10556/10556 [00:00<00:00, 61448.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6114/10556 [00:00<00:00, 61138.75it/s] 96%|| 10109/10556 [00:00<00:00, 51684.09it/s]100%|| 10556/10556 [00:00<00:00, 48831.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7159/10556 [00:00<00:00, 69033.83it/s]100%|| 10556/10556 [00:00<00:00, 67004.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7063/10556 [00:00<00:00, 69601.22it/s]100%|| 10556/10556 [00:00<00:00, 57650.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6597/10556 [00:00<00:00, 65969.59it/s]100%|| 10556/10556 [00:00<00:00, 64195.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4436/10556 [00:00<00:00, 44195.56it/s]100%|| 10556/10556 [00:00<00:00, 54457.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5063/10556 [00:00<00:00, 49465.56it/s]100%|| 10556/10556 [00:00<00:00, 55851.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6670/10556 [00:00<00:00, 66698.00it/s]100%|| 10556/10556 [00:00<00:00, 65213.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6593/10556 [00:00<00:00, 65925.35it/s]100%|| 10556/10556 [00:00<00:00, 64681.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7648/10556 [00:00<00:00, 73064.37it/s]100%|| 10556/10556 [00:00<00:00, 67485.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6825/10556 [00:00<00:00, 68226.80it/s]100%|| 10556/10556 [00:00<00:00, 67805.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6692/10556 [00:00<00:00, 66915.28it/s]100%|| 10556/10556 [00:00<00:00, 65090.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6637/10556 [00:00<00:00, 66368.64it/s]100%|| 10556/10556 [00:00<00:00, 64236.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7071/10556 [00:00<00:00, 65815.96it/s]100%|| 10556/10556 [00:00<00:00, 64979.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6568/10556 [00:00<00:00, 65679.91it/s]100%|| 10556/10556 [00:00<00:00, 64183.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6635/10556 [00:00<00:00, 66346.11it/s]100%|| 10556/10556 [00:00<00:00, 64923.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6928/10556 [00:00<00:00, 69279.08it/s]100%|| 10556/10556 [00:00<00:00, 65133.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6535/10556 [00:00<00:00, 65345.39it/s]100%|| 10556/10556 [00:00<00:00, 64208.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6736/10556 [00:00<00:00, 67357.49it/s]100%|| 10556/10556 [00:00<00:00, 64828.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6682/10556 [00:00<00:00, 66816.24it/s]100%|| 10556/10556 [00:00<00:00, 65339.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6929/10556 [00:00<00:00, 69288.08it/s]100%|| 10556/10556 [00:00<00:00, 68560.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7165/10556 [00:00<00:00, 68507.98it/s]100%|| 10556/10556 [00:00<00:00, 66670.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6644/10556 [00:00<00:00, 66437.05it/s]100%|| 10556/10556 [00:00<00:00, 64775.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6570/10556 [00:00<00:00, 65521.98it/s]100%|| 10556/10556 [00:00<00:00, 65100.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6633/10556 [00:00<00:00, 66328.32it/s]100%|| 10556/10556 [00:00<00:00, 58559.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6834/10556 [00:00<00:00, 67309.31it/s]100%|| 10556/10556 [00:00<00:00, 66010.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6936/10556 [00:00<00:00, 65329.96it/s]100%|| 10556/10556 [00:00<00:00, 63886.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4571/10556 [00:00<00:00, 45397.89it/s] 95%|| 10026/10556 [00:00<00:00, 47803.36it/s]100%|| 10556/10556 [00:00<00:00, 50158.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4658/10556 [00:00<00:00, 46579.82it/s] 88%| | 9322/10556 [00:00<00:00, 46597.21it/s]100%|| 10556/10556 [00:00<00:00, 45389.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5934/10556 [00:00<00:00, 57369.74it/s]100%|| 10556/10556 [00:00<00:00, 60163.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6639/10556 [00:00<00:00, 65812.17it/s]100%|| 10556/10556 [00:00<00:00, 52706.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6777/10556 [00:00<00:00, 67769.42it/s]100%|| 10556/10556 [00:00<00:00, 63928.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7370/10556 [00:00<00:00, 69841.10it/s]100%|| 10556/10556 [00:00<00:00, 67981.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6606/10556 [00:00<00:00, 66057.86it/s]100%|| 10556/10556 [00:00<00:00, 65349.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6528/10556 [00:00<00:00, 65277.88it/s]100%|| 10556/10556 [00:00<00:00, 64848.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7038/10556 [00:00<00:00, 70375.70it/s]100%|| 10556/10556 [00:00<00:00, 65093.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6693/10556 [00:00<00:00, 66925.76it/s]100%|| 10556/10556 [00:00<00:00, 65152.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6649/10556 [00:00<00:00, 66484.52it/s]100%|| 10556/10556 [00:00<00:00, 65358.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6712/10556 [00:00<00:00, 67117.50it/s]100%|| 10556/10556 [00:00<00:00, 65975.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7207/10556 [00:00<00:00, 72069.38it/s]100%|| 10556/10556 [00:00<00:00, 65844.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7109/10556 [00:00<00:00, 65924.32it/s]100%|| 10556/10556 [00:00<00:00, 65453.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6064/10556 [00:00<00:00, 60636.30it/s]100%|| 10556/10556 [00:00<00:00, 54594.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5509/10556 [00:00<00:00, 54029.89it/s]100%|| 10556/10556 [00:00<00:00, 58080.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4761/10556 [00:00<00:00, 45929.80it/s] 89%| | 9410/10556 [00:00<00:00, 45696.40it/s]100%|| 10556/10556 [00:00<00:00, 45275.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4709/10556 [00:00<00:00, 47089.37it/s] 98%|| 10397/10556 [00:00<00:00, 49653.15it/s]100%|| 10556/10556 [00:00<00:00, 50678.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6567/10556 [00:00<00:00, 65667.56it/s]100%|| 10556/10556 [00:00<00:00, 65091.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|  | 7527/10556 [00:00<00:00, 71047.98it/s]100%|| 10556/10556 [00:00<00:00, 68995.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7738/10556 [00:00<00:00, 77378.23it/s]100%|| 10556/10556 [00:00<00:00, 68502.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6545/10556 [00:00<00:00, 65448.81it/s]100%|| 10556/10556 [00:00<00:00, 63556.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6452/10556 [00:00<00:00, 61217.83it/s]100%|| 10556/10556 [00:00<00:00, 52979.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6903/10556 [00:00<00:00, 68268.81it/s]100%|| 10556/10556 [00:00<00:00, 67274.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|    | 5426/10556 [00:00<00:00, 54256.95it/s] 74%|  | 7826/10556 [00:00<00:00, 38979.39it/s]100%|| 10556/10556 [00:00<00:00, 42474.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5939/10556 [00:00<00:00, 52991.03it/s]100%|| 10556/10556 [00:00<00:00, 56698.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4196/10556 [00:00<00:00, 41959.04it/s] 83%| | 8768/10556 [00:00<00:00, 41614.22it/s]100%|| 10556/10556 [00:00<00:00, 41131.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4543/10556 [00:00<00:00, 45427.12it/s]100%|| 10556/10556 [00:00<00:00, 53750.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5548/10556 [00:00<00:00, 53530.31it/s] 68%|   | 7154/10556 [00:00<00:00, 28469.66it/s]100%|| 10556/10556 [00:00<00:00, 32903.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4804/10556 [00:00<00:00, 48036.27it/s] 90%| | 9501/10556 [00:00<00:00, 47491.08it/s]100%|| 10556/10556 [00:00<00:00, 50016.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 49%|     | 5178/10556 [00:00<00:00, 51756.97it/s] 97%|| 10275/10556 [00:00<00:00, 51517.05it/s]100%|| 10556/10556 [00:00<00:00, 51733.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125200.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4154/10556 [00:00<00:00, 41539.05it/s]100%|| 10556/10556 [00:00<00:00, 53170.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6583/10556 [00:00<00:00, 65825.83it/s]100%|| 10556/10556 [00:00<00:00, 64634.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6414/10556 [00:00<00:00, 64138.84it/s]100%|| 10556/10556 [00:00<00:00, 62561.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5360/10556 [00:00<00:00, 53598.90it/s]100%|| 10556/10556 [00:00<00:00, 55609.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6229/10556 [00:00<00:00, 62286.79it/s]100%|| 10556/10556 [00:00<00:00, 59118.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 29%|       | 3114/10556 [00:00<00:00, 26226.14it/s] 66%|   | 7019/10556 [00:00<00:00, 28069.62it/s]100%|| 10556/10556 [00:00<00:00, 32173.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4319/10556 [00:00<00:00, 41357.77it/s] 71%|   | 7479/10556 [00:00<00:00, 35452.87it/s]100%|| 10556/10556 [00:00<00:00, 33151.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 42%|     | 4391/10556 [00:00<00:00, 38769.68it/s]100%|| 10556/10556 [00:00<00:00, 50184.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4620/10556 [00:00<00:00, 46197.29it/s]100%|| 10556/10556 [00:00<00:00, 53966.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3956/10556 [00:00<00:00, 37028.94it/s] 77%|  | 8077/10556 [00:00<00:00, 38190.58it/s]100%|| 10556/10556 [00:00<00:00, 38793.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4876/10556 [00:00<00:00, 43691.13it/s]100%|| 10556/10556 [00:00<00:00, 59084.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9701/10556 [00:00<00:00, 95949.78it/s]100%|| 10556/10556 [00:00<00:00, 91721.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 5976/10556 [00:00<00:00, 57599.74it/s]100%|| 10556/10556 [00:00<00:00, 60341.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9429/10556 [00:00<00:00, 94289.87it/s]100%|| 10556/10556 [00:00<00:00, 97094.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4736/10556 [00:00<00:00, 47356.55it/s] 87%| | 9233/10556 [00:00<00:00, 46613.83it/s]100%|| 10556/10556 [00:00<00:00, 43573.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 35%|      | 3699/10556 [00:00<00:00, 36987.83it/s] 82%| | 8649/10556 [00:00<00:00, 40022.17it/s]100%|| 10556/10556 [00:00<00:00, 39462.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7379/10556 [00:00<00:00, 73778.64it/s]100%|| 10556/10556 [00:00<00:00, 55969.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6762/10556 [00:00<00:00, 67617.00it/s]100%|| 10556/10556 [00:00<00:00, 52707.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5500/10556 [00:00<00:00, 43977.77it/s] 90%| | 9553/10556 [00:00<00:00, 42882.19it/s]100%|| 10556/10556 [00:00<00:00, 44189.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5925/10556 [00:00<00:00, 59246.10it/s] 97%|| 10285/10556 [00:00<00:00, 52108.65it/s]100%|| 10556/10556 [00:00<00:00, 49294.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5393/10556 [00:00<00:00, 53929.67it/s]100%|| 10556/10556 [00:00<00:00, 56641.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7184/10556 [00:00<00:00, 66535.09it/s]100%|| 10556/10556 [00:00<00:00, 65705.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6682/10556 [00:00<00:00, 66817.20it/s]100%|| 10556/10556 [00:00<00:00, 65438.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6732/10556 [00:00<00:00, 67319.42it/s]100%|| 10556/10556 [00:00<00:00, 66162.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6675/10556 [00:00<00:00, 66747.52it/s]100%|| 10556/10556 [00:00<00:00, 59368.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5873/10556 [00:00<00:00, 58728.94it/s] 99%|| 10410/10556 [00:00<00:00, 53962.15it/s]100%|| 10556/10556 [00:00<00:00, 51463.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7026/10556 [00:00<00:00, 65344.90it/s]100%|| 10556/10556 [00:00<00:00, 63167.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5343/10556 [00:00<00:00, 52472.99it/s] 91%| | 9630/10556 [00:00<00:00, 49167.90it/s]100%|| 10556/10556 [00:00<00:00, 46970.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6324/10556 [00:00<00:00, 61882.98it/s]100%|| 10556/10556 [00:00<00:00, 62482.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5728/10556 [00:00<00:00, 57275.82it/s]100%|| 10556/10556 [00:00<00:00, 56026.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5867/10556 [00:00<00:00, 58667.26it/s]100%|| 10556/10556 [00:00<00:00, 54457.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6950/10556 [00:00<00:00, 56402.54it/s]100%|| 10556/10556 [00:00<00:00, 54679.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6589/10556 [00:00<00:00, 62819.41it/s]100%|| 10556/10556 [00:00<00:00, 53563.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6696/10556 [00:00<00:00, 65474.58it/s]100%|| 10556/10556 [00:00<00:00, 64547.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5382/10556 [00:00<00:00, 53818.38it/s]100%|| 10556/10556 [00:00<00:00, 55357.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5314/10556 [00:00<00:00, 53137.14it/s] 84%| | 8891/10556 [00:00<00:00, 46028.44it/s]100%|| 10556/10556 [00:00<00:00, 47093.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 189187.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 160213.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108760.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 171081.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177332.24it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179042.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 177027.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124370.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120313.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128099.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196346.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 212050.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 208735.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 186436.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 217112.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 148469.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126081.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 232149.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 210253.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200261.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 209043.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 185751.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 197841.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 194457.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 200878.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 198728.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196823.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121426.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122846.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117187.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122200.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7789/10556 [00:00<00:00, 77888.77it/s]100%|| 10556/10556 [00:00<00:00, 86349.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8244/10556 [00:00<00:00, 82434.97it/s]100%|| 10556/10556 [00:00<00:00, 78873.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10421/10556 [00:00<00:00, 104206.62it/s]100%|| 10556/10556 [00:00<00:00, 103917.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6191/10556 [00:00<00:00, 61526.03it/s]100%|| 10556/10556 [00:00<00:00, 60949.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6636/10556 [00:00<00:00, 64898.18it/s]100%|| 10556/10556 [00:00<00:00, 63201.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6385/10556 [00:00<00:00, 63847.32it/s]100%|| 10556/10556 [00:00<00:00, 70001.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9345/10556 [00:00<00:00, 93446.08it/s]100%|| 10556/10556 [00:00<00:00, 95929.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7863/10556 [00:00<00:00, 78628.01it/s]100%|| 10556/10556 [00:00<00:00, 83831.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122037.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6977/10556 [00:00<00:00, 69764.24it/s]100%|| 10556/10556 [00:00<00:00, 66709.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5510/10556 [00:00<00:00, 55099.40it/s]100%|| 10556/10556 [00:00<00:00, 57060.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9826/10556 [00:00<00:00, 98252.83it/s]100%|| 10556/10556 [00:00<00:00, 98705.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8265/10556 [00:00<00:00, 82644.76it/s]100%|| 10556/10556 [00:00<00:00, 88113.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|     | 4378/10556 [00:00<00:00, 43778.27it/s]100%|| 10556/10556 [00:00<00:00, 52987.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9554/10556 [00:00<00:00, 95537.13it/s]100%|| 10556/10556 [00:00<00:00, 93726.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7100/10556 [00:00<00:00, 70999.39it/s]100%|| 10556/10556 [00:00<00:00, 60398.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10343/10556 [00:00<00:00, 103423.44it/s]100%|| 10556/10556 [00:00<00:00, 101885.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106210.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6454/10556 [00:00<00:00, 64538.52it/s]100%|| 10556/10556 [00:00<00:00, 61566.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 99%|| 10490/10556 [00:00<00:00, 104882.85it/s]100%|| 10556/10556 [00:00<00:00, 103736.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6913/10556 [00:00<00:00, 69125.78it/s]100%|| 10556/10556 [00:00<00:00, 81873.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7559/10556 [00:00<00:00, 75588.45it/s]100%|| 10556/10556 [00:00<00:00, 71379.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8772/10556 [00:00<00:00, 87027.28it/s]100%|| 10556/10556 [00:00<00:00, 83622.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105573.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9613/10556 [00:00<00:00, 96127.11it/s]100%|| 10556/10556 [00:00<00:00, 97653.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106195.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116399.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5722/10556 [00:00<00:00, 54193.25it/s]100%|| 10556/10556 [00:00<00:00, 59065.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7468/10556 [00:00<00:00, 68326.67it/s]100%|| 10556/10556 [00:00<00:00, 71552.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5460/10556 [00:00<00:00, 54138.22it/s]100%|| 10556/10556 [00:00<00:00, 56496.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7930/10556 [00:00<00:00, 79296.86it/s]100%|| 10556/10556 [00:00<00:00, 85992.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119060.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8061/10556 [00:00<00:00, 80609.88it/s]100%|| 10556/10556 [00:00<00:00, 87931.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6508/10556 [00:00<00:00, 65077.73it/s]100%|| 10556/10556 [00:00<00:00, 60697.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8727/10556 [00:00<00:00, 87269.25it/s]100%|| 10556/10556 [00:00<00:00, 93196.55it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7086/10556 [00:00<00:00, 70856.01it/s]100%|| 10556/10556 [00:00<00:00, 80392.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6989/10556 [00:00<00:00, 69885.40it/s]100%|| 10556/10556 [00:00<00:00, 69625.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6427/10556 [00:00<00:00, 64269.75it/s]100%|| 10556/10556 [00:00<00:00, 60767.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|| 9655/10556 [00:00<00:00, 96549.86it/s]100%|| 10556/10556 [00:00<00:00, 97848.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7639/10556 [00:00<00:00, 76386.61it/s]100%|| 10556/10556 [00:00<00:00, 59712.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7278/10556 [00:00<00:00, 72590.39it/s]100%|| 10556/10556 [00:00<00:00, 80501.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9687/10556 [00:00<00:00, 96867.78it/s]100%|| 10556/10556 [00:00<00:00, 97607.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5756/10556 [00:00<00:00, 56556.83it/s]100%|| 10556/10556 [00:00<00:00, 56814.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7599/10556 [00:00<00:00, 74642.55it/s]100%|| 10556/10556 [00:00<00:00, 66393.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127422.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 124163.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 100810.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8343/10556 [00:00<00:00, 83424.11it/s]100%|| 10556/10556 [00:00<00:00, 89627.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10103/10556 [00:00<00:00, 100982.19it/s]100%|| 10556/10556 [00:00<00:00, 99611.17it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6918/10556 [00:00<00:00, 69176.44it/s]100%|| 10556/10556 [00:00<00:00, 64413.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10162/10556 [00:00<00:00, 101618.89it/s]100%|| 10556/10556 [00:00<00:00, 101854.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|  | 7534/10556 [00:00<00:00, 62798.62it/s]100%|| 10556/10556 [00:00<00:00, 68575.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8741/10556 [00:00<00:00, 87405.71it/s]100%|| 10556/10556 [00:00<00:00, 87006.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109398.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113997.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9943/10556 [00:00<00:00, 99427.96it/s]100%|| 10556/10556 [00:00<00:00, 97781.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6014/10556 [00:00<00:00, 60135.61it/s]100%|| 10556/10556 [00:00<00:00, 56827.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120652.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6757/10556 [00:00<00:00, 67564.43it/s]100%|| 10556/10556 [00:00<00:00, 67425.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6351/10556 [00:00<00:00, 63504.31it/s]100%|| 10556/10556 [00:00<00:00, 65790.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110118.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110825.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4744/10556 [00:00<00:00, 43559.44it/s]100%|| 10556/10556 [00:00<00:00, 52935.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118120.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5396/10556 [00:00<00:00, 53958.89it/s]100%|| 10556/10556 [00:00<00:00, 55768.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121639.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6781/10556 [00:00<00:00, 65275.79it/s]100%|| 10556/10556 [00:00<00:00, 78161.13it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5597/10556 [00:00<00:00, 55968.59it/s]100%|| 10556/10556 [00:00<00:00, 69487.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115920.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9541/10556 [00:00<00:00, 95408.27it/s]100%|| 10556/10556 [00:00<00:00, 97208.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9190/10556 [00:00<00:00, 91894.39it/s]100%|| 10556/10556 [00:00<00:00, 94877.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9160/10556 [00:00<00:00, 91595.06it/s]100%|| 10556/10556 [00:00<00:00, 94685.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121400.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121081.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6455/10556 [00:00<00:00, 62628.92it/s]100%|| 10556/10556 [00:00<00:00, 76356.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6599/10556 [00:00<00:00, 65984.40it/s]100%|| 10556/10556 [00:00<00:00, 68573.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123575.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133959.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117983.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115468.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109950.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120270.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10371/10556 [00:00<00:00, 103708.86it/s]100%|| 10556/10556 [00:00<00:00, 103481.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122181.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8317/10556 [00:00<00:00, 77780.19it/s]100%|| 10556/10556 [00:00<00:00, 65911.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4681/10556 [00:00<00:00, 45136.23it/s]100%|| 10556/10556 [00:00<00:00, 52847.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4809/10556 [00:00<00:00, 48087.98it/s] 72%|  | 7607/10556 [00:00<00:00, 39078.67it/s]100%|| 10556/10556 [00:00<00:00, 42215.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|      | 4004/10556 [00:00<00:00, 40037.84it/s]100%|| 10529/10556 [00:00<00:00, 45287.06it/s]100%|| 10556/10556 [00:00<00:00, 52636.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10017/10556 [00:00<00:00, 100162.21it/s]100%|| 10556/10556 [00:00<00:00, 97529.06it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6847/10556 [00:00<00:00, 66823.03it/s]100%|| 10556/10556 [00:00<00:00, 78305.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115263.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6557/10556 [00:00<00:00, 64937.76it/s]100%|| 10556/10556 [00:00<00:00, 78116.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9363/10556 [00:00<00:00, 93625.18it/s]100%|| 10556/10556 [00:00<00:00, 88169.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7035/10556 [00:00<00:00, 70345.54it/s]100%|| 10556/10556 [00:00<00:00, 81943.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121019.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118119.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9472/10556 [00:00<00:00, 94718.28it/s]100%|| 10556/10556 [00:00<00:00, 96932.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10358/10556 [00:00<00:00, 103577.38it/s]100%|| 10556/10556 [00:00<00:00, 91612.19it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6389/10556 [00:00<00:00, 63888.08it/s]100%|| 10556/10556 [00:00<00:00, 61534.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6767/10556 [00:00<00:00, 66210.51it/s]100%|| 10556/10556 [00:00<00:00, 65290.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6629/10556 [00:00<00:00, 65913.22it/s]100%|| 10556/10556 [00:00<00:00, 66576.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7870/10556 [00:00<00:00, 70530.61it/s]100%|| 10556/10556 [00:00<00:00, 61825.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3926/10556 [00:00<00:00, 39259.48it/s] 85%| | 8987/10556 [00:00<00:00, 42034.79it/s]100%|| 10556/10556 [00:00<00:00, 43942.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8484/10556 [00:00<00:00, 84838.06it/s]100%|| 10556/10556 [00:00<00:00, 86903.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6441/10556 [00:00<00:00, 64404.69it/s]100%|| 10556/10556 [00:00<00:00, 65022.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119053.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7287/10556 [00:00<00:00, 72869.03it/s]100%|| 10556/10556 [00:00<00:00, 68434.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106452.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120116.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6149/10556 [00:00<00:00, 61488.30it/s]100%|| 10556/10556 [00:00<00:00, 61515.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121780.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6984/10556 [00:00<00:00, 69839.07it/s]100%|| 10556/10556 [00:00<00:00, 75068.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6073/10556 [00:00<00:00, 60729.62it/s]100%|| 10556/10556 [00:00<00:00, 64226.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5869/10556 [00:00<00:00, 58687.96it/s]100%|| 10556/10556 [00:00<00:00, 69505.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116243.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8029/10556 [00:00<00:00, 80283.19it/s]100%|| 10556/10556 [00:00<00:00, 88163.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6788/10556 [00:00<00:00, 67877.96it/s]100%|| 10556/10556 [00:00<00:00, 63179.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5648/10556 [00:00<00:00, 52045.35it/s]100%|| 10556/10556 [00:00<00:00, 56445.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6284/10556 [00:00<00:00, 62836.61it/s]100%|| 10556/10556 [00:00<00:00, 76634.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4655/10556 [00:00<00:00, 46547.27it/s]100%|| 10556/10556 [00:00<00:00, 70684.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 127740.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8095/10556 [00:00<00:00, 80947.76it/s]100%|| 10556/10556 [00:00<00:00, 77527.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8242/10556 [00:00<00:00, 82414.18it/s]100%|| 10556/10556 [00:00<00:00, 85687.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6981/10556 [00:00<00:00, 67935.42it/s]100%|| 10556/10556 [00:00<00:00, 64808.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6747/10556 [00:00<00:00, 67468.46it/s]100%|| 10556/10556 [00:00<00:00, 54838.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8049/10556 [00:00<00:00, 76000.50it/s]100%|| 10556/10556 [00:00<00:00, 79476.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8771/10556 [00:00<00:00, 87707.78it/s]100%|| 10556/10556 [00:00<00:00, 90987.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6502/10556 [00:00<00:00, 64375.89it/s]100%|| 10556/10556 [00:00<00:00, 79119.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121056.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6655/10556 [00:00<00:00, 62440.93it/s]100%|| 10556/10556 [00:00<00:00, 61809.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6115/10556 [00:00<00:00, 61146.41it/s]100%|| 10556/10556 [00:00<00:00, 63261.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114245.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5496/10556 [00:00<00:00, 50509.31it/s]100%|| 10556/10556 [00:00<00:00, 51022.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9205/10556 [00:00<00:00, 92042.19it/s]100%|| 10556/10556 [00:00<00:00, 95142.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7458/10556 [00:00<00:00, 74574.91it/s]100%|| 10556/10556 [00:00<00:00, 68180.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 44%|     | 4597/10556 [00:00<00:00, 42478.99it/s] 96%|| 10151/10556 [00:00<00:00, 45205.86it/s]100%|| 10556/10556 [00:00<00:00, 48924.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5816/10556 [00:00<00:00, 54930.22it/s] 92%|| 9724/10556 [00:00<00:00, 48971.17it/s]100%|| 10556/10556 [00:00<00:00, 44654.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5728/10556 [00:00<00:00, 55740.07it/s] 87%| | 9200/10556 [00:00<00:00, 47128.66it/s]100%|| 10556/10556 [00:00<00:00, 47595.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10329/10556 [00:00<00:00, 103284.19it/s]100%|| 10556/10556 [00:00<00:00, 103089.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7887/10556 [00:00<00:00, 78863.31it/s]100%|| 10556/10556 [00:00<00:00, 86910.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 55%|    | 5823/10556 [00:00<00:00, 58227.42it/s]100%|| 10556/10556 [00:00<00:00, 58266.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9277/10556 [00:00<00:00, 92764.56it/s]100%|| 10556/10556 [00:00<00:00, 95487.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%| | 8584/10556 [00:00<00:00, 85839.67it/s]100%|| 10556/10556 [00:00<00:00, 90809.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6329/10556 [00:00<00:00, 63286.89it/s]100%|| 10556/10556 [00:00<00:00, 73266.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113494.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119522.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118641.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113438.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 9016/10556 [00:00<00:00, 90155.36it/s]100%|| 10556/10556 [00:00<00:00, 94022.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4136/10556 [00:00<00:00, 40354.43it/s] 97%|| 10229/10556 [00:00<00:00, 44059.77it/s]100%|| 10556/10556 [00:00<00:00, 46692.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6246/10556 [00:00<00:00, 62456.19it/s]100%|| 10556/10556 [00:00<00:00, 61496.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6236/10556 [00:00<00:00, 62356.94it/s]100%|| 10556/10556 [00:00<00:00, 65422.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6465/10556 [00:00<00:00, 64645.44it/s]100%|| 10556/10556 [00:00<00:00, 60661.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5039/10556 [00:00<00:00, 48893.96it/s]100%|| 10556/10556 [00:00<00:00, 68492.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10383/10556 [00:00<00:00, 103828.12it/s]100%|| 10556/10556 [00:00<00:00, 103804.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6500/10556 [00:00<00:00, 62052.84it/s]100%|| 10556/10556 [00:00<00:00, 76457.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7519/10556 [00:00<00:00, 75189.89it/s]100%|| 10556/10556 [00:00<00:00, 84124.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122174.19it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7141/10556 [00:00<00:00, 71405.30it/s]100%|| 10556/10556 [00:00<00:00, 82531.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7917/10556 [00:00<00:00, 79164.41it/s]100%|| 10556/10556 [00:00<00:00, 70470.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106088.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9603/10556 [00:00<00:00, 96024.60it/s]100%|| 10556/10556 [00:00<00:00, 92664.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5653/10556 [00:00<00:00, 54560.35it/s]100%|| 10556/10556 [00:00<00:00, 71530.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 109933.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10536/10556 [00:00<00:00, 105354.07it/s]100%|| 10556/10556 [00:00<00:00, 99306.64it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 74%|  | 7805/10556 [00:00<00:00, 74846.57it/s]100%|| 10556/10556 [00:00<00:00, 74854.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4273/10556 [00:00<00:00, 37841.73it/s]100%|| 10556/10556 [00:00<00:00, 50631.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123166.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125039.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120340.49it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8229/10556 [00:00<00:00, 80317.33it/s]100%|| 10556/10556 [00:00<00:00, 82040.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10262/10556 [00:00<00:00, 102618.14it/s]100%|| 10556/10556 [00:00<00:00, 102742.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8572/10556 [00:00<00:00, 85712.52it/s]100%|| 10556/10556 [00:00<00:00, 90969.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10108/10556 [00:00<00:00, 101072.87it/s]100%|| 10556/10556 [00:00<00:00, 97912.54it/s] 
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6603/10556 [00:00<00:00, 66026.44it/s]100%|| 10556/10556 [00:00<00:00, 64391.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5048/10556 [00:00<00:00, 50320.01it/s]100%|| 10556/10556 [00:00<00:00, 60786.85it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6635/10556 [00:00<00:00, 66349.91it/s]100%|| 10556/10556 [00:00<00:00, 58651.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 37%|      | 3954/10556 [00:00<00:00, 39538.44it/s] 92%|| 9742/10556 [00:00<00:00, 43346.00it/s]100%|| 10556/10556 [00:00<00:00, 48571.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6358/10556 [00:00<00:00, 61487.24it/s]100%|| 10556/10556 [00:00<00:00, 60720.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6020/10556 [00:00<00:00, 57407.36it/s]100%|| 10556/10556 [00:00<00:00, 58727.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6349/10556 [00:00<00:00, 63488.55it/s] 88%| | 9290/10556 [00:00<00:00, 45686.14it/s]100%|| 10556/10556 [00:00<00:00, 44261.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 40%|      | 4252/10556 [00:00<00:00, 41883.05it/s] 73%|  | 7700/10556 [00:00<00:00, 39347.53it/s]100%|| 10556/10556 [00:00<00:00, 45152.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5617/10556 [00:00<00:00, 56166.44it/s]100%|| 10556/10556 [00:00<00:00, 63390.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5932/10556 [00:00<00:00, 59318.93it/s] 75%|  | 7912/10556 [00:00<00:00, 36321.11it/s]100%|| 10556/10556 [00:00<00:00, 39369.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4836/10556 [00:00<00:00, 48358.78it/s]100%|| 10556/10556 [00:00<00:00, 57802.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4543/10556 [00:00<00:00, 45159.26it/s] 96%|| 10157/10556 [00:00<00:00, 47187.50it/s]100%|| 10556/10556 [00:00<00:00, 49305.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6409/10556 [00:00<00:00, 63648.02it/s]100%|| 10556/10556 [00:00<00:00, 59228.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6367/10556 [00:00<00:00, 62707.39it/s]100%|| 10556/10556 [00:00<00:00, 62758.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9216/10556 [00:00<00:00, 92156.13it/s]100%|| 10556/10556 [00:00<00:00, 95184.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5588/10556 [00:00<00:00, 55879.92it/s]100%|| 10556/10556 [00:00<00:00, 53504.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4340/10556 [00:00<00:00, 37423.81it/s]100%|| 10556/10556 [00:00<00:00, 49160.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7357/10556 [00:00<00:00, 73566.56it/s]100%|| 10556/10556 [00:00<00:00, 54584.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8126/10556 [00:00<00:00, 80138.90it/s]100%|| 10556/10556 [00:00<00:00, 66997.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6248/10556 [00:00<00:00, 62476.48it/s]100%|| 10556/10556 [00:00<00:00, 52828.61it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6242/10556 [00:00<00:00, 62415.30it/s]100%|| 10556/10556 [00:00<00:00, 68423.51it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121070.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121785.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122469.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120858.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120756.35it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115651.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6386/10556 [00:00<00:00, 62206.24it/s]100%|| 10556/10556 [00:00<00:00, 56970.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 33%|      | 3472/10556 [00:00<00:00, 33157.38it/s] 94%|| 9915/10556 [00:00<00:00, 38808.32it/s]100%|| 10556/10556 [00:00<00:00, 50236.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|    | 5419/10556 [00:00<00:00, 53003.19it/s]100%|| 10556/10556 [00:00<00:00, 56610.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10361/10556 [00:00<00:00, 103602.69it/s]100%|| 10556/10556 [00:00<00:00, 103695.98it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6647/10556 [00:00<00:00, 65693.67it/s]100%|| 10556/10556 [00:00<00:00, 61150.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6402/10556 [00:00<00:00, 62813.16it/s]100%|| 10556/10556 [00:00<00:00, 71478.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8716/10556 [00:00<00:00, 87155.10it/s]100%|| 10556/10556 [00:00<00:00, 91909.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9667/10556 [00:00<00:00, 96669.86it/s]100%|| 10556/10556 [00:00<00:00, 98307.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9606/10556 [00:00<00:00, 96059.18it/s]100%|| 10556/10556 [00:00<00:00, 97829.25it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111067.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6569/10556 [00:00<00:00, 64682.42it/s]100%|| 10556/10556 [00:00<00:00, 63578.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8980/10556 [00:00<00:00, 89797.52it/s]100%|| 10556/10556 [00:00<00:00, 93427.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10220/10556 [00:00<00:00, 102194.49it/s]100%|| 10556/10556 [00:00<00:00, 102488.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6309/10556 [00:00<00:00, 58043.64it/s]100%|| 10556/10556 [00:00<00:00, 58636.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6571/10556 [00:00<00:00, 65709.44it/s]100%|| 10556/10556 [00:00<00:00, 62876.97it/s]actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.70804'}; time used = 0.8086512088775635s
epoch 10: {'train_loss': '1.68172'}; time used = 0.9365279674530029s
epoch 15: {'train_loss': '1.64542'}; time used = 0.5177099704742432s
epoch 20: {'train_loss': '1.61318'}; time used = 0.6848714351654053s
epoch 25: {'train_loss': '1.59124'}; time used = 0.8238394260406494s
epoch 30: {'train_loss': '1.56626'}; time used = 0.812185525894165s
epoch 35: {'train_loss': '1.53799'}; time used = 0.50335693359375s
epoch 40: {'train_loss': '1.51915'}; time used = 0.6901206970214844s
epoch 45: {'train_loss': '1.50112'}; time used = 0.6551456451416016s
epoch 50: {'train_loss': '1.49273'}; time used = 0.7938957214355469s
epoch 55: {'train_loss': '1.47523'}; time used = 0.8175599575042725s
epoch 60: {'train_loss': '1.46341'}; time used = 0.4813072681427002s
epoch 65: {'train_loss': '1.44856'}; time used = 0.6413671970367432s
epoch 70: {'train_loss': '1.43533'}; time used = 0.7505378723144531s
epoch 75: {'train_loss': '1.43405'}; time used = 0.6295254230499268s
epoch 80: {'train_loss': '1.41818'}; time used = 0.6204710006713867s
epoch 85: {'train_loss': '1.41372'}; time used = 0.7045333385467529s
epoch 90: {'train_loss': '1.39902'}; time used = 0.659735918045044s
epoch 95: {'train_loss': '1.39553'}; time used = 0.700200080871582s
epoch 100: {'train_loss': '1.38879'}; time used = 0.5384347438812256s
epoch 105: {'train_loss': '1.38387'}; time used = 1.1275138854980469s
epoch 110: {'train_loss': '1.38179'}; time used = 1.0858829021453857s
epoch 115: {'train_loss': '1.37246'}; time used = 1.1677651405334473s
epoch 120: {'train_loss': '1.36661'}; time used = 1.1763958930969238s
epoch 125: {'train_loss': '1.36115'}; time used = 1.1920545101165771s
epoch 130: {'train_loss': '1.35610'}; time used = 1.2145044803619385s
epoch 135: {'train_loss': '1.35292'}; time used = 1.205552339553833s
epoch 140: {'train_loss': '1.35402'}; time used = 1.163740634918213s
epoch 145: {'train_loss': '1.34713'}; time used = 1.0869035720825195s
epoch 150: {'train_loss': '1.34496'}; time used = 1.2255525588989258s
epoch 155: {'train_loss': '1.34212'}; time used = 1.0123968124389648s
epoch 160: {'train_loss': '1.33694'}; time used = 1.1554195880889893s
epoch 165: {'train_loss': '1.33341'}; time used = 0.9891262054443359s
epoch 170: {'train_loss': '1.33341'}; time used = 0.8681361675262451s
epoch 175: {'train_loss': '1.32504'}; time used = 0.8726422786712646s
epoch 180: {'train_loss': '1.32266'}; time used = 0.8639278411865234s
epoch 185: {'train_loss': '1.32160'}; time used = 0.8884565830230713s
epoch 190: {'train_loss': '1.32042'}; time used = 1.0447063446044922s
epoch 195: {'train_loss': '1.31643'}; time used = 0.8675057888031006s
epoch 200: {'train_loss': '1.31154'}; time used = 0.892448902130127s
epoch 205: {'train_loss': '1.30940'}; time used = 1.0219707489013672s
epoch 210: {'train_loss': '1.30846'}; time used = 1.0250029563903809s
epoch 215: {'train_loss': '1.30819'}; time used = 1.2472286224365234s
epoch 220: {'train_loss': '1.30507'}; time used = 0.8987009525299072s
epoch 225: {'train_loss': '1.30175'}; time used = 1.306704044342041s
epoch 230: {'train_loss': '1.29637'}; time used = 0.9846010208129883s
epoch 235: {'train_loss': '1.29968'}; time used = 1.07621431350708s
epoch 240: {'train_loss': '1.29011'}; time used = 1.0124943256378174s
epoch 245: {'train_loss': '1.28606'}; time used = 1.0126030445098877s
epoch 250: {'train_loss': '1.28795'}; time used = 1.0242645740509033s
epoch 255: {'train_loss': '1.28520'}; time used = 0.786717414855957s
epoch 260: {'train_loss': '1.28231'}; time used = 0.36756372451782227s
epoch 265: {'train_loss': '1.28171'}; time used = 0.4080390930175781s
epoch 270: {'train_loss': '1.28058'}; time used = 0.3335292339324951s
epoch 275: {'train_loss': '1.27309'}; time used = 0.27922558784484863s
epoch 280: {'train_loss': '1.27555'}; time used = 0.28974103927612305s
epoch 285: {'train_loss': '1.27254'}; time used = 0.5038907527923584s
epoch 290: {'train_loss': '1.27710'}; time used = 0.8203790187835693s
epoch 295: {'train_loss': '1.27676'}; time used = 0.7309226989746094s
epoch 300: {'train_loss': '1.26715'}; time used = 0.7865505218505859s
epoch 305: {'train_loss': '1.26774'}; time used = 0.6644642353057861s
epoch 310: {'train_loss': '1.26395'}; time used = 0.6511733531951904s
epoch 315: {'train_loss': '1.26623'}; time used = 0.8152694702148438s
epoch 320: {'train_loss': '1.26731'}; time used = 0.6945080757141113s
epoch 325: {'train_loss': '1.26083'}; time used = 0.8378627300262451s
epoch 330: {'train_loss': '1.26405'}; time used = 0.6741225719451904s
epoch 335: {'train_loss': '1.26201'}; time used = 0.653841495513916s
epoch 340: {'train_loss': '1.25891'}; time used = 0.6368896961212158s
epoch 345: {'train_loss': '1.26120'}; time used = 0.8243958950042725s
epoch 350: {'train_loss': '1.25716'}; time used = 0.7860884666442871s
epoch 355: {'train_loss': '1.25988'}; time used = 0.6721882820129395s
epoch 360: {'train_loss': '1.26054'}; time used = 0.6434204578399658s
epoch 365: {'train_loss': '1.25629'}; time used = 0.5154728889465332s
epoch 370: {'train_loss': '1.25797'}; time used = 0.7340836524963379s
epoch 375: {'train_loss': '1.25661'}; time used = 0.8798315525054932s
epoch 380: {'train_loss': '1.25752'}; time used = 0.6208276748657227s
epoch 385: {'train_loss': '1.24490'}; time used = 0.810267448425293s
epoch 390: {'train_loss': '1.25154'}; time used = 0.9011368751525879s
epoch 395: {'train_loss': '1.25145'}; time used = 0.7021956443786621s
epoch 400: {'train_loss': '1.25141'}; time used = 0.7555887699127197s
epoch 405: {'train_loss': '1.24782'}; time used = 0.8032808303833008s
epoch 410: {'train_loss': '1.24480'}; time used = 0.8442826271057129s
epoch 415: {'train_loss': '1.25066'}; time used = 0.7584919929504395s
epoch 420: {'train_loss': '1.25569'}; time used = 0.8633875846862793s
epoch 425: {'train_loss': '1.25408'}; time used = 0.9409201145172119s
epoch 430: {'train_loss': '1.25196'}; time used = 0.6127309799194336s
epoch 435: {'train_loss': '1.24818'}; time used = 0.7981898784637451s
epoch 440: {'train_loss': '1.24896'}; time used = 0.8007440567016602s
epoch 445: {'train_loss': '1.24801'}; time used = 0.6717379093170166s
epoch 450: {'train_loss': '1.25184'}; time used = 0.7086191177368164s
epoch 455: {'train_loss': '1.24996'}; time used = 0.7099874019622803s
epoch 460: {'train_loss': '1.24653'}; time used = 0.7292928695678711s
epoch 465: {'train_loss': '1.24657'}; time used = 1.0719680786132812s
epoch 470: {'train_loss': '1.24814'}; time used = 1.2463939189910889s
epoch 475: {'train_loss': '1.24705'}; time used = 0.9284350872039795s
epoch 480: {'train_loss': '1.25017'}; time used = 0.90267014503479s
epoch 485: {'train_loss': '1.24693'}; time used = 0.48653435707092285s
epoch 490: {'train_loss': '1.24831'}; time used = 0.9212281703948975s
epoch 495: {'train_loss': '1.24514'}; time used = 0.6388583183288574s
epoch 500: {'train_loss': '1.24479'}; time used = 0.7848460674285889s
Finished training. Time used = 86.17051267623901.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06506465736686692, 'samples': 0.29487771112136596, 'weighted': 0.13430282067466348}

  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6571/10556 [00:00<00:00, 65702.23it/s]100%|| 10556/10556 [00:00<00:00, 63272.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5237/10556 [00:00<00:00, 52369.05it/s] 98%|| 10300/10556 [00:00<00:00, 51834.52it/s]100%|| 10556/10556 [00:00<00:00, 51528.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7031/10556 [00:00<00:00, 70304.37it/s]100%|| 10556/10556 [00:00<00:00, 69068.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8118/10556 [00:00<00:00, 81171.37it/s]100%|| 10556/10556 [00:00<00:00, 82781.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6936/10556 [00:00<00:00, 69353.12it/s]100%|| 10556/10556 [00:00<00:00, 73036.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6319/10556 [00:00<00:00, 61704.78it/s]100%|| 10556/10556 [00:00<00:00, 69100.23it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7393/10556 [00:00<00:00, 73929.37it/s]100%|| 10556/10556 [00:00<00:00, 82785.93it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106124.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 97%|| 10230/10556 [00:00<00:00, 102293.51it/s]100%|| 10556/10556 [00:00<00:00, 102290.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114153.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10095/10556 [00:00<00:00, 100941.19it/s]100%|| 10556/10556 [00:00<00:00, 101032.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7038/10556 [00:00<00:00, 70376.38it/s]100%|| 10556/10556 [00:00<00:00, 66625.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6881/10556 [00:00<00:00, 68110.98it/s]100%|| 10556/10556 [00:00<00:00, 59594.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122666.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%| | 8577/10556 [00:00<00:00, 85761.49it/s]100%|| 10556/10556 [00:00<00:00, 81602.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 89%| | 9364/10556 [00:00<00:00, 93635.18it/s]100%|| 10556/10556 [00:00<00:00, 95945.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107355.63it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117569.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120606.68it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117716.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117653.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112912.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 103687.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10018/10556 [00:00<00:00, 100175.32it/s]100%|| 10556/10556 [00:00<00:00, 101010.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6627/10556 [00:00<00:00, 66266.43it/s]100%|| 10556/10556 [00:00<00:00, 63835.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 41%|      | 4299/10556 [00:00<00:00, 42988.81it/s]100%|| 10556/10556 [00:00<00:00, 67242.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5956/10556 [00:00<00:00, 58441.06it/s]100%|| 10556/10556 [00:00<00:00, 74011.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9860/10556 [00:00<00:00, 92307.19it/s]100%|| 10556/10556 [00:00<00:00, 88811.79it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6667/10556 [00:00<00:00, 66668.79it/s]100%|| 10556/10556 [00:00<00:00, 73327.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7197/10556 [00:00<00:00, 71969.21it/s]100%|| 10556/10556 [00:00<00:00, 66560.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9144/10556 [00:00<00:00, 91434.20it/s]100%|| 10556/10556 [00:00<00:00, 94160.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6815/10556 [00:00<00:00, 68141.78it/s]100%|| 10556/10556 [00:00<00:00, 57429.54it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6554/10556 [00:00<00:00, 65532.41it/s]100%|| 10556/10556 [00:00<00:00, 68957.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8032/10556 [00:00<00:00, 79868.78it/s]100%|| 10556/10556 [00:00<00:00, 80883.08it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 47%|     | 4991/10556 [00:00<00:00, 49907.31it/s]100%|| 10556/10556 [00:00<00:00, 57114.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9891/10556 [00:00<00:00, 98908.68it/s]100%|| 10556/10556 [00:00<00:00, 99737.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 115844.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 46%|     | 4877/10556 [00:00<00:00, 46078.48it/s] 98%|| 10349/10556 [00:00<00:00, 48368.37it/s]100%|| 10556/10556 [00:00<00:00, 50573.21it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 39%|      | 4101/10556 [00:00<00:00, 41008.87it/s]100%|| 10556/10556 [00:00<00:00, 53499.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9548/10556 [00:00<00:00, 95476.68it/s]100%|| 10556/10556 [00:00<00:00, 97098.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5690/10556 [00:00<00:00, 56895.85it/s]100%|| 10556/10556 [00:00<00:00, 57447.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7224/10556 [00:00<00:00, 72235.07it/s]100%|| 10556/10556 [00:00<00:00, 82941.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118615.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118169.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6187/10556 [00:00<00:00, 61860.47it/s]100%|| 10556/10556 [00:00<00:00, 63795.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8614/10556 [00:00<00:00, 79307.88it/s]100%|| 10556/10556 [00:00<00:00, 74839.92it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 85%| | 8957/10556 [00:00<00:00, 89563.04it/s]100%|| 10556/10556 [00:00<00:00, 83710.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10126/10556 [00:00<00:00, 101254.06it/s]100%|| 10556/10556 [00:00<00:00, 101365.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8064/10556 [00:00<00:00, 80150.30it/s]100%|| 10556/10556 [00:00<00:00, 80253.83it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118611.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9139/10556 [00:00<00:00, 91386.17it/s]100%|| 10556/10556 [00:00<00:00, 94640.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 113037.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119362.66it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116782.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|      | 3959/10556 [00:00<00:00, 39585.98it/s] 82%| | 8699/10556 [00:00<00:00, 41447.70it/s]100%|| 10556/10556 [00:00<00:00, 47044.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5750/10556 [00:00<00:00, 55946.76it/s]100%|| 10556/10556 [00:00<00:00, 74019.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121452.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105803.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7153/10556 [00:00<00:00, 71529.73it/s]100%|| 10556/10556 [00:00<00:00, 75604.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107179.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6402/10556 [00:00<00:00, 64019.91it/s]100%|| 10556/10556 [00:00<00:00, 58917.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5311/10556 [00:00<00:00, 39876.96it/s]100%|| 10556/10556 [00:00<00:00, 52447.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9488/10556 [00:00<00:00, 94873.76it/s]100%|| 10556/10556 [00:00<00:00, 96609.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6717/10556 [00:00<00:00, 64841.86it/s]100%|| 10556/10556 [00:00<00:00, 69144.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10076/10556 [00:00<00:00, 100758.17it/s]100%|| 10556/10556 [00:00<00:00, 101151.38it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7185/10556 [00:00<00:00, 69322.63it/s]100%|| 10556/10556 [00:00<00:00, 66208.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6293/10556 [00:00<00:00, 60662.26it/s]100%|| 10556/10556 [00:00<00:00, 71477.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7338/10556 [00:00<00:00, 73375.35it/s]100%|| 10556/10556 [00:00<00:00, 83835.73it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 112711.99it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7920/10556 [00:00<00:00, 79199.51it/s]100%|| 10556/10556 [00:00<00:00, 84966.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118090.48it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119184.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119631.00it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118961.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119358.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118739.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 38%|      | 4025/10556 [00:00<00:00, 38907.93it/s]100%|| 10556/10556 [00:00<00:00, 68320.04it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6630/10556 [00:00<00:00, 66299.27it/s]100%|| 10556/10556 [00:00<00:00, 78766.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8862/10556 [00:00<00:00, 86126.62it/s]100%|| 10556/10556 [00:00<00:00, 88393.69it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6507/10556 [00:00<00:00, 60646.40it/s]100%|| 10556/10556 [00:00<00:00, 60940.88it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5551/10556 [00:00<00:00, 54348.65it/s]100%|| 10556/10556 [00:00<00:00, 55754.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105428.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 100111.87it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5406/10556 [00:00<00:00, 54056.83it/s]100%|| 10556/10556 [00:00<00:00, 51407.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 83%| | 8786/10556 [00:00<00:00, 87859.87it/s]100%|| 10556/10556 [00:00<00:00, 83002.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%|| 9655/10556 [00:00<00:00, 96545.72it/s]100%|| 10556/10556 [00:00<00:00, 98031.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6749/10556 [00:00<00:00, 65137.43it/s]100%|| 10556/10556 [00:00<00:00, 62969.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5953/10556 [00:00<00:00, 59525.94it/s]100%|| 10556/10556 [00:00<00:00, 54843.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6196/10556 [00:00<00:00, 61956.07it/s]100%|| 10556/10556 [00:00<00:00, 76404.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 5973/10556 [00:00<00:00, 59727.49it/s]100%|| 10556/10556 [00:00<00:00, 58563.59it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6685/10556 [00:00<00:00, 66844.96it/s]100%|| 10556/10556 [00:00<00:00, 65093.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|  | 7522/10556 [00:00<00:00, 75215.59it/s]100%|| 10556/10556 [00:00<00:00, 72247.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 45%|     | 4775/10556 [00:00<00:00, 45143.15it/s]100%|| 10556/10556 [00:00<00:00, 68919.31it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122653.11it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7323/10556 [00:00<00:00, 73225.71it/s]100%|| 10556/10556 [00:00<00:00, 80245.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8349/10556 [00:00<00:00, 83486.50it/s]100%|| 10556/10556 [00:00<00:00, 89655.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9193/10556 [00:00<00:00, 86389.91it/s]100%|| 10556/10556 [00:00<00:00, 89508.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119983.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7368/10556 [00:00<00:00, 71245.10it/s]100%|| 10556/10556 [00:00<00:00, 68195.86it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7358/10556 [00:00<00:00, 73576.74it/s]100%|| 10556/10556 [00:00<00:00, 83516.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122006.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121416.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 120119.14it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121748.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 121155.52it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122279.47it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6315/10556 [00:00<00:00, 61985.66it/s]100%|| 10556/10556 [00:00<00:00, 63998.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123840.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7350/10556 [00:00<00:00, 73496.39it/s]100%|| 10556/10556 [00:00<00:00, 83498.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 95%|| 10064/10556 [00:00<00:00, 100636.98it/s]100%|| 10556/10556 [00:00<00:00, 100958.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6682/10556 [00:00<00:00, 64453.70it/s]100%|| 10556/10556 [00:00<00:00, 73991.19it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.50555'}; time used = 0.8770372867584229s
epoch 10: {'train_loss': '1.38852'}; time used = 0.6029059886932373s
epoch 15: {'train_loss': '1.34590'}; time used = 0.7213253974914551s
epoch 20: {'train_loss': '1.32748'}; time used = 0.4838554859161377s
epoch 25: {'train_loss': '1.30669'}; time used = 0.6719214916229248s
epoch 30: {'train_loss': '1.28902'}; time used = 0.7476985454559326s
epoch 35: {'train_loss': '1.27227'}; time used = 0.8422629833221436s
epoch 40: {'train_loss': '1.25750'}; time used = 0.8926138877868652s
epoch 45: {'train_loss': '1.25708'}; time used = 0.6643707752227783s
epoch 50: {'train_loss': '1.24879'}; time used = 0.6224794387817383s
epoch 55: {'train_loss': '1.25060'}; time used = 0.735994815826416s
epoch 60: {'train_loss': '1.24543'}; time used = 0.6625051498413086s
epoch 65: {'train_loss': '1.24745'}; time used = 0.8102254867553711s
epoch 70: {'train_loss': '1.24601'}; time used = 0.6771929264068604s
epoch 75: {'train_loss': '1.24635'}; time used = 0.4673490524291992s
epoch 80: {'train_loss': '1.24384'}; time used = 0.8339114189147949s
epoch 85: {'train_loss': '1.24353'}; time used = 0.7120873928070068s
epoch 90: {'train_loss': '1.24333'}; time used = 0.9106886386871338s
epoch 95: {'train_loss': '1.23961'}; time used = 0.7197976112365723s
epoch 100: {'train_loss': '1.24502'}; time used = 0.6267156600952148s
epoch 105: {'train_loss': '1.23892'}; time used = 0.46093058586120605s
epoch 110: {'train_loss': '1.24640'}; time used = 0.6985347270965576s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.764161586761475.
Training classifier using 20.00% nodes...
{'micro': 0.29487771112136596, 'macro': 0.06508785332314744, 'samples': 0.29487771112136596, 'weighted': 0.13435070046813036}
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 196523.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 179406.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 180103.70it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 159975.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 133024.89it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 136172.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 139839.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111890.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117545.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106465.27it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7935/10556 [00:00<00:00, 79346.86it/s]100%|| 10556/10556 [00:00<00:00, 81403.26it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 105641.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 98%|| 10331/10556 [00:00<00:00, 103305.42it/s]100%|| 10556/10556 [00:00<00:00, 102943.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 56%|    | 5893/10556 [00:00<00:00, 54545.89it/s]100%|| 10556/10556 [00:00<00:00, 57828.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6942/10556 [00:00<00:00, 67244.32it/s]100%|| 10556/10556 [00:00<00:00, 54590.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 78%|  | 8207/10556 [00:00<00:00, 82067.14it/s]100%|| 10556/10556 [00:00<00:00, 88731.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122809.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7141/10556 [00:00<00:00, 67317.39it/s]100%|| 10556/10556 [00:00<00:00, 70366.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114311.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 54%|    | 5656/10556 [00:00<00:00, 56546.03it/s]100%|| 10556/10556 [00:00<00:00, 63641.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7395/10556 [00:00<00:00, 73947.95it/s]100%|| 10556/10556 [00:00<00:00, 83913.58it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5377/10556 [00:00<00:00, 45171.13it/s]100%|| 10556/10556 [00:00<00:00, 60974.62it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 71%|   | 7455/10556 [00:00<00:00, 74544.74it/s]100%|| 10556/10556 [00:00<00:00, 84249.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 88%| | 9245/10556 [00:00<00:00, 92443.70it/s]100%|| 10556/10556 [00:00<00:00, 84190.75it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 114620.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122630.01it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7600/10556 [00:00<00:00, 75994.64it/s]100%|| 10556/10556 [00:00<00:00, 85302.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123689.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6245/10556 [00:00<00:00, 61661.34it/s]100%|| 10556/10556 [00:00<00:00, 76761.03it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 129714.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8421/10556 [00:00<00:00, 84203.66it/s]100%|| 10556/10556 [00:00<00:00, 89465.74it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 7977/10556 [00:00<00:00, 79765.89it/s]100%|| 10556/10556 [00:00<00:00, 85959.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9533/10556 [00:00<00:00, 95325.55it/s]100%|| 10556/10556 [00:00<00:00, 97555.06it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123148.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123729.72it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126781.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 82%| | 8675/10556 [00:00<00:00, 85060.95it/s]100%|| 10556/10556 [00:00<00:00, 90400.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 77%|  | 8180/10556 [00:00<00:00, 78935.35it/s]100%|| 10556/10556 [00:00<00:00, 82233.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 79%|  | 8337/10556 [00:00<00:00, 83365.31it/s]100%|| 10556/10556 [00:00<00:00, 79734.97it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 51%|     | 5364/10556 [00:00<00:00, 48320.77it/s]100%|| 10556/10556 [00:00<00:00, 52638.17it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 108374.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107884.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7916/10556 [00:00<00:00, 79155.92it/s]100%|| 10556/10556 [00:00<00:00, 87171.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107913.76it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6244/10556 [00:00<00:00, 62438.57it/s]100%|| 10556/10556 [00:00<00:00, 65234.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 92%|| 9732/10556 [00:00<00:00, 97318.00it/s]100%|| 10556/10556 [00:00<00:00, 98711.29it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 58%|    | 6149/10556 [00:00<00:00, 53016.28it/s]100%|| 10556/10556 [00:00<00:00, 55120.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 60%|    | 6377/10556 [00:00<00:00, 63755.16it/s]100%|| 10556/10556 [00:00<00:00, 75548.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117393.18it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 122234.57it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6439/10556 [00:00<00:00, 63434.83it/s]100%|| 10556/10556 [00:00<00:00, 67095.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7169/10556 [00:00<00:00, 71684.26it/s]100%|| 10556/10556 [00:00<00:00, 78331.91it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 84%| | 8816/10556 [00:00<00:00, 88154.41it/s]100%|| 10556/10556 [00:00<00:00, 88130.64it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8453/10556 [00:00<00:00, 84526.86it/s]100%|| 10556/10556 [00:00<00:00, 83616.60it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 106321.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119381.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 87%| | 9221/10556 [00:00<00:00, 89344.41it/s]100%|| 10556/10556 [00:00<00:00, 86338.67it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 59%|    | 6190/10556 [00:00<00:00, 61897.11it/s]100%|| 10556/10556 [00:00<00:00, 56414.16it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6407/10556 [00:00<00:00, 64067.77it/s]100%|| 10556/10556 [00:00<00:00, 74116.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6767/10556 [00:00<00:00, 66611.10it/s]100%|| 10556/10556 [00:00<00:00, 63312.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 53%|    | 5546/10556 [00:00<00:00, 55457.14it/s]100%|| 10556/10556 [00:00<00:00, 74113.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 91%| | 9631/10556 [00:00<00:00, 96306.88it/s]100%|| 10556/10556 [00:00<00:00, 98097.37it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 61%|    | 6457/10556 [00:00<00:00, 60327.05it/s]100%|| 10556/10556 [00:00<00:00, 63186.65it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 116185.28it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7083/10556 [00:00<00:00, 70829.22it/s]100%|| 10556/10556 [00:00<00:00, 68625.33it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 123207.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6973/10556 [00:00<00:00, 60789.67it/s]100%|| 10556/10556 [00:00<00:00, 55619.02it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 52%|    | 5520/10556 [00:00<00:00, 51310.91it/s]100%|| 10556/10556 [00:00<00:00, 60006.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8442/10556 [00:00<00:00, 79335.70it/s]100%|| 10556/10556 [00:00<00:00, 77822.20it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 57%|    | 6019/10556 [00:00<00:00, 60186.90it/s]100%|| 10556/10556 [00:00<00:00, 57952.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 96%|| 10122/10556 [00:00<00:00, 101213.82it/s]100%|| 10556/10556 [00:00<00:00, 101752.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 93%|| 9773/10556 [00:00<00:00, 97728.23it/s]100%|| 10556/10556 [00:00<00:00, 95195.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 94%|| 9883/10556 [00:00<00:00, 98829.62it/s]100%|| 10556/10556 [00:00<00:00, 99848.39it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 125405.95it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 75%|  | 7914/10556 [00:00<00:00, 79138.57it/s]100%|| 10556/10556 [00:00<00:00, 85599.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 73%|  | 7721/10556 [00:00<00:00, 71663.15it/s]100%|| 10556/10556 [00:00<00:00, 81381.12it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 128658.36it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 126911.40it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 69%|   | 7258/10556 [00:00<00:00, 72575.57it/s]100%|| 10556/10556 [00:00<00:00, 66957.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 110242.30it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 86%| | 9122/10556 [00:00<00:00, 91216.61it/s]100%|| 10556/10556 [00:00<00:00, 93132.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 90%| | 9516/10556 [00:00<00:00, 95153.28it/s]100%|| 10556/10556 [00:00<00:00, 97006.81it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7146/10556 [00:00<00:00, 71453.76it/s]100%|| 10556/10556 [00:00<00:00, 79011.84it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111191.94it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 118768.71it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6749/10556 [00:00<00:00, 67484.11it/s]100%|| 10556/10556 [00:00<00:00, 55139.34it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5106/10556 [00:00<00:00, 49693.63it/s] 94%|| 9920/10556 [00:00<00:00, 49217.09it/s]100%|| 10556/10556 [00:00<00:00, 49747.44it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 28%|       | 3007/10556 [00:00<00:00, 24967.03it/s] 60%|    | 6281/10556 [00:00<00:00, 26881.22it/s]100%|| 10556/10556 [00:00<00:00, 40527.42it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 62%|   | 6542/10556 [00:00<00:00, 65418.35it/s]100%|| 10556/10556 [00:00<00:00, 63396.82it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 81%|  | 8562/10556 [00:00<00:00, 85615.39it/s]100%|| 10556/10556 [00:00<00:00, 89777.22it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 111633.50it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 6948/10556 [00:00<00:00, 65391.44it/s]100%|| 10556/10556 [00:00<00:00, 66436.09it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8423/10556 [00:00<00:00, 84225.66it/s]100%|| 10556/10556 [00:00<00:00, 90372.05it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 67%|   | 7079/10556 [00:00<00:00, 70717.23it/s]100%|| 10556/10556 [00:00<00:00, 69751.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 80%|  | 8493/10556 [00:00<00:00, 84923.20it/s]100%|| 10556/10556 [00:00<00:00, 89726.46it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 66%|   | 7013/10556 [00:00<00:00, 63604.07it/s]100%|| 10556/10556 [00:00<00:00, 62413.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6659/10556 [00:00<00:00, 66588.00it/s]100%|| 10556/10556 [00:00<00:00, 62603.77it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 43%|     | 4510/10556 [00:00<00:00, 45099.83it/s]100%|| 10556/10556 [00:00<00:00, 69643.15it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 97908.43it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 50%|     | 5257/10556 [00:00<00:00, 52567.79it/s]100%|| 10556/10556 [00:00<00:00, 50601.41it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 107000.96it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 65%|   | 6890/10556 [00:00<00:00, 67925.95it/s]100%|| 10556/10556 [00:00<00:00, 78861.53it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 76%|  | 8030/10556 [00:00<00:00, 80296.44it/s]100%|| 10556/10556 [00:00<00:00, 87968.32it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 117336.56it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 70%|   | 7398/10556 [00:00<00:00, 73978.48it/s]100%|| 10556/10556 [00:00<00:00, 77331.10it/s]
  0%|          | 0/10556 [00:00<?, ?it/s]100%|| 10556/10556 [00:00<00:00, 119644.90it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 68%|   | 7179/10556 [00:00<00:00, 71786.99it/s]100%|| 10556/10556 [00:00<00:00, 67638.80it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 72%|  | 7598/10556 [00:00<00:00, 75978.26it/s]100%|| 10556/10556 [00:00<00:00, 70797.07it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 63%|   | 6662/10556 [00:00<00:00, 66614.03it/s]100%|| 10556/10556 [00:00<00:00, 65345.45it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 64%|   | 6772/10556 [00:00<00:00, 67712.64it/s]100%|| 10556/10556 [00:00<00:00, 68627.78it/s]
  0%|          | 0/10556 [00:00<?, ?it/s] 48%|     | 5031/10556 [00:00<00:00, 48403.25it/s] 95%|| 10073/10556 [00:00<00:00, 48989.71it/s]100%|| 10556/10556 [00:00<00:00, 50014.71it/s]
actual args: {'cpu': False, 'devices': [0], 'model': 'ss_nodemodel', 'dataset': 'cora', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.2, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.02, 'early_stopping': 20, 'hiddens': [64, 64, 64], 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4, 'enc': 'none', 'dec': 'mlp', 'sampler': 'node-neighbor-except_neighbor', 'readout': 'mean', 'est': 'jsd'}
Loading Cora Dataset from root dir: /home/duyufeng/OpenNE/data/Cora
Executing task UnsupervisedNodeClassification.
Creating test set using 20.0% nodes as training set...finished
Start training...
encoder = none
repeating 1 times...
generating negative samples with except_neighbor...
negative samples generated
sampler length = 10556 10556 10556
total iter: 500
epoch 5: {'train_loss': '1.40130'}; time used = 0.41352033615112305s
epoch 10: {'train_loss': '1.34031'}; time used = 0.5714256763458252s
epoch 15: {'train_loss': '1.31336'}; time used = 0.7754127979278564s
epoch 20: {'train_loss': '1.27880'}; time used = 0.7184240818023682s
epoch 25: {'train_loss': '1.25946'}; time used = 0.6942176818847656s
epoch 30: {'train_loss': '1.25286'}; time used = 0.6001749038696289s
epoch 35: {'train_loss': '1.24936'}; time used = 0.5269129276275635s
epoch 40: {'train_loss': '1.24251'}; time used = 0.7858631610870361s
epoch 45: {'train_loss': '1.24409'}; time used = 0.660078763961792s
epoch 50: {'train_loss': '1.23584'}; time used = 0.7644534111022949s
epoch 55: {'train_loss': '1.23682'}; time used = 0.6393349170684814s
epoch 60: {'train_loss': '1.23217'}; time used = 0.8596858978271484s
epoch 65: {'train_loss': '1.23493'}; time used = 0.6736476421356201s
epoch 70: {'train_loss': '1.23204'}; time used = 0.8753681182861328s
epoch 75: {'train_loss': '1.23262'}; time used = 0.6179647445678711s
epoch 80: {'train_loss': '1.22851'}; time used = 0.6085939407348633s
epoch 85: {'train_loss': '1.22901'}; time used = 0.6870429515838623s
epoch 90: {'train_loss': '1.22893'}; time used = 0.9387905597686768s
epoch 95: {'train_loss': '1.22523'}; time used = 0.7761871814727783s
epoch 100: {'train_loss': '1.23054'}; time used = 0.8007526397705078s
epoch 105: {'train_loss': '1.22526'}; time used = 0.6437990665435791s
epoch 110: {'train_loss': '1.23434'}; time used = 0.9020960330963135s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.704583883285522.
Training classifier using 20.00% nodes...
{'micro': 0.29441624365482233, 'macro': 0.06507879838833068, 'samples': 0.29441624365482233, 'weighted': 0.13433200977895854}
