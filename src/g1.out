Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.16001'}; time used = 1.0091519355773926s
epoch 10: {'train_loss': '0.98014'}; time used = 1.1195526123046875s
epoch 15: {'train_loss': '0.89485'}; time used = 1.0281589031219482s
epoch 20: {'train_loss': '0.61166'}; time used = 0.920557975769043s
epoch 25: {'train_loss': '0.43632'}; time used = 0.9117105007171631s
epoch 30: {'train_loss': '0.31035'}; time used = 0.9441251754760742s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.270341873168945.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.78007'}; time used = 3.000103712081909s
epoch 10: {'train_loss': '2.75101'}; time used = 1.9934442043304443s
epoch 15: {'train_loss': '2.75145'}; time used = 1.7760505676269531s
epoch 20: {'train_loss': '2.74804'}; time used = 1.6804566383361816s
epoch 25: {'train_loss': '2.73481'}; time used = 1.9533472061157227s
epoch 30: {'train_loss': '2.71553'}; time used = 1.799933910369873s
epoch 35: {'train_loss': '2.69788'}; time used = 1.800981044769287s
epoch 40: {'train_loss': '2.65294'}; time used = 1.7287285327911377s
epoch 45: {'train_loss': '2.59379'}; time used = 1.8490848541259766s
epoch 50: {'train_loss': '2.52995'}; time used = 1.674015998840332s
epoch 55: {'train_loss': '2.48364'}; time used = 1.9052717685699463s
epoch 60: {'train_loss': '2.49626'}; time used = 1.7594032287597656s
epoch 65: {'train_loss': '2.44842'}; time used = 1.8582477569580078s
epoch 70: {'train_loss': '2.44061'}; time used = 1.713653326034546s
epoch 75: {'train_loss': '2.42619'}; time used = 2.157789945602417s
epoch 80: {'train_loss': '2.40729'}; time used = 3.109544277191162s
epoch 85: {'train_loss': '2.41716'}; time used = 3.0758743286132812s
epoch 90: {'train_loss': '2.41451'}; time used = 2.868948221206665s
epoch 95: {'train_loss': '2.40876'}; time used = 1.747626781463623s
epoch 100: {'train_loss': '2.41164'}; time used = 1.9023160934448242s
epoch 105: {'train_loss': '2.40237'}; time used = 1.8770153522491455s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 48.68358850479126.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.38268398268398274, 'samples': 0.5507246376811594, 'weighted': 0.40602296254470177, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.10690'}; time used = 2.0716607570648193s
epoch 10: {'train_loss': '0.00001'}; time used = 2.102726936340332s
epoch 15: {'train_loss': '0.04502'}; time used = 3.241260290145874s
epoch 20: {'train_loss': '0.00098'}; time used = 2.0538225173950195s
epoch 25: {'train_loss': '0.01202'}; time used = 2.0730788707733154s
epoch 30: {'train_loss': '0.00232'}; time used = 1.8616886138916016s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.02837061882019.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37833'}; time used = 1.8320364952087402s
epoch 10: {'train_loss': '1.29321'}; time used = 1.837221622467041s
epoch 15: {'train_loss': '1.18576'}; time used = 1.8165254592895508s
epoch 20: {'train_loss': '1.07595'}; time used = 1.9124372005462646s
epoch 25: {'train_loss': '0.70363'}; time used = 1.8825445175170898s
epoch 30: {'train_loss': '0.51999'}; time used = 1.7983155250549316s
epoch 35: {'train_loss': '0.69582'}; time used = 1.8232247829437256s
epoch 40: {'train_loss': '0.66543'}; time used = 1.962784767150879s
epoch 45: {'train_loss': '0.68158'}; time used = 1.8429017066955566s
epoch 50: {'train_loss': '0.57951'}; time used = 2.114396095275879s
epoch 55: {'train_loss': '0.43911'}; time used = 1.8847637176513672s
epoch 60: {'train_loss': '0.13690'}; time used = 1.812692403793335s
epoch 65: {'train_loss': '0.19674'}; time used = 1.8048269748687744s
epoch 70: {'train_loss': '0.11582'}; time used = 1.8347399234771729s
epoch 75: {'train_loss': '0.04255'}; time used = 1.9564557075500488s
epoch 80: {'train_loss': '0.03941'}; time used = 1.9069085121154785s
epoch 85: {'train_loss': '0.02006'}; time used = 1.861851453781128s
epoch 90: {'train_loss': '0.02966'}; time used = 1.891444206237793s
epoch 95: {'train_loss': '0.02008'}; time used = 2.114021062850952s
epoch 100: {'train_loss': '0.01903'}; time used = 1.963308572769165s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.27794599533081.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.591894852135816, 'samples': 0.6086956521739131, 'weighted': 0.5978951378637078, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89510'}; time used = 2.434685468673706s
epoch 10: {'train_loss': '2.81497'}; time used = 2.412461996078491s
epoch 15: {'train_loss': '2.79403'}; time used = 2.726722478866577s
epoch 20: {'train_loss': '2.77272'}; time used = 2.557135581970215s
epoch 25: {'train_loss': '2.75860'}; time used = 2.700430393218994s
epoch 30: {'train_loss': '2.74839'}; time used = 2.6152286529541016s
epoch 35: {'train_loss': '2.73822'}; time used = 2.5143203735351562s
epoch 40: {'train_loss': '2.72852'}; time used = 2.5093963146209717s
epoch 45: {'train_loss': '2.72138'}; time used = 2.6159603595733643s
epoch 50: {'train_loss': '2.71049'}; time used = 2.65633487701416s
epoch 55: {'train_loss': '2.70345'}; time used = 2.5713868141174316s
epoch 60: {'train_loss': '2.68704'}; time used = 2.6817374229431152s
epoch 65: {'train_loss': '2.68553'}; time used = 2.6246252059936523s
epoch 70: {'train_loss': '2.69594'}; time used = 2.5456511974334717s
epoch 75: {'train_loss': '2.66488'}; time used = 2.5538065433502197s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.5034499168396.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.4888888888888889, 'samples': 0.5507246376811594, 'weighted': 0.5017713365539452, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.17 GiB free; 45.65 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.04840'}; time used = 4.360424041748047s
epoch 10: {'train_loss': '2.77767'}; time used = 4.245521306991577s
epoch 15: {'train_loss': '2.80837'}; time used = 4.590134143829346s
epoch 20: {'train_loss': '2.79512'}; time used = 4.139214038848877s
epoch 25: {'train_loss': '2.77346'}; time used = 4.17155385017395s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.108672857284546.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.37864'}; time used = 2.1339831352233887s
epoch 10: {'train_loss': '0.25105'}; time used = 2.0638632774353027s
epoch 15: {'train_loss': '0.22828'}; time used = 2.0904934406280518s
epoch 20: {'train_loss': '0.23493'}; time used = 2.1010348796844482s
epoch 25: {'train_loss': '0.29602'}; time used = 2.1130316257476807s
epoch 30: {'train_loss': '0.27284'}; time used = 2.206749439239502s
epoch 35: {'train_loss': '0.20896'}; time used = 1.906693696975708s
epoch 40: {'train_loss': '0.23396'}; time used = 1.9702115058898926s
epoch 45: {'train_loss': '0.12679'}; time used = 1.8594143390655518s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.60785460472107.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.25 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.79890'}; time used = 2.313088893890381s
epoch 10: {'train_loss': '2.78345'}; time used = 2.019015312194824s
epoch 15: {'train_loss': '2.76976'}; time used = 1.8446106910705566s
epoch 20: {'train_loss': '2.76589'}; time used = 1.735715389251709s
epoch 25: {'train_loss': '2.75757'}; time used = 1.9488446712493896s
epoch 30: {'train_loss': '2.74804'}; time used = 1.788663625717163s
epoch 35: {'train_loss': '2.74654'}; time used = 2.0871360301971436s
epoch 40: {'train_loss': '2.74255'}; time used = 2.2171823978424072s
epoch 45: {'train_loss': '2.73926'}; time used = 2.2063193321228027s
epoch 50: {'train_loss': '2.73425'}; time used = 1.9696083068847656s
epoch 55: {'train_loss': '2.73393'}; time used = 1.9450464248657227s
epoch 60: {'train_loss': '2.72278'}; time used = 2.0304574966430664s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.83874225616455.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5295454545454545, 'samples': 0.5652173913043478, 'weighted': 0.5389328063241107, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.19792'}; time used = 1.1276910305023193s
epoch 10: {'train_loss': '0.10253'}; time used = 0.9878025054931641s
epoch 15: {'train_loss': '0.08043'}; time used = 0.9073116779327393s
epoch 20: {'train_loss': '0.11600'}; time used = 0.914353609085083s
epoch 25: {'train_loss': '0.14390'}; time used = 0.8970279693603516s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.472885370254517.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7548387096774194, 'samples': 0.7631578947368421, 'weighted': 0.7619694397283531, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37982'}; time used = 1.7078368663787842s
epoch 10: {'train_loss': '1.29813'}; time used = 1.7668230533599854s
epoch 15: {'train_loss': '1.19775'}; time used = 1.6760008335113525s
epoch 20: {'train_loss': '1.34117'}; time used = 1.686187505722046s
epoch 25: {'train_loss': '1.22284'}; time used = 1.7554810047149658s
epoch 30: {'train_loss': '1.13617'}; time used = 1.6801421642303467s
epoch 35: {'train_loss': '1.20656'}; time used = 1.6596744060516357s
epoch 40: {'train_loss': '1.20413'}; time used = 1.7905209064483643s
epoch 45: {'train_loss': '1.21715'}; time used = 1.6725273132324219s
epoch 50: {'train_loss': '1.17920'}; time used = 1.7116916179656982s
epoch 55: {'train_loss': '1.00206'}; time used = 1.6261327266693115s
epoch 60: {'train_loss': '1.07508'}; time used = 1.7113723754882812s
epoch 65: {'train_loss': '1.20622'}; time used = 1.680959939956665s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.944714069366455.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5371198568872988, 'samples': 0.5652173913043478, 'weighted': 0.5453838375981955, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.35981'}; time used = 1.0178487300872803s
epoch 10: {'train_loss': '1.31844'}; time used = 0.9345669746398926s
epoch 15: {'train_loss': '1.23525'}; time used = 0.9116923809051514s
epoch 20: {'train_loss': '1.18103'}; time used = 0.9217698574066162s
epoch 25: {'train_loss': '0.91968'}; time used = 0.9434506893157959s
epoch 30: {'train_loss': '0.99601'}; time used = 0.9244496822357178s
epoch 35: {'train_loss': '0.92313'}; time used = 1.1338632106781006s
epoch 40: {'train_loss': '0.84883'}; time used = 1.1726348400115967s
epoch 45: {'train_loss': '0.65276'}; time used = 1.2081952095031738s
epoch 50: {'train_loss': '0.76842'}; time used = 0.9686291217803955s
epoch 55: {'train_loss': '0.57137'}; time used = 0.9556546211242676s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.22957468032837.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.66286'}; time used = 1.1043612957000732s
epoch 10: {'train_loss': '2.27200'}; time used = 0.9335446357727051s
epoch 15: {'train_loss': '1.73385'}; time used = 1.0363678932189941s
epoch 20: {'train_loss': '1.43474'}; time used = 0.9721875190734863s
epoch 25: {'train_loss': '1.50977'}; time used = 1.0887799263000488s
epoch 30: {'train_loss': '1.90240'}; time used = 0.9425158500671387s
epoch 35: {'train_loss': '1.57394'}; time used = 1.0154447555541992s
epoch 40: {'train_loss': '1.44447'}; time used = 0.9350087642669678s
epoch 45: {'train_loss': '1.33610'}; time used = 1.0887205600738525s
epoch 50: {'train_loss': '1.20761'}; time used = 1.1117446422576904s
epoch 55: {'train_loss': '1.16372'}; time used = 1.0830576419830322s
epoch 60: {'train_loss': '1.11117'}; time used = 1.0472383499145508s
epoch 65: {'train_loss': '1.05892'}; time used = 0.9772515296936035s
epoch 70: {'train_loss': '1.02803'}; time used = 1.113907814025879s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.978036880493164.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6695652173913045, 'samples': 0.6842105263157895, 'weighted': 0.6805491990846683, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.59328'}; time used = 1.108285903930664s
epoch 10: {'train_loss': '2.46070'}; time used = 1.0625340938568115s
epoch 15: {'train_loss': '2.37415'}; time used = 1.1130483150482178s
epoch 20: {'train_loss': '2.31479'}; time used = 1.0994093418121338s
epoch 25: {'train_loss': '2.28622'}; time used = 0.9992105960845947s
epoch 30: {'train_loss': '2.21953'}; time used = 0.9185240268707275s
epoch 35: {'train_loss': '2.17576'}; time used = 0.92868971824646s
epoch 40: {'train_loss': '2.15818'}; time used = 0.9401617050170898s
epoch 45: {'train_loss': '2.14570'}; time used = 0.954221248626709s
epoch 50: {'train_loss': '2.16046'}; time used = 1.05240797996521s
epoch 55: {'train_loss': '2.13989'}; time used = 1.1056456565856934s
epoch 60: {'train_loss': '2.12641'}; time used = 1.0453147888183594s
epoch 65: {'train_loss': '2.13482'}; time used = 0.9234669208526611s
epoch 70: {'train_loss': '2.14422'}; time used = 0.9350795745849609s
epoch 75: {'train_loss': '2.11574'}; time used = 0.9098381996154785s
epoch 80: {'train_loss': '2.13199'}; time used = 2.486851453781128s
epoch 85: {'train_loss': '2.13700'}; time used = 1.2053699493408203s
epoch 90: {'train_loss': '2.10214'}; time used = 0.9122498035430908s
epoch 95: {'train_loss': '2.13554'}; time used = 0.9403162002563477s
epoch 100: {'train_loss': '2.15412'}; time used = 1.051558256149292s
epoch 105: {'train_loss': '2.13302'}; time used = 0.9839916229248047s
epoch 110: {'train_loss': '2.10860'}; time used = 0.9179439544677734s
epoch 115: {'train_loss': '2.11670'}; time used = 0.8783888816833496s
epoch 120: {'train_loss': '2.10372'}; time used = 1.277834177017212s
epoch 125: {'train_loss': '2.13040'}; time used = 1.1832222938537598s
epoch 130: {'train_loss': '2.11111'}; time used = 1.169508934020996s
epoch 135: {'train_loss': '2.10141'}; time used = 2.0826961994171143s
epoch 140: {'train_loss': '2.11728'}; time used = 1.888946294784546s
epoch 145: {'train_loss': '2.11902'}; time used = 2.1589603424072266s
epoch 150: {'train_loss': '2.11092'}; time used = 1.872518539428711s
epoch 155: {'train_loss': '2.13274'}; time used = 1.9045448303222656s
epoch 160: {'train_loss': '2.12703'}; time used = 0.9619104862213135s
epoch 165: {'train_loss': '2.13705'}; time used = 0.9742510318756104s
epoch 170: {'train_loss': '2.14566'}; time used = 1.0206682682037354s
epoch 175: {'train_loss': '2.09569'}; time used = 0.9663882255554199s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 45.20866250991821.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36639'}; time used = 3.1109938621520996s
epoch 10: {'train_loss': '1.33349'}; time used = 3.4416565895080566s
epoch 15: {'train_loss': '1.26172'}; time used = 3.3333284854888916s
epoch 20: {'train_loss': '1.29149'}; time used = 2.0859999656677246s
epoch 25: {'train_loss': '1.13536'}; time used = 1.9055724143981934s
epoch 30: {'train_loss': '1.01855'}; time used = 1.673783540725708s
epoch 35: {'train_loss': '0.98736'}; time used = 1.6544592380523682s
epoch 40: {'train_loss': '0.92023'}; time used = 1.7983405590057373s
epoch 45: {'train_loss': '0.83810'}; time used = 1.6739675998687744s
epoch 50: {'train_loss': '0.65654'}; time used = 1.702416181564331s
epoch 55: {'train_loss': '0.62940'}; time used = 1.674407720565796s
epoch 60: {'train_loss': '0.60408'}; time used = 1.641721248626709s
epoch 65: {'train_loss': '0.69305'}; time used = 1.6469762325286865s
epoch 70: {'train_loss': '0.59446'}; time used = 1.6540117263793945s
epoch 75: {'train_loss': '0.49012'}; time used = 1.7783052921295166s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.84489989280701.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5241379310344827, 'samples': 0.5362318840579711, 'weighted': 0.5296351824087956, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.62 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.27973'}; time used = 1.7315938472747803s
epoch 10: {'train_loss': '2.90798'}; time used = 1.7880995273590088s
epoch 15: {'train_loss': '2.83942'}; time used = 1.803760051727295s
epoch 20: {'train_loss': '2.77591'}; time used = 2.1467385292053223s
epoch 25: {'train_loss': '2.78209'}; time used = 1.9955790042877197s
epoch 30: {'train_loss': '2.78071'}; time used = 1.8321282863616943s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.826671600341797.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5218637992831542, 'samples': 0.5797101449275363, 'weighted': 0.5339151212924004, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.26 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36921'}; time used = 1.746337890625s
epoch 10: {'train_loss': '1.27734'}; time used = 1.7449252605438232s
epoch 15: {'train_loss': '1.20228'}; time used = 1.7305171489715576s
epoch 20: {'train_loss': '1.27646'}; time used = 1.7993316650390625s
epoch 25: {'train_loss': '1.21266'}; time used = 1.8314368724822998s
epoch 30: {'train_loss': '1.28965'}; time used = 1.696150302886963s
epoch 35: {'train_loss': '1.21463'}; time used = 1.6980845928192139s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.735556602478027.
Training classifier using 80.00% nodes...
{'micro': 0.6811594202898551, 'macro': 0.6794763513513513, 'samples': 0.6811594202898551, 'weighted': 0.6811594202898551, 'accuracy': 0.6811594202898551}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36160'}; time used = 1.8691198825836182s
epoch 10: {'train_loss': '1.27947'}; time used = 1.7383358478546143s
epoch 15: {'train_loss': '1.17939'}; time used = 1.840235948562622s
epoch 20: {'train_loss': '1.14463'}; time used = 1.7404794692993164s
epoch 25: {'train_loss': '1.00863'}; time used = 3.339221239089966s
epoch 30: {'train_loss': '0.70538'}; time used = 3.6287059783935547s
epoch 35: {'train_loss': '0.92007'}; time used = 2.665092945098877s
epoch 40: {'train_loss': '0.73394'}; time used = 1.9275944232940674s
epoch 45: {'train_loss': '0.60875'}; time used = 1.7491822242736816s
epoch 50: {'train_loss': '0.54452'}; time used = 1.7374322414398193s
epoch 55: {'train_loss': '0.37158'}; time used = 1.6995460987091064s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.587239980697632.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5282051282051283, 'samples': 0.5362318840579711, 'weighted': 0.5326644370122631, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.37092'}; time used = 1.171210765838623s
epoch 10: {'train_loss': '1.33511'}; time used = 1.0777370929718018s
epoch 15: {'train_loss': '1.24556'}; time used = 1.0741465091705322s
epoch 20: {'train_loss': '1.18576'}; time used = 1.14481520652771s
epoch 25: {'train_loss': '1.05653'}; time used = 1.093470811843872s
epoch 30: {'train_loss': '0.95065'}; time used = 1.1092689037322998s
epoch 35: {'train_loss': '0.99848'}; time used = 1.1679949760437012s
epoch 40: {'train_loss': '0.91903'}; time used = 1.0765807628631592s
epoch 45: {'train_loss': '0.77891'}; time used = 1.0828440189361572s
epoch 50: {'train_loss': '0.88237'}; time used = 1.2291741371154785s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.718522071838379.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7548387096774194, 'samples': 0.7631578947368421, 'weighted': 0.7619694397283531, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84817'}; time used = 6.4158995151519775s
epoch 10: {'train_loss': '2.77709'}; time used = 6.183075666427612s
epoch 15: {'train_loss': '2.78165'}; time used = 5.83621621131897s
epoch 20: {'train_loss': '2.77764'}; time used = 5.914299726486206s
epoch 25: {'train_loss': '2.77375'}; time used = 5.66169285774231s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.4230592250824.
Training classifier using 80.00% nodes...
{'micro': 0.45, 'macro': 0.3644725086193194, 'samples': 0.45, 'weighted': 0.35353833336073975, 'accuracy': 0.45}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.35756'}; time used = 2.0547988414764404s
epoch 10: {'train_loss': '2.82572'}; time used = 2.357476234436035s
epoch 15: {'train_loss': '2.79383'}; time used = 2.4121782779693604s
epoch 20: {'train_loss': '2.79172'}; time used = 2.2256038188934326s
epoch 25: {'train_loss': '2.79287'}; time used = 2.470118522644043s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.499249696731567.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.81620'}; time used = 3.239457368850708s
epoch 10: {'train_loss': '2.80341'}; time used = 3.4484519958496094s
epoch 15: {'train_loss': '2.77725'}; time used = 3.041775703430176s
epoch 20: {'train_loss': '2.77898'}; time used = 2.026902914047241s
epoch 25: {'train_loss': '2.75853'}; time used = 2.3242239952087402s
epoch 30: {'train_loss': '2.74163'}; time used = 1.9624087810516357s
epoch 35: {'train_loss': '2.71938'}; time used = 1.9997117519378662s
epoch 40: {'train_loss': '2.65049'}; time used = 2.13606858253479s
epoch 45: {'train_loss': '2.59544'}; time used = 2.227346897125244s
epoch 50: {'train_loss': '2.55323'}; time used = 2.233508825302124s
epoch 55: {'train_loss': '2.61930'}; time used = 2.310070276260376s
epoch 60: {'train_loss': '2.55465'}; time used = 2.2540929317474365s
epoch 65: {'train_loss': '2.52890'}; time used = 2.3275046348571777s
epoch 70: {'train_loss': '2.50617'}; time used = 2.097747564315796s
epoch 75: {'train_loss': '2.46439'}; time used = 1.9886634349822998s
epoch 80: {'train_loss': '2.44673'}; time used = 2.0421698093414307s
epoch 85: {'train_loss': '2.43948'}; time used = 1.9736907482147217s
epoch 90: {'train_loss': '2.47430'}; time used = 1.9693870544433594s
epoch 95: {'train_loss': '2.43988'}; time used = 1.975956916809082s
epoch 100: {'train_loss': '2.50495'}; time used = 1.9542388916015625s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 48.85688400268555.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.49988309562777655, 'samples': 0.5507246376811594, 'weighted': 0.5114379915489998, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.53045'}; time used = 1.332157850265503s
epoch 10: {'train_loss': '0.23896'}; time used = 1.2108590602874756s
epoch 15: {'train_loss': '0.10122'}; time used = 1.0891475677490234s
epoch 20: {'train_loss': '0.05313'}; time used = 1.0905568599700928s
epoch 25: {'train_loss': '0.13695'}; time used = 1.0917980670928955s
epoch 30: {'train_loss': '0.05066'}; time used = 1.1035003662109375s
epoch 35: {'train_loss': '0.05610'}; time used = 1.0650768280029297s
epoch 40: {'train_loss': '0.04805'}; time used = 1.1163411140441895s
epoch 45: {'train_loss': '0.06792'}; time used = 1.2277274131774902s
epoch 50: {'train_loss': '0.06685'}; time used = 1.2286043167114258s
epoch 55: {'train_loss': '0.04453'}; time used = 1.1587419509887695s
epoch 60: {'train_loss': '0.02328'}; time used = 1.175508975982666s
epoch 65: {'train_loss': '0.03020'}; time used = 1.1927433013916016s
epoch 70: {'train_loss': '0.02306'}; time used = 1.1517653465270996s
epoch 75: {'train_loss': '0.02219'}; time used = 1.0543301105499268s
epoch 80: {'train_loss': '0.00685'}; time used = 1.0674278736114502s
epoch 85: {'train_loss': '0.02787'}; time used = 1.0597174167633057s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.28169298171997.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.83867'}; time used = 1.1573753356933594s
epoch 10: {'train_loss': '2.78715'}; time used = 1.0826785564422607s
epoch 15: {'train_loss': '2.77316'}; time used = 1.0363705158233643s
epoch 20: {'train_loss': '2.77420'}; time used = 1.1028258800506592s
epoch 25: {'train_loss': '2.77536'}; time used = 1.0806357860565186s
epoch 30: {'train_loss': '2.77341'}; time used = 1.0120398998260498s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.860396146774292.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.3666666666666667, 'samples': 0.5789473684210527, 'weighted': 0.4245614035087719, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.43635'}; time used = 6.011975049972534s
epoch 10: {'train_loss': '2.82427'}; time used = 5.8353681564331055s
epoch 15: {'train_loss': '2.83111'}; time used = 5.649438858032227s
epoch 20: {'train_loss': '2.84291'}; time used = 5.844019174575806s
epoch 25: {'train_loss': '2.82756'}; time used = 6.073631763458252s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.21061086654663.
Training classifier using 80.00% nodes...
{'micro': 0.51, 'macro': 0.4894240128899554, 'samples': 0.51, 'weighted': 0.48415305720913904, 'accuracy': 0.51}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 34.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 26.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37544'}; time used = 1.15513014793396s
epoch 10: {'train_loss': '1.32342'}; time used = 1.0799517631530762s
epoch 15: {'train_loss': '1.24971'}; time used = 1.6150569915771484s
epoch 20: {'train_loss': '1.27083'}; time used = 3.4892666339874268s
epoch 25: {'train_loss': '1.18452'}; time used = 4.461878299713135s
epoch 30: {'train_loss': '1.03041'}; time used = 4.031447172164917s
epoch 35: {'train_loss': '0.98921'}; time used = 4.243274927139282s
epoch 40: {'train_loss': '0.95519'}; time used = 4.206979274749756s
epoch 45: {'train_loss': '0.66712'}; time used = 2.6595675945281982s
epoch 50: {'train_loss': '0.82003'}; time used = 1.046698808670044s
epoch 55: {'train_loss': '0.64443'}; time used = 1.0182931423187256s
epoch 60: {'train_loss': '0.78400'}; time used = 1.0984952449798584s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.91226530075073.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37758'}; time used = 1.703399658203125s
epoch 10: {'train_loss': '1.34552'}; time used = 1.5957448482513428s
epoch 15: {'train_loss': '1.27922'}; time used = 1.3692076206207275s
epoch 20: {'train_loss': '1.27377'}; time used = 1.5015654563903809s
epoch 25: {'train_loss': '1.16515'}; time used = 1.3951807022094727s
epoch 30: {'train_loss': '1.09699'}; time used = 1.4313066005706787s
epoch 35: {'train_loss': '1.04345'}; time used = 1.3461828231811523s
epoch 40: {'train_loss': '1.02374'}; time used = 1.3340590000152588s
epoch 45: {'train_loss': '0.72243'}; time used = 1.3408539295196533s
epoch 50: {'train_loss': '1.41757'}; time used = 1.3346776962280273s
epoch 55: {'train_loss': '1.37321'}; time used = 1.4718291759490967s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.529685020446777.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7913725490196077, 'samples': 0.8157894736842105, 'weighted': 0.8026418988648091, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.85346'}; time used = 10.588256597518921s
epoch 10: {'train_loss': '2.78018'}; time used = 6.821243762969971s
epoch 15: {'train_loss': '2.77267'}; time used = 8.755319833755493s
epoch 20: {'train_loss': '2.77843'}; time used = 8.402275323867798s
epoch 25: {'train_loss': '2.76727'}; time used = 9.254080057144165s
epoch 30: {'train_loss': '2.76123'}; time used = 12.563747644424438s
epoch 35: {'train_loss': '2.75106'}; time used = 7.558603286743164s
epoch 40: {'train_loss': '2.73598'}; time used = 7.880172491073608s
epoch 45: {'train_loss': '2.72249'}; time used = 8.07427430152893s
epoch 50: {'train_loss': '2.71527'}; time used = 6.777848958969116s
epoch 55: {'train_loss': '2.71175'}; time used = 6.843294620513916s
epoch 60: {'train_loss': '2.70872'}; time used = 8.582048177719116s
epoch 65: {'train_loss': '2.69660'}; time used = 8.220067262649536s
epoch 70: {'train_loss': '2.70325'}; time used = 7.5109543800354s
epoch 75: {'train_loss': '2.69000'}; time used = 7.398461103439331s
epoch 80: {'train_loss': '2.69630'}; time used = 7.298794507980347s
epoch 85: {'train_loss': '2.69053'}; time used = 7.369298219680786s
epoch 90: {'train_loss': '2.68631'}; time used = 8.660969495773315s
epoch 95: {'train_loss': '2.67863'}; time used = 9.46832537651062s
epoch 100: {'train_loss': '2.71292'}; time used = 6.942824363708496s
epoch 105: {'train_loss': '2.70127'}; time used = 6.690350770950317s
epoch 110: {'train_loss': '2.69723'}; time used = 6.847114324569702s
epoch 115: {'train_loss': '2.68532'}; time used = 6.750348806381226s
epoch 120: {'train_loss': '2.68168'}; time used = 8.067014217376709s
epoch 125: {'train_loss': '2.75697'}; time used = 9.964892864227295s
epoch 130: {'train_loss': '2.68802'}; time used = 6.8217456340789795s
epoch 135: {'train_loss': '2.69000'}; time used = 10.494943857192993s
epoch 140: {'train_loss': '2.67043'}; time used = 14.885704278945923s
epoch 145: {'train_loss': '2.67993'}; time used = 7.449827194213867s
epoch 150: {'train_loss': '2.67609'}; time used = 6.837172508239746s
epoch 155: {'train_loss': '2.67539'}; time used = 6.66243314743042s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 273.78689885139465.
Training classifier using 80.00% nodes...
{'micro': 0.46, 'macro': 0.4390840125281325, 'samples': 0.46, 'weighted': 0.43385851201983816, 'accuracy': 0.46}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.84872'}; time used = 3.5891807079315186s
epoch 10: {'train_loss': '2.78237'}; time used = 3.355853319168091s
epoch 15: {'train_loss': '2.77881'}; time used = 3.3154211044311523s
epoch 20: {'train_loss': '2.77988'}; time used = 3.195828437805176s
epoch 25: {'train_loss': '2.77259'}; time used = 3.035256862640381s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.467868328094482.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37458'}; time used = 1.8633406162261963s
epoch 10: {'train_loss': '1.30766'}; time used = 1.9774346351623535s
epoch 15: {'train_loss': '1.18817'}; time used = 1.9755182266235352s
epoch 20: {'train_loss': '0.92339'}; time used = 1.9171552658081055s
epoch 25: {'train_loss': '0.61543'}; time used = 2.0207080841064453s
epoch 30: {'train_loss': '0.50399'}; time used = 3.250974655151367s
epoch 35: {'train_loss': '1.00196'}; time used = 2.7343554496765137s
epoch 40: {'train_loss': '0.63843'}; time used = 1.8120276927947998s
epoch 45: {'train_loss': '0.42418'}; time used = 1.6759366989135742s
epoch 50: {'train_loss': '0.58576'}; time used = 1.7694449424743652s
epoch 55: {'train_loss': '0.20946'}; time used = 1.8356001377105713s
epoch 60: {'train_loss': '0.18779'}; time used = 1.7829725742340088s
epoch 65: {'train_loss': '0.13205'}; time used = 1.8516595363616943s
epoch 70: {'train_loss': '0.19411'}; time used = 2.00887393951416s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.69520044326782.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5740740740740741, 'samples': 0.5942028985507246, 'weighted': 0.5807836822329576, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.19598'}; time used = 1.6890287399291992s
epoch 10: {'train_loss': '1.14093'}; time used = 1.6240878105163574s
epoch 15: {'train_loss': '0.78726'}; time used = 1.6317389011383057s
epoch 20: {'train_loss': '0.63998'}; time used = 1.6358275413513184s
epoch 25: {'train_loss': '0.58707'}; time used = 1.7031126022338867s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.387965679168701.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.77876'}; time used = 1.827000617980957s
epoch 10: {'train_loss': '2.72905'}; time used = 1.6375246047973633s
epoch 15: {'train_loss': '2.69935'}; time used = 1.577714204788208s
epoch 20: {'train_loss': '2.68808'}; time used = 1.679389238357544s
epoch 25: {'train_loss': '2.67855'}; time used = 1.7687556743621826s
epoch 30: {'train_loss': '2.66873'}; time used = 1.6374504566192627s
epoch 35: {'train_loss': '2.66471'}; time used = 1.607285976409912s
epoch 40: {'train_loss': '2.65922'}; time used = 1.8313121795654297s
epoch 45: {'train_loss': '2.65088'}; time used = 1.7808308601379395s
epoch 50: {'train_loss': '2.63657'}; time used = 1.647183895111084s
epoch 55: {'train_loss': '2.62911'}; time used = 1.8726623058319092s
epoch 60: {'train_loss': '2.62792'}; time used = 1.6025018692016602s
epoch 65: {'train_loss': '2.60904'}; time used = 1.7595188617706299s
epoch 70: {'train_loss': '2.59411'}; time used = 1.8752620220184326s
epoch 75: {'train_loss': '2.58309'}; time used = 2.359815835952759s
epoch 80: {'train_loss': '2.57806'}; time used = 1.708738088607788s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.07461929321289.
Training classifier using 80.00% nodes...
{'micro': 0.4782608695652174, 'macro': 0.4646551724137931, 'samples': 0.4782608695652174, 'weighted': 0.470839580209895, 'accuracy': 0.4782608695652174}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.36328'}; time used = 4.95153546333313s
epoch 10: {'train_loss': '1.38647'}; time used = 4.874118804931641s
epoch 15: {'train_loss': '1.35927'}; time used = 8.664049863815308s
epoch 20: {'train_loss': '1.35498'}; time used = 5.660416603088379s
epoch 25: {'train_loss': '1.30108'}; time used = 5.239997386932373s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 63.33021855354309.
Training classifier using 80.00% nodes...
{'micro': 0.705, 'macro': 0.7049926248156204, 'samples': 0.705, 'weighted': 0.7049631240781019, 'accuracy': 0.705}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.91399'}; time used = 1.1568682193756104s
epoch 10: {'train_loss': '2.84836'}; time used = 1.1803977489471436s
epoch 15: {'train_loss': '2.82685'}; time used = 1.0198211669921875s
epoch 20: {'train_loss': '2.80659'}; time used = 1.08414626121521s
epoch 25: {'train_loss': '2.80108'}; time used = 1.1467535495758057s
epoch 30: {'train_loss': '2.79537'}; time used = 1.088771104812622s
epoch 35: {'train_loss': '2.80156'}; time used = 1.0602881908416748s
epoch 40: {'train_loss': '2.79575'}; time used = 2.0213234424591064s
epoch 45: {'train_loss': '2.79629'}; time used = 2.291771173477173s
epoch 50: {'train_loss': '2.78653'}; time used = 2.3906068801879883s
epoch 55: {'train_loss': '2.78686'}; time used = 2.4626052379608154s
epoch 60: {'train_loss': '2.78937'}; time used = 1.405224323272705s
epoch 65: {'train_loss': '2.78336'}; time used = 1.109910011291504s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.282744646072388.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.6041666666666666, 'samples': 0.631578947368421, 'weighted': 0.6206140350877193, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.23933'}; time used = 1.3094291687011719s
epoch 10: {'train_loss': '0.10613'}; time used = 1.1644792556762695s
epoch 15: {'train_loss': '0.07750'}; time used = 1.264345407485962s
epoch 20: {'train_loss': '0.03424'}; time used = 1.2731537818908691s
epoch 25: {'train_loss': '0.03214'}; time used = 1.1034629344940186s
epoch 30: {'train_loss': '0.02124'}; time used = 1.138016939163208s
epoch 35: {'train_loss': '0.02186'}; time used = 1.216789960861206s
epoch 40: {'train_loss': '0.01948'}; time used = 1.0483829975128174s
epoch 45: {'train_loss': '0.02452'}; time used = 1.1699206829071045s
epoch 50: {'train_loss': '0.01611'}; time used = 1.9264578819274902s
epoch 55: {'train_loss': '0.01463'}; time used = 1.9738988876342773s
epoch 60: {'train_loss': '0.01827'}; time used = 2.030735492706299s
epoch 65: {'train_loss': '0.02388'}; time used = 1.840651035308838s
epoch 70: {'train_loss': '0.01456'}; time used = 1.6072940826416016s
epoch 75: {'train_loss': '0.41964'}; time used = 0.9905931949615479s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.912041664123535.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.15448'}; time used = 1.1549527645111084s
epoch 10: {'train_loss': '2.80950'}; time used = 1.096043586730957s
epoch 15: {'train_loss': '2.83206'}; time used = 1.0399260520935059s
epoch 20: {'train_loss': '2.82242'}; time used = 1.0301709175109863s
epoch 25: {'train_loss': '2.80430'}; time used = 1.035015344619751s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.630683898925781.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.05572'}; time used = 6.638104438781738s
epoch 10: {'train_loss': '2.78048'}; time used = 6.878641843795776s
epoch 15: {'train_loss': '2.80789'}; time used = 6.429399013519287s
epoch 20: {'train_loss': '2.79575'}; time used = 6.5458197593688965s
epoch 25: {'train_loss': '2.77356'}; time used = 6.722841262817383s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.281267166137695.
Training classifier using 80.00% nodes...
{'micro': 0.46, 'macro': 0.45922930832247993, 'samples': 0.46, 'weighted': 0.45716671478709126, 'accuracy': 0.46}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.92306'}; time used = 1.799942970275879s
epoch 10: {'train_loss': '2.80505'}; time used = 1.874094009399414s
epoch 15: {'train_loss': '2.79137'}; time used = 1.815096139907837s
epoch 20: {'train_loss': '2.78773'}; time used = 1.9145050048828125s
epoch 25: {'train_loss': '2.78057'}; time used = 1.8586578369140625s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.869554996490479.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.62 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.93770'}; time used = 1.2456629276275635s
epoch 10: {'train_loss': '2.70391'}; time used = 1.0001707077026367s
epoch 15: {'train_loss': '2.58729'}; time used = 0.9993147850036621s
epoch 20: {'train_loss': '2.39983'}; time used = 1.3765158653259277s
epoch 25: {'train_loss': '2.10169'}; time used = 1.7768902778625488s
epoch 30: {'train_loss': '1.81028'}; time used = 1.8145439624786377s
epoch 35: {'train_loss': '1.61307'}; time used = 1.9446253776550293s
epoch 40: {'train_loss': '1.57032'}; time used = 2.05989933013916s
epoch 45: {'train_loss': '1.60950'}; time used = 1.792466402053833s
epoch 50: {'train_loss': '1.43565'}; time used = 1.0273728370666504s
epoch 55: {'train_loss': '1.47354'}; time used = 0.9678277969360352s
epoch 60: {'train_loss': '1.41626'}; time used = 1.107527732849121s
epoch 65: {'train_loss': '1.38205'}; time used = 0.9541847705841064s
epoch 70: {'train_loss': '1.37414'}; time used = 0.9742271900177002s
epoch 75: {'train_loss': '1.27917'}; time used = 0.9274768829345703s
epoch 80: {'train_loss': '1.34558'}; time used = 1.268390417098999s
epoch 85: {'train_loss': '1.36059'}; time used = 1.6324844360351562s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.397974729537964.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35397'}; time used = 1.0727293491363525s
epoch 10: {'train_loss': '1.44870'}; time used = 0.9688141345977783s
epoch 15: {'train_loss': '0.61945'}; time used = 0.953242301940918s
epoch 20: {'train_loss': '0.28518'}; time used = 1.0024728775024414s
epoch 25: {'train_loss': '0.02500'}; time used = 1.0210726261138916s
epoch 30: {'train_loss': '0.07708'}; time used = 0.9998483657836914s
epoch 35: {'train_loss': '0.02118'}; time used = 1.004098892211914s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.479524612426758.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.15779'}; time used = 1.305664300918579s
epoch 10: {'train_loss': '0.82439'}; time used = 1.2685589790344238s
epoch 15: {'train_loss': '0.65379'}; time used = 1.4009873867034912s
epoch 20: {'train_loss': '0.44859'}; time used = 1.4133327007293701s
epoch 25: {'train_loss': '0.38085'}; time used = 1.3577189445495605s
epoch 30: {'train_loss': '0.26155'}; time used = 1.2825751304626465s
epoch 35: {'train_loss': '0.22609'}; time used = 1.3772637844085693s
epoch 40: {'train_loss': '0.18319'}; time used = 1.4427165985107422s
epoch 45: {'train_loss': '0.18435'}; time used = 1.277806043624878s
epoch 50: {'train_loss': '0.18211'}; time used = 1.4273736476898193s
epoch 55: {'train_loss': '0.12049'}; time used = 2.1350643634796143s
epoch 60: {'train_loss': '0.15203'}; time used = 2.179328441619873s
epoch 65: {'train_loss': '0.24556'}; time used = 1.2765533924102783s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.83588743209839.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7172619047619048, 'samples': 0.7368421052631579, 'weighted': 0.7290100250626566, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.36328'}; time used = 5.002130031585693s
epoch 10: {'train_loss': '1.38647'}; time used = 5.097824811935425s
epoch 15: {'train_loss': '1.35927'}; time used = 8.029591798782349s
epoch 20: {'train_loss': '1.35498'}; time used = 6.657503843307495s
epoch 25: {'train_loss': '1.30108'}; time used = 5.16127610206604s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 71.15512919425964.
Training classifier using 80.00% nodes...
{'micro': 0.705, 'macro': 0.7049926248156204, 'samples': 0.705, 'weighted': 0.7049631240781019, 'accuracy': 0.705}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.83754'}; time used = 1.5053048133850098s
epoch 10: {'train_loss': '2.80317'}; time used = 1.247039556503296s
epoch 15: {'train_loss': '2.79028'}; time used = 1.2994458675384521s
epoch 20: {'train_loss': '2.78258'}; time used = 1.3215734958648682s
epoch 25: {'train_loss': '2.77610'}; time used = 1.172396183013916s
epoch 30: {'train_loss': '2.77097'}; time used = 1.4155430793762207s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.244648933410645.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.24983'}; time used = 3.266390323638916s
epoch 10: {'train_loss': '1.16800'}; time used = 3.380709648132324s
epoch 15: {'train_loss': '1.03345'}; time used = 3.4674458503723145s
epoch 20: {'train_loss': '0.88791'}; time used = 3.4503726959228516s
epoch 25: {'train_loss': '0.64981'}; time used = 3.5072009563446045s
epoch 30: {'train_loss': '0.50414'}; time used = 3.415764808654785s
epoch 35: {'train_loss': '0.26703'}; time used = 2.461378335952759s
epoch 40: {'train_loss': '0.14140'}; time used = 1.6264071464538574s
epoch 45: {'train_loss': '0.13064'}; time used = 1.6908252239227295s
epoch 50: {'train_loss': '0.07586'}; time used = 1.9131510257720947s
epoch 55: {'train_loss': '0.07420'}; time used = 1.9235050678253174s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.36165165901184.
Training classifier using 80.00% nodes...
{'micro': 0.6666666666666666, 'macro': 0.6595151255095473, 'samples': 0.6666666666666666, 'weighted': 0.663090896088107, 'accuracy': 0.6666666666666666}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.11480'}; time used = 1.5773494243621826s
epoch 10: {'train_loss': '2.77624'}; time used = 1.6324903964996338s
epoch 15: {'train_loss': '2.78143'}; time used = 1.4927408695220947s
epoch 20: {'train_loss': '2.79471'}; time used = 1.4041345119476318s
epoch 25: {'train_loss': '2.79812'}; time used = 1.344275712966919s
epoch 30: {'train_loss': '2.79336'}; time used = 1.3613557815551758s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.297979354858398.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6801346801346801, 'samples': 0.7368421052631579, 'weighted': 0.7013999645578592, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.74081'}; time used = 1.3911685943603516s
epoch 10: {'train_loss': '2.68036'}; time used = 1.3073413372039795s
epoch 15: {'train_loss': '2.57154'}; time used = 0.982872724533081s
epoch 20: {'train_loss': '2.41289'}; time used = 0.9110238552093506s
epoch 25: {'train_loss': '2.20120'}; time used = 0.9241237640380859s
epoch 30: {'train_loss': '2.28263'}; time used = 0.9117553234100342s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.397762298583984.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.36193'}; time used = 1.9401946067810059s
epoch 10: {'train_loss': '1.25814'}; time used = 1.7323014736175537s
epoch 15: {'train_loss': '1.18710'}; time used = 1.713421106338501s
epoch 20: {'train_loss': '1.21766'}; time used = 1.747969388961792s
epoch 25: {'train_loss': '1.15365'}; time used = 1.7654879093170166s
epoch 30: {'train_loss': '0.94576'}; time used = 1.8114345073699951s
epoch 35: {'train_loss': '0.70078'}; time used = 1.930100440979004s
epoch 40: {'train_loss': '0.67489'}; time used = 2.065049648284912s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.63147759437561.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '3.07778'}; time used = 1.3156869411468506s
epoch 10: {'train_loss': '2.89350'}; time used = 1.2116117477416992s
epoch 15: {'train_loss': '2.83916'}; time used = 1.1539666652679443s
epoch 20: {'train_loss': '2.78973'}; time used = 1.1297221183776855s
epoch 25: {'train_loss': '2.70586'}; time used = 1.142242670059204s
epoch 30: {'train_loss': '2.59645'}; time used = 1.1207239627838135s
epoch 35: {'train_loss': '2.43229'}; time used = 1.0917534828186035s
epoch 40: {'train_loss': '2.30321'}; time used = 1.0837841033935547s
epoch 45: {'train_loss': '2.26830'}; time used = 1.2433018684387207s
epoch 50: {'train_loss': '2.25419'}; time used = 1.2386691570281982s
epoch 55: {'train_loss': '2.19954'}; time used = 1.0183334350585938s
epoch 60: {'train_loss': '2.19164'}; time used = 1.1942832469940186s
epoch 65: {'train_loss': '2.21993'}; time used = 1.261063575744629s
epoch 70: {'train_loss': '2.21677'}; time used = 1.0917422771453857s
epoch 75: {'train_loss': '2.15685'}; time used = 1.1024680137634277s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.794944763183594.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.82 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.22637'}; time used = 2.020143985748291s
epoch 10: {'train_loss': '3.08833'}; time used = 1.804802417755127s
epoch 15: {'train_loss': '2.94099'}; time used = 1.7992699146270752s
epoch 20: {'train_loss': '2.82474'}; time used = 1.8626558780670166s
epoch 25: {'train_loss': '2.74037'}; time used = 1.880885362625122s
epoch 30: {'train_loss': '2.66644'}; time used = 1.7502851486206055s
epoch 35: {'train_loss': '2.62783'}; time used = 1.753741979598999s
epoch 40: {'train_loss': '2.56746'}; time used = 1.7474040985107422s
epoch 45: {'train_loss': '2.52945'}; time used = 1.7739946842193604s
epoch 50: {'train_loss': '2.49657'}; time used = 1.759474754333496s
epoch 55: {'train_loss': '2.49386'}; time used = 1.8635995388031006s
epoch 60: {'train_loss': '2.48905'}; time used = 1.725337028503418s
epoch 65: {'train_loss': '2.47682'}; time used = 3.0009870529174805s
epoch 70: {'train_loss': '2.46593'}; time used = 2.1282870769500732s
epoch 75: {'train_loss': '2.46951'}; time used = 1.7773680686950684s
epoch 80: {'train_loss': '2.43968'}; time used = 1.8147773742675781s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.798234701156616.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 4.48949933052063s
epoch 10: {'train_loss': '1.38629'}; time used = 4.277766704559326s
epoch 15: {'train_loss': '1.38629'}; time used = 4.323849678039551s
epoch 20: {'train_loss': '1.38629'}; time used = 4.679151773452759s
epoch 25: {'train_loss': '1.38629'}; time used = 4.365553617477417s
epoch 30: {'train_loss': '1.38629'}; time used = 4.475393295288086s
epoch 35: {'train_loss': '1.38629'}; time used = 4.678201913833618s
epoch 40: {'train_loss': '1.38629'}; time used = 6.423023700714111s
epoch 45: {'train_loss': '1.38629'}; time used = 4.513980865478516s
epoch 50: {'train_loss': '1.38629'}; time used = 4.355141639709473s
epoch 55: {'train_loss': '1.38629'}; time used = 4.597548007965088s
epoch 60: {'train_loss': '1.38629'}; time used = 4.6132824420928955s
epoch 65: {'train_loss': '1.38629'}; time used = 4.61792778968811s
epoch 70: {'train_loss': '1.38629'}; time used = 4.550554513931274s
epoch 75: {'train_loss': '1.38629'}; time used = 5.078039884567261s
epoch 80: {'train_loss': '1.38629'}; time used = 7.799046039581299s
epoch 85: {'train_loss': '1.38629'}; time used = 4.937613487243652s
epoch 90: {'train_loss': '1.38629'}; time used = 4.591351270675659s
epoch 95: {'train_loss': '1.38629'}; time used = 4.807628154754639s
epoch 100: {'train_loss': '1.38629'}; time used = 4.6510679721832275s
epoch 105: {'train_loss': '1.38629'}; time used = 4.775221347808838s
epoch 110: {'train_loss': '1.38629'}; time used = 4.975864887237549s
epoch 115: {'train_loss': '1.38629'}; time used = 4.695362329483032s
epoch 120: {'train_loss': '1.38629'}; time used = 5.941518783569336s
epoch 125: {'train_loss': '1.38629'}; time used = 7.055535554885864s
epoch 130: {'train_loss': '1.38629'}; time used = 4.42308497428894s
epoch 135: {'train_loss': '1.38629'}; time used = 4.2125139236450195s
epoch 140: {'train_loss': '1.38629'}; time used = 4.231938123703003s
epoch 145: {'train_loss': '1.38629'}; time used = 4.161495685577393s
epoch 150: {'train_loss': '1.38629'}; time used = 4.329499006271362s
epoch 155: {'train_loss': '1.38629'}; time used = 4.2696027755737305s
epoch 160: {'train_loss': '1.38629'}; time used = 4.247616291046143s
epoch 165: {'train_loss': '1.38629'}; time used = 4.807177305221558s
epoch 170: {'train_loss': '1.38629'}; time used = 4.939974308013916s
epoch 175: {'train_loss': '1.38629'}; time used = 4.328087091445923s
epoch 180: {'train_loss': '1.38629'}; time used = 4.216372489929199s
epoch 185: {'train_loss': '1.38629'}; time used = 4.1791369915008545s
epoch 190: {'train_loss': '1.38629'}; time used = 4.230851411819458s
epoch 195: {'train_loss': '1.38629'}; time used = 4.1510114669799805s
epoch 200: {'train_loss': '1.38629'}; time used = 4.42917013168335s
epoch 205: {'train_loss': '1.38629'}; time used = 4.990471363067627s
epoch 210: {'train_loss': '1.38629'}; time used = 4.736958742141724s
epoch 215: {'train_loss': '1.38629'}; time used = 4.234370946884155s
epoch 220: {'train_loss': '1.38629'}; time used = 4.266766786575317s
epoch 225: {'train_loss': '1.38629'}; time used = 4.338101863861084s
epoch 230: {'train_loss': '1.38629'}; time used = 4.969709396362305s
epoch 235: {'train_loss': '1.38629'}; time used = 7.174984693527222s
epoch 240: {'train_loss': '1.38629'}; time used = 4.429256439208984s
epoch 245: {'train_loss': '1.38629'}; time used = 4.2048327922821045s
epoch 250: {'train_loss': '1.38629'}; time used = 4.25408411026001s
epoch 255: {'train_loss': '1.38629'}; time used = 4.181347370147705s
epoch 260: {'train_loss': '1.38629'}; time used = 4.248141765594482s
epoch 265: {'train_loss': '1.38629'}; time used = 4.2256104946136475s
epoch 270: {'train_loss': '1.38629'}; time used = 4.4205002784729s
epoch 275: {'train_loss': '1.38629'}; time used = 4.696386814117432s
epoch 280: {'train_loss': '1.38629'}; time used = 4.932142019271851s
epoch 285: {'train_loss': '1.38629'}; time used = 5.095593690872192s
epoch 290: {'train_loss': '1.38629'}; time used = 4.99541711807251s
epoch 295: {'train_loss': '1.38629'}; time used = 5.01924204826355s
epoch 300: {'train_loss': '1.38629'}; time used = 4.9889442920684814s
epoch 305: {'train_loss': '1.38629'}; time used = 4.947712421417236s
epoch 310: {'train_loss': '1.38629'}; time used = 4.992335081100464s
epoch 315: {'train_loss': '1.38629'}; time used = 4.285145282745361s
epoch 320: {'train_loss': '1.38629'}; time used = 4.510265350341797s
epoch 325: {'train_loss': '1.38629'}; time used = 4.311249017715454s
epoch 330: {'train_loss': '1.38629'}; time used = 4.454743385314941s
epoch 335: {'train_loss': '1.38629'}; time used = 4.264150857925415s
epoch 340: {'train_loss': '1.38629'}; time used = 4.354218006134033s
epoch 345: {'train_loss': '1.38629'}; time used = 4.506730794906616s
epoch 350: {'train_loss': '1.38629'}; time used = 4.841012954711914s
epoch 355: {'train_loss': '1.38629'}; time used = 4.1880152225494385s
epoch 360: {'train_loss': '1.38629'}; time used = 4.2254860401153564s
epoch 365: {'train_loss': '1.38629'}; time used = 4.24811863899231s
epoch 370: {'train_loss': '1.38629'}; time used = 5.930569410324097s
epoch 375: {'train_loss': '1.38629'}; time used = 4.2927892208099365s
epoch 380: {'train_loss': '1.38629'}; time used = 4.34395432472229s
epoch 385: {'train_loss': '1.38629'}; time used = 4.245728015899658s
epoch 390: {'train_loss': '1.38629'}; time used = 4.4036829471588135s
epoch 395: {'train_loss': '1.38629'}; time used = 4.188686847686768s
epoch 400: {'train_loss': '1.38629'}; time used = 4.4573974609375s
epoch 405: {'train_loss': '1.38629'}; time used = 4.297972679138184s
epoch 410: {'train_loss': '1.38629'}; time used = 4.267136335372925s
epoch 415: {'train_loss': '1.38629'}; time used = 4.40952467918396s
epoch 420: {'train_loss': '1.38629'}; time used = 4.5170676708221436s
epoch 425: {'train_loss': '1.38629'}; time used = 4.287428140640259s
epoch 430: {'train_loss': '1.38629'}; time used = 4.328173637390137s
epoch 435: {'train_loss': '1.38629'}; time used = 4.31780481338501s
epoch 440: {'train_loss': '1.38629'}; time used = 4.197630405426025s
epoch 445: {'train_loss': '1.38629'}; time used = 4.312326908111572s
epoch 450: {'train_loss': '1.38629'}; time used = 4.279520750045776s
epoch 455: {'train_loss': '1.38629'}; time used = 4.61237907409668s
epoch 460: {'train_loss': '1.38629'}; time used = 4.277566194534302s
epoch 465: {'train_loss': '1.38629'}; time used = 4.400763511657715s
epoch 470: {'train_loss': '1.38629'}; time used = 4.402341842651367s
epoch 475: {'train_loss': '1.38629'}; time used = 4.495315790176392s
epoch 480: {'train_loss': '1.38629'}; time used = 4.408090353012085s
epoch 485: {'train_loss': '1.38629'}; time used = 6.2809789180755615s
epoch 490: {'train_loss': '1.38629'}; time used = 6.0025224685668945s
epoch 495: {'train_loss': '1.38629'}; time used = 4.267483949661255s
epoch 500: {'train_loss': '1.38629'}; time used = 4.3906848430633545s
Finished training. Time used = 472.28945803642273.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.77482'}; time used = 1.8650906085968018s
epoch 10: {'train_loss': '2.77016'}; time used = 1.8984971046447754s
epoch 15: {'train_loss': '2.76524'}; time used = 1.7988455295562744s
epoch 20: {'train_loss': '2.75431'}; time used = 1.8131790161132812s
epoch 25: {'train_loss': '2.75021'}; time used = 1.8290374279022217s
epoch 30: {'train_loss': '2.74344'}; time used = 1.7727863788604736s
epoch 35: {'train_loss': '2.74321'}; time used = 1.7976300716400146s
epoch 40: {'train_loss': '2.74386'}; time used = 1.781609058380127s
epoch 45: {'train_loss': '2.74161'}; time used = 1.9257514476776123s
epoch 50: {'train_loss': '2.73726'}; time used = 1.9318745136260986s
epoch 55: {'train_loss': '2.74150'}; time used = 1.8259916305541992s
epoch 60: {'train_loss': '2.73054'}; time used = 1.8103842735290527s
epoch 65: {'train_loss': '2.73485'}; time used = 1.8996896743774414s
epoch 70: {'train_loss': '2.73775'}; time used = 1.8891780376434326s
epoch 75: {'train_loss': '2.72885'}; time used = 1.8551599979400635s
epoch 80: {'train_loss': '2.73384'}; time used = 1.9137747287750244s
epoch 85: {'train_loss': '2.73737'}; time used = 1.8465886116027832s
epoch 90: {'train_loss': '2.72814'}; time used = 1.7838034629821777s
epoch 95: {'train_loss': '2.72419'}; time used = 1.8426461219787598s
epoch 100: {'train_loss': '2.73260'}; time used = 1.797654390335083s
epoch 105: {'train_loss': '2.72869'}; time used = 1.855989933013916s
epoch 110: {'train_loss': '2.73162'}; time used = 1.7645702362060547s
epoch 115: {'train_loss': '2.71591'}; time used = 2.020266532897949s
epoch 120: {'train_loss': '2.72083'}; time used = 1.8104119300842285s
epoch 125: {'train_loss': '2.72182'}; time used = 3.3399646282196045s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 52.300450563430786.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.94984'}; time used = 1.5849847793579102s
epoch 10: {'train_loss': '2.84253'}; time used = 1.5014524459838867s
epoch 15: {'train_loss': '2.81684'}; time used = 1.3836257457733154s
epoch 20: {'train_loss': '2.79039'}; time used = 1.469484806060791s
epoch 25: {'train_loss': '2.79676'}; time used = 1.316979169845581s
epoch 30: {'train_loss': '2.78777'}; time used = 1.2805325984954834s
epoch 35: {'train_loss': '2.78633'}; time used = 2.254331588745117s
epoch 40: {'train_loss': '2.78579'}; time used = 2.6493754386901855s
epoch 45: {'train_loss': '2.78890'}; time used = 2.6335346698760986s
epoch 50: {'train_loss': '2.78523'}; time used = 2.4937150478363037s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.290992975234985.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 4.835254430770874s
epoch 10: {'train_loss': '1.38629'}; time used = 4.452511310577393s
epoch 15: {'train_loss': '1.38629'}; time used = 4.722501754760742s
epoch 20: {'train_loss': '1.38629'}; time used = 4.707848072052002s
epoch 25: {'train_loss': '1.38629'}; time used = 4.617648601531982s
epoch 30: {'train_loss': '1.38629'}; time used = 4.3280556201934814s
epoch 35: {'train_loss': '1.38629'}; time used = 4.469749689102173s
epoch 40: {'train_loss': '1.38629'}; time used = 4.523160696029663s
epoch 45: {'train_loss': '1.38629'}; time used = 5.169243335723877s
epoch 50: {'train_loss': '1.38629'}; time used = 6.548675060272217s
epoch 55: {'train_loss': '1.38629'}; time used = 4.3906285762786865s
epoch 60: {'train_loss': '1.38629'}; time used = 4.245432376861572s
epoch 65: {'train_loss': '1.38629'}; time used = 4.229485273361206s
epoch 70: {'train_loss': '1.38629'}; time used = 4.361777067184448s
epoch 75: {'train_loss': '1.38629'}; time used = 4.158097267150879s
epoch 80: {'train_loss': '1.38629'}; time used = 4.165202617645264s
epoch 85: {'train_loss': '1.38629'}; time used = 4.229200839996338s
epoch 90: {'train_loss': '1.38629'}; time used = 4.311250448226929s
epoch 95: {'train_loss': '1.38629'}; time used = 4.389232635498047s
epoch 100: {'train_loss': '1.38629'}; time used = 4.4944658279418945s
epoch 105: {'train_loss': '1.38629'}; time used = 4.100118637084961s
epoch 110: {'train_loss': '1.38629'}; time used = 4.2027976512908936s
epoch 115: {'train_loss': '1.38629'}; time used = 4.196958065032959s
epoch 120: {'train_loss': '1.38629'}; time used = 4.499173164367676s
epoch 125: {'train_loss': '1.38629'}; time used = 4.444627285003662s
epoch 130: {'train_loss': '1.38629'}; time used = 4.241033554077148s
epoch 135: {'train_loss': '1.38629'}; time used = 4.200204372406006s
epoch 140: {'train_loss': '1.38629'}; time used = 4.252233982086182s
epoch 145: {'train_loss': '1.38629'}; time used = 4.247880697250366s
epoch 150: {'train_loss': '1.38629'}; time used = 4.2761619091033936s
epoch 155: {'train_loss': '1.38629'}; time used = 4.365674734115601s
epoch 160: {'train_loss': '1.38629'}; time used = 4.185814142227173s
epoch 165: {'train_loss': '1.38629'}; time used = 4.210269212722778s
epoch 170: {'train_loss': '1.38629'}; time used = 4.146645545959473s
epoch 175: {'train_loss': '1.38629'}; time used = 4.263453722000122s
epoch 180: {'train_loss': '1.38629'}; time used = 4.304544925689697s
epoch 185: {'train_loss': '1.38629'}; time used = 4.357576131820679s
epoch 190: {'train_loss': '1.38629'}; time used = 7.279233694076538s
epoch 195: {'train_loss': '1.38629'}; time used = 6.073992967605591s
epoch 200: {'train_loss': '1.38629'}; time used = 4.43110990524292s
epoch 205: {'train_loss': '1.38629'}; time used = 4.390707969665527s
epoch 210: {'train_loss': '1.38629'}; time used = 7.325089454650879s
epoch 215: {'train_loss': '1.38629'}; time used = 5.210183620452881s
epoch 220: {'train_loss': '1.38629'}; time used = 4.210171461105347s
epoch 225: {'train_loss': '1.38629'}; time used = 4.1847639083862305s
epoch 230: {'train_loss': '1.38629'}; time used = 4.207448482513428s
epoch 235: {'train_loss': '1.38629'}; time used = 4.136200904846191s
epoch 240: {'train_loss': '1.38629'}; time used = 4.223791837692261s
epoch 245: {'train_loss': '1.38629'}; time used = 7.1851887702941895s
epoch 250: {'train_loss': '1.38629'}; time used = 5.241487741470337s
epoch 255: {'train_loss': '1.38629'}; time used = 4.295098781585693s
epoch 260: {'train_loss': '1.38629'}; time used = 4.264178514480591s
epoch 265: {'train_loss': '1.38629'}; time used = 6.32127833366394s
epoch 270: {'train_loss': '1.38629'}; time used = 6.2300474643707275s
epoch 275: {'train_loss': '1.38629'}; time used = 4.29361629486084s
epoch 280: {'train_loss': '1.38629'}; time used = 4.1066083908081055s
epoch 285: {'train_loss': '1.38629'}; time used = 4.26732873916626s
epoch 290: {'train_loss': '1.38629'}; time used = 4.181624174118042s
epoch 295: {'train_loss': '1.38629'}; time used = 4.117337703704834s
epoch 300: {'train_loss': '1.38629'}; time used = 4.126102924346924s
epoch 305: {'train_loss': '1.38629'}; time used = 4.08336877822876s
epoch 310: {'train_loss': '1.38629'}; time used = 4.326363801956177s
epoch 315: {'train_loss': '1.38629'}; time used = 4.398600816726685s
epoch 320: {'train_loss': '1.38629'}; time used = 4.249849081039429s
epoch 325: {'train_loss': '1.38629'}; time used = 4.271196603775024s
epoch 330: {'train_loss': '1.38629'}; time used = 4.768238067626953s
epoch 335: {'train_loss': '1.38629'}; time used = 4.26061749458313s
epoch 340: {'train_loss': '1.38629'}; time used = 4.336215496063232s
epoch 345: {'train_loss': '1.38629'}; time used = 4.266948461532593s
epoch 350: {'train_loss': '1.38629'}; time used = 4.362462282180786s
epoch 355: {'train_loss': '1.38629'}; time used = 4.313460350036621s
epoch 360: {'train_loss': '1.38629'}; time used = 5.495967864990234s
epoch 365: {'train_loss': '1.38629'}; time used = 4.983043670654297s
epoch 370: {'train_loss': '1.38629'}; time used = 4.203402042388916s
epoch 375: {'train_loss': '1.38629'}; time used = 4.211933135986328s
epoch 380: {'train_loss': '1.38629'}; time used = 4.423701763153076s
epoch 385: {'train_loss': '1.38629'}; time used = 4.315411329269409s
epoch 390: {'train_loss': '1.38629'}; time used = 4.140782594680786s
epoch 395: {'train_loss': '1.38629'}; time used = 4.087547063827515s
epoch 400: {'train_loss': '1.38629'}; time used = 4.119843482971191s
epoch 405: {'train_loss': '1.38629'}; time used = 4.108898639678955s
epoch 410: {'train_loss': '1.38629'}; time used = 4.332759857177734s
epoch 415: {'train_loss': '1.38629'}; time used = 4.167320966720581s
epoch 420: {'train_loss': '1.38629'}; time used = 6.077405691146851s
epoch 425: {'train_loss': '1.38629'}; time used = 6.155335426330566s
epoch 430: {'train_loss': '1.38629'}; time used = 4.193970680236816s
epoch 435: {'train_loss': '1.38629'}; time used = 4.29062557220459s
epoch 440: {'train_loss': '1.38629'}; time used = 4.319541692733765s
epoch 445: {'train_loss': '1.38629'}; time used = 4.253500699996948s
epoch 450: {'train_loss': '1.38629'}; time used = 4.309009552001953s
epoch 455: {'train_loss': '1.38629'}; time used = 4.265856504440308s
epoch 460: {'train_loss': '1.38629'}; time used = 4.0984556674957275s
epoch 465: {'train_loss': '1.38629'}; time used = 4.445152044296265s
epoch 470: {'train_loss': '1.38629'}; time used = 6.24952244758606s
epoch 475: {'train_loss': '1.38629'}; time used = 4.465130805969238s
epoch 480: {'train_loss': '1.38629'}; time used = 4.228896141052246s
epoch 485: {'train_loss': '1.38629'}; time used = 6.419455289840698s
epoch 490: {'train_loss': '1.38629'}; time used = 6.353254556655884s
epoch 495: {'train_loss': '1.38629'}; time used = 4.349475622177124s
epoch 500: {'train_loss': '1.38629'}; time used = 4.3970558643341064s
Finished training. Time used = 470.67313838005066.
Training classifier using 80.00% nodes...
{'micro': 0.69, 'macro': 0.6888799678843838, 'samples': 0.69, 'weighted': 0.688506623845845, 'accuracy': 0.69}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.32053'}; time used = 2.111006021499634s
epoch 10: {'train_loss': '2.80381'}; time used = 1.8476829528808594s
epoch 15: {'train_loss': '2.72433'}; time used = 1.721092700958252s
epoch 20: {'train_loss': '2.73135'}; time used = 2.9786248207092285s
epoch 25: {'train_loss': '2.68987'}; time used = 3.227881669998169s
epoch 30: {'train_loss': '2.66985'}; time used = 3.237403392791748s
epoch 35: {'train_loss': '2.66324'}; time used = 1.9118239879608154s
epoch 40: {'train_loss': '2.64748'}; time used = 3.587261438369751s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.913613080978394.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5490196078431372, 'samples': 0.5797101449275363, 'weighted': 0.557544757033248, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.83810'}; time used = 1.2385389804840088s
epoch 10: {'train_loss': '2.78783'}; time used = 1.0169017314910889s
epoch 15: {'train_loss': '2.77264'}; time used = 1.0114684104919434s
epoch 20: {'train_loss': '2.77648'}; time used = 1.0107526779174805s
epoch 25: {'train_loss': '2.77518'}; time used = 2.281217336654663s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.85888123512268.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.14589'}; time used = 2.650567054748535s
epoch 10: {'train_loss': '0.74239'}; time used = 2.6511008739471436s
epoch 15: {'train_loss': '0.50840'}; time used = 2.558433771133423s
epoch 20: {'train_loss': '0.39486'}; time used = 2.4086382389068604s
epoch 25: {'train_loss': '0.36636'}; time used = 2.4204883575439453s
epoch 30: {'train_loss': '0.45320'}; time used = 2.3584682941436768s
epoch 35: {'train_loss': '0.32277'}; time used = 2.4406535625457764s
epoch 40: {'train_loss': '0.31233'}; time used = 2.3477632999420166s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.343518018722534.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4668181818181818, 'samples': 0.5072463768115942, 'weighted': 0.4774571805006588, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.33878'}; time used = 3.7418689727783203s
epoch 10: {'train_loss': '1.60689'}; time used = 1.1115391254425049s
epoch 15: {'train_loss': '1.39092'}; time used = 0.9864490032196045s
epoch 20: {'train_loss': '1.58400'}; time used = 1.1017277240753174s
epoch 25: {'train_loss': '1.18642'}; time used = 1.1904575824737549s
epoch 30: {'train_loss': '1.43162'}; time used = 1.1434447765350342s
epoch 35: {'train_loss': '1.43147'}; time used = 1.1409931182861328s
epoch 40: {'train_loss': '1.19853'}; time used = 1.3382699489593506s
epoch 45: {'train_loss': '1.11629'}; time used = 1.1516528129577637s
epoch 50: {'train_loss': '1.06424'}; time used = 0.994866132736206s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.84958529472351.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.63465'}; time used = 0.983421802520752s
epoch 10: {'train_loss': '2.27186'}; time used = 0.8940796852111816s
epoch 15: {'train_loss': '1.96565'}; time used = 1.0400123596191406s
epoch 20: {'train_loss': '1.79182'}; time used = 1.105480670928955s
epoch 25: {'train_loss': '1.68618'}; time used = 0.9623651504516602s
epoch 30: {'train_loss': '1.65829'}; time used = 0.9991869926452637s
epoch 35: {'train_loss': '1.51617'}; time used = 1.3820178508758545s
epoch 40: {'train_loss': '1.61335'}; time used = 1.3209562301635742s
epoch 45: {'train_loss': '1.48660'}; time used = 1.326781988143921s
epoch 50: {'train_loss': '1.44854'}; time used = 1.7120201587677002s
epoch 55: {'train_loss': '1.44780'}; time used = 1.6267435550689697s
epoch 60: {'train_loss': '1.42332'}; time used = 1.8344388008117676s
epoch 65: {'train_loss': '1.41516'}; time used = 2.250150442123413s
epoch 70: {'train_loss': '1.36192'}; time used = 1.9674150943756104s
epoch 75: {'train_loss': '1.41409'}; time used = 2.106461763381958s
epoch 80: {'train_loss': '1.38059'}; time used = 2.010908365249634s
epoch 85: {'train_loss': '1.43355'}; time used = 1.843229055404663s
epoch 90: {'train_loss': '1.39682'}; time used = 1.7885894775390625s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.687236309051514.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7172619047619048, 'samples': 0.7368421052631579, 'weighted': 0.7290100250626566, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.16 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.17 GiB free; 45.65 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.80124'}; time used = 1.9893226623535156s
epoch 10: {'train_loss': '2.77207'}; time used = 1.8485496044158936s
epoch 15: {'train_loss': '2.75430'}; time used = 1.9395761489868164s
epoch 20: {'train_loss': '2.74911'}; time used = 2.111400604248047s
epoch 25: {'train_loss': '2.73869'}; time used = 3.392242670059204s
epoch 30: {'train_loss': '2.72134'}; time used = 2.992032051086426s
epoch 35: {'train_loss': '2.70737'}; time used = 3.44155216217041s
epoch 40: {'train_loss': '2.67494'}; time used = 2.9081599712371826s
epoch 45: {'train_loss': '2.63144'}; time used = 2.071136236190796s
epoch 50: {'train_loss': '2.57410'}; time used = 1.9640004634857178s
epoch 55: {'train_loss': '2.52997'}; time used = 2.068129062652588s
epoch 60: {'train_loss': '2.50880'}; time used = 2.0491180419921875s
epoch 65: {'train_loss': '2.46655'}; time used = 2.0270042419433594s
epoch 70: {'train_loss': '2.45224'}; time used = 1.98240065574646s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.66173958778381.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.03631'}; time used = 1.4853904247283936s
epoch 10: {'train_loss': '0.64686'}; time used = 1.259692668914795s
epoch 15: {'train_loss': '0.44683'}; time used = 1.2649738788604736s
epoch 20: {'train_loss': '0.27608'}; time used = 1.2811884880065918s
epoch 25: {'train_loss': '0.26307'}; time used = 1.338308572769165s
epoch 30: {'train_loss': '0.17975'}; time used = 1.5763309001922607s
epoch 35: {'train_loss': '0.14593'}; time used = 1.4193196296691895s
epoch 40: {'train_loss': '0.12357'}; time used = 1.5375914573669434s
epoch 45: {'train_loss': '0.17317'}; time used = 1.2929093837738037s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.694988250732422.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6695652173913045, 'samples': 0.6842105263157895, 'weighted': 0.6805491990846683, 'accuracy': 0.6842105263157895}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.75387'}; time used = 1.6861531734466553s
epoch 10: {'train_loss': '2.70450'}; time used = 1.6332039833068848s
epoch 15: {'train_loss': '2.68465'}; time used = 1.6517343521118164s
epoch 20: {'train_loss': '2.67600'}; time used = 1.6394011974334717s
epoch 25: {'train_loss': '2.66542'}; time used = 1.7384626865386963s
epoch 30: {'train_loss': '2.65697'}; time used = 1.6374061107635498s
epoch 35: {'train_loss': '2.65355'}; time used = 1.6174402236938477s
epoch 40: {'train_loss': '2.64865'}; time used = 1.630953311920166s
epoch 45: {'train_loss': '2.64044'}; time used = 1.6564311981201172s
epoch 50: {'train_loss': '2.62456'}; time used = 1.6366710662841797s
epoch 55: {'train_loss': '2.62067'}; time used = 3.1475603580474854s
epoch 60: {'train_loss': '2.61959'}; time used = 2.0568344593048096s
epoch 65: {'train_loss': '2.60124'}; time used = 1.594757080078125s
epoch 70: {'train_loss': '2.58912'}; time used = 2.2363314628601074s
epoch 75: {'train_loss': '2.58160'}; time used = 1.675091028213501s
epoch 80: {'train_loss': '2.57710'}; time used = 1.7021267414093018s
epoch 85: {'train_loss': '2.57831'}; time used = 1.5543463230133057s
epoch 90: {'train_loss': '2.58290'}; time used = 1.5565471649169922s
epoch 95: {'train_loss': '2.57871'}; time used = 1.5995161533355713s
epoch 100: {'train_loss': '2.56996'}; time used = 1.5680325031280518s
epoch 105: {'train_loss': '2.57153'}; time used = 1.6183156967163086s
epoch 110: {'train_loss': '2.56856'}; time used = 1.5716257095336914s
epoch 115: {'train_loss': '2.56603'}; time used = 1.6354360580444336s
epoch 120: {'train_loss': '2.56692'}; time used = 2.3116304874420166s
epoch 125: {'train_loss': '2.56057'}; time used = 1.6338939666748047s
epoch 130: {'train_loss': '2.56549'}; time used = 1.6946687698364258s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 50.105735778808594.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.22146'}; time used = 3.6693716049194336s
epoch 10: {'train_loss': '1.17820'}; time used = 2.542691707611084s
epoch 15: {'train_loss': '1.12540'}; time used = 2.406449317932129s
epoch 20: {'train_loss': '0.82753'}; time used = 2.411975383758545s
epoch 25: {'train_loss': '0.87426'}; time used = 2.5057976245880127s
epoch 30: {'train_loss': '0.34036'}; time used = 2.368246078491211s
epoch 35: {'train_loss': '0.19175'}; time used = 2.4023239612579346s
epoch 40: {'train_loss': '0.11390'}; time used = 2.3782827854156494s
epoch 45: {'train_loss': '0.08630'}; time used = 2.7862703800201416s
epoch 50: {'train_loss': '0.02844'}; time used = 2.5528433322906494s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.3373863697052.
Training classifier using 80.00% nodes...
{'micro': 0.463768115942029, 'macro': 0.375030599755202, 'samples': 0.463768115942029, 'weighted': 0.3920955067142072, 'accuracy': 0.463768115942029}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77606'}; time used = 2.385695219039917s
epoch 10: {'train_loss': '2.77184'}; time used = 2.3587357997894287s
epoch 15: {'train_loss': '2.77090'}; time used = 2.3629651069641113s
epoch 20: {'train_loss': '2.76993'}; time used = 2.8706252574920654s
epoch 25: {'train_loss': '2.76572'}; time used = 2.785348415374756s
epoch 30: {'train_loss': '2.74990'}; time used = 3.1429569721221924s
epoch 35: {'train_loss': '2.71996'}; time used = 3.3980295658111572s
epoch 40: {'train_loss': '2.67329'}; time used = 2.987004041671753s
epoch 45: {'train_loss': '2.67576'}; time used = 2.012334108352661s
epoch 50: {'train_loss': '2.63151'}; time used = 1.9769618511199951s
epoch 55: {'train_loss': '2.61763'}; time used = 2.0635483264923096s
epoch 60: {'train_loss': '2.59690'}; time used = 2.0002541542053223s
epoch 65: {'train_loss': '2.58700'}; time used = 2.1614277362823486s
epoch 70: {'train_loss': '2.56220'}; time used = 2.0444681644439697s
epoch 75: {'train_loss': '2.51804'}; time used = 3.5360186100006104s
epoch 80: {'train_loss': '2.49388'}; time used = 3.282036542892456s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.42610549926758.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4828042328042328, 'samples': 0.5072463768115942, 'weighted': 0.4909516141400199, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.78010'}; time used = 4.990303039550781s
epoch 10: {'train_loss': '2.78323'}; time used = 4.611430644989014s
epoch 15: {'train_loss': '2.77394'}; time used = 7.905791759490967s
epoch 20: {'train_loss': '2.77327'}; time used = 5.88447380065918s
epoch 25: {'train_loss': '2.77554'}; time used = 4.991871118545532s
epoch 30: {'train_loss': '2.77456'}; time used = 5.12715744972229s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.590247631073.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37801'}; time used = 2.8757431507110596s
epoch 10: {'train_loss': '1.35158'}; time used = 2.873491048812866s
epoch 15: {'train_loss': '1.38082'}; time used = 3.0724551677703857s
epoch 20: {'train_loss': '1.44612'}; time used = 2.892727851867676s
epoch 25: {'train_loss': '1.42444'}; time used = 2.7258071899414062s
epoch 30: {'train_loss': '1.36374'}; time used = 2.634847640991211s
epoch 35: {'train_loss': '1.23277'}; time used = 2.597853899002075s
epoch 40: {'train_loss': '1.10923'}; time used = 2.768907070159912s
epoch 45: {'train_loss': '1.05806'}; time used = 2.67291259765625s
epoch 50: {'train_loss': '0.86066'}; time used = 2.70866322517395s
epoch 55: {'train_loss': '0.73505'}; time used = 2.8049845695495605s
epoch 60: {'train_loss': '0.93493'}; time used = 2.830810546875s
epoch 65: {'train_loss': '0.94542'}; time used = 2.6720244884490967s
epoch 70: {'train_loss': '0.88603'}; time used = 2.9266319274902344s
epoch 75: {'train_loss': '0.82350'}; time used = 4.368256568908691s
epoch 80: {'train_loss': '0.70743'}; time used = 4.17364764213562s
epoch 85: {'train_loss': '0.77968'}; time used = 2.824965238571167s
epoch 90: {'train_loss': '0.65859'}; time used = 2.720954179763794s
epoch 95: {'train_loss': '0.59237'}; time used = 2.748610019683838s
epoch 100: {'train_loss': '0.75581'}; time used = 2.7768001556396484s
epoch 105: {'train_loss': '0.43189'}; time used = 3.2614526748657227s
epoch 110: {'train_loss': '0.66636'}; time used = 4.248828649520874s
epoch 115: {'train_loss': '0.51356'}; time used = 3.6165013313293457s
epoch 120: {'train_loss': '0.46274'}; time used = 2.6912901401519775s
epoch 125: {'train_loss': '0.15865'}; time used = 2.6214802265167236s
epoch 130: {'train_loss': '0.20977'}; time used = 2.6994130611419678s
epoch 135: {'train_loss': '0.23670'}; time used = 2.6188838481903076s
epoch 140: {'train_loss': '0.32108'}; time used = 3.3149807453155518s
epoch 145: {'train_loss': '0.21288'}; time used = 4.093975067138672s
epoch 150: {'train_loss': '0.32556'}; time used = 4.120561361312866s
epoch 155: {'train_loss': '0.08617'}; time used = 2.6607110500335693s
epoch 160: {'train_loss': '1.65610'}; time used = 2.5602376461029053s
epoch 165: {'train_loss': '1.15766'}; time used = 2.6376073360443115s
epoch 170: {'train_loss': '1.32207'}; time used = 2.6513681411743164s
epoch 175: {'train_loss': '1.42244'}; time used = 2.764247417449951s
epoch 180: {'train_loss': '1.36353'}; time used = 2.7376368045806885s
epoch 185: {'train_loss': '1.37844'}; time used = 2.7627687454223633s
epoch 190: {'train_loss': '1.41382'}; time used = 2.6695425510406494s
epoch 195: {'train_loss': '1.36328'}; time used = 2.764411449432373s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 123.06006240844727.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5295454545454545, 'samples': 0.5652173913043478, 'weighted': 0.5389328063241107, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.75918'}; time used = 2.4772846698760986s
epoch 10: {'train_loss': '2.75441'}; time used = 2.4115560054779053s
epoch 15: {'train_loss': '2.74242'}; time used = 2.350829839706421s
epoch 20: {'train_loss': '2.70357'}; time used = 2.368105411529541s
epoch 25: {'train_loss': '2.65793'}; time used = 2.4459025859832764s
epoch 30: {'train_loss': '2.62146'}; time used = 2.370197296142578s
epoch 35: {'train_loss': '2.55952'}; time used = 2.3703861236572266s
epoch 40: {'train_loss': '2.54024'}; time used = 2.3948585987091064s
epoch 45: {'train_loss': '2.50688'}; time used = 2.3936827182769775s
epoch 50: {'train_loss': '2.51022'}; time used = 2.401474714279175s
epoch 55: {'train_loss': '2.48007'}; time used = 2.584707498550415s
epoch 60: {'train_loss': '2.48447'}; time used = 2.6136927604675293s
epoch 65: {'train_loss': '2.44848'}; time used = 2.5229949951171875s
epoch 70: {'train_loss': '2.41744'}; time used = 2.4085206985473633s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.974416971206665.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38065'}; time used = 1.753401517868042s
epoch 10: {'train_loss': '1.33833'}; time used = 1.68495512008667s
epoch 15: {'train_loss': '1.35206'}; time used = 1.9885070323944092s
epoch 20: {'train_loss': '1.37426'}; time used = 2.401209592819214s
epoch 25: {'train_loss': '1.20091'}; time used = 2.4357151985168457s
epoch 30: {'train_loss': '1.39744'}; time used = 2.0433406829833984s
epoch 35: {'train_loss': '1.36984'}; time used = 1.956181287765503s
epoch 40: {'train_loss': '1.33129'}; time used = 1.8643720149993896s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.825759887695312.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5062611806797853, 'samples': 0.5362318840579711, 'weighted': 0.5150760934380751, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.66 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.39430'}; time used = 1.120847225189209s
epoch 10: {'train_loss': '1.39810'}; time used = 0.9749457836151123s
epoch 15: {'train_loss': '1.29130'}; time used = 1.0015637874603271s
epoch 20: {'train_loss': '1.32147'}; time used = 1.0058376789093018s
epoch 25: {'train_loss': '1.15285'}; time used = 1.0206141471862793s
epoch 30: {'train_loss': '1.21301'}; time used = 0.9969770908355713s
epoch 35: {'train_loss': '1.30688'}; time used = 1.0071852207183838s
epoch 40: {'train_loss': '1.23026'}; time used = 1.003694772720337s
epoch 45: {'train_loss': '1.06294'}; time used = 1.041834831237793s
epoch 50: {'train_loss': '1.17394'}; time used = 0.9951748847961426s
epoch 55: {'train_loss': '1.14927'}; time used = 1.1486308574676514s
epoch 60: {'train_loss': '1.15573'}; time used = 1.0053255558013916s
epoch 65: {'train_loss': '0.96313'}; time used = 0.9840803146362305s
epoch 70: {'train_loss': '1.19506'}; time used = 0.98724365234375s
epoch 75: {'train_loss': '1.23107'}; time used = 1.0046007633209229s
epoch 80: {'train_loss': '1.06562'}; time used = 1.031949758529663s
epoch 85: {'train_loss': '1.14495'}; time used = 1.0137243270874023s
epoch 90: {'train_loss': '1.15234'}; time used = 0.9942235946655273s
epoch 95: {'train_loss': '1.18551'}; time used = 1.0010485649108887s
epoch 100: {'train_loss': '1.12353'}; time used = 1.031407117843628s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.198214292526245.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35690'}; time used = 1.9117512702941895s
epoch 10: {'train_loss': '1.30284'}; time used = 1.9990487098693848s
epoch 15: {'train_loss': '1.23644'}; time used = 2.0442512035369873s
epoch 20: {'train_loss': '1.34980'}; time used = 1.9603891372680664s
epoch 25: {'train_loss': '1.23967'}; time used = 2.015151262283325s
epoch 30: {'train_loss': '1.11463'}; time used = 1.8442654609680176s
epoch 35: {'train_loss': '1.27112'}; time used = 1.8519618511199951s
epoch 40: {'train_loss': '1.11200'}; time used = 1.8034889698028564s
epoch 45: {'train_loss': '1.28719'}; time used = 1.8003959655761719s
epoch 50: {'train_loss': '1.12489'}; time used = 1.8806395530700684s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.9464054107666.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.5988372093023256, 'samples': 0.6231884057971014, 'weighted': 0.6059993259184361, 'accuracy': 0.6231884057971014}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.78059'}; time used = 1.0780448913574219s
epoch 10: {'train_loss': '2.77592'}; time used = 0.9738559722900391s
epoch 15: {'train_loss': '2.77567'}; time used = 0.9619185924530029s
epoch 20: {'train_loss': '2.77509'}; time used = 0.9627110958099365s
epoch 25: {'train_loss': '2.77211'}; time used = 0.9582374095916748s
epoch 30: {'train_loss': '2.77222'}; time used = 0.9368143081665039s
epoch 35: {'train_loss': '2.77001'}; time used = 0.963557243347168s
epoch 40: {'train_loss': '2.77047'}; time used = 0.9348533153533936s
epoch 45: {'train_loss': '2.76958'}; time used = 0.9660420417785645s
epoch 50: {'train_loss': '2.76775'}; time used = 0.9616148471832275s
epoch 55: {'train_loss': '2.76762'}; time used = 0.9672861099243164s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.919193506240845.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.5064935064935066, 'samples': 0.6052631578947368, 'weighted': 0.5413533834586466, 'accuracy': 0.6052631578947368}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.32507'}; time used = 1.0436105728149414s
epoch 10: {'train_loss': '0.16440'}; time used = 0.923438310623169s
epoch 15: {'train_loss': '0.10938'}; time used = 0.893805742263794s
epoch 20: {'train_loss': '0.12329'}; time used = 0.9112453460693359s
epoch 25: {'train_loss': '0.14875'}; time used = 0.9217901229858398s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.080445528030396.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.49 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.99647'}; time used = 1.201157569885254s
epoch 10: {'train_loss': '2.85763'}; time used = 1.0990595817565918s
epoch 15: {'train_loss': '2.82675'}; time used = 1.1016154289245605s
epoch 20: {'train_loss': '2.81376'}; time used = 1.0746655464172363s
epoch 25: {'train_loss': '2.79810'}; time used = 1.0987181663513184s
epoch 30: {'train_loss': '2.80572'}; time used = 1.0759329795837402s
epoch 35: {'train_loss': '2.79180'}; time used = 1.1083688735961914s
epoch 40: {'train_loss': '2.79548'}; time used = 1.0897190570831299s
epoch 45: {'train_loss': '2.79685'}; time used = 1.096010684967041s
epoch 50: {'train_loss': '2.78753'}; time used = 1.066831111907959s
epoch 55: {'train_loss': '2.78482'}; time used = 1.0823981761932373s
epoch 60: {'train_loss': '2.78482'}; time used = 1.07069993019104s
epoch 65: {'train_loss': '2.78183'}; time used = 1.074524164199829s
epoch 70: {'train_loss': '2.77405'}; time used = 1.1004788875579834s
epoch 75: {'train_loss': '2.78088'}; time used = 1.1048805713653564s
epoch 80: {'train_loss': '2.77749'}; time used = 1.1901803016662598s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.637629747390747.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.88932'}; time used = 1.253251552581787s
epoch 10: {'train_loss': '2.78692'}; time used = 1.0964903831481934s
epoch 15: {'train_loss': '2.77250'}; time used = 1.182257890701294s
epoch 20: {'train_loss': '2.77797'}; time used = 1.0147671699523926s
epoch 25: {'train_loss': '2.77668'}; time used = 0.9991772174835205s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.639224290847778.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89985'}; time used = 1.9170916080474854s
epoch 10: {'train_loss': '2.79227'}; time used = 1.733412742614746s
epoch 15: {'train_loss': '2.78223'}; time used = 1.685234785079956s
epoch 20: {'train_loss': '2.77880'}; time used = 1.7226791381835938s
epoch 25: {'train_loss': '2.77572'}; time used = 1.8719761371612549s
epoch 30: {'train_loss': '2.77258'}; time used = 1.7896206378936768s
epoch 35: {'train_loss': '2.76789'}; time used = 1.6731889247894287s
epoch 40: {'train_loss': '2.76506'}; time used = 1.9224512577056885s
epoch 45: {'train_loss': '2.75922'}; time used = 1.8065381050109863s
epoch 50: {'train_loss': '2.75263'}; time used = 1.8036739826202393s
epoch 55: {'train_loss': '2.73020'}; time used = 1.7270894050598145s
epoch 60: {'train_loss': '2.67237'}; time used = 1.7070295810699463s
epoch 65: {'train_loss': '2.64517'}; time used = 1.6860930919647217s
epoch 70: {'train_loss': '2.61194'}; time used = 1.6639807224273682s
epoch 75: {'train_loss': '2.52772'}; time used = 1.9761042594909668s
epoch 80: {'train_loss': '2.50406'}; time used = 1.9156625270843506s
epoch 85: {'train_loss': '2.51574'}; time used = 1.8677916526794434s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.70021605491638.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.518095238095238, 'samples': 0.5217391304347826, 'weighted': 0.5211318150448585, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.05641'}; time used = 1.8285353183746338s
epoch 10: {'train_loss': '1.01880'}; time used = 1.791332721710205s
epoch 15: {'train_loss': '0.97046'}; time used = 1.5912399291992188s
epoch 20: {'train_loss': '0.89693'}; time used = 1.736640453338623s
epoch 25: {'train_loss': '0.83345'}; time used = 2.0746445655822754s
epoch 30: {'train_loss': '0.72495'}; time used = 4.082644939422607s
epoch 35: {'train_loss': '0.40080'}; time used = 2.956380605697632s
epoch 40: {'train_loss': '0.51798'}; time used = 1.8832385540008545s
epoch 45: {'train_loss': '0.45046'}; time used = 1.8343226909637451s
epoch 50: {'train_loss': '0.31886'}; time used = 1.903782844543457s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.18545413017273.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4145927601809955, 'samples': 0.5652173913043478, 'weighted': 0.43611056462718867, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.50 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.04837'}; time used = 1.0197405815124512s
epoch 10: {'train_loss': '2.80355'}; time used = 0.9753165245056152s
epoch 15: {'train_loss': '2.69720'}; time used = 0.9088950157165527s
epoch 20: {'train_loss': '2.55187'}; time used = 0.9866800308227539s
epoch 25: {'train_loss': '2.33078'}; time used = 0.9708802700042725s
epoch 30: {'train_loss': '2.10267'}; time used = 0.9719433784484863s
epoch 35: {'train_loss': '2.01162'}; time used = 1.1508657932281494s
epoch 40: {'train_loss': '2.04148'}; time used = 0.9564197063446045s
epoch 45: {'train_loss': '1.94914'}; time used = 1.860410213470459s
epoch 50: {'train_loss': '1.93851'}; time used = 2.303649425506592s
epoch 55: {'train_loss': '1.90353'}; time used = 1.0027587413787842s
epoch 60: {'train_loss': '1.81903'}; time used = 1.099268913269043s
epoch 65: {'train_loss': '1.83349'}; time used = 0.9960052967071533s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.65682363510132.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87441'}; time used = 1.3756773471832275s
epoch 10: {'train_loss': '2.80377'}; time used = 1.200287103652954s
epoch 15: {'train_loss': '2.77701'}; time used = 1.1873869895935059s
epoch 20: {'train_loss': '2.77392'}; time used = 1.078486680984497s
epoch 25: {'train_loss': '2.77920'}; time used = 1.0216810703277588s
epoch 30: {'train_loss': '2.77615'}; time used = 0.9716827869415283s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.30043649673462.
Training classifier using 80.00% nodes...
{'micro': 0.5526315789473685, 'macro': 0.4406926406926407, 'samples': 0.5526315789473685, 'weighted': 0.4802005012531328, 'accuracy': 0.5526315789473685}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35127'}; time used = 1.212221622467041s
epoch 10: {'train_loss': '1.28599'}; time used = 1.181736946105957s
epoch 15: {'train_loss': '1.17795'}; time used = 1.1222522258758545s
epoch 20: {'train_loss': '1.12248'}; time used = 1.1293306350708008s
epoch 25: {'train_loss': '0.91605'}; time used = 1.139014482498169s
epoch 30: {'train_loss': '0.89191'}; time used = 1.2270121574401855s
epoch 35: {'train_loss': '1.05553'}; time used = 1.1401798725128174s
epoch 40: {'train_loss': '0.95986'}; time used = 1.1645698547363281s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.706918478012085.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6933235509904623, 'samples': 0.7105263157894737, 'weighted': 0.7047920608564698, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39736'}; time used = 2.513641357421875s
epoch 10: {'train_loss': '1.35337'}; time used = 2.469616413116455s
epoch 15: {'train_loss': '1.38843'}; time used = 2.708833932876587s
epoch 20: {'train_loss': '1.44606'}; time used = 2.5869221687316895s
epoch 25: {'train_loss': '1.43057'}; time used = 2.820836067199707s
epoch 30: {'train_loss': '1.39909'}; time used = 2.604736566543579s
epoch 35: {'train_loss': '1.38159'}; time used = 4.338174819946289s
epoch 40: {'train_loss': '1.35790'}; time used = 3.8420703411102295s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.535226821899414.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5174825174825175, 'samples': 0.6086956521739131, 'weighted': 0.53268470659775, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.45 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.31979'}; time used = 1.7091166973114014s
epoch 10: {'train_loss': '1.22630'}; time used = 1.7024915218353271s
epoch 15: {'train_loss': '1.14699'}; time used = 1.6658430099487305s
epoch 20: {'train_loss': '1.34946'}; time used = 1.674656629562378s
epoch 25: {'train_loss': '1.25850'}; time used = 1.781799554824829s
epoch 30: {'train_loss': '1.15399'}; time used = 1.794834852218628s
epoch 35: {'train_loss': '1.22916'}; time used = 1.7169954776763916s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.24144411087036.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5616648411829135, 'samples': 0.5797101449275363, 'weighted': 0.5681095925202788, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.37092'}; time used = 1.1779568195343018s
epoch 10: {'train_loss': '1.33511'}; time used = 1.1282496452331543s
epoch 15: {'train_loss': '1.24556'}; time used = 1.0920977592468262s
epoch 20: {'train_loss': '1.18576'}; time used = 1.1091434955596924s
epoch 25: {'train_loss': '1.05653'}; time used = 1.1426358222961426s
epoch 30: {'train_loss': '0.95065'}; time used = 1.082685947418213s
epoch 35: {'train_loss': '0.99848'}; time used = 1.1547067165374756s
epoch 40: {'train_loss': '0.91903'}; time used = 1.1558287143707275s
epoch 45: {'train_loss': '0.77891'}; time used = 1.3655810356140137s
epoch 50: {'train_loss': '0.88237'}; time used = 1.2650635242462158s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.250336170196533.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7548387096774194, 'samples': 0.7631578947368421, 'weighted': 0.7619694397283531, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.65 GiB already allocated; 1.25 GiB free; 25.50 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85461'}; time used = 1.060375690460205s
epoch 10: {'train_loss': '2.78953'}; time used = 0.966480016708374s
epoch 15: {'train_loss': '2.77369'}; time used = 0.9949884414672852s
epoch 20: {'train_loss': '2.78500'}; time used = 1.118574857711792s
epoch 25: {'train_loss': '2.77735'}; time used = 0.9014661312103271s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.296754121780396.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84705'}; time used = 6.654938459396362s
epoch 10: {'train_loss': '2.77653'}; time used = 6.625162601470947s
epoch 15: {'train_loss': '2.77996'}; time used = 8.462647199630737s
epoch 20: {'train_loss': '2.77662'}; time used = 10.070767879486084s
epoch 25: {'train_loss': '2.77132'}; time used = 10.185254335403442s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 65.11994433403015.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.29648'}; time used = 8.492144584655762s
epoch 10: {'train_loss': '1.32545'}; time used = 9.441171884536743s
epoch 15: {'train_loss': '1.26097'}; time used = 7.486528158187866s
epoch 20: {'train_loss': '1.20575'}; time used = 7.868549585342407s
epoch 25: {'train_loss': '1.13392'}; time used = 7.38775634765625s
epoch 30: {'train_loss': '1.18674'}; time used = 7.472381591796875s
epoch 35: {'train_loss': '0.90045'}; time used = 7.415092945098877s
epoch 40: {'train_loss': '1.15998'}; time used = 7.5154993534088135s
epoch 45: {'train_loss': '1.09855'}; time used = 7.005666494369507s
epoch 50: {'train_loss': '1.09578'}; time used = 7.132532358169556s
epoch 55: {'train_loss': '1.21930'}; time used = 7.693585634231567s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 109.12914180755615.
Training classifier using 80.00% nodes...
{'micro': 0.5166666666666667, 'macro': 0.47511814545547865, 'samples': 0.5166666666666667, 'weighted': 0.467581019002262, 'accuracy': 0.5166666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.34664'}; time used = 1.1748666763305664s
epoch 10: {'train_loss': '1.42391'}; time used = 1.0785479545593262s
epoch 15: {'train_loss': '0.39618'}; time used = 0.9761605262756348s
epoch 20: {'train_loss': '0.28107'}; time used = 0.9764719009399414s
epoch 25: {'train_loss': '0.03138'}; time used = 1.107367992401123s
epoch 30: {'train_loss': '0.07670'}; time used = 1.0011928081512451s
epoch 35: {'train_loss': '0.02824'}; time used = 0.9750568866729736s
epoch 40: {'train_loss': '0.81826'}; time used = 0.9887208938598633s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.05704665184021.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87441'}; time used = 1.3775408267974854s
epoch 10: {'train_loss': '2.80377'}; time used = 1.335278034210205s
epoch 15: {'train_loss': '2.77701'}; time used = 2.0342636108398438s
epoch 20: {'train_loss': '2.77392'}; time used = 2.2776968479156494s
epoch 25: {'train_loss': '2.77920'}; time used = 2.2268099784851074s
epoch 30: {'train_loss': '2.77615'}; time used = 2.385786533355713s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.522048473358154.
Training classifier using 80.00% nodes...
{'micro': 0.5526315789473685, 'macro': 0.4406926406926407, 'samples': 0.5526315789473685, 'weighted': 0.4802005012531328, 'accuracy': 0.5526315789473685}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.82 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 6.183221340179443s
epoch 10: {'train_loss': '1.38629'}; time used = 6.116724967956543s
epoch 15: {'train_loss': '1.38629'}; time used = 6.170935153961182s
epoch 20: {'train_loss': '1.38629'}; time used = 6.362904071807861s
epoch 25: {'train_loss': '1.38629'}; time used = 6.233022689819336s
epoch 30: {'train_loss': '1.38629'}; time used = 6.386837720870972s
epoch 35: {'train_loss': '1.38629'}; time used = 6.270721673965454s
epoch 40: {'train_loss': '1.38629'}; time used = 6.2744140625s
epoch 45: {'train_loss': '1.38629'}; time used = 6.522937059402466s
epoch 50: {'train_loss': '1.38629'}; time used = 6.203270673751831s
epoch 55: {'train_loss': '1.38629'}; time used = 6.331791639328003s
epoch 60: {'train_loss': '1.38629'}; time used = 6.930874586105347s
epoch 65: {'train_loss': '1.38629'}; time used = 6.171193838119507s
epoch 70: {'train_loss': '1.38629'}; time used = 6.241910219192505s
epoch 75: {'train_loss': '1.38629'}; time used = 7.472110271453857s
epoch 80: {'train_loss': '1.38629'}; time used = 6.32398533821106s
epoch 85: {'train_loss': '1.38629'}; time used = 6.341576337814331s
epoch 90: {'train_loss': '1.38629'}; time used = 6.378605365753174s
epoch 95: {'train_loss': '1.38629'}; time used = 6.213539123535156s
epoch 100: {'train_loss': '1.38629'}; time used = 6.16096305847168s
epoch 105: {'train_loss': '1.38629'}; time used = 6.179832696914673s
epoch 110: {'train_loss': '1.38629'}; time used = 6.825130939483643s
epoch 115: {'train_loss': '1.38629'}; time used = 7.172909736633301s
epoch 120: {'train_loss': '1.38629'}; time used = 6.641370058059692s
epoch 125: {'train_loss': '1.38629'}; time used = 6.169981241226196s
epoch 130: {'train_loss': '1.38629'}; time used = 6.109072685241699s
epoch 135: {'train_loss': '1.38629'}; time used = 6.097099542617798s
epoch 140: {'train_loss': '1.38629'}; time used = 6.1662633419036865s
epoch 145: {'train_loss': '1.38629'}; time used = 6.033979177474976s
epoch 150: {'train_loss': '1.38629'}; time used = 6.055148601531982s
epoch 155: {'train_loss': '1.38629'}; time used = 6.198217391967773s
epoch 160: {'train_loss': '1.38629'}; time used = 6.325444459915161s
epoch 165: {'train_loss': '1.38629'}; time used = 6.110841512680054s
epoch 170: {'train_loss': '1.38629'}; time used = 6.09330940246582s
epoch 175: {'train_loss': '1.38629'}; time used = 6.182367563247681s
epoch 180: {'train_loss': '1.38629'}; time used = 6.177691698074341s
epoch 185: {'train_loss': '1.38629'}; time used = 6.148223400115967s
epoch 190: {'train_loss': '1.38629'}; time used = 6.1189234256744385s
epoch 195: {'train_loss': '1.38629'}; time used = 6.084309339523315s
epoch 200: {'train_loss': '1.38629'}; time used = 6.172797918319702s
epoch 205: {'train_loss': '1.38629'}; time used = 6.205450773239136s
epoch 210: {'train_loss': '1.38629'}; time used = 7.216767311096191s
epoch 215: {'train_loss': '1.38629'}; time used = 6.273126840591431s
epoch 220: {'train_loss': '1.38629'}; time used = 6.308444499969482s
epoch 225: {'train_loss': '1.38629'}; time used = 6.436610460281372s
epoch 230: {'train_loss': '1.38629'}; time used = 6.303506135940552s
epoch 235: {'train_loss': '1.38629'}; time used = 6.192262887954712s
epoch 240: {'train_loss': '1.38629'}; time used = 6.216986656188965s
epoch 245: {'train_loss': '1.38629'}; time used = 6.176103830337524s
epoch 250: {'train_loss': '1.38629'}; time used = 6.254389762878418s
epoch 255: {'train_loss': '1.38629'}; time used = 6.326056003570557s
epoch 260: {'train_loss': '1.38629'}; time used = 6.2259533405303955s
epoch 265: {'train_loss': '1.38629'}; time used = 6.011002779006958s
epoch 270: {'train_loss': '1.38629'}; time used = 6.038113832473755s
epoch 275: {'train_loss': '1.38629'}; time used = 6.094617128372192s
epoch 280: {'train_loss': '1.38629'}; time used = 6.178063631057739s
epoch 285: {'train_loss': '1.38629'}; time used = 6.583313226699829s
epoch 290: {'train_loss': '1.38629'}; time used = 9.17861795425415s
epoch 295: {'train_loss': '1.38629'}; time used = 7.82820725440979s
epoch 300: {'train_loss': '1.38629'}; time used = 6.29483962059021s
epoch 305: {'train_loss': '1.38629'}; time used = 6.619399547576904s
epoch 310: {'train_loss': '1.38629'}; time used = 8.57250714302063s
epoch 315: {'train_loss': '1.38629'}; time used = 8.791480302810669s
epoch 320: {'train_loss': '1.38629'}; time used = 6.407153606414795s
epoch 325: {'train_loss': '1.38629'}; time used = 6.537069320678711s
epoch 330: {'train_loss': '1.38629'}; time used = 6.477069616317749s
epoch 335: {'train_loss': '1.38629'}; time used = 9.06817889213562s
epoch 340: {'train_loss': '1.38629'}; time used = 7.297037124633789s
epoch 345: {'train_loss': '1.38629'}; time used = 6.697942733764648s
epoch 350: {'train_loss': '1.38629'}; time used = 6.335458517074585s
epoch 355: {'train_loss': '1.38629'}; time used = 6.287623882293701s
epoch 360: {'train_loss': '1.38629'}; time used = 6.180455684661865s
epoch 365: {'train_loss': '1.38629'}; time used = 6.209226608276367s
epoch 370: {'train_loss': '1.38629'}; time used = 6.199415683746338s
epoch 375: {'train_loss': '1.38629'}; time used = 6.181910514831543s
epoch 380: {'train_loss': '1.38629'}; time used = 6.302973747253418s
epoch 385: {'train_loss': '1.38629'}; time used = 6.1503660678863525s
epoch 390: {'train_loss': '1.38629'}; time used = 6.168398380279541s
epoch 395: {'train_loss': '1.38629'}; time used = 6.638892412185669s
epoch 400: {'train_loss': '1.38629'}; time used = 6.592982053756714s
epoch 405: {'train_loss': '1.38629'}; time used = 6.509083271026611s
epoch 410: {'train_loss': '1.38629'}; time used = 6.234452247619629s
epoch 415: {'train_loss': '1.38629'}; time used = 7.537522315979004s
epoch 420: {'train_loss': '1.38629'}; time used = 6.812780857086182s
epoch 425: {'train_loss': '1.38629'}; time used = 9.368494033813477s
epoch 430: {'train_loss': '1.38629'}; time used = 6.347133636474609s
epoch 435: {'train_loss': '1.38629'}; time used = 6.923004865646362s
epoch 440: {'train_loss': '1.38629'}; time used = 6.323207139968872s
epoch 445: {'train_loss': '1.38629'}; time used = 7.165339231491089s
epoch 450: {'train_loss': '1.38629'}; time used = 6.1900129318237305s
epoch 455: {'train_loss': '1.38629'}; time used = 6.185449600219727s
epoch 460: {'train_loss': '1.38629'}; time used = 6.201371431350708s
epoch 465: {'train_loss': '1.38629'}; time used = 6.318391799926758s
epoch 470: {'train_loss': '1.38629'}; time used = 6.180823802947998s
epoch 475: {'train_loss': '1.38629'}; time used = 6.137391090393066s
epoch 480: {'train_loss': '1.38629'}; time used = 6.401726007461548s
epoch 485: {'train_loss': '1.38629'}; time used = 6.367481470108032s
epoch 490: {'train_loss': '1.38629'}; time used = 6.167273283004761s
epoch 495: {'train_loss': '1.38629'}; time used = 8.196159839630127s
epoch 500: {'train_loss': '1.38629'}; time used = 6.326643228530884s
Finished training. Time used = 660.258962392807.
Training classifier using 80.00% nodes...
{'micro': 0.32666666666666666, 'macro': 0.18259451161005566, 'samples': 0.32666666666666666, 'weighted': 0.17711667626175395, 'accuracy': 0.32666666666666666}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38235'}; time used = 1.3372292518615723s
epoch 10: {'train_loss': '1.39789'}; time used = 1.0226960182189941s
epoch 15: {'train_loss': '1.28103'}; time used = 1.169454574584961s
epoch 20: {'train_loss': '1.34319'}; time used = 1.0805885791778564s
epoch 25: {'train_loss': '1.19762'}; time used = 1.1825551986694336s
epoch 30: {'train_loss': '1.24579'}; time used = 1.0116174221038818s
epoch 35: {'train_loss': '1.26575'}; time used = 1.9246106147766113s
epoch 40: {'train_loss': '1.18500'}; time used = 1.2771706581115723s
epoch 45: {'train_loss': '1.06305'}; time used = 1.0621864795684814s
epoch 50: {'train_loss': '1.13187'}; time used = 1.0970571041107178s
epoch 55: {'train_loss': '1.18416'}; time used = 1.0397531986236572s
epoch 60: {'train_loss': '1.23856'}; time used = 1.0288467407226562s
epoch 65: {'train_loss': '1.11126'}; time used = 1.3012914657592773s
epoch 70: {'train_loss': '1.21572'}; time used = 1.2227158546447754s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.02622079849243.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.41188'}; time used = 10.946311712265015s
epoch 10: {'train_loss': '2.81930'}; time used = 7.3104164600372314s
epoch 15: {'train_loss': '2.82479'}; time used = 11.708126306533813s
epoch 20: {'train_loss': '2.83732'}; time used = 9.157047986984253s
epoch 25: {'train_loss': '2.82707'}; time used = 7.034154415130615s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 62.29318928718567.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.44913711583924343, 'samples': 0.5033333333333333, 'weighted': 0.44046300236406616, 'accuracy': 0.5033333333333333}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.08639'}; time used = 1.4727704524993896s
epoch 10: {'train_loss': '2.77580'}; time used = 1.301222324371338s
epoch 15: {'train_loss': '2.77350'}; time used = 1.3175926208496094s
epoch 20: {'train_loss': '2.77530'}; time used = 1.330111026763916s
epoch 25: {'train_loss': '2.77796'}; time used = 1.3205747604370117s
epoch 30: {'train_loss': '2.77991'}; time used = 1.2944390773773193s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.085844278335571.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 26.50 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.76 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.81567'}; time used = 1.9616799354553223s
epoch 10: {'train_loss': '0.86602'}; time used = 1.9092984199523926s
epoch 15: {'train_loss': '0.36228'}; time used = 1.771362543106079s
epoch 20: {'train_loss': '0.22586'}; time used = 1.6347994804382324s
epoch 25: {'train_loss': '0.22166'}; time used = 0.997042179107666s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.94244909286499.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36942'}; time used = 1.789893627166748s
epoch 10: {'train_loss': '1.28932'}; time used = 1.6861822605133057s
epoch 15: {'train_loss': '1.23958'}; time used = 1.7632737159729004s
epoch 20: {'train_loss': '1.27624'}; time used = 1.6672930717468262s
epoch 25: {'train_loss': '1.14966'}; time used = 1.832853078842163s
epoch 30: {'train_loss': '1.02838'}; time used = 1.6711866855621338s
epoch 35: {'train_loss': '1.06545'}; time used = 1.7585687637329102s
epoch 40: {'train_loss': '0.83107'}; time used = 1.6498980522155762s
epoch 45: {'train_loss': '0.78776'}; time used = 2.226952314376831s
epoch 50: {'train_loss': '0.63418'}; time used = 3.602545976638794s
epoch 55: {'train_loss': '0.46576'}; time used = 3.46813702583313s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.560396671295166.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5367121507472385, 'samples': 0.5507246376811594, 'weighted': 0.5425506869697055, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 26.49 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79015'}; time used = 1.942997694015503s
epoch 10: {'train_loss': '2.77602'}; time used = 1.9430108070373535s
epoch 15: {'train_loss': '2.77137'}; time used = 2.486384391784668s
epoch 20: {'train_loss': '2.76710'}; time used = 2.4172542095184326s
epoch 25: {'train_loss': '2.76095'}; time used = 2.457212448120117s
epoch 30: {'train_loss': '2.75667'}; time used = 2.0507829189300537s
epoch 35: {'train_loss': '2.74970'}; time used = 2.00581955909729s
epoch 40: {'train_loss': '2.74920'}; time used = 1.9459753036499023s
epoch 45: {'train_loss': '2.74364'}; time used = 1.9072563648223877s
epoch 50: {'train_loss': '2.73512'}; time used = 2.012444496154785s
epoch 55: {'train_loss': '2.71792'}; time used = 2.3101248741149902s
epoch 60: {'train_loss': '2.66965'}; time used = 2.4164133071899414s
epoch 65: {'train_loss': '2.64299'}; time used = 2.4237849712371826s
epoch 70: {'train_loss': '2.63398'}; time used = 2.3322744369506836s
epoch 75: {'train_loss': '2.61443'}; time used = 2.428821086883545s
epoch 80: {'train_loss': '2.60906'}; time used = 2.335148811340332s
epoch 85: {'train_loss': '2.61446'}; time used = 2.3230972290039062s
epoch 90: {'train_loss': '2.59962'}; time used = 2.3362326622009277s
epoch 95: {'train_loss': '2.61556'}; time used = 2.367154121398926s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.095664739608765.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6485568760611206, 'samples': 0.6521739130434783, 'weighted': 0.6511404739056619, 'accuracy': 0.6521739130434783}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 5.098837614059448s
epoch 10: {'train_loss': '1.38629'}; time used = 4.5786356925964355s
epoch 15: {'train_loss': '1.38629'}; time used = 6.153880596160889s
epoch 20: {'train_loss': '1.38629'}; time used = 7.066516160964966s
epoch 25: {'train_loss': '1.38629'}; time used = 4.941334009170532s
epoch 30: {'train_loss': '1.38629'}; time used = 4.844292640686035s
epoch 35: {'train_loss': '1.38629'}; time used = 5.006756067276001s
epoch 40: {'train_loss': '1.38629'}; time used = 4.924288511276245s
epoch 45: {'train_loss': '1.38629'}; time used = 4.99938440322876s
epoch 50: {'train_loss': '1.38629'}; time used = 5.094621896743774s
epoch 55: {'train_loss': '1.38629'}; time used = 4.598201513290405s
epoch 60: {'train_loss': '1.38629'}; time used = 4.773278713226318s
epoch 65: {'train_loss': '1.38629'}; time used = 4.810160160064697s
epoch 70: {'train_loss': '1.38629'}; time used = 4.863253355026245s
epoch 75: {'train_loss': '1.38629'}; time used = 5.154178142547607s
epoch 80: {'train_loss': '1.38629'}; time used = 5.064061403274536s
epoch 85: {'train_loss': '1.38629'}; time used = 4.852586507797241s
epoch 90: {'train_loss': '1.38629'}; time used = 4.672682285308838s
epoch 95: {'train_loss': '1.38629'}; time used = 4.56701397895813s
epoch 100: {'train_loss': '1.38629'}; time used = 4.59462833404541s
epoch 105: {'train_loss': '1.38629'}; time used = 4.658751964569092s
epoch 110: {'train_loss': '1.38629'}; time used = 4.567234039306641s
epoch 115: {'train_loss': '1.38629'}; time used = 4.467488527297974s
epoch 120: {'train_loss': '1.38629'}; time used = 4.543391466140747s
epoch 125: {'train_loss': '1.38629'}; time used = 4.497763395309448s
epoch 130: {'train_loss': '1.38629'}; time used = 4.5515382289886475s
epoch 135: {'train_loss': '1.38629'}; time used = 5.0627076625823975s
epoch 140: {'train_loss': '1.38629'}; time used = 4.627896785736084s
epoch 145: {'train_loss': '1.38629'}; time used = 4.923985719680786s
epoch 150: {'train_loss': '1.38629'}; time used = 4.968528747558594s
epoch 155: {'train_loss': '1.38629'}; time used = 4.70673942565918s
epoch 160: {'train_loss': '1.38629'}; time used = 4.687987804412842s
epoch 165: {'train_loss': '1.38629'}; time used = 4.69295072555542s
epoch 170: {'train_loss': '1.38629'}; time used = 4.765036344528198s
epoch 175: {'train_loss': '1.38629'}; time used = 5.347140789031982s
epoch 180: {'train_loss': '1.38629'}; time used = 4.50489616394043s
epoch 185: {'train_loss': '1.38629'}; time used = 5.08366060256958s
epoch 190: {'train_loss': '1.38629'}; time used = 4.92363166809082s
epoch 195: {'train_loss': '1.38629'}; time used = 5.050597906112671s
epoch 200: {'train_loss': '1.38629'}; time used = 4.914128303527832s
epoch 205: {'train_loss': '1.38629'}; time used = 5.05976414680481s
epoch 210: {'train_loss': '1.38629'}; time used = 4.627756118774414s
epoch 215: {'train_loss': '1.38629'}; time used = 4.530405759811401s
epoch 220: {'train_loss': '1.38629'}; time used = 4.592516899108887s
epoch 225: {'train_loss': '1.38629'}; time used = 4.658511400222778s
epoch 230: {'train_loss': '1.38629'}; time used = 4.842131853103638s
epoch 235: {'train_loss': '1.38629'}; time used = 4.739492654800415s
epoch 240: {'train_loss': '1.38629'}; time used = 4.694565534591675s
epoch 245: {'train_loss': '1.38629'}; time used = 5.1760499477386475s
epoch 250: {'train_loss': '1.38629'}; time used = 4.688419342041016s
epoch 255: {'train_loss': '1.38629'}; time used = 4.760285377502441s
epoch 260: {'train_loss': '1.38629'}; time used = 4.892261981964111s
epoch 265: {'train_loss': '1.38629'}; time used = 4.761679172515869s
epoch 270: {'train_loss': '1.38629'}; time used = 4.635988235473633s
epoch 275: {'train_loss': '1.38629'}; time used = 5.125093221664429s
epoch 280: {'train_loss': '1.38629'}; time used = 5.294231414794922s
epoch 285: {'train_loss': '1.38629'}; time used = 4.583031892776489s
epoch 290: {'train_loss': '1.38629'}; time used = 4.69447922706604s
epoch 295: {'train_loss': '1.38629'}; time used = 4.750379800796509s
epoch 300: {'train_loss': '1.38629'}; time used = 4.714377164840698s
epoch 305: {'train_loss': '1.38629'}; time used = 4.615311145782471s
epoch 310: {'train_loss': '1.38629'}; time used = 4.678635358810425s
epoch 315: {'train_loss': '1.38629'}; time used = 5.756102561950684s
epoch 320: {'train_loss': '1.38629'}; time used = 5.456449270248413s
epoch 325: {'train_loss': '1.38629'}; time used = 4.641825437545776s
epoch 330: {'train_loss': '1.38629'}; time used = 4.651517629623413s
epoch 335: {'train_loss': '1.38629'}; time used = 4.813243389129639s
epoch 340: {'train_loss': '1.38629'}; time used = 4.594721794128418s
epoch 345: {'train_loss': '1.38629'}; time used = 4.624634504318237s
epoch 350: {'train_loss': '1.38629'}; time used = 4.682893991470337s
epoch 355: {'train_loss': '1.38629'}; time used = 4.638844966888428s
epoch 360: {'train_loss': '1.38629'}; time used = 5.072391510009766s
epoch 365: {'train_loss': '1.38629'}; time used = 4.5056891441345215s
epoch 370: {'train_loss': '1.38629'}; time used = 4.846250772476196s
epoch 375: {'train_loss': '1.38629'}; time used = 4.907298803329468s
epoch 380: {'train_loss': '1.38629'}; time used = 5.091926097869873s
epoch 385: {'train_loss': '1.38629'}; time used = 4.970019578933716s
epoch 390: {'train_loss': '1.38629'}; time used = 4.558071613311768s
epoch 395: {'train_loss': '1.38629'}; time used = 7.724865674972534s
epoch 400: {'train_loss': '1.38629'}; time used = 4.851881265640259s
epoch 405: {'train_loss': '1.38629'}; time used = 4.681387186050415s
epoch 410: {'train_loss': '1.38629'}; time used = 4.786078929901123s
epoch 415: {'train_loss': '1.38629'}; time used = 4.919697284698486s
epoch 420: {'train_loss': '1.38629'}; time used = 7.599637985229492s
epoch 425: {'train_loss': '1.38629'}; time used = 5.469182252883911s
epoch 430: {'train_loss': '1.38629'}; time used = 5.655642747879028s
epoch 435: {'train_loss': '1.38629'}; time used = 5.120875358581543s
epoch 440: {'train_loss': '1.38629'}; time used = 4.7559123039245605s
epoch 445: {'train_loss': '1.38629'}; time used = 4.741168737411499s
epoch 450: {'train_loss': '1.38629'}; time used = 4.504865407943726s
epoch 455: {'train_loss': '1.38629'}; time used = 5.111224412918091s
epoch 460: {'train_loss': '1.38629'}; time used = 5.514768362045288s
epoch 465: {'train_loss': '1.38629'}; time used = 4.994821548461914s
epoch 470: {'train_loss': '1.38629'}; time used = 5.719425439834595s
epoch 475: {'train_loss': '1.38629'}; time used = 4.525525808334351s
epoch 480: {'train_loss': '1.38629'}; time used = 5.254582405090332s
epoch 485: {'train_loss': '1.38629'}; time used = 4.844942092895508s
epoch 490: {'train_loss': '1.38629'}; time used = 5.321809530258179s
epoch 495: {'train_loss': '1.38629'}; time used = 5.339596748352051s
epoch 500: {'train_loss': '1.38629'}; time used = 4.573734283447266s
Finished training. Time used = 502.8368458747864.
Training classifier using 80.00% nodes...
{'micro': 0.7250000000000001, 'macro': 0.7249931248281207, 'samples': 0.725, 'weighted': 0.725020625515638, 'accuracy': 0.725}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.79947'}; time used = 1.7279634475708008s
epoch 10: {'train_loss': '2.77243'}; time used = 1.7107024192810059s
epoch 15: {'train_loss': '2.75450'}; time used = 1.9869670867919922s
epoch 20: {'train_loss': '2.75006'}; time used = 1.9859366416931152s
epoch 25: {'train_loss': '2.74002'}; time used = 1.8306224346160889s
epoch 30: {'train_loss': '2.72541'}; time used = 1.7064414024353027s
epoch 35: {'train_loss': '2.71099'}; time used = 1.588996410369873s
epoch 40: {'train_loss': '2.67997'}; time used = 1.589270830154419s
epoch 45: {'train_loss': '2.63793'}; time used = 1.65138578414917s
epoch 50: {'train_loss': '2.58077'}; time used = 1.6069316864013672s
epoch 55: {'train_loss': '2.51879'}; time used = 1.7597386837005615s
epoch 60: {'train_loss': '2.50561'}; time used = 1.6510295867919922s
epoch 65: {'train_loss': '2.45689'}; time used = 1.7696466445922852s
epoch 70: {'train_loss': '2.44774'}; time used = 1.5993058681488037s
epoch 75: {'train_loss': '2.43902'}; time used = 1.6915621757507324s
epoch 80: {'train_loss': '2.41459'}; time used = 1.734529972076416s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.94949722290039.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5538793103448276, 'samples': 0.5652173913043478, 'weighted': 0.5590329835082459, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.50 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.33809'}; time used = 2.0583689212799072s
epoch 10: {'train_loss': '1.26638'}; time used = 1.9177587032318115s
epoch 15: {'train_loss': '1.23918'}; time used = 1.920060634613037s
epoch 20: {'train_loss': '1.18003'}; time used = 1.9715700149536133s
epoch 25: {'train_loss': '1.04870'}; time used = 2.0141091346740723s
epoch 30: {'train_loss': '0.76546'}; time used = 1.9714860916137695s
epoch 35: {'train_loss': '0.68985'}; time used = 2.089259624481201s
epoch 40: {'train_loss': '0.68255'}; time used = 1.9849469661712646s
epoch 45: {'train_loss': '0.50846'}; time used = 1.8451106548309326s
epoch 50: {'train_loss': '0.41127'}; time used = 1.867119550704956s
epoch 55: {'train_loss': '0.23317'}; time used = 1.9348375797271729s
epoch 60: {'train_loss': '0.30163'}; time used = 1.8615612983703613s
epoch 65: {'train_loss': '0.19642'}; time used = 1.8521032333374023s
epoch 70: {'train_loss': '0.39257'}; time used = 1.9032464027404785s
epoch 75: {'train_loss': '0.14882'}; time used = 1.9223692417144775s
epoch 80: {'train_loss': '0.06986'}; time used = 1.961118221282959s
epoch 85: {'train_loss': '0.03927'}; time used = 1.8742668628692627s
epoch 90: {'train_loss': '0.02518'}; time used = 2.069019317626953s
epoch 95: {'train_loss': '0.03940'}; time used = 1.8385484218597412s
epoch 100: {'train_loss': '0.11150'}; time used = 1.988985538482666s
epoch 105: {'train_loss': '0.00803'}; time used = 1.9407455921173096s
epoch 110: {'train_loss': '0.03265'}; time used = 1.9416251182556152s
epoch 115: {'train_loss': '0.00530'}; time used = 1.8247342109680176s
epoch 120: {'train_loss': '0.00561'}; time used = 1.928528070449829s
epoch 125: {'train_loss': '0.01424'}; time used = 1.925997257232666s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 51.50284028053284.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.33823'}; time used = 2.239190101623535s
epoch 10: {'train_loss': '1.26824'}; time used = 2.1356868743896484s
epoch 15: {'train_loss': '1.24846'}; time used = 2.106072425842285s
epoch 20: {'train_loss': '1.20313'}; time used = 2.2486627101898193s
epoch 25: {'train_loss': '1.02736'}; time used = 2.2021076679229736s
epoch 30: {'train_loss': '0.80934'}; time used = 2.111267328262329s
epoch 35: {'train_loss': '0.77247'}; time used = 2.1157376766204834s
epoch 40: {'train_loss': '0.67000'}; time used = 2.1329474449157715s
epoch 45: {'train_loss': '0.54150'}; time used = 2.106618642807007s
epoch 50: {'train_loss': '0.49412'}; time used = 2.1488988399505615s
epoch 55: {'train_loss': '0.42730'}; time used = 2.18249773979187s
epoch 60: {'train_loss': '0.29440'}; time used = 2.1421186923980713s
epoch 65: {'train_loss': '0.20488'}; time used = 2.166672706604004s
epoch 70: {'train_loss': '0.30124'}; time used = 2.135880708694458s
epoch 75: {'train_loss': '0.09957'}; time used = 1.9854462146759033s
epoch 80: {'train_loss': '0.04782'}; time used = 2.159644842147827s
epoch 85: {'train_loss': '0.09386'}; time used = 2.1089961528778076s
epoch 90: {'train_loss': '0.03068'}; time used = 1.9460294246673584s
epoch 95: {'train_loss': '0.04189'}; time used = 2.148171901702881s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.77117085456848.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.86081'}; time used = 1.7707931995391846s
epoch 10: {'train_loss': '2.78709'}; time used = 1.6714072227478027s
epoch 15: {'train_loss': '2.77596'}; time used = 1.8553740978240967s
epoch 20: {'train_loss': '2.76483'}; time used = 1.9408750534057617s
epoch 25: {'train_loss': '2.76683'}; time used = 1.8723430633544922s
epoch 30: {'train_loss': '2.76429'}; time used = 2.0770809650421143s
epoch 35: {'train_loss': '2.76008'}; time used = 2.049224853515625s
epoch 40: {'train_loss': '2.75910'}; time used = 1.7700164318084717s
epoch 45: {'train_loss': '2.75631'}; time used = 1.829425573348999s
epoch 50: {'train_loss': '2.75791'}; time used = 1.8111906051635742s
epoch 55: {'train_loss': '2.76102'}; time used = 1.8290112018585205s
epoch 60: {'train_loss': '2.76526'}; time used = 1.7753207683563232s
epoch 65: {'train_loss': '2.75768'}; time used = 1.7135753631591797s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.80663251876831.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.39869281045751637, 'samples': 0.5362318840579711, 'weighted': 0.4195320640333428, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87521'}; time used = 2.205942392349243s
epoch 10: {'train_loss': '2.79443'}; time used = 2.3471035957336426s
epoch 15: {'train_loss': '2.77270'}; time used = 2.2641351222991943s
epoch 20: {'train_loss': '2.77897'}; time used = 1.0431253910064697s
epoch 25: {'train_loss': '2.77909'}; time used = 1.000732660293579s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.577749490737915.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.93004'}; time used = 2.022921562194824s
epoch 10: {'train_loss': '2.81447'}; time used = 1.9237182140350342s
epoch 15: {'train_loss': '2.78392'}; time used = 1.8001048564910889s
epoch 20: {'train_loss': '2.77147'}; time used = 1.8554201126098633s
epoch 25: {'train_loss': '2.77563'}; time used = 1.884904146194458s
epoch 30: {'train_loss': '2.77506'}; time used = 1.7146453857421875s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.776758909225464.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.42761573454642754, 'samples': 0.5507246376811594, 'weighted': 0.44685150066122936, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 4.5078651905059814s
epoch 10: {'train_loss': '1.38629'}; time used = 4.194319486618042s
epoch 15: {'train_loss': '1.38629'}; time used = 4.517714262008667s
epoch 20: {'train_loss': '1.38629'}; time used = 4.368376970291138s
epoch 25: {'train_loss': '1.38629'}; time used = 4.41723370552063s
epoch 30: {'train_loss': '1.38629'}; time used = 4.512715101242065s
epoch 35: {'train_loss': '1.38629'}; time used = 4.155199766159058s
epoch 40: {'train_loss': '1.38629'}; time used = 4.165666818618774s
epoch 45: {'train_loss': '1.38629'}; time used = 4.115733861923218s
epoch 50: {'train_loss': '1.38629'}; time used = 4.1121368408203125s
epoch 55: {'train_loss': '1.38629'}; time used = 4.095270395278931s
epoch 60: {'train_loss': '1.38629'}; time used = 4.409869194030762s
epoch 65: {'train_loss': '1.38629'}; time used = 4.191638231277466s
epoch 70: {'train_loss': '1.38629'}; time used = 4.140756130218506s
epoch 75: {'train_loss': '1.38629'}; time used = 4.150074243545532s
epoch 80: {'train_loss': '1.38629'}; time used = 4.172373056411743s
epoch 85: {'train_loss': '1.38629'}; time used = 4.140827417373657s
epoch 90: {'train_loss': '1.38629'}; time used = 4.14502477645874s
epoch 95: {'train_loss': '1.38629'}; time used = 4.2672178745269775s
epoch 100: {'train_loss': '1.38629'}; time used = 4.215734004974365s
epoch 105: {'train_loss': '1.38629'}; time used = 4.130804777145386s
epoch 110: {'train_loss': '1.38629'}; time used = 4.652646541595459s
epoch 115: {'train_loss': '1.38629'}; time used = 9.030012130737305s
epoch 120: {'train_loss': '1.38629'}; time used = 8.032439470291138s
epoch 125: {'train_loss': '1.38629'}; time used = 5.365281343460083s
epoch 130: {'train_loss': '1.38629'}; time used = 4.586850643157959s
epoch 135: {'train_loss': '1.38629'}; time used = 7.362287521362305s
epoch 140: {'train_loss': '1.38629'}; time used = 4.7215821743011475s
epoch 145: {'train_loss': '1.38629'}; time used = 4.217748403549194s
epoch 150: {'train_loss': '1.38629'}; time used = 4.891687393188477s
epoch 155: {'train_loss': '1.38629'}; time used = 4.419900417327881s
epoch 160: {'train_loss': '1.38629'}; time used = 4.414747714996338s
epoch 165: {'train_loss': '1.38629'}; time used = 4.315047264099121s
epoch 170: {'train_loss': '1.38629'}; time used = 4.46770453453064s
epoch 175: {'train_loss': '1.38629'}; time used = 4.2511022090911865s
epoch 180: {'train_loss': '1.38629'}; time used = 4.104773283004761s
epoch 185: {'train_loss': '1.38629'}; time used = 4.124499797821045s
epoch 190: {'train_loss': '1.38629'}; time used = 4.131152868270874s
epoch 195: {'train_loss': '1.38629'}; time used = 4.022895336151123s
epoch 200: {'train_loss': '1.38629'}; time used = 4.257180213928223s
epoch 205: {'train_loss': '1.38629'}; time used = 4.226307153701782s
epoch 210: {'train_loss': '1.38629'}; time used = 4.61110520362854s
epoch 215: {'train_loss': '1.38629'}; time used = 6.6821393966674805s
epoch 220: {'train_loss': '1.38629'}; time used = 4.526636838912964s
epoch 225: {'train_loss': '1.38629'}; time used = 4.190718650817871s
epoch 230: {'train_loss': '1.38629'}; time used = 4.119822025299072s
epoch 235: {'train_loss': '1.38629'}; time used = 4.093693494796753s
epoch 240: {'train_loss': '1.38629'}; time used = 4.165016174316406s
epoch 245: {'train_loss': '1.38629'}; time used = 4.056072235107422s
epoch 250: {'train_loss': '1.38629'}; time used = 4.1566314697265625s
epoch 255: {'train_loss': '1.38629'}; time used = 4.49114465713501s
epoch 260: {'train_loss': '1.38629'}; time used = 4.197505712509155s
epoch 265: {'train_loss': '1.38629'}; time used = 4.152589559555054s
epoch 270: {'train_loss': '1.38629'}; time used = 4.154916286468506s
epoch 275: {'train_loss': '1.38629'}; time used = 4.240314722061157s
epoch 280: {'train_loss': '1.38629'}; time used = 4.320955514907837s
epoch 285: {'train_loss': '1.38629'}; time used = 4.3069984912872314s
epoch 290: {'train_loss': '1.38629'}; time used = 4.051855564117432s
epoch 295: {'train_loss': '1.38629'}; time used = 4.0527427196502686s
epoch 300: {'train_loss': '1.38629'}; time used = 4.045543670654297s
epoch 305: {'train_loss': '1.38629'}; time used = 4.100499391555786s
epoch 310: {'train_loss': '1.38629'}; time used = 4.252198696136475s
epoch 315: {'train_loss': '1.38629'}; time used = 4.2919862270355225s
epoch 320: {'train_loss': '1.38629'}; time used = 4.312140464782715s
epoch 325: {'train_loss': '1.38629'}; time used = 4.235501527786255s
epoch 330: {'train_loss': '1.38629'}; time used = 4.232454061508179s
epoch 335: {'train_loss': '1.38629'}; time used = 6.970210790634155s
epoch 340: {'train_loss': '1.38629'}; time used = 5.277509927749634s
epoch 345: {'train_loss': '1.38629'}; time used = 4.11256217956543s
epoch 350: {'train_loss': '1.38629'}; time used = 4.1010870933532715s
epoch 355: {'train_loss': '1.38629'}; time used = 4.075098276138306s
epoch 360: {'train_loss': '1.38629'}; time used = 5.080301761627197s
epoch 365: {'train_loss': '1.38629'}; time used = 4.160776376724243s
epoch 370: {'train_loss': '1.38629'}; time used = 4.051450967788696s
epoch 375: {'train_loss': '1.38629'}; time used = 4.089811563491821s
epoch 380: {'train_loss': '1.38629'}; time used = 4.231996059417725s
epoch 385: {'train_loss': '1.38629'}; time used = 5.241954803466797s
epoch 390: {'train_loss': '1.38629'}; time used = 4.3002753257751465s
epoch 395: {'train_loss': '1.38629'}; time used = 4.2421205043792725s
epoch 400: {'train_loss': '1.38629'}; time used = 4.220437288284302s
epoch 405: {'train_loss': '1.38629'}; time used = 4.086369514465332s
epoch 410: {'train_loss': '1.38629'}; time used = 4.153619050979614s
epoch 415: {'train_loss': '1.38629'}; time used = 4.100385904312134s
epoch 420: {'train_loss': '1.38629'}; time used = 4.1154420375823975s
epoch 425: {'train_loss': '1.38629'}; time used = 4.248450040817261s
epoch 430: {'train_loss': '1.38629'}; time used = 4.246252775192261s
epoch 435: {'train_loss': '1.38629'}; time used = 4.198829412460327s
epoch 440: {'train_loss': '1.38629'}; time used = 4.2985429763793945s
epoch 445: {'train_loss': '1.38629'}; time used = 4.155518531799316s
epoch 450: {'train_loss': '1.38629'}; time used = 4.183604955673218s
epoch 455: {'train_loss': '1.38629'}; time used = 4.355380058288574s
epoch 460: {'train_loss': '1.38629'}; time used = 4.129701375961304s
epoch 465: {'train_loss': '1.38629'}; time used = 6.653361082077026s
epoch 470: {'train_loss': '1.38629'}; time used = 5.976956605911255s
epoch 475: {'train_loss': '1.38629'}; time used = 4.976852893829346s
epoch 480: {'train_loss': '1.38629'}; time used = 4.23966121673584s
epoch 485: {'train_loss': '1.38629'}; time used = 5.135124444961548s
epoch 490: {'train_loss': '1.38629'}; time used = 7.0912463665008545s
epoch 495: {'train_loss': '1.38629'}; time used = 4.456015110015869s
epoch 500: {'train_loss': '1.38629'}; time used = 4.916943550109863s
Finished training. Time used = 463.75240206718445.
Training classifier using 80.00% nodes...
{'micro': 0.63, 'macro': 0.6262626262626263, 'samples': 0.63, 'weighted': 0.6255151515151515, 'accuracy': 0.63}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.03255'}; time used = 1.8220787048339844s
epoch 10: {'train_loss': '0.00697'}; time used = 1.6476588249206543s
epoch 15: {'train_loss': '0.00484'}; time used = 1.8844528198242188s
epoch 20: {'train_loss': '0.00030'}; time used = 1.6595628261566162s
epoch 25: {'train_loss': '0.00009'}; time used = 2.239417552947998s
epoch 30: {'train_loss': '0.00014'}; time used = 2.0685813426971436s
epoch 35: {'train_loss': '0.02936'}; time used = 2.9959256649017334s
epoch 40: {'train_loss': '0.00027'}; time used = 2.9767911434173584s
epoch 45: {'train_loss': '0.00094'}; time used = 3.1679975986480713s
epoch 50: {'train_loss': '0.00311'}; time used = 2.3885912895202637s
epoch 55: {'train_loss': '0.00334'}; time used = 2.181039810180664s
epoch 60: {'train_loss': '0.03440'}; time used = 2.2167768478393555s
epoch 65: {'train_loss': '0.01470'}; time used = 2.125750780105591s
epoch 70: {'train_loss': '0.19933'}; time used = 2.2584078311920166s
epoch 75: {'train_loss': '0.05422'}; time used = 2.370661497116089s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.61021137237549.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5101591187270502, 'samples': 0.5797101449275363, 'weighted': 0.5235343160732975, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.78528'}; time used = 1.2263634204864502s
epoch 10: {'train_loss': '2.78267'}; time used = 1.0723834037780762s
epoch 15: {'train_loss': '2.77995'}; time used = 1.0526294708251953s
epoch 20: {'train_loss': '2.77204'}; time used = 1.0662140846252441s
epoch 25: {'train_loss': '2.76994'}; time used = 0.9891328811645508s
epoch 30: {'train_loss': '2.76888'}; time used = 1.0251150131225586s
epoch 35: {'train_loss': '2.76572'}; time used = 1.0698835849761963s
epoch 40: {'train_loss': '2.76285'}; time used = 0.9944305419921875s
epoch 45: {'train_loss': '2.75893'}; time used = 1.0038881301879883s
epoch 50: {'train_loss': '2.75523'}; time used = 1.0019035339355469s
epoch 55: {'train_loss': '2.75235'}; time used = 0.9949150085449219s
epoch 60: {'train_loss': '2.75622'}; time used = 1.0096018314361572s
epoch 65: {'train_loss': '2.75107'}; time used = 1.0146889686584473s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.074530601501465.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.05 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.45576'}; time used = 10.634644269943237s
epoch 10: {'train_loss': '2.84594'}; time used = 7.151815414428711s
epoch 15: {'train_loss': '2.83535'}; time used = 9.307221174240112s
epoch 20: {'train_loss': '2.84114'}; time used = 7.533105134963989s
epoch 25: {'train_loss': '2.82544'}; time used = 6.483441591262817s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.06043362617493.
Training classifier using 80.00% nodes...
{'micro': 0.4766666666666667, 'macro': 0.44754915871401374, 'samples': 0.4766666666666667, 'weighted': 0.441275001833388, 'accuracy': 0.4766666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.34646'}; time used = 2.8852639198303223s
epoch 10: {'train_loss': '1.22953'}; time used = 1.7769677639007568s
epoch 15: {'train_loss': '1.16824'}; time used = 1.8407340049743652s
epoch 20: {'train_loss': '1.18026'}; time used = 1.8046760559082031s
epoch 25: {'train_loss': '1.11841'}; time used = 1.8283195495605469s
epoch 30: {'train_loss': '1.00907'}; time used = 1.9386284351348877s
epoch 35: {'train_loss': '0.99752'}; time used = 1.7706153392791748s
epoch 40: {'train_loss': '0.90665'}; time used = 3.267244577407837s
epoch 45: {'train_loss': '0.90523'}; time used = 3.458811044692993s
epoch 50: {'train_loss': '0.71168'}; time used = 3.609417676925659s
epoch 55: {'train_loss': '0.63900'}; time used = 2.258892297744751s
epoch 60: {'train_loss': '0.66906'}; time used = 1.7255878448486328s
epoch 65: {'train_loss': '0.60893'}; time used = 1.6713969707489014s
epoch 70: {'train_loss': '0.73283'}; time used = 1.632805347442627s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.48831844329834.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.49988309562777655, 'samples': 0.5507246376811594, 'weighted': 0.5114379915489998, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 26.49 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.67315'}; time used = 1.7150883674621582s
epoch 10: {'train_loss': '0.12654'}; time used = 1.6980044841766357s
epoch 15: {'train_loss': '0.03267'}; time used = 1.6810343265533447s
epoch 20: {'train_loss': '0.07233'}; time used = 1.607013463973999s
epoch 25: {'train_loss': '0.06473'}; time used = 1.6323494911193848s
epoch 30: {'train_loss': '0.03461'}; time used = 1.5948305130004883s
epoch 35: {'train_loss': '0.04897'}; time used = 1.5502851009368896s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.451791524887085.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.42761573454642754, 'samples': 0.5507246376811594, 'weighted': 0.44685150066122936, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.70499'}; time used = 1.2476246356964111s
epoch 10: {'train_loss': '2.64397'}; time used = 1.0342535972595215s
epoch 15: {'train_loss': '2.59784'}; time used = 1.0157296657562256s
epoch 20: {'train_loss': '2.53503'}; time used = 1.0944774150848389s
epoch 25: {'train_loss': '2.45905'}; time used = 1.0356028079986572s
epoch 30: {'train_loss': '2.37269'}; time used = 1.1182639598846436s
epoch 35: {'train_loss': '2.32201'}; time used = 1.1019096374511719s
epoch 40: {'train_loss': '2.27800'}; time used = 1.0773725509643555s
epoch 45: {'train_loss': '2.23662'}; time used = 1.104430913925171s
epoch 50: {'train_loss': '2.21514'}; time used = 1.1754519939422607s
epoch 55: {'train_loss': '2.20146'}; time used = 1.1820871829986572s
epoch 60: {'train_loss': '2.16377'}; time used = 1.259944200515747s
epoch 65: {'train_loss': '2.13972'}; time used = 1.0750360488891602s
epoch 70: {'train_loss': '2.17111'}; time used = 1.0043964385986328s
epoch 75: {'train_loss': '2.15979'}; time used = 1.019796371459961s
epoch 80: {'train_loss': '2.13527'}; time used = 1.000812292098999s
epoch 85: {'train_loss': '2.12093'}; time used = 1.007744312286377s
epoch 90: {'train_loss': '2.07294'}; time used = 0.9881553649902344s
epoch 95: {'train_loss': '2.02795'}; time used = 0.9898502826690674s
epoch 100: {'train_loss': '2.02167'}; time used = 1.001657247543335s
epoch 105: {'train_loss': '2.03444'}; time used = 1.1558589935302734s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.599695205688477.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36639'}; time used = 1.8060948848724365s
epoch 10: {'train_loss': '1.33349'}; time used = 1.6875436305999756s
epoch 15: {'train_loss': '1.26172'}; time used = 1.7423834800720215s
epoch 20: {'train_loss': '1.29149'}; time used = 1.9274628162384033s
epoch 25: {'train_loss': '1.13536'}; time used = 1.8706696033477783s
epoch 30: {'train_loss': '1.01855'}; time used = 1.7698822021484375s
epoch 35: {'train_loss': '0.98736'}; time used = 1.6652610301971436s
epoch 40: {'train_loss': '0.92023'}; time used = 1.6404986381530762s
epoch 45: {'train_loss': '0.83810'}; time used = 1.8781797885894775s
epoch 50: {'train_loss': '0.65654'}; time used = 1.82279372215271s
epoch 55: {'train_loss': '0.62940'}; time used = 1.6848158836364746s
epoch 60: {'train_loss': '0.60408'}; time used = 1.6578080654144287s
epoch 65: {'train_loss': '0.69305'}; time used = 1.6684579849243164s
epoch 70: {'train_loss': '0.59446'}; time used = 1.6609997749328613s
epoch 75: {'train_loss': '0.49012'}; time used = 1.7389001846313477s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.933618307113647.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5241379310344827, 'samples': 0.5362318840579711, 'weighted': 0.5296351824087956, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83383'}; time used = 8.352169513702393s
epoch 10: {'train_loss': '2.80236'}; time used = 7.707054138183594s
epoch 15: {'train_loss': '2.78751'}; time used = 8.369553327560425s
epoch 20: {'train_loss': '2.77730'}; time used = 8.431071519851685s
epoch 25: {'train_loss': '2.77083'}; time used = 14.773449182510376s
epoch 30: {'train_loss': '2.76691'}; time used = 11.02698016166687s
epoch 35: {'train_loss': '2.76212'}; time used = 10.459875345230103s
epoch 40: {'train_loss': '2.75378'}; time used = 15.343805074691772s
epoch 45: {'train_loss': '2.74014'}; time used = 7.480631113052368s
epoch 50: {'train_loss': '2.73077'}; time used = 7.501312494277954s
epoch 55: {'train_loss': '2.72466'}; time used = 7.834643840789795s
epoch 60: {'train_loss': '2.72051'}; time used = 8.660266637802124s
epoch 65: {'train_loss': '2.71115'}; time used = 10.175591468811035s
epoch 70: {'train_loss': '2.71153'}; time used = 7.711622953414917s
epoch 75: {'train_loss': '2.70352'}; time used = 7.527005434036255s
epoch 80: {'train_loss': '2.70598'}; time used = 7.320236682891846s
epoch 85: {'train_loss': '2.69618'}; time used = 7.551776170730591s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 174.9674141407013.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.44394149287461043, 'samples': 0.5066666666666667, 'weighted': 0.4346568615337503, 'accuracy': 0.5066666666666667}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.80742'}; time used = 3.093186378479004s
epoch 10: {'train_loss': '2.75573'}; time used = 2.918653964996338s
epoch 15: {'train_loss': '2.69637'}; time used = 2.0392589569091797s
epoch 20: {'train_loss': '2.63639'}; time used = 1.9463655948638916s
epoch 25: {'train_loss': '2.57774'}; time used = 1.8081393241882324s
epoch 30: {'train_loss': '2.51083'}; time used = 1.697417974472046s
epoch 35: {'train_loss': '2.41835'}; time used = 3.3788416385650635s
epoch 40: {'train_loss': '2.30513'}; time used = 3.1611711978912354s
epoch 45: {'train_loss': '2.39905'}; time used = 3.046736478805542s
epoch 50: {'train_loss': '2.36279'}; time used = 2.66105580329895s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.10466527938843.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.77934'}; time used = 2.4111268520355225s
epoch 10: {'train_loss': '2.77370'}; time used = 1.20701265335083s
epoch 15: {'train_loss': '2.78450'}; time used = 1.1397168636322021s
epoch 20: {'train_loss': '2.78196'}; time used = 1.2154974937438965s
epoch 25: {'train_loss': '2.77334'}; time used = 1.1472992897033691s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.69569730758667.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6346153846153846, 'samples': 0.6842105263157895, 'weighted': 0.6558704453441294, 'accuracy': 0.6842105263157895}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.14275'}; time used = 2.512864589691162s
epoch 10: {'train_loss': '1.00327'}; time used = 2.3957746028900146s
epoch 15: {'train_loss': '0.14830'}; time used = 2.4316699504852295s
epoch 20: {'train_loss': '0.00097'}; time used = 2.453812599182129s
epoch 25: {'train_loss': '0.00095'}; time used = 2.401074171066284s
epoch 30: {'train_loss': '0.02732'}; time used = 2.363581418991089s
epoch 35: {'train_loss': '0.10219'}; time used = 2.3248181343078613s
epoch 40: {'train_loss': '0.16416'}; time used = 2.3075764179229736s
epoch 45: {'train_loss': '0.00607'}; time used = 2.32114839553833s
epoch 50: {'train_loss': '0.00612'}; time used = 2.2937498092651367s
epoch 55: {'train_loss': '0.00208'}; time used = 2.3646528720855713s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.119343757629395.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5836206896551723, 'samples': 0.5942028985507246, 'weighted': 0.588430784607696, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.60407'}; time used = 2.2972888946533203s
epoch 10: {'train_loss': '0.40146'}; time used = 2.0655345916748047s
epoch 15: {'train_loss': '0.29727'}; time used = 2.1084632873535156s
epoch 20: {'train_loss': '0.18230'}; time used = 1.7711796760559082s
epoch 25: {'train_loss': '0.18794'}; time used = 1.6605150699615479s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.072525262832642.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.32470'}; time used = 1.7134835720062256s
epoch 10: {'train_loss': '1.23144'}; time used = 1.7288827896118164s
epoch 15: {'train_loss': '1.21774'}; time used = 1.6619439125061035s
epoch 20: {'train_loss': '1.24377'}; time used = 1.6953935623168945s
epoch 25: {'train_loss': '0.88411'}; time used = 1.6337244510650635s
epoch 30: {'train_loss': '0.96320'}; time used = 1.5924460887908936s
epoch 35: {'train_loss': '1.06848'}; time used = 1.5890941619873047s
epoch 40: {'train_loss': '1.15836'}; time used = 1.6081664562225342s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.356181383132935.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.03517'}; time used = 1.9171442985534668s
epoch 10: {'train_loss': '0.94469'}; time used = 2.6942126750946045s
epoch 15: {'train_loss': '0.64979'}; time used = 2.5361106395721436s
epoch 20: {'train_loss': '0.64326'}; time used = 1.8539505004882812s
epoch 25: {'train_loss': '0.42835'}; time used = 2.1049206256866455s
epoch 30: {'train_loss': '0.30581'}; time used = 1.828005313873291s
epoch 35: {'train_loss': '0.38521'}; time used = 1.7237348556518555s
epoch 40: {'train_loss': '0.32406'}; time used = 1.6786320209503174s
epoch 45: {'train_loss': '0.27743'}; time used = 1.6809020042419434s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.35811686515808.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5321487023614684, 'samples': 0.5797101449275363, 'weighted': 0.5429581211264838, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36706'}; time used = 1.4512481689453125s
epoch 10: {'train_loss': '1.40237'}; time used = 1.3368000984191895s
epoch 15: {'train_loss': '1.42555'}; time used = 1.4173192977905273s
epoch 20: {'train_loss': '1.30991'}; time used = 1.4081535339355469s
epoch 25: {'train_loss': '1.38871'}; time used = 1.3852384090423584s
epoch 30: {'train_loss': '1.35006'}; time used = 1.3868458271026611s
epoch 35: {'train_loss': '1.37837'}; time used = 1.3823912143707275s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.54833459854126.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.34811'}; time used = 2.07234787940979s
epoch 10: {'train_loss': '0.36064'}; time used = 1.9868288040161133s
epoch 15: {'train_loss': '0.16037'}; time used = 2.0061752796173096s
epoch 20: {'train_loss': '0.10226'}; time used = 2.068612813949585s
epoch 25: {'train_loss': '0.10592'}; time used = 2.687795639038086s
epoch 30: {'train_loss': '0.03809'}; time used = 3.0259430408477783s
epoch 35: {'train_loss': '0.09125'}; time used = 2.9294755458831787s
epoch 40: {'train_loss': '0.07116'}; time used = 1.7550690174102783s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.937911987304688.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4661508704061895, 'samples': 0.5362318840579711, 'weighted': 0.48016707313654583, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.72800'}; time used = 1.8354172706604004s
epoch 10: {'train_loss': '2.75614'}; time used = 1.9003512859344482s
epoch 15: {'train_loss': '2.72121'}; time used = 1.810957431793213s
epoch 20: {'train_loss': '2.69503'}; time used = 1.71938157081604s
epoch 25: {'train_loss': '2.66534'}; time used = 1.9736146926879883s
epoch 30: {'train_loss': '2.64423'}; time used = 1.8691487312316895s
epoch 35: {'train_loss': '2.63769'}; time used = 2.00339937210083s
epoch 40: {'train_loss': '2.63497'}; time used = 1.7914433479309082s
epoch 45: {'train_loss': '2.63232'}; time used = 1.9002184867858887s
epoch 50: {'train_loss': '2.61941'}; time used = 1.751481056213379s
epoch 55: {'train_loss': '2.61375'}; time used = 1.915888786315918s
epoch 60: {'train_loss': '2.61581'}; time used = 1.8546254634857178s
epoch 65: {'train_loss': '2.59801'}; time used = 1.8530523777008057s
epoch 70: {'train_loss': '2.57919'}; time used = 1.8076744079589844s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.85012412071228.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.83038'}; time used = 1.0912973880767822s
epoch 10: {'train_loss': '2.37220'}; time used = 0.9211714267730713s
epoch 15: {'train_loss': '1.88824'}; time used = 0.9079678058624268s
epoch 20: {'train_loss': '1.46903'}; time used = 0.893803596496582s
epoch 25: {'train_loss': '1.42786'}; time used = 0.9469916820526123s
epoch 30: {'train_loss': '1.24535'}; time used = 0.9927792549133301s
epoch 35: {'train_loss': '1.11143'}; time used = 0.9403634071350098s
epoch 40: {'train_loss': '1.70767'}; time used = 0.943061351776123s
epoch 45: {'train_loss': '1.31006'}; time used = 0.9161064624786377s
epoch 50: {'train_loss': '1.07032'}; time used = 0.9205234050750732s
epoch 55: {'train_loss': '1.12290'}; time used = 0.9196970462799072s
epoch 60: {'train_loss': '1.02579'}; time used = 0.9836316108703613s
epoch 65: {'train_loss': '1.02033'}; time used = 1.0281391143798828s
epoch 70: {'train_loss': '0.95783'}; time used = 0.9131481647491455s
epoch 75: {'train_loss': '0.86507'}; time used = 0.9479005336761475s
epoch 80: {'train_loss': '0.95591'}; time used = 1.1473257541656494s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.38170576095581.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79424'}; time used = 1.7937030792236328s
epoch 10: {'train_loss': '2.77626'}; time used = 1.743220329284668s
epoch 15: {'train_loss': '2.77480'}; time used = 1.9874413013458252s
epoch 20: {'train_loss': '2.76628'}; time used = 2.014613628387451s
epoch 25: {'train_loss': '2.76485'}; time used = 1.9374616146087646s
epoch 30: {'train_loss': '2.76313'}; time used = 1.6785173416137695s
epoch 35: {'train_loss': '2.75710'}; time used = 1.6758065223693848s
epoch 40: {'train_loss': '2.75797'}; time used = 1.6765742301940918s
epoch 45: {'train_loss': '2.75804'}; time used = 1.8986341953277588s
epoch 50: {'train_loss': '2.75664'}; time used = 1.7530803680419922s
epoch 55: {'train_loss': '2.76039'}; time used = 1.62095046043396s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.417582988739014.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.03128'}; time used = 2.6231160163879395s
epoch 10: {'train_loss': '2.91840'}; time used = 2.4357540607452393s
epoch 15: {'train_loss': '2.85992'}; time used = 2.610414505004883s
epoch 20: {'train_loss': '2.82369'}; time used = 2.5006556510925293s
epoch 25: {'train_loss': '2.80099'}; time used = 2.6611857414245605s
epoch 30: {'train_loss': '2.79198'}; time used = 2.6821157932281494s
epoch 35: {'train_loss': '2.79632'}; time used = 2.6130118370056152s
epoch 40: {'train_loss': '2.78516'}; time used = 2.4404234886169434s
epoch 45: {'train_loss': '2.77688'}; time used = 2.4805655479431152s
epoch 50: {'train_loss': '2.76403'}; time used = 2.484557867050171s
epoch 55: {'train_loss': '2.75355'}; time used = 2.55118727684021s
epoch 60: {'train_loss': '2.73527'}; time used = 5.3681933879852295s
epoch 65: {'train_loss': '2.73331'}; time used = 5.1149914264678955s
epoch 70: {'train_loss': '2.73924'}; time used = 2.4329636096954346s
epoch 75: {'train_loss': '2.71477'}; time used = 2.8464818000793457s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.547961950302124.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5062611806797853, 'samples': 0.5362318840579711, 'weighted': 0.5150760934380751, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.06703'}; time used = 1.9334640502929688s
epoch 10: {'train_loss': '2.95598'}; time used = 1.8603160381317139s
epoch 15: {'train_loss': '2.86457'}; time used = 1.870532512664795s
epoch 20: {'train_loss': '2.82729'}; time used = 1.9274868965148926s
epoch 25: {'train_loss': '2.80190'}; time used = 2.0252182483673096s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.64725923538208.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.46215740507920544, 'samples': 0.5507246376811594, 'weighted': 0.4779729823295543, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37458'}; time used = 1.7831311225891113s
epoch 10: {'train_loss': '1.30766'}; time used = 1.787311315536499s
epoch 15: {'train_loss': '1.18817'}; time used = 1.7891559600830078s
epoch 20: {'train_loss': '0.92339'}; time used = 1.6757819652557373s
epoch 25: {'train_loss': '0.61543'}; time used = 1.8560504913330078s
epoch 30: {'train_loss': '0.50399'}; time used = 1.757629632949829s
epoch 35: {'train_loss': '1.00196'}; time used = 1.7681312561035156s
epoch 40: {'train_loss': '0.63843'}; time used = 1.765289306640625s
epoch 45: {'train_loss': '0.42418'}; time used = 1.7507288455963135s
epoch 50: {'train_loss': '0.58576'}; time used = 1.7574198246002197s
epoch 55: {'train_loss': '0.20946'}; time used = 1.7416541576385498s
epoch 60: {'train_loss': '0.18779'}; time used = 1.7296726703643799s
epoch 65: {'train_loss': '0.13205'}; time used = 1.885575771331787s
epoch 70: {'train_loss': '0.19411'}; time used = 1.7622780799865723s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.000680685043335.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5740740740740741, 'samples': 0.5942028985507246, 'weighted': 0.5807836822329576, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.04815'}; time used = 8.970936059951782s
epoch 10: {'train_loss': '2.77770'}; time used = 6.504262924194336s
epoch 15: {'train_loss': '2.80981'}; time used = 6.48725700378418s
epoch 20: {'train_loss': '2.79534'}; time used = 7.292266368865967s
epoch 25: {'train_loss': '2.77468'}; time used = 7.058274984359741s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.5450074672699.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.44062727286437714, 'samples': 0.5066666666666667, 'weighted': 0.43096777671234404, 'accuracy': 0.5066666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.02372'}; time used = 1.6965463161468506s
epoch 10: {'train_loss': '2.95679'}; time used = 1.898500919342041s
epoch 15: {'train_loss': '2.84175'}; time used = 1.8377938270568848s
epoch 20: {'train_loss': '2.79007'}; time used = 1.8184099197387695s
epoch 25: {'train_loss': '2.75855'}; time used = 1.9351952075958252s
epoch 30: {'train_loss': '2.73026'}; time used = 1.9086883068084717s
epoch 35: {'train_loss': '2.70624'}; time used = 1.8022229671478271s
epoch 40: {'train_loss': '2.67579'}; time used = 1.839463233947754s
epoch 45: {'train_loss': '2.64020'}; time used = 1.863377332687378s
epoch 50: {'train_loss': '2.60730'}; time used = 1.929426670074463s
epoch 55: {'train_loss': '2.59715'}; time used = 1.7650833129882812s
epoch 60: {'train_loss': '2.58167'}; time used = 1.6384451389312744s
epoch 65: {'train_loss': '2.54124'}; time used = 1.6252615451812744s
epoch 70: {'train_loss': '2.50117'}; time used = 1.6621618270874023s
epoch 75: {'train_loss': '2.47672'}; time used = 1.6223969459533691s
epoch 80: {'train_loss': '2.44416'}; time used = 1.6943871974945068s
epoch 85: {'train_loss': '2.44909'}; time used = 1.5479092597961426s
epoch 90: {'train_loss': '2.48025'}; time used = 1.6537325382232666s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.63674712181091.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.6057142857142858, 'samples': 0.6086956521739131, 'weighted': 0.6081987577639751, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.33350'}; time used = 7.648217678070068s
epoch 10: {'train_loss': '1.24267'}; time used = 7.384504318237305s
epoch 15: {'train_loss': '1.03550'}; time used = 7.254926443099976s
epoch 20: {'train_loss': '0.67433'}; time used = 7.206459999084473s
epoch 25: {'train_loss': '0.37054'}; time used = 7.904748916625977s
epoch 30: {'train_loss': '0.38753'}; time used = 10.986149311065674s
epoch 35: {'train_loss': '0.14379'}; time used = 7.539262771606445s
epoch 40: {'train_loss': '0.15797'}; time used = 7.142680883407593s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 82.27855610847473.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.4479981953578722, 'samples': 0.5066666666666667, 'weighted': 0.4389844790053328, 'accuracy': 0.5066666666666667}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.21007'}; time used = 1.0839636325836182s
epoch 10: {'train_loss': '2.77959'}; time used = 0.9040822982788086s
epoch 15: {'train_loss': '2.77894'}; time used = 0.8859000205993652s
epoch 20: {'train_loss': '2.75280'}; time used = 0.8783574104309082s
epoch 25: {'train_loss': '2.70729'}; time used = 0.9955048561096191s
epoch 30: {'train_loss': '2.61528'}; time used = 0.8852460384368896s
epoch 35: {'train_loss': '2.37223'}; time used = 1.053858995437622s
epoch 40: {'train_loss': '2.11430'}; time used = 1.106614112854004s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.662188291549683.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.24104'}; time used = 1.7705135345458984s
epoch 10: {'train_loss': '2.81796'}; time used = 1.678173542022705s
epoch 15: {'train_loss': '2.76538'}; time used = 1.744861364364624s
epoch 20: {'train_loss': '2.76921'}; time used = 1.6612718105316162s
epoch 25: {'train_loss': '2.75719'}; time used = 1.8096795082092285s
epoch 30: {'train_loss': '2.74782'}; time used = 1.5876564979553223s
epoch 35: {'train_loss': '2.74346'}; time used = 1.572331190109253s
epoch 40: {'train_loss': '2.73601'}; time used = 1.5727150440216064s
epoch 45: {'train_loss': '2.72198'}; time used = 1.6856040954589844s
epoch 50: {'train_loss': '2.71186'}; time used = 1.767204761505127s
epoch 55: {'train_loss': '2.70944'}; time used = 1.6783010959625244s
epoch 60: {'train_loss': '2.69009'}; time used = 1.618150234222412s
epoch 65: {'train_loss': '2.68089'}; time used = 1.8690509796142578s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.959192514419556.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5782929399367756, 'samples': 0.5797101449275363, 'weighted': 0.5800644461752263, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35478'}; time used = 1.7601752281188965s
epoch 10: {'train_loss': '1.05232'}; time used = 1.7741894721984863s
epoch 15: {'train_loss': '0.66455'}; time used = 1.8693180084228516s
epoch 20: {'train_loss': '0.78327'}; time used = 1.83809494972229s
epoch 25: {'train_loss': '0.68389'}; time used = 1.8045787811279297s
epoch 30: {'train_loss': '0.32587'}; time used = 1.701448917388916s
epoch 35: {'train_loss': '0.91210'}; time used = 2.066713571548462s
epoch 40: {'train_loss': '0.74201'}; time used = 2.0677757263183594s
epoch 45: {'train_loss': '0.35702'}; time used = 1.7919673919677734s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.94212818145752.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.62 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.18620'}; time used = 1.0832290649414062s
epoch 10: {'train_loss': '0.43249'}; time used = 0.9237866401672363s
epoch 15: {'train_loss': '0.05659'}; time used = 1.077735424041748s
epoch 20: {'train_loss': '0.02376'}; time used = 0.9670014381408691s
epoch 25: {'train_loss': '0.03093'}; time used = 0.8963057994842529s
epoch 30: {'train_loss': '0.00783'}; time used = 0.8836925029754639s
epoch 35: {'train_loss': '0.01089'}; time used = 0.9967541694641113s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.80966591835022.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7172619047619048, 'samples': 0.7368421052631579, 'weighted': 0.7290100250626566, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.35564'}; time used = 1.8634283542633057s
epoch 10: {'train_loss': '1.24849'}; time used = 1.8596138954162598s
epoch 15: {'train_loss': '1.17605'}; time used = 1.7164015769958496s
epoch 20: {'train_loss': '1.19465'}; time used = 1.9828546047210693s
epoch 25: {'train_loss': '1.09811'}; time used = 1.7470557689666748s
epoch 30: {'train_loss': '0.94253'}; time used = 1.6758713722229004s
epoch 35: {'train_loss': '0.99837'}; time used = 4.354042291641235s
epoch 40: {'train_loss': '0.92184'}; time used = 5.083291530609131s
epoch 45: {'train_loss': '0.90852'}; time used = 1.779271125793457s
epoch 50: {'train_loss': '0.70808'}; time used = 1.7000744342803955s
epoch 55: {'train_loss': '0.58442'}; time used = 1.6274831295013428s
epoch 60: {'train_loss': '0.58893'}; time used = 1.6616601943969727s
epoch 65: {'train_loss': '0.85276'}; time used = 1.7240707874298096s
epoch 70: {'train_loss': '0.69891'}; time used = 1.8220396041870117s
epoch 75: {'train_loss': '0.56285'}; time used = 1.6839120388031006s
epoch 80: {'train_loss': '0.35285'}; time used = 1.6824581623077393s
epoch 85: {'train_loss': '0.42858'}; time used = 1.8637151718139648s
epoch 90: {'train_loss': '0.05368'}; time used = 1.7917327880859375s
epoch 95: {'train_loss': '0.15729'}; time used = 1.7033262252807617s
epoch 100: {'train_loss': '0.00663'}; time used = 1.7213969230651855s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.81470060348511.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5538793103448276, 'samples': 0.5652173913043478, 'weighted': 0.5590329835082459, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.21292'}; time used = 1.382890224456787s
epoch 10: {'train_loss': '0.10264'}; time used = 0.9698143005371094s
epoch 15: {'train_loss': '0.08044'}; time used = 0.9846358299255371s
epoch 20: {'train_loss': '0.11614'}; time used = 1.1365845203399658s
epoch 25: {'train_loss': '0.14393'}; time used = 0.9467148780822754s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.23007082939148.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37767'}; time used = 2.335164785385132s
epoch 10: {'train_loss': '1.34257'}; time used = 2.8856899738311768s
epoch 15: {'train_loss': '1.36560'}; time used = 3.2564151287078857s
epoch 20: {'train_loss': '1.39597'}; time used = 2.4063704013824463s
epoch 25: {'train_loss': '1.30191'}; time used = 2.277831554412842s
epoch 30: {'train_loss': '1.16056'}; time used = 2.255997657775879s
epoch 35: {'train_loss': '1.07262'}; time used = 2.4515740871429443s
epoch 40: {'train_loss': '1.06764'}; time used = 2.3381505012512207s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.01464915275574.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4145927601809955, 'samples': 0.5652173913043478, 'weighted': 0.43611056462718867, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.89187'}; time used = 1.5937888622283936s
epoch 10: {'train_loss': '2.86210'}; time used = 1.594308853149414s
epoch 15: {'train_loss': '2.79200'}; time used = 1.6993613243103027s
epoch 20: {'train_loss': '2.74933'}; time used = 1.9413447380065918s
epoch 25: {'train_loss': '2.70896'}; time used = 1.8512744903564453s
epoch 30: {'train_loss': '2.67821'}; time used = 2.2791895866394043s
epoch 35: {'train_loss': '2.63987'}; time used = 2.3170018196105957s
epoch 40: {'train_loss': '2.60326'}; time used = 1.7812776565551758s
epoch 45: {'train_loss': '2.56205'}; time used = 1.6060152053833008s
epoch 50: {'train_loss': '2.49487'}; time used = 1.5784881114959717s
epoch 55: {'train_loss': '2.46625'}; time used = 1.6290271282196045s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.790306329727173.
Training classifier using 80.00% nodes...
{'micro': 0.4782608695652174, 'macro': 0.4772727272727273, 'samples': 0.4782608695652174, 'weighted': 0.47891963109354413, 'accuracy': 0.4782608695652174}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.64 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.48759'}; time used = 1.8813934326171875s
epoch 10: {'train_loss': '3.00275'}; time used = 1.8322949409484863s
epoch 15: {'train_loss': '2.88663'}; time used = 1.831864356994629s
epoch 20: {'train_loss': '2.85358'}; time used = 1.8207552433013916s
epoch 25: {'train_loss': '2.82021'}; time used = 2.050539016723633s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.162961721420288.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4891114982578397, 'samples': 0.5072463768115942, 'weighted': 0.49608645154774533, 'accuracy': 0.5072463768115942}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.79 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.62 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.63529'}; time used = 1.775174617767334s
epoch 10: {'train_loss': '0.04889'}; time used = 1.6816978454589844s
epoch 15: {'train_loss': '0.14184'}; time used = 1.6920795440673828s
epoch 20: {'train_loss': '0.02548'}; time used = 1.6852104663848877s
epoch 25: {'train_loss': '0.04612'}; time used = 1.8739182949066162s
epoch 30: {'train_loss': '0.02275'}; time used = 1.7180569171905518s
epoch 35: {'train_loss': '0.02525'}; time used = 1.6854240894317627s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.576194047927856.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5436507936507937, 'samples': 0.5652173913043478, 'weighted': 0.5508396595353117, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.05552'}; time used = 4.881984710693359s
epoch 10: {'train_loss': '2.78301'}; time used = 4.702625274658203s
epoch 15: {'train_loss': '2.79044'}; time used = 4.423241853713989s
epoch 20: {'train_loss': '2.79886'}; time used = 4.715056419372559s
epoch 25: {'train_loss': '2.77348'}; time used = 4.576602458953857s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 59.7410523891449.
Training classifier using 80.00% nodes...
{'micro': 0.685, 'macro': 0.6849921248031201, 'samples': 0.685, 'weighted': 0.6849606240156004, 'accuracy': 0.685}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.77406'}; time used = 1.1305227279663086s
epoch 10: {'train_loss': '2.79770'}; time used = 0.9868156909942627s
epoch 15: {'train_loss': '2.71735'}; time used = 0.8747055530548096s
epoch 20: {'train_loss': '2.40685'}; time used = 1.064836025238037s
epoch 25: {'train_loss': '1.81759'}; time used = 0.9480068683624268s
epoch 30: {'train_loss': '1.76502'}; time used = 0.8921215534210205s
epoch 35: {'train_loss': '1.58440'}; time used = 0.8860986232757568s
epoch 40: {'train_loss': '1.52487'}; time used = 1.0350902080535889s
epoch 45: {'train_loss': '1.57780'}; time used = 0.959265947341919s
epoch 50: {'train_loss': '1.71965'}; time used = 0.9150254726409912s
epoch 55: {'train_loss': '1.55945'}; time used = 1.0288739204406738s
epoch 60: {'train_loss': '1.56900'}; time used = 1.0238289833068848s
epoch 65: {'train_loss': '1.45615'}; time used = 0.9265224933624268s
epoch 70: {'train_loss': '1.43507'}; time used = 0.9730217456817627s
epoch 75: {'train_loss': '1.36481'}; time used = 0.8779120445251465s
epoch 80: {'train_loss': '1.38760'}; time used = 0.8798167705535889s
epoch 85: {'train_loss': '1.40762'}; time used = 0.985806941986084s
epoch 90: {'train_loss': '1.37799'}; time used = 0.9291543960571289s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.164982795715332.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.30239'}; time used = 2.5320327281951904s
epoch 10: {'train_loss': '2.91457'}; time used = 2.4777228832244873s
epoch 15: {'train_loss': '2.84955'}; time used = 2.463322639465332s
epoch 20: {'train_loss': '2.82495'}; time used = 1.7664794921875s
epoch 25: {'train_loss': '2.80375'}; time used = 1.2466318607330322s
epoch 30: {'train_loss': '2.79554'}; time used = 1.1790814399719238s
epoch 35: {'train_loss': '2.80112'}; time used = 1.081833839416504s
epoch 40: {'train_loss': '2.79249'}; time used = 1.0685374736785889s
epoch 45: {'train_loss': '2.79089'}; time used = 1.128110647201538s
epoch 50: {'train_loss': '2.78234'}; time used = 1.0550005435943604s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.910106420516968.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.525, 'samples': 0.631578947368421, 'weighted': 0.5605263157894737, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.77101'}; time used = 1.0580480098724365s
epoch 10: {'train_loss': '2.69579'}; time used = 0.9012026786804199s
epoch 15: {'train_loss': '2.54917'}; time used = 0.9248406887054443s
epoch 20: {'train_loss': '2.37545'}; time used = 1.0319054126739502s
epoch 25: {'train_loss': '2.17012'}; time used = 0.975271463394165s
epoch 30: {'train_loss': '2.10935'}; time used = 0.932941198348999s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.841514587402344.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.8869047619047619, 'samples': 0.8947368421052632, 'weighted': 0.8916040100250626, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.10102'}; time used = 1.0712103843688965s
epoch 10: {'train_loss': '0.82679'}; time used = 1.0407278537750244s
epoch 15: {'train_loss': '0.92952'}; time used = 1.0027852058410645s
epoch 20: {'train_loss': '0.61140'}; time used = 0.9918496608734131s
epoch 25: {'train_loss': '0.57359'}; time used = 1.025467872619629s
epoch 30: {'train_loss': '0.39605'}; time used = 1.060131311416626s
epoch 35: {'train_loss': '0.24997'}; time used = 1.033886432647705s
epoch 40: {'train_loss': '0.12268'}; time used = 1.0804269313812256s
epoch 45: {'train_loss': '0.08469'}; time used = 1.1796958446502686s
epoch 50: {'train_loss': '0.06182'}; time used = 1.0576653480529785s
epoch 55: {'train_loss': '0.04715'}; time used = 1.0165627002716064s
epoch 60: {'train_loss': '0.02086'}; time used = 1.0439543724060059s
epoch 65: {'train_loss': '0.03133'}; time used = 1.2993464469909668s
epoch 70: {'train_loss': '0.02705'}; time used = 1.4571080207824707s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.902241468429565.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5722943722943723, 'samples': 0.6578947368421053, 'weighted': 0.6025062656641604, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37745'}; time used = 1.1392412185668945s
epoch 10: {'train_loss': '1.54904'}; time used = 1.0343759059906006s
epoch 15: {'train_loss': '1.38355'}; time used = 1.0255978107452393s
epoch 20: {'train_loss': '1.38899'}; time used = 1.02431321144104s
epoch 25: {'train_loss': '1.38783'}; time used = 1.0635876655578613s
epoch 30: {'train_loss': '1.38416'}; time used = 1.9897332191467285s
epoch 35: {'train_loss': '1.39152'}; time used = 2.7022361755371094s
epoch 40: {'train_loss': '1.37133'}; time used = 1.5542993545532227s
epoch 45: {'train_loss': '1.33632'}; time used = 0.985905647277832s
epoch 50: {'train_loss': '1.40059'}; time used = 1.0035679340362549s
epoch 55: {'train_loss': '1.36883'}; time used = 1.0069961547851562s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.76259469985962.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.05631'}; time used = 1.7240090370178223s
epoch 10: {'train_loss': '0.46876'}; time used = 1.64509916305542s
epoch 15: {'train_loss': '0.30834'}; time used = 1.724684715270996s
epoch 20: {'train_loss': '0.28074'}; time used = 1.7091560363769531s
epoch 25: {'train_loss': '0.30440'}; time used = 1.7469267845153809s
epoch 30: {'train_loss': '0.29153'}; time used = 1.7364768981933594s
epoch 35: {'train_loss': '0.28912'}; time used = 1.7881202697753906s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.585740327835083.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39657'}; time used = 1.0879020690917969s
epoch 10: {'train_loss': '1.37657'}; time used = 0.9572229385375977s
epoch 15: {'train_loss': '1.25997'}; time used = 0.9796187877655029s
epoch 20: {'train_loss': '1.22466'}; time used = 0.9700992107391357s
epoch 25: {'train_loss': '1.07887'}; time used = 0.9686834812164307s
epoch 30: {'train_loss': '1.04458'}; time used = 0.9574334621429443s
epoch 35: {'train_loss': '0.90110'}; time used = 0.9470021724700928s
epoch 40: {'train_loss': '0.89669'}; time used = 0.9436812400817871s
epoch 45: {'train_loss': '0.71853'}; time used = 0.9460365772247314s
epoch 50: {'train_loss': '1.01798'}; time used = 1.0495364665985107s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.2240731716156.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.04890'}; time used = 1.0962882041931152s
epoch 10: {'train_loss': '0.87197'}; time used = 0.9425852298736572s
epoch 15: {'train_loss': '0.70545'}; time used = 0.9707930088043213s
epoch 20: {'train_loss': '0.51253'}; time used = 1.1172606945037842s
epoch 25: {'train_loss': '0.39394'}; time used = 1.11897611618042s
epoch 30: {'train_loss': '0.30200'}; time used = 1.1242387294769287s
epoch 35: {'train_loss': '0.23035'}; time used = 1.1215143203735352s
epoch 40: {'train_loss': '0.22397'}; time used = 1.114957571029663s
epoch 45: {'train_loss': '0.27883'}; time used = 1.1041460037231445s
epoch 50: {'train_loss': '0.25362'}; time used = 0.9392659664154053s
epoch 55: {'train_loss': '0.22925'}; time used = 0.9352054595947266s
epoch 60: {'train_loss': '0.19392'}; time used = 1.02323317527771s
epoch 65: {'train_loss': '0.23543'}; time used = 0.9458916187286377s
epoch 70: {'train_loss': '0.20325'}; time used = 0.9552273750305176s
epoch 75: {'train_loss': '0.09906'}; time used = 0.9569895267486572s
epoch 80: {'train_loss': '0.13897'}; time used = 1.003694772720337s
epoch 85: {'train_loss': '0.15078'}; time used = 0.9706361293792725s
epoch 90: {'train_loss': '0.10974'}; time used = 0.9957225322723389s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.93365716934204.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39173'}; time used = 1.1311538219451904s
epoch 10: {'train_loss': '1.36188'}; time used = 1.037032127380371s
epoch 15: {'train_loss': '1.26067'}; time used = 1.186669111251831s
epoch 20: {'train_loss': '1.28189'}; time used = 1.2071709632873535s
epoch 25: {'train_loss': '1.18657'}; time used = 1.2143640518188477s
epoch 30: {'train_loss': '1.05412'}; time used = 1.1795666217803955s
epoch 35: {'train_loss': '1.13107'}; time used = 1.2004244327545166s
epoch 40: {'train_loss': '1.13537'}; time used = 1.2122602462768555s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.558014631271362.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 9.248242855072021s
epoch 10: {'train_loss': '1.38629'}; time used = 7.859980344772339s
epoch 15: {'train_loss': '1.38629'}; time used = 6.83661961555481s
epoch 20: {'train_loss': '1.38629'}; time used = 8.253518104553223s
epoch 25: {'train_loss': '1.38629'}; time used = 6.699100017547607s
epoch 30: {'train_loss': '1.38629'}; time used = 6.177280426025391s
epoch 35: {'train_loss': '1.38629'}; time used = 6.190604209899902s
epoch 40: {'train_loss': '1.38629'}; time used = 6.462453603744507s
epoch 45: {'train_loss': '1.38629'}; time used = 6.4838597774505615s
epoch 50: {'train_loss': '1.38629'}; time used = 6.2633280754089355s
epoch 55: {'train_loss': '1.38629'}; time used = 6.92634129524231s
epoch 60: {'train_loss': '1.38629'}; time used = 6.520202159881592s
epoch 65: {'train_loss': '1.38629'}; time used = 6.8200297355651855s
epoch 70: {'train_loss': '1.38629'}; time used = 7.110883712768555s
epoch 75: {'train_loss': '1.38629'}; time used = 6.2391932010650635s
epoch 80: {'train_loss': '1.38629'}; time used = 6.58672571182251s
epoch 85: {'train_loss': '1.38629'}; time used = 8.314184427261353s
epoch 90: {'train_loss': '1.38629'}; time used = 6.697232723236084s
epoch 95: {'train_loss': '1.38629'}; time used = 6.206957578659058s
epoch 100: {'train_loss': '1.38629'}; time used = 6.14245867729187s
epoch 105: {'train_loss': '1.38629'}; time used = 6.445801019668579s
epoch 110: {'train_loss': '1.38629'}; time used = 6.2847514152526855s
epoch 115: {'train_loss': '1.38629'}; time used = 6.512729644775391s
epoch 120: {'train_loss': '1.38629'}; time used = 9.503981113433838s
epoch 125: {'train_loss': '1.38629'}; time used = 7.2928643226623535s
epoch 130: {'train_loss': '1.38629'}; time used = 6.327656269073486s
epoch 135: {'train_loss': '1.38629'}; time used = 6.561500787734985s
epoch 140: {'train_loss': '1.38629'}; time used = 6.4957053661346436s
epoch 145: {'train_loss': '1.38629'}; time used = 6.159552335739136s
epoch 150: {'train_loss': '1.38629'}; time used = 6.0997724533081055s
epoch 155: {'train_loss': '1.38629'}; time used = 7.7621307373046875s
epoch 160: {'train_loss': '1.38629'}; time used = 6.827857732772827s
epoch 165: {'train_loss': '1.38629'}; time used = 7.047066688537598s
epoch 170: {'train_loss': '1.38629'}; time used = 6.777344465255737s
epoch 175: {'train_loss': '1.38629'}; time used = 6.462339639663696s
epoch 180: {'train_loss': '1.38629'}; time used = 10.143165349960327s
epoch 185: {'train_loss': '1.38629'}; time used = 10.294853925704956s
epoch 190: {'train_loss': '1.38629'}; time used = 6.520843029022217s
epoch 195: {'train_loss': '1.38629'}; time used = 6.2836012840271s
epoch 200: {'train_loss': '1.38629'}; time used = 6.183632850646973s
epoch 205: {'train_loss': '1.38629'}; time used = 6.23699951171875s
epoch 210: {'train_loss': '1.38629'}; time used = 6.198828458786011s
epoch 215: {'train_loss': '1.38629'}; time used = 6.184213399887085s
epoch 220: {'train_loss': '1.38629'}; time used = 6.207062244415283s
epoch 225: {'train_loss': '1.38629'}; time used = 6.252989053726196s
epoch 230: {'train_loss': '1.38629'}; time used = 6.953531742095947s
epoch 235: {'train_loss': '1.38629'}; time used = 6.25695538520813s
epoch 240: {'train_loss': '1.38629'}; time used = 6.202211618423462s
epoch 245: {'train_loss': '1.38629'}; time used = 6.275820970535278s
epoch 250: {'train_loss': '1.38629'}; time used = 6.3431150913238525s
epoch 255: {'train_loss': '1.38629'}; time used = 6.242983102798462s
epoch 260: {'train_loss': '1.38629'}; time used = 7.800073146820068s
epoch 265: {'train_loss': '1.38629'}; time used = 9.887580871582031s
epoch 270: {'train_loss': '1.38629'}; time used = 10.914963245391846s
epoch 275: {'train_loss': '1.38629'}; time used = 6.6793272495269775s
epoch 280: {'train_loss': '1.38629'}; time used = 7.395685434341431s
epoch 285: {'train_loss': '1.38629'}; time used = 9.612155199050903s
epoch 290: {'train_loss': '1.38629'}; time used = 7.424000263214111s
epoch 295: {'train_loss': '1.38629'}; time used = 6.976562738418579s
epoch 300: {'train_loss': '1.38629'}; time used = 6.48358154296875s
epoch 305: {'train_loss': '1.38629'}; time used = 8.636029720306396s
epoch 310: {'train_loss': '1.38629'}; time used = 8.42668342590332s
epoch 315: {'train_loss': '1.38629'}; time used = 7.307908058166504s
epoch 320: {'train_loss': '1.38629'}; time used = 8.66211748123169s
epoch 325: {'train_loss': '1.38629'}; time used = 6.4075000286102295s
epoch 330: {'train_loss': '1.38629'}; time used = 6.209144592285156s
epoch 335: {'train_loss': '1.38629'}; time used = 6.355381727218628s
epoch 340: {'train_loss': '1.38629'}; time used = 6.329845190048218s
epoch 345: {'train_loss': '1.38629'}; time used = 6.372762203216553s
epoch 350: {'train_loss': '1.38629'}; time used = 6.24488639831543s
epoch 355: {'train_loss': '1.38629'}; time used = 6.112772464752197s
epoch 360: {'train_loss': '1.38629'}; time used = 6.149624824523926s
epoch 365: {'train_loss': '1.38629'}; time used = 7.374365329742432s
epoch 370: {'train_loss': '1.38629'}; time used = 7.43491530418396s
epoch 375: {'train_loss': '1.38629'}; time used = 7.340031147003174s
epoch 380: {'train_loss': '1.38629'}; time used = 7.2075231075286865s
epoch 385: {'train_loss': '1.38629'}; time used = 10.826151132583618s
epoch 390: {'train_loss': '1.38629'}; time used = 8.112836360931396s
epoch 395: {'train_loss': '1.38629'}; time used = 6.531092643737793s
epoch 400: {'train_loss': '1.38629'}; time used = 6.4344213008880615s
epoch 405: {'train_loss': '1.38629'}; time used = 6.246019601821899s
epoch 410: {'train_loss': '1.38629'}; time used = 6.262056827545166s
epoch 415: {'train_loss': '1.38629'}; time used = 6.3779296875s
epoch 420: {'train_loss': '1.38629'}; time used = 6.319908618927002s
epoch 425: {'train_loss': '1.38629'}; time used = 8.372733116149902s
epoch 430: {'train_loss': '1.38629'}; time used = 8.32634949684143s
epoch 435: {'train_loss': '1.38629'}; time used = 6.463726997375488s
epoch 440: {'train_loss': '1.38629'}; time used = 6.340175151824951s
epoch 445: {'train_loss': '1.38629'}; time used = 6.327331066131592s
epoch 450: {'train_loss': '1.38629'}; time used = 6.257121562957764s
epoch 455: {'train_loss': '1.38629'}; time used = 6.363996982574463s
epoch 460: {'train_loss': '1.38629'}; time used = 7.245124578475952s
epoch 465: {'train_loss': '1.38629'}; time used = 7.506312608718872s
epoch 470: {'train_loss': '1.38629'}; time used = 6.265092849731445s
epoch 475: {'train_loss': '1.38629'}; time used = 6.262795925140381s
epoch 480: {'train_loss': '1.38629'}; time used = 6.39688515663147s
epoch 485: {'train_loss': '1.38629'}; time used = 7.0652594566345215s
epoch 490: {'train_loss': '1.38629'}; time used = 8.037464618682861s
epoch 495: {'train_loss': '1.38629'}; time used = 6.692820310592651s
epoch 500: {'train_loss': '1.38629'}; time used = 6.4064319133758545s
Finished training. Time used = 710.4124674797058.
Training classifier using 80.00% nodes...
{'micro': 0.32666666666666666, 'macro': 0.18259451161005566, 'samples': 0.32666666666666666, 'weighted': 0.17711667626175395, 'accuracy': 0.32666666666666666}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.83248'}; time used = 6.670364856719971s
epoch 10: {'train_loss': '2.80120'}; time used = 6.596997022628784s
epoch 15: {'train_loss': '2.78457'}; time used = 6.680589914321899s
epoch 20: {'train_loss': '2.77603'}; time used = 8.511619329452515s
epoch 25: {'train_loss': '2.76843'}; time used = 6.566998720169067s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 56.963371992111206.
Training classifier using 80.00% nodes...
{'micro': 0.4666666666666667, 'macro': 0.46399826781583203, 'samples': 0.4666666666666667, 'weighted': 0.4619009798798792, 'accuracy': 0.4666666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.58803'}; time used = 1.0743348598480225s
epoch 10: {'train_loss': '1.96249'}; time used = 1.9740025997161865s
epoch 15: {'train_loss': '1.80942'}; time used = 2.1914682388305664s
epoch 20: {'train_loss': '1.54739'}; time used = 1.0737226009368896s
epoch 25: {'train_loss': '1.55807'}; time used = 1.11106276512146s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.552334308624268.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7913725490196077, 'samples': 0.8157894736842105, 'weighted': 0.8026418988648091, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.78366'}; time used = 1.3043334484100342s
epoch 10: {'train_loss': '2.78356'}; time used = 1.1600735187530518s
epoch 15: {'train_loss': '2.78080'}; time used = 1.1519877910614014s
epoch 20: {'train_loss': '2.77423'}; time used = 1.1493825912475586s
epoch 25: {'train_loss': '2.77280'}; time used = 1.1539607048034668s
epoch 30: {'train_loss': '2.77332'}; time used = 1.1557831764221191s
epoch 35: {'train_loss': '2.77341'}; time used = 1.164201259613037s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.806714534759521.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6161616161616161, 'samples': 0.6842105263157895, 'weighted': 0.6416799574694312, 'accuracy': 0.6842105263157895}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.31 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77240'}; time used = 2.2058753967285156s
epoch 10: {'train_loss': '2.78425'}; time used = 1.1109542846679688s
epoch 15: {'train_loss': '2.78095'}; time used = 1.1091530323028564s
epoch 20: {'train_loss': '2.77229'}; time used = 1.2394580841064453s
epoch 25: {'train_loss': '2.77531'}; time used = 1.103304386138916s
epoch 30: {'train_loss': '2.77211'}; time used = 1.2402479648590088s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.479137420654297.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.31 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.20207'}; time used = 1.788839340209961s
epoch 10: {'train_loss': '0.53286'}; time used = 1.8288562297821045s
epoch 15: {'train_loss': '0.44735'}; time used = 1.7454590797424316s
epoch 20: {'train_loss': '0.37196'}; time used = 1.7967076301574707s
epoch 25: {'train_loss': '0.30563'}; time used = 1.875154733657837s
epoch 30: {'train_loss': '0.26443'}; time used = 1.6241908073425293s
epoch 35: {'train_loss': '0.27122'}; time used = 1.5373477935791016s
epoch 40: {'train_loss': '0.27595'}; time used = 1.7626347541809082s
epoch 45: {'train_loss': '0.29079'}; time used = 1.6344876289367676s
epoch 50: {'train_loss': '0.28948'}; time used = 1.6538188457489014s
epoch 55: {'train_loss': '0.24069'}; time used = 1.789870023727417s
epoch 60: {'train_loss': '0.27113'}; time used = 1.629560947418213s
epoch 65: {'train_loss': '0.22061'}; time used = 1.6171822547912598s
epoch 70: {'train_loss': '0.29784'}; time used = 1.6109230518341064s
epoch 75: {'train_loss': '0.19235'}; time used = 1.6192002296447754s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.15852379798889.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.27368'}; time used = 1.7035698890686035s
epoch 10: {'train_loss': '0.90802'}; time used = 1.8903982639312744s
epoch 15: {'train_loss': '0.35702'}; time used = 1.6814744472503662s
epoch 20: {'train_loss': '0.52489'}; time used = 1.6728627681732178s
epoch 25: {'train_loss': '0.30252'}; time used = 1.7442803382873535s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.261624574661255.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5201264488935722, 'samples': 0.5217391304347826, 'weighted': 0.5221423008200852, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.33653'}; time used = 2.5511772632598877s
epoch 10: {'train_loss': '1.22648'}; time used = 2.4231057167053223s
epoch 15: {'train_loss': '1.21070'}; time used = 2.6898717880249023s
epoch 20: {'train_loss': '1.20461'}; time used = 2.5828633308410645s
epoch 25: {'train_loss': '1.15898'}; time used = 2.526218891143799s
epoch 30: {'train_loss': '1.09433'}; time used = 2.4678423404693604s
epoch 35: {'train_loss': '0.99837'}; time used = 2.598341226577759s
epoch 40: {'train_loss': '0.91570'}; time used = 2.6180379390716553s
epoch 45: {'train_loss': '1.00583'}; time used = 2.40352201461792s
epoch 50: {'train_loss': '0.68609'}; time used = 2.5110058784484863s
epoch 55: {'train_loss': '0.60054'}; time used = 2.436624765396118s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.0174503326416.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.566601689408707, 'samples': 0.5797101449275363, 'weighted': 0.5720635458748858, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.74501'}; time used = 2.12353515625s
epoch 10: {'train_loss': '2.57902'}; time used = 2.347616672515869s
epoch 15: {'train_loss': '2.40938'}; time used = 2.016045570373535s
epoch 20: {'train_loss': '2.11800'}; time used = 2.150209665298462s
epoch 25: {'train_loss': '2.06361'}; time used = 2.182251453399658s
epoch 30: {'train_loss': '1.94305'}; time used = 1.979485034942627s
epoch 35: {'train_loss': '1.90913'}; time used = 2.1628987789154053s
epoch 40: {'train_loss': '1.86445'}; time used = 2.0853071212768555s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.68591594696045.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77937'}; time used = 2.555724620819092s
epoch 10: {'train_loss': '2.77319'}; time used = 3.462702989578247s
epoch 15: {'train_loss': '2.76981'}; time used = 3.4032435417175293s
epoch 20: {'train_loss': '2.76480'}; time used = 2.0905396938323975s
epoch 25: {'train_loss': '2.76318'}; time used = 1.870520830154419s
epoch 30: {'train_loss': '2.75683'}; time used = 1.8124217987060547s
epoch 35: {'train_loss': '2.75364'}; time used = 1.6624696254730225s
epoch 40: {'train_loss': '2.75125'}; time used = 2.703066110610962s
epoch 45: {'train_loss': '2.74574'}; time used = 1.9851853847503662s
epoch 50: {'train_loss': '2.74652'}; time used = 2.119997262954712s
epoch 55: {'train_loss': '2.74437'}; time used = 1.8182485103607178s
epoch 60: {'train_loss': '2.73301'}; time used = 1.7556021213531494s
epoch 65: {'train_loss': '2.73018'}; time used = 1.7293806076049805s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.629536390304565.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5251942286348501, 'samples': 0.5507246376811594, 'weighted': 0.5331724814618218, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.40305'}; time used = 1.9510219097137451s
epoch 10: {'train_loss': '0.93079'}; time used = 2.001317024230957s
epoch 15: {'train_loss': '0.00001'}; time used = 2.6371781826019287s
epoch 20: {'train_loss': '0.00000'}; time used = 1.8292577266693115s
epoch 25: {'train_loss': '0.00000'}; time used = 1.9997401237487793s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.176737308502197.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4968569273321599, 'samples': 0.5797101449275363, 'weighted': 0.5116521447599057, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 26.50 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 6.491904020309448s
epoch 10: {'train_loss': '1.38629'}; time used = 6.381675481796265s
epoch 15: {'train_loss': '1.38629'}; time used = 6.325777292251587s
epoch 20: {'train_loss': '1.38629'}; time used = 6.583158731460571s
epoch 25: {'train_loss': '1.38629'}; time used = 6.556713581085205s
epoch 30: {'train_loss': '1.38629'}; time used = 8.748911142349243s
epoch 35: {'train_loss': '1.38629'}; time used = 8.06131362915039s
epoch 40: {'train_loss': '1.38629'}; time used = 6.186628341674805s
epoch 45: {'train_loss': '1.38629'}; time used = 6.554885387420654s
epoch 50: {'train_loss': '1.38629'}; time used = 6.251885414123535s
epoch 55: {'train_loss': '1.38629'}; time used = 6.308557510375977s
epoch 60: {'train_loss': '1.38629'}; time used = 6.387251615524292s
epoch 65: {'train_loss': '1.38629'}; time used = 6.388563394546509s
epoch 70: {'train_loss': '1.38629'}; time used = 6.293133974075317s
epoch 75: {'train_loss': '1.38629'}; time used = 6.204313039779663s
epoch 80: {'train_loss': '1.38629'}; time used = 6.353422403335571s
epoch 85: {'train_loss': '1.38629'}; time used = 6.172014951705933s
epoch 90: {'train_loss': '1.38629'}; time used = 6.404828310012817s
epoch 95: {'train_loss': '1.38629'}; time used = 6.507327318191528s
epoch 100: {'train_loss': '1.38629'}; time used = 6.331820249557495s
epoch 105: {'train_loss': '1.38629'}; time used = 6.2381885051727295s
epoch 110: {'train_loss': '1.38629'}; time used = 6.424100399017334s
epoch 115: {'train_loss': '1.38629'}; time used = 6.669616222381592s
epoch 120: {'train_loss': '1.38629'}; time used = 10.78316855430603s
epoch 125: {'train_loss': '1.38629'}; time used = 7.150289297103882s
epoch 130: {'train_loss': '1.38629'}; time used = 6.300329685211182s
epoch 135: {'train_loss': '1.38629'}; time used = 6.4180543422698975s
epoch 140: {'train_loss': '1.38629'}; time used = 6.380441188812256s
epoch 145: {'train_loss': '1.38629'}; time used = 7.310229063034058s
epoch 150: {'train_loss': '1.38629'}; time used = 6.5383172035217285s
epoch 155: {'train_loss': '1.38629'}; time used = 10.625957727432251s
epoch 160: {'train_loss': '1.38629'}; time used = 7.1434595584869385s
epoch 165: {'train_loss': '1.38629'}; time used = 9.052230596542358s
epoch 170: {'train_loss': '1.38629'}; time used = 8.295083999633789s
epoch 175: {'train_loss': '1.38629'}; time used = 7.024099588394165s
epoch 180: {'train_loss': '1.38629'}; time used = 6.438808917999268s
epoch 185: {'train_loss': '1.38629'}; time used = 6.212908029556274s
epoch 190: {'train_loss': '1.38629'}; time used = 6.174116373062134s
epoch 195: {'train_loss': '1.38629'}; time used = 6.299327373504639s
epoch 200: {'train_loss': '1.38629'}; time used = 6.3438615798950195s
epoch 205: {'train_loss': '1.38629'}; time used = 6.352475881576538s
epoch 210: {'train_loss': '1.38629'}; time used = 11.02698802947998s
epoch 215: {'train_loss': '1.38629'}; time used = 7.585266828536987s
epoch 220: {'train_loss': '1.38629'}; time used = 9.554579257965088s
epoch 225: {'train_loss': '1.38629'}; time used = 13.848806142807007s
epoch 230: {'train_loss': '1.38629'}; time used = 7.291046619415283s
epoch 235: {'train_loss': '1.38629'}; time used = 6.567954778671265s
epoch 240: {'train_loss': '1.38629'}; time used = 6.450278043746948s
epoch 245: {'train_loss': '1.38629'}; time used = 6.29073691368103s
epoch 250: {'train_loss': '1.38629'}; time used = 6.291026830673218s
epoch 255: {'train_loss': '1.38629'}; time used = 6.569539546966553s
epoch 260: {'train_loss': '1.38629'}; time used = 7.040910482406616s
epoch 265: {'train_loss': '1.38629'}; time used = 7.329944372177124s
epoch 270: {'train_loss': '1.38629'}; time used = 7.333774089813232s
epoch 275: {'train_loss': '1.38629'}; time used = 7.344943284988403s
epoch 280: {'train_loss': '1.38629'}; time used = 7.992233037948608s
epoch 285: {'train_loss': '1.38629'}; time used = 6.352643966674805s
epoch 290: {'train_loss': '1.38629'}; time used = 6.502835512161255s
epoch 295: {'train_loss': '1.38629'}; time used = 6.220372200012207s
epoch 300: {'train_loss': '1.38629'}; time used = 6.235712766647339s
epoch 305: {'train_loss': '1.38629'}; time used = 6.284332513809204s
epoch 310: {'train_loss': '1.38629'}; time used = 6.244795083999634s
epoch 315: {'train_loss': '1.38629'}; time used = 6.0877509117126465s
epoch 320: {'train_loss': '1.38629'}; time used = 6.189164876937866s
epoch 325: {'train_loss': '1.38629'}; time used = 8.221899032592773s
epoch 330: {'train_loss': '1.38629'}; time used = 7.989034652709961s
epoch 335: {'train_loss': '1.38629'}; time used = 10.504979848861694s
epoch 340: {'train_loss': '1.38629'}; time used = 7.448324680328369s
epoch 345: {'train_loss': '1.38629'}; time used = 8.60950231552124s
epoch 350: {'train_loss': '1.38629'}; time used = 7.575345277786255s
epoch 355: {'train_loss': '1.38629'}; time used = 6.7481091022491455s
epoch 360: {'train_loss': '1.38629'}; time used = 6.372025966644287s
epoch 365: {'train_loss': '1.38629'}; time used = 6.830210447311401s
epoch 370: {'train_loss': '1.38629'}; time used = 6.279184103012085s
epoch 375: {'train_loss': '1.38629'}; time used = 6.153919219970703s
epoch 380: {'train_loss': '1.38629'}; time used = 6.431532859802246s
epoch 385: {'train_loss': '1.38629'}; time used = 10.298213243484497s
epoch 390: {'train_loss': '1.38629'}; time used = 7.596356153488159s
epoch 395: {'train_loss': '1.38629'}; time used = 7.191118001937866s
epoch 400: {'train_loss': '1.38629'}; time used = 7.110329627990723s
epoch 405: {'train_loss': '1.38629'}; time used = 7.106060028076172s
epoch 410: {'train_loss': '1.38629'}; time used = 7.133544445037842s
epoch 415: {'train_loss': '1.38629'}; time used = 7.174264192581177s
epoch 420: {'train_loss': '1.38629'}; time used = 7.231412649154663s
epoch 425: {'train_loss': '1.38629'}; time used = 6.324111461639404s
epoch 430: {'train_loss': '1.38629'}; time used = 8.661668062210083s
epoch 435: {'train_loss': '1.38629'}; time used = 7.692741394042969s
epoch 440: {'train_loss': '1.38629'}; time used = 6.443243503570557s
epoch 445: {'train_loss': '1.38629'}; time used = 6.202364921569824s
epoch 450: {'train_loss': '1.38629'}; time used = 6.313260793685913s
epoch 455: {'train_loss': '1.38629'}; time used = 6.211947679519653s
epoch 460: {'train_loss': '1.38629'}; time used = 6.290192604064941s
epoch 465: {'train_loss': '1.38629'}; time used = 10.566538572311401s
epoch 470: {'train_loss': '1.38629'}; time used = 6.575835466384888s
epoch 475: {'train_loss': '1.38629'}; time used = 6.179108619689941s
epoch 480: {'train_loss': '1.38629'}; time used = 6.270492076873779s
epoch 485: {'train_loss': '1.38629'}; time used = 6.355714797973633s
epoch 490: {'train_loss': '1.38629'}; time used = 6.183411598205566s
epoch 495: {'train_loss': '1.38629'}; time used = 6.190783500671387s
epoch 500: {'train_loss': '1.38629'}; time used = 6.303938150405884s
Finished training. Time used = 717.1106407642365.
Training classifier using 80.00% nodes...
{'micro': 0.4633333333333333, 'macro': 0.4411917026697685, 'samples': 0.4633333333333333, 'weighted': 0.43508095158967536, 'accuracy': 0.4633333333333333}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.32191'}; time used = 2.060671806335449s
epoch 10: {'train_loss': '1.24575'}; time used = 1.9275846481323242s
epoch 15: {'train_loss': '1.24732'}; time used = 1.9552154541015625s
epoch 20: {'train_loss': '1.19618'}; time used = 1.941460132598877s
epoch 25: {'train_loss': '1.08388'}; time used = 1.9630866050720215s
epoch 30: {'train_loss': '0.88538'}; time used = 1.8959193229675293s
epoch 35: {'train_loss': '0.88929'}; time used = 1.9016449451446533s
epoch 40: {'train_loss': '0.81404'}; time used = 1.9752347469329834s
epoch 45: {'train_loss': '0.73100'}; time used = 1.9123334884643555s
epoch 50: {'train_loss': '0.72745'}; time used = 2.0414371490478516s
epoch 55: {'train_loss': '0.71098'}; time used = 1.978804588317871s
epoch 60: {'train_loss': '0.66401'}; time used = 1.9030256271362305s
epoch 65: {'train_loss': '0.75578'}; time used = 1.908355951309204s
epoch 70: {'train_loss': '0.64243'}; time used = 1.9272994995117188s
epoch 75: {'train_loss': '0.68221'}; time used = 1.8781447410583496s
epoch 80: {'train_loss': '0.55431'}; time used = 1.919309139251709s
epoch 85: {'train_loss': '0.53745'}; time used = 1.8712196350097656s
epoch 90: {'train_loss': '0.59420'}; time used = 1.854637861251831s
epoch 95: {'train_loss': '0.59050'}; time used = 1.8674695491790771s
epoch 100: {'train_loss': '0.52672'}; time used = 1.8594069480895996s
epoch 105: {'train_loss': '0.51208'}; time used = 1.9363901615142822s
epoch 110: {'train_loss': '0.54958'}; time used = 1.8641650676727295s
epoch 115: {'train_loss': '0.56540'}; time used = 1.8643486499786377s
epoch 120: {'train_loss': '0.51807'}; time used = 1.8719258308410645s
epoch 125: {'train_loss': '0.51671'}; time used = 1.8832995891571045s
epoch 130: {'train_loss': '0.53921'}; time used = 1.8991601467132568s
epoch 135: {'train_loss': '0.60638'}; time used = 1.9515609741210938s
epoch 140: {'train_loss': '0.57184'}; time used = 1.8758330345153809s
epoch 145: {'train_loss': '0.42829'}; time used = 1.875798225402832s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 59.717479944229126.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5108695652173914, 'samples': 0.5652173913043478, 'weighted': 0.5226843100189036, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.35993'}; time used = 2.7828528881073s
epoch 10: {'train_loss': '1.27301'}; time used = 2.795565366744995s
epoch 15: {'train_loss': '1.29081'}; time used = 2.9059789180755615s
epoch 20: {'train_loss': '1.33182'}; time used = 2.8465561866760254s
epoch 25: {'train_loss': '1.32013'}; time used = 2.833547592163086s
epoch 30: {'train_loss': '1.26861'}; time used = 2.710909605026245s
epoch 35: {'train_loss': '1.25042'}; time used = 2.6979176998138428s
epoch 40: {'train_loss': '1.20564'}; time used = 2.6954894065856934s
epoch 45: {'train_loss': '1.26452'}; time used = 2.750335931777954s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.9755117893219.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5251942286348501, 'samples': 0.5507246376811594, 'weighted': 0.5331724814618218, 'accuracy': 0.5507246376811594}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.83867'}; time used = 1.123744010925293s
epoch 10: {'train_loss': '2.78715'}; time used = 1.0010859966278076s
epoch 15: {'train_loss': '2.77316'}; time used = 0.9899773597717285s
epoch 20: {'train_loss': '2.77420'}; time used = 1.004831314086914s
epoch 25: {'train_loss': '2.77536'}; time used = 1.0002357959747314s
epoch 30: {'train_loss': '2.77341'}; time used = 0.9633262157440186s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.431086301803589.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.3666666666666667, 'samples': 0.5789473684210527, 'weighted': 0.4245614035087719, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 26.49 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.84406'}; time used = 1.8739428520202637s
epoch 10: {'train_loss': '2.72870'}; time used = 1.7134912014007568s
epoch 15: {'train_loss': '2.70457'}; time used = 1.7278549671173096s
epoch 20: {'train_loss': '2.68265'}; time used = 1.7233092784881592s
epoch 25: {'train_loss': '2.65917'}; time used = 1.8037989139556885s
epoch 30: {'train_loss': '2.63972'}; time used = 1.7180168628692627s
epoch 35: {'train_loss': '2.62867'}; time used = 1.5142550468444824s
epoch 40: {'train_loss': '2.61490'}; time used = 1.5285024642944336s
epoch 45: {'train_loss': '2.60111'}; time used = 1.5323376655578613s
epoch 50: {'train_loss': '2.58115'}; time used = 1.541208267211914s
epoch 55: {'train_loss': '2.58703'}; time used = 1.6536126136779785s
epoch 60: {'train_loss': '2.59556'}; time used = 1.665576696395874s
epoch 65: {'train_loss': '2.58314'}; time used = 2.0138936042785645s
epoch 70: {'train_loss': '2.56749'}; time used = 2.0523874759674072s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.6108341217041.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5218637992831542, 'samples': 0.5797101449275363, 'weighted': 0.5339151212924004, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36382'}; time used = 1.938952922821045s
epoch 10: {'train_loss': '1.28572'}; time used = 1.7225406169891357s
epoch 15: {'train_loss': '1.16988'}; time used = 1.8521921634674072s
epoch 20: {'train_loss': '1.15245'}; time used = 2.3107991218566895s
epoch 25: {'train_loss': '0.95459'}; time used = 2.2439160346984863s
epoch 30: {'train_loss': '0.83388'}; time used = 2.129377841949463s
epoch 35: {'train_loss': '0.89747'}; time used = 2.007998466491699s
epoch 40: {'train_loss': '0.75081'}; time used = 1.9823455810546875s
epoch 45: {'train_loss': '0.62057'}; time used = 2.0234124660491943s
epoch 50: {'train_loss': '0.35958'}; time used = 1.8639237880706787s
epoch 55: {'train_loss': '0.34417'}; time used = 1.7731716632843018s
epoch 60: {'train_loss': '0.36563'}; time used = 1.772153615951538s
epoch 65: {'train_loss': '0.36604'}; time used = 1.8819239139556885s
epoch 70: {'train_loss': '0.13208'}; time used = 1.7426693439483643s
epoch 75: {'train_loss': '0.03637'}; time used = 1.8944091796875s
epoch 80: {'train_loss': '0.11198'}; time used = 1.9091382026672363s
epoch 85: {'train_loss': '0.13641'}; time used = 1.9764704704284668s
epoch 90: {'train_loss': '0.01983'}; time used = 1.7719619274139404s
epoch 95: {'train_loss': '0.07652'}; time used = 1.8797688484191895s
epoch 100: {'train_loss': '0.70686'}; time used = 1.856247901916504s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.38853693008423.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5315564495851144, 'samples': 0.6086956521739131, 'weighted': 0.545331307190257, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.33399'}; time used = 1.8234336376190186s
epoch 10: {'train_loss': '1.23131'}; time used = 1.7011966705322266s
epoch 15: {'train_loss': '1.18835'}; time used = 1.6919164657592773s
epoch 20: {'train_loss': '1.31426'}; time used = 1.7119030952453613s
epoch 25: {'train_loss': '1.25735'}; time used = 1.7733097076416016s
epoch 30: {'train_loss': '1.21243'}; time used = 3.578129529953003s
epoch 35: {'train_loss': '1.25752'}; time used = 4.867236137390137s
epoch 40: {'train_loss': '1.17740'}; time used = 1.8131225109100342s
epoch 45: {'train_loss': '1.22737'}; time used = 1.7093298435211182s
epoch 50: {'train_loss': '1.10052'}; time used = 2.5644943714141846s
epoch 55: {'train_loss': '1.07567'}; time used = 1.795210361480713s
epoch 60: {'train_loss': '1.13940'}; time used = 1.6848256587982178s
epoch 65: {'train_loss': '1.23101'}; time used = 1.7384381294250488s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.585795879364014.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5538793103448276, 'samples': 0.5652173913043478, 'weighted': 0.5590329835082459, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.84693'}; time used = 2.8243978023529053s
epoch 10: {'train_loss': '2.76552'}; time used = 2.0882344245910645s
epoch 15: {'train_loss': '2.77653'}; time used = 2.2408597469329834s
epoch 20: {'train_loss': '2.76495'}; time used = 2.229696035385132s
epoch 25: {'train_loss': '2.73861'}; time used = 2.139282464981079s
epoch 30: {'train_loss': '2.72295'}; time used = 3.4303345680236816s
epoch 35: {'train_loss': '2.71218'}; time used = 3.2324283123016357s
epoch 40: {'train_loss': '2.70726'}; time used = 2.536254405975342s
epoch 45: {'train_loss': '2.69863'}; time used = 2.1392765045166016s
epoch 50: {'train_loss': '2.69548'}; time used = 2.350050449371338s
epoch 55: {'train_loss': '2.69904'}; time used = 2.1600842475891113s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.9326171875.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4888888888888888, 'samples': 0.5362318840579711, 'weighted': 0.5001610305958131, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.85049'}; time used = 1.1226823329925537s
epoch 10: {'train_loss': '2.77985'}; time used = 1.0946238040924072s
epoch 15: {'train_loss': '2.78093'}; time used = 1.0555217266082764s
epoch 20: {'train_loss': '2.77920'}; time used = 1.059905767440796s
epoch 25: {'train_loss': '2.77305'}; time used = 1.1612417697906494s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.782840728759766.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37475'}; time used = 1.5102481842041016s
epoch 10: {'train_loss': '1.29825'}; time used = 1.965338945388794s
epoch 15: {'train_loss': '1.19115'}; time used = 3.684978723526001s
epoch 20: {'train_loss': '1.41152'}; time used = 2.3807640075683594s
epoch 25: {'train_loss': '1.37191'}; time used = 1.4260411262512207s
epoch 30: {'train_loss': '1.38604'}; time used = 1.3511643409729004s
epoch 35: {'train_loss': '1.39415'}; time used = 1.339902639389038s
epoch 40: {'train_loss': '1.37596'}; time used = 1.3221933841705322s
epoch 45: {'train_loss': '1.35495'}; time used = 1.305201530456543s
epoch 50: {'train_loss': '1.38715'}; time used = 1.3379490375518799s
epoch 55: {'train_loss': '1.37860'}; time used = 1.3728740215301514s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.22939395904541.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.4176245210727969, 'samples': 0.5789473684210527, 'weighted': 0.4660213752772736, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.26 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.94342'}; time used = 2.674043893814087s
epoch 10: {'train_loss': '2.74617'}; time used = 3.0539562702178955s
epoch 15: {'train_loss': '2.75338'}; time used = 2.348421573638916s
epoch 20: {'train_loss': '2.73613'}; time used = 2.3303277492523193s
epoch 25: {'train_loss': '2.71606'}; time used = 2.3470513820648193s
epoch 30: {'train_loss': '2.68986'}; time used = 2.2677371501922607s
epoch 35: {'train_loss': '2.64638'}; time used = 2.2491466999053955s
epoch 40: {'train_loss': '2.60254'}; time used = 2.2788920402526855s
epoch 45: {'train_loss': '2.52798'}; time used = 2.2440969944000244s
epoch 50: {'train_loss': '2.52045'}; time used = 2.259093761444092s
epoch 55: {'train_loss': '2.49521'}; time used = 2.4038023948669434s
epoch 60: {'train_loss': '2.48324'}; time used = 2.5430123805999756s
epoch 65: {'train_loss': '2.45464'}; time used = 2.4559483528137207s
epoch 70: {'train_loss': '2.41445'}; time used = 2.7451953887939453s
epoch 75: {'train_loss': '2.41576'}; time used = 2.4935107231140137s
epoch 80: {'train_loss': '2.39347'}; time used = 2.327040433883667s
epoch 85: {'train_loss': '2.40620'}; time used = 2.30029559135437s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.343037128448486.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.50682261208577, 'samples': 0.5217391304347826, 'weighted': 0.5130378280645252, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.40138'}; time used = 1.7051904201507568s
epoch 10: {'train_loss': '1.23309'}; time used = 1.6745953559875488s
epoch 15: {'train_loss': '1.04362'}; time used = 1.7142269611358643s
epoch 20: {'train_loss': '0.73343'}; time used = 1.7460579872131348s
epoch 25: {'train_loss': '0.59798'}; time used = 1.8846566677093506s
epoch 30: {'train_loss': '0.56864'}; time used = 1.7423830032348633s
epoch 35: {'train_loss': '0.29303'}; time used = 1.777261734008789s
epoch 40: {'train_loss': '0.26225'}; time used = 1.7030069828033447s
epoch 45: {'train_loss': '0.05281'}; time used = 1.67801833152771s
epoch 50: {'train_loss': '0.00636'}; time used = 1.7350263595581055s
epoch 55: {'train_loss': '0.00775'}; time used = 1.6712992191314697s
epoch 60: {'train_loss': '0.00587'}; time used = 1.8619487285614014s
epoch 65: {'train_loss': '0.00573'}; time used = 1.886772871017456s
epoch 70: {'train_loss': '0.00334'}; time used = 1.702608346939087s
epoch 75: {'train_loss': '0.00234'}; time used = 1.7839324474334717s
epoch 80: {'train_loss': '0.05620'}; time used = 1.7027506828308105s
epoch 85: {'train_loss': '0.00128'}; time used = 1.723792314529419s
epoch 90: {'train_loss': '0.03927'}; time used = 1.995586633682251s
epoch 95: {'train_loss': '0.00453'}; time used = 1.7301480770111084s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.80850148200989.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.6299077451190731, 'samples': 0.6376811594202898, 'weighted': 0.6337944522696815, 'accuracy': 0.6376811594202898}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.36356'}; time used = 7.664720058441162s
epoch 10: {'train_loss': '1.38118'}; time used = 7.574789762496948s
epoch 15: {'train_loss': '1.28274'}; time used = 7.573083162307739s
epoch 20: {'train_loss': '1.11632'}; time used = 7.39807391166687s
epoch 25: {'train_loss': '1.03387'}; time used = 8.003127336502075s
epoch 30: {'train_loss': '0.93606'}; time used = 8.345455408096313s
epoch 35: {'train_loss': '0.87594'}; time used = 8.44002103805542s
epoch 40: {'train_loss': '0.74938'}; time used = 7.38197922706604s
epoch 45: {'train_loss': '0.72435'}; time used = 7.421353101730347s
epoch 50: {'train_loss': '0.55729'}; time used = 6.822508096694946s
epoch 55: {'train_loss': '0.57499'}; time used = 6.616069555282593s
epoch 60: {'train_loss': '0.47590'}; time used = 7.389864921569824s
epoch 65: {'train_loss': '0.98904'}; time used = 7.631319761276245s
epoch 70: {'train_loss': '0.54741'}; time used = 6.994511127471924s
epoch 75: {'train_loss': '0.47414'}; time used = 7.069539785385132s
epoch 80: {'train_loss': '0.42569'}; time used = 7.125910520553589s
epoch 85: {'train_loss': '0.34419'}; time used = 8.058160781860352s
epoch 90: {'train_loss': '0.31292'}; time used = 7.950835943222046s
epoch 95: {'train_loss': '0.21504'}; time used = 6.572241306304932s
epoch 100: {'train_loss': '0.34996'}; time used = 7.789850234985352s
epoch 105: {'train_loss': '0.23002'}; time used = 8.140071868896484s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 176.72197818756104.
Training classifier using 80.00% nodes...
{'micro': 0.49666666666666665, 'macro': 0.48716451832279334, 'samples': 0.49666666666666665, 'weighted': 0.4830146990521793, 'accuracy': 0.49666666666666665}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.05596'}; time used = 2.0135385990142822s
epoch 10: {'train_loss': '2.77363'}; time used = 1.9980416297912598s
epoch 15: {'train_loss': '2.80762'}; time used = 1.9860320091247559s
epoch 20: {'train_loss': '2.80065'}; time used = 2.0261406898498535s
epoch 25: {'train_loss': '2.76722'}; time used = 2.027801752090454s
epoch 30: {'train_loss': '2.76746'}; time used = 1.9622111320495605s
epoch 35: {'train_loss': '2.75646'}; time used = 2.2484681606292725s
epoch 40: {'train_loss': '2.74381'}; time used = 2.5194215774536133s
epoch 45: {'train_loss': '2.73473'}; time used = 2.1535604000091553s
epoch 50: {'train_loss': '2.72586'}; time used = 2.3108808994293213s
epoch 55: {'train_loss': '2.72574'}; time used = 3.052234649658203s
epoch 60: {'train_loss': '2.71670'}; time used = 3.8710567951202393s
epoch 65: {'train_loss': '2.71331'}; time used = 3.832590103149414s
epoch 70: {'train_loss': '2.71670'}; time used = 2.0244171619415283s
epoch 75: {'train_loss': '2.69739'}; time used = 2.1409835815429688s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.57508683204651.
Training classifier using 80.00% nodes...
{'micro': 0.6666666666666666, 'macro': 0.6562703053931124, 'samples': 0.6666666666666666, 'weighted': 0.6606021225904266, 'accuracy': 0.6666666666666666}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.83103'}; time used = 2.335676670074463s
epoch 10: {'train_loss': '2.78753'}; time used = 2.1749870777130127s
epoch 15: {'train_loss': '2.66319'}; time used = 2.0821142196655273s
epoch 20: {'train_loss': '2.50664'}; time used = 2.0698094367980957s
epoch 25: {'train_loss': '2.30436'}; time used = 2.077557325363159s
epoch 30: {'train_loss': '2.18422'}; time used = 1.5316832065582275s
epoch 35: {'train_loss': '2.05701'}; time used = 1.5232205390930176s
epoch 40: {'train_loss': '2.14162'}; time used = 1.3991057872772217s
epoch 45: {'train_loss': '2.06206'}; time used = 1.5026047229766846s
epoch 50: {'train_loss': '2.02029'}; time used = 1.4495964050292969s
epoch 55: {'train_loss': '2.00697'}; time used = 1.4519245624542236s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.700368642807007.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6801346801346801, 'samples': 0.7368421052631579, 'weighted': 0.7013999645578592, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87621'}; time used = 2.6104438304901123s
epoch 10: {'train_loss': '2.79899'}; time used = 3.0579686164855957s
epoch 15: {'train_loss': '2.78607'}; time used = 3.2744336128234863s
epoch 20: {'train_loss': '2.77566'}; time used = 3.0896918773651123s
epoch 25: {'train_loss': '2.76650'}; time used = 2.388099431991577s
epoch 30: {'train_loss': '2.74845'}; time used = 2.2971277236938477s
epoch 35: {'train_loss': '2.72483'}; time used = 2.3208870887756348s
epoch 40: {'train_loss': '2.71172'}; time used = 2.4271256923675537s
epoch 45: {'train_loss': '2.66839'}; time used = 2.2895021438598633s
epoch 50: {'train_loss': '2.61994'}; time used = 2.2853775024414062s
epoch 55: {'train_loss': '2.60133'}; time used = 2.3768911361694336s
epoch 60: {'train_loss': '2.60124'}; time used = 2.299809217453003s
epoch 65: {'train_loss': '2.52989'}; time used = 2.2854835987091064s
epoch 70: {'train_loss': '2.46892'}; time used = 2.511930465698242s
epoch 75: {'train_loss': '2.44717'}; time used = 2.399052143096924s
epoch 80: {'train_loss': '2.42671'}; time used = 2.3648781776428223s
epoch 85: {'train_loss': '2.39805'}; time used = 2.3247809410095215s
epoch 90: {'train_loss': '2.45728'}; time used = 2.2796413898468018s
epoch 95: {'train_loss': '2.37849'}; time used = 2.303368330001831s
epoch 100: {'train_loss': '2.34045'}; time used = 2.3284707069396973s
epoch 105: {'train_loss': '2.36833'}; time used = 2.370776653289795s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 56.708465814590454.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4661508704061895, 'samples': 0.5362318840579711, 'weighted': 0.48016707313654583, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89859'}; time used = 2.5705413818359375s
epoch 10: {'train_loss': '2.81870'}; time used = 3.3952412605285645s
epoch 15: {'train_loss': '2.79683'}; time used = 3.0836031436920166s
epoch 20: {'train_loss': '2.77904'}; time used = 2.562530755996704s
epoch 25: {'train_loss': '2.77282'}; time used = 2.5240070819854736s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.449478149414062.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.5777233782129743, 'samples': 0.6376811594202898, 'weighted': 0.5892537207528425, 'accuracy': 0.6376811594202898}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.34292'}; time used = 1.97255277633667s
epoch 10: {'train_loss': '1.16755'}; time used = 1.941220760345459s
epoch 15: {'train_loss': '1.02185'}; time used = 1.9251830577850342s
epoch 20: {'train_loss': '1.04992'}; time used = 1.9241671562194824s
epoch 25: {'train_loss': '1.05075'}; time used = 1.9781217575073242s
epoch 30: {'train_loss': '0.80235'}; time used = 1.887507677078247s
epoch 35: {'train_loss': '0.66571'}; time used = 1.9504344463348389s
epoch 40: {'train_loss': '0.59233'}; time used = 1.9011437892913818s
epoch 45: {'train_loss': '0.57872'}; time used = 1.8640263080596924s
epoch 50: {'train_loss': '0.64244'}; time used = 1.9349026679992676s
epoch 55: {'train_loss': '0.39506'}; time used = 2.0552847385406494s
epoch 60: {'train_loss': '0.54391'}; time used = 2.269921064376831s
epoch 65: {'train_loss': '0.92754'}; time used = 1.954033374786377s
epoch 70: {'train_loss': '1.27387'}; time used = 1.853186845779419s
epoch 75: {'train_loss': '0.62003'}; time used = 1.9695863723754883s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.23873829841614.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84502'}; time used = 8.668762683868408s
epoch 10: {'train_loss': '2.77480'}; time used = 8.398877382278442s
epoch 15: {'train_loss': '2.77599'}; time used = 6.969212532043457s
epoch 20: {'train_loss': '2.77202'}; time used = 8.069515228271484s
epoch 25: {'train_loss': '2.76328'}; time used = 7.612548351287842s
epoch 30: {'train_loss': '2.76123'}; time used = 7.751478910446167s
epoch 35: {'train_loss': '2.74770'}; time used = 7.653744220733643s
epoch 40: {'train_loss': '2.73678'}; time used = 7.474776983261108s
epoch 45: {'train_loss': '2.72918'}; time used = 6.793528079986572s
epoch 50: {'train_loss': '2.72638'}; time used = 8.104907751083374s
epoch 55: {'train_loss': '2.72266'}; time used = 6.751748561859131s
epoch 60: {'train_loss': '2.72151'}; time used = 6.730806827545166s
epoch 65: {'train_loss': '2.71312'}; time used = 6.635019540786743s
epoch 70: {'train_loss': '2.71466'}; time used = 7.025342226028442s
epoch 75: {'train_loss': '2.70950'}; time used = 6.68860125541687s
epoch 80: {'train_loss': '2.71387'}; time used = 8.212677717208862s
epoch 85: {'train_loss': '2.70812'}; time used = 7.428314208984375s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 145.49779105186462.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.44913711583924343, 'samples': 0.5033333333333333, 'weighted': 0.44046300236406616, 'accuracy': 0.5033333333333333}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77734'}; time used = 1.170271873474121s
epoch 10: {'train_loss': '2.77314'}; time used = 1.0237317085266113s
epoch 15: {'train_loss': '2.77377'}; time used = 1.0291013717651367s
epoch 20: {'train_loss': '2.77579'}; time used = 1.0312480926513672s
epoch 25: {'train_loss': '2.77393'}; time used = 1.021738052368164s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.862074613571167.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38804'}; time used = 1.2273330688476562s
epoch 10: {'train_loss': '1.36074'}; time used = 1.1142237186431885s
epoch 15: {'train_loss': '1.19827'}; time used = 1.067620038986206s
epoch 20: {'train_loss': '1.02726'}; time used = 1.6677889823913574s
epoch 25: {'train_loss': '0.98520'}; time used = 2.973043203353882s
epoch 30: {'train_loss': '0.81266'}; time used = 1.1291966438293457s
epoch 35: {'train_loss': '0.68500'}; time used = 1.1835062503814697s
epoch 40: {'train_loss': '0.64580'}; time used = 1.0863409042358398s
epoch 45: {'train_loss': '0.92789'}; time used = 1.0901293754577637s
epoch 50: {'train_loss': '0.62913'}; time used = 1.0327701568603516s
epoch 55: {'train_loss': '0.74334'}; time used = 1.0492565631866455s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.791120767593384.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.26 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.05722'}; time used = 4.423960447311401s
epoch 10: {'train_loss': '2.78217'}; time used = 4.219187498092651s
epoch 15: {'train_loss': '2.79065'}; time used = 4.7000627517700195s
epoch 20: {'train_loss': '2.79817'}; time used = 6.626235008239746s
epoch 25: {'train_loss': '2.77452'}; time used = 4.1811699867248535s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.533092737197876.
Training classifier using 80.00% nodes...
{'micro': 0.705, 'macro': 0.7049926248156204, 'samples': 0.705, 'weighted': 0.7050221255531389, 'accuracy': 0.705}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.36193'}; time used = 1.9065194129943848s
epoch 10: {'train_loss': '1.25814'}; time used = 2.0404980182647705s
epoch 15: {'train_loss': '1.18710'}; time used = 3.6770029067993164s
epoch 20: {'train_loss': '1.21766'}; time used = 3.6883389949798584s
epoch 25: {'train_loss': '1.15365'}; time used = 2.0517544746398926s
epoch 30: {'train_loss': '0.94576'}; time used = 1.8744919300079346s
epoch 35: {'train_loss': '0.70078'}; time used = 1.6538066864013672s
epoch 40: {'train_loss': '0.67489'}; time used = 1.8420917987823486s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.73576259613037.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.15448'}; time used = 1.0945024490356445s
epoch 10: {'train_loss': '2.80950'}; time used = 1.0863051414489746s
epoch 15: {'train_loss': '2.83206'}; time used = 0.9989991188049316s
epoch 20: {'train_loss': '2.82242'}; time used = 0.9858174324035645s
epoch 25: {'train_loss': '2.80430'}; time used = 1.0216569900512695s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.007592678070068.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '3.10460'}; time used = 2.1170501708984375s
epoch 10: {'train_loss': '2.95735'}; time used = 3.1220483779907227s
epoch 15: {'train_loss': '2.87077'}; time used = 2.0699479579925537s
epoch 20: {'train_loss': '2.85139'}; time used = 1.992130994796753s
epoch 25: {'train_loss': '2.82154'}; time used = 2.002829074859619s
epoch 30: {'train_loss': '2.81079'}; time used = 1.938136339187622s
epoch 35: {'train_loss': '2.80167'}; time used = 1.9478049278259277s
epoch 40: {'train_loss': '2.79473'}; time used = 1.9331443309783936s
epoch 45: {'train_loss': '2.79424'}; time used = 2.0168282985687256s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.59652829170227.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.560909090909091, 'samples': 0.5942028985507246, 'weighted': 0.5696706192358367, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 26.50 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.78323'}; time used = 1.1758625507354736s
epoch 10: {'train_loss': '2.77856'}; time used = 1.040710687637329s
epoch 15: {'train_loss': '2.77807'}; time used = 0.9637537002563477s
epoch 20: {'train_loss': '2.77501'}; time used = 0.9944548606872559s
epoch 25: {'train_loss': '2.77193'}; time used = 0.9932601451873779s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.528043508529663.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 6.757778882980347s
epoch 10: {'train_loss': '1.38629'}; time used = 6.673330783843994s
epoch 15: {'train_loss': '1.38629'}; time used = 8.409003973007202s
epoch 20: {'train_loss': '1.38629'}; time used = 7.558312892913818s
epoch 25: {'train_loss': '1.38629'}; time used = 7.001530885696411s
epoch 30: {'train_loss': '1.38629'}; time used = 7.57178521156311s
epoch 35: {'train_loss': '1.38629'}; time used = 10.695165157318115s
epoch 40: {'train_loss': '1.38629'}; time used = 6.9298601150512695s
epoch 45: {'train_loss': '1.38629'}; time used = 6.9643402099609375s
epoch 50: {'train_loss': '1.38629'}; time used = 6.997282266616821s
epoch 55: {'train_loss': '1.38629'}; time used = 8.628293752670288s
epoch 60: {'train_loss': '1.38629'}; time used = 8.359909534454346s
epoch 65: {'train_loss': '1.38629'}; time used = 6.547302722930908s
epoch 70: {'train_loss': '1.38629'}; time used = 6.822188138961792s
epoch 75: {'train_loss': '1.38629'}; time used = 6.755481243133545s
epoch 80: {'train_loss': '1.38629'}; time used = 6.508309602737427s
epoch 85: {'train_loss': '1.38629'}; time used = 6.692115783691406s
epoch 90: {'train_loss': '1.38629'}; time used = 6.817543268203735s
epoch 95: {'train_loss': '1.38629'}; time used = 11.36750078201294s
epoch 100: {'train_loss': '1.38629'}; time used = 11.999988794326782s
epoch 105: {'train_loss': '1.38629'}; time used = 8.982463121414185s
epoch 110: {'train_loss': '1.38629'}; time used = 6.3417863845825195s
epoch 115: {'train_loss': '1.38629'}; time used = 6.317391633987427s
epoch 120: {'train_loss': '1.38629'}; time used = 6.292108058929443s
epoch 125: {'train_loss': '1.38629'}; time used = 6.232559680938721s
epoch 130: {'train_loss': '1.38629'}; time used = 6.4435272216796875s
epoch 135: {'train_loss': '1.38629'}; time used = 8.659507751464844s
epoch 140: {'train_loss': '1.38629'}; time used = 7.990880250930786s
epoch 145: {'train_loss': '1.38629'}; time used = 7.004756689071655s
epoch 150: {'train_loss': '1.38629'}; time used = 10.228379487991333s
epoch 155: {'train_loss': '1.38629'}; time used = 6.7439398765563965s
epoch 160: {'train_loss': '1.38629'}; time used = 6.546975135803223s
epoch 165: {'train_loss': '1.38629'}; time used = 6.553687334060669s
epoch 170: {'train_loss': '1.38629'}; time used = 7.2197301387786865s
epoch 175: {'train_loss': '1.38629'}; time used = 6.525476932525635s
epoch 180: {'train_loss': '1.38629'}; time used = 6.26581883430481s
epoch 185: {'train_loss': '1.38629'}; time used = 6.318285226821899s
epoch 190: {'train_loss': '1.38629'}; time used = 6.259944438934326s
epoch 195: {'train_loss': '1.38629'}; time used = 6.677274465560913s
epoch 200: {'train_loss': '1.38629'}; time used = 8.969163417816162s
epoch 205: {'train_loss': '1.38629'}; time used = 10.120459794998169s
epoch 210: {'train_loss': '1.38629'}; time used = 6.489291191101074s
epoch 215: {'train_loss': '1.38629'}; time used = 6.525940179824829s
epoch 220: {'train_loss': '1.38629'}; time used = 6.991501569747925s
epoch 225: {'train_loss': '1.38629'}; time used = 10.1373770236969s
epoch 230: {'train_loss': '1.38629'}; time used = 9.712140798568726s
epoch 235: {'train_loss': '1.38629'}; time used = 6.599011659622192s
epoch 240: {'train_loss': '1.38629'}; time used = 6.528447866439819s
epoch 245: {'train_loss': '1.38629'}; time used = 6.349529027938843s
epoch 250: {'train_loss': '1.38629'}; time used = 6.49983549118042s
epoch 255: {'train_loss': '1.38629'}; time used = 7.03191351890564s
epoch 260: {'train_loss': '1.38629'}; time used = 6.784051418304443s
epoch 265: {'train_loss': '1.38629'}; time used = 6.469090938568115s
epoch 270: {'train_loss': '1.38629'}; time used = 6.4752092361450195s
epoch 275: {'train_loss': '1.38629'}; time used = 6.802167654037476s
epoch 280: {'train_loss': '1.38629'}; time used = 6.665354490280151s
epoch 285: {'train_loss': '1.38629'}; time used = 10.64341425895691s
epoch 290: {'train_loss': '1.38629'}; time used = 7.539112567901611s
epoch 295: {'train_loss': '1.38629'}; time used = 10.044373035430908s
epoch 300: {'train_loss': '1.38629'}; time used = 6.617049932479858s
epoch 305: {'train_loss': '1.38629'}; time used = 6.440552234649658s
epoch 310: {'train_loss': '1.38629'}; time used = 6.542596101760864s
epoch 315: {'train_loss': '1.38629'}; time used = 9.705862045288086s
epoch 320: {'train_loss': '1.38629'}; time used = 9.18662691116333s
epoch 325: {'train_loss': '1.38629'}; time used = 6.898788213729858s
epoch 330: {'train_loss': '1.38629'}; time used = 9.864277839660645s
epoch 335: {'train_loss': '1.38629'}; time used = 7.89568567276001s
epoch 340: {'train_loss': '1.38629'}; time used = 6.421739339828491s
epoch 345: {'train_loss': '1.38629'}; time used = 7.058665037155151s
epoch 350: {'train_loss': '1.38629'}; time used = 6.637277364730835s
epoch 355: {'train_loss': '1.38629'}; time used = 6.726259231567383s
epoch 360: {'train_loss': '1.38629'}; time used = 9.332268238067627s
epoch 365: {'train_loss': '1.38629'}; time used = 7.539276599884033s
epoch 370: {'train_loss': '1.38629'}; time used = 6.769617795944214s
epoch 375: {'train_loss': '1.38629'}; time used = 6.505084276199341s
epoch 380: {'train_loss': '1.38629'}; time used = 7.248692274093628s
epoch 385: {'train_loss': '1.38629'}; time used = 10.145068645477295s
epoch 390: {'train_loss': '1.38629'}; time used = 7.52563214302063s
epoch 395: {'train_loss': '1.38629'}; time used = 6.858391046524048s
epoch 400: {'train_loss': '1.38629'}; time used = 10.285541772842407s
epoch 405: {'train_loss': '1.38629'}; time used = 6.698193550109863s
epoch 410: {'train_loss': '1.38629'}; time used = 8.228236436843872s
epoch 415: {'train_loss': '1.38629'}; time used = 7.9972217082977295s
epoch 420: {'train_loss': '1.38629'}; time used = 10.829746007919312s
epoch 425: {'train_loss': '1.38629'}; time used = 7.904289960861206s
epoch 430: {'train_loss': '1.38629'}; time used = 7.996735572814941s
epoch 435: {'train_loss': '1.38629'}; time used = 11.040038585662842s
epoch 440: {'train_loss': '1.38629'}; time used = 6.812240362167358s
epoch 445: {'train_loss': '1.38629'}; time used = 7.210714817047119s
epoch 450: {'train_loss': '1.38629'}; time used = 7.896143198013306s
epoch 455: {'train_loss': '1.38629'}; time used = 7.682475328445435s
epoch 460: {'train_loss': '1.38629'}; time used = 6.705218315124512s
epoch 465: {'train_loss': '1.38629'}; time used = 6.658384323120117s
epoch 470: {'train_loss': '1.38629'}; time used = 6.7826409339904785s
epoch 475: {'train_loss': '1.38629'}; time used = 6.618248462677002s
epoch 480: {'train_loss': '1.38629'}; time used = 7.585737466812134s
epoch 485: {'train_loss': '1.38629'}; time used = 9.025032043457031s
epoch 490: {'train_loss': '1.38629'}; time used = 7.26753306388855s
epoch 495: {'train_loss': '1.38629'}; time used = 6.518468379974365s
epoch 500: {'train_loss': '1.38629'}; time used = 6.550210237503052s
Finished training. Time used = 766.789882183075.
Training classifier using 80.00% nodes...
{'micro': 0.4633333333333333, 'macro': 0.4411917026697685, 'samples': 0.4633333333333333, 'weighted': 0.43508095158967536, 'accuracy': 0.4633333333333333}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37738'}; time used = 1.8333110809326172s
epoch 10: {'train_loss': '1.30822'}; time used = 1.6993520259857178s
epoch 15: {'train_loss': '1.26561'}; time used = 1.7405648231506348s
epoch 20: {'train_loss': '1.36247'}; time used = 1.7034413814544678s
epoch 25: {'train_loss': '1.24075'}; time used = 1.783604621887207s
epoch 30: {'train_loss': '1.15205'}; time used = 1.7060878276824951s
epoch 35: {'train_loss': '1.24894'}; time used = 1.7082388401031494s
epoch 40: {'train_loss': '1.13163'}; time used = 1.7182741165161133s
epoch 45: {'train_loss': '1.17289'}; time used = 1.7863743305206299s
epoch 50: {'train_loss': '1.10107'}; time used = 1.746931791305542s
epoch 55: {'train_loss': '1.04574'}; time used = 1.7062923908233643s
epoch 60: {'train_loss': '1.10278'}; time used = 1.7211203575134277s
epoch 65: {'train_loss': '1.23764'}; time used = 1.6978352069854736s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.25999426841736.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5836206896551723, 'samples': 0.5942028985507246, 'weighted': 0.588430784607696, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.31412'}; time used = 3.301009178161621s
epoch 10: {'train_loss': '1.06080'}; time used = 2.1707966327667236s
epoch 15: {'train_loss': '0.77012'}; time used = 2.4363200664520264s
epoch 20: {'train_loss': '0.47989'}; time used = 2.307953357696533s
epoch 25: {'train_loss': '0.55198'}; time used = 3.253787040710449s
epoch 30: {'train_loss': '0.27356'}; time used = 4.076330661773682s
epoch 35: {'train_loss': '0.39029'}; time used = 3.727609872817993s
epoch 40: {'train_loss': '0.24256'}; time used = 2.2711589336395264s
epoch 45: {'train_loss': '0.60699'}; time used = 2.3196356296539307s
epoch 50: {'train_loss': '0.46014'}; time used = 2.2366983890533447s
epoch 55: {'train_loss': '0.48425'}; time used = 2.2251274585723877s
epoch 60: {'train_loss': '0.32286'}; time used = 2.3310658931732178s
epoch 65: {'train_loss': '0.19001'}; time used = 2.2161521911621094s
epoch 70: {'train_loss': '0.34685'}; time used = 2.419459581375122s
epoch 75: {'train_loss': '0.25650'}; time used = 2.3984436988830566s
epoch 80: {'train_loss': '0.30207'}; time used = 2.297943353652954s
epoch 85: {'train_loss': '0.16664'}; time used = 2.154103994369507s
epoch 90: {'train_loss': '0.35770'}; time used = 2.611572742462158s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 65.02783250808716.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5576923076923077, 'samples': 0.5652173913043478, 'weighted': 0.5618729096989966, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 6.4019811153411865s
epoch 10: {'train_loss': '1.38629'}; time used = 6.600323915481567s
epoch 15: {'train_loss': '1.38629'}; time used = 6.548815011978149s
epoch 20: {'train_loss': '1.38629'}; time used = 6.712584018707275s
epoch 25: {'train_loss': '1.38629'}; time used = 6.564374923706055s
epoch 30: {'train_loss': '1.38629'}; time used = 6.8872151374816895s
epoch 35: {'train_loss': '1.38629'}; time used = 6.25145959854126s
epoch 40: {'train_loss': '1.38629'}; time used = 6.320186138153076s
epoch 45: {'train_loss': '1.38629'}; time used = 6.260124683380127s
epoch 50: {'train_loss': '1.38629'}; time used = 9.847176551818848s
epoch 55: {'train_loss': '1.38629'}; time used = 6.240143537521362s
epoch 60: {'train_loss': '1.38629'}; time used = 6.131167411804199s
epoch 65: {'train_loss': '1.38629'}; time used = 6.0544750690460205s
epoch 70: {'train_loss': '1.38629'}; time used = 6.331689119338989s
epoch 75: {'train_loss': '1.38629'}; time used = 6.417913913726807s
epoch 80: {'train_loss': '1.38629'}; time used = 6.167163372039795s
epoch 85: {'train_loss': '1.38629'}; time used = 5.956723690032959s
epoch 90: {'train_loss': '1.38629'}; time used = 6.7942891120910645s
epoch 95: {'train_loss': '1.38629'}; time used = 6.143168210983276s
epoch 100: {'train_loss': '1.38629'}; time used = 6.284601211547852s
epoch 105: {'train_loss': '1.38629'}; time used = 6.315671920776367s
epoch 110: {'train_loss': '1.38629'}; time used = 6.3054563999176025s
epoch 115: {'train_loss': '1.38629'}; time used = 6.3174989223480225s
epoch 120: {'train_loss': '1.38629'}; time used = 6.099491119384766s
epoch 125: {'train_loss': '1.38629'}; time used = 6.01943564414978s
epoch 130: {'train_loss': '1.38629'}; time used = 5.968909740447998s
epoch 135: {'train_loss': '1.38629'}; time used = 6.158951282501221s
epoch 140: {'train_loss': '1.38629'}; time used = 7.016554832458496s
epoch 145: {'train_loss': '1.38629'}; time used = 6.2079432010650635s
epoch 150: {'train_loss': '1.38629'}; time used = 6.1353044509887695s
epoch 155: {'train_loss': '1.38629'}; time used = 7.73052453994751s
epoch 160: {'train_loss': '1.38629'}; time used = 6.108794927597046s
epoch 165: {'train_loss': '1.38629'}; time used = 7.7595391273498535s
epoch 170: {'train_loss': '1.38629'}; time used = 6.004326105117798s
epoch 175: {'train_loss': '1.38629'}; time used = 5.930629014968872s
epoch 180: {'train_loss': '1.38629'}; time used = 6.014042377471924s
epoch 185: {'train_loss': '1.38629'}; time used = 6.183931589126587s
epoch 190: {'train_loss': '1.38629'}; time used = 6.0220770835876465s
epoch 195: {'train_loss': '1.38629'}; time used = 6.300299167633057s
epoch 200: {'train_loss': '1.38629'}; time used = 6.745931148529053s
epoch 205: {'train_loss': '1.38629'}; time used = 6.107377529144287s
epoch 210: {'train_loss': '1.38629'}; time used = 6.133237361907959s
epoch 215: {'train_loss': '1.38629'}; time used = 6.498990774154663s
epoch 220: {'train_loss': '1.38629'}; time used = 6.468512058258057s
epoch 225: {'train_loss': '1.38629'}; time used = 9.373122930526733s
epoch 230: {'train_loss': '1.38629'}; time used = 6.782354831695557s
epoch 235: {'train_loss': '1.38629'}; time used = 8.361179113388062s
epoch 240: {'train_loss': '1.38629'}; time used = 6.154910087585449s
epoch 245: {'train_loss': '1.38629'}; time used = 6.222485303878784s
epoch 250: {'train_loss': '1.38629'}; time used = 6.476803302764893s
epoch 255: {'train_loss': '1.38629'}; time used = 9.470837116241455s
epoch 260: {'train_loss': '1.38629'}; time used = 6.566965579986572s
epoch 265: {'train_loss': '1.38629'}; time used = 6.080828666687012s
epoch 270: {'train_loss': '1.38629'}; time used = 6.0626091957092285s
epoch 275: {'train_loss': '1.38629'}; time used = 6.3320558071136475s
epoch 280: {'train_loss': '1.38629'}; time used = 6.516082048416138s
epoch 285: {'train_loss': '1.38629'}; time used = 9.641342163085938s
epoch 290: {'train_loss': '1.38629'}; time used = 6.07631254196167s
epoch 295: {'train_loss': '1.38629'}; time used = 6.322052478790283s
epoch 300: {'train_loss': '1.38629'}; time used = 6.2494800090789795s
epoch 305: {'train_loss': '1.38629'}; time used = 6.135306358337402s
epoch 310: {'train_loss': '1.38629'}; time used = 6.0872883796691895s
epoch 315: {'train_loss': '1.38629'}; time used = 6.714388132095337s
epoch 320: {'train_loss': '1.38629'}; time used = 6.232545375823975s
epoch 325: {'train_loss': '1.38629'}; time used = 6.153158187866211s
epoch 330: {'train_loss': '1.38629'}; time used = 6.138720273971558s
epoch 335: {'train_loss': '1.38629'}; time used = 8.139423370361328s
epoch 340: {'train_loss': '1.38629'}; time used = 6.329762935638428s
epoch 345: {'train_loss': '1.38629'}; time used = 6.2586915493011475s
epoch 350: {'train_loss': '1.38629'}; time used = 6.5138726234436035s
epoch 355: {'train_loss': '1.38629'}; time used = 6.062806129455566s
epoch 360: {'train_loss': '1.38629'}; time used = 5.974653720855713s
epoch 365: {'train_loss': '1.38629'}; time used = 5.937493562698364s
epoch 370: {'train_loss': '1.38629'}; time used = 6.454261064529419s
epoch 375: {'train_loss': '1.38629'}; time used = 6.767793893814087s
epoch 380: {'train_loss': '1.38629'}; time used = 10.684989213943481s
epoch 385: {'train_loss': '1.38629'}; time used = 6.550773620605469s
epoch 390: {'train_loss': '1.38629'}; time used = 6.256896734237671s
epoch 395: {'train_loss': '1.38629'}; time used = 10.28715705871582s
epoch 400: {'train_loss': '1.38629'}; time used = 7.0926172733306885s
epoch 405: {'train_loss': '1.38629'}; time used = 6.211428880691528s
epoch 410: {'train_loss': '1.38629'}; time used = 6.2958738803863525s
epoch 415: {'train_loss': '1.38629'}; time used = 9.586076021194458s
epoch 420: {'train_loss': '1.38629'}; time used = 6.708250999450684s
epoch 425: {'train_loss': '1.38629'}; time used = 6.473819732666016s
epoch 430: {'train_loss': '1.38629'}; time used = 6.212777853012085s
epoch 435: {'train_loss': '1.38629'}; time used = 6.220095157623291s
epoch 440: {'train_loss': '1.38629'}; time used = 6.348181486129761s
epoch 445: {'train_loss': '1.38629'}; time used = 6.127643585205078s
epoch 450: {'train_loss': '1.38629'}; time used = 6.173243761062622s
epoch 455: {'train_loss': '1.38629'}; time used = 6.3000922203063965s
epoch 460: {'train_loss': '1.38629'}; time used = 6.298557281494141s
epoch 465: {'train_loss': '1.38629'}; time used = 10.06269097328186s
epoch 470: {'train_loss': '1.38629'}; time used = 6.097672939300537s
epoch 475: {'train_loss': '1.38629'}; time used = 6.297275543212891s
epoch 480: {'train_loss': '1.38629'}; time used = 6.149099349975586s
epoch 485: {'train_loss': '1.38629'}; time used = 7.900574207305908s
epoch 490: {'train_loss': '1.38629'}; time used = 6.352107286453247s
epoch 495: {'train_loss': '1.38629'}; time used = 12.640460729598999s
epoch 500: {'train_loss': '1.38629'}; time used = 13.4175865650177s
Finished training. Time used = 692.0221807956696.
Training classifier using 80.00% nodes...
{'micro': 0.4633333333333333, 'macro': 0.4411917026697685, 'samples': 0.4633333333333333, 'weighted': 0.43508095158967536, 'accuracy': 0.4633333333333333}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.05 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.80795'}; time used = 1.1259522438049316s
epoch 10: {'train_loss': '2.77665'}; time used = 1.0764403343200684s
epoch 15: {'train_loss': '2.77437'}; time used = 1.6925673484802246s
epoch 20: {'train_loss': '2.78015'}; time used = 2.338615894317627s
epoch 25: {'train_loss': '2.77732'}; time used = 2.272305488586426s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.974152326583862.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39585'}; time used = 1.187157154083252s
epoch 10: {'train_loss': '1.40337'}; time used = 1.0693135261535645s
epoch 15: {'train_loss': '1.29525'}; time used = 1.1023976802825928s
epoch 20: {'train_loss': '1.31598'}; time used = 1.2416610717773438s
epoch 25: {'train_loss': '1.09875'}; time used = 1.2674376964569092s
epoch 30: {'train_loss': '1.29351'}; time used = 1.231919527053833s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.446461915969849.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.24951'}; time used = 1.879248857498169s
epoch 10: {'train_loss': '1.18270'}; time used = 1.7503654956817627s
epoch 15: {'train_loss': '1.14995'}; time used = 1.6899189949035645s
epoch 20: {'train_loss': '1.12008'}; time used = 1.7209289073944092s
epoch 25: {'train_loss': '1.08103'}; time used = 1.903893232345581s
epoch 30: {'train_loss': '1.06100'}; time used = 2.036896228790283s
epoch 35: {'train_loss': '1.03172'}; time used = 2.1406238079071045s
epoch 40: {'train_loss': '0.84032'}; time used = 1.758899211883545s
epoch 45: {'train_loss': '0.61686'}; time used = 1.845318078994751s
epoch 50: {'train_loss': '0.53779'}; time used = 1.8231537342071533s
epoch 55: {'train_loss': '0.35418'}; time used = 1.9947702884674072s
epoch 60: {'train_loss': '0.35029'}; time used = 1.6606166362762451s
epoch 65: {'train_loss': '0.48020'}; time used = 1.7156846523284912s
epoch 70: {'train_loss': '0.35719'}; time used = 1.8416664600372314s
epoch 75: {'train_loss': '0.39705'}; time used = 1.7896411418914795s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.72772455215454.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.46215740507920544, 'samples': 0.5507246376811594, 'weighted': 0.4779729823295543, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39567'}; time used = 1.3873586654663086s
epoch 10: {'train_loss': '1.36603'}; time used = 1.2619993686676025s
epoch 15: {'train_loss': '1.26483'}; time used = 1.2516398429870605s
epoch 20: {'train_loss': '1.24531'}; time used = 0.9712364673614502s
epoch 25: {'train_loss': '0.99484'}; time used = 1.010962724685669s
epoch 30: {'train_loss': '1.11854'}; time used = 0.9808495044708252s
epoch 35: {'train_loss': '0.91387'}; time used = 1.0005028247833252s
epoch 40: {'train_loss': '0.78642'}; time used = 1.0634043216705322s
epoch 45: {'train_loss': '0.62437'}; time used = 1.1718173027038574s
epoch 50: {'train_loss': '0.72731'}; time used = 1.1747221946716309s
epoch 55: {'train_loss': '0.63819'}; time used = 1.2338354587554932s
epoch 60: {'train_loss': '0.68778'}; time used = 1.2745416164398193s
epoch 65: {'train_loss': '0.46307'}; time used = 1.1738166809082031s
epoch 70: {'train_loss': '0.89673'}; time used = 1.2070302963256836s
epoch 75: {'train_loss': '0.83916'}; time used = 1.196056604385376s
epoch 80: {'train_loss': '0.47372'}; time used = 1.1988656520843506s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.456281185150146.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6125490196078432, 'samples': 0.6578947368421053, 'weighted': 0.6334778121775028, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.38119'}; time used = 1.3056814670562744s
epoch 10: {'train_loss': '2.85601'}; time used = 1.1988861560821533s
epoch 15: {'train_loss': '2.83597'}; time used = 1.2193808555603027s
epoch 20: {'train_loss': '2.82327'}; time used = 1.2635924816131592s
epoch 25: {'train_loss': '2.80723'}; time used = 1.196800708770752s
epoch 30: {'train_loss': '2.79344'}; time used = 1.1854209899902344s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.54829454421997.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5722943722943723, 'samples': 0.6578947368421053, 'weighted': 0.6025062656641604, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.16494'}; time used = 1.5825600624084473s
epoch 10: {'train_loss': '0.80699'}; time used = 1.1981098651885986s
epoch 15: {'train_loss': '0.62734'}; time used = 1.2598893642425537s
epoch 20: {'train_loss': '0.57619'}; time used = 1.1535205841064453s
epoch 25: {'train_loss': '0.48933'}; time used = 1.0966007709503174s
epoch 30: {'train_loss': '0.41132'}; time used = 1.3081157207489014s
epoch 35: {'train_loss': '0.36890'}; time used = 1.108457088470459s
epoch 40: {'train_loss': '0.33616'}; time used = 1.179689645767212s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.204241752624512.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6161616161616161, 'samples': 0.6842105263157895, 'weighted': 0.6416799574694312, 'accuracy': 0.6842105263157895}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.85458'}; time used = 6.360723495483398s
epoch 10: {'train_loss': '2.78031'}; time used = 6.271088600158691s
epoch 15: {'train_loss': '2.77649'}; time used = 6.18755030632019s
epoch 20: {'train_loss': '2.78483'}; time used = 7.085487127304077s
epoch 25: {'train_loss': '2.77488'}; time used = 6.824337482452393s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.31367254257202.
Training classifier using 80.00% nodes...
{'micro': 0.4766666666666667, 'macro': 0.3865399104728981, 'samples': 0.4766666666666667, 'weighted': 0.37494371315871117, 'accuracy': 0.4766666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.75502'}; time used = 1.308800458908081s
epoch 10: {'train_loss': '2.74075'}; time used = 1.128274917602539s
epoch 15: {'train_loss': '2.69640'}; time used = 1.1883552074432373s
epoch 20: {'train_loss': '2.62251'}; time used = 1.3102543354034424s
epoch 25: {'train_loss': '2.50467'}; time used = 1.1536834239959717s
epoch 30: {'train_loss': '2.36135'}; time used = 1.1968779563903809s
epoch 35: {'train_loss': '2.27043'}; time used = 1.3222222328186035s
epoch 40: {'train_loss': '2.21876'}; time used = 1.2874836921691895s
epoch 45: {'train_loss': '2.20443'}; time used = 1.2514193058013916s
epoch 50: {'train_loss': '2.23242'}; time used = 1.4281840324401855s
epoch 55: {'train_loss': '2.16796'}; time used = 1.083524227142334s
epoch 60: {'train_loss': '2.12727'}; time used = 1.1421842575073242s
epoch 65: {'train_loss': '2.11607'}; time used = 1.0816411972045898s
epoch 70: {'train_loss': '2.15519'}; time used = 1.1058614253997803s
epoch 75: {'train_loss': '2.10788'}; time used = 1.1176254749298096s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.971883535385132.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 27.19 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.84634'}; time used = 4.258717775344849s
epoch 10: {'train_loss': '2.77286'}; time used = 3.2563023567199707s
epoch 15: {'train_loss': '2.78452'}; time used = 4.757840156555176s
epoch 20: {'train_loss': '2.78321'}; time used = 4.648688316345215s
epoch 25: {'train_loss': '2.77270'}; time used = 4.014975070953369s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.32402467727661.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6086956521739131, 'samples': 0.6521739130434783, 'weighted': 0.618147448015123, 'accuracy': 0.6521739130434783}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.32062'}; time used = 2.107692003250122s
epoch 10: {'train_loss': '1.24614'}; time used = 1.9966344833374023s
epoch 15: {'train_loss': '1.23860'}; time used = 2.083406925201416s
epoch 20: {'train_loss': '1.22136'}; time used = 2.2965097427368164s
epoch 25: {'train_loss': '1.18261'}; time used = 2.169997215270996s
epoch 30: {'train_loss': '0.98794'}; time used = 2.024110794067383s
epoch 35: {'train_loss': '0.91463'}; time used = 2.1464452743530273s
epoch 40: {'train_loss': '0.87289'}; time used = 2.011636734008789s
epoch 45: {'train_loss': '0.76341'}; time used = 2.1770479679107666s
epoch 50: {'train_loss': '0.74687'}; time used = 3.4782609939575195s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.870676040649414.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5315564495851144, 'samples': 0.6086956521739131, 'weighted': 0.545331307190257, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.88 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.78552'}; time used = 3.154330253601074s
epoch 10: {'train_loss': '2.76148'}; time used = 2.738375425338745s
epoch 15: {'train_loss': '2.74308'}; time used = 1.9876079559326172s
epoch 20: {'train_loss': '2.70746'}; time used = 1.8208458423614502s
epoch 25: {'train_loss': '2.64665'}; time used = 1.8513731956481934s
epoch 30: {'train_loss': '2.60319'}; time used = 1.8132095336914062s
epoch 35: {'train_loss': '2.54977'}; time used = 2.07381010055542s
epoch 40: {'train_loss': '2.51150'}; time used = 1.8503201007843018s
epoch 45: {'train_loss': '2.43598'}; time used = 1.7289562225341797s
epoch 50: {'train_loss': '2.34521'}; time used = 1.8918731212615967s
epoch 55: {'train_loss': '2.31187'}; time used = 1.8504772186279297s
epoch 60: {'train_loss': '2.25523'}; time used = 2.8761556148529053s
epoch 65: {'train_loss': '2.19893'}; time used = 3.3094394207000732s
epoch 70: {'train_loss': '2.11163'}; time used = 2.9872026443481445s
epoch 75: {'train_loss': '2.22732'}; time used = 2.277933359146118s
epoch 80: {'train_loss': '2.06741'}; time used = 2.186875581741333s
epoch 85: {'train_loss': '2.04654'}; time used = 1.9866135120391846s
epoch 90: {'train_loss': '1.98110'}; time used = 2.620389461517334s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 45.65860104560852.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.36837725381414704, 'samples': 0.5217391304347826, 'weighted': 0.3909304709642405, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.38014'}; time used = 1.0730257034301758s
epoch 10: {'train_loss': '0.27661'}; time used = 0.9272503852844238s
epoch 15: {'train_loss': '0.29830'}; time used = 0.8481447696685791s
epoch 20: {'train_loss': '0.28244'}; time used = 0.8570504188537598s
epoch 25: {'train_loss': '0.32807'}; time used = 0.871248722076416s
epoch 30: {'train_loss': '0.25697'}; time used = 0.855764627456665s
epoch 35: {'train_loss': '0.28863'}; time used = 0.8688843250274658s
epoch 40: {'train_loss': '0.23356'}; time used = 0.8661332130432129s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.271074295043945.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.33350'}; time used = 7.968345403671265s
epoch 10: {'train_loss': '1.24267'}; time used = 8.045870304107666s
epoch 15: {'train_loss': '1.03550'}; time used = 10.919514417648315s
epoch 20: {'train_loss': '0.67433'}; time used = 10.96616244316101s
epoch 25: {'train_loss': '0.37054'}; time used = 7.689100027084351s
epoch 30: {'train_loss': '0.38753'}; time used = 9.87545919418335s
epoch 35: {'train_loss': '0.14379'}; time used = 9.83812403678894s
epoch 40: {'train_loss': '0.15797'}; time used = 10.628964185714722s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 95.4033637046814.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.4479981953578722, 'samples': 0.5066666666666667, 'weighted': 0.4389844790053328, 'accuracy': 0.5066666666666667}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.40915'}; time used = 5.358164072036743s
epoch 10: {'train_loss': '2.81779'}; time used = 5.229768753051758s
epoch 15: {'train_loss': '2.82786'}; time used = 5.486216306686401s
epoch 20: {'train_loss': '2.84117'}; time used = 5.192288160324097s
epoch 25: {'train_loss': '2.82683'}; time used = 8.413166761398315s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.16705942153931.
Training classifier using 80.00% nodes...
{'micro': 0.7, 'macro': 0.6999699969997, 'samples': 0.7, 'weighted': 0.7000300030002999, 'accuracy': 0.7}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.05075'}; time used = 1.1202490329742432s
epoch 10: {'train_loss': '0.83889'}; time used = 1.3190383911132812s
epoch 15: {'train_loss': '0.73815'}; time used = 1.6849150657653809s
epoch 20: {'train_loss': '0.52236'}; time used = 0.9918680191040039s
epoch 25: {'train_loss': '0.46012'}; time used = 1.1656675338745117s
epoch 30: {'train_loss': '0.34677'}; time used = 1.0995497703552246s
epoch 35: {'train_loss': '0.31750'}; time used = 1.0074777603149414s
epoch 40: {'train_loss': '0.26674'}; time used = 1.0355510711669922s
epoch 45: {'train_loss': '0.21076'}; time used = 1.020998239517212s
epoch 50: {'train_loss': '0.22840'}; time used = 1.0074808597564697s
epoch 55: {'train_loss': '0.14717'}; time used = 0.983708381652832s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.625921964645386.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.88145'}; time used = 1.7609949111938477s
epoch 10: {'train_loss': '2.79060'}; time used = 1.528522253036499s
epoch 15: {'train_loss': '2.75718'}; time used = 2.087080955505371s
epoch 20: {'train_loss': '2.73178'}; time used = 1.9347915649414062s
epoch 25: {'train_loss': '2.70894'}; time used = 1.6766164302825928s
epoch 30: {'train_loss': '2.68625'}; time used = 1.6031079292297363s
epoch 35: {'train_loss': '2.66978'}; time used = 1.7392375469207764s
epoch 40: {'train_loss': '2.64867'}; time used = 1.536693811416626s
epoch 45: {'train_loss': '2.62093'}; time used = 1.5698411464691162s
epoch 50: {'train_loss': '2.59382'}; time used = 1.5635900497436523s
epoch 55: {'train_loss': '2.59562'}; time used = 3.010678291320801s
epoch 60: {'train_loss': '2.58381'}; time used = 1.6730413436889648s
epoch 65: {'train_loss': '2.56359'}; time used = 1.544971227645874s
epoch 70: {'train_loss': '2.53346'}; time used = 1.6962916851043701s
epoch 75: {'train_loss': '2.52353'}; time used = 1.563783884048462s
epoch 80: {'train_loss': '2.50434'}; time used = 1.611480951309204s
epoch 85: {'train_loss': '2.50399'}; time used = 1.524174451828003s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.08475065231323.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4719387755102041, 'samples': 0.5652173913043478, 'weighted': 0.4880212954747117, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.27973'}; time used = 1.7767014503479004s
epoch 10: {'train_loss': '2.90798'}; time used = 1.9847590923309326s
epoch 15: {'train_loss': '2.83942'}; time used = 2.0838844776153564s
epoch 20: {'train_loss': '2.77591'}; time used = 1.9288201332092285s
epoch 25: {'train_loss': '2.78209'}; time used = 2.208691358566284s
epoch 30: {'train_loss': '2.78071'}; time used = 1.8297264575958252s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.590933561325073.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5218637992831542, 'samples': 0.5797101449275363, 'weighted': 0.5339151212924004, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.38826'}; time used = 1.2682075500488281s
epoch 10: {'train_loss': '1.38044'}; time used = 1.081050157546997s
epoch 15: {'train_loss': '1.33123'}; time used = 1.0643837451934814s
epoch 20: {'train_loss': '1.34158'}; time used = 1.0800962448120117s
epoch 25: {'train_loss': '1.30208'}; time used = 1.0501868724822998s
epoch 30: {'train_loss': '1.31376'}; time used = 1.0549755096435547s
epoch 35: {'train_loss': '1.29237'}; time used = 1.061521291732788s
epoch 40: {'train_loss': '1.20985'}; time used = 1.0703511238098145s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.256508111953735.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.19 GiB free; 24.67 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.75502'}; time used = 1.1665270328521729s
epoch 10: {'train_loss': '2.74075'}; time used = 1.1387434005737305s
epoch 15: {'train_loss': '2.69640'}; time used = 1.0912044048309326s
epoch 20: {'train_loss': '2.62251'}; time used = 1.1797471046447754s
epoch 25: {'train_loss': '2.50467'}; time used = 1.189182996749878s
epoch 30: {'train_loss': '2.36135'}; time used = 1.2450799942016602s
epoch 35: {'train_loss': '2.27043'}; time used = 2.208444833755493s
epoch 40: {'train_loss': '2.21876'}; time used = 1.5612783432006836s
epoch 45: {'train_loss': '2.20443'}; time used = 1.0936577320098877s
epoch 50: {'train_loss': '2.23242'}; time used = 1.0834405422210693s
epoch 55: {'train_loss': '2.16796'}; time used = 2.295443296432495s
epoch 60: {'train_loss': '2.12727'}; time used = 2.2424991130828857s
epoch 65: {'train_loss': '2.11607'}; time used = 1.976961612701416s
epoch 70: {'train_loss': '2.15519'}; time used = 1.9043426513671875s
epoch 75: {'train_loss': '2.10788'}; time used = 1.622082233428955s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.333131790161133.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.34724'}; time used = 1.6380298137664795s
epoch 10: {'train_loss': '1.25630'}; time used = 1.6528594493865967s
epoch 15: {'train_loss': '1.24238'}; time used = 1.6418137550354004s
epoch 20: {'train_loss': '1.13380'}; time used = 1.6313025951385498s
epoch 25: {'train_loss': '0.79507'}; time used = 1.757690191268921s
epoch 30: {'train_loss': '0.90241'}; time used = 1.5983939170837402s
epoch 35: {'train_loss': '1.05642'}; time used = 1.6300861835479736s
epoch 40: {'train_loss': '1.10957'}; time used = 1.6052513122558594s
epoch 45: {'train_loss': '0.94722'}; time used = 1.6207337379455566s
epoch 50: {'train_loss': '1.25645'}; time used = 3.3156933784484863s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.79594087600708.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5765079365079364, 'samples': 0.5797101449275363, 'weighted': 0.5791764435242696, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38804'}; time used = 1.1615488529205322s
epoch 10: {'train_loss': '1.36074'}; time used = 1.0537004470825195s
epoch 15: {'train_loss': '1.19827'}; time used = 1.069540023803711s
epoch 20: {'train_loss': '1.02726'}; time used = 1.010380744934082s
epoch 25: {'train_loss': '0.98520'}; time used = 1.0035479068756104s
epoch 30: {'train_loss': '0.81266'}; time used = 1.1069998741149902s
epoch 35: {'train_loss': '0.68500'}; time used = 1.0172502994537354s
epoch 40: {'train_loss': '0.64580'}; time used = 1.0466914176940918s
epoch 45: {'train_loss': '0.92789'}; time used = 1.0064244270324707s
epoch 50: {'train_loss': '0.62913'}; time used = 1.4861774444580078s
epoch 55: {'train_loss': '0.74334'}; time used = 1.0032472610473633s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.889774560928345.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.80301'}; time used = 2.157400131225586s
epoch 10: {'train_loss': '2.70298'}; time used = 2.2409415245056152s
epoch 15: {'train_loss': '2.66593'}; time used = 2.3085553646087646s
epoch 20: {'train_loss': '2.65977'}; time used = 2.1489593982696533s
epoch 25: {'train_loss': '2.65161'}; time used = 2.1004040241241455s
epoch 30: {'train_loss': '2.63348'}; time used = 2.2028493881225586s
epoch 35: {'train_loss': '2.62881'}; time used = 2.4554667472839355s
epoch 40: {'train_loss': '2.62712'}; time used = 2.0239245891571045s
epoch 45: {'train_loss': '2.61866'}; time used = 2.090115785598755s
epoch 50: {'train_loss': '2.60256'}; time used = 2.0063843727111816s
epoch 55: {'train_loss': '2.59804'}; time used = 2.132373094558716s
epoch 60: {'train_loss': '2.60034'}; time used = 1.7857263088226318s
epoch 65: {'train_loss': '2.58557'}; time used = 1.7102241516113281s
epoch 70: {'train_loss': '2.57511'}; time used = 1.7407691478729248s
epoch 75: {'train_loss': '2.56169'}; time used = 1.7509799003601074s
epoch 80: {'train_loss': '2.56260'}; time used = 1.8345839977264404s
epoch 85: {'train_loss': '2.56420'}; time used = 1.7845637798309326s
epoch 90: {'train_loss': '2.57282'}; time used = 1.73319411277771s
epoch 95: {'train_loss': '2.56999'}; time used = 1.742436408996582s
epoch 100: {'train_loss': '2.55879'}; time used = 1.7146222591400146s
epoch 105: {'train_loss': '2.56123'}; time used = 1.7882521152496338s
epoch 110: {'train_loss': '2.56153'}; time used = 1.8334167003631592s
epoch 115: {'train_loss': '2.55700'}; time used = 2.0698251724243164s
epoch 120: {'train_loss': '2.56133'}; time used = 2.045022487640381s
epoch 125: {'train_loss': '2.55480'}; time used = 2.0584821701049805s
epoch 130: {'train_loss': '2.56025'}; time used = 2.053643226623535s
epoch 135: {'train_loss': '2.55932'}; time used = 2.1328115463256836s
epoch 140: {'train_loss': '2.55754'}; time used = 2.083832263946533s
epoch 145: {'train_loss': '2.55121'}; time used = 2.0771913528442383s
epoch 150: {'train_loss': '2.55651'}; time used = 2.064282178878784s
epoch 155: {'train_loss': '2.55399'}; time used = 2.1074845790863037s
epoch 160: {'train_loss': '2.56198'}; time used = 1.890446424484253s
epoch 165: {'train_loss': '2.54729'}; time used = 1.855264663696289s
epoch 170: {'train_loss': '2.55519'}; time used = 1.7726645469665527s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 71.04820108413696.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.91546'}; time used = 1.925973653793335s
epoch 10: {'train_loss': '2.79026'}; time used = 2.136164426803589s
epoch 15: {'train_loss': '2.79670'}; time used = 1.9164512157440186s
epoch 20: {'train_loss': '2.79310'}; time used = 2.125958204269409s
epoch 25: {'train_loss': '2.78091'}; time used = 2.2991011142730713s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.106547355651855.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4968569273321599, 'samples': 0.5797101449275363, 'weighted': 0.5116521447599057, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.38714'}; time used = 1.2465715408325195s
epoch 10: {'train_loss': '1.34747'}; time used = 0.9600067138671875s
epoch 15: {'train_loss': '1.18094'}; time used = 0.9835941791534424s
epoch 20: {'train_loss': '1.03783'}; time used = 0.9767048358917236s
epoch 25: {'train_loss': '0.62421'}; time used = 0.9802358150482178s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.960160493850708.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.17153'}; time used = 1.1210484504699707s
epoch 10: {'train_loss': '1.05015'}; time used = 1.0054032802581787s
epoch 15: {'train_loss': '0.93359'}; time used = 1.0288116931915283s
epoch 20: {'train_loss': '0.78005'}; time used = 1.0286455154418945s
epoch 25: {'train_loss': '0.58632'}; time used = 1.0284826755523682s
epoch 30: {'train_loss': '0.40377'}; time used = 1.1240170001983643s
epoch 35: {'train_loss': '0.31864'}; time used = 1.0451710224151611s
epoch 40: {'train_loss': '0.23954'}; time used = 0.983515739440918s
epoch 45: {'train_loss': '0.23456'}; time used = 1.0665597915649414s
epoch 50: {'train_loss': '0.21464'}; time used = 0.9938960075378418s
epoch 55: {'train_loss': '0.16992'}; time used = 1.0355064868927002s
epoch 60: {'train_loss': '0.14980'}; time used = 1.1381170749664307s
epoch 65: {'train_loss': '0.17179'}; time used = 1.0293707847595215s
epoch 70: {'train_loss': '0.10011'}; time used = 1.036724328994751s
epoch 75: {'train_loss': '0.04891'}; time used = 1.255256175994873s
epoch 80: {'train_loss': '0.02973'}; time used = 1.7558350563049316s
epoch 85: {'train_loss': '0.03575'}; time used = 1.881485939025879s
epoch 90: {'train_loss': '0.02262'}; time used = 1.8611912727355957s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.573374032974243.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.86081'}; time used = 1.9917607307434082s
epoch 10: {'train_loss': '2.78709'}; time used = 1.8134667873382568s
epoch 15: {'train_loss': '2.77596'}; time used = 1.8050236701965332s
epoch 20: {'train_loss': '2.76483'}; time used = 1.8499376773834229s
epoch 25: {'train_loss': '2.76683'}; time used = 1.8876829147338867s
epoch 30: {'train_loss': '2.76429'}; time used = 1.8806986808776855s
epoch 35: {'train_loss': '2.76008'}; time used = 1.8506503105163574s
epoch 40: {'train_loss': '2.75910'}; time used = 1.8880019187927246s
epoch 45: {'train_loss': '2.75631'}; time used = 2.0091261863708496s
epoch 50: {'train_loss': '2.75791'}; time used = 2.5593488216400146s
epoch 55: {'train_loss': '2.76102'}; time used = 3.023944616317749s
epoch 60: {'train_loss': '2.76526'}; time used = 4.391804456710815s
epoch 65: {'train_loss': '2.75768'}; time used = 3.6872715950012207s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.652066469192505.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.39869281045751637, 'samples': 0.5362318840579711, 'weighted': 0.4195320640333428, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38294'}; time used = 1.9093177318572998s
epoch 10: {'train_loss': '1.19155'}; time used = 1.8779370784759521s
epoch 15: {'train_loss': '0.90465'}; time used = 1.8957278728485107s
epoch 20: {'train_loss': '0.95324'}; time used = 1.8912100791931152s
epoch 25: {'train_loss': '0.59466'}; time used = 2.019883394241333s
epoch 30: {'train_loss': '0.40423'}; time used = 1.9249308109283447s
epoch 35: {'train_loss': '0.65533'}; time used = 1.9118311405181885s
epoch 40: {'train_loss': '0.49168'}; time used = 1.905777931213379s
epoch 45: {'train_loss': '0.13300'}; time used = 2.0508551597595215s
epoch 50: {'train_loss': '0.06316'}; time used = 2.1093437671661377s
epoch 55: {'train_loss': '0.00189'}; time used = 1.8975186347961426s
epoch 60: {'train_loss': '0.00095'}; time used = 1.9155752658843994s
epoch 65: {'train_loss': '0.00084'}; time used = 1.9041790962219238s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.547653675079346.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5538793103448276, 'samples': 0.5652173913043478, 'weighted': 0.5590329835082459, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.23635'}; time used = 1.1828594207763672s
epoch 10: {'train_loss': '1.76339'}; time used = 1.175276517868042s
epoch 15: {'train_loss': '1.37960'}; time used = 1.0564725399017334s
epoch 20: {'train_loss': '1.40762'}; time used = 1.0506188869476318s
epoch 25: {'train_loss': '1.37758'}; time used = 1.066697120666504s
epoch 30: {'train_loss': '1.49641'}; time used = 1.197740077972412s
epoch 35: {'train_loss': '1.36253'}; time used = 1.2228446006774902s
epoch 40: {'train_loss': '1.36068'}; time used = 1.0888724327087402s
epoch 45: {'train_loss': '1.22136'}; time used = 1.0848231315612793s
epoch 50: {'train_loss': '1.13295'}; time used = 1.1640565395355225s
epoch 55: {'train_loss': '1.38834'}; time used = 1.0874931812286377s
epoch 60: {'train_loss': '1.37867'}; time used = 1.0537254810333252s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.17771601676941.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5438596491228069, 'samples': 0.6578947368421053, 'weighted': 0.579870729455217, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.43324'}; time used = 1.2698874473571777s
epoch 10: {'train_loss': '2.83588'}; time used = 1.070303201675415s
epoch 15: {'train_loss': '2.81065'}; time used = 1.1277828216552734s
epoch 20: {'train_loss': '2.80778'}; time used = 1.0956039428710938s
epoch 25: {'train_loss': '2.80414'}; time used = 1.027656078338623s
epoch 30: {'train_loss': '2.79583'}; time used = 1.0214979648590088s
epoch 35: {'train_loss': '2.78733'}; time used = 1.355111837387085s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.158723592758179.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.10 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.10808'}; time used = 2.520461082458496s
epoch 10: {'train_loss': '1.11438'}; time used = 4.23218846321106s
epoch 15: {'train_loss': '0.67282'}; time used = 2.23134708404541s
epoch 20: {'train_loss': '0.01325'}; time used = 1.9197680950164795s
epoch 25: {'train_loss': '0.00023'}; time used = 2.003138780593872s
epoch 30: {'train_loss': '0.00000'}; time used = 1.8748645782470703s
epoch 35: {'train_loss': '0.00000'}; time used = 1.8520851135253906s
epoch 40: {'train_loss': '0.00000'}; time used = 1.8686256408691406s
epoch 45: {'train_loss': '0.00344'}; time used = 1.8710856437683105s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.47339129447937.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5920608108108107, 'samples': 0.5942028985507246, 'weighted': 0.5942028985507246, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.19634'}; time used = 1.870307445526123s
epoch 10: {'train_loss': '1.13981'}; time used = 1.8303253650665283s
epoch 15: {'train_loss': '0.82085'}; time used = 1.8293843269348145s
epoch 20: {'train_loss': '0.65300'}; time used = 1.5545756816864014s
epoch 25: {'train_loss': '0.58963'}; time used = 3.042083740234375s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.908751249313354.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 6.601311922073364s
epoch 10: {'train_loss': '1.38629'}; time used = 6.279466152191162s
epoch 15: {'train_loss': '1.38629'}; time used = 6.607550144195557s
epoch 20: {'train_loss': '1.38629'}; time used = 6.485745429992676s
epoch 25: {'train_loss': '1.38629'}; time used = 6.297631502151489s
epoch 30: {'train_loss': '1.38629'}; time used = 6.271117448806763s
epoch 35: {'train_loss': '1.38629'}; time used = 6.236315965652466s
epoch 40: {'train_loss': '1.38629'}; time used = 7.3332085609436035s
epoch 45: {'train_loss': '1.38629'}; time used = 6.465229511260986s
epoch 50: {'train_loss': '1.38629'}; time used = 6.304258584976196s
epoch 55: {'train_loss': '1.38629'}; time used = 6.621008634567261s
epoch 60: {'train_loss': '1.38629'}; time used = 6.715301990509033s
epoch 65: {'train_loss': '1.38629'}; time used = 6.3894360065460205s
epoch 70: {'train_loss': '1.38629'}; time used = 6.389929533004761s
epoch 75: {'train_loss': '1.38629'}; time used = 6.65503716468811s
epoch 80: {'train_loss': '1.38629'}; time used = 9.103252410888672s
epoch 85: {'train_loss': '1.38629'}; time used = 8.2703537940979s
epoch 90: {'train_loss': '1.38629'}; time used = 6.824336051940918s
epoch 95: {'train_loss': '1.38629'}; time used = 6.244743824005127s
epoch 100: {'train_loss': '1.38629'}; time used = 6.280364751815796s
epoch 105: {'train_loss': '1.38629'}; time used = 6.220753908157349s
epoch 110: {'train_loss': '1.38629'}; time used = 6.227312088012695s
epoch 115: {'train_loss': '1.38629'}; time used = 6.432227373123169s
epoch 120: {'train_loss': '1.38629'}; time used = 6.599191427230835s
epoch 125: {'train_loss': '1.38629'}; time used = 10.598015069961548s
epoch 130: {'train_loss': '1.38629'}; time used = 6.782751083374023s
epoch 135: {'train_loss': '1.38629'}; time used = 7.586401462554932s
epoch 140: {'train_loss': '1.38629'}; time used = 9.47489309310913s
epoch 145: {'train_loss': '1.38629'}; time used = 6.9330761432647705s
epoch 150: {'train_loss': '1.38629'}; time used = 6.744517803192139s
epoch 155: {'train_loss': '1.38629'}; time used = 6.312093019485474s
epoch 160: {'train_loss': '1.38629'}; time used = 6.5201287269592285s
epoch 165: {'train_loss': '1.38629'}; time used = 6.427367925643921s
epoch 170: {'train_loss': '1.38629'}; time used = 6.2509400844573975s
epoch 175: {'train_loss': '1.38629'}; time used = 6.175015211105347s
epoch 180: {'train_loss': '1.38629'}; time used = 6.256895542144775s
epoch 185: {'train_loss': '1.38629'}; time used = 7.426034450531006s
epoch 190: {'train_loss': '1.38629'}; time used = 9.11521577835083s
epoch 195: {'train_loss': '1.38629'}; time used = 7.376936435699463s
epoch 200: {'train_loss': '1.38629'}; time used = 7.224874496459961s
epoch 205: {'train_loss': '1.38629'}; time used = 6.256139039993286s
epoch 210: {'train_loss': '1.38629'}; time used = 6.226617813110352s
epoch 215: {'train_loss': '1.38629'}; time used = 6.258423328399658s
epoch 220: {'train_loss': '1.38629'}; time used = 7.584916353225708s
epoch 225: {'train_loss': '1.38629'}; time used = 6.399386882781982s
epoch 230: {'train_loss': '1.38629'}; time used = 6.328906536102295s
epoch 235: {'train_loss': '1.38629'}; time used = 6.405179262161255s
epoch 240: {'train_loss': '1.38629'}; time used = 6.6461873054504395s
epoch 245: {'train_loss': '1.38629'}; time used = 6.401356935501099s
epoch 250: {'train_loss': '1.38629'}; time used = 6.895658493041992s
epoch 255: {'train_loss': '1.38629'}; time used = 6.860450983047485s
epoch 260: {'train_loss': '1.38629'}; time used = 7.238245248794556s
epoch 265: {'train_loss': '1.38629'}; time used = 6.671509265899658s
epoch 270: {'train_loss': '1.38629'}; time used = 6.732621192932129s
epoch 275: {'train_loss': '1.38629'}; time used = 6.581491708755493s
epoch 280: {'train_loss': '1.38629'}; time used = 6.237543106079102s
epoch 285: {'train_loss': '1.38629'}; time used = 6.872543096542358s
epoch 290: {'train_loss': '1.38629'}; time used = 6.32324481010437s
epoch 295: {'train_loss': '1.38629'}; time used = 6.587257623672485s
epoch 300: {'train_loss': '1.38629'}; time used = 6.610041856765747s
epoch 305: {'train_loss': '1.38629'}; time used = 7.358369588851929s
epoch 310: {'train_loss': '1.38629'}; time used = 8.919276237487793s
epoch 315: {'train_loss': '1.38629'}; time used = 6.516510009765625s
epoch 320: {'train_loss': '1.38629'}; time used = 7.351405620574951s
epoch 325: {'train_loss': '1.38629'}; time used = 6.423660755157471s
epoch 330: {'train_loss': '1.38629'}; time used = 6.580327987670898s
epoch 335: {'train_loss': '1.38629'}; time used = 8.893554210662842s
epoch 340: {'train_loss': '1.38629'}; time used = 7.0896618366241455s
epoch 345: {'train_loss': '1.38629'}; time used = 6.47155499458313s
epoch 350: {'train_loss': '1.38629'}; time used = 6.317847013473511s
epoch 355: {'train_loss': '1.38629'}; time used = 6.564374685287476s
epoch 360: {'train_loss': '1.38629'}; time used = 6.41133189201355s
epoch 365: {'train_loss': '1.38629'}; time used = 6.380135536193848s
epoch 370: {'train_loss': '1.38629'}; time used = 6.546387434005737s
epoch 375: {'train_loss': '1.38629'}; time used = 9.027383089065552s
epoch 380: {'train_loss': '1.38629'}; time used = 6.303491830825806s
epoch 385: {'train_loss': '1.38629'}; time used = 7.451768159866333s
epoch 390: {'train_loss': '1.38629'}; time used = 9.281728506088257s
epoch 395: {'train_loss': '1.38629'}; time used = 6.86149787902832s
epoch 400: {'train_loss': '1.38629'}; time used = 6.283794164657593s
epoch 405: {'train_loss': '1.38629'}; time used = 6.568385601043701s
epoch 410: {'train_loss': '1.38629'}; time used = 6.685594081878662s
epoch 415: {'train_loss': '1.38629'}; time used = 10.436225414276123s
epoch 420: {'train_loss': '1.38629'}; time used = 6.419250011444092s
epoch 425: {'train_loss': '1.38629'}; time used = 10.23708963394165s
epoch 430: {'train_loss': '1.38629'}; time used = 6.630900144577026s
epoch 435: {'train_loss': '1.38629'}; time used = 6.562460899353027s
epoch 440: {'train_loss': '1.38629'}; time used = 6.353971242904663s
epoch 445: {'train_loss': '1.38629'}; time used = 7.175535202026367s
epoch 450: {'train_loss': '1.38629'}; time used = 9.484408140182495s
epoch 455: {'train_loss': '1.38629'}; time used = 6.84581446647644s
epoch 460: {'train_loss': '1.38629'}; time used = 6.694714307785034s
epoch 465: {'train_loss': '1.38629'}; time used = 6.287821531295776s
epoch 470: {'train_loss': '1.38629'}; time used = 9.021507024765015s
epoch 475: {'train_loss': '1.38629'}; time used = 8.140431880950928s
epoch 480: {'train_loss': '1.38629'}; time used = 6.265281915664673s
epoch 485: {'train_loss': '1.38629'}; time used = 6.292918920516968s
epoch 490: {'train_loss': '1.38629'}; time used = 6.332355260848999s
epoch 495: {'train_loss': '1.38629'}; time used = 6.266010284423828s
epoch 500: {'train_loss': '1.38629'}; time used = 6.694283723831177s
Finished training. Time used = 707.2557418346405.
Training classifier using 80.00% nodes...
{'micro': 0.32666666666666666, 'macro': 0.18259451161005566, 'samples': 0.32666666666666666, 'weighted': 0.17711667626175395, 'accuracy': 0.32666666666666666}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.30983'}; time used = 3.2322628498077393s
epoch 10: {'train_loss': '1.23540'}; time used = 2.489784002304077s
epoch 15: {'train_loss': '1.21180'}; time used = 3.6376333236694336s
epoch 20: {'train_loss': '1.34377'}; time used = 4.161335706710815s
epoch 25: {'train_loss': '1.26128'}; time used = 3.7221317291259766s
epoch 30: {'train_loss': '1.14590'}; time used = 2.516625165939331s
epoch 35: {'train_loss': '1.29171'}; time used = 2.470245838165283s
epoch 40: {'train_loss': '1.19194'}; time used = 2.4666025638580322s
epoch 45: {'train_loss': '1.26582'}; time used = 2.5203661918640137s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.69760608673096.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.47826086956521735, 'samples': 0.5362318840579711, 'weighted': 0.4908632640201637, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.06 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.80795'}; time used = 2.6495048999786377s
epoch 10: {'train_loss': '2.77665'}; time used = 2.6504576206207275s
epoch 15: {'train_loss': '2.77437'}; time used = 2.3787176609039307s
epoch 20: {'train_loss': '2.78015'}; time used = 1.3314220905303955s
epoch 25: {'train_loss': '2.77732'}; time used = 1.0682165622711182s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.124061822891235.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.36328'}; time used = 5.975704669952393s
epoch 10: {'train_loss': '1.38882'}; time used = 5.190766334533691s
epoch 15: {'train_loss': '1.37029'}; time used = 5.178596258163452s
epoch 20: {'train_loss': '1.35785'}; time used = 8.372725486755371s
epoch 25: {'train_loss': '1.36405'}; time used = 9.502893686294556s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 51.74426484107971.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.7199159915991601, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.93565'}; time used = 3.1136884689331055s
epoch 10: {'train_loss': '2.77480'}; time used = 2.460275411605835s
epoch 15: {'train_loss': '2.77185'}; time used = 2.694788694381714s
epoch 20: {'train_loss': '2.77558'}; time used = 2.6457488536834717s
epoch 25: {'train_loss': '2.77935'}; time used = 2.6047539710998535s
epoch 30: {'train_loss': '2.77608'}; time used = 4.361107110977173s
epoch 35: {'train_loss': '2.76833'}; time used = 2.603313446044922s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.821686267852783.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4661508704061895, 'samples': 0.5362318840579711, 'weighted': 0.48016707313654583, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.37954'}; time used = 1.2908935546875s
epoch 10: {'train_loss': '0.27704'}; time used = 0.9341347217559814s
epoch 15: {'train_loss': '0.29931'}; time used = 1.0604965686798096s
epoch 20: {'train_loss': '0.28281'}; time used = 1.189185380935669s
epoch 25: {'train_loss': '0.32889'}; time used = 1.1479032039642334s
epoch 30: {'train_loss': '0.25797'}; time used = 1.0877976417541504s
epoch 35: {'train_loss': '0.29062'}; time used = 0.895442008972168s
epoch 40: {'train_loss': '0.24326'}; time used = 0.9878981113433838s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.024490118026733.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.57514'}; time used = 0.957855224609375s
epoch 10: {'train_loss': '2.44900'}; time used = 0.8840506076812744s
epoch 15: {'train_loss': '2.36224'}; time used = 0.87064528465271s
epoch 20: {'train_loss': '2.31988'}; time used = 1.0347247123718262s
epoch 25: {'train_loss': '2.29444'}; time used = 1.146991491317749s
epoch 30: {'train_loss': '2.23280'}; time used = 1.0452651977539062s
epoch 35: {'train_loss': '2.18912'}; time used = 1.0516200065612793s
epoch 40: {'train_loss': '2.16590'}; time used = 1.0572023391723633s
epoch 45: {'train_loss': '2.14761'}; time used = 1.1029372215270996s
epoch 50: {'train_loss': '2.15996'}; time used = 1.0859184265136719s
epoch 55: {'train_loss': '2.14017'}; time used = 1.046816349029541s
epoch 60: {'train_loss': '2.12690'}; time used = 1.2053050994873047s
epoch 65: {'train_loss': '2.13425'}; time used = 1.0488917827606201s
epoch 70: {'train_loss': '2.14304'}; time used = 1.1428883075714111s
epoch 75: {'train_loss': '2.11465'}; time used = 2.0823287963867188s
epoch 80: {'train_loss': '2.13138'}; time used = 1.0499253273010254s
epoch 85: {'train_loss': '2.13801'}; time used = 1.1131823062896729s
epoch 90: {'train_loss': '2.10190'}; time used = 1.084550380706787s
epoch 95: {'train_loss': '2.13478'}; time used = 1.0905556678771973s
epoch 100: {'train_loss': '2.14681'}; time used = 0.8302278518676758s
epoch 105: {'train_loss': '2.12217'}; time used = 0.8884689807891846s
epoch 110: {'train_loss': '2.09964'}; time used = 0.8337047100067139s
epoch 115: {'train_loss': '2.10430'}; time used = 0.8238890171051025s
epoch 120: {'train_loss': '2.08936'}; time used = 0.8241374492645264s
epoch 125: {'train_loss': '2.11637'}; time used = 0.8427829742431641s
epoch 130: {'train_loss': '2.09648'}; time used = 0.8113787174224854s
epoch 135: {'train_loss': '2.08166'}; time used = 0.8173890113830566s
epoch 140: {'train_loss': '2.09833'}; time used = 0.8176219463348389s
epoch 145: {'train_loss': '2.10329'}; time used = 0.8244926929473877s
epoch 150: {'train_loss': '2.09270'}; time used = 0.82381272315979s
epoch 155: {'train_loss': '2.11340'}; time used = 0.8292958736419678s
epoch 160: {'train_loss': '2.10643'}; time used = 0.8253562450408936s
epoch 165: {'train_loss': '2.11721'}; time used = 0.8942797183990479s
epoch 170: {'train_loss': '2.12451'}; time used = 0.9053182601928711s
epoch 175: {'train_loss': '2.07698'}; time used = 1.0201165676116943s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.177680015563965.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.20126'}; time used = 1.2673368453979492s
epoch 10: {'train_loss': '1.60662'}; time used = 1.3047716617584229s
epoch 15: {'train_loss': '1.37859'}; time used = 1.158142328262329s
epoch 20: {'train_loss': '1.43272'}; time used = 1.1438581943511963s
epoch 25: {'train_loss': '1.30062'}; time used = 1.1437299251556396s
epoch 30: {'train_loss': '1.15699'}; time used = 1.1448230743408203s
epoch 35: {'train_loss': '0.74924'}; time used = 1.1375136375427246s
epoch 40: {'train_loss': '0.25564'}; time used = 1.1433956623077393s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.934574842453003.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.02372'}; time used = 1.6221446990966797s
epoch 10: {'train_loss': '2.95679'}; time used = 1.7543935775756836s
epoch 15: {'train_loss': '2.84175'}; time used = 1.6871793270111084s
epoch 20: {'train_loss': '2.79007'}; time used = 1.6576390266418457s
epoch 25: {'train_loss': '2.75855'}; time used = 1.760956048965454s
epoch 30: {'train_loss': '2.73026'}; time used = 1.5656864643096924s
epoch 35: {'train_loss': '2.70624'}; time used = 1.695185661315918s
epoch 40: {'train_loss': '2.67579'}; time used = 1.6392590999603271s
epoch 45: {'train_loss': '2.64020'}; time used = 1.6983795166015625s
epoch 50: {'train_loss': '2.60730'}; time used = 1.6088635921478271s
epoch 55: {'train_loss': '2.59715'}; time used = 1.72141695022583s
epoch 60: {'train_loss': '2.58167'}; time used = 1.5595130920410156s
epoch 65: {'train_loss': '2.54124'}; time used = 1.6905126571655273s
epoch 70: {'train_loss': '2.50117'}; time used = 1.5466721057891846s
epoch 75: {'train_loss': '2.47672'}; time used = 1.6631813049316406s
epoch 80: {'train_loss': '2.44416'}; time used = 1.7069389820098877s
epoch 85: {'train_loss': '2.44909'}; time used = 1.6117990016937256s
epoch 90: {'train_loss': '2.48025'}; time used = 1.749265432357788s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.947415590286255.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.6057142857142858, 'samples': 0.6086956521739131, 'weighted': 0.6081987577639751, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.35261'}; time used = 2.6096630096435547s
epoch 10: {'train_loss': '1.40139'}; time used = 2.422877311706543s
epoch 15: {'train_loss': '1.34760'}; time used = 1.4625577926635742s
epoch 20: {'train_loss': '1.35908'}; time used = 1.049370288848877s
epoch 25: {'train_loss': '1.29443'}; time used = 1.0634443759918213s
epoch 30: {'train_loss': '1.29899'}; time used = 0.9797961711883545s
epoch 35: {'train_loss': '1.30113'}; time used = 1.0061557292938232s
epoch 40: {'train_loss': '1.23480'}; time used = 0.9967551231384277s
epoch 45: {'train_loss': '1.10423'}; time used = 1.01312255859375s
epoch 50: {'train_loss': '1.21131'}; time used = 0.9678020477294922s
epoch 55: {'train_loss': '1.19943'}; time used = 0.9791009426116943s
epoch 60: {'train_loss': '1.23258'}; time used = 0.9869663715362549s
epoch 65: {'train_loss': '1.04701'}; time used = 0.9956057071685791s
epoch 70: {'train_loss': '1.33287'}; time used = 1.0248358249664307s
epoch 75: {'train_loss': '1.22671'}; time used = 0.961946964263916s
epoch 80: {'train_loss': '1.07475'}; time used = 0.9652199745178223s
epoch 85: {'train_loss': '1.08850'}; time used = 0.9929254055023193s
epoch 90: {'train_loss': '1.06802'}; time used = 0.9917223453521729s
epoch 95: {'train_loss': '1.18963'}; time used = 0.9462172985076904s
epoch 100: {'train_loss': '1.14890'}; time used = 1.003852128982544s
epoch 105: {'train_loss': '1.09855'}; time used = 0.9775710105895996s
epoch 110: {'train_loss': '1.18990'}; time used = 1.0077555179595947s
epoch 115: {'train_loss': '1.27460'}; time used = 1.0660417079925537s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.95846486091614.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.731764705882353, 'samples': 0.7631578947368421, 'weighted': 0.7462538699690403, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.34043'}; time used = 1.74721097946167s
epoch 10: {'train_loss': '2.81467'}; time used = 1.6984543800354004s
epoch 15: {'train_loss': '2.72100'}; time used = 1.685166358947754s
epoch 20: {'train_loss': '2.72562'}; time used = 1.5992794036865234s
epoch 25: {'train_loss': '2.69155'}; time used = 1.8193252086639404s
epoch 30: {'train_loss': '2.67081'}; time used = 1.6252896785736084s
epoch 35: {'train_loss': '2.66299'}; time used = 1.718865156173706s
epoch 40: {'train_loss': '2.64528'}; time used = 2.945725679397583s
epoch 45: {'train_loss': '2.61409'}; time used = 2.3920748233795166s
epoch 50: {'train_loss': '2.57670'}; time used = 1.6129975318908691s
epoch 55: {'train_loss': '2.56145'}; time used = 1.884303092956543s
epoch 60: {'train_loss': '2.55192'}; time used = 1.7758047580718994s
epoch 65: {'train_loss': '2.52320'}; time used = 1.7633812427520752s
epoch 70: {'train_loss': '2.49333'}; time used = 1.6086461544036865s
epoch 75: {'train_loss': '2.49545'}; time used = 2.863086223602295s
epoch 80: {'train_loss': '2.46624'}; time used = 4.951744079589844s
epoch 85: {'train_loss': '2.46971'}; time used = 4.2836573123931885s
epoch 90: {'train_loss': '2.45948'}; time used = 4.017841577529907s
epoch 95: {'train_loss': '2.43917'}; time used = 2.949512243270874s
epoch 100: {'train_loss': '2.42469'}; time used = 3.0124855041503906s
epoch 105: {'train_loss': '2.40989'}; time used = 1.8514602184295654s
epoch 110: {'train_loss': '2.39099'}; time used = 1.7963123321533203s
epoch 115: {'train_loss': '2.38886'}; time used = 1.6544480323791504s
epoch 120: {'train_loss': '2.37339'}; time used = 1.573549747467041s
epoch 125: {'train_loss': '2.37030'}; time used = 1.8268167972564697s
epoch 130: {'train_loss': '2.35788'}; time used = 1.6393992900848389s
epoch 135: {'train_loss': '2.37095'}; time used = 1.996337652206421s
epoch 140: {'train_loss': '2.36316'}; time used = 2.4518837928771973s
epoch 145: {'train_loss': '2.34854'}; time used = 1.635230541229248s
epoch 150: {'train_loss': '2.34941'}; time used = 1.6154708862304688s
epoch 155: {'train_loss': '2.32107'}; time used = 1.9423112869262695s
epoch 160: {'train_loss': '2.32092'}; time used = 1.7726726531982422s
epoch 165: {'train_loss': '2.31477'}; time used = 1.5933942794799805s
epoch 170: {'train_loss': '2.33866'}; time used = 1.5613291263580322s
epoch 175: {'train_loss': '2.31406'}; time used = 1.523162841796875s
epoch 180: {'train_loss': '2.30686'}; time used = 1.509200096130371s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 79.91525268554688.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5337837837837838, 'samples': 0.5362318840579711, 'weighted': 0.5362318840579711, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77483'}; time used = 1.49336838722229s
epoch 10: {'train_loss': '2.77444'}; time used = 1.3410584926605225s
epoch 15: {'train_loss': '2.78077'}; time used = 1.3730618953704834s
epoch 20: {'train_loss': '2.77432'}; time used = 1.3652520179748535s
epoch 25: {'train_loss': '2.77300'}; time used = 1.338494062423706s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.275668859481812.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.55 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.35216'}; time used = 9.064585447311401s
epoch 10: {'train_loss': '1.31061'}; time used = 8.151822805404663s
epoch 15: {'train_loss': '1.07222'}; time used = 7.102133274078369s
epoch 20: {'train_loss': '0.70538'}; time used = 7.338271141052246s
epoch 25: {'train_loss': '0.52456'}; time used = 7.093631029129028s
epoch 30: {'train_loss': '0.48519'}; time used = 10.141733646392822s
epoch 35: {'train_loss': '0.21654'}; time used = 7.20952582359314s
epoch 40: {'train_loss': '0.16253'}; time used = 6.803986549377441s
epoch 45: {'train_loss': '0.74839'}; time used = 7.355556488037109s
epoch 50: {'train_loss': '0.35766'}; time used = 7.12327241897583s
epoch 55: {'train_loss': '0.24859'}; time used = 7.410114765167236s
epoch 60: {'train_loss': '0.13607'}; time used = 7.079345941543579s
epoch 65: {'train_loss': '0.25181'}; time used = 9.428852796554565s
epoch 70: {'train_loss': '0.18030'}; time used = 7.018120765686035s
epoch 75: {'train_loss': '0.12722'}; time used = 6.868631362915039s
epoch 80: {'train_loss': '0.18658'}; time used = 7.050780773162842s
epoch 85: {'train_loss': '0.01917'}; time used = 7.478290319442749s
epoch 90: {'train_loss': '0.26505'}; time used = 9.939834356307983s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 163.06797885894775.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.4991362126245848, 'samples': 0.5066666666666667, 'weighted': 0.4954764119601329, 'accuracy': 0.5066666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76007'}; time used = 2.303468704223633s
epoch 10: {'train_loss': '2.74084'}; time used = 2.4503512382507324s
epoch 15: {'train_loss': '2.71797'}; time used = 2.2004144191741943s
epoch 20: {'train_loss': '2.69350'}; time used = 2.062528610229492s
epoch 25: {'train_loss': '2.65128'}; time used = 1.9580471515655518s
epoch 30: {'train_loss': '2.60969'}; time used = 1.900160789489746s
epoch 35: {'train_loss': '2.58552'}; time used = 1.8284320831298828s
epoch 40: {'train_loss': '2.55296'}; time used = 1.790137529373169s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.077807903289795.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5538793103448276, 'samples': 0.5652173913043478, 'weighted': 0.5590329835082459, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.31246'}; time used = 1.1766760349273682s
epoch 10: {'train_loss': '1.31919'}; time used = 1.0911376476287842s
epoch 15: {'train_loss': '1.06267'}; time used = 1.0895121097564697s
epoch 20: {'train_loss': '1.18838'}; time used = 0.9882082939147949s
epoch 25: {'train_loss': '0.53300'}; time used = 1.0067400932312012s
epoch 30: {'train_loss': '0.46508'}; time used = 1.1137208938598633s
epoch 35: {'train_loss': '0.79758'}; time used = 1.0968561172485352s
epoch 40: {'train_loss': '0.70304'}; time used = 1.004392385482788s
epoch 45: {'train_loss': '0.59081'}; time used = 1.0895934104919434s
epoch 50: {'train_loss': '0.47339'}; time used = 1.0356996059417725s
epoch 55: {'train_loss': '0.27423'}; time used = 0.9930579662322998s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.149289846420288.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6933235509904623, 'samples': 0.7105263157894737, 'weighted': 0.7047920608564698, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.50673'}; time used = 1.5340380668640137s
epoch 10: {'train_loss': '0.18653'}; time used = 1.514848232269287s
epoch 15: {'train_loss': '0.08473'}; time used = 1.3940153121948242s
epoch 20: {'train_loss': '0.01861'}; time used = 1.41386079788208s
epoch 25: {'train_loss': '0.09167'}; time used = 1.2725131511688232s
epoch 30: {'train_loss': '0.02885'}; time used = 1.272761583328247s
epoch 35: {'train_loss': '0.01624'}; time used = 2.0256776809692383s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.605562925338745.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6840513983371126, 'samples': 0.7105263157894737, 'weighted': 0.6984922624020369, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.77638'}; time used = 1.2695374488830566s
epoch 10: {'train_loss': '2.74198'}; time used = 1.2644758224487305s
epoch 15: {'train_loss': '2.67345'}; time used = 1.293189287185669s
epoch 20: {'train_loss': '2.49413'}; time used = 1.3924498558044434s
epoch 25: {'train_loss': '2.35362'}; time used = 1.2291805744171143s
epoch 30: {'train_loss': '2.30347'}; time used = 1.0675110816955566s
epoch 35: {'train_loss': '2.22609'}; time used = 1.0736606121063232s
epoch 40: {'train_loss': '2.16637'}; time used = 1.0491158962249756s
epoch 45: {'train_loss': '2.17436'}; time used = 1.078402042388916s
epoch 50: {'train_loss': '2.18202'}; time used = 1.0563695430755615s
epoch 55: {'train_loss': '2.10995'}; time used = 1.0946786403656006s
epoch 60: {'train_loss': '2.11747'}; time used = 1.1605784893035889s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.827371835708618.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.525, 'samples': 0.631578947368421, 'weighted': 0.5605263157894737, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.96385'}; time used = 1.2395837306976318s
epoch 10: {'train_loss': '2.87198'}; time used = 1.0354914665222168s
epoch 15: {'train_loss': '2.87376'}; time used = 1.0226531028747559s
epoch 20: {'train_loss': '2.83214'}; time used = 1.042762041091919s
epoch 25: {'train_loss': '2.80399'}; time used = 1.055866003036499s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.658039093017578.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7172619047619048, 'samples': 0.7368421052631579, 'weighted': 0.7290100250626566, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.19620'}; time used = 1.194880485534668s
epoch 10: {'train_loss': '0.96944'}; time used = 1.1753637790679932s
epoch 15: {'train_loss': '0.64883'}; time used = 0.9783856868743896s
epoch 20: {'train_loss': '0.43326'}; time used = 0.8905563354492188s
epoch 25: {'train_loss': '0.34680'}; time used = 0.9028491973876953s
epoch 30: {'train_loss': '0.23684'}; time used = 0.8880140781402588s
epoch 35: {'train_loss': '0.20630'}; time used = 1.018887996673584s
epoch 40: {'train_loss': '0.29192'}; time used = 0.9113304615020752s
epoch 45: {'train_loss': '0.23534'}; time used = 0.9099535942077637s
epoch 50: {'train_loss': '0.22364'}; time used = 0.9852325916290283s
epoch 55: {'train_loss': '0.13651'}; time used = 1.0044431686401367s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.62205457687378.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 7.07806134223938s
epoch 10: {'train_loss': '1.38629'}; time used = 5.254144191741943s
epoch 15: {'train_loss': '1.38629'}; time used = 4.071550607681274s
epoch 20: {'train_loss': '1.38629'}; time used = 4.338196516036987s
epoch 25: {'train_loss': '1.38629'}; time used = 4.1587419509887695s
epoch 30: {'train_loss': '1.38629'}; time used = 5.693088054656982s
epoch 35: {'train_loss': '1.38629'}; time used = 6.9301440715789795s
epoch 40: {'train_loss': '1.38629'}; time used = 4.397439002990723s
epoch 45: {'train_loss': '1.38629'}; time used = 4.372702121734619s
epoch 50: {'train_loss': '1.38629'}; time used = 5.29649543762207s
epoch 55: {'train_loss': '1.38629'}; time used = 6.899596214294434s
epoch 60: {'train_loss': '1.38629'}; time used = 4.45907735824585s
epoch 65: {'train_loss': '1.38629'}; time used = 4.217040777206421s
epoch 70: {'train_loss': '1.38629'}; time used = 4.1760149002075195s
epoch 75: {'train_loss': '1.38629'}; time used = 4.167601108551025s
epoch 80: {'train_loss': '1.38629'}; time used = 5.202481746673584s
epoch 85: {'train_loss': '1.38629'}; time used = 4.098395109176636s
epoch 90: {'train_loss': '1.38629'}; time used = 4.0689780712127686s
epoch 95: {'train_loss': '1.38629'}; time used = 5.864921808242798s
epoch 100: {'train_loss': '1.38629'}; time used = 5.946359395980835s
epoch 105: {'train_loss': '1.38629'}; time used = 3.940464496612549s
epoch 110: {'train_loss': '1.38629'}; time used = 4.0204856395721436s
epoch 115: {'train_loss': '1.38629'}; time used = 4.776442766189575s
epoch 120: {'train_loss': '1.38629'}; time used = 7.0188775062561035s
epoch 125: {'train_loss': '1.38629'}; time used = 5.615556716918945s
epoch 130: {'train_loss': '1.38629'}; time used = 6.098607301712036s
epoch 135: {'train_loss': '1.38629'}; time used = 4.075464725494385s
epoch 140: {'train_loss': '1.38629'}; time used = 4.260935544967651s
epoch 145: {'train_loss': '1.38629'}; time used = 3.9522924423217773s
epoch 150: {'train_loss': '1.38629'}; time used = 4.1301116943359375s
epoch 155: {'train_loss': '1.38629'}; time used = 4.13889741897583s
epoch 160: {'train_loss': '1.38629'}; time used = 4.047598838806152s
epoch 165: {'train_loss': '1.38629'}; time used = 3.9224777221679688s
epoch 170: {'train_loss': '1.38629'}; time used = 4.032168626785278s
epoch 175: {'train_loss': '1.38629'}; time used = 4.125052213668823s
epoch 180: {'train_loss': '1.38629'}; time used = 4.067062616348267s
epoch 185: {'train_loss': '1.38629'}; time used = 4.040774345397949s
epoch 190: {'train_loss': '1.38629'}; time used = 4.0903167724609375s
epoch 195: {'train_loss': '1.38629'}; time used = 3.9873533248901367s
epoch 200: {'train_loss': '1.38629'}; time used = 4.029067277908325s
epoch 205: {'train_loss': '1.38629'}; time used = 5.582590341567993s
epoch 210: {'train_loss': '1.38629'}; time used = 4.949328422546387s
epoch 215: {'train_loss': '1.38629'}; time used = 3.8408000469207764s
epoch 220: {'train_loss': '1.38629'}; time used = 3.9545652866363525s
epoch 225: {'train_loss': '1.38629'}; time used = 3.910240411758423s
epoch 230: {'train_loss': '1.38629'}; time used = 4.9333086013793945s
epoch 235: {'train_loss': '1.38629'}; time used = 4.214518070220947s
epoch 240: {'train_loss': '1.38629'}; time used = 4.10648250579834s
epoch 245: {'train_loss': '1.38629'}; time used = 4.2425010204315186s
epoch 250: {'train_loss': '1.38629'}; time used = 6.875321626663208s
epoch 255: {'train_loss': '1.38629'}; time used = 4.686570882797241s
epoch 260: {'train_loss': '1.38629'}; time used = 4.2533581256866455s
epoch 265: {'train_loss': '1.38629'}; time used = 4.211459636688232s
epoch 270: {'train_loss': '1.38629'}; time used = 4.541640758514404s
epoch 275: {'train_loss': '1.38629'}; time used = 4.106341600418091s
epoch 280: {'train_loss': '1.38629'}; time used = 3.952094078063965s
epoch 285: {'train_loss': '1.38629'}; time used = 4.0590150356292725s
epoch 290: {'train_loss': '1.38629'}; time used = 5.320925712585449s
epoch 295: {'train_loss': '1.38629'}; time used = 5.27006459236145s
epoch 300: {'train_loss': '1.38629'}; time used = 4.745473623275757s
epoch 305: {'train_loss': '1.38629'}; time used = 4.458104610443115s
epoch 310: {'train_loss': '1.38629'}; time used = 7.650836706161499s
epoch 315: {'train_loss': '1.38629'}; time used = 7.939727544784546s
epoch 320: {'train_loss': '1.38629'}; time used = 7.44579291343689s
epoch 325: {'train_loss': '1.38629'}; time used = 4.594051122665405s
epoch 330: {'train_loss': '1.38629'}; time used = 3.926460027694702s
epoch 335: {'train_loss': '1.38629'}; time used = 5.628477096557617s
epoch 340: {'train_loss': '1.38629'}; time used = 6.45164942741394s
epoch 345: {'train_loss': '1.38629'}; time used = 3.984639883041382s
epoch 350: {'train_loss': '1.38629'}; time used = 3.9297006130218506s
epoch 355: {'train_loss': '1.38629'}; time used = 4.044392108917236s
epoch 360: {'train_loss': '1.38629'}; time used = 4.1132283210754395s
epoch 365: {'train_loss': '1.38629'}; time used = 4.804378986358643s
epoch 370: {'train_loss': '1.38629'}; time used = 6.919111967086792s
epoch 375: {'train_loss': '1.38629'}; time used = 4.749711751937866s
epoch 380: {'train_loss': '1.38629'}; time used = 4.150178909301758s
epoch 385: {'train_loss': '1.38629'}; time used = 3.9713783264160156s
epoch 390: {'train_loss': '1.38629'}; time used = 3.958648681640625s
epoch 395: {'train_loss': '1.38629'}; time used = 3.9467616081237793s
epoch 400: {'train_loss': '1.38629'}; time used = 4.22068452835083s
epoch 405: {'train_loss': '1.38629'}; time used = 4.0230560302734375s
epoch 410: {'train_loss': '1.38629'}; time used = 4.20304536819458s
epoch 415: {'train_loss': '1.38629'}; time used = 4.1205527782440186s
epoch 420: {'train_loss': '1.38629'}; time used = 6.6207664012908936s
epoch 425: {'train_loss': '1.38629'}; time used = 5.377620697021484s
epoch 430: {'train_loss': '1.38629'}; time used = 4.171470880508423s
epoch 435: {'train_loss': '1.38629'}; time used = 4.048413515090942s
epoch 440: {'train_loss': '1.38629'}; time used = 3.9747722148895264s
epoch 445: {'train_loss': '1.38629'}; time used = 4.298954486846924s
epoch 450: {'train_loss': '1.38629'}; time used = 4.1640784740448s
epoch 455: {'train_loss': '1.38629'}; time used = 4.181694030761719s
epoch 460: {'train_loss': '1.38629'}; time used = 3.958796501159668s
epoch 465: {'train_loss': '1.38629'}; time used = 4.014209985733032s
epoch 470: {'train_loss': '1.38629'}; time used = 3.974623441696167s
epoch 475: {'train_loss': '1.38629'}; time used = 4.046084880828857s
epoch 480: {'train_loss': '1.38629'}; time used = 4.030327558517456s
epoch 485: {'train_loss': '1.38629'}; time used = 4.375049829483032s
epoch 490: {'train_loss': '1.38629'}; time used = 4.699402332305908s
epoch 495: {'train_loss': '1.38629'}; time used = 4.771920680999756s
epoch 500: {'train_loss': '1.38629'}; time used = 5.741936922073364s
Finished training. Time used = 478.9052588939667.
Training classifier using 80.00% nodes...
{'micro': 0.67, 'macro': 0.6659580929243851, 'samples': 0.67, 'weighted': 0.6652232007288187, 'accuracy': 0.67}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89510'}; time used = 2.6302413940429688s
epoch 10: {'train_loss': '2.81497'}; time used = 3.3244802951812744s
epoch 15: {'train_loss': '2.79403'}; time used = 2.7575883865356445s
epoch 20: {'train_loss': '2.77272'}; time used = 2.652019739151001s
epoch 25: {'train_loss': '2.75860'}; time used = 2.8513388633728027s
epoch 30: {'train_loss': '2.74839'}; time used = 4.010886907577515s
epoch 35: {'train_loss': '2.73822'}; time used = 3.8545944690704346s
epoch 40: {'train_loss': '2.72852'}; time used = 3.1456894874572754s
epoch 45: {'train_loss': '2.72138'}; time used = 2.485311269760132s
epoch 50: {'train_loss': '2.71049'}; time used = 2.5805554389953613s
epoch 55: {'train_loss': '2.70345'}; time used = 2.4992990493774414s
epoch 60: {'train_loss': '2.68704'}; time used = 2.579759359359741s
epoch 65: {'train_loss': '2.68553'}; time used = 2.491481304168701s
epoch 70: {'train_loss': '2.69594'}; time used = 3.6810741424560547s
epoch 75: {'train_loss': '2.66488'}; time used = 3.2301084995269775s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 51.58849239349365.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.4888888888888889, 'samples': 0.5507246376811594, 'weighted': 0.5017713365539452, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.51 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76703'}; time used = 1.8972163200378418s
epoch 10: {'train_loss': '2.76045'}; time used = 1.893841028213501s
epoch 15: {'train_loss': '2.74929'}; time used = 1.6686041355133057s
epoch 20: {'train_loss': '2.72712'}; time used = 1.67763352394104s
epoch 25: {'train_loss': '2.68946'}; time used = 2.7518296241760254s
epoch 30: {'train_loss': '2.65566'}; time used = 3.046574115753174s
epoch 35: {'train_loss': '2.60761'}; time used = 3.3762929439544678s
epoch 40: {'train_loss': '2.55366'}; time used = 2.111335277557373s
epoch 45: {'train_loss': '2.50692'}; time used = 2.081913471221924s
epoch 50: {'train_loss': '2.42731'}; time used = 1.702864170074463s
epoch 55: {'train_loss': '2.43964'}; time used = 1.9212939739227295s
epoch 60: {'train_loss': '2.32725'}; time used = 1.6750400066375732s
epoch 65: {'train_loss': '2.38253'}; time used = 2.061201333999634s
epoch 70: {'train_loss': '2.40454'}; time used = 4.193840742111206s
epoch 75: {'train_loss': '2.34320'}; time used = 4.7060699462890625s
epoch 80: {'train_loss': '2.26305'}; time used = 5.598476886749268s
epoch 85: {'train_loss': '2.21036'}; time used = 5.151739597320557s
epoch 90: {'train_loss': '2.16882'}; time used = 4.5007078647613525s
epoch 95: {'train_loss': '2.41297'}; time used = 4.921189308166504s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 60.12120723724365.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5114782235571765, 'samples': 0.5217391304347826, 'weighted': 0.5166086769959796, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.82735'}; time used = 1.9130299091339111s
epoch 10: {'train_loss': '2.78821'}; time used = 1.8802556991577148s
epoch 15: {'train_loss': '2.77095'}; time used = 2.045933723449707s
epoch 20: {'train_loss': '2.77626'}; time used = 1.8485329151153564s
epoch 25: {'train_loss': '2.76753'}; time used = 2.2077927589416504s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.005077600479126.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5101591187270502, 'samples': 0.5797101449275363, 'weighted': 0.5235343160732975, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.93013'}; time used = 1.7995765209197998s
epoch 10: {'train_loss': '2.80828'}; time used = 2.0341334342956543s
epoch 15: {'train_loss': '2.75989'}; time used = 1.7323999404907227s
epoch 20: {'train_loss': '2.70902'}; time used = 1.8521173000335693s
epoch 25: {'train_loss': '2.66062'}; time used = 1.8578312397003174s
epoch 30: {'train_loss': '2.62614'}; time used = 1.762129783630371s
epoch 35: {'train_loss': '2.60620'}; time used = 1.820396900177002s
epoch 40: {'train_loss': '2.58780'}; time used = 1.7462360858917236s
epoch 45: {'train_loss': '2.55634'}; time used = 1.7268052101135254s
epoch 50: {'train_loss': '2.52055'}; time used = 1.7222957611083984s
epoch 55: {'train_loss': '2.53222'}; time used = 1.816910982131958s
epoch 60: {'train_loss': '2.52814'}; time used = 1.76033616065979s
epoch 65: {'train_loss': '2.50731'}; time used = 1.7508447170257568s
epoch 70: {'train_loss': '2.48182'}; time used = 1.7791645526885986s
epoch 75: {'train_loss': '2.45139'}; time used = 1.7477281093597412s
epoch 80: {'train_loss': '2.41219'}; time used = 1.7835144996643066s
epoch 85: {'train_loss': '2.41273'}; time used = 1.7268707752227783s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.01827096939087.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.05782'}; time used = 1.7912726402282715s
epoch 10: {'train_loss': '0.47206'}; time used = 1.9197993278503418s
epoch 15: {'train_loss': '0.30918'}; time used = 2.2875044345855713s
epoch 20: {'train_loss': '0.28501'}; time used = 1.687495231628418s
epoch 25: {'train_loss': '0.30347'}; time used = 1.8259103298187256s
epoch 30: {'train_loss': '0.31210'}; time used = 1.6476490497589111s
epoch 35: {'train_loss': '0.29449'}; time used = 1.7294368743896484s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.222387313842773.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5616648411829135, 'samples': 0.5797101449275363, 'weighted': 0.5681095925202788, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.17153'}; time used = 2.271117925643921s
epoch 10: {'train_loss': '1.05015'}; time used = 1.8634204864501953s
epoch 15: {'train_loss': '0.93359'}; time used = 1.9075779914855957s
epoch 20: {'train_loss': '0.78005'}; time used = 1.8280553817749023s
epoch 25: {'train_loss': '0.58632'}; time used = 1.8981199264526367s
epoch 30: {'train_loss': '0.40377'}; time used = 1.4337332248687744s
epoch 35: {'train_loss': '0.31864'}; time used = 1.0868418216705322s
epoch 40: {'train_loss': '0.23954'}; time used = 1.1149134635925293s
epoch 45: {'train_loss': '0.23456'}; time used = 1.2973248958587646s
epoch 50: {'train_loss': '0.21464'}; time used = 1.238588809967041s
epoch 55: {'train_loss': '0.16992'}; time used = 1.2426996231079102s
epoch 60: {'train_loss': '0.14980'}; time used = 1.1451706886291504s
epoch 65: {'train_loss': '0.17179'}; time used = 1.15537691116333s
epoch 70: {'train_loss': '0.10011'}; time used = 1.251885175704956s
epoch 75: {'train_loss': '0.04891'}; time used = 1.0989155769348145s
epoch 80: {'train_loss': '0.02973'}; time used = 1.07832932472229s
epoch 85: {'train_loss': '0.03575'}; time used = 1.0614449977874756s
epoch 90: {'train_loss': '0.02262'}; time used = 1.0635569095611572s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.77202820777893.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 6.465018033981323s
epoch 10: {'train_loss': '1.38629'}; time used = 10.04511046409607s
epoch 15: {'train_loss': '1.38629'}; time used = 7.027593612670898s
epoch 20: {'train_loss': '1.38629'}; time used = 6.689755916595459s
epoch 25: {'train_loss': '1.38629'}; time used = 6.401024103164673s
epoch 30: {'train_loss': '1.38629'}; time used = 6.68918251991272s
epoch 35: {'train_loss': '1.38629'}; time used = 7.200356483459473s
epoch 40: {'train_loss': '1.38629'}; time used = 6.388989448547363s
epoch 45: {'train_loss': '1.38629'}; time used = 8.472140789031982s
epoch 50: {'train_loss': '1.38629'}; time used = 7.667144536972046s
epoch 55: {'train_loss': '1.38629'}; time used = 6.287548780441284s
epoch 60: {'train_loss': '1.38629'}; time used = 6.2355711460113525s
epoch 65: {'train_loss': '1.38629'}; time used = 6.3485448360443115s
epoch 70: {'train_loss': '1.38629'}; time used = 6.6557862758636475s
epoch 75: {'train_loss': '1.38629'}; time used = 6.360386610031128s
epoch 80: {'train_loss': '1.38629'}; time used = 6.2694091796875s
epoch 85: {'train_loss': '1.38629'}; time used = 6.189002990722656s
epoch 90: {'train_loss': '1.38629'}; time used = 6.218416452407837s
epoch 95: {'train_loss': '1.38629'}; time used = 6.326805830001831s
epoch 100: {'train_loss': '1.38629'}; time used = 7.025432348251343s
epoch 105: {'train_loss': '1.38629'}; time used = 6.326146125793457s
epoch 110: {'train_loss': '1.38629'}; time used = 7.9405198097229s
epoch 115: {'train_loss': '1.38629'}; time used = 6.832782506942749s
epoch 120: {'train_loss': '1.38629'}; time used = 8.385237693786621s
epoch 125: {'train_loss': '1.38629'}; time used = 8.265241384506226s
epoch 130: {'train_loss': '1.38629'}; time used = 8.729576826095581s
epoch 135: {'train_loss': '1.38629'}; time used = 6.642262697219849s
epoch 140: {'train_loss': '1.38629'}; time used = 8.476698160171509s
epoch 145: {'train_loss': '1.38629'}; time used = 7.925471305847168s
epoch 150: {'train_loss': '1.38629'}; time used = 6.406842947006226s
epoch 155: {'train_loss': '1.38629'}; time used = 9.549057960510254s
epoch 160: {'train_loss': '1.38629'}; time used = 8.224220514297485s
epoch 165: {'train_loss': '1.38629'}; time used = 7.2688257694244385s
epoch 170: {'train_loss': '1.38629'}; time used = 7.335439920425415s
epoch 175: {'train_loss': '1.38629'}; time used = 7.45033073425293s
epoch 180: {'train_loss': '1.38629'}; time used = 6.636176109313965s
epoch 185: {'train_loss': '1.38629'}; time used = 10.219334363937378s
epoch 190: {'train_loss': '1.38629'}; time used = 7.657163858413696s
epoch 195: {'train_loss': '1.38629'}; time used = 6.285727500915527s
epoch 200: {'train_loss': '1.38629'}; time used = 6.19087553024292s
epoch 205: {'train_loss': '1.38629'}; time used = 7.035402774810791s
epoch 210: {'train_loss': '1.38629'}; time used = 6.965906143188477s
epoch 215: {'train_loss': '1.38629'}; time used = 9.163668394088745s
epoch 220: {'train_loss': '1.38629'}; time used = 8.10610842704773s
epoch 225: {'train_loss': '1.38629'}; time used = 9.149404048919678s
epoch 230: {'train_loss': '1.38629'}; time used = 7.016798496246338s
epoch 235: {'train_loss': '1.38629'}; time used = 6.378926038742065s
epoch 240: {'train_loss': '1.38629'}; time used = 6.730725049972534s
epoch 245: {'train_loss': '1.38629'}; time used = 7.236576318740845s
epoch 250: {'train_loss': '1.38629'}; time used = 9.707666397094727s
epoch 255: {'train_loss': '1.38629'}; time used = 6.94980001449585s
epoch 260: {'train_loss': '1.38629'}; time used = 8.330573081970215s
epoch 265: {'train_loss': '1.38629'}; time used = 8.387702703475952s
epoch 270: {'train_loss': '1.38629'}; time used = 6.4818010330200195s
epoch 275: {'train_loss': '1.38629'}; time used = 6.612613677978516s
epoch 280: {'train_loss': '1.38629'}; time used = 7.291147232055664s
epoch 285: {'train_loss': '1.38629'}; time used = 7.4129416942596436s
epoch 290: {'train_loss': '1.38629'}; time used = 6.361050605773926s
epoch 295: {'train_loss': '1.38629'}; time used = 6.249204635620117s
epoch 300: {'train_loss': '1.38629'}; time used = 6.469237327575684s
epoch 305: {'train_loss': '1.38629'}; time used = 6.282751798629761s
epoch 310: {'train_loss': '1.38629'}; time used = 6.059630870819092s
epoch 315: {'train_loss': '1.38629'}; time used = 6.170862913131714s
epoch 320: {'train_loss': '1.38629'}; time used = 6.386963605880737s
epoch 325: {'train_loss': '1.38629'}; time used = 6.355950117111206s
epoch 330: {'train_loss': '1.38629'}; time used = 6.521710634231567s
epoch 335: {'train_loss': '1.38629'}; time used = 6.4075868129730225s
epoch 340: {'train_loss': '1.38629'}; time used = 6.256446838378906s
epoch 345: {'train_loss': '1.38629'}; time used = 6.37627649307251s
epoch 350: {'train_loss': '1.38629'}; time used = 6.354168176651001s
epoch 355: {'train_loss': '1.38629'}; time used = 7.352002382278442s
epoch 360: {'train_loss': '1.38629'}; time used = 6.294570446014404s
epoch 365: {'train_loss': '1.38629'}; time used = 6.137407302856445s
epoch 370: {'train_loss': '1.38629'}; time used = 6.4246909618377686s
epoch 375: {'train_loss': '1.38629'}; time used = 6.478946685791016s
epoch 380: {'train_loss': '1.38629'}; time used = 6.372372150421143s
epoch 385: {'train_loss': '1.38629'}; time used = 6.094480752944946s
epoch 390: {'train_loss': '1.38629'}; time used = 6.484444856643677s
epoch 395: {'train_loss': '1.38629'}; time used = 6.396316289901733s
epoch 400: {'train_loss': '1.38629'}; time used = 10.387096881866455s
epoch 405: {'train_loss': '1.38629'}; time used = 6.349053621292114s
epoch 410: {'train_loss': '1.38629'}; time used = 6.209742069244385s
epoch 415: {'train_loss': '1.38629'}; time used = 6.369707107543945s
epoch 420: {'train_loss': '1.38629'}; time used = 6.294867753982544s
epoch 425: {'train_loss': '1.38629'}; time used = 7.185557842254639s
epoch 430: {'train_loss': '1.38629'}; time used = 7.373875379562378s
epoch 435: {'train_loss': '1.38629'}; time used = 6.7260847091674805s
epoch 440: {'train_loss': '1.38629'}; time used = 9.939828395843506s
epoch 445: {'train_loss': '1.38629'}; time used = 6.650686025619507s
epoch 450: {'train_loss': '1.38629'}; time used = 6.368131875991821s
epoch 455: {'train_loss': '1.38629'}; time used = 6.30009388923645s
epoch 460: {'train_loss': '1.38629'}; time used = 6.315681457519531s
epoch 465: {'train_loss': '1.38629'}; time used = 6.173533201217651s
epoch 470: {'train_loss': '1.38629'}; time used = 6.168751955032349s
epoch 475: {'train_loss': '1.38629'}; time used = 7.7515599727630615s
epoch 480: {'train_loss': '1.38629'}; time used = 8.72166395187378s
epoch 485: {'train_loss': '1.38629'}; time used = 6.238973379135132s
epoch 490: {'train_loss': '1.38629'}; time used = 6.828580141067505s
epoch 495: {'train_loss': '1.38629'}; time used = 6.41240930557251s
epoch 500: {'train_loss': '1.38629'}; time used = 6.453526973724365s
Finished training. Time used = 715.1358246803284.
Training classifier using 80.00% nodes...
{'micro': 0.41, 'macro': 0.33154377842354993, 'samples': 0.41, 'weighted': 0.3215974650708434, 'accuracy': 0.41}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38430'}; time used = 1.8697140216827393s
epoch 10: {'train_loss': '1.31526'}; time used = 2.530379056930542s
epoch 15: {'train_loss': '1.25461'}; time used = 3.354538679122925s
epoch 20: {'train_loss': '1.33173'}; time used = 3.3440234661102295s
epoch 25: {'train_loss': '1.20726'}; time used = 2.170478105545044s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.135080099105835.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5179175118323192, 'samples': 0.5507246376811594, 'weighted': 0.5270306023458858, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.76613'}; time used = 0.9559361934661865s
epoch 10: {'train_loss': '2.39908'}; time used = 0.890521764755249s
epoch 15: {'train_loss': '2.26610'}; time used = 0.8845272064208984s
epoch 20: {'train_loss': '2.13723'}; time used = 0.9008302688598633s
epoch 25: {'train_loss': '2.10015'}; time used = 1.0265653133392334s
epoch 30: {'train_loss': '2.04562'}; time used = 1.0027549266815186s
epoch 35: {'train_loss': '1.98778'}; time used = 0.9294795989990234s
epoch 40: {'train_loss': '1.96078'}; time used = 1.005417823791504s
epoch 45: {'train_loss': '1.94982'}; time used = 0.9433917999267578s
epoch 50: {'train_loss': '1.90840'}; time used = 0.8830406665802002s
epoch 55: {'train_loss': '1.87323'}; time used = 0.8945479393005371s
epoch 60: {'train_loss': '1.84562'}; time used = 0.9208910465240479s
epoch 65: {'train_loss': '1.79910'}; time used = 0.9866836071014404s
epoch 70: {'train_loss': '1.81299'}; time used = 1.0723567008972168s
epoch 75: {'train_loss': '1.77051'}; time used = 1.0004241466522217s
epoch 80: {'train_loss': '1.77697'}; time used = 0.986886739730835s
epoch 85: {'train_loss': '1.80470'}; time used = 1.0532188415527344s
epoch 90: {'train_loss': '1.78139'}; time used = 0.8544409275054932s
epoch 95: {'train_loss': '1.76862'}; time used = 1.0683636665344238s
epoch 100: {'train_loss': '1.77148'}; time used = 0.99881911277771s
epoch 105: {'train_loss': '1.73276'}; time used = 0.9697213172912598s
epoch 110: {'train_loss': '1.72416'}; time used = 1.0720789432525635s
epoch 115: {'train_loss': '1.71889'}; time used = 0.8822555541992188s
epoch 120: {'train_loss': '1.70031'}; time used = 0.875058650970459s
epoch 125: {'train_loss': '1.71600'}; time used = 0.8898708820343018s
epoch 130: {'train_loss': '1.68752'}; time used = 1.0066561698913574s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.266900300979614.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.27368'}; time used = 1.7423107624053955s
epoch 10: {'train_loss': '0.90802'}; time used = 1.6388053894042969s
epoch 15: {'train_loss': '0.35702'}; time used = 1.6576902866363525s
epoch 20: {'train_loss': '0.52489'}; time used = 1.712864875793457s
epoch 25: {'train_loss': '0.30252'}; time used = 1.7379810810089111s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.69192099571228.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5201264488935722, 'samples': 0.5217391304347826, 'weighted': 0.5221423008200852, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 27.08 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.99291'}; time used = 3.080082654953003s
epoch 10: {'train_loss': '2.96680'}; time used = 3.148958921432495s
epoch 15: {'train_loss': '2.83629'}; time used = 2.8593361377716064s
epoch 20: {'train_loss': '2.78668'}; time used = 2.732658624649048s
epoch 25: {'train_loss': '2.75378'}; time used = 1.7802412509918213s
epoch 30: {'train_loss': '2.72964'}; time used = 1.807332992553711s
epoch 35: {'train_loss': '2.70505'}; time used = 1.8048267364501953s
epoch 40: {'train_loss': '2.67457'}; time used = 2.054292917251587s
epoch 45: {'train_loss': '2.65663'}; time used = 1.7484774589538574s
epoch 50: {'train_loss': '2.61982'}; time used = 2.090277910232544s
epoch 55: {'train_loss': '2.60364'}; time used = 1.7679939270019531s
epoch 60: {'train_loss': '2.58550'}; time used = 2.7245051860809326s
epoch 65: {'train_loss': '2.53948'}; time used = 3.540802478790283s
epoch 70: {'train_loss': '2.51711'}; time used = 3.0581095218658447s
epoch 75: {'train_loss': '2.47413'}; time used = 2.694862127304077s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.74407482147217.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.49988309562777655, 'samples': 0.5507246376811594, 'weighted': 0.5114379915489998, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.14629'}; time used = 2.487053871154785s
epoch 10: {'train_loss': '0.72466'}; time used = 2.3428738117218018s
epoch 15: {'train_loss': '0.14133'}; time used = 2.3746774196624756s
epoch 20: {'train_loss': '0.00140'}; time used = 2.432682991027832s
epoch 25: {'train_loss': '0.00086'}; time used = 2.5270140171051025s
epoch 30: {'train_loss': '0.15758'}; time used = 2.461268663406372s
epoch 35: {'train_loss': '0.05344'}; time used = 2.4620859622955322s
epoch 40: {'train_loss': '0.15522'}; time used = 2.5257489681243896s
epoch 45: {'train_loss': '0.00425'}; time used = 2.4943859577178955s
epoch 50: {'train_loss': '0.04239'}; time used = 2.4969706535339355s
epoch 55: {'train_loss': '0.03206'}; time used = 2.446080446243286s
epoch 60: {'train_loss': '0.11779'}; time used = 2.598212718963623s
epoch 65: {'train_loss': '0.15279'}; time used = 2.5573806762695312s
epoch 70: {'train_loss': '0.04871'}; time used = 2.36553692817688s
epoch 75: {'train_loss': '0.02164'}; time used = 2.402425527572632s
epoch 80: {'train_loss': '0.07994'}; time used = 2.44942569732666s
epoch 85: {'train_loss': '0.00001'}; time used = 2.4145233631134033s
epoch 90: {'train_loss': '0.03687'}; time used = 2.302034616470337s
epoch 95: {'train_loss': '0.00612'}; time used = 2.3914809226989746s
epoch 100: {'train_loss': '0.00029'}; time used = 2.3884475231170654s
epoch 105: {'train_loss': '0.00001'}; time used = 2.3903417587280273s
epoch 110: {'train_loss': '0.00005'}; time used = 3.371678352355957s
epoch 115: {'train_loss': '0.00001'}; time used = 3.4267852306365967s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 62.45851016044617.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.491578947368421, 'samples': 0.5942028985507246, 'weighted': 0.5081311975591152, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.41718'}; time used = 1.1558690071105957s
epoch 10: {'train_loss': '2.82430'}; time used = 1.0078182220458984s
epoch 15: {'train_loss': '2.80480'}; time used = 1.0078814029693604s
epoch 20: {'train_loss': '2.80628'}; time used = 1.0135891437530518s
epoch 25: {'train_loss': '2.80301'}; time used = 0.9742357730865479s
epoch 30: {'train_loss': '2.79471'}; time used = 1.0029315948486328s
epoch 35: {'train_loss': '2.78374'}; time used = 0.9681446552276611s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.441051721572876.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.18774'}; time used = 1.1330900192260742s
epoch 10: {'train_loss': '0.07326'}; time used = 1.0709824562072754s
epoch 15: {'train_loss': '0.07764'}; time used = 0.9713997840881348s
epoch 20: {'train_loss': '0.04617'}; time used = 0.8720884323120117s
epoch 25: {'train_loss': '0.04662'}; time used = 0.8529520034790039s
epoch 30: {'train_loss': '0.02738'}; time used = 0.8693196773529053s
epoch 35: {'train_loss': '0.01302'}; time used = 1.4948885440826416s
epoch 40: {'train_loss': '0.02347'}; time used = 1.8284063339233398s
epoch 45: {'train_loss': '0.03261'}; time used = 1.040595293045044s
epoch 50: {'train_loss': '0.03228'}; time used = 0.876197338104248s
epoch 55: {'train_loss': '0.01773'}; time used = 0.9284789562225342s
epoch 60: {'train_loss': '0.01031'}; time used = 1.1430058479309082s
epoch 65: {'train_loss': '0.02475'}; time used = 0.8638794422149658s
epoch 70: {'train_loss': '0.01766'}; time used = 0.8848567008972168s
epoch 75: {'train_loss': '0.01742'}; time used = 0.8856155872344971s
epoch 80: {'train_loss': '0.01739'}; time used = 0.8619089126586914s
epoch 85: {'train_loss': '0.02138'}; time used = 0.9751312732696533s
epoch 90: {'train_loss': '0.02840'}; time used = 0.9412658214569092s
epoch 95: {'train_loss': '0.03182'}; time used = 0.8525867462158203s
epoch 100: {'train_loss': '0.03544'}; time used = 0.899446964263916s
epoch 105: {'train_loss': '0.01005'}; time used = 1.2248022556304932s
epoch 110: {'train_loss': '0.01443'}; time used = 1.6740937232971191s
epoch 115: {'train_loss': '0.01734'}; time used = 1.635634183883667s
epoch 120: {'train_loss': '0.02534'}; time used = 1.6952555179595947s
epoch 125: {'train_loss': '0.02457'}; time used = 1.7383651733398438s
epoch 130: {'train_loss': '0.01361'}; time used = 1.4723269939422607s
epoch 135: {'train_loss': '0.02074'}; time used = 0.9289414882659912s
epoch 140: {'train_loss': '0.03513'}; time used = 1.1034457683563232s
epoch 145: {'train_loss': '0.01703'}; time used = 0.984978199005127s
epoch 150: {'train_loss': '0.01345'}; time used = 1.6896955966949463s
epoch 155: {'train_loss': '0.01715'}; time used = 0.9022831916809082s
epoch 160: {'train_loss': '0.01005'}; time used = 0.8591501712799072s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.27130079269409.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7414965986394557, 'samples': 0.7631578947368421, 'weighted': 0.7533118510562119, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 7.5520524978637695s
epoch 10: {'train_loss': '1.38629'}; time used = 6.8083038330078125s
epoch 15: {'train_loss': '1.38629'}; time used = 6.777542591094971s
epoch 20: {'train_loss': '1.38629'}; time used = 6.866875886917114s
epoch 25: {'train_loss': '1.38629'}; time used = 6.761517763137817s
epoch 30: {'train_loss': '1.38629'}; time used = 9.385118246078491s
epoch 35: {'train_loss': '1.38629'}; time used = 7.4134345054626465s
epoch 40: {'train_loss': '1.38629'}; time used = 6.481747388839722s
epoch 45: {'train_loss': '1.38629'}; time used = 6.573699235916138s
epoch 50: {'train_loss': '1.38629'}; time used = 6.690466403961182s
epoch 55: {'train_loss': '1.38629'}; time used = 6.56459379196167s
epoch 60: {'train_loss': '1.38629'}; time used = 6.409766435623169s
epoch 65: {'train_loss': '1.38629'}; time used = 6.635831356048584s
epoch 70: {'train_loss': '1.38629'}; time used = 6.691746950149536s
epoch 75: {'train_loss': '1.38629'}; time used = 7.404861927032471s
epoch 80: {'train_loss': '1.38629'}; time used = 7.400842666625977s
epoch 85: {'train_loss': '1.38629'}; time used = 6.745219945907593s
epoch 90: {'train_loss': '1.38629'}; time used = 6.801194667816162s
epoch 95: {'train_loss': '1.38629'}; time used = 7.4882519245147705s
epoch 100: {'train_loss': '1.38629'}; time used = 7.0382771492004395s
epoch 105: {'train_loss': '1.38629'}; time used = 6.818071365356445s
epoch 110: {'train_loss': '1.38629'}; time used = 8.359638452529907s
epoch 115: {'train_loss': '1.38629'}; time used = 6.849524974822998s
epoch 120: {'train_loss': '1.38629'}; time used = 6.816225528717041s
epoch 125: {'train_loss': '1.38629'}; time used = 6.643776178359985s
epoch 130: {'train_loss': '1.38629'}; time used = 10.509545087814331s
epoch 135: {'train_loss': '1.38629'}; time used = 6.904651403427124s
epoch 140: {'train_loss': '1.38629'}; time used = 6.552704572677612s
epoch 145: {'train_loss': '1.38629'}; time used = 6.595709562301636s
epoch 150: {'train_loss': '1.38629'}; time used = 6.613300323486328s
epoch 155: {'train_loss': '1.38629'}; time used = 6.604636192321777s
epoch 160: {'train_loss': '1.38629'}; time used = 6.634094476699829s
epoch 165: {'train_loss': '1.38629'}; time used = 6.55512547492981s
epoch 170: {'train_loss': '1.38629'}; time used = 6.546418190002441s
epoch 175: {'train_loss': '1.38629'}; time used = 6.519559383392334s
epoch 180: {'train_loss': '1.38629'}; time used = 6.564624071121216s
epoch 185: {'train_loss': '1.38629'}; time used = 6.92290735244751s
epoch 190: {'train_loss': '1.38629'}; time used = 6.596747159957886s
epoch 195: {'train_loss': '1.38629'}; time used = 6.648252725601196s
epoch 200: {'train_loss': '1.38629'}; time used = 6.530604600906372s
epoch 205: {'train_loss': '1.38629'}; time used = 6.561857461929321s
epoch 210: {'train_loss': '1.38629'}; time used = 6.5352160930633545s
epoch 215: {'train_loss': '1.38629'}; time used = 6.931002140045166s
epoch 220: {'train_loss': '1.38629'}; time used = 6.699923992156982s
epoch 225: {'train_loss': '1.38629'}; time used = 6.832566976547241s
epoch 230: {'train_loss': '1.38629'}; time used = 6.746719598770142s
epoch 235: {'train_loss': '1.38629'}; time used = 6.577723503112793s
epoch 240: {'train_loss': '1.38629'}; time used = 6.495480537414551s
epoch 245: {'train_loss': '1.38629'}; time used = 6.548146486282349s
epoch 250: {'train_loss': '1.38629'}; time used = 6.605143308639526s
epoch 255: {'train_loss': '1.38629'}; time used = 6.71267294883728s
epoch 260: {'train_loss': '1.38629'}; time used = 6.7232794761657715s
epoch 265: {'train_loss': '1.38629'}; time used = 6.589289903640747s
epoch 270: {'train_loss': '1.38629'}; time used = 6.7335100173950195s
epoch 275: {'train_loss': '1.38629'}; time used = 6.945170640945435s
epoch 280: {'train_loss': '1.38629'}; time used = 6.5789220333099365s
epoch 285: {'train_loss': '1.38629'}; time used = 6.654266595840454s
epoch 290: {'train_loss': '1.38629'}; time used = 6.779714107513428s
epoch 295: {'train_loss': '1.38629'}; time used = 6.588179349899292s
epoch 300: {'train_loss': '1.38629'}; time used = 6.72477650642395s
epoch 305: {'train_loss': '1.38629'}; time used = 6.469511270523071s
epoch 310: {'train_loss': '1.38629'}; time used = 6.459357500076294s
epoch 315: {'train_loss': '1.38629'}; time used = 6.673946142196655s
epoch 320: {'train_loss': '1.38629'}; time used = 6.795859336853027s
epoch 325: {'train_loss': '1.38629'}; time used = 6.664841651916504s
epoch 330: {'train_loss': '1.38629'}; time used = 6.684763431549072s
epoch 335: {'train_loss': '1.38629'}; time used = 9.899766445159912s
epoch 340: {'train_loss': '1.38629'}; time used = 7.582492113113403s
epoch 345: {'train_loss': '1.38629'}; time used = 6.629880428314209s
epoch 350: {'train_loss': '1.38629'}; time used = 6.567296504974365s
epoch 355: {'train_loss': '1.38629'}; time used = 6.896179437637329s
epoch 360: {'train_loss': '1.38629'}; time used = 10.651157855987549s
epoch 365: {'train_loss': '1.38629'}; time used = 6.643816947937012s
epoch 370: {'train_loss': '1.38629'}; time used = 6.857085943222046s
epoch 375: {'train_loss': '1.38629'}; time used = 6.554598093032837s
epoch 380: {'train_loss': '1.38629'}; time used = 6.568490028381348s
epoch 385: {'train_loss': '1.38629'}; time used = 6.574157476425171s
epoch 390: {'train_loss': '1.38629'}; time used = 6.557702541351318s
epoch 395: {'train_loss': '1.38629'}; time used = 6.681990146636963s
epoch 400: {'train_loss': '1.38629'}; time used = 6.681958198547363s
epoch 405: {'train_loss': '1.38629'}; time used = 6.860896587371826s
epoch 410: {'train_loss': '1.38629'}; time used = 6.593622922897339s
epoch 415: {'train_loss': '1.38629'}; time used = 6.621212482452393s
epoch 420: {'train_loss': '1.38629'}; time used = 6.595715761184692s
epoch 425: {'train_loss': '1.38629'}; time used = 6.491218090057373s
epoch 430: {'train_loss': '1.38629'}; time used = 6.613600969314575s
epoch 435: {'train_loss': '1.38629'}; time used = 6.527984619140625s
epoch 440: {'train_loss': '1.38629'}; time used = 8.327031373977661s
epoch 445: {'train_loss': '1.38629'}; time used = 7.522046327590942s
epoch 450: {'train_loss': '1.38629'}; time used = 6.627779960632324s
epoch 455: {'train_loss': '1.38629'}; time used = 6.683444976806641s
epoch 460: {'train_loss': '1.38629'}; time used = 6.854740381240845s
epoch 465: {'train_loss': '1.38629'}; time used = 6.703416585922241s
epoch 470: {'train_loss': '1.38629'}; time used = 6.7104644775390625s
epoch 475: {'train_loss': '1.38629'}; time used = 6.463679313659668s
epoch 480: {'train_loss': '1.38629'}; time used = 6.463592767715454s
epoch 485: {'train_loss': '1.38629'}; time used = 6.7060863971710205s
epoch 490: {'train_loss': '1.38629'}; time used = 6.873690366744995s
epoch 495: {'train_loss': '1.38629'}; time used = 6.904804468154907s
epoch 500: {'train_loss': '1.38629'}; time used = 6.683587551116943s
Finished training. Time used = 700.272262096405.
Training classifier using 80.00% nodes...
{'micro': 0.4633333333333333, 'macro': 0.4411917026697685, 'samples': 0.4633333333333333, 'weighted': 0.43508095158967536, 'accuracy': 0.4633333333333333}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.77934'}; time used = 1.3976778984069824s
epoch 10: {'train_loss': '2.77370'}; time used = 1.2156965732574463s
epoch 15: {'train_loss': '2.78450'}; time used = 1.4111344814300537s
epoch 20: {'train_loss': '2.78196'}; time used = 1.192112922668457s
epoch 25: {'train_loss': '2.77334'}; time used = 1.2010459899902344s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.100765466690063.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6346153846153846, 'samples': 0.6842105263157895, 'weighted': 0.6558704453441294, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.43377'}; time used = 5.131463050842285s
epoch 10: {'train_loss': '2.82810'}; time used = 4.985212087631226s
epoch 15: {'train_loss': '2.83169'}; time used = 4.883159637451172s
epoch 20: {'train_loss': '2.84284'}; time used = 5.036531209945679s
epoch 25: {'train_loss': '2.82812'}; time used = 5.182086944580078s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 45.48247456550598.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 252, in main
    res = task.evaluate(model, res, graph)  # evaluate
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/graph_classification.py", line 21, in evaluate
    return self._classify(dataset, res, 0)
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/graph_classification.py", line 34, in _classify
    return clf.train_and_evaluate(dataset, self.train_kwargs()['clf_ratio'], seed=seed)
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/classify.py", line 80, in train_and_evaluate
    self.train(X_train, Y_train, graph.labels()[1])
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/classify.py", line 50, in train
    self.clf.fit(X_train, Y)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/multiclass.py", line 216, in fit
    for i, column in enumerate(columns))
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 921, in __call__
    if self.dispatch_one_batch(iterator):
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 759, in dispatch_one_batch
    self._dispatch(tasks)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 716, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/_parallel_backends.py", line 182, in apply_async
    result = ImmediateResult(func)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/_parallel_backends.py", line 549, in __init__
    self.results = batch()
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 225, in __call__
    for func, args, kwargs in self.items]
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 225, in <listcomp>
    for func, args, kwargs in self.items]
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/multiclass.py", line 80, in _fit_binary
    estimator.fit(X, y)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py", line 2004, in fit
    accept_large_sparse=solver != 'liblinear')
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/utils/validation.py", line 719, in check_X_y
    estimator=estimator)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/utils/validation.py", line 542, in check_array
    allow_nan=force_all_finite == 'allow-nan')
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/utils/validation.py", line 56, in _assert_all_finite
    raise ValueError(msg_err.format(type_err, X.dtype))
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.40995'}; time used = 3.7222583293914795s
epoch 10: {'train_loss': '1.34769'}; time used = 3.539492607116699s
epoch 15: {'train_loss': '1.37109'}; time used = 2.0940299034118652s
epoch 20: {'train_loss': '1.44586'}; time used = 2.090833902359009s
epoch 25: {'train_loss': '1.37457'}; time used = 2.098679542541504s
epoch 30: {'train_loss': '1.33536'}; time used = 2.187771797180176s
epoch 35: {'train_loss': '1.34308'}; time used = 2.190655469894409s
epoch 40: {'train_loss': '0.67122'}; time used = 2.792541742324829s
epoch 45: {'train_loss': '0.00000'}; time used = 3.9232218265533447s
epoch 50: {'train_loss': '0.01676'}; time used = 3.8798422813415527s
epoch 55: {'train_loss': '0.00008'}; time used = 1.9939076900482178s
epoch 60: {'train_loss': '0.00000'}; time used = 2.0424623489379883s
epoch 65: {'train_loss': '0.00000'}; time used = 1.908607006072998s
epoch 70: {'train_loss': '0.00000'}; time used = 1.962357759475708s
epoch 75: {'train_loss': '0.00000'}; time used = 2.081522226333618s
epoch 80: {'train_loss': '0.00000'}; time used = 1.91396164894104s
epoch 85: {'train_loss': '0.00000'}; time used = 1.950312852859497s
epoch 90: {'train_loss': '0.00000'}; time used = 1.9352993965148926s
epoch 95: {'train_loss': '0.00000'}; time used = 1.9437220096588135s
epoch 100: {'train_loss': 'nan'}; time used = 1.9589807987213135s
epoch 105: {'train_loss': 'nan'}; time used = 1.9132270812988281s
epoch 110: {'train_loss': 'nan'}; time used = 1.898348093032837s
epoch 115: {'train_loss': 'nan'}; time used = 1.9419302940368652s
epoch 120: {'train_loss': 'nan'}; time used = 1.9972848892211914s
epoch 125: {'train_loss': 'nan'}; time used = 1.861769199371338s
epoch 130: {'train_loss': 'nan'}; time used = 3.0300230979919434s
epoch 135: {'train_loss': 'nan'}; time used = 1.8849518299102783s
epoch 140: {'train_loss': 'nan'}; time used = 1.8695833683013916s
epoch 145: {'train_loss': 'nan'}; time used = 1.949554443359375s
epoch 150: {'train_loss': 'nan'}; time used = 1.8854479789733887s
epoch 155: {'train_loss': 'nan'}; time used = 1.9408445358276367s
epoch 160: {'train_loss': 'nan'}; time used = 1.9085838794708252s
epoch 165: {'train_loss': 'nan'}; time used = 1.8753669261932373s
epoch 170: {'train_loss': 'nan'}; time used = 2.264958620071411s
epoch 175: {'train_loss': 'nan'}; time used = 2.357593059539795s
epoch 180: {'train_loss': 'nan'}; time used = 4.11991548538208s
epoch 185: {'train_loss': 'nan'}; time used = 2.0322203636169434s
epoch 190: {'train_loss': 'nan'}; time used = 2.0067338943481445s
epoch 195: {'train_loss': 'nan'}; time used = 1.8843088150024414s
epoch 200: {'train_loss': 'nan'}; time used = 2.2750754356384277s
epoch 205: {'train_loss': 'nan'}; time used = 2.096165895462036s
epoch 210: {'train_loss': 'nan'}; time used = 2.8231232166290283s
epoch 215: {'train_loss': 'nan'}; time used = 1.940758228302002s
epoch 220: {'train_loss': 'nan'}; time used = 1.9768717288970947s
epoch 225: {'train_loss': 'nan'}; time used = 2.000232696533203s
epoch 230: {'train_loss': 'nan'}; time used = 1.902820348739624s
epoch 235: {'train_loss': 'nan'}; time used = 2.7084388732910156s
epoch 240: {'train_loss': 'nan'}; time used = 3.541574001312256s
epoch 245: {'train_loss': 'nan'}; time used = 3.7851083278656006s
epoch 250: {'train_loss': 'nan'}; time used = 2.942443370819092s
epoch 255: {'train_loss': 'nan'}; time used = 2.0849523544311523s
epoch 260: {'train_loss': 'nan'}; time used = 2.014399528503418s
epoch 265: {'train_loss': 'nan'}; time used = 1.8705508708953857s
epoch 270: {'train_loss': 'nan'}; time used = 1.8534150123596191s
epoch 275: {'train_loss': 'nan'}; time used = 1.92264723777771s
epoch 280: {'train_loss': 'nan'}; time used = 1.8983886241912842s
epoch 285: {'train_loss': 'nan'}; time used = 2.013517379760742s
epoch 290: {'train_loss': 'nan'}; time used = 2.763326644897461s
epoch 295: {'train_loss': 'nan'}; time used = 2.3138747215270996s
epoch 300: {'train_loss': 'nan'}; time used = 2.3397340774536133s
epoch 305: {'train_loss': 'nan'}; time used = 2.185563802719116s
epoch 310: {'train_loss': 'nan'}; time used = 2.115020751953125s
epoch 315: {'train_loss': 'nan'}; time used = 1.9735524654388428s
epoch 320: {'train_loss': 'nan'}; time used = 1.9796733856201172s
epoch 325: {'train_loss': 'nan'}; time used = 1.910114049911499s
epoch 330: {'train_loss': 'nan'}; time used = 2.014369010925293s
epoch 335: {'train_loss': 'nan'}; time used = 1.9840588569641113s
epoch 340: {'train_loss': 'nan'}; time used = 1.9001996517181396s
epoch 345: {'train_loss': 'nan'}; time used = 1.891385793685913s
epoch 350: {'train_loss': 'nan'}; time used = 2.055084228515625s
epoch 355: {'train_loss': 'nan'}; time used = 2.0485117435455322s
epoch 360: {'train_loss': 'nan'}; time used = 1.9760112762451172s
epoch 365: {'train_loss': 'nan'}; time used = 1.992537260055542s
epoch 370: {'train_loss': 'nan'}; time used = 1.9736261367797852s
epoch 375: {'train_loss': 'nan'}; time used = 1.8766937255859375s
epoch 380: {'train_loss': 'nan'}; time used = 1.9640305042266846s
epoch 385: {'train_loss': 'nan'}; time used = 2.051706314086914s
epoch 390: {'train_loss': 'nan'}; time used = 1.9657325744628906s
epoch 395: {'train_loss': 'nan'}; time used = 1.977940320968628s
epoch 400: {'train_loss': 'nan'}; time used = 1.912473201751709s
epoch 405: {'train_loss': 'nan'}; time used = 1.9149668216705322s
epoch 410: {'train_loss': 'nan'}; time used = 2.0242936611175537s
epoch 415: {'train_loss': 'nan'}; time used = 2.27577805519104s
epoch 420: {'train_loss': 'nan'}; time used = 2.377486228942871s
epoch 425: {'train_loss': 'nan'}; time used = 2.40421724319458s
epoch 430: {'train_loss': 'nan'}; time used = 2.399399995803833s
epoch 435: {'train_loss': 'nan'}; time used = 2.3888566493988037s
epoch 440: {'train_loss': 'nan'}; time used = 2.4363512992858887s
epoch 445: {'train_loss': 'nan'}; time used = 1.9492769241333008s
epoch 450: {'train_loss': 'nan'}; time used = 1.8890058994293213s
epoch 455: {'train_loss': 'nan'}; time used = 2.165231704711914s
epoch 460: {'train_loss': 'nan'}; time used = 1.9036738872528076s
epoch 465: {'train_loss': 'nan'}; time used = 2.2106218338012695s
epoch 470: {'train_loss': 'nan'}; time used = 1.961512565612793s
epoch 475: {'train_loss': 'nan'}; time used = 1.8898277282714844s
epoch 480: {'train_loss': 'nan'}; time used = 1.8728249073028564s
epoch 485: {'train_loss': 'nan'}; time used = 1.8643429279327393s
epoch 490: {'train_loss': 'nan'}; time used = 1.8721153736114502s
epoch 495: {'train_loss': 'nan'}; time used = 1.9581823348999023s
epoch 500: {'train_loss': 'nan'}; time used = 1.8864805698394775s
Finished training. Time used = 231.069682598114.
Training classifier using 80.00% nodes...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.35725'}; time used = 7.377444267272949s
epoch 10: {'train_loss': '1.37777'}; time used = 7.294243335723877s
epoch 15: {'train_loss': '1.31525'}; time used = 11.210683584213257s
epoch 20: {'train_loss': '1.25462'}; time used = 6.782874822616577s
epoch 25: {'train_loss': '1.16974'}; time used = 6.825761556625366s
epoch 30: {'train_loss': '1.28651'}; time used = 6.567718744277954s
epoch 35: {'train_loss': '1.13915'}; time used = 6.348633527755737s
epoch 40: {'train_loss': '1.15673'}; time used = 6.521794557571411s
epoch 45: {'train_loss': '1.12409'}; time used = 6.537123918533325s
epoch 50: {'train_loss': '1.09297'}; time used = 6.441413402557373s
epoch 55: {'train_loss': '1.28650'}; time used = 6.457787036895752s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 111.65101957321167.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.48326715373031975, 'samples': 0.5066666666666667, 'weighted': 0.4775108609727149, 'accuracy': 0.5066666666666667}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.15383'}; time used = 1.7201929092407227s
epoch 10: {'train_loss': '0.45288'}; time used = 1.4820618629455566s
epoch 15: {'train_loss': '0.22148'}; time used = 1.6634681224822998s
epoch 20: {'train_loss': '0.31599'}; time used = 1.5215415954589844s
epoch 25: {'train_loss': '0.86477'}; time used = 1.5742111206054688s
epoch 30: {'train_loss': '0.28723'}; time used = 1.4737935066223145s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.787311315536499.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5606960950764007, 'samples': 0.5652173913043478, 'weighted': 0.5639255923820773, 'accuracy': 0.5652173913043478}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38242'}; time used = 2.4215376377105713s
epoch 10: {'train_loss': '1.32953'}; time used = 1.7432458400726318s
epoch 15: {'train_loss': '1.31482'}; time used = 1.7902042865753174s
epoch 20: {'train_loss': '1.41776'}; time used = 1.7479887008666992s
epoch 25: {'train_loss': '1.29556'}; time used = 1.7977514266967773s
epoch 30: {'train_loss': '1.10529'}; time used = 2.1072630882263184s
epoch 35: {'train_loss': '1.24654'}; time used = 2.045306444168091s
epoch 40: {'train_loss': '1.15609'}; time used = 1.9062979221343994s
epoch 45: {'train_loss': '1.31793'}; time used = 1.732618808746338s
epoch 50: {'train_loss': '1.08770'}; time used = 1.724332332611084s
epoch 55: {'train_loss': '1.04631'}; time used = 1.7267036437988281s
epoch 60: {'train_loss': '1.22784'}; time used = 1.8167486190795898s
epoch 65: {'train_loss': '1.24786'}; time used = 1.7633047103881836s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.472678184509277.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.38432'}; time used = 3.3683621883392334s
epoch 10: {'train_loss': '1.34796'}; time used = 2.5097875595092773s
epoch 15: {'train_loss': '1.38288'}; time used = 2.5986275672912598s
epoch 20: {'train_loss': '1.44774'}; time used = 2.6394853591918945s
epoch 25: {'train_loss': '1.42706'}; time used = 2.56112003326416s
epoch 30: {'train_loss': '1.39426'}; time used = 3.9490060806274414s
epoch 35: {'train_loss': '1.37693'}; time used = 3.9825239181518555s
epoch 40: {'train_loss': '1.35806'}; time used = 3.9486947059631348s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.3278865814209.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5836206896551723, 'samples': 0.5942028985507246, 'weighted': 0.588430784607696, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79972'}; time used = 2.536033868789673s
epoch 10: {'train_loss': '2.76849'}; time used = 2.450194835662842s
epoch 15: {'train_loss': '2.75878'}; time used = 2.3296966552734375s
epoch 20: {'train_loss': '2.73918'}; time used = 2.306323528289795s
epoch 25: {'train_loss': '2.71626'}; time used = 2.3554372787475586s
epoch 30: {'train_loss': '2.68554'}; time used = 2.279721736907959s
epoch 35: {'train_loss': '2.64642'}; time used = 2.3042232990264893s
epoch 40: {'train_loss': '2.64693'}; time used = 2.2938435077667236s
epoch 45: {'train_loss': '2.61682'}; time used = 2.3135931491851807s
epoch 50: {'train_loss': '2.57892'}; time used = 2.3126347064971924s
epoch 55: {'train_loss': '2.53468'}; time used = 2.400395393371582s
epoch 60: {'train_loss': '2.52294'}; time used = 2.351292848587036s
epoch 65: {'train_loss': '2.46268'}; time used = 2.3481287956237793s
epoch 70: {'train_loss': '2.44901'}; time used = 2.3311548233032227s
epoch 75: {'train_loss': '2.43417'}; time used = 3.0567739009857178s
epoch 80: {'train_loss': '2.40934'}; time used = 2.6535260677337646s
epoch 85: {'train_loss': '2.42718'}; time used = 2.4288413524627686s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.22721338272095.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5314348302300109, 'samples': 0.5507246376811594, 'weighted': 0.5383240471768497, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.85346'}; time used = 8.630680322647095s
epoch 10: {'train_loss': '2.78018'}; time used = 7.64525032043457s
epoch 15: {'train_loss': '2.77267'}; time used = 7.189350605010986s
epoch 20: {'train_loss': '2.77843'}; time used = 7.281449556350708s
epoch 25: {'train_loss': '2.76727'}; time used = 7.537305116653442s
epoch 30: {'train_loss': '2.76123'}; time used = 7.1612465381622314s
epoch 35: {'train_loss': '2.75106'}; time used = 7.377148389816284s
epoch 40: {'train_loss': '2.73598'}; time used = 6.998695611953735s
epoch 45: {'train_loss': '2.72249'}; time used = 7.194455623626709s
epoch 50: {'train_loss': '2.71527'}; time used = 7.056026458740234s
epoch 55: {'train_loss': '2.71175'}; time used = 7.342324256896973s
epoch 60: {'train_loss': '2.70872'}; time used = 7.22908616065979s
epoch 65: {'train_loss': '2.69660'}; time used = 7.121563673019409s
epoch 70: {'train_loss': '2.70325'}; time used = 6.950972318649292s
epoch 75: {'train_loss': '2.69000'}; time used = 9.378844976425171s
epoch 80: {'train_loss': '2.69630'}; time used = 8.213525295257568s
epoch 85: {'train_loss': '2.69053'}; time used = 10.215415239334106s
epoch 90: {'train_loss': '2.68631'}; time used = 8.10302734375s
epoch 95: {'train_loss': '2.67863'}; time used = 10.795758247375488s
epoch 100: {'train_loss': '2.71292'}; time used = 10.567277669906616s
epoch 105: {'train_loss': '2.70127'}; time used = 8.433941841125488s
epoch 110: {'train_loss': '2.69723'}; time used = 7.076232671737671s
epoch 115: {'train_loss': '2.68532'}; time used = 7.266983985900879s
epoch 120: {'train_loss': '2.68168'}; time used = 7.025155067443848s
epoch 125: {'train_loss': '2.75697'}; time used = 7.313355922698975s
epoch 130: {'train_loss': '2.68802'}; time used = 7.104628562927246s
epoch 135: {'train_loss': '2.69000'}; time used = 6.992748737335205s
epoch 140: {'train_loss': '2.67043'}; time used = 6.979503154754639s
epoch 145: {'train_loss': '2.67993'}; time used = 7.088597536087036s
epoch 150: {'train_loss': '2.67609'}; time used = 6.971781969070435s
epoch 155: {'train_loss': '2.67539'}; time used = 6.960586786270142s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 277.79478120803833.
Training classifier using 80.00% nodes...
{'micro': 0.46, 'macro': 0.4390840125281325, 'samples': 0.46, 'weighted': 0.43385851201983816, 'accuracy': 0.46}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 27.19 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.40406'}; time used = 1.8165159225463867s
epoch 10: {'train_loss': '1.23037'}; time used = 1.9618158340454102s
epoch 15: {'train_loss': '0.82081'}; time used = 2.0035579204559326s
epoch 20: {'train_loss': '0.84504'}; time used = 2.090801239013672s
epoch 25: {'train_loss': '0.32495'}; time used = 2.04892635345459s
epoch 30: {'train_loss': '0.20406'}; time used = 2.083012104034424s
epoch 35: {'train_loss': '0.74298'}; time used = 1.8633379936218262s
epoch 40: {'train_loss': '0.49227'}; time used = 1.7648189067840576s
epoch 45: {'train_loss': '0.38853'}; time used = 2.0842833518981934s
epoch 50: {'train_loss': '0.60713'}; time used = 2.360799551010132s
epoch 55: {'train_loss': '0.13324'}; time used = 2.189620018005371s
epoch 60: {'train_loss': '0.13913'}; time used = 1.9801559448242188s
epoch 65: {'train_loss': '0.14055'}; time used = 1.7143816947937012s
epoch 70: {'train_loss': '0.07747'}; time used = 1.722161054611206s
epoch 75: {'train_loss': '0.02589'}; time used = 1.7940089702606201s
epoch 80: {'train_loss': '0.02342'}; time used = 1.7000160217285156s
epoch 85: {'train_loss': '0.55516'}; time used = 1.7304317951202393s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.54347014427185.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37738'}; time used = 1.8087520599365234s
epoch 10: {'train_loss': '1.30822'}; time used = 2.074284553527832s
epoch 15: {'train_loss': '1.26561'}; time used = 1.9315106868743896s
epoch 20: {'train_loss': '1.36247'}; time used = 1.776752233505249s
epoch 25: {'train_loss': '1.24075'}; time used = 1.811617374420166s
epoch 30: {'train_loss': '1.15205'}; time used = 1.835390329360962s
epoch 35: {'train_loss': '1.24894'}; time used = 1.9186067581176758s
epoch 40: {'train_loss': '1.13163'}; time used = 1.8484916687011719s
epoch 45: {'train_loss': '1.17289'}; time used = 1.7234687805175781s
epoch 50: {'train_loss': '1.10107'}; time used = 1.8720898628234863s
epoch 55: {'train_loss': '1.04574'}; time used = 1.8750452995300293s
epoch 60: {'train_loss': '1.10278'}; time used = 1.8790016174316406s
epoch 65: {'train_loss': '1.23764'}; time used = 1.8736011981964111s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.54427146911621.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5836206896551723, 'samples': 0.5942028985507246, 'weighted': 0.588430784607696, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.84084'}; time used = 5.4872190952301025s
epoch 10: {'train_loss': '2.77302'}; time used = 3.316108465194702s
epoch 15: {'train_loss': '2.79580'}; time used = 2.4605154991149902s
epoch 20: {'train_loss': '2.78337'}; time used = 2.5805578231811523s
epoch 25: {'train_loss': '2.77323'}; time used = 2.5190794467926025s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.587907552719116.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5801217038539555, 'samples': 0.6086956521739131, 'weighted': 0.5880589117206103, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.96246'}; time used = 1.7639544010162354s
epoch 10: {'train_loss': '2.85744'}; time used = 1.7367148399353027s
epoch 15: {'train_loss': '2.77341'}; time used = 1.764653205871582s
epoch 20: {'train_loss': '2.76951'}; time used = 1.8110802173614502s
epoch 25: {'train_loss': '2.75747'}; time used = 1.8892598152160645s
epoch 30: {'train_loss': '2.74761'}; time used = 1.968571424484253s
epoch 35: {'train_loss': '2.74271'}; time used = 2.0119593143463135s
epoch 40: {'train_loss': '2.72870'}; time used = 1.8092873096466064s
epoch 45: {'train_loss': '2.71829'}; time used = 3.761704444885254s
epoch 50: {'train_loss': '2.70040'}; time used = 3.839322566986084s
epoch 55: {'train_loss': '2.70087'}; time used = 3.027935266494751s
epoch 60: {'train_loss': '2.68482'}; time used = 2.0127458572387695s
epoch 65: {'train_loss': '2.68175'}; time used = 1.9931385517120361s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.97007918357849.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.6133620689655173, 'samples': 0.6231884057971014, 'weighted': 0.6178285857071465, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.20 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.67315'}; time used = 1.6367132663726807s
epoch 10: {'train_loss': '0.12654'}; time used = 1.7530951499938965s
epoch 15: {'train_loss': '0.03267'}; time used = 1.6730029582977295s
epoch 20: {'train_loss': '0.07233'}; time used = 1.668189287185669s
epoch 25: {'train_loss': '0.06473'}; time used = 1.7753307819366455s
epoch 30: {'train_loss': '0.03461'}; time used = 1.6581954956054688s
epoch 35: {'train_loss': '0.04897'}; time used = 1.6950569152832031s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.976118564605713.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.42761573454642754, 'samples': 0.5507246376811594, 'weighted': 0.44685150066122936, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.51918'}; time used = 1.0587425231933594s
epoch 10: {'train_loss': '0.41502'}; time used = 1.0774712562561035s
epoch 15: {'train_loss': '0.28380'}; time used = 0.9889507293701172s
epoch 20: {'train_loss': '0.16241'}; time used = 1.033743143081665s
epoch 25: {'train_loss': '0.21499'}; time used = 0.9732189178466797s
epoch 30: {'train_loss': '0.12831'}; time used = 1.9298083782196045s
epoch 35: {'train_loss': '0.14849'}; time used = 1.903761863708496s
epoch 40: {'train_loss': '0.18181'}; time used = 1.9463880062103271s
epoch 45: {'train_loss': '0.15339'}; time used = 1.8805336952209473s
epoch 50: {'train_loss': '0.19612'}; time used = 1.8202509880065918s
epoch 55: {'train_loss': '0.14492'}; time used = 1.0998849868774414s
epoch 60: {'train_loss': '0.11716'}; time used = 1.157336950302124s
epoch 65: {'train_loss': '0.15732'}; time used = 0.9807593822479248s
epoch 70: {'train_loss': '0.09023'}; time used = 0.9663503170013428s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.37872576713562.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.76798'}; time used = 1.8065032958984375s
epoch 10: {'train_loss': '2.74352'}; time used = 1.8688325881958008s
epoch 15: {'train_loss': '2.72358'}; time used = 1.9241583347320557s
epoch 20: {'train_loss': '2.70463'}; time used = 1.9406042098999023s
epoch 25: {'train_loss': '2.67950'}; time used = 1.801530361175537s
epoch 30: {'train_loss': '2.65594'}; time used = 1.8796961307525635s
epoch 35: {'train_loss': '2.64243'}; time used = 1.6982195377349854s
epoch 40: {'train_loss': '2.62605'}; time used = 1.9009358882904053s
epoch 45: {'train_loss': '2.59891'}; time used = 1.933506965637207s
epoch 50: {'train_loss': '2.56859'}; time used = 1.8835272789001465s
epoch 55: {'train_loss': '2.55141'}; time used = 1.8735947608947754s
epoch 60: {'train_loss': '2.52933'}; time used = 1.8203651905059814s
epoch 65: {'train_loss': '2.48896'}; time used = 1.802255392074585s
epoch 70: {'train_loss': '2.44349'}; time used = 1.7128398418426514s
epoch 75: {'train_loss': '2.41670'}; time used = 1.7106146812438965s
epoch 80: {'train_loss': '2.40519'}; time used = 2.115225076675415s
epoch 85: {'train_loss': '2.41029'}; time used = 1.7151641845703125s
epoch 90: {'train_loss': '2.40819'}; time used = 1.69541335105896s
epoch 95: {'train_loss': '2.40720'}; time used = 1.771733045578003s
epoch 100: {'train_loss': '2.38248'}; time used = 1.7072765827178955s
epoch 105: {'train_loss': '2.38719'}; time used = 1.7678601741790771s
epoch 110: {'train_loss': '2.37019'}; time used = 1.6884326934814453s
epoch 115: {'train_loss': '2.37295'}; time used = 1.675225019454956s
epoch 120: {'train_loss': '2.36601'}; time used = 1.6694200038909912s
epoch 125: {'train_loss': '2.35467'}; time used = 1.6758482456207275s
epoch 130: {'train_loss': '2.37341'}; time used = 1.683211088180542s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 49.77208232879639.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.491578947368421, 'samples': 0.5942028985507246, 'weighted': 0.5081311975591152, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.77968'}; time used = 1.727187156677246s
epoch 10: {'train_loss': '2.75108'}; time used = 1.6523942947387695s
epoch 15: {'train_loss': '2.75131'}; time used = 1.6772899627685547s
epoch 20: {'train_loss': '2.74829'}; time used = 1.6492676734924316s
epoch 25: {'train_loss': '2.73591'}; time used = 1.763139009475708s
epoch 30: {'train_loss': '2.71795'}; time used = 1.6490387916564941s
epoch 35: {'train_loss': '2.70556'}; time used = 1.6704282760620117s
epoch 40: {'train_loss': '2.67027'}; time used = 1.6597051620483398s
epoch 45: {'train_loss': '2.61460'}; time used = 2.3383002281188965s
epoch 50: {'train_loss': '2.54844'}; time used = 2.7842259407043457s
epoch 55: {'train_loss': '2.49521'}; time used = 1.7346000671386719s
epoch 60: {'train_loss': '2.49229'}; time used = 1.6883494853973389s
epoch 65: {'train_loss': '2.43566'}; time used = 2.2058916091918945s
epoch 70: {'train_loss': '2.42611'}; time used = 1.9039161205291748s
epoch 75: {'train_loss': '2.41895'}; time used = 1.712329387664795s
epoch 80: {'train_loss': '2.39812'}; time used = 1.8550992012023926s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.811723470687866.
Training classifier using 80.00% nodes...
{'micro': 0.6811594202898551, 'macro': 0.6805555555555556, 'samples': 0.6811594202898551, 'weighted': 0.6815619967793881, 'accuracy': 0.6811594202898551}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36175'}; time used = 1.806501865386963s
epoch 10: {'train_loss': '1.28706'}; time used = 1.7400972843170166s
epoch 15: {'train_loss': '1.17901'}; time used = 1.6771464347839355s
epoch 20: {'train_loss': '1.21265'}; time used = 1.8251914978027344s
epoch 25: {'train_loss': '1.10668'}; time used = 1.8028719425201416s
epoch 30: {'train_loss': '1.05247'}; time used = 1.6108651161193848s
epoch 35: {'train_loss': '1.10929'}; time used = 1.6354639530181885s
epoch 40: {'train_loss': '0.87443'}; time used = 1.6156065464019775s
epoch 45: {'train_loss': '0.80625'}; time used = 1.6395156383514404s
epoch 50: {'train_loss': '0.68032'}; time used = 1.701608657836914s
epoch 55: {'train_loss': '0.59843'}; time used = 1.6157197952270508s
epoch 60: {'train_loss': '0.70606'}; time used = 1.616330862045288s
epoch 65: {'train_loss': '0.74626'}; time used = 1.7302229404449463s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.772387742996216.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5728044026599404, 'samples': 0.6086956521739131, 'weighted': 0.5817772150384336, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39557'}; time used = 1.0925242900848389s
epoch 10: {'train_loss': '1.40233'}; time used = 0.9939305782318115s
epoch 15: {'train_loss': '1.15832'}; time used = 0.9997298717498779s
epoch 20: {'train_loss': '1.43581'}; time used = 0.9790868759155273s
epoch 25: {'train_loss': '0.95048'}; time used = 1.0010318756103516s
epoch 30: {'train_loss': '0.78396'}; time used = 0.9833920001983643s
epoch 35: {'train_loss': '0.94525'}; time used = 1.0181362628936768s
epoch 40: {'train_loss': '0.65789'}; time used = 0.9999735355377197s
epoch 45: {'train_loss': '0.96162'}; time used = 0.9822566509246826s
epoch 50: {'train_loss': '0.94952'}; time used = 0.9772813320159912s
epoch 55: {'train_loss': '0.88327'}; time used = 1.0009496212005615s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.393840312957764.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6761363636363636, 'samples': 0.6842105263157895, 'weighted': 0.6842105263157895, 'accuracy': 0.6842105263157895}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.20815'}; time used = 1.1577403545379639s
epoch 10: {'train_loss': '0.12148'}; time used = 0.9082803726196289s
epoch 15: {'train_loss': '0.08466'}; time used = 0.8689756393432617s
epoch 20: {'train_loss': '0.11762'}; time used = 0.8530235290527344s
epoch 25: {'train_loss': '0.14389'}; time used = 1.0805025100708008s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.301787376403809.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.731764705882353, 'samples': 0.7631578947368421, 'weighted': 0.7462538699690403, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.25 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.30284'}; time used = 1.717902660369873s
epoch 10: {'train_loss': '1.13240'}; time used = 1.5423011779785156s
epoch 15: {'train_loss': '1.12517'}; time used = 1.5459520816802979s
epoch 20: {'train_loss': '1.00317'}; time used = 1.6940877437591553s
epoch 25: {'train_loss': '0.95582'}; time used = 1.6130073070526123s
epoch 30: {'train_loss': '0.90895'}; time used = 1.6268539428710938s
epoch 35: {'train_loss': '0.88641'}; time used = 1.6047658920288086s
epoch 40: {'train_loss': '0.83676'}; time used = 1.5521912574768066s
epoch 45: {'train_loss': '0.83432'}; time used = 1.573629379272461s
epoch 50: {'train_loss': '0.73790'}; time used = 1.5663018226623535s
epoch 55: {'train_loss': '0.72119'}; time used = 1.6624174118041992s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.08343815803528.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5108695652173914, 'samples': 0.5652173913043478, 'weighted': 0.5226843100189036, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36409'}; time used = 1.8846042156219482s
epoch 10: {'train_loss': '1.29635'}; time used = 3.7091777324676514s
epoch 15: {'train_loss': '1.23216'}; time used = 3.585171937942505s
epoch 20: {'train_loss': '1.30168'}; time used = 1.8255858421325684s
epoch 25: {'train_loss': '1.02189'}; time used = 1.82045316696167s
epoch 30: {'train_loss': '0.94610'}; time used = 1.8922617435455322s
epoch 35: {'train_loss': '0.79437'}; time used = 1.869316577911377s
epoch 40: {'train_loss': '0.71195'}; time used = 1.746062994003296s
epoch 45: {'train_loss': '0.71085'}; time used = 1.836474895477295s
epoch 50: {'train_loss': '0.65028'}; time used = 1.7273013591766357s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.194756269454956.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5410856039476507, 'samples': 0.5507246376811594, 'weighted': 0.545905120814405, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.77968'}; time used = 1.738713264465332s
epoch 10: {'train_loss': '2.75108'}; time used = 1.694047451019287s
epoch 15: {'train_loss': '2.75131'}; time used = 1.680680274963379s
epoch 20: {'train_loss': '2.74829'}; time used = 1.6995244026184082s
epoch 25: {'train_loss': '2.73591'}; time used = 1.77091383934021s
epoch 30: {'train_loss': '2.71795'}; time used = 1.7671079635620117s
epoch 35: {'train_loss': '2.70556'}; time used = 1.61067795753479s
epoch 40: {'train_loss': '2.67027'}; time used = 1.6253631114959717s
epoch 45: {'train_loss': '2.61460'}; time used = 1.9563839435577393s
epoch 50: {'train_loss': '2.54844'}; time used = 1.7494237422943115s
epoch 55: {'train_loss': '2.49521'}; time used = 2.3037383556365967s
epoch 60: {'train_loss': '2.49229'}; time used = 1.6046757698059082s
epoch 65: {'train_loss': '2.43566'}; time used = 1.681872844696045s
epoch 70: {'train_loss': '2.42611'}; time used = 1.6099460124969482s
epoch 75: {'train_loss': '2.41895'}; time used = 1.614856243133545s
epoch 80: {'train_loss': '2.39812'}; time used = 1.832472324371338s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.0117449760437.
Training classifier using 80.00% nodes...
{'micro': 0.6811594202898551, 'macro': 0.6805555555555556, 'samples': 0.6811594202898551, 'weighted': 0.6815619967793881, 'accuracy': 0.6811594202898551}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79135'}; time used = 1.902885913848877s
epoch 10: {'train_loss': '2.77129'}; time used = 1.6588435173034668s
epoch 15: {'train_loss': '2.76856'}; time used = 1.6657376289367676s
epoch 20: {'train_loss': '2.76222'}; time used = 1.7401297092437744s
epoch 25: {'train_loss': '2.75809'}; time used = 1.8177969455718994s
epoch 30: {'train_loss': '2.75456'}; time used = 1.8280894756317139s
epoch 35: {'train_loss': '2.74440'}; time used = 1.9671945571899414s
epoch 40: {'train_loss': '2.74455'}; time used = 1.7087714672088623s
epoch 45: {'train_loss': '2.72468'}; time used = 1.6871495246887207s
epoch 50: {'train_loss': '2.69889'}; time used = 2.0325472354888916s
epoch 55: {'train_loss': '2.67587'}; time used = 1.8958313465118408s
epoch 60: {'train_loss': '2.63799'}; time used = 2.6652443408966064s
epoch 65: {'train_loss': '2.63879'}; time used = 2.194878578186035s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.925876140594482.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5765079365079364, 'samples': 0.5797101449275363, 'weighted': 0.5791764435242696, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36045'}; time used = 2.372894763946533s
epoch 10: {'train_loss': '1.23285'}; time used = 2.1627962589263916s
epoch 15: {'train_loss': '1.11361'}; time used = 2.1589250564575195s
epoch 20: {'train_loss': '1.26058'}; time used = 2.2001662254333496s
epoch 25: {'train_loss': '1.08184'}; time used = 2.322327136993408s
epoch 30: {'train_loss': '1.03285'}; time used = 2.3053367137908936s
epoch 35: {'train_loss': '0.94203'}; time used = 1.7086000442504883s
epoch 40: {'train_loss': '0.79145'}; time used = 1.8821995258331299s
epoch 45: {'train_loss': '0.78769'}; time used = 1.7130749225616455s
epoch 50: {'train_loss': '0.77549'}; time used = 1.7864978313446045s
epoch 55: {'train_loss': '0.63320'}; time used = 1.994687795639038s
epoch 60: {'train_loss': '0.71099'}; time used = 1.7902038097381592s
epoch 65: {'train_loss': '0.79526'}; time used = 1.7519402503967285s
epoch 70: {'train_loss': '1.81037'}; time used = 1.7229454517364502s
epoch 75: {'train_loss': '0.60349'}; time used = 1.7929980754852295s
epoch 80: {'train_loss': '0.55687'}; time used = 1.7357280254364014s
epoch 85: {'train_loss': '0.69630'}; time used = 1.755030632019043s
epoch 90: {'train_loss': '0.73322'}; time used = 1.707573652267456s
epoch 95: {'train_loss': '0.42088'}; time used = 1.7138707637786865s
epoch 100: {'train_loss': '0.56995'}; time used = 1.779067039489746s
epoch 105: {'train_loss': '0.26675'}; time used = 1.6948208808898926s
epoch 110: {'train_loss': '0.39174'}; time used = 1.713630199432373s
epoch 115: {'train_loss': '0.37782'}; time used = 1.7039382457733154s
epoch 120: {'train_loss': '0.23357'}; time used = 1.6938741207122803s
epoch 125: {'train_loss': '0.13488'}; time used = 1.709155559539795s
epoch 130: {'train_loss': '0.28278'}; time used = 1.7589457035064697s
epoch 135: {'train_loss': '0.09571'}; time used = 1.7203397750854492s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 55.98156929016113.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4866071428571428, 'samples': 0.5652173913043478, 'weighted': 0.5011645962732919, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.23521'}; time used = 1.7819583415985107s
epoch 10: {'train_loss': '1.15595'}; time used = 1.8081059455871582s
epoch 15: {'train_loss': '1.03288'}; time used = 1.6966407299041748s
epoch 20: {'train_loss': '0.91302'}; time used = 1.7888562679290771s
epoch 25: {'train_loss': '0.84340'}; time used = 1.7109596729278564s
epoch 30: {'train_loss': '0.77937'}; time used = 1.6302149295806885s
epoch 35: {'train_loss': '0.67980'}; time used = 1.6504242420196533s
epoch 40: {'train_loss': '0.46720'}; time used = 1.6341369152069092s
epoch 45: {'train_loss': '0.29688'}; time used = 1.6415722370147705s
epoch 50: {'train_loss': '0.26742'}; time used = 1.6300415992736816s
epoch 55: {'train_loss': '0.23546'}; time used = 1.7908790111541748s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.011683464050293.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5434782608695652, 'samples': 0.5942028985507246, 'weighted': 0.5545053560176434, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.96185'}; time used = 1.304673194885254s
epoch 10: {'train_loss': '2.81142'}; time used = 1.139308214187622s
epoch 15: {'train_loss': '2.79720'}; time used = 1.1610569953918457s
epoch 20: {'train_loss': '2.73455'}; time used = 1.1189641952514648s
epoch 25: {'train_loss': '2.61879'}; time used = 1.165403127670288s
epoch 30: {'train_loss': '2.43475'}; time used = 1.1279594898223877s
epoch 35: {'train_loss': '2.29530'}; time used = 1.1428120136260986s
epoch 40: {'train_loss': '2.19789'}; time used = 1.1161613464355469s
epoch 45: {'train_loss': '2.20709'}; time used = 1.1337523460388184s
epoch 50: {'train_loss': '2.22096'}; time used = 1.1253952980041504s
epoch 55: {'train_loss': '2.19927'}; time used = 1.1310820579528809s
epoch 60: {'train_loss': '2.16415'}; time used = 1.2487165927886963s
epoch 65: {'train_loss': '2.12828'}; time used = 1.139674186706543s
epoch 70: {'train_loss': '2.15821'}; time used = 1.1798906326293945s
epoch 75: {'train_loss': '2.06762'}; time used = 1.173658847808838s
epoch 80: {'train_loss': '2.08614'}; time used = 1.1592152118682861s
epoch 85: {'train_loss': '2.07676'}; time used = 1.1639881134033203s
epoch 90: {'train_loss': '2.14400'}; time used = 1.290184497833252s
epoch 95: {'train_loss': '2.09467'}; time used = 1.1553387641906738s
epoch 100: {'train_loss': '2.05859'}; time used = 1.1396701335906982s
epoch 105: {'train_loss': '2.04557'}; time used = 1.2034144401550293s
epoch 110: {'train_loss': '2.03021'}; time used = 1.1341841220855713s
epoch 115: {'train_loss': '1.99752'}; time used = 1.125187873840332s
epoch 120: {'train_loss': '1.98938'}; time used = 1.210310459136963s
epoch 125: {'train_loss': '2.09628'}; time used = 1.1494967937469482s
epoch 130: {'train_loss': '1.99079'}; time used = 1.1494450569152832s
epoch 135: {'train_loss': '1.98323'}; time used = 1.2060632705688477s
epoch 140: {'train_loss': '1.96294'}; time used = 1.189979076385498s
epoch 145: {'train_loss': '1.98189'}; time used = 1.1463556289672852s
epoch 150: {'train_loss': '2.00279'}; time used = 1.1062231063842773s
epoch 155: {'train_loss': '1.92655'}; time used = 1.1273863315582275s
epoch 160: {'train_loss': '2.08048'}; time used = 1.1144933700561523s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.03514742851257.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.638095238095238, 'samples': 0.7105263157894737, 'weighted': 0.6636591478696743, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.82431'}; time used = 1.2739791870117188s
epoch 10: {'train_loss': '2.77735'}; time used = 1.1805951595306396s
epoch 15: {'train_loss': '2.77489'}; time used = 1.0559582710266113s
epoch 20: {'train_loss': '2.77775'}; time used = 1.3797907829284668s
epoch 25: {'train_loss': '2.77470'}; time used = 1.1167302131652832s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.23181438446045.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.31 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.32752'}; time used = 1.044628381729126s
epoch 10: {'train_loss': '0.17111'}; time used = 0.898993730545044s
epoch 15: {'train_loss': '0.11421'}; time used = 1.0541648864746094s
epoch 20: {'train_loss': '0.12392'}; time used = 0.9220645427703857s
epoch 25: {'train_loss': '0.21250'}; time used = 1.259704351425171s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 7.871182203292847.
Training classifier using 80.00% nodes...
{'micro': 0.9210526315789473, 'macro': 0.9182795698924731, 'samples': 0.9210526315789473, 'weighted': 0.920656479909451, 'accuracy': 0.9210526315789473}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.00911'}; time used = 1.7225699424743652s
epoch 10: {'train_loss': '0.76039'}; time used = 1.6383616924285889s
epoch 15: {'train_loss': '0.00380'}; time used = 1.693065881729126s
epoch 20: {'train_loss': '0.19395'}; time used = 1.6039891242980957s
epoch 25: {'train_loss': '0.06993'}; time used = 1.9956107139587402s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.319153785705566.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.34119'}; time used = 1.9093682765960693s
epoch 10: {'train_loss': '1.26717'}; time used = 1.916240930557251s
epoch 15: {'train_loss': '1.25854'}; time used = 1.817467451095581s
epoch 20: {'train_loss': '1.29315'}; time used = 1.8539259433746338s
epoch 25: {'train_loss': '1.25898'}; time used = 2.2853055000305176s
epoch 30: {'train_loss': '1.15552'}; time used = 2.0835094451904297s
epoch 35: {'train_loss': '1.16592'}; time used = 1.974240779876709s
epoch 40: {'train_loss': '1.12841'}; time used = 2.029688835144043s
epoch 45: {'train_loss': '1.14841'}; time used = 1.9969499111175537s
epoch 50: {'train_loss': '0.99460'}; time used = 2.264561653137207s
epoch 55: {'train_loss': '0.95038'}; time used = 1.9317612648010254s
epoch 60: {'train_loss': '0.77475'}; time used = 2.0686020851135254s
epoch 65: {'train_loss': '0.86181'}; time used = 1.9375262260437012s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.89796495437622.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.75918'}; time used = 2.5602970123291016s
epoch 10: {'train_loss': '2.75441'}; time used = 2.4319968223571777s
epoch 15: {'train_loss': '2.74242'}; time used = 2.3623902797698975s
epoch 20: {'train_loss': '2.70357'}; time used = 2.4083776473999023s
epoch 25: {'train_loss': '2.65793'}; time used = 2.450314998626709s
epoch 30: {'train_loss': '2.62146'}; time used = 2.6034998893737793s
epoch 35: {'train_loss': '2.55952'}; time used = 2.5379981994628906s
epoch 40: {'train_loss': '2.54024'}; time used = 2.5479421615600586s
epoch 45: {'train_loss': '2.50688'}; time used = 2.599036931991577s
epoch 50: {'train_loss': '2.51022'}; time used = 2.446535348892212s
epoch 55: {'train_loss': '2.48007'}; time used = 2.4563491344451904s
epoch 60: {'train_loss': '2.48447'}; time used = 2.566272020339966s
epoch 65: {'train_loss': '2.44848'}; time used = 2.5300681591033936s
epoch 70: {'train_loss': '2.41744'}; time used = 2.6109936237335205s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.30750489234924.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.59987'}; time used = 1.8208625316619873s
epoch 10: {'train_loss': '0.06298'}; time used = 1.6655690670013428s
epoch 15: {'train_loss': '0.17133'}; time used = 1.7424461841583252s
epoch 20: {'train_loss': '0.06020'}; time used = 1.8090806007385254s
epoch 25: {'train_loss': '0.05670'}; time used = 1.763373851776123s
epoch 30: {'train_loss': '0.02041'}; time used = 1.7764382362365723s
epoch 35: {'train_loss': '0.04119'}; time used = 1.7138781547546387s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.66016411781311.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4449375866851595, 'samples': 0.5797101449275363, 'weighted': 0.4647570805443325, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.04 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36928'}; time used = 1.243077039718628s
epoch 10: {'train_loss': '1.22427'}; time used = 1.1027624607086182s
epoch 15: {'train_loss': '1.04666'}; time used = 1.168529748916626s
epoch 20: {'train_loss': '0.68947'}; time used = 1.2213454246520996s
epoch 25: {'train_loss': '0.56184'}; time used = 1.223961353302002s
epoch 30: {'train_loss': '0.45609'}; time used = 1.1501541137695312s
epoch 35: {'train_loss': '0.49123'}; time used = 1.2974112033843994s
epoch 40: {'train_loss': '0.82835'}; time used = 1.173807144165039s
epoch 45: {'train_loss': '0.60742'}; time used = 1.1153285503387451s
epoch 50: {'train_loss': '0.74927'}; time used = 1.1332979202270508s
epoch 55: {'train_loss': '0.62583'}; time used = 1.1041741371154785s
epoch 60: {'train_loss': '0.42948'}; time used = 1.1135175228118896s
epoch 65: {'train_loss': '0.40982'}; time used = 1.1420001983642578s
epoch 70: {'train_loss': '0.36341'}; time used = 1.1201205253601074s
epoch 75: {'train_loss': '0.69781'}; time used = 1.1061995029449463s
epoch 80: {'train_loss': '0.39115'}; time used = 1.1058971881866455s
epoch 85: {'train_loss': '0.40786'}; time used = 1.1640727519989014s
epoch 90: {'train_loss': '0.52736'}; time used = 1.0924761295318604s
epoch 95: {'train_loss': '0.34440'}; time used = 1.1271662712097168s
epoch 100: {'train_loss': '0.59279'}; time used = 1.1249845027923584s
epoch 105: {'train_loss': '0.68500'}; time used = 1.2475757598876953s
epoch 110: {'train_loss': '0.65640'}; time used = 1.1380610466003418s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.57002592086792.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7194421657095981, 'samples': 0.7631578947368421, 'weighted': 0.7369284573204957, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.88142'}; time used = 2.2497060298919678s
epoch 10: {'train_loss': '2.81190'}; time used = 2.1658942699432373s
epoch 15: {'train_loss': '2.79253'}; time used = 2.1640853881835938s
epoch 20: {'train_loss': '2.78146'}; time used = 3.2514591217041016s
epoch 25: {'train_loss': '2.77299'}; time used = 2.1388633251190186s
epoch 30: {'train_loss': '2.77107'}; time used = 2.1352434158325195s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.61006212234497.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.89639'}; time used = 1.5339739322662354s
epoch 10: {'train_loss': '2.81327'}; time used = 1.380155086517334s
epoch 15: {'train_loss': '2.79403'}; time used = 1.3943021297454834s
epoch 20: {'train_loss': '2.78147'}; time used = 1.2807161808013916s
epoch 25: {'train_loss': '2.77577'}; time used = 1.2765967845916748s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.963483095169067.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5947497949138638, 'samples': 0.6578947368421053, 'weighted': 0.6200077716851604, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.18760'}; time used = 1.1636199951171875s
epoch 10: {'train_loss': '0.07160'}; time used = 1.100297212600708s
epoch 15: {'train_loss': '0.08470'}; time used = 1.0339009761810303s
epoch 20: {'train_loss': '0.25589'}; time used = 0.9304304122924805s
epoch 25: {'train_loss': '0.06980'}; time used = 0.9765017032623291s
epoch 30: {'train_loss': '0.05434'}; time used = 0.9278264045715332s
epoch 35: {'train_loss': '0.03826'}; time used = 0.897841215133667s
epoch 40: {'train_loss': '0.03483'}; time used = 0.9129676818847656s
epoch 45: {'train_loss': '0.03795'}; time used = 0.9077067375183105s
epoch 50: {'train_loss': '0.03819'}; time used = 0.9002082347869873s
epoch 55: {'train_loss': '0.01953'}; time used = 0.9321322441101074s
epoch 60: {'train_loss': '0.01115'}; time used = 0.9726648330688477s
epoch 65: {'train_loss': '0.02516'}; time used = 1.055006742477417s
epoch 70: {'train_loss': '0.01882'}; time used = 0.9239444732666016s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.98763942718506.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.14629'}; time used = 2.7012903690338135s
epoch 10: {'train_loss': '0.72466'}; time used = 2.6321847438812256s
epoch 15: {'train_loss': '0.14133'}; time used = 2.458750009536743s
epoch 20: {'train_loss': '0.00140'}; time used = 2.6682190895080566s
epoch 25: {'train_loss': '0.00086'}; time used = 2.6999802589416504s
epoch 30: {'train_loss': '0.15758'}; time used = 2.456993579864502s
epoch 35: {'train_loss': '0.05344'}; time used = 2.3865790367126465s
epoch 40: {'train_loss': '0.15522'}; time used = 2.3820793628692627s
epoch 45: {'train_loss': '0.00425'}; time used = 2.40185546875s
epoch 50: {'train_loss': '0.04239'}; time used = 2.3728599548339844s
epoch 55: {'train_loss': '0.03206'}; time used = 2.5048396587371826s
epoch 60: {'train_loss': '0.11779'}; time used = 2.384999990463257s
epoch 65: {'train_loss': '0.15279'}; time used = 2.4073023796081543s
epoch 70: {'train_loss': '0.04871'}; time used = 2.4526665210723877s
epoch 75: {'train_loss': '0.02164'}; time used = 2.8900485038757324s
epoch 80: {'train_loss': '0.07994'}; time used = 2.4712893962860107s
epoch 85: {'train_loss': '0.00001'}; time used = 2.5106701850891113s
epoch 90: {'train_loss': '0.03687'}; time used = 2.4463555812835693s
epoch 95: {'train_loss': '0.00612'}; time used = 2.429183006286621s
epoch 100: {'train_loss': '0.00029'}; time used = 3.4875473976135254s
epoch 105: {'train_loss': '0.00001'}; time used = 2.4607653617858887s
epoch 110: {'train_loss': '0.00005'}; time used = 2.368896961212158s
epoch 115: {'train_loss': '0.00001'}; time used = 2.3549916744232178s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 62.19326901435852.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.491578947368421, 'samples': 0.5942028985507246, 'weighted': 0.5081311975591152, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.81359'}; time used = 1.7499854564666748s
epoch 10: {'train_loss': '2.80231'}; time used = 1.7616639137268066s
epoch 15: {'train_loss': '2.78671'}; time used = 1.725510835647583s
epoch 20: {'train_loss': '2.77822'}; time used = 1.7379732131958008s
epoch 25: {'train_loss': '2.77254'}; time used = 1.8053114414215088s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.000703811645508.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6393728222996516, 'samples': 0.6521739130434783, 'weighted': 0.644296318739585, 'accuracy': 0.6521739130434783}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37894'}; time used = 1.9185194969177246s
epoch 10: {'train_loss': '1.30891'}; time used = 1.8651494979858398s
epoch 15: {'train_loss': '1.29121'}; time used = 1.9264247417449951s
epoch 20: {'train_loss': '1.13476'}; time used = 2.1454410552978516s
epoch 25: {'train_loss': '0.86050'}; time used = 2.323075532913208s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.424859523773193.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4456521739130434, 'samples': 0.5072463768115942, 'weighted': 0.459042218021424, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.05539'}; time used = 1.9959144592285156s
epoch 10: {'train_loss': '0.93304'}; time used = 1.9639251232147217s
epoch 15: {'train_loss': '0.88725'}; time used = 1.75980544090271s
epoch 20: {'train_loss': '0.93834'}; time used = 1.596437931060791s
epoch 25: {'train_loss': '0.84692'}; time used = 1.7528176307678223s
epoch 30: {'train_loss': '0.72921'}; time used = 1.6573336124420166s
epoch 35: {'train_loss': '0.48981'}; time used = 1.8507134914398193s
epoch 40: {'train_loss': '0.47402'}; time used = 1.857053518295288s
epoch 45: {'train_loss': '0.50790'}; time used = 1.7823774814605713s
epoch 50: {'train_loss': '0.40378'}; time used = 1.7583286762237549s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.805362462997437.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.38268398268398274, 'samples': 0.5507246376811594, 'weighted': 0.40602296254470177, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.92349'}; time used = 1.9427061080932617s
epoch 10: {'train_loss': '2.80127'}; time used = 1.8298299312591553s
epoch 15: {'train_loss': '2.76721'}; time used = 1.830327033996582s
epoch 20: {'train_loss': '2.74317'}; time used = 1.8064274787902832s
epoch 25: {'train_loss': '2.72155'}; time used = 1.8192150592803955s
epoch 30: {'train_loss': '2.70044'}; time used = 1.6228301525115967s
epoch 35: {'train_loss': '2.67557'}; time used = 1.596559762954712s
epoch 40: {'train_loss': '2.62550'}; time used = 1.7538115978240967s
epoch 45: {'train_loss': '2.59021'}; time used = 3.5308525562286377s
epoch 50: {'train_loss': '2.54735'}; time used = 3.2827486991882324s
epoch 55: {'train_loss': '2.53316'}; time used = 1.6956911087036133s
epoch 60: {'train_loss': '2.51693'}; time used = 1.710777997970581s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.918749570846558.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.6086956521739131, 'samples': 0.6086956521739131, 'weighted': 0.6086956521739131, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.37404'}; time used = 2.4561660289764404s
epoch 10: {'train_loss': '1.33814'}; time used = 2.2078821659088135s
epoch 15: {'train_loss': '1.36502'}; time used = 2.174278497695923s
epoch 20: {'train_loss': '1.45631'}; time used = 2.1401898860931396s
epoch 25: {'train_loss': '1.41163'}; time used = 2.2623870372772217s
epoch 30: {'train_loss': '1.31707'}; time used = 2.077864408493042s
epoch 35: {'train_loss': '1.29292'}; time used = 2.1515214443206787s
epoch 40: {'train_loss': '1.15064'}; time used = 2.110154628753662s
epoch 45: {'train_loss': '1.11182'}; time used = 1.994974136352539s
epoch 50: {'train_loss': '0.91278'}; time used = 2.1824371814727783s
epoch 55: {'train_loss': '0.86216'}; time used = 2.1011805534362793s
epoch 60: {'train_loss': '0.82599'}; time used = 2.098585367202759s
epoch 65: {'train_loss': '0.85422'}; time used = 2.070660352706909s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.54782271385193.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5864594894561599, 'samples': 0.6086956521739131, 'weighted': 0.5934082903054577, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36668'}; time used = 1.9954197406768799s
epoch 10: {'train_loss': '1.22799'}; time used = 2.0555882453918457s
epoch 15: {'train_loss': '1.04073'}; time used = 2.1712329387664795s
epoch 20: {'train_loss': '0.94235'}; time used = 2.0053017139434814s
epoch 25: {'train_loss': '1.02166'}; time used = 2.0642824172973633s
epoch 30: {'train_loss': '0.83054'}; time used = 2.7822208404541016s
epoch 35: {'train_loss': '0.85143'}; time used = 3.7886199951171875s
epoch 40: {'train_loss': '0.83565'}; time used = 3.6890828609466553s
epoch 45: {'train_loss': '0.55279'}; time used = 2.263289451599121s
epoch 50: {'train_loss': '0.53604'}; time used = 2.1506741046905518s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.633833646774292.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5436507936507937, 'samples': 0.5652173913043478, 'weighted': 0.5508396595353117, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37058'}; time used = 4.401149272918701s
epoch 10: {'train_loss': '1.27608'}; time used = 3.964542865753174s
epoch 15: {'train_loss': '1.01308'}; time used = 2.2062811851501465s
epoch 20: {'train_loss': '0.53765'}; time used = 2.1089797019958496s
epoch 25: {'train_loss': '0.45308'}; time used = 2.078730344772339s
epoch 30: {'train_loss': '0.16255'}; time used = 2.0266761779785156s
epoch 35: {'train_loss': '0.55047'}; time used = 2.0779449939727783s
epoch 40: {'train_loss': '0.21324'}; time used = 2.1679399013519287s
epoch 45: {'train_loss': '0.37178'}; time used = 2.0112955570220947s
epoch 50: {'train_loss': '0.25055'}; time used = 2.24202561378479s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.541016817092896.
Training classifier using 80.00% nodes...
{'micro': 0.7101449275362319, 'macro': 0.7086148648648649, 'samples': 0.7101449275362319, 'weighted': 0.7101449275362319, 'accuracy': 0.7101449275362319}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 5.776513576507568s
epoch 10: {'train_loss': '1.38629'}; time used = 4.467960357666016s
epoch 15: {'train_loss': '1.38629'}; time used = 4.340909004211426s
epoch 20: {'train_loss': '1.38629'}; time used = 4.2380759716033936s
epoch 25: {'train_loss': '1.38629'}; time used = 4.558168411254883s
epoch 30: {'train_loss': '1.38629'}; time used = 4.313189506530762s
epoch 35: {'train_loss': '1.38629'}; time used = 4.308695077896118s
epoch 40: {'train_loss': '1.38629'}; time used = 4.229945421218872s
epoch 45: {'train_loss': '1.38629'}; time used = 4.46564507484436s
epoch 50: {'train_loss': '1.38629'}; time used = 4.288087368011475s
epoch 55: {'train_loss': '1.38629'}; time used = 5.949787855148315s
epoch 60: {'train_loss': '1.38629'}; time used = 6.152727842330933s
epoch 65: {'train_loss': '1.38629'}; time used = 4.3879029750823975s
epoch 70: {'train_loss': '1.38629'}; time used = 4.213141679763794s
epoch 75: {'train_loss': '1.38629'}; time used = 4.320500135421753s
epoch 80: {'train_loss': '1.38629'}; time used = 4.506836414337158s
epoch 85: {'train_loss': '1.38629'}; time used = 4.247344017028809s
epoch 90: {'train_loss': '1.38629'}; time used = 4.375859260559082s
epoch 95: {'train_loss': '1.38629'}; time used = 4.868138313293457s
epoch 100: {'train_loss': '1.38629'}; time used = 4.841944932937622s
epoch 105: {'train_loss': '1.38629'}; time used = 4.372105598449707s
epoch 110: {'train_loss': '1.38629'}; time used = 4.432129383087158s
epoch 115: {'train_loss': '1.38629'}; time used = 4.31383490562439s
epoch 120: {'train_loss': '1.38629'}; time used = 4.318926572799683s
epoch 125: {'train_loss': '1.38629'}; time used = 4.2822959423065186s
epoch 130: {'train_loss': '1.38629'}; time used = 4.3624067306518555s
epoch 135: {'train_loss': '1.38629'}; time used = 4.4130494594573975s
epoch 140: {'train_loss': '1.38629'}; time used = 4.5502166748046875s
epoch 145: {'train_loss': '1.38629'}; time used = 4.543433904647827s
epoch 150: {'train_loss': '1.38629'}; time used = 4.33517599105835s
epoch 155: {'train_loss': '1.38629'}; time used = 4.508147239685059s
epoch 160: {'train_loss': '1.38629'}; time used = 4.457497835159302s
epoch 165: {'train_loss': '1.38629'}; time used = 4.460954904556274s
epoch 170: {'train_loss': '1.38629'}; time used = 4.180211782455444s
epoch 175: {'train_loss': '1.38629'}; time used = 4.210381031036377s
epoch 180: {'train_loss': '1.38629'}; time used = 4.35664701461792s
epoch 185: {'train_loss': '1.38629'}; time used = 4.523751258850098s
epoch 190: {'train_loss': '1.38629'}; time used = 4.512933254241943s
epoch 195: {'train_loss': '1.38629'}; time used = 4.514426231384277s
epoch 200: {'train_loss': '1.38629'}; time used = 4.4416515827178955s
epoch 205: {'train_loss': '1.38629'}; time used = 4.608494281768799s
epoch 210: {'train_loss': '1.38629'}; time used = 5.001021862030029s
epoch 215: {'train_loss': '1.38629'}; time used = 4.535186767578125s
epoch 220: {'train_loss': '1.38629'}; time used = 4.401894569396973s
epoch 225: {'train_loss': '1.38629'}; time used = 4.401139497756958s
epoch 230: {'train_loss': '1.38629'}; time used = 4.74187445640564s
epoch 235: {'train_loss': '1.38629'}; time used = 7.037466049194336s
epoch 240: {'train_loss': '1.38629'}; time used = 5.648870229721069s
epoch 245: {'train_loss': '1.38629'}; time used = 4.521181106567383s
epoch 250: {'train_loss': '1.38629'}; time used = 4.563879489898682s
epoch 255: {'train_loss': '1.38629'}; time used = 4.454519987106323s
epoch 260: {'train_loss': '1.38629'}; time used = 7.39771580696106s
epoch 265: {'train_loss': '1.38629'}; time used = 5.370515584945679s
epoch 270: {'train_loss': '1.38629'}; time used = 4.594463109970093s
epoch 275: {'train_loss': '1.38629'}; time used = 4.621460199356079s
epoch 280: {'train_loss': '1.38629'}; time used = 4.4889843463897705s
epoch 285: {'train_loss': '1.38629'}; time used = 4.59520149230957s
epoch 290: {'train_loss': '1.38629'}; time used = 4.5405402183532715s
epoch 295: {'train_loss': '1.38629'}; time used = 4.699431657791138s
epoch 300: {'train_loss': '1.38629'}; time used = 4.812985181808472s
epoch 305: {'train_loss': '1.38629'}; time used = 4.684903621673584s
epoch 310: {'train_loss': '1.38629'}; time used = 6.091799736022949s
epoch 315: {'train_loss': '1.38629'}; time used = 7.0383141040802s
epoch 320: {'train_loss': '1.38629'}; time used = 4.917231321334839s
epoch 325: {'train_loss': '1.38629'}; time used = 4.906410217285156s
epoch 330: {'train_loss': '1.38629'}; time used = 4.946134090423584s
epoch 335: {'train_loss': '1.38629'}; time used = 7.2778871059417725s
epoch 340: {'train_loss': '1.38629'}; time used = 4.969283103942871s
epoch 345: {'train_loss': '1.38629'}; time used = 5.20212721824646s
epoch 350: {'train_loss': '1.38629'}; time used = 4.923555135726929s
epoch 355: {'train_loss': '1.38629'}; time used = 4.637586355209351s
epoch 360: {'train_loss': '1.38629'}; time used = 4.867295503616333s
epoch 365: {'train_loss': '1.38629'}; time used = 4.946197986602783s
epoch 370: {'train_loss': '1.38629'}; time used = 5.016149044036865s
epoch 375: {'train_loss': '1.38629'}; time used = 4.88047456741333s
epoch 380: {'train_loss': '1.38629'}; time used = 4.89669942855835s
epoch 385: {'train_loss': '1.38629'}; time used = 4.709994316101074s
epoch 390: {'train_loss': '1.38629'}; time used = 4.899079322814941s
epoch 395: {'train_loss': '1.38629'}; time used = 4.7077109813690186s
epoch 400: {'train_loss': '1.38629'}; time used = 6.696468114852905s
epoch 405: {'train_loss': '1.38629'}; time used = 7.058509588241577s
epoch 410: {'train_loss': '1.38629'}; time used = 5.057507038116455s
epoch 415: {'train_loss': '1.38629'}; time used = 4.809658765792847s
epoch 420: {'train_loss': '1.38629'}; time used = 5.004013299942017s
epoch 425: {'train_loss': '1.38629'}; time used = 5.061241388320923s
epoch 430: {'train_loss': '1.38629'}; time used = 6.186777114868164s
epoch 435: {'train_loss': '1.38629'}; time used = 8.168511152267456s
epoch 440: {'train_loss': '1.38629'}; time used = 8.31655216217041s
epoch 445: {'train_loss': '1.38629'}; time used = 7.803402900695801s
epoch 450: {'train_loss': '1.38629'}; time used = 4.753468036651611s
epoch 455: {'train_loss': '1.38629'}; time used = 4.593729496002197s
epoch 460: {'train_loss': '1.38629'}; time used = 4.548853874206543s
epoch 465: {'train_loss': '1.38629'}; time used = 4.6194212436676025s
epoch 470: {'train_loss': '1.38629'}; time used = 4.604971647262573s
epoch 475: {'train_loss': '1.38629'}; time used = 4.6565797328948975s
epoch 480: {'train_loss': '1.38629'}; time used = 4.717465400695801s
epoch 485: {'train_loss': '1.38629'}; time used = 5.994076251983643s
epoch 490: {'train_loss': '1.38629'}; time used = 7.243759870529175s
epoch 495: {'train_loss': '1.38629'}; time used = 4.839051008224487s
epoch 500: {'train_loss': '1.38629'}; time used = 5.178797960281372s
Finished training. Time used = 509.328644990921.
Training classifier using 80.00% nodes...
{'micro': 0.7250000000000001, 'macro': 0.7249931248281207, 'samples': 0.725, 'weighted': 0.725020625515638, 'accuracy': 0.725}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.35053'}; time used = 1.9755115509033203s
epoch 10: {'train_loss': '1.29218'}; time used = 2.2019882202148438s
epoch 15: {'train_loss': '1.29437'}; time used = 2.5998950004577637s
epoch 20: {'train_loss': '1.41435'}; time used = 1.8165841102600098s
epoch 25: {'train_loss': '1.36588'}; time used = 1.9963443279266357s
epoch 30: {'train_loss': '1.32239'}; time used = 1.9633526802062988s
epoch 35: {'train_loss': '1.30831'}; time used = 1.9437260627746582s
epoch 40: {'train_loss': '1.28450'}; time used = 2.304436445236206s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.060711145401.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.86171'}; time used = 2.3234269618988037s
epoch 10: {'train_loss': '2.79330'}; time used = 2.777132034301758s
epoch 15: {'train_loss': '2.77702'}; time used = 4.907283306121826s
epoch 20: {'train_loss': '2.77244'}; time used = 2.065016508102417s
epoch 25: {'train_loss': '2.77502'}; time used = 2.03640079498291s
epoch 30: {'train_loss': '2.77445'}; time used = 2.3631770610809326s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.999112844467163.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4719387755102041, 'samples': 0.5652173913043478, 'weighted': 0.4880212954747117, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87724'}; time used = 4.174023151397705s
epoch 10: {'train_loss': '2.79986'}; time used = 2.36726450920105s
epoch 15: {'train_loss': '2.77879'}; time used = 2.171126365661621s
epoch 20: {'train_loss': '2.77263'}; time used = 1.9889862537384033s
epoch 25: {'train_loss': '2.77165'}; time used = 2.3106489181518555s
epoch 30: {'train_loss': '2.76853'}; time used = 2.1697165966033936s
epoch 35: {'train_loss': '2.76830'}; time used = 2.1412408351898193s
epoch 40: {'train_loss': '2.76775'}; time used = 2.3331525325775146s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.5982563495636.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.560909090909091, 'samples': 0.5942028985507246, 'weighted': 0.5696706192358367, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.05399'}; time used = 1.2420542240142822s
epoch 10: {'train_loss': '2.79385'}; time used = 1.262758731842041s
epoch 15: {'train_loss': '2.79020'}; time used = 1.253880500793457s
epoch 20: {'train_loss': '2.79902'}; time used = 1.1729841232299805s
epoch 25: {'train_loss': '2.77259'}; time used = 1.2016575336456299s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.377999067306519.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.80997'}; time used = 2.250946283340454s
epoch 10: {'train_loss': '2.78055'}; time used = 2.0354132652282715s
epoch 15: {'train_loss': '2.77634'}; time used = 2.741814613342285s
epoch 20: {'train_loss': '2.77140'}; time used = 2.4005870819091797s
epoch 25: {'train_loss': '2.76572'}; time used = 2.1301052570343018s
epoch 30: {'train_loss': '2.75888'}; time used = 2.0903289318084717s
epoch 35: {'train_loss': '2.75934'}; time used = 2.1901330947875977s
epoch 40: {'train_loss': '2.75559'}; time used = 2.151421546936035s
epoch 45: {'train_loss': '2.75006'}; time used = 2.1914525032043457s
epoch 50: {'train_loss': '2.75154'}; time used = 2.1666107177734375s
epoch 55: {'train_loss': '2.75078'}; time used = 2.316697120666504s
epoch 60: {'train_loss': '2.74607'}; time used = 2.140759229660034s
epoch 65: {'train_loss': '2.74274'}; time used = 3.6356029510498047s
epoch 70: {'train_loss': '2.73505'}; time used = 3.751251697540283s
epoch 75: {'train_loss': '2.73119'}; time used = 3.8087825775146484s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.80601096153259.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5062611806797853, 'samples': 0.5362318840579711, 'weighted': 0.5150760934380751, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.09089'}; time used = 1.341099500656128s
epoch 10: {'train_loss': '0.03447'}; time used = 1.1367168426513672s
epoch 15: {'train_loss': '0.04624'}; time used = 1.1520655155181885s
epoch 20: {'train_loss': '0.00787'}; time used = 1.3262298107147217s
epoch 25: {'train_loss': '0.01046'}; time used = 1.3710377216339111s
epoch 30: {'train_loss': '0.00050'}; time used = 1.256079912185669s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.463606357574463.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.89287'}; time used = 1.4283778667449951s
epoch 10: {'train_loss': '2.81230'}; time used = 1.361274242401123s
epoch 15: {'train_loss': '2.79347'}; time used = 1.2308008670806885s
epoch 20: {'train_loss': '2.78047'}; time used = 1.136728286743164s
epoch 25: {'train_loss': '2.77323'}; time used = 1.3390262126922607s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.523696422576904.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.85662'}; time used = 1.8432395458221436s
epoch 10: {'train_loss': '2.95262'}; time used = 1.94118070602417s
epoch 15: {'train_loss': '2.81467'}; time used = 1.9573578834533691s
epoch 20: {'train_loss': '2.76649'}; time used = 1.8053617477416992s
epoch 25: {'train_loss': '2.73732'}; time used = 2.7859017848968506s
epoch 30: {'train_loss': '2.71198'}; time used = 1.9390020370483398s
epoch 35: {'train_loss': '2.68932'}; time used = 1.71736741065979s
epoch 40: {'train_loss': '2.65807'}; time used = 1.6921095848083496s
epoch 45: {'train_loss': '2.63979'}; time used = 1.7915771007537842s
epoch 50: {'train_loss': '2.60073'}; time used = 1.7307300567626953s
epoch 55: {'train_loss': '2.58082'}; time used = 1.8797922134399414s
epoch 60: {'train_loss': '2.55301'}; time used = 1.8223679065704346s
epoch 65: {'train_loss': '2.51286'}; time used = 1.9250247478485107s
epoch 70: {'train_loss': '2.49758'}; time used = 1.8126909732818604s
epoch 75: {'train_loss': '2.46912'}; time used = 1.9713139533996582s
epoch 80: {'train_loss': '2.47959'}; time used = 1.844444990158081s
epoch 85: {'train_loss': '2.46634'}; time used = 1.7220394611358643s
epoch 90: {'train_loss': '2.45633'}; time used = 1.836885929107666s
epoch 95: {'train_loss': '2.44050'}; time used = 1.7743480205535889s
epoch 100: {'train_loss': '2.40138'}; time used = 1.7234830856323242s
epoch 105: {'train_loss': '2.42828'}; time used = 2.065290927886963s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.11809730529785.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5558268590455051, 'samples': 0.5797101449275363, 'weighted': 0.5632903858836398, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.55091'}; time used = 1.1839191913604736s
epoch 10: {'train_loss': '0.38419'}; time used = 1.2622039318084717s
epoch 15: {'train_loss': '0.25673'}; time used = 1.1858155727386475s
epoch 20: {'train_loss': '0.20653'}; time used = 1.1748948097229004s
epoch 25: {'train_loss': '0.24312'}; time used = 1.1285045146942139s
epoch 30: {'train_loss': '0.16407'}; time used = 1.0796003341674805s
epoch 35: {'train_loss': '0.14953'}; time used = 1.2420923709869385s
epoch 40: {'train_loss': '0.02996'}; time used = 1.2880125045776367s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.06808614730835.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.72829'}; time used = 1.5908761024475098s
epoch 10: {'train_loss': '2.68594'}; time used = 1.563507318496704s
epoch 15: {'train_loss': '2.41637'}; time used = 1.3925979137420654s
epoch 20: {'train_loss': '2.42279'}; time used = 1.589871883392334s
epoch 25: {'train_loss': '2.12547'}; time used = 1.4844906330108643s
epoch 30: {'train_loss': '2.16364'}; time used = 1.342421531677246s
epoch 35: {'train_loss': '1.99186'}; time used = 1.3338897228240967s
epoch 40: {'train_loss': '1.98199'}; time used = 1.473712682723999s
epoch 45: {'train_loss': '1.95572'}; time used = 1.4049079418182373s
epoch 50: {'train_loss': '1.94207'}; time used = 1.3601882457733154s
epoch 55: {'train_loss': '1.85506'}; time used = 1.439131498336792s
epoch 60: {'train_loss': '2.27295'}; time used = 1.5452182292938232s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.910759687423706.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.69840'}; time used = 1.1245765686035156s
epoch 10: {'train_loss': '2.63170'}; time used = 1.9871997833251953s
epoch 15: {'train_loss': '2.54245'}; time used = 2.0694761276245117s
epoch 20: {'train_loss': '2.47893'}; time used = 2.140822649002075s
epoch 25: {'train_loss': '2.38261'}; time used = 1.873856782913208s
epoch 30: {'train_loss': '2.29349'}; time used = 2.0672290325164795s
epoch 35: {'train_loss': '2.27132'}; time used = 1.8492176532745361s
epoch 40: {'train_loss': '2.22972'}; time used = 1.2418766021728516s
epoch 45: {'train_loss': '2.18511'}; time used = 1.4660835266113281s
epoch 50: {'train_loss': '2.17491'}; time used = 1.699357032775879s
epoch 55: {'train_loss': '2.24242'}; time used = 1.1204986572265625s
epoch 60: {'train_loss': '2.09117'}; time used = 1.1764471530914307s
epoch 65: {'train_loss': '2.04901'}; time used = 1.160231113433838s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.551833868026733.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85613'}; time used = 1.1870105266571045s
epoch 10: {'train_loss': '2.78714'}; time used = 1.1065583229064941s
epoch 15: {'train_loss': '2.77368'}; time used = 1.0155434608459473s
epoch 20: {'train_loss': '2.78401'}; time used = 1.164379596710205s
epoch 25: {'train_loss': '2.77668'}; time used = 1.338810920715332s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.70618486404419.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86520'}; time used = 1.2077114582061768s
epoch 10: {'train_loss': '2.81772'}; time used = 1.2610993385314941s
epoch 15: {'train_loss': '2.78975'}; time used = 1.1524064540863037s
epoch 20: {'train_loss': '2.77337'}; time used = 1.1384122371673584s
epoch 25: {'train_loss': '2.77400'}; time used = 1.1378247737884521s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.809603929519653.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77114'}; time used = 2.8119890689849854s
epoch 10: {'train_loss': '2.74921'}; time used = 2.334904670715332s
epoch 15: {'train_loss': '2.72577'}; time used = 2.2538535594940186s
epoch 20: {'train_loss': '2.68679'}; time used = 2.2378745079040527s
epoch 25: {'train_loss': '2.69394'}; time used = 2.243277072906494s
epoch 30: {'train_loss': '2.68459'}; time used = 2.451493978500366s
epoch 35: {'train_loss': '2.68752'}; time used = 2.164523124694824s
epoch 40: {'train_loss': '2.68576'}; time used = 2.541123867034912s
epoch 45: {'train_loss': '2.68282'}; time used = 2.3026795387268066s
epoch 50: {'train_loss': '2.68291'}; time used = 3.2759244441986084s
epoch 55: {'train_loss': '2.69218'}; time used = 2.2637343406677246s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.72154688835144.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4888888888888888, 'samples': 0.5362318840579711, 'weighted': 0.5001610305958131, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.91103'}; time used = 1.9786500930786133s
epoch 10: {'train_loss': '2.77622'}; time used = 1.9047353267669678s
epoch 15: {'train_loss': '2.74534'}; time used = 2.0464046001434326s
epoch 20: {'train_loss': '2.69150'}; time used = 1.997903823852539s
epoch 25: {'train_loss': '2.63167'}; time used = 1.98201322555542s
epoch 30: {'train_loss': '2.59775'}; time used = 2.61301851272583s
epoch 35: {'train_loss': '2.53874'}; time used = 1.9428346157073975s
epoch 40: {'train_loss': '2.45608'}; time used = 2.0767300128936768s
epoch 45: {'train_loss': '2.38010'}; time used = 1.9545810222625732s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.326601266860962.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4719387755102041, 'samples': 0.5652173913043478, 'weighted': 0.4880212954747117, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.94385'}; time used = 1.978151798248291s
epoch 10: {'train_loss': '2.81508'}; time used = 1.9397153854370117s
epoch 15: {'train_loss': '2.80939'}; time used = 1.9530353546142578s
epoch 20: {'train_loss': '2.79042'}; time used = 2.026317834854126s
epoch 25: {'train_loss': '2.77528'}; time used = 2.01969051361084s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.439276218414307.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5337837837837838, 'samples': 0.5362318840579711, 'weighted': 0.5362318840579711, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.15426'}; time used = 1.2178623676300049s
epoch 10: {'train_loss': '0.90164'}; time used = 1.2623403072357178s
epoch 15: {'train_loss': '0.76142'}; time used = 1.1816625595092773s
epoch 20: {'train_loss': '0.63294'}; time used = 1.1392436027526855s
epoch 25: {'train_loss': '0.58059'}; time used = 1.1956188678741455s
epoch 30: {'train_loss': '0.48360'}; time used = 1.2897062301635742s
epoch 35: {'train_loss': '0.44677'}; time used = 1.0756120681762695s
epoch 40: {'train_loss': '0.39533'}; time used = 1.1873142719268799s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.325245141983032.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.525, 'samples': 0.631578947368421, 'weighted': 0.5605263157894737, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.37422'}; time used = 2.1993536949157715s
epoch 10: {'train_loss': '1.34491'}; time used = 2.507706880569458s
epoch 15: {'train_loss': '1.37537'}; time used = 2.1974446773529053s
epoch 20: {'train_loss': '1.44505'}; time used = 2.2479193210601807s
epoch 25: {'train_loss': '1.40862'}; time used = 2.146921157836914s
epoch 30: {'train_loss': '1.35677'}; time used = 2.20316481590271s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.807512760162354.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.83847'}; time used = 4.715873956680298s
epoch 10: {'train_loss': '2.80269'}; time used = 4.831139326095581s
epoch 15: {'train_loss': '2.78988'}; time used = 1.5077579021453857s
epoch 20: {'train_loss': '2.78275'}; time used = 1.4416649341583252s
epoch 25: {'train_loss': '2.77671'}; time used = 1.3026940822601318s
epoch 30: {'train_loss': '2.77198'}; time used = 1.3264613151550293s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.746933221817017.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6161616161616161, 'samples': 0.6842105263157895, 'weighted': 0.6416799574694312, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37544'}; time used = 2.3435556888580322s
epoch 10: {'train_loss': '1.32342'}; time used = 2.542400360107422s
epoch 15: {'train_loss': '1.24971'}; time used = 2.2683112621307373s
epoch 20: {'train_loss': '1.27083'}; time used = 1.9580178260803223s
epoch 25: {'train_loss': '1.18452'}; time used = 1.2562551498413086s
epoch 30: {'train_loss': '1.03041'}; time used = 1.4259233474731445s
epoch 35: {'train_loss': '0.98921'}; time used = 1.346278190612793s
epoch 40: {'train_loss': '0.95519'}; time used = 1.2916011810302734s
epoch 45: {'train_loss': '0.66712'}; time used = 1.0980679988861084s
epoch 50: {'train_loss': '0.82003'}; time used = 1.2522013187408447s
epoch 55: {'train_loss': '0.64443'}; time used = 1.2718310356140137s
epoch 60: {'train_loss': '0.78400'}; time used = 1.5352301597595215s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.40130305290222.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.37285'}; time used = 1.3111498355865479s
epoch 10: {'train_loss': '1.41366'}; time used = 1.1889681816101074s
epoch 15: {'train_loss': '1.35692'}; time used = 1.3388607501983643s
epoch 20: {'train_loss': '1.38593'}; time used = 1.2027902603149414s
epoch 25: {'train_loss': '1.34566'}; time used = 1.2080161571502686s
epoch 30: {'train_loss': '1.36180'}; time used = 1.3045167922973633s
epoch 35: {'train_loss': '1.38171'}; time used = 1.3015203475952148s
epoch 40: {'train_loss': '1.34152'}; time used = 1.226259469985962s
epoch 45: {'train_loss': '1.24927'}; time used = 1.4267592430114746s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.902563095092773.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.21714'}; time used = 2.7725069522857666s
epoch 10: {'train_loss': '2.79546'}; time used = 2.4187402725219727s
epoch 15: {'train_loss': '2.72838'}; time used = 1.7733337879180908s
epoch 20: {'train_loss': '2.67240'}; time used = 1.7527472972869873s
epoch 25: {'train_loss': '2.62874'}; time used = 1.7734520435333252s
epoch 30: {'train_loss': '2.59774'}; time used = 1.8306851387023926s
epoch 35: {'train_loss': '2.56790'}; time used = 1.812133550643921s
epoch 40: {'train_loss': '2.54401'}; time used = 1.6818575859069824s
epoch 45: {'train_loss': '2.52000'}; time used = 1.8762741088867188s
epoch 50: {'train_loss': '2.46658'}; time used = 1.8380482196807861s
epoch 55: {'train_loss': '2.43496'}; time used = 1.877821922302246s
epoch 60: {'train_loss': '2.41563'}; time used = 1.7722923755645752s
epoch 65: {'train_loss': '2.37054'}; time used = 1.7007215023040771s
epoch 70: {'train_loss': '2.30573'}; time used = 1.8228418827056885s
epoch 75: {'train_loss': '2.27263'}; time used = 1.7834105491638184s
epoch 80: {'train_loss': '2.41090'}; time used = 1.7236590385437012s
epoch 85: {'train_loss': '2.29565'}; time used = 1.7419853210449219s
epoch 90: {'train_loss': '2.29997'}; time used = 1.6725375652313232s
epoch 95: {'train_loss': '2.26800'}; time used = 1.6486871242523193s
epoch 100: {'train_loss': '2.21234'}; time used = 1.8078629970550537s
epoch 105: {'train_loss': '2.21020'}; time used = 2.2091147899627686s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 45.45103693008423.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5765079365079364, 'samples': 0.5797101449275363, 'weighted': 0.5791764435242696, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.85162'}; time used = 9.352949857711792s
epoch 10: {'train_loss': '2.77659'}; time used = 11.014959335327148s
epoch 15: {'train_loss': '2.77430'}; time used = 7.993252515792847s
epoch 20: {'train_loss': '2.78035'}; time used = 8.972607135772705s
epoch 25: {'train_loss': '2.76678'}; time used = 8.283692121505737s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 67.74073266983032.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.464967516241879, 'samples': 0.5033333333333333, 'weighted': 0.4575402298850575, 'accuracy': 0.5033333333333333}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.81567'}; time used = 1.1658592224121094s
epoch 10: {'train_loss': '0.86602'}; time used = 1.018819808959961s
epoch 15: {'train_loss': '0.36228'}; time used = 1.0248603820800781s
epoch 20: {'train_loss': '0.22586'}; time used = 1.1237637996673584s
epoch 25: {'train_loss': '0.22166'}; time used = 0.922313928604126s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.42665958404541.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.94385'}; time used = 2.261129379272461s
epoch 10: {'train_loss': '2.81508'}; time used = 3.443535327911377s
epoch 15: {'train_loss': '2.80939'}; time used = 2.1358747482299805s
epoch 20: {'train_loss': '2.79042'}; time used = 2.0492606163024902s
epoch 25: {'train_loss': '2.77528'}; time used = 1.9072492122650146s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.211357116699219.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5337837837837838, 'samples': 0.5362318840579711, 'weighted': 0.5362318840579711, 'accuracy': 0.5362318840579711}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.40004'}; time used = 2.521406650543213s
epoch 10: {'train_loss': '1.39316'}; time used = 1.4507911205291748s
epoch 15: {'train_loss': '1.38770'}; time used = 1.206667184829712s
epoch 20: {'train_loss': '1.38844'}; time used = 1.34977126121521s
epoch 25: {'train_loss': '1.38956'}; time used = 1.2198278903961182s
epoch 30: {'train_loss': '1.38421'}; time used = 1.0952956676483154s
epoch 35: {'train_loss': '1.39220'}; time used = 1.0823168754577637s
epoch 40: {'train_loss': '1.37420'}; time used = 1.2464025020599365s
epoch 45: {'train_loss': '1.34842'}; time used = 1.350292444229126s
epoch 50: {'train_loss': '1.41032'}; time used = 1.1194782257080078s
epoch 55: {'train_loss': '1.38009'}; time used = 1.1791722774505615s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.134015798568726.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.3666666666666667, 'samples': 0.5789473684210527, 'weighted': 0.4245614035087719, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.50 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39952'}; time used = 1.2528891563415527s
epoch 10: {'train_loss': '1.39259'}; time used = 1.1398403644561768s
epoch 15: {'train_loss': '1.38087'}; time used = 1.1559062004089355s
epoch 20: {'train_loss': '1.37582'}; time used = 1.211108922958374s
epoch 25: {'train_loss': '1.30733'}; time used = 1.2723197937011719s
epoch 30: {'train_loss': '1.24891'}; time used = 1.1523470878601074s
epoch 35: {'train_loss': '1.28940'}; time used = 1.3464703559875488s
epoch 40: {'train_loss': '1.18739'}; time used = 1.2489619255065918s
epoch 45: {'train_loss': '1.04133'}; time used = 1.2990796566009521s
epoch 50: {'train_loss': '1.14541'}; time used = 1.4098808765411377s
epoch 55: {'train_loss': '1.09383'}; time used = 1.2526562213897705s
epoch 60: {'train_loss': '1.14950'}; time used = 1.1346056461334229s
epoch 65: {'train_loss': '0.98843'}; time used = 1.4795637130737305s
epoch 70: {'train_loss': '1.25174'}; time used = 1.1925296783447266s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.38678550720215.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36045'}; time used = 1.9557209014892578s
epoch 10: {'train_loss': '1.23285'}; time used = 1.926933765411377s
epoch 15: {'train_loss': '1.11361'}; time used = 1.9864990711212158s
epoch 20: {'train_loss': '1.26058'}; time used = 3.3167755603790283s
epoch 25: {'train_loss': '1.08184'}; time used = 5.328984260559082s
epoch 30: {'train_loss': '1.03285'}; time used = 2.3783957958221436s
epoch 35: {'train_loss': '0.94203'}; time used = 2.1545042991638184s
epoch 40: {'train_loss': '0.79145'}; time used = 3.12103271484375s
epoch 45: {'train_loss': '0.78769'}; time used = 2.120569944381714s
epoch 50: {'train_loss': '0.77549'}; time used = 2.3159561157226562s
epoch 55: {'train_loss': '0.63320'}; time used = 2.4702506065368652s
epoch 60: {'train_loss': '0.71099'}; time used = 1.969142198562622s
epoch 65: {'train_loss': '0.79526'}; time used = 2.328423261642456s
epoch 70: {'train_loss': '1.81037'}; time used = 2.0078318119049072s
epoch 75: {'train_loss': '0.60349'}; time used = 2.285219430923462s
epoch 80: {'train_loss': '0.55687'}; time used = 2.055894136428833s
epoch 85: {'train_loss': '0.69630'}; time used = 2.4668798446655273s
epoch 90: {'train_loss': '0.73322'}; time used = 1.9736967086791992s
epoch 95: {'train_loss': '0.42088'}; time used = 1.8202826976776123s
epoch 100: {'train_loss': '0.56995'}; time used = 1.943556547164917s
epoch 105: {'train_loss': '0.26675'}; time used = 1.9045016765594482s
epoch 110: {'train_loss': '0.39174'}; time used = 2.1066904067993164s
epoch 115: {'train_loss': '0.37782'}; time used = 1.9576568603515625s
epoch 120: {'train_loss': '0.23357'}; time used = 1.873628854751587s
epoch 125: {'train_loss': '0.13488'}; time used = 1.773902416229248s
epoch 130: {'train_loss': '0.28278'}; time used = 1.9866642951965332s
epoch 135: {'train_loss': '0.09571'}; time used = 1.9010603427886963s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 67.77724409103394.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4866071428571428, 'samples': 0.5652173913043478, 'weighted': 0.5011645962732919, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.40127'}; time used = 2.643923759460449s
epoch 10: {'train_loss': '1.41017'}; time used = 2.4032280445098877s
epoch 15: {'train_loss': '1.38865'}; time used = 1.389338493347168s
epoch 20: {'train_loss': '1.39510'}; time used = 1.2926626205444336s
epoch 25: {'train_loss': '1.41536'}; time used = 1.1729028224945068s
epoch 30: {'train_loss': '1.37398'}; time used = 1.3291985988616943s
epoch 35: {'train_loss': '1.39234'}; time used = 1.4062607288360596s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.032180070877075.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6161616161616161, 'samples': 0.6842105263157895, 'weighted': 0.6416799574694312, 'accuracy': 0.6842105263157895}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.59253'}; time used = 1.3148548603057861s
epoch 10: {'train_loss': '1.96645'}; time used = 1.112154483795166s
epoch 15: {'train_loss': '1.76059'}; time used = 1.0813407897949219s
epoch 20: {'train_loss': '1.62946'}; time used = 0.9795999526977539s
epoch 25: {'train_loss': '2.15821'}; time used = 1.0872910022735596s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.89919400215149.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.04 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.10432'}; time used = 2.4930293560028076s
epoch 10: {'train_loss': '0.27804'}; time used = 3.3092198371887207s
epoch 15: {'train_loss': '0.14590'}; time used = 3.4137306213378906s
epoch 20: {'train_loss': '0.10129'}; time used = 3.393756151199341s
epoch 25: {'train_loss': '0.08266'}; time used = 2.5615792274475098s
epoch 30: {'train_loss': '0.07366'}; time used = 2.6623268127441406s
epoch 35: {'train_loss': '0.06917'}; time used = 2.424534559249878s
epoch 40: {'train_loss': '0.04853'}; time used = 2.345515727996826s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.7379047870636.
Training classifier using 80.00% nodes...
{'micro': 0.4927536231884058, 'macro': 0.4462279293739968, 'samples': 0.4927536231884058, 'weighted': 0.4578593528275991, 'accuracy': 0.4927536231884058}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.78011'}; time used = 8.628857851028442s
epoch 10: {'train_loss': '2.78242'}; time used = 6.921140432357788s
epoch 15: {'train_loss': '2.76809'}; time used = 6.73143744468689s
epoch 20: {'train_loss': '2.76115'}; time used = 6.775080680847168s
epoch 25: {'train_loss': '2.75182'}; time used = 6.858119487762451s
epoch 30: {'train_loss': '2.74094'}; time used = 7.227788925170898s
epoch 35: {'train_loss': '2.72421'}; time used = 10.548363208770752s
epoch 40: {'train_loss': '2.71257'}; time used = 7.18720269203186s
epoch 45: {'train_loss': '2.70620'}; time used = 7.70750093460083s
epoch 50: {'train_loss': '2.70325'}; time used = 6.900690317153931s
epoch 55: {'train_loss': '2.70239'}; time used = 7.25600004196167s
epoch 60: {'train_loss': '2.69959'}; time used = 7.201403379440308s
epoch 65: {'train_loss': '2.69782'}; time used = 7.18602991104126s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 126.4432282447815.
Training classifier using 80.00% nodes...
{'micro': 0.48333333333333334, 'macro': 0.4396391064228565, 'samples': 0.48333333333333334, 'weighted': 0.431823067558529, 'accuracy': 0.48333333333333334}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37178'}; time used = 1.8644177913665771s
epoch 10: {'train_loss': '1.28211'}; time used = 2.076582670211792s
epoch 15: {'train_loss': '1.04731'}; time used = 2.331390857696533s
epoch 20: {'train_loss': '0.71877'}; time used = 2.0982437133789062s
epoch 25: {'train_loss': '0.29404'}; time used = 2.2280242443084717s
epoch 30: {'train_loss': '0.20968'}; time used = 2.1110026836395264s
epoch 35: {'train_loss': '0.48877'}; time used = 2.252918004989624s
epoch 40: {'train_loss': '0.23870'}; time used = 1.9553215503692627s
epoch 45: {'train_loss': '0.40210'}; time used = 1.9056212902069092s
epoch 50: {'train_loss': '0.11104'}; time used = 2.117687702178955s
epoch 55: {'train_loss': '0.01336'}; time used = 2.064584970474243s
epoch 60: {'train_loss': '0.17405'}; time used = 1.976241111755371s
epoch 65: {'train_loss': '0.23126'}; time used = 1.9367311000823975s
epoch 70: {'train_loss': '0.12578'}; time used = 2.063178539276123s
epoch 75: {'train_loss': '0.23170'}; time used = 2.565378189086914s
epoch 80: {'train_loss': '0.45521'}; time used = 1.8762941360473633s
epoch 85: {'train_loss': '0.01548'}; time used = 1.9440641403198242s
epoch 90: {'train_loss': '0.01160'}; time used = 1.8679189682006836s
epoch 95: {'train_loss': '0.40801'}; time used = 1.776456356048584s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.74566197395325.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5213369770863989, 'samples': 0.5217391304347826, 'weighted': 0.522342360457358, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77177'}; time used = 1.2106399536132812s
epoch 10: {'train_loss': '2.77366'}; time used = 1.167551040649414s
epoch 15: {'train_loss': '2.77801'}; time used = 1.361419677734375s
epoch 20: {'train_loss': '2.77524'}; time used = 1.2744779586791992s
epoch 25: {'train_loss': '2.77225'}; time used = 1.1912024021148682s
epoch 30: {'train_loss': '2.77254'}; time used = 1.1977119445800781s
epoch 35: {'train_loss': '2.77252'}; time used = 1.0501608848571777s
epoch 40: {'train_loss': '2.77198'}; time used = 1.113013744354248s
epoch 45: {'train_loss': '2.77244'}; time used = 1.1624834537506104s
epoch 50: {'train_loss': '2.77176'}; time used = 1.1409509181976318s
epoch 55: {'train_loss': '2.77115'}; time used = 1.0995607376098633s
epoch 60: {'train_loss': '2.77107'}; time used = 1.1478831768035889s
epoch 65: {'train_loss': '2.77083'}; time used = 1.1460978984832764s
epoch 70: {'train_loss': '2.76816'}; time used = 1.160367727279663s
epoch 75: {'train_loss': '2.76923'}; time used = 1.0845434665679932s
epoch 80: {'train_loss': '2.76793'}; time used = 1.240816354751587s
epoch 85: {'train_loss': '2.76855'}; time used = 1.0450639724731445s
epoch 90: {'train_loss': '2.77850'}; time used = 1.09559965133667s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.467500686645508.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.55 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.27720'}; time used = 1.969822883605957s
epoch 10: {'train_loss': '2.89442'}; time used = 1.8361737728118896s
epoch 15: {'train_loss': '2.83683'}; time used = 1.8879191875457764s
epoch 20: {'train_loss': '2.78746'}; time used = 1.9255502223968506s
epoch 25: {'train_loss': '2.77191'}; time used = 2.095876932144165s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.10835099220276.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.96185'}; time used = 1.5044662952423096s
epoch 10: {'train_loss': '2.64246'}; time used = 0.9414281845092773s
epoch 15: {'train_loss': '2.55063'}; time used = 1.1701316833496094s
epoch 20: {'train_loss': '2.49812'}; time used = 1.0751500129699707s
epoch 25: {'train_loss': '2.46398'}; time used = 1.0225601196289062s
epoch 30: {'train_loss': '2.36473'}; time used = 0.9821207523345947s
epoch 35: {'train_loss': '2.28171'}; time used = 1.0551331043243408s
epoch 40: {'train_loss': '2.18337'}; time used = 1.082075834274292s
epoch 45: {'train_loss': '2.13867'}; time used = 0.9763040542602539s
epoch 50: {'train_loss': '2.15672'}; time used = 0.953183650970459s
epoch 55: {'train_loss': '2.13096'}; time used = 0.9508769512176514s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.814305782318115.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.83524'}; time used = 3.5841281414031982s
epoch 10: {'train_loss': '2.78227'}; time used = 3.081789016723633s
epoch 15: {'train_loss': '2.77518'}; time used = 2.176607847213745s
epoch 20: {'train_loss': '2.77085'}; time used = 2.491546869277954s
epoch 25: {'train_loss': '2.76241'}; time used = 2.4058725833892822s
epoch 30: {'train_loss': '2.75404'}; time used = 2.221013069152832s
epoch 35: {'train_loss': '2.72837'}; time used = 2.1338284015655518s
epoch 40: {'train_loss': '2.67444'}; time used = 2.2063162326812744s
epoch 45: {'train_loss': '2.61074'}; time used = 2.1497247219085693s
epoch 50: {'train_loss': '2.54520'}; time used = 2.035902976989746s
epoch 55: {'train_loss': '2.53606'}; time used = 2.2390103340148926s
epoch 60: {'train_loss': '2.52760'}; time used = 2.537667989730835s
epoch 65: {'train_loss': '2.49434'}; time used = 2.566389799118042s
epoch 70: {'train_loss': '2.47069'}; time used = 2.2675576210021973s
epoch 75: {'train_loss': '2.42366'}; time used = 2.1471259593963623s
epoch 80: {'train_loss': '2.42395'}; time used = 2.328446626663208s
epoch 85: {'train_loss': '2.42064'}; time used = 2.0741968154907227s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.13517236709595.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.6057142857142858, 'samples': 0.6086956521739131, 'weighted': 0.6081987577639751, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79304'}; time used = 1.729478359222412s
epoch 10: {'train_loss': '2.75068'}; time used = 1.4313602447509766s
epoch 15: {'train_loss': '2.75598'}; time used = 1.4523310661315918s
epoch 20: {'train_loss': '2.67619'}; time used = 1.6324529647827148s
epoch 25: {'train_loss': '2.59397'}; time used = 1.5934534072875977s
epoch 30: {'train_loss': '2.42593'}; time used = 2.143915891647339s
epoch 35: {'train_loss': '2.23404'}; time used = 2.14565110206604s
epoch 40: {'train_loss': '2.14843'}; time used = 2.1515204906463623s
epoch 45: {'train_loss': '2.09830'}; time used = 2.255220890045166s
epoch 50: {'train_loss': '2.10948'}; time used = 2.437042236328125s
epoch 55: {'train_loss': '2.05336'}; time used = 1.6712772846221924s
epoch 60: {'train_loss': '2.00469'}; time used = 1.5849084854125977s
epoch 65: {'train_loss': '1.98151'}; time used = 1.4316987991333008s
epoch 70: {'train_loss': '1.96824'}; time used = 1.4418251514434814s
epoch 75: {'train_loss': '1.87812'}; time used = 1.4326553344726562s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.484705686569214.
Training classifier using 80.00% nodes...
{'micro': 0.5526315789473685, 'macro': 0.4406926406926407, 'samples': 0.5526315789473685, 'weighted': 0.4802005012531328, 'accuracy': 0.5526315789473685}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.05 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.33787'}; time used = 3.89428973197937s
epoch 10: {'train_loss': '1.23930'}; time used = 3.7910311222076416s
epoch 15: {'train_loss': '1.21687'}; time used = 3.4967992305755615s
epoch 20: {'train_loss': '1.29424'}; time used = 2.322221040725708s
epoch 25: {'train_loss': '1.24467'}; time used = 2.3823208808898926s
epoch 30: {'train_loss': '1.21680'}; time used = 2.0618197917938232s
epoch 35: {'train_loss': '1.24978'}; time used = 2.139955759048462s
epoch 40: {'train_loss': '1.18063'}; time used = 2.2339422702789307s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.26254630088806.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5353535353535354, 'samples': 0.5362318840579711, 'weighted': 0.5368174498609282, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.43635'}; time used = 7.067591667175293s
epoch 10: {'train_loss': '2.82427'}; time used = 6.809699058532715s
epoch 15: {'train_loss': '2.83111'}; time used = 6.5811073780059814s
epoch 20: {'train_loss': '2.84291'}; time used = 7.631205797195435s
epoch 25: {'train_loss': '2.82756'}; time used = 7.197169303894043s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.13899278640747.
Training classifier using 80.00% nodes...
{'micro': 0.51, 'macro': 0.4894240128899554, 'samples': 0.51, 'weighted': 0.48415305720913904, 'accuracy': 0.51}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.98090'}; time used = 1.7060937881469727s
epoch 10: {'train_loss': '2.78990'}; time used = 1.9320073127746582s
epoch 15: {'train_loss': '2.74067'}; time used = 1.7780261039733887s
epoch 20: {'train_loss': '2.72098'}; time used = 1.8238565921783447s
epoch 25: {'train_loss': '2.70811'}; time used = 1.7907078266143799s
epoch 30: {'train_loss': '2.68986'}; time used = 2.664686441421509s
epoch 35: {'train_loss': '2.66783'}; time used = 2.909745216369629s
epoch 40: {'train_loss': '2.63268'}; time used = 3.148305654525757s
epoch 45: {'train_loss': '2.62053'}; time used = 2.5503644943237305s
epoch 50: {'train_loss': '2.58746'}; time used = 1.9892020225524902s
epoch 55: {'train_loss': '2.58398'}; time used = 2.036634683609009s
epoch 60: {'train_loss': '2.57356'}; time used = 2.715491771697998s
epoch 65: {'train_loss': '2.54888'}; time used = 1.9799907207489014s
epoch 70: {'train_loss': '2.53020'}; time used = 1.7639524936676025s
epoch 75: {'train_loss': '2.49666'}; time used = 1.7381808757781982s
epoch 80: {'train_loss': '2.49688'}; time used = 1.8441932201385498s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.90753173828125.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5706929843381249, 'samples': 0.5797101449275363, 'weighted': 0.5752015646328306, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.28 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39748'}; time used = 1.176501989364624s
epoch 10: {'train_loss': '1.38228'}; time used = 1.2142844200134277s
epoch 15: {'train_loss': '1.29866'}; time used = 1.1122729778289795s
epoch 20: {'train_loss': '1.30379'}; time used = 1.103381872177124s
epoch 25: {'train_loss': '1.14184'}; time used = 1.1175248622894287s
epoch 30: {'train_loss': '1.11752'}; time used = 2.277878761291504s
epoch 35: {'train_loss': '0.97928'}; time used = 2.602330207824707s
epoch 40: {'train_loss': '1.24023'}; time used = 2.4810805320739746s
epoch 45: {'train_loss': '0.96694'}; time used = 2.4354770183563232s
epoch 50: {'train_loss': '0.99408'}; time used = 2.5883028507232666s
epoch 55: {'train_loss': '0.85809'}; time used = 2.360527515411377s
epoch 60: {'train_loss': '1.05316'}; time used = 1.1394929885864258s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.035695791244507.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7564102564102564, 'samples': 0.7894736842105263, 'weighted': 0.7705802968960862, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.38046'}; time used = 2.718583583831787s
epoch 10: {'train_loss': '1.23765'}; time used = 3.9028751850128174s
epoch 15: {'train_loss': '1.23485'}; time used = 3.638476848602295s
epoch 20: {'train_loss': '1.15786'}; time used = 3.7704906463623047s
epoch 25: {'train_loss': '1.16269'}; time used = 1.989802360534668s
epoch 30: {'train_loss': '1.21929'}; time used = 1.9733128547668457s
epoch 35: {'train_loss': '1.11815'}; time used = 2.2014710903167725s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.12698793411255.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.486815415821501, 'samples': 0.5217391304347826, 'weighted': 0.4965164476585237, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.09305'}; time used = 1.290848731994629s
epoch 10: {'train_loss': '2.79745'}; time used = 1.2848072052001953s
epoch 15: {'train_loss': '2.77535'}; time used = 1.2579808235168457s
epoch 20: {'train_loss': '2.78100'}; time used = 1.0731141567230225s
epoch 25: {'train_loss': '2.78365'}; time used = 1.2254159450531006s
epoch 30: {'train_loss': '2.78110'}; time used = 1.2176260948181152s
epoch 35: {'train_loss': '2.77912'}; time used = 1.1066398620605469s
epoch 40: {'train_loss': '2.77680'}; time used = 1.0932729244232178s
epoch 45: {'train_loss': '2.77404'}; time used = 1.055217981338501s
epoch 50: {'train_loss': '2.77275'}; time used = 1.0818183422088623s
epoch 55: {'train_loss': '2.77240'}; time used = 1.1936616897583008s
epoch 60: {'train_loss': '2.77310'}; time used = 1.0485234260559082s
epoch 65: {'train_loss': '2.77260'}; time used = 1.0821514129638672s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.856963634490967.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.39517'}; time used = 1.192636489868164s
epoch 10: {'train_loss': '1.38261'}; time used = 1.0610289573669434s
epoch 15: {'train_loss': '1.34414'}; time used = 1.0915329456329346s
epoch 20: {'train_loss': '1.34436'}; time used = 1.1996009349822998s
epoch 25: {'train_loss': '1.31979'}; time used = 1.18729829788208s
epoch 30: {'train_loss': '1.30152'}; time used = 1.180990219116211s
epoch 35: {'train_loss': '1.27288'}; time used = 1.222217321395874s
epoch 40: {'train_loss': '1.22149'}; time used = 1.1417975425720215s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.41049861907959.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.84264'}; time used = 1.60227370262146s
epoch 10: {'train_loss': '2.77450'}; time used = 1.374892234802246s
epoch 15: {'train_loss': '2.78142'}; time used = 1.7148046493530273s
epoch 20: {'train_loss': '2.78407'}; time used = 1.3779199123382568s
epoch 25: {'train_loss': '2.77319'}; time used = 1.7190206050872803s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.677313566207886.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38235'}; time used = 1.293553352355957s
epoch 10: {'train_loss': '1.39789'}; time used = 1.3998498916625977s
epoch 15: {'train_loss': '1.28103'}; time used = 1.2619807720184326s
epoch 20: {'train_loss': '1.34319'}; time used = 1.1394917964935303s
epoch 25: {'train_loss': '1.19762'}; time used = 2.1676816940307617s
epoch 30: {'train_loss': '1.24579'}; time used = 3.9959769248962402s
epoch 35: {'train_loss': '1.26575'}; time used = 3.616178035736084s
epoch 40: {'train_loss': '1.18500'}; time used = 3.503993034362793s
epoch 45: {'train_loss': '1.06305'}; time used = 1.1945922374725342s
epoch 50: {'train_loss': '1.13187'}; time used = 1.1101129055023193s
epoch 55: {'train_loss': '1.18416'}; time used = 1.1305522918701172s
epoch 60: {'train_loss': '1.23856'}; time used = 1.2138519287109375s
epoch 65: {'train_loss': '1.11126'}; time used = 1.1710162162780762s
epoch 70: {'train_loss': '1.21572'}; time used = 1.1594586372375488s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.496363401412964.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.19 GiB free; 24.69 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.81097'}; time used = 1.1425485610961914s
epoch 10: {'train_loss': '2.70174'}; time used = 1.226609230041504s
epoch 15: {'train_loss': '2.61865'}; time used = 1.0461077690124512s
epoch 20: {'train_loss': '2.53021'}; time used = 1.0912773609161377s
epoch 25: {'train_loss': '2.41663'}; time used = 1.1045193672180176s
epoch 30: {'train_loss': '2.28663'}; time used = 1.0377857685089111s
epoch 35: {'train_loss': '2.14908'}; time used = 1.1975419521331787s
epoch 40: {'train_loss': '2.05308'}; time used = 1.0340139865875244s
epoch 45: {'train_loss': '2.07825'}; time used = 1.2430641651153564s
epoch 50: {'train_loss': '1.92941'}; time used = 1.214416742324829s
epoch 55: {'train_loss': '1.85995'}; time used = 1.04520583152771s
epoch 60: {'train_loss': '1.83577'}; time used = 1.148296594619751s
epoch 65: {'train_loss': '1.80003'}; time used = 1.054276704788208s
epoch 70: {'train_loss': '1.81352'}; time used = 1.1203320026397705s
epoch 75: {'train_loss': '1.78316'}; time used = 1.2793586254119873s
epoch 80: {'train_loss': '1.78766'}; time used = 1.962684154510498s
epoch 85: {'train_loss': '1.83035'}; time used = 1.8172845840454102s
epoch 90: {'train_loss': '1.81531'}; time used = 1.8117890357971191s
epoch 95: {'train_loss': '1.80666'}; time used = 1.704833984375s
epoch 100: {'train_loss': '1.82455'}; time used = 1.9411308765411377s
epoch 105: {'train_loss': '1.79672'}; time used = 1.9818191528320312s
epoch 110: {'train_loss': '1.79161'}; time used = 1.3523378372192383s
epoch 115: {'train_loss': '1.78099'}; time used = 0.9975049495697021s
epoch 120: {'train_loss': '1.77390'}; time used = 1.1211891174316406s
epoch 125: {'train_loss': '1.78760'}; time used = 1.134671926498413s
epoch 130: {'train_loss': '1.76338'}; time used = 1.1007137298583984s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.89379549026489.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79562'}; time used = 4.072091817855835s
epoch 10: {'train_loss': '2.78020'}; time used = 3.721710681915283s
epoch 15: {'train_loss': '2.77403'}; time used = 2.914433002471924s
epoch 20: {'train_loss': '2.76854'}; time used = 1.9794766902923584s
epoch 25: {'train_loss': '2.76718'}; time used = 1.9819207191467285s
epoch 30: {'train_loss': '2.76244'}; time used = 2.384148359298706s
epoch 35: {'train_loss': '2.75909'}; time used = 2.4455361366271973s
epoch 40: {'train_loss': '2.75784'}; time used = 2.0302040576934814s
epoch 45: {'train_loss': '2.75734'}; time used = 2.00382399559021s
epoch 50: {'train_loss': '2.75243'}; time used = 2.14353084564209s
epoch 55: {'train_loss': '2.75420'}; time used = 2.2391514778137207s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.78324055671692.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.78006'}; time used = 1.348698616027832s
epoch 10: {'train_loss': '2.77293'}; time used = 1.3445773124694824s
epoch 15: {'train_loss': '2.77939'}; time used = 1.3839564323425293s
epoch 20: {'train_loss': '2.78122'}; time used = 1.3290448188781738s
epoch 25: {'train_loss': '2.77513'}; time used = 1.227309226989746s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.404336214065552.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.82 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.23541'}; time used = 1.6280040740966797s
epoch 10: {'train_loss': '2.81589'}; time used = 1.2983896732330322s
epoch 15: {'train_loss': '2.71810'}; time used = 1.3561508655548096s
epoch 20: {'train_loss': '2.71514'}; time used = 1.3522937297821045s
epoch 25: {'train_loss': '2.66447'}; time used = 1.371330976486206s
epoch 30: {'train_loss': '2.55360'}; time used = 1.3305268287658691s
epoch 35: {'train_loss': '2.42875'}; time used = 1.3854882717132568s
epoch 40: {'train_loss': '2.32276'}; time used = 1.454664945602417s
epoch 45: {'train_loss': '2.22668'}; time used = 1.3254783153533936s
epoch 50: {'train_loss': '2.18841'}; time used = 1.315739393234253s
epoch 55: {'train_loss': '2.10693'}; time used = 1.3490748405456543s
epoch 60: {'train_loss': '2.10022'}; time used = 1.423583745956421s
epoch 65: {'train_loss': '2.07516'}; time used = 1.3012974262237549s
epoch 70: {'train_loss': '2.05259'}; time used = 1.3498120307922363s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.599101781845093.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.86436'}; time used = 1.2901015281677246s
epoch 10: {'train_loss': '2.80056'}; time used = 2.098418712615967s
epoch 15: {'train_loss': '2.78697'}; time used = 2.2442007064819336s
epoch 20: {'train_loss': '2.77888'}; time used = 2.1470961570739746s
epoch 25: {'train_loss': '2.77275'}; time used = 2.314465045928955s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.534837484359741.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.33978'}; time used = 2.045330286026001s
epoch 10: {'train_loss': '1.21379'}; time used = 2.3680620193481445s
epoch 15: {'train_loss': '1.17053'}; time used = 2.5790092945098877s
epoch 20: {'train_loss': '1.17577'}; time used = 3.8011233806610107s
epoch 25: {'train_loss': '1.12283'}; time used = 4.23646879196167s
epoch 30: {'train_loss': '1.01994'}; time used = 3.6628003120422363s
epoch 35: {'train_loss': '0.96113'}; time used = 2.100367784500122s
epoch 40: {'train_loss': '0.92867'}; time used = 1.96384859085083s
epoch 45: {'train_loss': '0.91964'}; time used = 2.1949453353881836s
epoch 50: {'train_loss': '0.75582'}; time used = 2.1856069564819336s
epoch 55: {'train_loss': '0.65620'}; time used = 2.25496506690979s
epoch 60: {'train_loss': '0.73388'}; time used = 2.0880188941955566s
epoch 65: {'train_loss': '0.80339'}; time used = 3.56026554107666s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.06473469734192.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6393728222996516, 'samples': 0.6521739130434783, 'weighted': 0.644296318739585, 'accuracy': 0.6521739130434783}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.37598'}; time used = 2.84918475151062s
epoch 10: {'train_loss': '1.33216'}; time used = 2.514615535736084s
epoch 15: {'train_loss': '1.33438'}; time used = 2.9791762828826904s
epoch 20: {'train_loss': '1.39671'}; time used = 4.360318660736084s
epoch 25: {'train_loss': '1.34840'}; time used = 4.031911849975586s
epoch 30: {'train_loss': '1.29639'}; time used = 4.128976345062256s
epoch 35: {'train_loss': '1.28202'}; time used = 2.1892850399017334s
epoch 40: {'train_loss': '1.26790'}; time used = 2.056368589401245s
epoch 45: {'train_loss': '1.28630'}; time used = 2.3605427742004395s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.0321204662323.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.5012048192771084, 'samples': 0.5217391304347826, 'weighted': 0.5085385018334206, 'accuracy': 0.5217391304347826}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.82611'}; time used = 1.2639665603637695s
epoch 10: {'train_loss': '0.78444'}; time used = 1.062281608581543s
epoch 15: {'train_loss': '0.39401'}; time used = 1.03377366065979s
epoch 20: {'train_loss': '0.23668'}; time used = 1.041280746459961s
epoch 25: {'train_loss': '0.19818'}; time used = 1.1809170246124268s
epoch 30: {'train_loss': '0.16270'}; time used = 1.2121944427490234s
epoch 35: {'train_loss': '0.09567'}; time used = 4.173025608062744s
epoch 40: {'train_loss': '0.06757'}; time used = 3.9338159561157227s
epoch 45: {'train_loss': '0.07765'}; time used = 4.076488494873047s
epoch 50: {'train_loss': '0.11079'}; time used = 2.0024607181549072s
epoch 55: {'train_loss': '0.10551'}; time used = 1.1434946060180664s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.015615224838257.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.38046'}; time used = 1.9773573875427246s
epoch 10: {'train_loss': '1.23765'}; time used = 1.823625087738037s
epoch 15: {'train_loss': '1.23485'}; time used = 1.9493591785430908s
epoch 20: {'train_loss': '1.15786'}; time used = 1.9697010517120361s
epoch 25: {'train_loss': '1.16269'}; time used = 2.0480217933654785s
epoch 30: {'train_loss': '1.21929'}; time used = 1.8428406715393066s
epoch 35: {'train_loss': '1.11815'}; time used = 2.029693603515625s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.659464597702026.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.486815415821501, 'samples': 0.5217391304347826, 'weighted': 0.4965164476585237, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.35756'}; time used = 2.146162271499634s
epoch 10: {'train_loss': '2.82572'}; time used = 2.0761845111846924s
epoch 15: {'train_loss': '2.79383'}; time used = 2.4498085975646973s
epoch 20: {'train_loss': '2.79172'}; time used = 2.0386645793914795s
epoch 25: {'train_loss': '2.79287'}; time used = 2.0885753631591797s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.696365118026733.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.80502'}; time used = 1.0974173545837402s
epoch 10: {'train_loss': '2.70076'}; time used = 1.0865707397460938s
epoch 15: {'train_loss': '2.62915'}; time used = 1.127847671508789s
epoch 20: {'train_loss': '2.53432'}; time used = 1.2639870643615723s
epoch 25: {'train_loss': '2.42489'}; time used = 1.308401346206665s
epoch 30: {'train_loss': '2.28964'}; time used = 1.1408445835113525s
epoch 35: {'train_loss': '2.13895'}; time used = 1.176177740097046s
epoch 40: {'train_loss': '2.02806'}; time used = 1.2529938220977783s
epoch 45: {'train_loss': '2.02019'}; time used = 1.1824934482574463s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.627197980880737.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.55 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.44084'}; time used = 1.0729668140411377s
epoch 10: {'train_loss': '0.26903'}; time used = 1.019005298614502s
epoch 15: {'train_loss': '0.28154'}; time used = 1.0131118297576904s
epoch 20: {'train_loss': '0.25562'}; time used = 1.003502607345581s
epoch 25: {'train_loss': '0.29112'}; time used = 1.0590944290161133s
epoch 30: {'train_loss': '0.24123'}; time used = 1.1066720485687256s
epoch 35: {'train_loss': '0.27526'}; time used = 1.1528825759887695s
epoch 40: {'train_loss': '0.21563'}; time used = 1.2547509670257568s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.926580905914307.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.38432'}; time used = 2.773212194442749s
epoch 10: {'train_loss': '1.34796'}; time used = 2.944540500640869s
epoch 15: {'train_loss': '1.38288'}; time used = 4.351818323135376s
epoch 20: {'train_loss': '1.44774'}; time used = 4.248113393783569s
epoch 25: {'train_loss': '1.42706'}; time used = 3.71156644821167s
epoch 30: {'train_loss': '1.39426'}; time used = 2.676316261291504s
epoch 35: {'train_loss': '1.37693'}; time used = 2.620826482772827s
epoch 40: {'train_loss': '1.35806'}; time used = 2.6793906688690186s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.79733920097351.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5836206896551723, 'samples': 0.5942028985507246, 'weighted': 0.588430784607696, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.18819'}; time used = 2.018136501312256s
epoch 10: {'train_loss': '0.53207'}; time used = 1.8612675666809082s
epoch 15: {'train_loss': '0.44285'}; time used = 1.8347158432006836s
epoch 20: {'train_loss': '0.36828'}; time used = 1.8798387050628662s
epoch 25: {'train_loss': '0.30778'}; time used = 1.9786651134490967s
epoch 30: {'train_loss': '0.26827'}; time used = 2.0958292484283447s
epoch 35: {'train_loss': '0.26937'}; time used = 1.9675133228302002s
epoch 40: {'train_loss': '0.28663'}; time used = 1.7368550300598145s
epoch 45: {'train_loss': '0.28766'}; time used = 1.8092930316925049s
epoch 50: {'train_loss': '0.28693'}; time used = 1.7960612773895264s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.82331109046936.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.93310'}; time used = 1.1270947456359863s
epoch 10: {'train_loss': '0.63313'}; time used = 1.121244192123413s
epoch 15: {'train_loss': '0.49203'}; time used = 1.139589786529541s
epoch 20: {'train_loss': '0.38866'}; time used = 1.1944208145141602s
epoch 25: {'train_loss': '0.38806'}; time used = 1.1921460628509521s
epoch 30: {'train_loss': '0.29751'}; time used = 1.2455973625183105s
epoch 35: {'train_loss': '0.31816'}; time used = 1.2007339000701904s
epoch 40: {'train_loss': '0.28106'}; time used = 1.296217679977417s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.748429298400879.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.09305'}; time used = 1.2611157894134521s
epoch 10: {'train_loss': '2.79745'}; time used = 1.1846880912780762s
epoch 15: {'train_loss': '2.77535'}; time used = 1.1304831504821777s
epoch 20: {'train_loss': '2.78100'}; time used = 1.2054104804992676s
epoch 25: {'train_loss': '2.78365'}; time used = 1.2143216133117676s
epoch 30: {'train_loss': '2.78110'}; time used = 1.2384240627288818s
epoch 35: {'train_loss': '2.77912'}; time used = 1.099555253982544s
epoch 40: {'train_loss': '2.77680'}; time used = 1.2281067371368408s
epoch 45: {'train_loss': '2.77404'}; time used = 1.1731066703796387s
epoch 50: {'train_loss': '2.77275'}; time used = 1.1077933311462402s
epoch 55: {'train_loss': '2.77240'}; time used = 1.242461919784546s
epoch 60: {'train_loss': '2.77310'}; time used = 1.194995403289795s
epoch 65: {'train_loss': '2.77260'}; time used = 1.1287903785705566s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.902612924575806.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.79429'}; time used = 2.693391799926758s
epoch 10: {'train_loss': '2.82693'}; time used = 2.6466615200042725s
epoch 15: {'train_loss': '2.77315'}; time used = 2.629920721054077s
epoch 20: {'train_loss': '2.76507'}; time used = 2.5333852767944336s
epoch 25: {'train_loss': '2.76306'}; time used = 2.6318776607513428s
epoch 30: {'train_loss': '2.74754'}; time used = 2.4673867225646973s
epoch 35: {'train_loss': '2.72452'}; time used = 2.6067965030670166s
epoch 40: {'train_loss': '2.71689'}; time used = 2.5305538177490234s
epoch 45: {'train_loss': '2.68408'}; time used = 2.6592273712158203s
epoch 50: {'train_loss': '2.65931'}; time used = 2.525848865509033s
epoch 55: {'train_loss': '2.61870'}; time used = 2.644975423812866s
epoch 60: {'train_loss': '2.98148'}; time used = 2.583803415298462s
epoch 65: {'train_loss': '2.61622'}; time used = 2.6021029949188232s
epoch 70: {'train_loss': '2.63300'}; time used = 2.5005850791931152s
epoch 75: {'train_loss': '2.53056'}; time used = 2.4563467502593994s
epoch 80: {'train_loss': '2.51244'}; time used = 2.5030484199523926s
epoch 85: {'train_loss': '2.46501'}; time used = 2.4679675102233887s
epoch 90: {'train_loss': '2.45561'}; time used = 2.476832151412964s
epoch 95: {'train_loss': '2.42158'}; time used = 2.463642120361328s
epoch 100: {'train_loss': '2.39969'}; time used = 2.465719699859619s
epoch 105: {'train_loss': '2.40677'}; time used = 2.5985019207000732s
epoch 110: {'train_loss': '2.39352'}; time used = 2.537881374359131s
epoch 115: {'train_loss': '2.38969'}; time used = 2.410165309906006s
epoch 120: {'train_loss': '2.35077'}; time used = 2.609363317489624s
epoch 125: {'train_loss': '2.38618'}; time used = 2.4693496227264404s
epoch 130: {'train_loss': '2.33722'}; time used = 3.0323486328125s
epoch 135: {'train_loss': '2.33185'}; time used = 3.6155850887298584s
epoch 140: {'train_loss': '2.33463'}; time used = 2.474353313446045s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 77.33012342453003.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.6327443048754524, 'samples': 0.6376811594202898, 'weighted': 0.6358298389659759, 'accuracy': 0.6376811594202898}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.87431'}; time used = 1.846299648284912s
epoch 10: {'train_loss': '2.79271'}; time used = 1.7749311923980713s
epoch 15: {'train_loss': '2.78810'}; time used = 1.9888174533843994s
epoch 20: {'train_loss': '2.77761'}; time used = 1.9520483016967773s
epoch 25: {'train_loss': '2.77210'}; time used = 2.208209753036499s
epoch 30: {'train_loss': '2.77173'}; time used = 2.6719350814819336s
epoch 35: {'train_loss': '2.77060'}; time used = 2.1278650760650635s
epoch 40: {'train_loss': '2.76982'}; time used = 2.0241177082061768s
epoch 45: {'train_loss': '2.76867'}; time used = 2.1185967922210693s
epoch 50: {'train_loss': '2.76816'}; time used = 1.8109121322631836s
epoch 55: {'train_loss': '2.76721'}; time used = 1.7976844310760498s
epoch 60: {'train_loss': '2.76533'}; time used = 1.9089388847351074s
epoch 65: {'train_loss': '2.75994'}; time used = 1.8313002586364746s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.51284146308899.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5538793103448276, 'samples': 0.5652173913043478, 'weighted': 0.5590329835082459, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.09353'}; time used = 3.428555727005005s
epoch 10: {'train_loss': '2.82458'}; time used = 3.3479244709014893s
epoch 15: {'train_loss': '2.83091'}; time used = 1.2622439861297607s
epoch 20: {'train_loss': '2.81199'}; time used = 1.3245575428009033s
epoch 25: {'train_loss': '2.79632'}; time used = 1.206925392150879s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.599298000335693.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.77233'}; time used = 6.174977540969849s
epoch 10: {'train_loss': '2.76381'}; time used = 4.142151355743408s
epoch 15: {'train_loss': '2.75679'}; time used = 2.856583595275879s
epoch 20: {'train_loss': '2.72788'}; time used = 2.4374516010284424s
epoch 25: {'train_loss': '2.72497'}; time used = 2.2553963661193848s
epoch 30: {'train_loss': '2.71437'}; time used = 1.9029312133789062s
epoch 35: {'train_loss': '2.71373'}; time used = 1.6701648235321045s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 45.93346333503723.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5095161660169686, 'samples': 0.5507246376811594, 'weighted': 0.5198182839330163, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.84898'}; time used = 1.3865611553192139s
epoch 10: {'train_loss': '0.22916'}; time used = 1.085080862045288s
epoch 15: {'train_loss': '0.19918'}; time used = 0.9443135261535645s
epoch 20: {'train_loss': '0.14971'}; time used = 0.9706518650054932s
epoch 25: {'train_loss': '0.16390'}; time used = 1.0078885555267334s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.574636936187744.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.79102'}; time used = 2.143612861633301s
epoch 10: {'train_loss': '2.89206'}; time used = 2.0473623275756836s
epoch 15: {'train_loss': '2.80853'}; time used = 2.2152438163757324s
epoch 20: {'train_loss': '2.77795'}; time used = 2.1852142810821533s
epoch 25: {'train_loss': '2.76984'}; time used = 2.276670455932617s
epoch 30: {'train_loss': '2.76829'}; time used = 2.082813262939453s
epoch 35: {'train_loss': '2.76940'}; time used = 2.27321457862854s
epoch 40: {'train_loss': '2.76972'}; time used = 2.4448604583740234s
epoch 45: {'train_loss': '2.76704'}; time used = 4.121078729629517s
epoch 50: {'train_loss': '2.76368'}; time used = 2.2408359050750732s
epoch 55: {'train_loss': '2.76360'}; time used = 2.299839973449707s
epoch 60: {'train_loss': '2.75601'}; time used = 2.169790267944336s
epoch 65: {'train_loss': '2.75219'}; time used = 2.0823898315429688s
epoch 70: {'train_loss': '2.75363'}; time used = 2.0765249729156494s
epoch 75: {'train_loss': '2.74528'}; time used = 2.1363558769226074s
epoch 80: {'train_loss': '2.75005'}; time used = 2.125393867492676s
epoch 85: {'train_loss': '2.74942'}; time used = 2.8386330604553223s
epoch 90: {'train_loss': '2.74016'}; time used = 2.522231340408325s
epoch 95: {'train_loss': '2.74095'}; time used = 1.9859511852264404s
epoch 100: {'train_loss': '2.74274'}; time used = 2.2132632732391357s
epoch 105: {'train_loss': '2.73485'}; time used = 2.035750389099121s
epoch 110: {'train_loss': '2.73735'}; time used = 2.4159302711486816s
epoch 115: {'train_loss': '2.72493'}; time used = 2.4044713973999023s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 61.02328944206238.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.38186'}; time used = 1.4597744941711426s
epoch 10: {'train_loss': '1.38366'}; time used = 1.3132638931274414s
epoch 15: {'train_loss': '1.32687'}; time used = 1.252943992614746s
epoch 20: {'train_loss': '1.32667'}; time used = 1.3383989334106445s
epoch 25: {'train_loss': '1.30081'}; time used = 1.2763535976409912s
epoch 30: {'train_loss': '1.27598'}; time used = 1.4640352725982666s
epoch 35: {'train_loss': '1.28205'}; time used = 1.0577037334442139s
epoch 40: {'train_loss': '1.19843'}; time used = 1.098513126373291s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.722542524337769.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.25430'}; time used = 4.063048839569092s
epoch 10: {'train_loss': '1.14738'}; time used = 4.768049478530884s
epoch 15: {'train_loss': '0.96616'}; time used = 2.769678831100464s
epoch 20: {'train_loss': '0.81602'}; time used = 2.251657724380493s
epoch 25: {'train_loss': '0.67486'}; time used = 2.2930145263671875s
epoch 30: {'train_loss': '0.59836'}; time used = 2.275202512741089s
epoch 35: {'train_loss': '0.62922'}; time used = 2.334688663482666s
epoch 40: {'train_loss': '0.54273'}; time used = 3.3247504234313965s
epoch 45: {'train_loss': '0.55112'}; time used = 3.4323699474334717s
epoch 50: {'train_loss': '0.60319'}; time used = 3.3791842460632324s
epoch 55: {'train_loss': '0.55153'}; time used = 2.3593358993530273s
epoch 60: {'train_loss': '0.51203'}; time used = 2.0957138538360596s
epoch 65: {'train_loss': '0.47154'}; time used = 2.181570053100586s
epoch 70: {'train_loss': '0.45369'}; time used = 2.05094313621521s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.29740929603577.
Training classifier using 80.00% nodes...
{'micro': 0.4782608695652174, 'macro': 0.3994197292069632, 'samples': 0.4782608695652174, 'weighted': 0.415187957278614, 'accuracy': 0.4782608695652174}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.35053'}; time used = 2.3216748237609863s
epoch 10: {'train_loss': '1.29218'}; time used = 2.263265371322632s
epoch 15: {'train_loss': '1.29437'}; time used = 2.1468729972839355s
epoch 20: {'train_loss': '1.41435'}; time used = 2.1342999935150146s
epoch 25: {'train_loss': '1.36588'}; time used = 2.3009798526763916s
epoch 30: {'train_loss': '1.32239'}; time used = 1.870476245880127s
epoch 35: {'train_loss': '1.30831'}; time used = 2.201836347579956s
epoch 40: {'train_loss': '1.28450'}; time used = 2.291168212890625s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.067999124526978.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38700'}; time used = 1.529353380203247s
epoch 10: {'train_loss': '1.39653'}; time used = 1.1518995761871338s
epoch 15: {'train_loss': '1.27109'}; time used = 1.2560338973999023s
epoch 20: {'train_loss': '1.32650'}; time used = 1.3295607566833496s
epoch 25: {'train_loss': '1.17288'}; time used = 2.36313533782959s
epoch 30: {'train_loss': '1.25951'}; time used = 2.805168867111206s
epoch 35: {'train_loss': '1.26976'}; time used = 2.7063348293304443s
epoch 40: {'train_loss': '1.20992'}; time used = 3.106459140777588s
epoch 45: {'train_loss': '1.01995'}; time used = 2.760514497756958s
epoch 50: {'train_loss': '1.11673'}; time used = 3.1342225074768066s
epoch 55: {'train_loss': '1.10382'}; time used = 3.100318431854248s
epoch 60: {'train_loss': '1.15426'}; time used = 3.135939359664917s
epoch 65: {'train_loss': '0.92887'}; time used = 2.8873510360717773s
epoch 70: {'train_loss': '1.33701'}; time used = 3.0804436206817627s
epoch 75: {'train_loss': '1.31823'}; time used = 2.4842581748962402s
epoch 80: {'train_loss': '1.02394'}; time used = 1.860304594039917s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 43.654462575912476.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7548387096774194, 'samples': 0.7631578947368421, 'weighted': 0.7619694397283531, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.19936'}; time used = 1.178889274597168s
epoch 10: {'train_loss': '0.86097'}; time used = 1.2452168464660645s
epoch 15: {'train_loss': '0.69403'}; time used = 1.1894738674163818s
epoch 20: {'train_loss': '0.59825'}; time used = 1.1171445846557617s
epoch 25: {'train_loss': '0.56724'}; time used = 1.2517366409301758s
epoch 30: {'train_loss': '0.57150'}; time used = 1.2237887382507324s
epoch 35: {'train_loss': '0.46929'}; time used = 1.3441078662872314s
epoch 40: {'train_loss': '0.37660'}; time used = 3.007481813430786s
epoch 45: {'train_loss': '0.31118'}; time used = 2.7869138717651367s
epoch 50: {'train_loss': '0.27177'}; time used = 2.8400168418884277s
epoch 55: {'train_loss': '0.27991'}; time used = 2.9580483436584473s
epoch 60: {'train_loss': '0.21765'}; time used = 2.7096424102783203s
epoch 65: {'train_loss': '0.20883'}; time used = 1.1732847690582275s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.352834463119507.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.731764705882353, 'samples': 0.7631578947368421, 'weighted': 0.7462538699690403, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79424'}; time used = 2.3407766819000244s
epoch 10: {'train_loss': '2.77626'}; time used = 2.0836970806121826s
epoch 15: {'train_loss': '2.77480'}; time used = 2.266092538833618s
epoch 20: {'train_loss': '2.76628'}; time used = 2.0607149600982666s
epoch 25: {'train_loss': '2.76485'}; time used = 2.0583930015563965s
epoch 30: {'train_loss': '2.76313'}; time used = 2.798720598220825s
epoch 35: {'train_loss': '2.75710'}; time used = 3.7421622276306152s
epoch 40: {'train_loss': '2.75797'}; time used = 3.8439815044403076s
epoch 45: {'train_loss': '2.75804'}; time used = 2.9848806858062744s
epoch 50: {'train_loss': '2.75664'}; time used = 2.0195844173431396s
epoch 55: {'train_loss': '2.76039'}; time used = 2.057033061981201s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.30529451370239.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.19792'}; time used = 1.1405727863311768s
epoch 10: {'train_loss': '0.10253'}; time used = 1.170027494430542s
epoch 15: {'train_loss': '0.08043'}; time used = 1.0804951190948486s
epoch 20: {'train_loss': '0.11600'}; time used = 1.2950258255004883s
epoch 25: {'train_loss': '0.14390'}; time used = 1.2435390949249268s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.057547569274902.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7548387096774194, 'samples': 0.7631578947368421, 'weighted': 0.7619694397283531, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.87784'}; time used = 1.979036569595337s
epoch 10: {'train_loss': '2.97629'}; time used = 1.9170572757720947s
epoch 15: {'train_loss': '2.88337'}; time used = 1.8887898921966553s
epoch 20: {'train_loss': '2.81858'}; time used = 2.093726873397827s
epoch 25: {'train_loss': '2.77828'}; time used = 2.0510175228118896s
epoch 30: {'train_loss': '2.74813'}; time used = 3.259089946746826s
epoch 35: {'train_loss': '2.72770'}; time used = 2.828674793243408s
epoch 40: {'train_loss': '2.69683'}; time used = 2.430326461791992s
epoch 45: {'train_loss': '2.65034'}; time used = 2.214596748352051s
epoch 50: {'train_loss': '2.58124'}; time used = 2.0163025856018066s
epoch 55: {'train_loss': '2.56778'}; time used = 2.169954299926758s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.407315492630005.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.37527'}; time used = 1.2279739379882812s
epoch 10: {'train_loss': '1.31943'}; time used = 1.1524856090545654s
epoch 15: {'train_loss': '1.19888'}; time used = 1.1963496208190918s
epoch 20: {'train_loss': '1.17722'}; time used = 1.3278019428253174s
epoch 25: {'train_loss': '0.98226'}; time used = 1.2216880321502686s
epoch 30: {'train_loss': '0.88744'}; time used = 1.1488008499145508s
epoch 35: {'train_loss': '0.80879'}; time used = 1.1788203716278076s
epoch 40: {'train_loss': '0.78523'}; time used = 1.181941032409668s
epoch 45: {'train_loss': '0.64944'}; time used = 1.0911400318145752s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.860321998596191.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.82722'}; time used = 2.083449602127075s
epoch 10: {'train_loss': '2.80633'}; time used = 1.9931960105895996s
epoch 15: {'train_loss': '2.77292'}; time used = 2.1740875244140625s
epoch 20: {'train_loss': '2.77816'}; time used = 1.9870216846466064s
epoch 25: {'train_loss': '2.76182'}; time used = 2.2099175453186035s
epoch 30: {'train_loss': '2.74023'}; time used = 2.0699095726013184s
epoch 35: {'train_loss': '2.72075'}; time used = 2.1818249225616455s
epoch 40: {'train_loss': '2.65556'}; time used = 2.2343297004699707s
epoch 45: {'train_loss': '2.60945'}; time used = 2.0126709938049316s
epoch 50: {'train_loss': '2.96715'}; time used = 2.8378453254699707s
epoch 55: {'train_loss': '2.65547'}; time used = 3.1760456562042236s
epoch 60: {'train_loss': '2.60284'}; time used = 2.0784459114074707s
epoch 65: {'train_loss': '2.61049'}; time used = 2.2233645915985107s
epoch 70: {'train_loss': '2.57646'}; time used = 2.201272964477539s
epoch 75: {'train_loss': '2.49736'}; time used = 2.5870609283447266s
epoch 80: {'train_loss': '2.49498'}; time used = 3.452502489089966s
epoch 85: {'train_loss': '2.47065'}; time used = 3.638315200805664s
epoch 90: {'train_loss': '2.49994'}; time used = 3.364048957824707s
epoch 95: {'train_loss': '2.46718'}; time used = 2.07323956489563s
epoch 100: {'train_loss': '2.43208'}; time used = 2.150999069213867s
epoch 105: {'train_loss': '2.44401'}; time used = 2.1348798274993896s
epoch 110: {'train_loss': '2.45231'}; time used = 2.1476120948791504s
epoch 115: {'train_loss': '2.41265'}; time used = 1.983769178390503s
epoch 120: {'train_loss': '2.42384'}; time used = 2.24241304397583s
epoch 125: {'train_loss': '2.42406'}; time used = 3.9190080165863037s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 65.14507031440735.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.6133620689655173, 'samples': 0.6231884057971014, 'weighted': 0.6178285857071465, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.26 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.07 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.78323'}; time used = 2.638913869857788s
epoch 10: {'train_loss': '2.77856'}; time used = 2.664745807647705s
epoch 15: {'train_loss': '2.77807'}; time used = 2.6910197734832764s
epoch 20: {'train_loss': '2.77501'}; time used = 2.829035758972168s
epoch 25: {'train_loss': '2.77193'}; time used = 2.1185965538024902s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.19049644470215.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.62014'}; time used = 1.2818679809570312s
epoch 10: {'train_loss': '2.44861'}; time used = 1.2742857933044434s
epoch 15: {'train_loss': '2.33860'}; time used = 2.003840923309326s
epoch 20: {'train_loss': '2.28007'}; time used = 2.3154449462890625s
epoch 25: {'train_loss': '2.19167'}; time used = 1.4774422645568848s
epoch 30: {'train_loss': '2.12509'}; time used = 1.1440327167510986s
epoch 35: {'train_loss': '2.11969'}; time used = 1.2596399784088135s
epoch 40: {'train_loss': '2.12698'}; time used = 1.077195644378662s
epoch 45: {'train_loss': '2.11748'}; time used = 1.0770273208618164s
epoch 50: {'train_loss': '2.13107'}; time used = 1.1372418403625488s
epoch 55: {'train_loss': '2.11267'}; time used = 1.0819940567016602s
epoch 60: {'train_loss': '2.09535'}; time used = 1.0715289115905762s
epoch 65: {'train_loss': '2.09993'}; time used = 1.0900797843933105s
epoch 70: {'train_loss': '2.10461'}; time used = 1.213402509689331s
epoch 75: {'train_loss': '2.07404'}; time used = 1.3184313774108887s
epoch 80: {'train_loss': '2.08792'}; time used = 1.149477243423462s
epoch 85: {'train_loss': '2.09473'}; time used = 1.1508333683013916s
epoch 90: {'train_loss': '2.05428'}; time used = 1.1452147960662842s
epoch 95: {'train_loss': '2.08513'}; time used = 1.0889708995819092s
epoch 100: {'train_loss': '2.10835'}; time used = 1.106260061264038s
epoch 105: {'train_loss': '2.08079'}; time used = 1.3773112297058105s
epoch 110: {'train_loss': '2.04892'}; time used = 1.3258435726165771s
epoch 115: {'train_loss': '2.06836'}; time used = 1.1064043045043945s
epoch 120: {'train_loss': '2.05550'}; time used = 1.111363172531128s
epoch 125: {'train_loss': '2.08525'}; time used = 1.0980818271636963s
epoch 130: {'train_loss': '2.06897'}; time used = 1.3003311157226562s
epoch 135: {'train_loss': '2.04491'}; time used = 1.8115553855895996s
epoch 140: {'train_loss': '2.06365'}; time used = 2.175893545150757s
epoch 145: {'train_loss': '2.05916'}; time used = 1.9806756973266602s
epoch 150: {'train_loss': '2.04483'}; time used = 2.0275306701660156s
epoch 155: {'train_loss': '2.07557'}; time used = 1.9832172393798828s
epoch 160: {'train_loss': '2.05832'}; time used = 1.888641119003296s
epoch 165: {'train_loss': '2.07999'}; time used = 1.8517093658447266s
epoch 170: {'train_loss': '2.09667'}; time used = 1.8111324310302734s
epoch 175: {'train_loss': '2.03995'}; time used = 1.5808954238891602s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 53.44268822669983.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.24548'}; time used = 2.593864679336548s
epoch 10: {'train_loss': '0.20615'}; time used = 3.510876178741455s
epoch 15: {'train_loss': '0.46704'}; time used = 3.5757665634155273s
epoch 20: {'train_loss': '0.04655'}; time used = 3.4681811332702637s
epoch 25: {'train_loss': '0.00012'}; time used = 2.9724957942962646s
epoch 30: {'train_loss': '0.00012'}; time used = 2.171217918395996s
epoch 35: {'train_loss': '0.00000'}; time used = 2.1544058322906494s
epoch 40: {'train_loss': '0.00015'}; time used = 2.0618438720703125s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.739815950393677.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.5550595238095237, 'samples': 0.6231884057971014, 'weighted': 0.567675983436853, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.88 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.22140'}; time used = 1.200775146484375s
epoch 10: {'train_loss': '0.12612'}; time used = 1.0752558708190918s
epoch 15: {'train_loss': '0.18276'}; time used = 1.2306382656097412s
epoch 20: {'train_loss': '0.06237'}; time used = 1.0192029476165771s
epoch 25: {'train_loss': '0.06444'}; time used = 1.0609736442565918s
epoch 30: {'train_loss': '0.07560'}; time used = 1.0314092636108398s
epoch 35: {'train_loss': '0.06851'}; time used = 1.150632619857788s
epoch 40: {'train_loss': '0.05031'}; time used = 1.2777447700500488s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.663140773773193.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.31251'}; time used = 2.2459044456481934s
epoch 10: {'train_loss': '1.38854'}; time used = 2.3227806091308594s
epoch 15: {'train_loss': '1.38769'}; time used = 2.4109489917755127s
epoch 20: {'train_loss': '1.38730'}; time used = 2.519547939300537s
epoch 25: {'train_loss': '1.38946'}; time used = 2.2309508323669434s
epoch 30: {'train_loss': '1.38317'}; time used = 1.7118396759033203s
epoch 35: {'train_loss': '1.38619'}; time used = 1.207740306854248s
epoch 40: {'train_loss': '1.37177'}; time used = 1.3653912544250488s
epoch 45: {'train_loss': '1.33104'}; time used = 1.2810792922973633s
epoch 50: {'train_loss': '1.37015'}; time used = 1.6511220932006836s
epoch 55: {'train_loss': '1.25482'}; time used = 1.0123958587646484s
epoch 60: {'train_loss': '1.36663'}; time used = 1.0076625347137451s
epoch 65: {'train_loss': '0.79326'}; time used = 1.0496842861175537s
epoch 70: {'train_loss': '1.97307'}; time used = 1.117795467376709s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.421448469161987.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37491'}; time used = 1.386772871017456s
epoch 10: {'train_loss': '1.30782'}; time used = 1.323169469833374s
epoch 15: {'train_loss': '1.20380'}; time used = 1.3969411849975586s
epoch 20: {'train_loss': '1.21835'}; time used = 1.519484519958496s
epoch 25: {'train_loss': '1.07081'}; time used = 1.5716984272003174s
epoch 30: {'train_loss': '1.03305'}; time used = 1.2930488586425781s
epoch 35: {'train_loss': '1.08285'}; time used = 1.3464844226837158s
epoch 40: {'train_loss': '0.98018'}; time used = 1.3192517757415771s
epoch 45: {'train_loss': '0.73971'}; time used = 1.2480604648590088s
epoch 50: {'train_loss': '0.84334'}; time used = 1.37898588180542s
epoch 55: {'train_loss': '0.95514'}; time used = 1.231595516204834s
epoch 60: {'train_loss': '0.85200'}; time used = 1.31966233253479s
epoch 65: {'train_loss': '0.65031'}; time used = 1.503197193145752s
epoch 70: {'train_loss': '0.70308'}; time used = 1.2335045337677002s
epoch 75: {'train_loss': '0.88747'}; time used = 1.3989629745483398s
epoch 80: {'train_loss': '0.60528'}; time used = 1.3495135307312012s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.361777782440186.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 27.19 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 7.244302272796631s
epoch 10: {'train_loss': '1.38629'}; time used = 4.854318141937256s
epoch 15: {'train_loss': '1.38629'}; time used = 4.487545967102051s
epoch 20: {'train_loss': '1.38629'}; time used = 4.506291389465332s
epoch 25: {'train_loss': '1.38629'}; time used = 4.30975866317749s
epoch 30: {'train_loss': '1.38629'}; time used = 4.627705812454224s
epoch 35: {'train_loss': '1.38629'}; time used = 4.633668899536133s
epoch 40: {'train_loss': '1.38629'}; time used = 4.311465740203857s
epoch 45: {'train_loss': '1.38629'}; time used = 4.601159334182739s
epoch 50: {'train_loss': '1.38629'}; time used = 7.281225681304932s
epoch 55: {'train_loss': '1.38629'}; time used = 5.886139631271362s
epoch 60: {'train_loss': '1.38629'}; time used = 4.393771171569824s
epoch 65: {'train_loss': '1.38629'}; time used = 4.507263898849487s
epoch 70: {'train_loss': '1.38629'}; time used = 5.790858745574951s
epoch 75: {'train_loss': '1.38629'}; time used = 6.983723163604736s
epoch 80: {'train_loss': '1.38629'}; time used = 4.486507415771484s
epoch 85: {'train_loss': '1.38629'}; time used = 4.469351530075073s
epoch 90: {'train_loss': '1.38629'}; time used = 4.3823082447052s
epoch 95: {'train_loss': '1.38629'}; time used = 4.4653894901275635s
epoch 100: {'train_loss': '1.38629'}; time used = 4.438098907470703s
epoch 105: {'train_loss': '1.38629'}; time used = 4.3207972049713135s
epoch 110: {'train_loss': '1.38629'}; time used = 4.392185211181641s
epoch 115: {'train_loss': '1.38629'}; time used = 4.435597896575928s
epoch 120: {'train_loss': '1.38629'}; time used = 4.923417568206787s
epoch 125: {'train_loss': '1.38629'}; time used = 5.695767402648926s
epoch 130: {'train_loss': '1.38629'}; time used = 5.170883655548096s
epoch 135: {'train_loss': '1.38629'}; time used = 5.078659772872925s
epoch 140: {'train_loss': '1.38629'}; time used = 5.010112285614014s
epoch 145: {'train_loss': '1.38629'}; time used = 4.770004510879517s
epoch 150: {'train_loss': '1.38629'}; time used = 4.372532606124878s
epoch 155: {'train_loss': '1.38629'}; time used = 4.40595269203186s
epoch 160: {'train_loss': '1.38629'}; time used = 4.360225200653076s
epoch 165: {'train_loss': '1.38629'}; time used = 4.5142669677734375s
epoch 170: {'train_loss': '1.38629'}; time used = 4.888106822967529s
epoch 175: {'train_loss': '1.38629'}; time used = 5.26140022277832s
epoch 180: {'train_loss': '1.38629'}; time used = 5.169098377227783s
epoch 185: {'train_loss': '1.38629'}; time used = 4.916952610015869s
epoch 190: {'train_loss': '1.38629'}; time used = 5.118351221084595s
epoch 195: {'train_loss': '1.38629'}; time used = 4.386574983596802s
epoch 200: {'train_loss': '1.38629'}; time used = 4.766723871231079s
epoch 205: {'train_loss': '1.38629'}; time used = 4.318389892578125s
epoch 210: {'train_loss': '1.38629'}; time used = 5.093867063522339s
epoch 215: {'train_loss': '1.38629'}; time used = 5.800027132034302s
epoch 220: {'train_loss': '1.38629'}; time used = 4.504557371139526s
epoch 225: {'train_loss': '1.38629'}; time used = 4.764752388000488s
epoch 230: {'train_loss': '1.38629'}; time used = 4.632065534591675s
epoch 235: {'train_loss': '1.38629'}; time used = 5.873263359069824s
epoch 240: {'train_loss': '1.38629'}; time used = 4.527815341949463s
epoch 245: {'train_loss': '1.38629'}; time used = 4.616409778594971s
epoch 250: {'train_loss': '1.38629'}; time used = 4.710225820541382s
epoch 255: {'train_loss': '1.38629'}; time used = 4.7872538566589355s
epoch 260: {'train_loss': '1.38629'}; time used = 4.546398639678955s
epoch 265: {'train_loss': '1.38629'}; time used = 4.283292770385742s
epoch 270: {'train_loss': '1.38629'}; time used = 4.597848176956177s
epoch 275: {'train_loss': '1.38629'}; time used = 4.651832580566406s
epoch 280: {'train_loss': '1.38629'}; time used = 4.703213453292847s
epoch 285: {'train_loss': '1.38629'}; time used = 4.678141832351685s
epoch 290: {'train_loss': '1.38629'}; time used = 4.182078838348389s
epoch 295: {'train_loss': '1.38629'}; time used = 4.336785078048706s
epoch 300: {'train_loss': '1.38629'}; time used = 5.042249441146851s
epoch 305: {'train_loss': '1.38629'}; time used = 4.71390438079834s
epoch 310: {'train_loss': '1.38629'}; time used = 4.417068719863892s
epoch 315: {'train_loss': '1.38629'}; time used = 4.971743583679199s
epoch 320: {'train_loss': '1.38629'}; time used = 4.249185562133789s
epoch 325: {'train_loss': '1.38629'}; time used = 4.5530922412872314s
epoch 330: {'train_loss': '1.38629'}; time used = 4.4716637134552s
epoch 335: {'train_loss': '1.38629'}; time used = 4.406563997268677s
epoch 340: {'train_loss': '1.38629'}; time used = 4.352890491485596s
epoch 345: {'train_loss': '1.38629'}; time used = 4.500803232192993s
epoch 350: {'train_loss': '1.38629'}; time used = 4.387204885482788s
epoch 355: {'train_loss': '1.38629'}; time used = 4.387651205062866s
epoch 360: {'train_loss': '1.38629'}; time used = 5.06374979019165s
epoch 365: {'train_loss': '1.38629'}; time used = 4.782891035079956s
epoch 370: {'train_loss': '1.38629'}; time used = 4.421176910400391s
epoch 375: {'train_loss': '1.38629'}; time used = 4.50475549697876s
epoch 380: {'train_loss': '1.38629'}; time used = 4.3384318351745605s
epoch 385: {'train_loss': '1.38629'}; time used = 4.2237584590911865s
epoch 390: {'train_loss': '1.38629'}; time used = 4.30737829208374s
epoch 395: {'train_loss': '1.38629'}; time used = 4.334591627120972s
epoch 400: {'train_loss': '1.38629'}; time used = 6.112721920013428s
epoch 405: {'train_loss': '1.38629'}; time used = 7.35232949256897s
epoch 410: {'train_loss': '1.38629'}; time used = 4.346333026885986s
epoch 415: {'train_loss': '1.38629'}; time used = 4.620387315750122s
epoch 420: {'train_loss': '1.38629'}; time used = 4.385490417480469s
epoch 425: {'train_loss': '1.38629'}; time used = 4.106830358505249s
epoch 430: {'train_loss': '1.38629'}; time used = 4.523565292358398s
epoch 435: {'train_loss': '1.38629'}; time used = 4.301837921142578s
epoch 440: {'train_loss': '1.38629'}; time used = 4.880237102508545s
epoch 445: {'train_loss': '1.38629'}; time used = 5.514261722564697s
epoch 450: {'train_loss': '1.38629'}; time used = 4.977220296859741s
epoch 455: {'train_loss': '1.38629'}; time used = 4.2640135288238525s
epoch 460: {'train_loss': '1.38629'}; time used = 4.202284574508667s
epoch 465: {'train_loss': '1.38629'}; time used = 4.276910066604614s
epoch 470: {'train_loss': '1.38629'}; time used = 4.35042405128479s
epoch 475: {'train_loss': '1.38629'}; time used = 4.487135648727417s
epoch 480: {'train_loss': '1.38629'}; time used = 4.896841287612915s
epoch 485: {'train_loss': '1.38629'}; time used = 5.098647832870483s
epoch 490: {'train_loss': '1.38629'}; time used = 4.319759130477905s
epoch 495: {'train_loss': '1.38629'}; time used = 4.4361748695373535s
epoch 500: {'train_loss': '1.38629'}; time used = 4.445861577987671s
Finished training. Time used = 485.91438126564026.
Training classifier using 80.00% nodes...
{'micro': 0.69, 'macro': 0.6888799678843838, 'samples': 0.69, 'weighted': 0.688506623845845, 'accuracy': 0.69}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.38119'}; time used = 1.65755295753479s
epoch 10: {'train_loss': '2.85601'}; time used = 1.350904941558838s
epoch 15: {'train_loss': '2.83597'}; time used = 1.6175706386566162s
epoch 20: {'train_loss': '2.82327'}; time used = 1.398205041885376s
epoch 25: {'train_loss': '2.80723'}; time used = 1.6533353328704834s
epoch 30: {'train_loss': '2.79344'}; time used = 2.8947970867156982s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.351638078689575.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5722943722943723, 'samples': 0.6578947368421053, 'weighted': 0.6025062656641604, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.79721'}; time used = 1.1919684410095215s
epoch 10: {'train_loss': '0.53180'}; time used = 1.154845952987671s
epoch 15: {'train_loss': '0.20311'}; time used = 0.9586441516876221s
epoch 20: {'train_loss': '0.40612'}; time used = 1.0180797576904297s
epoch 25: {'train_loss': '0.26432'}; time used = 1.204878807067871s
epoch 30: {'train_loss': '0.17012'}; time used = 1.142317771911621s
epoch 35: {'train_loss': '0.14694'}; time used = 1.1845877170562744s
epoch 40: {'train_loss': '0.13860'}; time used = 1.125335454940796s
epoch 45: {'train_loss': '0.11282'}; time used = 1.1138956546783447s
epoch 50: {'train_loss': '0.10487'}; time used = 1.108246088027954s
epoch 55: {'train_loss': '0.08957'}; time used = 1.1647100448608398s
epoch 60: {'train_loss': '0.06163'}; time used = 1.2051801681518555s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.24396324157715.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.16901'}; time used = 2.026015043258667s
epoch 10: {'train_loss': '0.70441'}; time used = 1.8842699527740479s
epoch 15: {'train_loss': '0.46350'}; time used = 1.8971121311187744s
epoch 20: {'train_loss': '0.33113'}; time used = 1.893096685409546s
epoch 25: {'train_loss': '0.17753'}; time used = 2.034601926803589s
epoch 30: {'train_loss': '0.13471'}; time used = 1.852369785308838s
epoch 35: {'train_loss': '0.10987'}; time used = 1.8677129745483398s
epoch 40: {'train_loss': '0.11030'}; time used = 3.1944046020507812s
epoch 45: {'train_loss': '0.08843'}; time used = 2.208664894104004s
epoch 50: {'train_loss': '0.10086'}; time used = 1.8597679138183594s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.270413875579834.
Training classifier using 80.00% nodes...
{'micro': 0.6811594202898551, 'macro': 0.6778438030560272, 'samples': 0.6811594202898551, 'weighted': 0.68021210108019, 'accuracy': 0.6811594202898551}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86170'}; time used = 1.8558199405670166s
epoch 10: {'train_loss': '2.78649'}; time used = 2.007444381713867s
epoch 15: {'train_loss': '2.74489'}; time used = 1.7567050457000732s
epoch 20: {'train_loss': '2.73336'}; time used = 1.7256760597229004s
epoch 25: {'train_loss': '2.71100'}; time used = 1.8693008422851562s
epoch 30: {'train_loss': '2.67821'}; time used = 1.9724061489105225s
epoch 35: {'train_loss': '2.64628'}; time used = 1.9860451221466064s
epoch 40: {'train_loss': '2.60561'}; time used = 1.8996009826660156s
epoch 45: {'train_loss': '2.56312'}; time used = 2.094353675842285s
epoch 50: {'train_loss': '2.49713'}; time used = 1.7897071838378906s
epoch 55: {'train_loss': '2.48419'}; time used = 1.8331615924835205s
epoch 60: {'train_loss': '2.44128'}; time used = 1.9232001304626465s
epoch 65: {'train_loss': '2.35952'}; time used = 1.883589267730713s
epoch 70: {'train_loss': '2.33918'}; time used = 3.1782948970794678s
epoch 75: {'train_loss': '2.30990'}; time used = 2.9439685344696045s
epoch 80: {'train_loss': '2.23624'}; time used = 3.225454092025757s
epoch 85: {'train_loss': '2.29301'}; time used = 2.650332450866699s
epoch 90: {'train_loss': '2.28056'}; time used = 1.9717037677764893s
epoch 95: {'train_loss': '2.21054'}; time used = 1.9043753147125244s
epoch 100: {'train_loss': '2.18560'}; time used = 1.9124031066894531s
epoch 105: {'train_loss': '2.15720'}; time used = 1.7635321617126465s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 48.00128245353699.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5191637630662022, 'samples': 0.5362318840579711, 'weighted': 0.5257284249861133, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.78005'}; time used = 10.236699342727661s
epoch 10: {'train_loss': '2.78330'}; time used = 8.131291627883911s
epoch 15: {'train_loss': '2.77370'}; time used = 6.979318141937256s
epoch 20: {'train_loss': '2.77352'}; time used = 6.677038192749023s
epoch 25: {'train_loss': '2.77577'}; time used = 6.627996444702148s
epoch 30: {'train_loss': '2.77443'}; time used = 7.148371696472168s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 56.605085611343384.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.45193159120188153, 'samples': 0.5066666666666667, 'weighted': 0.4431736434658251, 'accuracy': 0.5066666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39169'}; time used = 1.290743350982666s
epoch 10: {'train_loss': '1.36842'}; time used = 1.410463809967041s
epoch 15: {'train_loss': '1.33444'}; time used = 1.4221484661102295s
epoch 20: {'train_loss': '1.22990'}; time used = 2.372690439224243s
epoch 25: {'train_loss': '0.90566'}; time used = 1.4958117008209229s
epoch 30: {'train_loss': '1.05256'}; time used = 1.2204387187957764s
epoch 35: {'train_loss': '1.00019'}; time used = 1.277611494064331s
epoch 40: {'train_loss': '0.80325'}; time used = 1.160940170288086s
epoch 45: {'train_loss': '0.75433'}; time used = 1.1675493717193604s
epoch 50: {'train_loss': '0.64507'}; time used = 1.2564616203308105s
epoch 55: {'train_loss': '1.31460'}; time used = 1.2506663799285889s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.48271369934082.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.77974'}; time used = 1.4211866855621338s
epoch 10: {'train_loss': '2.74066'}; time used = 1.230018138885498s
epoch 15: {'train_loss': '2.67105'}; time used = 1.2706553936004639s
epoch 20: {'train_loss': '2.49515'}; time used = 1.264345407485962s
epoch 25: {'train_loss': '2.36117'}; time used = 1.283060073852539s
epoch 30: {'train_loss': '2.29859'}; time used = 1.2541241645812988s
epoch 35: {'train_loss': '2.24335'}; time used = 1.1976509094238281s
epoch 40: {'train_loss': '2.17989'}; time used = 1.2305548191070557s
epoch 45: {'train_loss': '2.15183'}; time used = 1.3177084922790527s
epoch 50: {'train_loss': '2.12783'}; time used = 1.213024377822876s
epoch 55: {'train_loss': '2.08511'}; time used = 1.1234166622161865s
epoch 60: {'train_loss': '2.17417'}; time used = 1.4392080307006836s
epoch 65: {'train_loss': '2.07297'}; time used = 1.337430477142334s
epoch 70: {'train_loss': '2.08543'}; time used = 1.2097225189208984s
epoch 75: {'train_loss': '2.02889'}; time used = 2.047325611114502s
epoch 80: {'train_loss': '1.98560'}; time used = 2.0847456455230713s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.719873189926147.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.38014'}; time used = 1.300152063369751s
epoch 10: {'train_loss': '0.27661'}; time used = 1.0655620098114014s
epoch 15: {'train_loss': '0.29830'}; time used = 1.0628676414489746s
epoch 20: {'train_loss': '0.28244'}; time used = 0.9713220596313477s
epoch 25: {'train_loss': '0.32807'}; time used = 1.1295349597930908s
epoch 30: {'train_loss': '0.25697'}; time used = 1.2361080646514893s
epoch 35: {'train_loss': '0.28863'}; time used = 1.0822463035583496s
epoch 40: {'train_loss': '0.23356'}; time used = 1.164154291152954s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.349133014678955.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.10690'}; time used = 2.1440532207489014s
epoch 10: {'train_loss': '0.00001'}; time used = 1.9238643646240234s
epoch 15: {'train_loss': '0.04502'}; time used = 2.1533806324005127s
epoch 20: {'train_loss': '0.00098'}; time used = 1.905672311782837s
epoch 25: {'train_loss': '0.01202'}; time used = 2.071918487548828s
epoch 30: {'train_loss': '0.00232'}; time used = 1.8568332195281982s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.569570064544678.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.42208'}; time used = 2.197064161300659s
epoch 10: {'train_loss': '2.91760'}; time used = 2.0050840377807617s
epoch 15: {'train_loss': '2.88454'}; time used = 2.0464775562286377s
epoch 20: {'train_loss': '2.84181'}; time used = 2.008082389831543s
epoch 25: {'train_loss': '2.79332'}; time used = 2.31364369392395s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.974369525909424.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5871794871794872, 'samples': 0.5942028985507246, 'weighted': 0.5910813823857303, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.40004'}; time used = 1.2275452613830566s
epoch 10: {'train_loss': '1.39316'}; time used = 1.0930581092834473s
epoch 15: {'train_loss': '1.38770'}; time used = 1.142197847366333s
epoch 20: {'train_loss': '1.38844'}; time used = 1.0752263069152832s
epoch 25: {'train_loss': '1.38956'}; time used = 1.3109760284423828s
epoch 30: {'train_loss': '1.38421'}; time used = 1.0428760051727295s
epoch 35: {'train_loss': '1.39220'}; time used = 1.3561620712280273s
epoch 40: {'train_loss': '1.37420'}; time used = 1.3512248992919922s
epoch 45: {'train_loss': '1.34842'}; time used = 1.134242057800293s
epoch 50: {'train_loss': '1.41032'}; time used = 1.1419792175292969s
epoch 55: {'train_loss': '1.38009'}; time used = 1.109156847000122s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.06454372406006.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.3666666666666667, 'samples': 0.5789473684210527, 'weighted': 0.4245614035087719, 'accuracy': 0.5789473684210527}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.85632'}; time used = 6.039635896682739s
epoch 10: {'train_loss': '2.78289'}; time used = 5.0671210289001465s
epoch 15: {'train_loss': '2.77433'}; time used = 6.551784038543701s
epoch 20: {'train_loss': '2.78284'}; time used = 9.048096895217896s
epoch 25: {'train_loss': '2.77537'}; time used = 9.220205068588257s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 75.9830048084259.
Training classifier using 80.00% nodes...
{'micro': 0.695, 'macro': 0.6948092557848655, 'samples': 0.695, 'weighted': 0.694656660412758, 'accuracy': 0.695}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.25433'}; time used = 1.991502046585083s
epoch 10: {'train_loss': '1.17586'}; time used = 2.003614902496338s
epoch 15: {'train_loss': '1.12973'}; time used = 2.122792959213257s
epoch 20: {'train_loss': '0.95037'}; time used = 2.396414041519165s
epoch 25: {'train_loss': '0.84994'}; time used = 2.2881317138671875s
epoch 30: {'train_loss': '0.54971'}; time used = 2.0510663986206055s
epoch 35: {'train_loss': '0.39776'}; time used = 1.8971099853515625s
epoch 40: {'train_loss': '0.22240'}; time used = 2.1383378505706787s
epoch 45: {'train_loss': '0.22269'}; time used = 2.0328807830810547s
epoch 50: {'train_loss': '0.15049'}; time used = 2.0213658809661865s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.096929788589478.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.40665742024965323, 'samples': 0.5507246376811594, 'weighted': 0.42784377575428645, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.37449'}; time used = 1.079970359802246s
epoch 10: {'train_loss': '0.22291'}; time used = 0.9600260257720947s
epoch 15: {'train_loss': '0.16345'}; time used = 1.1669807434082031s
epoch 20: {'train_loss': '0.15410'}; time used = 1.0425846576690674s
epoch 25: {'train_loss': '0.17146'}; time used = 1.040973424911499s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.088148593902588.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.72530'}; time used = 1.417661428451538s
epoch 10: {'train_loss': '2.69580'}; time used = 1.3019745349884033s
epoch 15: {'train_loss': '2.42230'}; time used = 1.3837473392486572s
epoch 20: {'train_loss': '2.28408'}; time used = 1.4334635734558105s
epoch 25: {'train_loss': '2.09291'}; time used = 1.3533015251159668s
epoch 30: {'train_loss': '2.12543'}; time used = 1.378462314605713s
epoch 35: {'train_loss': '1.93091'}; time used = 1.4063432216644287s
epoch 40: {'train_loss': '1.94897'}; time used = 1.3319578170776367s
epoch 45: {'train_loss': '1.93974'}; time used = 1.3398985862731934s
epoch 50: {'train_loss': '1.93183'}; time used = 1.393449068069458s
epoch 55: {'train_loss': '1.83947'}; time used = 1.3804945945739746s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.865652084350586.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7414965986394557, 'samples': 0.7631578947368421, 'weighted': 0.7533118510562119, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.38930'}; time used = 4.0215842723846436s
epoch 10: {'train_loss': '1.35146'}; time used = 4.88869571685791s
epoch 15: {'train_loss': '1.38316'}; time used = 5.136428356170654s
epoch 20: {'train_loss': '1.44782'}; time used = 4.94763445854187s
epoch 25: {'train_loss': '1.42530'}; time used = 5.338620185852051s
epoch 30: {'train_loss': '1.38806'}; time used = 4.6574530601501465s
epoch 35: {'train_loss': '1.37899'}; time used = 3.4189956188201904s
epoch 40: {'train_loss': '1.36118'}; time used = 2.7662363052368164s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.667912006378174.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.25 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.38273'}; time used = 3.9700558185577393s
epoch 10: {'train_loss': '1.35135'}; time used = 3.8233587741851807s
epoch 15: {'train_loss': '1.35060'}; time used = 3.8893280029296875s
epoch 20: {'train_loss': '1.37185'}; time used = 2.304048538208008s
epoch 25: {'train_loss': '1.21204'}; time used = 2.3272416591644287s
epoch 30: {'train_loss': '0.94162'}; time used = 2.1427552700042725s
epoch 35: {'train_loss': '1.01883'}; time used = 2.058861017227173s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.621176958084106.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.45526315789473687, 'samples': 0.5652173913043478, 'weighted': 0.47299771167048055, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.43324'}; time used = 1.2559268474578857s
epoch 10: {'train_loss': '2.83588'}; time used = 1.3278653621673584s
epoch 15: {'train_loss': '2.81065'}; time used = 1.326244831085205s
epoch 20: {'train_loss': '2.80778'}; time used = 1.2243516445159912s
epoch 25: {'train_loss': '2.80414'}; time used = 1.223278522491455s
epoch 30: {'train_loss': '2.79583'}; time used = 1.2963483333587646s
epoch 35: {'train_loss': '2.78733'}; time used = 1.1468045711517334s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.453917264938354.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.34853'}; time used = 2.0887818336486816s
epoch 10: {'train_loss': '1.28538'}; time used = 2.2131552696228027s
epoch 15: {'train_loss': '1.27638'}; time used = 2.147881031036377s
epoch 20: {'train_loss': '1.36087'}; time used = 2.0348868370056152s
epoch 25: {'train_loss': '1.30529'}; time used = 3.501014471054077s
epoch 30: {'train_loss': '1.22818'}; time used = 2.1935224533081055s
epoch 35: {'train_loss': '1.18620'}; time used = 2.475127935409546s
epoch 40: {'train_loss': '1.15465'}; time used = 1.9321229457855225s
epoch 45: {'train_loss': '1.17411'}; time used = 1.9890949726104736s
epoch 50: {'train_loss': '1.07931'}; time used = 2.0172975063323975s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.327688217163086.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84805'}; time used = 5.115095138549805s
epoch 10: {'train_loss': '2.77701'}; time used = 4.630481958389282s
epoch 15: {'train_loss': '2.78162'}; time used = 4.9576735496521s
epoch 20: {'train_loss': '2.77760'}; time used = 5.832228183746338s
epoch 25: {'train_loss': '2.77394'}; time used = 7.2761759757995605s
epoch 30: {'train_loss': '2.77525'}; time used = 5.894067049026489s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.02721619606018.
Training classifier using 80.00% nodes...
{'micro': 0.68, 'macro': 0.6784242789669379, 'samples': 0.68, 'weighted': 0.6779740729574917, 'accuracy': 0.68}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.83437'}; time used = 1.6367592811584473s
epoch 10: {'train_loss': '2.74573'}; time used = 1.5071473121643066s
epoch 15: {'train_loss': '2.66200'}; time used = 1.467686653137207s
epoch 20: {'train_loss': '2.56995'}; time used = 1.36320161819458s
epoch 25: {'train_loss': '2.52522'}; time used = 1.5048129558563232s
epoch 30: {'train_loss': '2.44656'}; time used = 1.290970802307129s
epoch 35: {'train_loss': '2.32116'}; time used = 1.468385934829712s
epoch 40: {'train_loss': '2.32428'}; time used = 1.3466989994049072s
epoch 45: {'train_loss': '2.26259'}; time used = 1.339566707611084s
epoch 50: {'train_loss': '2.22764'}; time used = 1.4384667873382568s
epoch 55: {'train_loss': '2.12797'}; time used = 1.6451032161712646s
epoch 60: {'train_loss': '2.11878'}; time used = 1.606856346130371s
epoch 65: {'train_loss': '2.10444'}; time used = 1.4681787490844727s
epoch 70: {'train_loss': '2.05776'}; time used = 1.303593635559082s
epoch 75: {'train_loss': '2.02685'}; time used = 1.532541275024414s
epoch 80: {'train_loss': '2.00950'}; time used = 1.3334295749664307s
epoch 85: {'train_loss': '1.99113'}; time used = 1.5237224102020264s
epoch 90: {'train_loss': '2.13133'}; time used = 1.3205814361572266s
epoch 95: {'train_loss': '2.16547'}; time used = 1.408421516418457s
epoch 100: {'train_loss': '2.09229'}; time used = 1.4131145477294922s
epoch 105: {'train_loss': '1.99164'}; time used = 1.6270523071289062s
epoch 110: {'train_loss': '1.99405'}; time used = 1.43760347366333s
epoch 115: {'train_loss': '1.97328'}; time used = 1.4020988941192627s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.570555448532104.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86515'}; time used = 1.2004899978637695s
epoch 10: {'train_loss': '2.77536'}; time used = 1.1556565761566162s
epoch 15: {'train_loss': '2.80412'}; time used = 1.147859811782837s
epoch 20: {'train_loss': '2.77917'}; time used = 1.2854087352752686s
epoch 25: {'train_loss': '2.77743'}; time used = 1.2998173236846924s
epoch 30: {'train_loss': '2.77560'}; time used = 1.4480547904968262s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.689386129379272.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.51 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.73222'}; time used = 1.6312181949615479s
epoch 10: {'train_loss': '2.59380'}; time used = 1.007511854171753s
epoch 15: {'train_loss': '2.42854'}; time used = 1.16951584815979s
epoch 20: {'train_loss': '2.34628'}; time used = 0.9655804634094238s
epoch 25: {'train_loss': '2.21499'}; time used = 0.9393234252929688s
epoch 30: {'train_loss': '2.17172'}; time used = 1.156468391418457s
epoch 35: {'train_loss': '1.96411'}; time used = 1.0343902111053467s
epoch 40: {'train_loss': '1.88226'}; time used = 1.0125982761383057s
epoch 45: {'train_loss': '1.67874'}; time used = 1.031639814376831s
epoch 50: {'train_loss': '1.62555'}; time used = 1.0852625370025635s
epoch 55: {'train_loss': '1.55504'}; time used = 1.0736629962921143s
epoch 60: {'train_loss': '1.50808'}; time used = 1.1347880363464355s
epoch 65: {'train_loss': '1.49343'}; time used = 1.1042392253875732s
epoch 70: {'train_loss': '1.47159'}; time used = 1.1502561569213867s
epoch 75: {'train_loss': '1.37789'}; time used = 1.0599501132965088s
epoch 80: {'train_loss': '1.45393'}; time used = 1.0306272506713867s
epoch 85: {'train_loss': '1.45598'}; time used = 1.242868423461914s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.271920204162598.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.05 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.04 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.83499'}; time used = 2.2105484008789062s
epoch 10: {'train_loss': '2.78071'}; time used = 2.2540621757507324s
epoch 15: {'train_loss': '2.77559'}; time used = 2.210296154022217s
epoch 20: {'train_loss': '2.77133'}; time used = 2.2394020557403564s
epoch 25: {'train_loss': '2.76236'}; time used = 2.1983482837677s
epoch 30: {'train_loss': '2.75280'}; time used = 2.2271461486816406s
epoch 35: {'train_loss': '2.72605'}; time used = 2.1094939708709717s
epoch 40: {'train_loss': '2.67303'}; time used = 2.349438428878784s
epoch 45: {'train_loss': '2.61082'}; time used = 2.269138813018799s
epoch 50: {'train_loss': '2.54063'}; time used = 2.9072277545928955s
epoch 55: {'train_loss': '2.54309'}; time used = 2.7254724502563477s
epoch 60: {'train_loss': '2.53510'}; time used = 2.3507323265075684s
epoch 65: {'train_loss': '2.50127'}; time used = 2.7619495391845703s
epoch 70: {'train_loss': '2.47307'}; time used = 2.563926935195923s
epoch 75: {'train_loss': '2.42935'}; time used = 2.4426517486572266s
epoch 80: {'train_loss': '2.43965'}; time used = 2.395693778991699s
epoch 85: {'train_loss': '2.45173'}; time used = 2.2205700874328613s
epoch 90: {'train_loss': '2.48099'}; time used = 2.0608408451080322s
epoch 95: {'train_loss': '2.45311'}; time used = 2.1841392517089844s
epoch 100: {'train_loss': '2.40835'}; time used = 2.2933871746063232s
epoch 105: {'train_loss': '2.42402'}; time used = 2.2773590087890625s
epoch 110: {'train_loss': '2.39353'}; time used = 2.228966474533081s
epoch 115: {'train_loss': '2.37189'}; time used = 2.4463117122650146s
epoch 120: {'train_loss': '2.38077'}; time used = 2.525951623916626s
epoch 125: {'train_loss': '2.76533'}; time used = 2.3986713886260986s
epoch 130: {'train_loss': '2.51400'}; time used = 3.487344264984131s
epoch 135: {'train_loss': '2.50031'}; time used = 2.381570339202881s
epoch 140: {'train_loss': '2.47613'}; time used = 2.236058235168457s
epoch 145: {'train_loss': '2.45447'}; time used = 2.1095364093780518s
epoch 150: {'train_loss': '2.44350'}; time used = 2.229048013687134s
epoch 155: {'train_loss': '2.41017'}; time used = 2.161571979522705s
epoch 160: {'train_loss': '2.40005'}; time used = 3.588547468185425s
epoch 165: {'train_loss': '2.38032'}; time used = 3.0732274055480957s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 84.51612377166748.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.16527'}; time used = 2.1016836166381836s
epoch 10: {'train_loss': '1.07387'}; time used = 1.8904633522033691s
epoch 15: {'train_loss': '0.98585'}; time used = 1.908599615097046s
epoch 20: {'train_loss': '0.82553'}; time used = 2.1145691871643066s
epoch 25: {'train_loss': '0.51941'}; time used = 2.216082811355591s
epoch 30: {'train_loss': '0.38032'}; time used = 2.0083260536193848s
epoch 35: {'train_loss': '0.20452'}; time used = 1.7304465770721436s
epoch 40: {'train_loss': '0.13387'}; time used = 1.706941843032837s
epoch 45: {'train_loss': '0.06172'}; time used = 1.8417975902557373s
epoch 50: {'train_loss': '0.04303'}; time used = 1.7833483219146729s
epoch 55: {'train_loss': '0.10180'}; time used = 2.1796624660491943s
epoch 60: {'train_loss': '0.03570'}; time used = 1.8185522556304932s
epoch 65: {'train_loss': '0.02645'}; time used = 1.8104643821716309s
epoch 70: {'train_loss': '0.02050'}; time used = 1.7692909240722656s
epoch 75: {'train_loss': '0.02327'}; time used = 1.8260748386383057s
epoch 80: {'train_loss': '0.01495'}; time used = 1.8200910091400146s
epoch 85: {'train_loss': '0.01882'}; time used = 1.8039524555206299s
epoch 90: {'train_loss': '0.01518'}; time used = 1.8832483291625977s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.65516257286072.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5864594894561599, 'samples': 0.6086956521739131, 'weighted': 0.5934082903054577, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.19 GiB free; 24.69 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.79944'}; time used = 1.699042797088623s
epoch 10: {'train_loss': '2.70082'}; time used = 1.7037947177886963s
epoch 15: {'train_loss': '2.66792'}; time used = 1.760401964187622s
epoch 20: {'train_loss': '2.65773'}; time used = 1.5329205989837646s
epoch 25: {'train_loss': '2.65157'}; time used = 1.9279963970184326s
epoch 30: {'train_loss': '2.63579'}; time used = 1.8128957748413086s
epoch 35: {'train_loss': '2.63191'}; time used = 1.7475552558898926s
epoch 40: {'train_loss': '2.63034'}; time used = 1.580087423324585s
epoch 45: {'train_loss': '2.62154'}; time used = 1.556603193283081s
epoch 50: {'train_loss': '2.60225'}; time used = 1.6338090896606445s
epoch 55: {'train_loss': '2.59620'}; time used = 1.7384998798370361s
epoch 60: {'train_loss': '2.59604'}; time used = 1.7740285396575928s
epoch 65: {'train_loss': '2.58800'}; time used = 1.7070097923278809s
epoch 70: {'train_loss': '2.56768'}; time used = 1.5702760219573975s
epoch 75: {'train_loss': '2.56040'}; time used = 1.8241913318634033s
epoch 80: {'train_loss': '2.56170'}; time used = 1.8609933853149414s
epoch 85: {'train_loss': '2.55880'}; time used = 1.6278512477874756s
epoch 90: {'train_loss': '2.56496'}; time used = 1.8828980922698975s
epoch 95: {'train_loss': '2.56446'}; time used = 1.588374137878418s
epoch 100: {'train_loss': '2.55411'}; time used = 1.6490836143493652s
epoch 105: {'train_loss': '2.55678'}; time used = 1.785414218902588s
epoch 110: {'train_loss': '2.55615'}; time used = 1.6266841888427734s
epoch 115: {'train_loss': '2.55342'}; time used = 1.5576536655426025s
epoch 120: {'train_loss': '2.55503'}; time used = 1.7154004573822021s
epoch 125: {'train_loss': '2.55325'}; time used = 1.558717966079712s
epoch 130: {'train_loss': '2.55938'}; time used = 1.9254131317138672s
epoch 135: {'train_loss': '2.55152'}; time used = 1.894883632659912s
epoch 140: {'train_loss': '2.54828'}; time used = 1.8488335609436035s
epoch 145: {'train_loss': '2.54499'}; time used = 1.7595014572143555s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 53.66467618942261.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.6073761854583772, 'samples': 0.6086956521739131, 'weighted': 0.609025518852797, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.81234'}; time used = 1.297703504562378s
epoch 10: {'train_loss': '2.77930'}; time used = 1.1289334297180176s
epoch 15: {'train_loss': '2.77274'}; time used = 1.1230547428131104s
epoch 20: {'train_loss': '2.77628'}; time used = 1.1657326221466064s
epoch 25: {'train_loss': '2.77690'}; time used = 1.1431477069854736s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.136070966720581.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7172619047619048, 'samples': 0.7368421052631579, 'weighted': 0.7290100250626566, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.19 GiB free; 24.68 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.44166'}; time used = 1.545475721359253s
epoch 10: {'train_loss': '0.18609'}; time used = 1.4821975231170654s
epoch 15: {'train_loss': '0.09349'}; time used = 1.3765950202941895s
epoch 20: {'train_loss': '0.08046'}; time used = 1.3939096927642822s
epoch 25: {'train_loss': '0.21924'}; time used = 1.536555290222168s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.404295682907104.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6125490196078432, 'samples': 0.6578947368421053, 'weighted': 0.6334778121775028, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.98090'}; time used = 1.9740681648254395s
epoch 10: {'train_loss': '2.78990'}; time used = 1.7804172039031982s
epoch 15: {'train_loss': '2.74067'}; time used = 1.7712717056274414s
epoch 20: {'train_loss': '2.72098'}; time used = 1.6991639137268066s
epoch 25: {'train_loss': '2.70811'}; time used = 1.9017589092254639s
epoch 30: {'train_loss': '2.68986'}; time used = 2.0687448978424072s
epoch 35: {'train_loss': '2.66783'}; time used = 1.7189526557922363s
epoch 40: {'train_loss': '2.63268'}; time used = 1.7172579765319824s
epoch 45: {'train_loss': '2.62053'}; time used = 1.6453235149383545s
epoch 50: {'train_loss': '2.58746'}; time used = 1.6248178482055664s
epoch 55: {'train_loss': '2.58398'}; time used = 1.7519407272338867s
epoch 60: {'train_loss': '2.57356'}; time used = 1.7471895217895508s
epoch 65: {'train_loss': '2.54888'}; time used = 1.673957347869873s
epoch 70: {'train_loss': '2.53020'}; time used = 1.705951452255249s
epoch 75: {'train_loss': '2.49666'}; time used = 1.666740894317627s
epoch 80: {'train_loss': '2.49688'}; time used = 1.8095011711120605s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.53028178215027.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5706929843381249, 'samples': 0.5797101449275363, 'weighted': 0.5752015646328306, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39585'}; time used = 1.1435787677764893s
epoch 10: {'train_loss': '1.40337'}; time used = 1.1929359436035156s
epoch 15: {'train_loss': '1.29525'}; time used = 1.0338828563690186s
epoch 20: {'train_loss': '1.31598'}; time used = 1.2834036350250244s
epoch 25: {'train_loss': '1.09875'}; time used = 1.1512491703033447s
epoch 30: {'train_loss': '1.29351'}; time used = 1.2313833236694336s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.697323560714722.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.72092'}; time used = 1.316364049911499s
epoch 10: {'train_loss': '2.65284'}; time used = 1.033756971359253s
epoch 15: {'train_loss': '2.61787'}; time used = 1.1675527095794678s
epoch 20: {'train_loss': '2.56962'}; time used = 1.1654202938079834s
epoch 25: {'train_loss': '2.51554'}; time used = 1.3243978023529053s
epoch 30: {'train_loss': '2.44188'}; time used = 1.4450125694274902s
epoch 35: {'train_loss': '2.36151'}; time used = 1.1804430484771729s
epoch 40: {'train_loss': '2.31265'}; time used = 1.1090426445007324s
epoch 45: {'train_loss': '2.25703'}; time used = 1.423233985900879s
epoch 50: {'train_loss': '2.22169'}; time used = 1.157440423965454s
epoch 55: {'train_loss': '2.20609'}; time used = 1.0587186813354492s
epoch 60: {'train_loss': '2.14797'}; time used = 1.12852144241333s
epoch 65: {'train_loss': '2.14105'}; time used = 1.1601507663726807s
epoch 70: {'train_loss': '2.15541'}; time used = 0.9903984069824219s
epoch 75: {'train_loss': '2.11169'}; time used = 1.1615447998046875s
epoch 80: {'train_loss': '2.15854'}; time used = 1.1187283992767334s
epoch 85: {'train_loss': '2.17807'}; time used = 1.057997465133667s
epoch 90: {'train_loss': '2.13507'}; time used = 1.1076195240020752s
epoch 95: {'train_loss': '2.08357'}; time used = 1.0203685760498047s
epoch 100: {'train_loss': '2.07646'}; time used = 1.1211771965026855s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.671247482299805.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.86596'}; time used = 1.1374802589416504s
epoch 10: {'train_loss': '2.79962'}; time used = 1.0566034317016602s
epoch 15: {'train_loss': '2.78496'}; time used = 1.0320801734924316s
epoch 20: {'train_loss': '2.77648'}; time used = 1.0754735469818115s
epoch 25: {'train_loss': '2.77011'}; time used = 1.2048864364624023s
epoch 30: {'train_loss': '2.76814'}; time used = 1.0996947288513184s
epoch 35: {'train_loss': '2.76477'}; time used = 1.0457243919372559s
epoch 40: {'train_loss': '2.76111'}; time used = 1.0316312313079834s
epoch 45: {'train_loss': '2.75770'}; time used = 1.0226693153381348s
epoch 50: {'train_loss': '2.75419'}; time used = 1.1141502857208252s
epoch 55: {'train_loss': '2.75062'}; time used = 0.9214575290679932s
epoch 60: {'train_loss': '2.75200'}; time used = 0.9259703159332275s
epoch 65: {'train_loss': '2.74706'}; time used = 1.1471755504608154s
epoch 70: {'train_loss': '2.73383'}; time used = 1.1471490859985352s
epoch 75: {'train_loss': '2.73469'}; time used = 1.0787677764892578s
epoch 80: {'train_loss': '2.70941'}; time used = 0.9834532737731934s
epoch 85: {'train_loss': '2.71774'}; time used = 0.9617166519165039s
epoch 90: {'train_loss': '2.70296'}; time used = 1.0119907855987549s
epoch 95: {'train_loss': '2.69291'}; time used = 1.1620771884918213s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.491392135620117.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.82431'}; time used = 1.1406989097595215s
epoch 10: {'train_loss': '2.77735'}; time used = 0.9793238639831543s
epoch 15: {'train_loss': '2.77489'}; time used = 0.9839606285095215s
epoch 20: {'train_loss': '2.77775'}; time used = 1.0182723999023438s
epoch 25: {'train_loss': '2.77470'}; time used = 1.0944931507110596s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.748294353485107.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.05596'}; time used = 2.1255249977111816s
epoch 10: {'train_loss': '2.77363'}; time used = 2.036762237548828s
epoch 15: {'train_loss': '2.80762'}; time used = 2.0257887840270996s
epoch 20: {'train_loss': '2.80065'}; time used = 2.0874316692352295s
epoch 25: {'train_loss': '2.76722'}; time used = 2.0779387950897217s
epoch 30: {'train_loss': '2.76746'}; time used = 1.9837298393249512s
epoch 35: {'train_loss': '2.75646'}; time used = 2.01627779006958s
epoch 40: {'train_loss': '2.74381'}; time used = 1.9833650588989258s
epoch 45: {'train_loss': '2.73473'}; time used = 1.999457597732544s
epoch 50: {'train_loss': '2.72586'}; time used = 2.058429479598999s
epoch 55: {'train_loss': '2.72574'}; time used = 1.9852635860443115s
epoch 60: {'train_loss': '2.71670'}; time used = 1.9928641319274902s
epoch 65: {'train_loss': '2.71331'}; time used = 1.9807679653167725s
epoch 70: {'train_loss': '2.71670'}; time used = 1.9926550388336182s
epoch 75: {'train_loss': '2.69739'}; time used = 2.1261439323425293s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.180078983306885.
Training classifier using 80.00% nodes...
{'micro': 0.6666666666666666, 'macro': 0.6562703053931124, 'samples': 0.6666666666666666, 'weighted': 0.6606021225904266, 'accuracy': 0.6666666666666666}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.45 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39274'}; time used = 1.1727821826934814s
epoch 10: {'train_loss': '1.37996'}; time used = 1.1877243518829346s
epoch 15: {'train_loss': '1.34288'}; time used = 1.0628561973571777s
epoch 20: {'train_loss': '1.31355'}; time used = 1.0783002376556396s
epoch 25: {'train_loss': '1.24586'}; time used = 1.0955369472503662s
epoch 30: {'train_loss': '1.13049'}; time used = 1.0533764362335205s
epoch 35: {'train_loss': '0.91282'}; time used = 1.1150171756744385s
epoch 40: {'train_loss': '0.87024'}; time used = 1.0801715850830078s
epoch 45: {'train_loss': '0.78156'}; time used = 1.1178486347198486s
epoch 50: {'train_loss': '0.71338'}; time used = 1.2328221797943115s
epoch 55: {'train_loss': '0.58696'}; time used = 1.1056268215179443s
epoch 60: {'train_loss': '0.71545'}; time used = 1.0783357620239258s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.67998456954956.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7490829053558328, 'samples': 0.7631578947368421, 'weighted': 0.7584662316098391, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.33645'}; time used = 1.851680040359497s
epoch 10: {'train_loss': '1.26823'}; time used = 1.7579143047332764s
epoch 15: {'train_loss': '1.25424'}; time used = 1.7682445049285889s
epoch 20: {'train_loss': '1.30088'}; time used = 1.9530000686645508s
epoch 25: {'train_loss': '1.26472'}; time used = 2.2651562690734863s
epoch 30: {'train_loss': '1.18485'}; time used = 2.3443448543548584s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.47911810874939.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.491578947368421, 'samples': 0.5942028985507246, 'weighted': 0.5081311975591152, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.88549'}; time used = 1.2604734897613525s
epoch 10: {'train_loss': '2.81638'}; time used = 1.1533803939819336s
epoch 15: {'train_loss': '2.80135'}; time used = 1.1123950481414795s
epoch 20: {'train_loss': '2.78896'}; time used = 1.1858441829681396s
epoch 25: {'train_loss': '2.78512'}; time used = 1.1440880298614502s
epoch 30: {'train_loss': '2.77841'}; time used = 1.1065309047698975s
epoch 35: {'train_loss': '2.78039'}; time used = 1.4119136333465576s
epoch 40: {'train_loss': '2.77270'}; time used = 1.140751600265503s
epoch 45: {'train_loss': '2.77107'}; time used = 1.1587715148925781s
epoch 50: {'train_loss': '2.76323'}; time used = 1.2265686988830566s
epoch 55: {'train_loss': '2.75691'}; time used = 1.209550142288208s
epoch 60: {'train_loss': '2.75700'}; time used = 1.2301859855651855s
epoch 65: {'train_loss': '2.75514'}; time used = 1.1077311038970947s
epoch 70: {'train_loss': '2.73478'}; time used = 1.4845962524414062s
epoch 75: {'train_loss': '2.73959'}; time used = 1.1132972240447998s
epoch 80: {'train_loss': '2.72086'}; time used = 1.1742839813232422s
epoch 85: {'train_loss': '2.72018'}; time used = 1.227081298828125s
epoch 90: {'train_loss': '2.71692'}; time used = 1.153771162033081s
epoch 95: {'train_loss': '2.70959'}; time used = 1.1708741188049316s
epoch 100: {'train_loss': '2.69112'}; time used = 1.0859375s
epoch 105: {'train_loss': '2.70234'}; time used = 1.0838725566864014s
epoch 110: {'train_loss': '2.68805'}; time used = 1.2485227584838867s
epoch 115: {'train_loss': '2.69081'}; time used = 1.1938855648040771s
epoch 120: {'train_loss': '2.69222'}; time used = 1.1174888610839844s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.77434277534485.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8246153846153846, 'samples': 0.8421052631578947, 'weighted': 0.8333603238866396, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.03474'}; time used = 1.0141496658325195s
epoch 10: {'train_loss': '0.66138'}; time used = 0.9453921318054199s
epoch 15: {'train_loss': '0.43572'}; time used = 0.8974623680114746s
epoch 20: {'train_loss': '0.31438'}; time used = 0.8525490760803223s
epoch 25: {'train_loss': '0.24237'}; time used = 0.8425338268280029s
epoch 30: {'train_loss': '0.22469'}; time used = 1.5991785526275635s
epoch 35: {'train_loss': '0.25898'}; time used = 1.0629537105560303s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.403901100158691.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84822'}; time used = 4.7748377323150635s
epoch 10: {'train_loss': '2.77743'}; time used = 4.566002368927002s
epoch 15: {'train_loss': '2.78147'}; time used = 5.034143686294556s
epoch 20: {'train_loss': '2.77765'}; time used = 6.574207305908203s
epoch 25: {'train_loss': '2.77368'}; time used = 7.044618368148804s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.89681529998779.
Training classifier using 80.00% nodes...
{'micro': 0.7299999999999999, 'macro': 0.7298919567827131, 'samples': 0.73, 'weighted': 0.7297839135654262, 'accuracy': 0.73}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.59987'}; time used = 2.61974835395813s
epoch 10: {'train_loss': '0.06298'}; time used = 1.9197185039520264s
epoch 15: {'train_loss': '0.17133'}; time used = 2.0794053077697754s
epoch 20: {'train_loss': '0.06020'}; time used = 1.6830368041992188s
epoch 25: {'train_loss': '0.05670'}; time used = 1.8554399013519287s
epoch 30: {'train_loss': '0.02041'}; time used = 1.6797127723693848s
epoch 35: {'train_loss': '0.04119'}; time used = 1.674769401550293s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.53817892074585.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4449375866851595, 'samples': 0.5797101449275363, 'weighted': 0.4647570805443325, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.08023'}; time used = 1.677776575088501s
epoch 10: {'train_loss': '0.92203'}; time used = 1.624272108078003s
epoch 15: {'train_loss': '0.83016'}; time used = 2.155794620513916s
epoch 20: {'train_loss': '1.02935'}; time used = 2.843845844268799s
epoch 25: {'train_loss': '1.01120'}; time used = 3.0970587730407715s
epoch 30: {'train_loss': '0.89069'}; time used = 2.71931529045105s
epoch 35: {'train_loss': '0.57365'}; time used = 1.5773465633392334s
epoch 40: {'train_loss': '0.51417'}; time used = 1.669884443283081s
epoch 45: {'train_loss': '0.31985'}; time used = 1.5349047183990479s
epoch 50: {'train_loss': '0.15262'}; time used = 1.6496872901916504s
epoch 55: {'train_loss': '0.05873'}; time used = 1.5779821872711182s
epoch 60: {'train_loss': '0.60623'}; time used = 1.6202647686004639s
epoch 65: {'train_loss': '0.38570'}; time used = 1.5081901550292969s
epoch 70: {'train_loss': '0.51640'}; time used = 1.5166330337524414s
epoch 75: {'train_loss': '0.14028'}; time used = 1.6348321437835693s
epoch 80: {'train_loss': '0.28798'}; time used = 1.5954177379608154s
epoch 85: {'train_loss': '0.16096'}; time used = 1.6014554500579834s
epoch 90: {'train_loss': '0.49498'}; time used = 1.5107097625732422s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.15346050262451.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5295454545454545, 'samples': 0.5652173913043478, 'weighted': 0.5389328063241107, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.27530'}; time used = 2.023176908493042s
epoch 10: {'train_loss': '2.96492'}; time used = 3.5963587760925293s
epoch 15: {'train_loss': '2.88044'}; time used = 4.6901772022247314s
epoch 20: {'train_loss': '2.80379'}; time used = 4.563562631607056s
epoch 25: {'train_loss': '2.81676'}; time used = 1.477238655090332s
epoch 30: {'train_loss': '2.80200'}; time used = 1.4462602138519287s
epoch 35: {'train_loss': '2.79526'}; time used = 1.3850624561309814s
epoch 40: {'train_loss': '2.79241'}; time used = 1.790611982345581s
epoch 45: {'train_loss': '2.79304'}; time used = 1.5105180740356445s
epoch 50: {'train_loss': '2.78845'}; time used = 1.5754320621490479s
epoch 55: {'train_loss': '2.78276'}; time used = 1.5275001525878906s
epoch 60: {'train_loss': '2.78239'}; time used = 1.4750761985778809s
epoch 65: {'train_loss': '2.77831'}; time used = 1.397707462310791s
epoch 70: {'train_loss': '2.77659'}; time used = 1.3436510562896729s
epoch 75: {'train_loss': '2.78597'}; time used = 1.358311414718628s
epoch 80: {'train_loss': '2.78073'}; time used = 1.3632595539093018s
epoch 85: {'train_loss': '2.78141'}; time used = 1.353376865386963s
epoch 90: {'train_loss': '2.78116'}; time used = 1.3738892078399658s
epoch 95: {'train_loss': '2.77725'}; time used = 1.6738827228546143s
epoch 100: {'train_loss': '2.77569'}; time used = 1.5708284378051758s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.72640347480774.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5521885521885521, 'samples': 0.631578947368421, 'weighted': 0.5819599503810029, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.35992'}; time used = 2.490018844604492s
epoch 10: {'train_loss': '2.98530'}; time used = 3.073091983795166s
epoch 15: {'train_loss': '2.88507'}; time used = 2.58316969871521s
epoch 20: {'train_loss': '2.85917'}; time used = 1.9934258460998535s
epoch 25: {'train_loss': '2.83035'}; time used = 2.111076593399048s
epoch 30: {'train_loss': '2.81824'}; time used = 2.0519514083862305s
epoch 35: {'train_loss': '2.80992'}; time used = 2.0272462368011475s
epoch 40: {'train_loss': '2.80247'}; time used = 2.0522847175598145s
epoch 45: {'train_loss': '2.80468'}; time used = 2.631303071975708s
epoch 50: {'train_loss': '2.79635'}; time used = 1.9937856197357178s
epoch 55: {'train_loss': '2.79685'}; time used = 2.1191744804382324s
epoch 60: {'train_loss': '2.79003'}; time used = 1.9989652633666992s
epoch 65: {'train_loss': '2.77700'}; time used = 1.9977025985717773s
epoch 70: {'train_loss': '2.76793'}; time used = 2.0427205562591553s
epoch 75: {'train_loss': '2.74993'}; time used = 2.124624252319336s
epoch 80: {'train_loss': '2.72737'}; time used = 2.3656840324401855s
epoch 85: {'train_loss': '2.69296'}; time used = 2.0072433948516846s
epoch 90: {'train_loss': '2.66700'}; time used = 2.125913381576538s
epoch 95: {'train_loss': '2.64200'}; time used = 2.129037618637085s
epoch 100: {'train_loss': '2.58645'}; time used = 2.571819543838501s
epoch 105: {'train_loss': '2.59423'}; time used = 3.7077105045318604s
epoch 110: {'train_loss': '2.58174'}; time used = 4.452184200286865s
epoch 115: {'train_loss': '2.54324'}; time used = 3.7706212997436523s
epoch 120: {'train_loss': '2.54945'}; time used = 4.055145978927612s
epoch 125: {'train_loss': '2.53403'}; time used = 3.9900832176208496s
epoch 130: {'train_loss': '2.53723'}; time used = 3.9886295795440674s
epoch 135: {'train_loss': '2.56670'}; time used = 3.7806689739227295s
epoch 140: {'train_loss': '2.54571'}; time used = 2.370408535003662s
epoch 145: {'train_loss': '2.51468'}; time used = 2.3968353271484375s
epoch 150: {'train_loss': '2.51159'}; time used = 2.3078925609588623s
epoch 155: {'train_loss': '2.48690'}; time used = 2.348757743835449s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 85.63885736465454.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.41025641025641024, 'samples': 0.5217391304347826, 'weighted': 0.42883686361947226, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.29638'}; time used = 2.6160006523132324s
epoch 10: {'train_loss': '1.19393'}; time used = 2.0124399662017822s
epoch 15: {'train_loss': '1.01247'}; time used = 3.9573330879211426s
epoch 20: {'train_loss': '0.83308'}; time used = 3.4843997955322266s
epoch 25: {'train_loss': '0.71107'}; time used = 2.4502246379852295s
epoch 30: {'train_loss': '0.47107'}; time used = 3.1121163368225098s
epoch 35: {'train_loss': '0.40068'}; time used = 3.402737617492676s
epoch 40: {'train_loss': '0.17675'}; time used = 2.927762269973755s
epoch 45: {'train_loss': '0.16054'}; time used = 2.1449015140533447s
epoch 50: {'train_loss': '0.09380'}; time used = 2.213571786880493s
epoch 55: {'train_loss': '0.10662'}; time used = 2.195490598678589s
epoch 60: {'train_loss': '0.13671'}; time used = 2.0730814933776855s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.95715117454529.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5101591187270502, 'samples': 0.5797101449275363, 'weighted': 0.5235343160732975, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.12 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.32507'}; time used = 1.0387177467346191s
epoch 10: {'train_loss': '0.16440'}; time used = 0.9594478607177734s
epoch 15: {'train_loss': '0.10938'}; time used = 0.963238000869751s
epoch 20: {'train_loss': '0.12329'}; time used = 0.9852700233459473s
epoch 25: {'train_loss': '0.14875'}; time used = 1.0860416889190674s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.633218050003052.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37308'}; time used = 1.232537031173706s
epoch 10: {'train_loss': '1.31931'}; time used = 1.118669033050537s
epoch 15: {'train_loss': '1.16626'}; time used = 1.1408717632293701s
epoch 20: {'train_loss': '1.04141'}; time used = 1.1249921321868896s
epoch 25: {'train_loss': '0.75849'}; time used = 1.1178607940673828s
epoch 30: {'train_loss': '0.74747'}; time used = 1.214109182357788s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.992950439453125.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7661538461538462, 'samples': 0.7894736842105263, 'weighted': 0.7778137651821863, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.81234'}; time used = 1.0413622856140137s
epoch 10: {'train_loss': '2.77930'}; time used = 0.9484272003173828s
epoch 15: {'train_loss': '2.77274'}; time used = 0.9736001491546631s
epoch 20: {'train_loss': '2.77628'}; time used = 0.9894273281097412s
epoch 25: {'train_loss': '2.77690'}; time used = 0.9798538684844971s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 7.920728445053101.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7172619047619048, 'samples': 0.7368421052631579, 'weighted': 0.7290100250626566, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.39332'}; time used = 1.0559768676757812s
epoch 10: {'train_loss': '1.40529'}; time used = 1.076993465423584s
epoch 15: {'train_loss': '1.34709'}; time used = 0.9730439186096191s
epoch 20: {'train_loss': '1.37487'}; time used = 0.977304220199585s
epoch 25: {'train_loss': '1.33916'}; time used = 1.0846397876739502s
epoch 30: {'train_loss': '1.35642'}; time used = 0.9534969329833984s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.070428371429443.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7548387096774194, 'samples': 0.7631578947368421, 'weighted': 0.7619694397283531, 'accuracy': 0.7631578947368421}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.80742'}; time used = 2.856490135192871s
epoch 10: {'train_loss': '2.75573'}; time used = 2.874364137649536s
epoch 15: {'train_loss': '2.69637'}; time used = 3.0043623447418213s
epoch 20: {'train_loss': '2.63639'}; time used = 2.3188114166259766s
epoch 25: {'train_loss': '2.57774'}; time used = 1.7677927017211914s
epoch 30: {'train_loss': '2.51083'}; time used = 1.5910248756408691s
epoch 35: {'train_loss': '2.41835'}; time used = 1.6758553981781006s
epoch 40: {'train_loss': '2.30513'}; time used = 1.6277930736541748s
epoch 45: {'train_loss': '2.39905'}; time used = 1.9150924682617188s
epoch 50: {'train_loss': '2.36279'}; time used = 1.991225242614746s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.613950729370117.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86923'}; time used = 1.1398017406463623s
epoch 10: {'train_loss': '2.79428'}; time used = 1.0619685649871826s
epoch 15: {'train_loss': '2.77385'}; time used = 1.032806158065796s
epoch 20: {'train_loss': '2.77958'}; time used = 1.0864157676696777s
epoch 25: {'train_loss': '2.77819'}; time used = 1.292283296585083s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.726580381393433.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.78552'}; time used = 1.8536324501037598s
epoch 10: {'train_loss': '2.76148'}; time used = 1.869246244430542s
epoch 15: {'train_loss': '2.74308'}; time used = 3.3226826190948486s
epoch 20: {'train_loss': '2.70746'}; time used = 3.9708988666534424s
epoch 25: {'train_loss': '2.64665'}; time used = 4.018072128295898s
epoch 30: {'train_loss': '2.60319'}; time used = 1.7200255393981934s
epoch 35: {'train_loss': '2.54977'}; time used = 1.6756370067596436s
epoch 40: {'train_loss': '2.51150'}; time used = 1.687476634979248s
epoch 45: {'train_loss': '2.43598'}; time used = 1.7776117324829102s
epoch 50: {'train_loss': '2.34521'}; time used = 1.7137963771820068s
epoch 55: {'train_loss': '2.31187'}; time used = 1.8174829483032227s
epoch 60: {'train_loss': '2.25523'}; time used = 1.9397673606872559s
epoch 65: {'train_loss': '2.19893'}; time used = 1.939143180847168s
epoch 70: {'train_loss': '2.11163'}; time used = 1.702279806137085s
epoch 75: {'train_loss': '2.22732'}; time used = 1.795048713684082s
epoch 80: {'train_loss': '2.06741'}; time used = 1.7403173446655273s
epoch 85: {'train_loss': '2.04654'}; time used = 1.8098726272583008s
epoch 90: {'train_loss': '1.98110'}; time used = 1.6977031230926514s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.27826714515686.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.36837725381414704, 'samples': 0.5217391304347826, 'weighted': 0.3909304709642405, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.60 GiB already allocated; 1.30 GiB free; 17.03 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.87859'}; time used = 1.1445047855377197s
epoch 10: {'train_loss': '2.79819'}; time used = 1.0243785381317139s
epoch 15: {'train_loss': '2.77852'}; time used = 1.1169307231903076s
epoch 20: {'train_loss': '2.77561'}; time used = 1.0360023975372314s
epoch 25: {'train_loss': '2.77607'}; time used = 1.062093734741211s
epoch 30: {'train_loss': '2.77418'}; time used = 1.1112453937530518s
epoch 35: {'train_loss': '2.77461'}; time used = 1.0746116638183594s
epoch 40: {'train_loss': '2.77269'}; time used = 1.0184855461120605s
epoch 45: {'train_loss': '2.77396'}; time used = 1.030198574066162s
epoch 50: {'train_loss': '2.77149'}; time used = 1.0271344184875488s
epoch 55: {'train_loss': '2.77146'}; time used = 1.0070977210998535s
epoch 60: {'train_loss': '2.77196'}; time used = 1.0064442157745361s
epoch 65: {'train_loss': '2.77162'}; time used = 1.0013961791992188s
epoch 70: {'train_loss': '2.77048'}; time used = 1.0378663539886475s
epoch 75: {'train_loss': '2.76979'}; time used = 1.0913395881652832s
epoch 80: {'train_loss': '2.76722'}; time used = 1.0662834644317627s
epoch 85: {'train_loss': '2.76739'}; time used = 1.05755615234375s
epoch 90: {'train_loss': '2.76472'}; time used = 1.0257418155670166s
epoch 95: {'train_loss': '2.76213'}; time used = 1.0566768646240234s
epoch 100: {'train_loss': '2.75491'}; time used = 1.0778722763061523s
epoch 105: {'train_loss': '2.74685'}; time used = 1.0352511405944824s
epoch 110: {'train_loss': '2.72501'}; time used = 1.0708673000335693s
epoch 115: {'train_loss': '2.69539'}; time used = 1.0913035869598389s
epoch 120: {'train_loss': '2.68064'}; time used = 1.0577492713928223s
epoch 125: {'train_loss': '2.64043'}; time used = 1.0490162372589111s
epoch 130: {'train_loss': '2.63965'}; time used = 1.0371754169464111s
epoch 135: {'train_loss': '2.61164'}; time used = 1.0281195640563965s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.46384787559509.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8125440451021847, 'samples': 0.8157894736842105, 'weighted': 0.8164385594006157, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '3.01652'}; time used = 1.905632495880127s
epoch 10: {'train_loss': '2.83757'}; time used = 1.8885436058044434s
epoch 15: {'train_loss': '2.78078'}; time used = 1.9181475639343262s
epoch 20: {'train_loss': '2.77394'}; time used = 1.815598964691162s
epoch 25: {'train_loss': '2.77795'}; time used = 1.9219422340393066s
epoch 30: {'train_loss': '2.77080'}; time used = 1.7807328701019287s
epoch 35: {'train_loss': '2.77156'}; time used = 1.7754697799682617s
epoch 40: {'train_loss': '2.77179'}; time used = 1.7598812580108643s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.361401796340942.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4817404817404818, 'samples': 0.5797101449275363, 'weighted': 0.4980687589383242, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.35992'}; time used = 2.0360629558563232s
epoch 10: {'train_loss': '2.98530'}; time used = 1.9865076541900635s
epoch 15: {'train_loss': '2.88507'}; time used = 1.9822828769683838s
epoch 20: {'train_loss': '2.85917'}; time used = 1.9883642196655273s
epoch 25: {'train_loss': '2.83035'}; time used = 2.0556230545043945s
epoch 30: {'train_loss': '2.81824'}; time used = 2.032386541366577s
epoch 35: {'train_loss': '2.80992'}; time used = 2.13956356048584s
epoch 40: {'train_loss': '2.80247'}; time used = 2.029726028442383s
epoch 45: {'train_loss': '2.80468'}; time used = 2.0059003829956055s
epoch 50: {'train_loss': '2.79635'}; time used = 1.972881555557251s
epoch 55: {'train_loss': '2.79685'}; time used = 2.277883529663086s
epoch 60: {'train_loss': '2.79003'}; time used = 2.0470731258392334s
epoch 65: {'train_loss': '2.77700'}; time used = 1.984239101409912s
epoch 70: {'train_loss': '2.76793'}; time used = 2.101288318634033s
epoch 75: {'train_loss': '2.74993'}; time used = 2.1291041374206543s
epoch 80: {'train_loss': '2.72737'}; time used = 2.095322847366333s
epoch 85: {'train_loss': '2.69296'}; time used = 2.000427484512329s
epoch 90: {'train_loss': '2.66700'}; time used = 2.0153608322143555s
epoch 95: {'train_loss': '2.64200'}; time used = 2.159193277359009s
epoch 100: {'train_loss': '2.58645'}; time used = 1.9882826805114746s
epoch 105: {'train_loss': '2.59423'}; time used = 2.0391860008239746s
epoch 110: {'train_loss': '2.58174'}; time used = 1.9841959476470947s
epoch 115: {'train_loss': '2.54324'}; time used = 1.946052074432373s
epoch 120: {'train_loss': '2.54945'}; time used = 1.994858980178833s
epoch 125: {'train_loss': '2.53403'}; time used = 2.0699944496154785s
epoch 130: {'train_loss': '2.53723'}; time used = 2.0552725791931152s
epoch 135: {'train_loss': '2.56670'}; time used = 1.9732568264007568s
epoch 140: {'train_loss': '2.54571'}; time used = 1.9342668056488037s
epoch 145: {'train_loss': '2.51468'}; time used = 1.9630711078643799s
epoch 150: {'train_loss': '2.51159'}; time used = 1.968398094177246s
epoch 155: {'train_loss': '2.48690'}; time used = 1.9774062633514404s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 66.77912425994873.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.41025641025641024, 'samples': 0.5217391304347826, 'weighted': 0.42883686361947226, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.13268'}; time used = 1.1476924419403076s
epoch 10: {'train_loss': '2.79335'}; time used = 0.9632432460784912s
epoch 15: {'train_loss': '2.78170'}; time used = 1.010347843170166s
epoch 20: {'train_loss': '2.79644'}; time used = 1.1379694938659668s
epoch 25: {'train_loss': '2.77689'}; time used = 1.257265329360962s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.09958529472351.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.88360'}; time used = 1.1051464080810547s
epoch 10: {'train_loss': '2.80493'}; time used = 0.972043514251709s
epoch 15: {'train_loss': '2.79124'}; time used = 0.9484822750091553s
epoch 20: {'train_loss': '2.78297'}; time used = 0.9911177158355713s
epoch 25: {'train_loss': '2.77711'}; time used = 0.980353832244873s
epoch 30: {'train_loss': '2.77238'}; time used = 0.9636805057525635s
epoch 35: {'train_loss': '2.77002'}; time used = 0.9650216102600098s
epoch 40: {'train_loss': '2.76919'}; time used = 0.9408242702484131s
epoch 45: {'train_loss': '2.76897'}; time used = 0.9640405178070068s
epoch 50: {'train_loss': '2.76564'}; time used = 0.9797370433807373s
epoch 55: {'train_loss': '2.76276'}; time used = 0.9308412075042725s
epoch 60: {'train_loss': '2.76000'}; time used = 0.9694914817810059s
epoch 65: {'train_loss': '2.75362'}; time used = 1.0201013088226318s
epoch 70: {'train_loss': '2.72743'}; time used = 1.1162526607513428s
epoch 75: {'train_loss': '2.69693'}; time used = 1.1389522552490234s
epoch 80: {'train_loss': '2.63395'}; time used = 1.1913130283355713s
epoch 85: {'train_loss': '2.63470'}; time used = 1.1052873134613037s
epoch 90: {'train_loss': '2.59131'}; time used = 1.0985159873962402s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.55562448501587.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.20250'}; time used = 1.7426087856292725s
epoch 10: {'train_loss': '2.77935'}; time used = 1.8656203746795654s
epoch 15: {'train_loss': '2.70933'}; time used = 1.7301316261291504s
epoch 20: {'train_loss': '2.66240'}; time used = 1.8111653327941895s
epoch 25: {'train_loss': '2.62399'}; time used = 1.8007631301879883s
epoch 30: {'train_loss': '2.59575'}; time used = 1.8415157794952393s
epoch 35: {'train_loss': '2.56981'}; time used = 1.7603044509887695s
epoch 40: {'train_loss': '2.54797'}; time used = 1.8341455459594727s
epoch 45: {'train_loss': '2.52872'}; time used = 1.6974222660064697s
epoch 50: {'train_loss': '2.48889'}; time used = 1.963629961013794s
epoch 55: {'train_loss': '2.47205'}; time used = 1.9130213260650635s
epoch 60: {'train_loss': '2.44889'}; time used = 2.914961576461792s
epoch 65: {'train_loss': '2.39565'}; time used = 3.1691477298736572s
epoch 70: {'train_loss': '2.32166'}; time used = 3.0609052181243896s
epoch 75: {'train_loss': '2.30464'}; time used = 2.319284677505493s
epoch 80: {'train_loss': '2.28806'}; time used = 1.9110915660858154s
epoch 85: {'train_loss': '2.28732'}; time used = 1.6929259300231934s
epoch 90: {'train_loss': '2.28394'}; time used = 1.663132667541504s
epoch 95: {'train_loss': '2.25754'}; time used = 1.7203738689422607s
epoch 100: {'train_loss': '2.20921'}; time used = 1.6859800815582275s
epoch 105: {'train_loss': '2.20493'}; time used = 1.7490003108978271s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.2344012260437.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5739833936555248, 'samples': 0.5797101449275363, 'weighted': 0.5775626132005319, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.34 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.90086'}; time used = 3.511192560195923s
epoch 10: {'train_loss': '2.81202'}; time used = 2.7180075645446777s
epoch 15: {'train_loss': '2.81486'}; time used = 2.0075173377990723s
epoch 20: {'train_loss': '2.80136'}; time used = 1.8395326137542725s
epoch 25: {'train_loss': '2.79042'}; time used = 1.992051362991333s
epoch 30: {'train_loss': '2.78381'}; time used = 3.2614612579345703s
epoch 35: {'train_loss': '2.77922'}; time used = 1.8577334880828857s
epoch 40: {'train_loss': '2.77634'}; time used = 1.9540042877197266s
epoch 45: {'train_loss': '2.77419'}; time used = 1.7221722602844238s
epoch 50: {'train_loss': '2.77299'}; time used = 1.9130854606628418s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.75818133354187.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.44599844599844596, 'samples': 0.5507246376811594, 'weighted': 0.46345281127889815, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77200'}; time used = 1.1158933639526367s
epoch 10: {'train_loss': '2.77446'}; time used = 1.0706214904785156s
epoch 15: {'train_loss': '2.77858'}; time used = 1.1170389652252197s
epoch 20: {'train_loss': '2.77494'}; time used = 1.1419403553009033s
epoch 25: {'train_loss': '2.77232'}; time used = 1.0467250347137451s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.063696384429932.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.10033'}; time used = 1.0806779861450195s
epoch 10: {'train_loss': '2.79834'}; time used = 0.9885444641113281s
epoch 15: {'train_loss': '2.79971'}; time used = 1.1616804599761963s
epoch 20: {'train_loss': '2.80011'}; time used = 0.9752740859985352s
epoch 25: {'train_loss': '2.77300'}; time used = 1.2056808471679688s
epoch 30: {'train_loss': '2.78206'}; time used = 2.5029687881469727s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.002676963806152.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.49 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.35380'}; time used = 1.1977806091308594s
epoch 10: {'train_loss': '0.24596'}; time used = 1.135023593902588s
epoch 15: {'train_loss': '0.24066'}; time used = 1.2134277820587158s
epoch 20: {'train_loss': '0.23398'}; time used = 1.0686063766479492s
epoch 25: {'train_loss': '0.27155'}; time used = 1.0906639099121094s
epoch 30: {'train_loss': '0.19694'}; time used = 1.0979158878326416s
epoch 35: {'train_loss': '0.20978'}; time used = 1.026075839996338s
epoch 40: {'train_loss': '0.19240'}; time used = 0.9357857704162598s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.788809299468994.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 27.17 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.78071'}; time used = 4.803914785385132s
epoch 10: {'train_loss': '2.78421'}; time used = 4.7488508224487305s
epoch 15: {'train_loss': '2.77383'}; time used = 4.634536504745483s
epoch 20: {'train_loss': '2.76977'}; time used = 4.782945871353149s
epoch 25: {'train_loss': '2.76902'}; time used = 4.729165077209473s
epoch 30: {'train_loss': '2.76524'}; time used = 4.78408670425415s
epoch 35: {'train_loss': '2.76088'}; time used = 4.635644435882568s
epoch 40: {'train_loss': '2.75628'}; time used = 4.751735687255859s
epoch 45: {'train_loss': '2.74901'}; time used = 4.687471628189087s
epoch 50: {'train_loss': '2.74592'}; time used = 5.034651517868042s
epoch 55: {'train_loss': '2.74293'}; time used = 6.268018960952759s
epoch 60: {'train_loss': '2.77202'}; time used = 8.105451107025146s
epoch 65: {'train_loss': '2.75436'}; time used = 5.026612758636475s
epoch 70: {'train_loss': '2.75057'}; time used = 5.252175331115723s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 126.30510950088501.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.719747772995696, 'samples': 0.72, 'weighted': 0.7195796216594934, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.17664'}; time used = 2.554436445236206s
epoch 10: {'train_loss': '1.10928'}; time used = 3.001392126083374s
epoch 15: {'train_loss': '0.90439'}; time used = 2.9797422885894775s
epoch 20: {'train_loss': '0.80030'}; time used = 2.20157527923584s
epoch 25: {'train_loss': '0.53702'}; time used = 1.7951295375823975s
epoch 30: {'train_loss': '0.38720'}; time used = 2.851461410522461s
epoch 35: {'train_loss': '0.29466'}; time used = 3.2944939136505127s
epoch 40: {'train_loss': '0.23322'}; time used = 2.6267569065093994s
epoch 45: {'train_loss': '0.13456'}; time used = 1.7898974418640137s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.776426315307617.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5792682926829268, 'samples': 0.5942028985507246, 'weighted': 0.5850123718628489, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '0.41234'}; time used = 2.300368070602417s
epoch 10: {'train_loss': '0.28914'}; time used = 2.683070421218872s
epoch 15: {'train_loss': '0.19308'}; time used = 3.2242655754089355s
epoch 20: {'train_loss': '0.31267'}; time used = 2.8829944133758545s
epoch 25: {'train_loss': '0.70885'}; time used = 1.8798532485961914s
epoch 30: {'train_loss': '0.28229'}; time used = 1.6893715858459473s
epoch 35: {'train_loss': '0.47985'}; time used = 1.5152466297149658s
epoch 40: {'train_loss': '0.34453'}; time used = 1.6715445518493652s
epoch 45: {'train_loss': '0.33202'}; time used = 1.4927818775177002s
epoch 50: {'train_loss': '0.41289'}; time used = 1.5715949535369873s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.366299867630005.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5899830220713073, 'samples': 0.5942028985507246, 'weighted': 0.5929972195566053, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.49 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.24717'}; time used = 1.5644357204437256s
epoch 10: {'train_loss': '1.17426'}; time used = 1.4843778610229492s
epoch 15: {'train_loss': '1.14437'}; time used = 1.677299976348877s
epoch 20: {'train_loss': '1.09879'}; time used = 1.5470952987670898s
epoch 25: {'train_loss': '1.04810'}; time used = 1.5820772647857666s
epoch 30: {'train_loss': '1.01622'}; time used = 1.5330696105957031s
epoch 35: {'train_loss': '0.98549'}; time used = 1.5642170906066895s
epoch 40: {'train_loss': '0.74950'}; time used = 1.5829710960388184s
epoch 45: {'train_loss': '0.48018'}; time used = 1.5301144123077393s
epoch 50: {'train_loss': '0.45961'}; time used = 1.5222642421722412s
epoch 55: {'train_loss': '0.29787'}; time used = 1.6242761611938477s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.286397695541382.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5606960950764007, 'samples': 0.5652173913043478, 'weighted': 0.5639255923820773, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.20778'}; time used = 1.8404738903045654s
epoch 10: {'train_loss': '1.02254'}; time used = 1.7791857719421387s
epoch 15: {'train_loss': '0.47395'}; time used = 1.8638949394226074s
epoch 20: {'train_loss': '0.27501'}; time used = 1.8670387268066406s
epoch 25: {'train_loss': '0.13586'}; time used = 2.6636033058166504s
epoch 30: {'train_loss': '0.09666'}; time used = 3.1471941471099854s
epoch 35: {'train_loss': '0.11933'}; time used = 3.2200374603271484s
epoch 40: {'train_loss': '0.13395'}; time used = 3.6106162071228027s
epoch 45: {'train_loss': '0.14752'}; time used = 3.1054086685180664s
epoch 50: {'train_loss': '0.18302'}; time used = 2.9715147018432617s
epoch 55: {'train_loss': '0.14242'}; time used = 3.3649652004241943s
epoch 60: {'train_loss': '0.12573'}; time used = 2.0545809268951416s
epoch 65: {'train_loss': '0.09060'}; time used = 1.896071434020996s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.539533376693726.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.80722'}; time used = 2.207335948944092s
epoch 10: {'train_loss': '2.77809'}; time used = 2.1786696910858154s
epoch 15: {'train_loss': '2.77193'}; time used = 1.7960190773010254s
epoch 20: {'train_loss': '2.76537'}; time used = 2.2953009605407715s
epoch 25: {'train_loss': '2.76017'}; time used = 1.9906013011932373s
epoch 30: {'train_loss': '2.75837'}; time used = 2.0126266479492188s
epoch 35: {'train_loss': '2.75806'}; time used = 1.8299064636230469s
epoch 40: {'train_loss': '2.76032'}; time used = 1.8952796459197998s
epoch 45: {'train_loss': '2.75733'}; time used = 1.9301612377166748s
epoch 50: {'train_loss': '2.75380'}; time used = 2.0448150634765625s
epoch 55: {'train_loss': '2.76148'}; time used = 1.740565299987793s
epoch 60: {'train_loss': '2.75348'}; time used = 1.8738915920257568s
epoch 65: {'train_loss': '2.74065'}; time used = 1.8279695510864258s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.98946714401245.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.47826086956521735, 'samples': 0.5362318840579711, 'weighted': 0.4908632640201637, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.02 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.81658'}; time used = 4.224694013595581s
epoch 10: {'train_loss': '2.78092'}; time used = 3.3096604347229004s
epoch 15: {'train_loss': '2.76087'}; time used = 1.9806287288665771s
epoch 20: {'train_loss': '2.75167'}; time used = 1.9443273544311523s
epoch 25: {'train_loss': '2.74306'}; time used = 2.1373038291931152s
epoch 30: {'train_loss': '2.72554'}; time used = 1.912353754043579s
epoch 35: {'train_loss': '2.71643'}; time used = 1.9960169792175293s
epoch 40: {'train_loss': '2.70871'}; time used = 2.5245673656463623s
epoch 45: {'train_loss': '2.70224'}; time used = 3.696636199951172s
epoch 50: {'train_loss': '2.69439'}; time used = 3.8521645069122314s
epoch 55: {'train_loss': '2.69380'}; time used = 2.2193779945373535s
epoch 60: {'train_loss': '2.67553'}; time used = 1.9674413204193115s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.97691082954407.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.4763769889840881, 'samples': 0.5507246376811594, 'weighted': 0.49067461373352494, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.26327'}; time used = 1.623896837234497s
epoch 10: {'train_loss': '1.13159'}; time used = 1.5759146213531494s
epoch 15: {'train_loss': '0.98224'}; time used = 1.6027898788452148s
epoch 20: {'train_loss': '0.92522'}; time used = 1.5958316326141357s
epoch 25: {'train_loss': '0.85927'}; time used = 1.844043254852295s
epoch 30: {'train_loss': '0.80303'}; time used = 1.7482578754425049s
epoch 35: {'train_loss': '0.77291'}; time used = 1.6161353588104248s
epoch 40: {'train_loss': '0.72248'}; time used = 1.5722131729125977s
epoch 45: {'train_loss': '0.63729'}; time used = 1.699751377105713s
epoch 50: {'train_loss': '0.37333'}; time used = 1.7917404174804688s
epoch 55: {'train_loss': '0.16888'}; time used = 1.886497974395752s
epoch 60: {'train_loss': '0.07770'}; time used = 1.695141315460205s
epoch 65: {'train_loss': '0.07173'}; time used = 1.6151137351989746s
epoch 70: {'train_loss': '0.04928'}; time used = 1.636615514755249s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.51557493209839.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5606960950764007, 'samples': 0.5652173913043478, 'weighted': 0.5639255923820773, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.79429'}; time used = 3.1181089878082275s
epoch 10: {'train_loss': '2.82693'}; time used = 2.399381637573242s
epoch 15: {'train_loss': '2.77315'}; time used = 2.5060365200042725s
epoch 20: {'train_loss': '2.76507'}; time used = 2.4440817832946777s
epoch 25: {'train_loss': '2.76306'}; time used = 2.50604248046875s
epoch 30: {'train_loss': '2.74754'}; time used = 2.415384292602539s
epoch 35: {'train_loss': '2.72452'}; time used = 2.439749240875244s
epoch 40: {'train_loss': '2.71689'}; time used = 2.4571709632873535s
epoch 45: {'train_loss': '2.68408'}; time used = 2.4694759845733643s
epoch 50: {'train_loss': '2.65931'}; time used = 2.5132975578308105s
epoch 55: {'train_loss': '2.61870'}; time used = 2.639634847640991s
epoch 60: {'train_loss': '2.98148'}; time used = 2.533356189727783s
epoch 65: {'train_loss': '2.61622'}; time used = 2.455005645751953s
epoch 70: {'train_loss': '2.63300'}; time used = 3.4431731700897217s
epoch 75: {'train_loss': '2.53056'}; time used = 3.542498826980591s
epoch 80: {'train_loss': '2.51244'}; time used = 3.4625322818756104s
epoch 85: {'train_loss': '2.46501'}; time used = 2.4604203701019287s
epoch 90: {'train_loss': '2.45561'}; time used = 2.267432451248169s
epoch 95: {'train_loss': '2.42158'}; time used = 2.3083081245422363s
epoch 100: {'train_loss': '2.39969'}; time used = 2.315120220184326s
epoch 105: {'train_loss': '2.40677'}; time used = 2.3380446434020996s
epoch 110: {'train_loss': '2.39352'}; time used = 2.2677130699157715s
epoch 115: {'train_loss': '2.38969'}; time used = 2.3849880695343018s
epoch 120: {'train_loss': '2.35077'}; time used = 2.308642864227295s
epoch 125: {'train_loss': '2.38618'}; time used = 2.3371353149414062s
epoch 130: {'train_loss': '2.33722'}; time used = 2.2925186157226562s
epoch 135: {'train_loss': '2.33185'}; time used = 2.4429211616516113s
epoch 140: {'train_loss': '2.33463'}; time used = 2.346470832824707s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 75.69804978370667.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.6327443048754524, 'samples': 0.6376811594202898, 'weighted': 0.6358298389659759, 'accuracy': 0.6376811594202898}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 5.567480087280273s
epoch 10: {'train_loss': '1.38629'}; time used = 4.354349374771118s
epoch 15: {'train_loss': '1.38629'}; time used = 4.857373476028442s
epoch 20: {'train_loss': '1.38629'}; time used = 4.894272327423096s
epoch 25: {'train_loss': '1.38629'}; time used = 4.413360357284546s
epoch 30: {'train_loss': '1.38629'}; time used = 4.2975029945373535s
epoch 35: {'train_loss': '1.38629'}; time used = 4.275527477264404s
epoch 40: {'train_loss': '1.38629'}; time used = 4.177406549453735s
epoch 45: {'train_loss': '1.38629'}; time used = 4.561450004577637s
epoch 50: {'train_loss': '1.38629'}; time used = 4.702664852142334s
epoch 55: {'train_loss': '1.38629'}; time used = 5.537328243255615s
epoch 60: {'train_loss': '1.38629'}; time used = 6.541475296020508s
epoch 65: {'train_loss': '1.38629'}; time used = 4.179035902023315s
epoch 70: {'train_loss': '1.38629'}; time used = 4.2246949672698975s
epoch 75: {'train_loss': '1.38629'}; time used = 4.232195615768433s
epoch 80: {'train_loss': '1.38629'}; time used = 4.114879846572876s
epoch 85: {'train_loss': '1.38629'}; time used = 4.263644456863403s
epoch 90: {'train_loss': '1.38629'}; time used = 4.475599050521851s
epoch 95: {'train_loss': '1.38629'}; time used = 4.964499235153198s
epoch 100: {'train_loss': '1.38629'}; time used = 4.6372292041778564s
epoch 105: {'train_loss': '1.38629'}; time used = 4.243709325790405s
epoch 110: {'train_loss': '1.38629'}; time used = 4.230952978134155s
epoch 115: {'train_loss': '1.38629'}; time used = 4.37932562828064s
epoch 120: {'train_loss': '1.38629'}; time used = 4.22326922416687s
epoch 125: {'train_loss': '1.38629'}; time used = 4.272360324859619s
epoch 130: {'train_loss': '1.38629'}; time used = 4.344594240188599s
epoch 135: {'train_loss': '1.38629'}; time used = 4.624400615692139s
epoch 140: {'train_loss': '1.38629'}; time used = 4.366721868515015s
epoch 145: {'train_loss': '1.38629'}; time used = 4.513982534408569s
epoch 150: {'train_loss': '1.38629'}; time used = 4.0985753536224365s
epoch 155: {'train_loss': '1.38629'}; time used = 4.43621826171875s
epoch 160: {'train_loss': '1.38629'}; time used = 4.518948554992676s
epoch 165: {'train_loss': '1.38629'}; time used = 4.468588829040527s
epoch 170: {'train_loss': '1.38629'}; time used = 4.023134231567383s
epoch 175: {'train_loss': '1.38629'}; time used = 3.988557815551758s
epoch 180: {'train_loss': '1.38629'}; time used = 4.269747018814087s
epoch 185: {'train_loss': '1.38629'}; time used = 4.8485541343688965s
epoch 190: {'train_loss': '1.38629'}; time used = 4.069641351699829s
epoch 195: {'train_loss': '1.38629'}; time used = 4.022152662277222s
epoch 200: {'train_loss': '1.38629'}; time used = 4.206681728363037s
epoch 205: {'train_loss': '1.38629'}; time used = 4.099070310592651s
epoch 210: {'train_loss': '1.38629'}; time used = 4.233580589294434s
epoch 215: {'train_loss': '1.38629'}; time used = 3.997641086578369s
epoch 220: {'train_loss': '1.38629'}; time used = 4.534897804260254s
epoch 225: {'train_loss': '1.38629'}; time used = 4.938684463500977s
epoch 230: {'train_loss': '1.38629'}; time used = 4.246190786361694s
epoch 235: {'train_loss': '1.38629'}; time used = 5.295497417449951s
epoch 240: {'train_loss': '1.38629'}; time used = 7.260349988937378s
epoch 245: {'train_loss': '1.38629'}; time used = 5.060290813446045s
epoch 250: {'train_loss': '1.38629'}; time used = 4.233403205871582s
epoch 255: {'train_loss': '1.38629'}; time used = 4.4465172290802s
epoch 260: {'train_loss': '1.38629'}; time used = 4.264829874038696s
epoch 265: {'train_loss': '1.38629'}; time used = 4.074459791183472s
epoch 270: {'train_loss': '1.38629'}; time used = 4.1134724617004395s
epoch 275: {'train_loss': '1.38629'}; time used = 4.148598909378052s
epoch 280: {'train_loss': '1.38629'}; time used = 4.189427375793457s
epoch 285: {'train_loss': '1.38629'}; time used = 4.0545432567596436s
epoch 290: {'train_loss': '1.38629'}; time used = 4.041776895523071s
epoch 295: {'train_loss': '1.38629'}; time used = 4.170097589492798s
epoch 300: {'train_loss': '1.38629'}; time used = 4.190019607543945s
epoch 305: {'train_loss': '1.38629'}; time used = 4.0852437019348145s
epoch 310: {'train_loss': '1.38629'}; time used = 4.243396997451782s
epoch 315: {'train_loss': '1.38629'}; time used = 4.19370698928833s
epoch 320: {'train_loss': '1.38629'}; time used = 6.063169717788696s
epoch 325: {'train_loss': '1.38629'}; time used = 4.432590007781982s
epoch 330: {'train_loss': '1.38629'}; time used = 4.3379199504852295s
epoch 335: {'train_loss': '1.38629'}; time used = 4.115095615386963s
epoch 340: {'train_loss': '1.38629'}; time used = 4.183696508407593s
epoch 345: {'train_loss': '1.38629'}; time used = 4.2305591106414795s
epoch 350: {'train_loss': '1.38629'}; time used = 4.212863445281982s
epoch 355: {'train_loss': '1.38629'}; time used = 6.4994401931762695s
epoch 360: {'train_loss': '1.38629'}; time used = 7.918300151824951s
epoch 365: {'train_loss': '1.38629'}; time used = 5.032649755477905s
epoch 370: {'train_loss': '1.38629'}; time used = 4.2038586139678955s
epoch 375: {'train_loss': '1.38629'}; time used = 4.29648232460022s
epoch 380: {'train_loss': '1.38629'}; time used = 4.214081764221191s
epoch 385: {'train_loss': '1.38629'}; time used = 4.89017653465271s
epoch 390: {'train_loss': '1.38629'}; time used = 4.291724681854248s
epoch 395: {'train_loss': '1.38629'}; time used = 4.076024770736694s
epoch 400: {'train_loss': '1.38629'}; time used = 4.234703779220581s
epoch 405: {'train_loss': '1.38629'}; time used = 4.180927991867065s
epoch 410: {'train_loss': '1.38629'}; time used = 5.478325843811035s
epoch 415: {'train_loss': '1.38629'}; time used = 4.02921724319458s
epoch 420: {'train_loss': '1.38629'}; time used = 4.27636456489563s
epoch 425: {'train_loss': '1.38629'}; time used = 4.114665269851685s
epoch 430: {'train_loss': '1.38629'}; time used = 4.152199029922485s
epoch 435: {'train_loss': '1.38629'}; time used = 4.1195690631866455s
epoch 440: {'train_loss': '1.38629'}; time used = 3.9240660667419434s
epoch 445: {'train_loss': '1.38629'}; time used = 3.9987809658050537s
epoch 450: {'train_loss': '1.38629'}; time used = 4.033738374710083s
epoch 455: {'train_loss': '1.38629'}; time used = 4.00575065612793s
epoch 460: {'train_loss': '1.38629'}; time used = 3.952923536300659s
epoch 465: {'train_loss': '1.38629'}; time used = 4.083857536315918s
epoch 470: {'train_loss': '1.38629'}; time used = 4.0806190967559814s
epoch 475: {'train_loss': '1.38629'}; time used = 4.070005178451538s
epoch 480: {'train_loss': '1.38629'}; time used = 4.04715633392334s
epoch 485: {'train_loss': '1.38629'}; time used = 4.161273241043091s
epoch 490: {'train_loss': '1.38629'}; time used = 4.112385511398315s
epoch 495: {'train_loss': '1.38629'}; time used = 4.344325304031372s
epoch 500: {'train_loss': '1.38629'}; time used = 4.155400514602661s
Finished training. Time used = 453.53728008270264.
Training classifier using 80.00% nodes...
{'micro': 0.65, 'macro': 0.6457131288591963, 'samples': 0.65, 'weighted': 0.6449336977426864, 'accuracy': 0.65}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.89 GiB already allocated; 1.01 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36382'}; time used = 1.879213809967041s
epoch 10: {'train_loss': '1.28572'}; time used = 1.8633551597595215s
epoch 15: {'train_loss': '1.16988'}; time used = 1.9189770221710205s
epoch 20: {'train_loss': '1.15245'}; time used = 2.9610445499420166s
epoch 25: {'train_loss': '0.95459'}; time used = 3.728876829147339s
epoch 30: {'train_loss': '0.83388'}; time used = 3.550238609313965s
epoch 35: {'train_loss': '0.89747'}; time used = 2.011384963989258s
epoch 40: {'train_loss': '0.75081'}; time used = 1.9510889053344727s
epoch 45: {'train_loss': '0.62057'}; time used = 1.8914611339569092s
epoch 50: {'train_loss': '0.35958'}; time used = 1.8805291652679443s
epoch 55: {'train_loss': '0.34417'}; time used = 1.822453498840332s
epoch 60: {'train_loss': '0.36563'}; time used = 1.795903205871582s
epoch 65: {'train_loss': '0.36604'}; time used = 2.01176118850708s
epoch 70: {'train_loss': '0.13208'}; time used = 1.8606631755828857s
epoch 75: {'train_loss': '0.03637'}; time used = 1.9812281131744385s
epoch 80: {'train_loss': '0.11198'}; time used = 1.996511697769165s
epoch 85: {'train_loss': '0.13641'}; time used = 1.9216907024383545s
epoch 90: {'train_loss': '0.01983'}; time used = 1.784961462020874s
epoch 95: {'train_loss': '0.07652'}; time used = 1.834885835647583s
epoch 100: {'train_loss': '0.70686'}; time used = 3.9915428161621094s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 50.66579508781433.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5315564495851144, 'samples': 0.6086956521739131, 'weighted': 0.545331307190257, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.16183'}; time used = 1.8148329257965088s
epoch 10: {'train_loss': '0.01436'}; time used = 1.753713846206665s
epoch 15: {'train_loss': '0.04782'}; time used = 1.6705477237701416s
epoch 20: {'train_loss': '0.00085'}; time used = 1.6791388988494873s
epoch 25: {'train_loss': '0.01799'}; time used = 1.7754015922546387s
epoch 30: {'train_loss': '0.00014'}; time used = 1.6563842296600342s
epoch 35: {'train_loss': '0.11317'}; time used = 1.6664464473724365s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.465596675872803.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5208333333333334, 'samples': 0.5652173913043478, 'weighted': 0.5314009661835749, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.44 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 252, in main
    res = task.evaluate(model, res, graph)  # evaluate
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/graph_classification.py", line 21, in evaluate
    return self._classify(dataset, res, 0)
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/graph_classification.py", line 34, in _classify
    return clf.train_and_evaluate(dataset, self.train_kwargs()['clf_ratio'], seed=seed)
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/classify.py", line 80, in train_and_evaluate
    self.train(X_train, Y_train, graph.labels()[1])
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/classify.py", line 50, in train
    self.clf.fit(X_train, Y)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/multiclass.py", line 216, in fit
    for i, column in enumerate(columns))
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 921, in __call__
    if self.dispatch_one_batch(iterator):
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 759, in dispatch_one_batch
    self._dispatch(tasks)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 716, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/_parallel_backends.py", line 182, in apply_async
    result = ImmediateResult(func)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/_parallel_backends.py", line 549, in __init__
    self.results = batch()
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 225, in __call__
    for func, args, kwargs in self.items]
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 225, in <listcomp>
    for func, args, kwargs in self.items]
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/multiclass.py", line 80, in _fit_binary
    estimator.fit(X, y)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py", line 2004, in fit
    accept_large_sparse=solver != 'liblinear')
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/utils/validation.py", line 719, in check_X_y
    estimator=estimator)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/utils/validation.py", line 542, in check_array
    allow_nan=force_all_finite == 'allow-nan')
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/utils/validation.py", line 56, in _assert_all_finite
    raise ValueError(msg_err.format(type_err, X.dtype))
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.40995'}; time used = 2.126781940460205s
epoch 10: {'train_loss': '1.34769'}; time used = 1.9790136814117432s
epoch 15: {'train_loss': '1.37109'}; time used = 1.9083571434020996s
epoch 20: {'train_loss': '1.44586'}; time used = 2.1396520137786865s
epoch 25: {'train_loss': '1.37457'}; time used = 2.28277850151062s
epoch 30: {'train_loss': '1.33536'}; time used = 3.71126389503479s
epoch 35: {'train_loss': '1.34308'}; time used = 3.774851083755493s
epoch 40: {'train_loss': '0.67122'}; time used = 3.8026201725006104s
epoch 45: {'train_loss': '0.00000'}; time used = 1.8834693431854248s
epoch 50: {'train_loss': '0.01676'}; time used = 1.8893043994903564s
epoch 55: {'train_loss': '0.00008'}; time used = 1.8298225402832031s
epoch 60: {'train_loss': '0.00000'}; time used = 1.864302396774292s
epoch 65: {'train_loss': '0.00000'}; time used = 1.9446353912353516s
epoch 70: {'train_loss': '0.00000'}; time used = 1.835893154144287s
epoch 75: {'train_loss': '0.00000'}; time used = 2.0466148853302s
epoch 80: {'train_loss': '0.00000'}; time used = 1.9742257595062256s
epoch 85: {'train_loss': '0.00000'}; time used = 2.0230796337127686s
epoch 90: {'train_loss': '0.00000'}; time used = 1.824831247329712s
epoch 95: {'train_loss': '0.00000'}; time used = 1.830897331237793s
epoch 100: {'train_loss': 'nan'}; time used = 1.9341959953308105s
epoch 105: {'train_loss': 'nan'}; time used = 1.9931342601776123s
epoch 110: {'train_loss': 'nan'}; time used = 1.990478515625s
epoch 115: {'train_loss': 'nan'}; time used = 2.15035080909729s
epoch 120: {'train_loss': 'nan'}; time used = 2.1493258476257324s
epoch 125: {'train_loss': 'nan'}; time used = 1.9706001281738281s
epoch 130: {'train_loss': 'nan'}; time used = 3.8024990558624268s
epoch 135: {'train_loss': 'nan'}; time used = 3.9297828674316406s
epoch 140: {'train_loss': 'nan'}; time used = 2.0530853271484375s
epoch 145: {'train_loss': 'nan'}; time used = 1.948517084121704s
epoch 150: {'train_loss': 'nan'}; time used = 2.7746987342834473s
epoch 155: {'train_loss': 'nan'}; time used = 1.8626585006713867s
epoch 160: {'train_loss': 'nan'}; time used = 1.9930140972137451s
epoch 165: {'train_loss': 'nan'}; time used = 1.8058338165283203s
epoch 170: {'train_loss': 'nan'}; time used = 1.7790148258209229s
epoch 175: {'train_loss': 'nan'}; time used = 1.7699661254882812s
epoch 180: {'train_loss': 'nan'}; time used = 1.838947057723999s
epoch 185: {'train_loss': 'nan'}; time used = 1.9570386409759521s
epoch 190: {'train_loss': 'nan'}; time used = 1.791722297668457s
epoch 195: {'train_loss': 'nan'}; time used = 1.7912676334381104s
epoch 200: {'train_loss': 'nan'}; time used = 1.7680926322937012s
epoch 205: {'train_loss': 'nan'}; time used = 3.9687092304229736s
epoch 210: {'train_loss': 'nan'}; time used = 2.406348466873169s
epoch 215: {'train_loss': 'nan'}; time used = 2.9887218475341797s
epoch 220: {'train_loss': 'nan'}; time used = 3.4923598766326904s
epoch 225: {'train_loss': 'nan'}; time used = 1.8080830574035645s
epoch 230: {'train_loss': 'nan'}; time used = 1.9725720882415771s
epoch 235: {'train_loss': 'nan'}; time used = 1.986907958984375s
epoch 240: {'train_loss': 'nan'}; time used = 1.8281702995300293s
epoch 245: {'train_loss': 'nan'}; time used = 1.8588366508483887s
epoch 250: {'train_loss': 'nan'}; time used = 1.9698436260223389s
epoch 255: {'train_loss': 'nan'}; time used = 1.8658204078674316s
epoch 260: {'train_loss': 'nan'}; time used = 2.1489064693450928s
epoch 265: {'train_loss': 'nan'}; time used = 1.8506090641021729s
epoch 270: {'train_loss': 'nan'}; time used = 2.1034653186798096s
epoch 275: {'train_loss': 'nan'}; time used = 2.02903413772583s
epoch 280: {'train_loss': 'nan'}; time used = 3.6436166763305664s
epoch 285: {'train_loss': 'nan'}; time used = 4.475412130355835s
epoch 290: {'train_loss': 'nan'}; time used = 4.885153532028198s
epoch 295: {'train_loss': 'nan'}; time used = 4.502717971801758s
epoch 300: {'train_loss': 'nan'}; time used = 4.3967907428741455s
epoch 305: {'train_loss': 'nan'}; time used = 4.022662162780762s
epoch 310: {'train_loss': 'nan'}; time used = 2.6720104217529297s
epoch 315: {'train_loss': 'nan'}; time used = 2.18034029006958s
epoch 320: {'train_loss': 'nan'}; time used = 2.0053226947784424s
epoch 325: {'train_loss': 'nan'}; time used = 2.0033156871795654s
epoch 330: {'train_loss': 'nan'}; time used = 2.0105488300323486s
epoch 335: {'train_loss': 'nan'}; time used = 3.607905149459839s
epoch 340: {'train_loss': 'nan'}; time used = 3.516970634460449s
epoch 345: {'train_loss': 'nan'}; time used = 3.0375406742095947s
epoch 350: {'train_loss': 'nan'}; time used = 1.830512523651123s
epoch 355: {'train_loss': 'nan'}; time used = 1.8801624774932861s
epoch 360: {'train_loss': 'nan'}; time used = 1.7904224395751953s
epoch 365: {'train_loss': 'nan'}; time used = 2.601181983947754s
epoch 370: {'train_loss': 'nan'}; time used = 2.126721143722534s
epoch 375: {'train_loss': 'nan'}; time used = 1.8203375339508057s
epoch 380: {'train_loss': 'nan'}; time used = 1.8707334995269775s
epoch 385: {'train_loss': 'nan'}; time used = 1.835705041885376s
epoch 390: {'train_loss': 'nan'}; time used = 2.0924689769744873s
epoch 395: {'train_loss': 'nan'}; time used = 2.347416639328003s
epoch 400: {'train_loss': 'nan'}; time used = 3.7696614265441895s
epoch 405: {'train_loss': 'nan'}; time used = 4.171141147613525s
epoch 410: {'train_loss': 'nan'}; time used = 4.6425251960754395s
epoch 415: {'train_loss': 'nan'}; time used = 4.359795570373535s
epoch 420: {'train_loss': 'nan'}; time used = 1.8863184452056885s
epoch 425: {'train_loss': 'nan'}; time used = 1.8830852508544922s
epoch 430: {'train_loss': 'nan'}; time used = 1.833017110824585s
epoch 435: {'train_loss': 'nan'}; time used = 1.8504352569580078s
epoch 440: {'train_loss': 'nan'}; time used = 1.8899965286254883s
epoch 445: {'train_loss': 'nan'}; time used = 3.536412000656128s
epoch 450: {'train_loss': 'nan'}; time used = 1.9670283794403076s
epoch 455: {'train_loss': 'nan'}; time used = 1.9459435939788818s
epoch 460: {'train_loss': 'nan'}; time used = 1.7756068706512451s
epoch 465: {'train_loss': 'nan'}; time used = 1.9135186672210693s
epoch 470: {'train_loss': 'nan'}; time used = 1.8363099098205566s
epoch 475: {'train_loss': 'nan'}; time used = 1.7483248710632324s
epoch 480: {'train_loss': 'nan'}; time used = 2.057429075241089s
epoch 485: {'train_loss': 'nan'}; time used = 1.9281401634216309s
epoch 490: {'train_loss': 'nan'}; time used = 2.1412062644958496s
epoch 495: {'train_loss': 'nan'}; time used = 2.2224130630493164s
epoch 500: {'train_loss': 'nan'}; time used = 1.8876688480377197s
Finished training. Time used = 258.8524127006531.
Training classifier using 80.00% nodes...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.23521'}; time used = 2.9046630859375s
epoch 10: {'train_loss': '1.15595'}; time used = 1.984602689743042s
epoch 15: {'train_loss': '1.03288'}; time used = 2.1320788860321045s
epoch 20: {'train_loss': '0.91302'}; time used = 2.092290163040161s
epoch 25: {'train_loss': '0.84340'}; time used = 2.0790109634399414s
epoch 30: {'train_loss': '0.77937'}; time used = 1.91690993309021s
epoch 35: {'train_loss': '0.67980'}; time used = 1.8919153213500977s
epoch 40: {'train_loss': '0.46720'}; time used = 3.031191825866699s
epoch 45: {'train_loss': '0.29688'}; time used = 3.435533046722412s
epoch 50: {'train_loss': '0.26742'}; time used = 3.116223096847534s
epoch 55: {'train_loss': '0.23546'}; time used = 2.3406460285186768s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.239309549331665.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5434782608695652, 'samples': 0.5942028985507246, 'weighted': 0.5545053560176434, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.23109'}; time used = 1.1491045951843262s
epoch 10: {'train_loss': '2.89361'}; time used = 1.0603210926055908s
epoch 15: {'train_loss': '2.77772'}; time used = 1.0792996883392334s
epoch 20: {'train_loss': '2.79009'}; time used = 1.061730146408081s
epoch 25: {'train_loss': '2.78459'}; time used = 0.954972505569458s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.589070081710815.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6955128205128205, 'samples': 0.7368421052631579, 'weighted': 0.713225371120108, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.63030'}; time used = 1.04876708984375s
epoch 10: {'train_loss': '0.43721'}; time used = 1.0281999111175537s
epoch 15: {'train_loss': '0.30247'}; time used = 1.0436112880706787s
epoch 20: {'train_loss': '0.21032'}; time used = 0.9764032363891602s
epoch 25: {'train_loss': '0.18059'}; time used = 0.9907281398773193s
epoch 30: {'train_loss': '0.14936'}; time used = 1.0879762172698975s
epoch 35: {'train_loss': '0.05593'}; time used = 0.9125206470489502s
epoch 40: {'train_loss': '0.13740'}; time used = 0.9368910789489746s
epoch 45: {'train_loss': '0.10892'}; time used = 0.9152274131774902s
epoch 50: {'train_loss': '0.13871'}; time used = 0.9395203590393066s
epoch 55: {'train_loss': '0.15067'}; time used = 0.9239864349365234s
epoch 60: {'train_loss': '0.10417'}; time used = 1.0592832565307617s
epoch 65: {'train_loss': '0.08571'}; time used = 0.951324462890625s
epoch 70: {'train_loss': '0.04951'}; time used = 0.9386014938354492s
epoch 75: {'train_loss': '0.10604'}; time used = 0.9187958240509033s
epoch 80: {'train_loss': '0.15426'}; time used = 0.9109086990356445s
epoch 85: {'train_loss': '0.24255'}; time used = 0.9286880493164062s
epoch 90: {'train_loss': '0.05430'}; time used = 0.9246730804443359s
epoch 95: {'train_loss': '0.10722'}; time used = 0.9223601818084717s
epoch 100: {'train_loss': '0.22446'}; time used = 0.9477038383483887s
epoch 105: {'train_loss': '0.15639'}; time used = 1.1637871265411377s
epoch 110: {'train_loss': '0.15488'}; time used = 2.331397771835327s
epoch 115: {'train_loss': '0.10953'}; time used = 1.2345001697540283s
epoch 120: {'train_loss': '0.02773'}; time used = 0.958794355392456s
epoch 125: {'train_loss': '0.11634'}; time used = 0.9737679958343506s
epoch 130: {'train_loss': '0.13345'}; time used = 1.0310606956481934s
epoch 135: {'train_loss': '0.12968'}; time used = 1.0957691669464111s
epoch 140: {'train_loss': '0.15205'}; time used = 1.2521100044250488s
epoch 145: {'train_loss': '0.14036'}; time used = 1.2690813541412354s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.25940489768982.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6801346801346801, 'samples': 0.7368421052631579, 'weighted': 0.7013999645578592, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.82 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.40162'}; time used = 1.6896040439605713s
epoch 10: {'train_loss': '1.34981'}; time used = 1.1959447860717773s
epoch 15: {'train_loss': '1.39770'}; time used = 1.241575002670288s
epoch 20: {'train_loss': '1.37498'}; time used = 1.1860229969024658s
epoch 25: {'train_loss': '1.34000'}; time used = 1.1757757663726807s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.095831632614136.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6570959803117309, 'samples': 0.7105263157894737, 'weighted': 0.6784681145028281, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.38629'}; time used = 7.289703845977783s
epoch 10: {'train_loss': '1.38629'}; time used = 6.856360912322998s
epoch 15: {'train_loss': '1.38629'}; time used = 7.091848134994507s
epoch 20: {'train_loss': '1.38629'}; time used = 6.507007122039795s
epoch 25: {'train_loss': '1.38629'}; time used = 6.447728872299194s
epoch 30: {'train_loss': '1.38629'}; time used = 6.50095534324646s
epoch 35: {'train_loss': '1.38629'}; time used = 6.5628392696380615s
epoch 40: {'train_loss': '1.38629'}; time used = 6.421620607376099s
epoch 45: {'train_loss': '1.38629'}; time used = 6.865143299102783s
epoch 50: {'train_loss': '1.38629'}; time used = 6.6098315715789795s
epoch 55: {'train_loss': '1.38629'}; time used = 7.23023796081543s
epoch 60: {'train_loss': '1.38629'}; time used = 6.746282339096069s
epoch 65: {'train_loss': '1.38629'}; time used = 6.87822151184082s
epoch 70: {'train_loss': '1.38629'}; time used = 6.417988538742065s
epoch 75: {'train_loss': '1.38629'}; time used = 6.708642244338989s
epoch 80: {'train_loss': '1.38629'}; time used = 6.337639331817627s
epoch 85: {'train_loss': '1.38629'}; time used = 6.657460451126099s
epoch 90: {'train_loss': '1.38629'}; time used = 6.724477767944336s
epoch 95: {'train_loss': '1.38629'}; time used = 6.702366352081299s
epoch 100: {'train_loss': '1.38629'}; time used = 6.634936094284058s
epoch 105: {'train_loss': '1.38629'}; time used = 6.249544143676758s
epoch 110: {'train_loss': '1.38629'}; time used = 6.26316499710083s
epoch 115: {'train_loss': '1.38629'}; time used = 6.9074156284332275s
epoch 120: {'train_loss': '1.38629'}; time used = 6.8409013748168945s
epoch 125: {'train_loss': '1.38629'}; time used = 6.789660930633545s
epoch 130: {'train_loss': '1.38629'}; time used = 6.894833087921143s
epoch 135: {'train_loss': '1.38629'}; time used = 6.611361980438232s
epoch 140: {'train_loss': '1.38629'}; time used = 6.481090307235718s
epoch 145: {'train_loss': '1.38629'}; time used = 6.992719411849976s
epoch 150: {'train_loss': '1.38629'}; time used = 6.527047157287598s
epoch 155: {'train_loss': '1.38629'}; time used = 6.798708915710449s
epoch 160: {'train_loss': '1.38629'}; time used = 6.894171714782715s
epoch 165: {'train_loss': '1.38629'}; time used = 6.46081280708313s
epoch 170: {'train_loss': '1.38629'}; time used = 6.4340980052948s
epoch 175: {'train_loss': '1.38629'}; time used = 6.614321231842041s
epoch 180: {'train_loss': '1.38629'}; time used = 7.008589506149292s
epoch 185: {'train_loss': '1.38629'}; time used = 6.83246111869812s
epoch 190: {'train_loss': '1.38629'}; time used = 6.9437415599823s
epoch 195: {'train_loss': '1.38629'}; time used = 6.383742809295654s
epoch 200: {'train_loss': '1.38629'}; time used = 6.61172342300415s
epoch 205: {'train_loss': '1.38629'}; time used = 6.623961925506592s
epoch 210: {'train_loss': '1.38629'}; time used = 6.414602994918823s
epoch 215: {'train_loss': '1.38629'}; time used = 6.262291193008423s
epoch 220: {'train_loss': '1.38629'}; time used = 6.773884296417236s
epoch 225: {'train_loss': '1.38629'}; time used = 6.402199029922485s
epoch 230: {'train_loss': '1.38629'}; time used = 6.514319181442261s
epoch 235: {'train_loss': '1.38629'}; time used = 6.440405368804932s
epoch 240: {'train_loss': '1.38629'}; time used = 6.808403968811035s
epoch 245: {'train_loss': '1.38629'}; time used = 6.5941925048828125s
epoch 250: {'train_loss': '1.38629'}; time used = 6.433548450469971s
epoch 255: {'train_loss': '1.38629'}; time used = 6.631322145462036s
epoch 260: {'train_loss': '1.38629'}; time used = 7.060636520385742s
epoch 265: {'train_loss': '1.38629'}; time used = 6.271583080291748s
epoch 270: {'train_loss': '1.38629'}; time used = 6.5104615688323975s
epoch 275: {'train_loss': '1.38629'}; time used = 6.976627588272095s
epoch 280: {'train_loss': '1.38629'}; time used = 6.806331157684326s
epoch 285: {'train_loss': '1.38629'}; time used = 6.7316975593566895s
epoch 290: {'train_loss': '1.38629'}; time used = 6.501380681991577s
epoch 295: {'train_loss': '1.38629'}; time used = 6.4553000926971436s
epoch 300: {'train_loss': '1.38629'}; time used = 6.71426248550415s
epoch 305: {'train_loss': '1.38629'}; time used = 6.613099575042725s
epoch 310: {'train_loss': '1.38629'}; time used = 6.6075029373168945s
epoch 315: {'train_loss': '1.38629'}; time used = 6.842132329940796s
epoch 320: {'train_loss': '1.38629'}; time used = 6.746374607086182s
epoch 325: {'train_loss': '1.38629'}; time used = 6.248259782791138s
epoch 330: {'train_loss': '1.38629'}; time used = 6.209433078765869s
epoch 335: {'train_loss': '1.38629'}; time used = 6.362368106842041s
epoch 340: {'train_loss': '1.38629'}; time used = 6.18748927116394s
epoch 345: {'train_loss': '1.38629'}; time used = 6.266311883926392s
epoch 350: {'train_loss': '1.38629'}; time used = 6.194766521453857s
epoch 355: {'train_loss': '1.38629'}; time used = 6.329992055892944s
epoch 360: {'train_loss': '1.38629'}; time used = 6.302035570144653s
epoch 365: {'train_loss': '1.38629'}; time used = 6.353780746459961s
epoch 370: {'train_loss': '1.38629'}; time used = 6.373685598373413s
epoch 375: {'train_loss': '1.38629'}; time used = 6.159370422363281s
epoch 380: {'train_loss': '1.38629'}; time used = 6.1654369831085205s
epoch 385: {'train_loss': '1.38629'}; time used = 6.240927219390869s
epoch 390: {'train_loss': '1.38629'}; time used = 6.283238887786865s
epoch 395: {'train_loss': '1.38629'}; time used = 6.270479679107666s
epoch 400: {'train_loss': '1.38629'}; time used = 9.372532844543457s
epoch 405: {'train_loss': '1.38629'}; time used = 7.549838542938232s
epoch 410: {'train_loss': '1.38629'}; time used = 6.3753886222839355s
epoch 415: {'train_loss': '1.38629'}; time used = 6.386759519577026s
epoch 420: {'train_loss': '1.38629'}; time used = 6.4770166873931885s
epoch 425: {'train_loss': '1.38629'}; time used = 6.334875106811523s
epoch 430: {'train_loss': '1.38629'}; time used = 6.197384834289551s
epoch 435: {'train_loss': '1.38629'}; time used = 6.457472562789917s
epoch 440: {'train_loss': '1.38629'}; time used = 7.503408193588257s
epoch 445: {'train_loss': '1.38629'}; time used = 7.791496992111206s
epoch 450: {'train_loss': '1.38629'}; time used = 6.33496618270874s
epoch 455: {'train_loss': '1.38629'}; time used = 6.244890928268433s
epoch 460: {'train_loss': '1.38629'}; time used = 6.660925388336182s
epoch 465: {'train_loss': '1.38629'}; time used = 6.249784231185913s
epoch 470: {'train_loss': '1.38629'}; time used = 6.236376762390137s
epoch 475: {'train_loss': '1.38629'}; time used = 6.228983640670776s
epoch 480: {'train_loss': '1.38629'}; time used = 6.430542707443237s
epoch 485: {'train_loss': '1.38629'}; time used = 6.3905675411224365s
epoch 490: {'train_loss': '1.38629'}; time used = 6.709418296813965s
epoch 495: {'train_loss': '1.38629'}; time used = 9.73745584487915s
epoch 500: {'train_loss': '1.38629'}; time used = 6.797325134277344s
Finished training. Time used = 672.9632947444916.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.4534952727421347, 'samples': 0.5033333333333333, 'weighted': 0.44496733763679375, 'accuracy': 0.5033333333333333}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.82 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77606'}; time used = 2.0119450092315674s
epoch 10: {'train_loss': '2.77184'}; time used = 1.9777805805206299s
epoch 15: {'train_loss': '2.77090'}; time used = 1.9885804653167725s
epoch 20: {'train_loss': '2.76993'}; time used = 2.0447909832000732s
epoch 25: {'train_loss': '2.76572'}; time used = 2.0190322399139404s
epoch 30: {'train_loss': '2.74990'}; time used = 1.9221150875091553s
epoch 35: {'train_loss': '2.71996'}; time used = 1.9158389568328857s
epoch 40: {'train_loss': '2.67329'}; time used = 1.975053310394287s
epoch 45: {'train_loss': '2.67576'}; time used = 1.991687536239624s
epoch 50: {'train_loss': '2.63151'}; time used = 1.9875271320343018s
epoch 55: {'train_loss': '2.61763'}; time used = 2.212113380432129s
epoch 60: {'train_loss': '2.59690'}; time used = 2.0246036052703857s
epoch 65: {'train_loss': '2.58700'}; time used = 1.9492952823638916s
epoch 70: {'train_loss': '2.56220'}; time used = 1.937901258468628s
epoch 75: {'train_loss': '2.51804'}; time used = 1.9317195415496826s
epoch 80: {'train_loss': '2.49388'}; time used = 1.9856786727905273s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.99811005592346.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.4828042328042328, 'samples': 0.5072463768115942, 'weighted': 0.4909516141400199, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37180'}; time used = 1.8922576904296875s
epoch 10: {'train_loss': '1.27734'}; time used = 1.7752885818481445s
epoch 15: {'train_loss': '1.20037'}; time used = 1.7549245357513428s
epoch 20: {'train_loss': '1.14062'}; time used = 1.7805798053741455s
epoch 25: {'train_loss': '0.85176'}; time used = 1.8407530784606934s
epoch 30: {'train_loss': '0.81649'}; time used = 1.7796714305877686s
epoch 35: {'train_loss': '0.88333'}; time used = 1.8287146091461182s
epoch 40: {'train_loss': '0.71303'}; time used = 2.1126487255096436s
epoch 45: {'train_loss': '0.54915'}; time used = 2.182514190673828s
epoch 50: {'train_loss': '0.66397'}; time used = 2.219719648361206s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.58731746673584.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.6299077451190731, 'samples': 0.6376811594202898, 'weighted': 0.6337944522696815, 'accuracy': 0.6376811594202898}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.93565'}; time used = 2.491727828979492s
epoch 10: {'train_loss': '2.77480'}; time used = 2.4647443294525146s
epoch 15: {'train_loss': '2.77185'}; time used = 2.9715065956115723s
epoch 20: {'train_loss': '2.77558'}; time used = 2.689988613128662s
epoch 25: {'train_loss': '2.77935'}; time used = 2.6068689823150635s
epoch 30: {'train_loss': '2.77608'}; time used = 3.4777145385742188s
epoch 35: {'train_loss': '2.76833'}; time used = 4.207928657531738s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.74186682701111.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4661508704061895, 'samples': 0.5362318840579711, 'weighted': 0.48016707313654583, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.03656'}; time used = 1.3347461223602295s
epoch 10: {'train_loss': '0.69703'}; time used = 0.9476053714752197s
epoch 15: {'train_loss': '0.50154'}; time used = 1.06524658203125s
epoch 20: {'train_loss': '0.35973'}; time used = 1.1262576580047607s
epoch 25: {'train_loss': '0.30834'}; time used = 1.1287333965301514s
epoch 30: {'train_loss': '0.22283'}; time used = 0.9388763904571533s
epoch 35: {'train_loss': '0.21572'}; time used = 0.9685783386230469s
epoch 40: {'train_loss': '0.14129'}; time used = 1.1755542755126953s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.922714471817017.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.93528'}; time used = 1.325085163116455s
epoch 10: {'train_loss': '2.88355'}; time used = 1.2540531158447266s
epoch 15: {'train_loss': '2.84000'}; time used = 1.2027077674865723s
epoch 20: {'train_loss': '2.80943'}; time used = 1.1852080821990967s
epoch 25: {'train_loss': '2.79588'}; time used = 1.3205184936523438s
epoch 30: {'train_loss': '2.79957'}; time used = 1.2900991439819336s
epoch 35: {'train_loss': '2.78982'}; time used = 1.4218215942382812s
epoch 40: {'train_loss': '2.79187'}; time used = 1.2608981132507324s
epoch 45: {'train_loss': '2.79128'}; time used = 1.2334747314453125s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.50261378288269.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.04 GiB already allocated; 867.44 MiB free; 28.12 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.31 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39567'}; time used = 1.1904656887054443s
epoch 10: {'train_loss': '1.36603'}; time used = 1.0536646842956543s
epoch 15: {'train_loss': '1.26483'}; time used = 1.0512886047363281s
epoch 20: {'train_loss': '1.24531'}; time used = 1.1352176666259766s
epoch 25: {'train_loss': '0.99484'}; time used = 1.066082239151001s
epoch 30: {'train_loss': '1.11854'}; time used = 1.0392796993255615s
epoch 35: {'train_loss': '0.91387'}; time used = 1.0029547214508057s
epoch 40: {'train_loss': '0.78642'}; time used = 1.0373547077178955s
epoch 45: {'train_loss': '0.62437'}; time used = 1.0177090167999268s
epoch 50: {'train_loss': '0.72731'}; time used = 1.0355925559997559s
epoch 55: {'train_loss': '0.63819'}; time used = 0.9997355937957764s
epoch 60: {'train_loss': '0.68778'}; time used = 1.0393524169921875s
epoch 65: {'train_loss': '0.46307'}; time used = 1.0250847339630127s
epoch 70: {'train_loss': '0.89673'}; time used = 1.1138558387756348s
epoch 75: {'train_loss': '0.83916'}; time used = 1.0544521808624268s
epoch 80: {'train_loss': '0.47372'}; time used = 1.0447964668273926s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.1405770778656.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6125490196078432, 'samples': 0.6578947368421053, 'weighted': 0.6334778121775028, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.79344'}; time used = 1.7858829498291016s
epoch 10: {'train_loss': '2.77192'}; time used = 1.778435230255127s
epoch 15: {'train_loss': '2.75738'}; time used = 1.9101343154907227s
epoch 20: {'train_loss': '2.73956'}; time used = 1.9962425231933594s
epoch 25: {'train_loss': '2.72268'}; time used = 1.875175952911377s
epoch 30: {'train_loss': '2.70896'}; time used = 1.9430615901947021s
epoch 35: {'train_loss': '2.70097'}; time used = 1.8219375610351562s
epoch 40: {'train_loss': '2.68867'}; time used = 1.7397332191467285s
epoch 45: {'train_loss': '2.68223'}; time used = 1.7893486022949219s
epoch 50: {'train_loss': '2.67659'}; time used = 1.912369966506958s
epoch 55: {'train_loss': '2.67281'}; time used = 1.7417027950286865s
epoch 60: {'train_loss': '2.65592'}; time used = 1.735511302947998s
epoch 65: {'train_loss': '2.64879'}; time used = 1.9312338829040527s
epoch 70: {'train_loss': '2.65638'}; time used = 2.000950574874878s
epoch 75: {'train_loss': '2.63970'}; time used = 2.000441312789917s
epoch 80: {'train_loss': '2.64315'}; time used = 1.928354024887085s
epoch 85: {'train_loss': '2.64660'}; time used = 1.928943395614624s
epoch 90: {'train_loss': '2.62973'}; time used = 1.762786865234375s
epoch 95: {'train_loss': '2.63511'}; time used = 1.856515884399414s
epoch 100: {'train_loss': '2.63192'}; time used = 1.9976942539215088s
epoch 105: {'train_loss': '2.62001'}; time used = 1.9179236888885498s
epoch 110: {'train_loss': '2.62148'}; time used = 1.725158929824829s
epoch 115: {'train_loss': '2.60156'}; time used = 1.7933745384216309s
epoch 120: {'train_loss': '2.61418'}; time used = 1.765458345413208s
epoch 125: {'train_loss': '2.61150'}; time used = 1.7842493057250977s
epoch 130: {'train_loss': '2.61426'}; time used = 1.7733867168426514s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 53.038257360458374.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5411602843384544, 'samples': 0.5797101449275363, 'weighted': 0.550797749485725, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.54 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.11416'}; time used = 2.9037795066833496s
epoch 10: {'train_loss': '1.04279'}; time used = 2.018432140350342s
epoch 15: {'train_loss': '0.99459'}; time used = 1.8417882919311523s
epoch 20: {'train_loss': '0.58334'}; time used = 1.6902732849121094s
epoch 25: {'train_loss': '0.36624'}; time used = 1.7552778720855713s
epoch 30: {'train_loss': '0.13040'}; time used = 1.566298484802246s
epoch 35: {'train_loss': '0.07581'}; time used = 1.7163958549499512s
epoch 40: {'train_loss': '0.04901'}; time used = 1.7225279808044434s
epoch 45: {'train_loss': '0.05246'}; time used = 2.311577081680298s
epoch 50: {'train_loss': '0.12552'}; time used = 2.784660577774048s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.95545268058777.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.47826086956521735, 'samples': 0.5362318840579711, 'weighted': 0.4908632640201637, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.60407'}; time used = 1.1871061325073242s
epoch 10: {'train_loss': '0.40146'}; time used = 1.0679004192352295s
epoch 15: {'train_loss': '0.29727'}; time used = 0.9617838859558105s
epoch 20: {'train_loss': '0.18230'}; time used = 0.9448602199554443s
epoch 25: {'train_loss': '0.18794'}; time used = 1.0114853382110596s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.312060832977295.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.15779'}; time used = 1.4427683353424072s
epoch 10: {'train_loss': '0.82439'}; time used = 1.4167721271514893s
epoch 15: {'train_loss': '0.65379'}; time used = 1.412052869796753s
epoch 20: {'train_loss': '0.44859'}; time used = 1.367422103881836s
epoch 25: {'train_loss': '0.38085'}; time used = 1.280792236328125s
epoch 30: {'train_loss': '0.26155'}; time used = 1.2957751750946045s
epoch 35: {'train_loss': '0.22609'}; time used = 1.2968311309814453s
epoch 40: {'train_loss': '0.18319'}; time used = 1.2965025901794434s
epoch 45: {'train_loss': '0.18435'}; time used = 1.2988698482513428s
epoch 50: {'train_loss': '0.18211'}; time used = 1.3740582466125488s
epoch 55: {'train_loss': '0.12049'}; time used = 1.2949590682983398s
epoch 60: {'train_loss': '0.15203'}; time used = 1.4914562702178955s
epoch 65: {'train_loss': '0.24556'}; time used = 1.470477819442749s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.48597240447998.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7172619047619048, 'samples': 0.7368421052631579, 'weighted': 0.7290100250626566, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.71615'}; time used = 1.7766592502593994s
epoch 10: {'train_loss': '2.63748'}; time used = 1.5997223854064941s
epoch 15: {'train_loss': '2.62594'}; time used = 1.7547485828399658s
epoch 20: {'train_loss': '2.59395'}; time used = 1.7821874618530273s
epoch 25: {'train_loss': '2.56984'}; time used = 1.8834455013275146s
epoch 30: {'train_loss': '2.54095'}; time used = 2.0108940601348877s
epoch 35: {'train_loss': '2.51397'}; time used = 2.1881494522094727s
epoch 40: {'train_loss': '2.48229'}; time used = 2.1581127643585205s
epoch 45: {'train_loss': '2.43822'}; time used = 4.010898113250732s
epoch 50: {'train_loss': '2.46225'}; time used = 2.758023500442505s
epoch 55: {'train_loss': '2.38971'}; time used = 1.7493982315063477s
epoch 60: {'train_loss': '2.35322'}; time used = 1.6376941204071045s
epoch 65: {'train_loss': '2.31582'}; time used = 1.7324247360229492s
epoch 70: {'train_loss': '2.64635'}; time used = 1.649474859237671s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.8160080909729.
Training classifier using 80.00% nodes...
{'micro': 0.5217391304347826, 'macro': 0.42745788282625097, 'samples': 0.5217391304347826, 'weighted': 0.4442938198992031, 'accuracy': 0.5217391304347826}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39472'}; time used = 1.2172155380249023s
epoch 10: {'train_loss': '1.39949'}; time used = 1.0835778713226318s
epoch 15: {'train_loss': '1.28379'}; time used = 1.1655972003936768s
epoch 20: {'train_loss': '1.02435'}; time used = 1.131615161895752s
epoch 25: {'train_loss': '0.81245'}; time used = 4.248383283615112s
epoch 30: {'train_loss': '0.69615'}; time used = 5.659360408782959s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.09978699684143.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.69 GiB already allocated; 1.19 GiB free; 34.65 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.19733'}; time used = 1.1684157848358154s
epoch 10: {'train_loss': '0.95631'}; time used = 1.1322975158691406s
epoch 15: {'train_loss': '0.64542'}; time used = 1.1203749179840088s
epoch 20: {'train_loss': '0.43131'}; time used = 1.1790592670440674s
epoch 25: {'train_loss': '0.34611'}; time used = 1.0577235221862793s
epoch 30: {'train_loss': '0.23448'}; time used = 0.952387809753418s
epoch 35: {'train_loss': '0.20022'}; time used = 0.9539294242858887s
epoch 40: {'train_loss': '0.15515'}; time used = 0.9553229808807373s
epoch 45: {'train_loss': '0.13009'}; time used = 0.9406259059906006s
epoch 50: {'train_loss': '0.18770'}; time used = 0.9478399753570557s
epoch 55: {'train_loss': '0.10384'}; time used = 1.068464994430542s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.936100721359253.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.26471'}; time used = 1.4529314041137695s
epoch 10: {'train_loss': '2.80964'}; time used = 0.9948511123657227s
epoch 15: {'train_loss': '2.80960'}; time used = 1.029714822769165s
epoch 20: {'train_loss': '2.81810'}; time used = 2.2215070724487305s
epoch 25: {'train_loss': '2.81257'}; time used = 1.382850170135498s
epoch 30: {'train_loss': '2.79832'}; time used = 1.4362621307373047s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.188433170318604.
Training classifier using 80.00% nodes...
{'micro': 0.6052631578947368, 'macro': 0.47368421052631576, 'samples': 0.6052631578947368, 'weighted': 0.5152354570637119, 'accuracy': 0.6052631578947368}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.94043'}; time used = 1.8338475227355957s
epoch 10: {'train_loss': '2.79125'}; time used = 1.9031736850738525s
epoch 15: {'train_loss': '2.79407'}; time used = 1.9634058475494385s
epoch 20: {'train_loss': '2.78495'}; time used = 2.1344707012176514s
epoch 25: {'train_loss': '2.77842'}; time used = 2.1110246181488037s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.598698854446411.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76952'}; time used = 1.0316267013549805s
epoch 10: {'train_loss': '2.57206'}; time used = 0.9800629615783691s
epoch 15: {'train_loss': '2.41008'}; time used = 2.044173002243042s
epoch 20: {'train_loss': '2.31840'}; time used = 2.1609103679656982s
epoch 25: {'train_loss': '2.18239'}; time used = 1.0958476066589355s
epoch 30: {'train_loss': '1.94437'}; time used = 0.920832633972168s
epoch 35: {'train_loss': '1.96090'}; time used = 0.9484536647796631s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.916696071624756.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7172619047619048, 'samples': 0.7368421052631579, 'weighted': 0.7290100250626566, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.36297'}; time used = 6.495114326477051s
epoch 10: {'train_loss': '1.37813'}; time used = 5.417561769485474s
epoch 15: {'train_loss': '1.34820'}; time used = 5.279456615447998s
epoch 20: {'train_loss': '1.35543'}; time used = 5.166688680648804s
epoch 25: {'train_loss': '1.33473'}; time used = 4.966259956359863s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 50.92144751548767.
Training classifier using 80.00% nodes...
{'micro': 0.7299999999999999, 'macro': 0.7295673076923077, 'samples': 0.73, 'weighted': 0.7293509615384616, 'accuracy': 0.73}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39611'}; time used = 1.4198722839355469s
epoch 10: {'train_loss': '1.40511'}; time used = 1.292792797088623s
epoch 15: {'train_loss': '1.37842'}; time used = 1.2004597187042236s
epoch 20: {'train_loss': '1.38433'}; time used = 1.4107520580291748s
epoch 25: {'train_loss': '1.32854'}; time used = 1.2474989891052246s
epoch 30: {'train_loss': '1.30995'}; time used = 1.3242852687835693s
epoch 35: {'train_loss': '1.25121'}; time used = 2.3719193935394287s
epoch 40: {'train_loss': '1.28437'}; time used = 2.627694606781006s
epoch 45: {'train_loss': '0.95053'}; time used = 2.5452065467834473s
epoch 50: {'train_loss': '1.02972'}; time used = 2.586254119873047s
epoch 55: {'train_loss': '0.94212'}; time used = 1.6899135112762451s
epoch 60: {'train_loss': '0.90206'}; time used = 1.2707085609436035s
epoch 65: {'train_loss': '0.76507'}; time used = 1.2885549068450928s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.605109691619873.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6955128205128205, 'samples': 0.7368421052631579, 'weighted': 0.713225371120108, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.45576'}; time used = 7.184466600418091s
epoch 10: {'train_loss': '2.84594'}; time used = 6.597498416900635s
epoch 15: {'train_loss': '2.83535'}; time used = 7.908617734909058s
epoch 20: {'train_loss': '2.84114'}; time used = 6.760194301605225s
epoch 25: {'train_loss': '2.82544'}; time used = 6.73649787902832s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.3908531665802.
Training classifier using 80.00% nodes...
{'micro': 0.4766666666666667, 'macro': 0.44754915871401374, 'samples': 0.4766666666666667, 'weighted': 0.441275001833388, 'accuracy': 0.4766666666666667}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.25962'}; time used = 1.27120041847229s
epoch 10: {'train_loss': '2.84992'}; time used = 1.1148762702941895s
epoch 15: {'train_loss': '2.71637'}; time used = 1.0168323516845703s
epoch 20: {'train_loss': '2.64156'}; time used = 1.1142902374267578s
epoch 25: {'train_loss': '2.52580'}; time used = 0.9575138092041016s
epoch 30: {'train_loss': '2.43514'}; time used = 0.9658951759338379s
epoch 35: {'train_loss': '2.37888'}; time used = 1.0271110534667969s
epoch 40: {'train_loss': '2.36922'}; time used = 0.9442312717437744s
epoch 45: {'train_loss': '2.34255'}; time used = 0.9144761562347412s
epoch 50: {'train_loss': '2.32549'}; time used = 1.023763656616211s
epoch 55: {'train_loss': '2.32195'}; time used = 0.9578182697296143s
epoch 60: {'train_loss': '2.29183'}; time used = 1.0215098857879639s
epoch 65: {'train_loss': '2.26723'}; time used = 1.0434460639953613s
epoch 70: {'train_loss': '2.28343'}; time used = 0.9790139198303223s
epoch 75: {'train_loss': '2.25606'}; time used = 1.0355820655822754s
epoch 80: {'train_loss': '2.22820'}; time used = 0.9897465705871582s
epoch 85: {'train_loss': '2.29465'}; time used = 1.0033314228057861s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.149399042129517.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.731764705882353, 'samples': 0.7631578947368421, 'weighted': 0.7462538699690403, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.78528'}; time used = 1.3051064014434814s
epoch 10: {'train_loss': '2.78267'}; time used = 1.0566604137420654s
epoch 15: {'train_loss': '2.77995'}; time used = 1.0477240085601807s
epoch 20: {'train_loss': '2.77204'}; time used = 1.5730576515197754s
epoch 25: {'train_loss': '2.76994'}; time used = 2.365478992462158s
epoch 30: {'train_loss': '2.76888'}; time used = 2.4088215827941895s
epoch 35: {'train_loss': '2.76572'}; time used = 2.406510353088379s
epoch 40: {'train_loss': '2.76285'}; time used = 2.23690128326416s
epoch 45: {'train_loss': '2.75893'}; time used = 1.1139185428619385s
epoch 50: {'train_loss': '2.75523'}; time used = 1.1678106784820557s
epoch 55: {'train_loss': '2.75235'}; time used = 1.2179925441741943s
epoch 60: {'train_loss': '2.75622'}; time used = 1.1736109256744385s
epoch 65: {'train_loss': '2.75107'}; time used = 1.2206525802612305s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.489768981933594.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.65 GiB already allocated; 1.25 GiB free; 25.50 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.16912'}; time used = 2.035741090774536s
epoch 10: {'train_loss': '2.89063'}; time used = 1.9480841159820557s
epoch 15: {'train_loss': '2.80269'}; time used = 2.198432445526123s
epoch 20: {'train_loss': '2.77412'}; time used = 2.2556161880493164s
epoch 25: {'train_loss': '2.78510'}; time used = 2.0614216327667236s
epoch 30: {'train_loss': '2.77404'}; time used = 1.9091897010803223s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.023373126983643.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5062611806797853, 'samples': 0.5362318840579711, 'weighted': 0.5150760934380751, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.45 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77436'}; time used = 2.1738195419311523s
epoch 10: {'train_loss': '2.77105'}; time used = 2.0510096549987793s
epoch 15: {'train_loss': '2.77088'}; time used = 2.0260348320007324s
epoch 20: {'train_loss': '2.76932'}; time used = 2.046987533569336s
epoch 25: {'train_loss': '2.76390'}; time used = 2.13702130317688s
epoch 30: {'train_loss': '2.74626'}; time used = 1.9777097702026367s
epoch 35: {'train_loss': '2.71388'}; time used = 1.9704220294952393s
epoch 40: {'train_loss': '2.65962'}; time used = 2.128706693649292s
epoch 45: {'train_loss': '2.68056'}; time used = 2.130993604660034s
epoch 50: {'train_loss': '2.69232'}; time used = 2.0312392711639404s
epoch 55: {'train_loss': '2.64661'}; time used = 2.1470868587493896s
epoch 60: {'train_loss': '2.60161'}; time used = 2.052475929260254s
epoch 65: {'train_loss': '2.59083'}; time used = 2.1040141582489014s
epoch 70: {'train_loss': '2.57994'}; time used = 1.9374749660491943s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.821653366088867.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5071428571428571, 'samples': 0.5942028985507246, 'weighted': 0.5221532091097308, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '3.04733'}; time used = 6.9738428592681885s
epoch 10: {'train_loss': '2.77759'}; time used = 7.707152605056763s
epoch 15: {'train_loss': '2.81078'}; time used = 7.425541400909424s
epoch 20: {'train_loss': '2.79149'}; time used = 7.751520872116089s
epoch 25: {'train_loss': '2.77398'}; time used = 7.102800607681274s
epoch 30: {'train_loss': '2.77806'}; time used = 7.0004847049713135s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 60.93757748603821.
Training classifier using 80.00% nodes...
{'micro': 0.5033333333333333, 'macro': 0.43783014101327455, 'samples': 0.5033333333333333, 'weighted': 0.4282545588167746, 'accuracy': 0.5033333333333333}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.37404'}; time used = 2.0106794834136963s
epoch 10: {'train_loss': '1.33814'}; time used = 2.389085054397583s
epoch 15: {'train_loss': '1.36502'}; time used = 2.2013132572174072s
epoch 20: {'train_loss': '1.45631'}; time used = 2.493746042251587s
epoch 25: {'train_loss': '1.41163'}; time used = 2.546180009841919s
epoch 30: {'train_loss': '1.31707'}; time used = 2.463752508163452s
epoch 35: {'train_loss': '1.29292'}; time used = 2.240309715270996s
epoch 40: {'train_loss': '1.15064'}; time used = 1.8694226741790771s
epoch 45: {'train_loss': '1.11182'}; time used = 1.9850244522094727s
epoch 50: {'train_loss': '0.91278'}; time used = 2.3353474140167236s
epoch 55: {'train_loss': '0.86216'}; time used = 2.0967581272125244s
epoch 60: {'train_loss': '0.82599'}; time used = 1.9047682285308838s
epoch 65: {'train_loss': '0.85422'}; time used = 1.9045052528381348s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.324755907058716.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5864594894561599, 'samples': 0.6086956521739131, 'weighted': 0.5934082903054577, 'accuracy': 0.6086956521739131}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.45 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36926'}; time used = 4.149658441543579s
epoch 10: {'train_loss': '1.34528'}; time used = 3.136486768722534s
epoch 15: {'train_loss': '1.37787'}; time used = 2.318199872970581s
epoch 20: {'train_loss': '1.44802'}; time used = 2.2694761753082275s
epoch 25: {'train_loss': '1.42927'}; time used = 2.2153608798980713s
epoch 30: {'train_loss': '1.39554'}; time used = 2.256079912185669s
epoch 35: {'train_loss': '1.37334'}; time used = 2.1527256965637207s
epoch 40: {'train_loss': '1.35644'}; time used = 2.224439859390259s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.59308648109436.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4968569273321599, 'samples': 0.5797101449275363, 'weighted': 0.5116521447599057, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.16427'}; time used = 1.7699949741363525s
epoch 10: {'train_loss': '1.09456'}; time used = 1.6365365982055664s
epoch 15: {'train_loss': '0.89598'}; time used = 1.703129768371582s
epoch 20: {'train_loss': '0.68501'}; time used = 1.612553358078003s
epoch 25: {'train_loss': '0.46956'}; time used = 2.201152801513672s
epoch 30: {'train_loss': '0.26857'}; time used = 1.9145636558532715s
epoch 35: {'train_loss': '0.21162'}; time used = 1.9868285655975342s
epoch 40: {'train_loss': '0.19386'}; time used = 1.8728117942810059s
epoch 45: {'train_loss': '0.08907'}; time used = 2.7183494567871094s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.50874924659729.
Training classifier using 80.00% nodes...
{'micro': 0.4927536231884058, 'macro': 0.46392896781354054, 'samples': 0.4927536231884058, 'weighted': 0.4729366726181859, 'accuracy': 0.4927536231884058}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.88 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37491'}; time used = 1.3145911693572998s
epoch 10: {'train_loss': '1.30782'}; time used = 1.1280393600463867s
epoch 15: {'train_loss': '1.20380'}; time used = 1.3320379257202148s
epoch 20: {'train_loss': '1.21835'}; time used = 1.1192986965179443s
epoch 25: {'train_loss': '1.07081'}; time used = 1.1608498096466064s
epoch 30: {'train_loss': '1.03305'}; time used = 1.2517242431640625s
epoch 35: {'train_loss': '1.08285'}; time used = 1.2700114250183105s
epoch 40: {'train_loss': '0.98018'}; time used = 1.2670822143554688s
epoch 45: {'train_loss': '0.73971'}; time used = 1.5434105396270752s
epoch 50: {'train_loss': '0.84334'}; time used = 1.3823938369750977s
epoch 55: {'train_loss': '0.95514'}; time used = 1.216930866241455s
epoch 60: {'train_loss': '0.85200'}; time used = 1.099602460861206s
epoch 65: {'train_loss': '0.65031'}; time used = 1.1433796882629395s
epoch 70: {'train_loss': '0.70308'}; time used = 1.2987709045410156s
epoch 75: {'train_loss': '0.88747'}; time used = 1.1155710220336914s
epoch 80: {'train_loss': '0.60528'}; time used = 1.0951311588287354s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.764440059661865.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.75752'}; time used = 1.2043430805206299s
epoch 10: {'train_loss': '2.56929'}; time used = 1.1145470142364502s
epoch 15: {'train_loss': '2.41551'}; time used = 0.948805570602417s
epoch 20: {'train_loss': '2.33082'}; time used = 0.9442687034606934s
epoch 25: {'train_loss': '2.21407'}; time used = 0.9353179931640625s
epoch 30: {'train_loss': '2.01489'}; time used = 0.9157295227050781s
epoch 35: {'train_loss': '1.78391'}; time used = 0.9418919086456299s
epoch 40: {'train_loss': '1.96970'}; time used = 0.9335496425628662s
epoch 45: {'train_loss': '1.74596'}; time used = 0.9181466102600098s
epoch 50: {'train_loss': '1.78368'}; time used = 0.9415433406829834s
epoch 55: {'train_loss': '1.67518'}; time used = 0.9859302043914795s
epoch 60: {'train_loss': '1.62689'}; time used = 1.1823394298553467s
epoch 65: {'train_loss': '1.57324'}; time used = 0.9795527458190918s
epoch 70: {'train_loss': '1.53790'}; time used = 0.9898056983947754s
epoch 75: {'train_loss': '1.45414'}; time used = 0.9572403430938721s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.20722222328186.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.95482'}; time used = 4.91415810585022s
epoch 10: {'train_loss': '2.85247'}; time used = 3.874817132949829s
epoch 15: {'train_loss': '2.82747'}; time used = 4.4659953117370605s
epoch 20: {'train_loss': '2.80076'}; time used = 3.813539743423462s
epoch 25: {'train_loss': '2.78415'}; time used = 2.004004716873169s
epoch 30: {'train_loss': '2.77703'}; time used = 1.0587987899780273s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.24524140357971.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.31 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.06592'}; time used = 1.8751955032348633s
epoch 10: {'train_loss': '0.59144'}; time used = 1.585716962814331s
epoch 15: {'train_loss': '0.49598'}; time used = 1.6058275699615479s
epoch 20: {'train_loss': '0.46348'}; time used = 1.8422887325286865s
epoch 25: {'train_loss': '0.51989'}; time used = 1.7238502502441406s
epoch 30: {'train_loss': '0.52461'}; time used = 1.5982284545898438s
epoch 35: {'train_loss': '0.46421'}; time used = 1.7228002548217773s
epoch 40: {'train_loss': '0.51688'}; time used = 1.6433446407318115s
epoch 45: {'train_loss': '0.43264'}; time used = 1.6052241325378418s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.586718797683716.
Training classifier using 80.00% nodes...
{'micro': 0.6521739130434783, 'macro': 0.6431034482758622, 'samples': 0.6521739130434783, 'weighted': 0.6472263868065968, 'accuracy': 0.6521739130434783}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.34073'}; time used = 5.313988447189331s
epoch 10: {'train_loss': '1.33175'}; time used = 8.89225959777832s
epoch 15: {'train_loss': '1.29788'}; time used = 5.979416847229004s
epoch 20: {'train_loss': '1.25568'}; time used = 5.067265033721924s
epoch 25: {'train_loss': '1.23917'}; time used = 5.301831483840942s
epoch 30: {'train_loss': '1.14263'}; time used = 4.951786279678345s
epoch 35: {'train_loss': '0.99573'}; time used = 4.796640396118164s
epoch 40: {'train_loss': '1.04744'}; time used = 5.464787244796753s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 64.67618942260742.
Training classifier using 80.00% nodes...
{'micro': 0.715, 'macro': 0.714935860568628, 'samples': 0.715, 'weighted': 0.7150213798104573, 'accuracy': 0.715}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '3.25145'}; time used = 1.2951679229736328s
epoch 10: {'train_loss': '2.84066'}; time used = 1.224740743637085s
epoch 15: {'train_loss': '2.71351'}; time used = 1.0842235088348389s
epoch 20: {'train_loss': '2.63489'}; time used = 1.0156404972076416s
epoch 25: {'train_loss': '2.51993'}; time used = 1.4692795276641846s
epoch 30: {'train_loss': '2.43396'}; time used = 2.146935224533081s
epoch 35: {'train_loss': '2.37934'}; time used = 1.2616322040557861s
epoch 40: {'train_loss': '2.36758'}; time used = 1.148247241973877s
epoch 45: {'train_loss': '2.32925'}; time used = 1.074042558670044s
epoch 50: {'train_loss': '2.30832'}; time used = 1.0916728973388672s
epoch 55: {'train_loss': '2.30555'}; time used = 1.2839276790618896s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.07256579399109.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5438596491228069, 'samples': 0.6578947368421053, 'weighted': 0.579870729455217, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76076'}; time used = 1.5001304149627686s
epoch 10: {'train_loss': '2.75252'}; time used = 1.2747540473937988s
epoch 15: {'train_loss': '2.72866'}; time used = 1.2294447422027588s
epoch 20: {'train_loss': '2.65938'}; time used = 1.2886126041412354s
epoch 25: {'train_loss': '2.51346'}; time used = 1.276343584060669s
epoch 30: {'train_loss': '2.33053'}; time used = 1.4628987312316895s
epoch 35: {'train_loss': '2.23452'}; time used = 1.3837347030639648s
epoch 40: {'train_loss': '2.23968'}; time used = 1.3259716033935547s
epoch 45: {'train_loss': '2.17371'}; time used = 1.2762064933776855s
epoch 50: {'train_loss': '2.11558'}; time used = 1.4561903476715088s
epoch 55: {'train_loss': '1.97081'}; time used = 1.2459495067596436s
epoch 60: {'train_loss': '2.04928'}; time used = 1.4024248123168945s
epoch 65: {'train_loss': '2.04532'}; time used = 1.3443882465362549s
epoch 70: {'train_loss': '1.97604'}; time used = 1.4321179389953613s
epoch 75: {'train_loss': '1.85252'}; time used = 1.4108047485351562s
epoch 80: {'train_loss': '1.88105'}; time used = 1.2662544250488281s
epoch 85: {'train_loss': '1.83880'}; time used = 1.8079993724822998s
epoch 90: {'train_loss': '1.80983'}; time used = 1.981407880783081s
epoch 95: {'train_loss': '1.83553'}; time used = 2.005209445953369s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.29279685020447.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5737179487179487, 'samples': 0.631578947368421, 'weighted': 0.5985155195681512, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.87799'}; time used = 2.6123404502868652s
epoch 10: {'train_loss': '2.78631'}; time used = 1.9666438102722168s
epoch 15: {'train_loss': '2.77445'}; time used = 1.8910648822784424s
epoch 20: {'train_loss': '2.76923'}; time used = 1.9730150699615479s
epoch 25: {'train_loss': '2.76917'}; time used = 2.7967827320098877s
epoch 30: {'train_loss': '2.76731'}; time used = 1.7943053245544434s
epoch 35: {'train_loss': '2.76589'}; time used = 1.8318135738372803s
epoch 40: {'train_loss': '2.76338'}; time used = 1.7981877326965332s
epoch 45: {'train_loss': '2.76500'}; time used = 1.8794915676116943s
epoch 50: {'train_loss': '2.75931'}; time used = 1.8458735942840576s
epoch 55: {'train_loss': '2.76135'}; time used = 2.0494437217712402s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.15239953994751.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5208333333333333, 'samples': 0.5942028985507246, 'weighted': 0.5344202898550725, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.34561'}; time used = 1.0600337982177734s
epoch 10: {'train_loss': '1.33175'}; time used = 0.981257438659668s
epoch 15: {'train_loss': '1.16629'}; time used = 0.9786763191223145s
epoch 20: {'train_loss': '1.02726'}; time used = 0.9751396179199219s
epoch 25: {'train_loss': '0.81883'}; time used = 0.9944982528686523s
epoch 30: {'train_loss': '0.83625'}; time used = 0.9943737983703613s
epoch 35: {'train_loss': '0.73176'}; time used = 1.2452037334442139s
epoch 40: {'train_loss': '0.65280'}; time used = 1.151719331741333s
epoch 45: {'train_loss': '0.45527'}; time used = 0.9590458869934082s
epoch 50: {'train_loss': '0.67085'}; time used = 1.0956320762634277s
epoch 55: {'train_loss': '0.31496'}; time used = 0.9522325992584229s
epoch 60: {'train_loss': '0.41956'}; time used = 0.9143447875976562s
epoch 65: {'train_loss': '1.15563'}; time used = 0.9893863201141357s
epoch 70: {'train_loss': '0.62061'}; time used = 0.9845354557037354s
epoch 75: {'train_loss': '0.68915'}; time used = 0.9361388683319092s
epoch 80: {'train_loss': '0.50059'}; time used = 1.0551769733428955s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.180253267288208.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37465'}; time used = 2.7439239025115967s
epoch 10: {'train_loss': '1.34538'}; time used = 2.8058083057403564s
epoch 15: {'train_loss': '1.36919'}; time used = 2.66463041305542s
epoch 20: {'train_loss': '1.38557'}; time used = 2.6767449378967285s
epoch 25: {'train_loss': '1.24574'}; time used = 2.804624080657959s
epoch 30: {'train_loss': '1.04726'}; time used = 2.666267156600952s
epoch 35: {'train_loss': '0.93427'}; time used = 2.7652697563171387s
epoch 40: {'train_loss': '0.88178'}; time used = 2.7388668060302734s
epoch 45: {'train_loss': '0.67201'}; time used = 2.67063307762146s
epoch 50: {'train_loss': '0.75978'}; time used = 2.8692173957824707s
epoch 55: {'train_loss': '0.67540'}; time used = 2.758089780807495s
epoch 60: {'train_loss': '0.47825'}; time used = 2.753784656524658s
epoch 65: {'train_loss': '0.43630'}; time used = 2.7433550357818604s
epoch 70: {'train_loss': '0.67534'}; time used = 3.976804256439209s
epoch 75: {'train_loss': '0.55167'}; time used = 4.428441762924194s
epoch 80: {'train_loss': '0.57175'}; time used = 4.182227373123169s
epoch 85: {'train_loss': '0.72795'}; time used = 2.878012180328369s
epoch 90: {'train_loss': '0.60275'}; time used = 2.63122820854187s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 58.70436763763428.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5371198568872988, 'samples': 0.5652173913043478, 'weighted': 0.5453838375981955, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.62 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76952'}; time used = 1.0200519561767578s
epoch 10: {'train_loss': '2.57206'}; time used = 0.918656587600708s
epoch 15: {'train_loss': '2.41008'}; time used = 0.9123320579528809s
epoch 20: {'train_loss': '2.31840'}; time used = 0.9558296203613281s
epoch 25: {'train_loss': '2.18239'}; time used = 0.953223466873169s
epoch 30: {'train_loss': '1.94437'}; time used = 1.5490567684173584s
epoch 35: {'train_loss': '1.96090'}; time used = 1.478658676147461s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.878835439682007.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7172619047619048, 'samples': 0.7368421052631579, 'weighted': 0.7290100250626566, 'accuracy': 0.7368421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.01758'}; time used = 1.1361041069030762s
epoch 10: {'train_loss': '0.54809'}; time used = 1.0708630084991455s
epoch 15: {'train_loss': '0.36861'}; time used = 1.0983524322509766s
epoch 20: {'train_loss': '0.23929'}; time used = 1.7015554904937744s
epoch 25: {'train_loss': '0.16066'}; time used = 1.622096061706543s
epoch 30: {'train_loss': '0.10263'}; time used = 1.7780070304870605s
epoch 35: {'train_loss': '0.06827'}; time used = 1.7857325077056885s
epoch 40: {'train_loss': '0.05345'}; time used = 1.6664364337921143s
epoch 45: {'train_loss': '0.05501'}; time used = 1.0439982414245605s
epoch 50: {'train_loss': '0.04403'}; time used = 0.9317567348480225s
epoch 55: {'train_loss': '0.03117'}; time used = 1.012017011642456s
epoch 60: {'train_loss': '0.02338'}; time used = 1.0159509181976318s
epoch 65: {'train_loss': '0.03157'}; time used = 0.9635541439056396s
epoch 70: {'train_loss': '0.02279'}; time used = 1.0457096099853516s
epoch 75: {'train_loss': '0.02282'}; time used = 0.9371187686920166s
epoch 80: {'train_loss': '0.01844'}; time used = 0.9749495983123779s
epoch 85: {'train_loss': '0.02288'}; time used = 1.1969609260559082s
epoch 90: {'train_loss': '0.02672'}; time used = 1.1836564540863037s
epoch 95: {'train_loss': '0.03073'}; time used = 1.073087453842163s
epoch 100: {'train_loss': '0.03475'}; time used = 1.0974695682525635s
epoch 105: {'train_loss': '0.01359'}; time used = 0.9976873397827148s
epoch 110: {'train_loss': '0.01412'}; time used = 1.1083121299743652s
epoch 115: {'train_loss': '0.01942'}; time used = 1.070889949798584s
epoch 120: {'train_loss': '0.02311'}; time used = 0.9607059955596924s
epoch 125: {'train_loss': '0.02337'}; time used = 0.9136700630187988s
epoch 130: {'train_loss': '0.01344'}; time used = 0.8412253856658936s
epoch 135: {'train_loss': '0.01812'}; time used = 1.537705421447754s
epoch 140: {'train_loss': '0.02845'}; time used = 1.0528945922851562s
epoch 145: {'train_loss': '0.01162'}; time used = 0.886887788772583s
epoch 150: {'train_loss': '0.01255'}; time used = 0.9292378425598145s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.63218855857849.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.856386999244142, 'samples': 0.868421052631579, 'weighted': 0.8629510283645622, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.28 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.95254'}; time used = 1.959045648574829s
epoch 10: {'train_loss': '2.71475'}; time used = 1.727407693862915s
epoch 15: {'train_loss': '2.58814'}; time used = 1.9271035194396973s
epoch 20: {'train_loss': '2.38566'}; time used = 1.8238937854766846s
epoch 25: {'train_loss': '2.05329'}; time used = 1.7874581813812256s
epoch 30: {'train_loss': '1.77521'}; time used = 1.2338619232177734s
epoch 35: {'train_loss': '1.57568'}; time used = 0.9050757884979248s
epoch 40: {'train_loss': '1.56184'}; time used = 0.95102858543396s
epoch 45: {'train_loss': '1.59826'}; time used = 1.0027878284454346s
epoch 50: {'train_loss': '1.43566'}; time used = 0.9800159931182861s
epoch 55: {'train_loss': '1.44947'}; time used = 0.9626798629760742s
epoch 60: {'train_loss': '1.42285'}; time used = 0.9733424186706543s
epoch 65: {'train_loss': '1.40766'}; time used = 1.0922043323516846s
epoch 70: {'train_loss': '1.38871'}; time used = 0.830571174621582s
epoch 75: {'train_loss': '1.28445'}; time used = 0.8319830894470215s
epoch 80: {'train_loss': '1.32348'}; time used = 0.8780252933502197s
epoch 85: {'train_loss': '1.32279'}; time used = 0.8919963836669922s
epoch 90: {'train_loss': '1.28137'}; time used = 0.8866102695465088s
epoch 95: {'train_loss': '1.27588'}; time used = 0.8750429153442383s
epoch 100: {'train_loss': '1.28565'}; time used = 0.8907666206359863s
epoch 105: {'train_loss': '1.31505'}; time used = 0.9183187484741211s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.59560489654541.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.33531'}; time used = 1.1807425022125244s
epoch 10: {'train_loss': '1.54096'}; time used = 1.0151593685150146s
epoch 15: {'train_loss': '1.23222'}; time used = 1.1240224838256836s
epoch 20: {'train_loss': '0.70040'}; time used = 1.0995347499847412s
epoch 25: {'train_loss': '0.11377'}; time used = 1.0458731651306152s
epoch 30: {'train_loss': '0.13817'}; time used = 1.0090603828430176s
epoch 35: {'train_loss': '0.05087'}; time used = 1.0796189308166504s
epoch 40: {'train_loss': '0.13809'}; time used = 1.0138475894927979s
epoch 45: {'train_loss': '0.77325'}; time used = 0.9838829040527344s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.85762095451355.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.93 GiB already allocated; 987.44 MiB free; 26.48 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 44.07 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.85466'}; time used = 1.2589964866638184s
epoch 10: {'train_loss': '0.76193'}; time used = 1.1345970630645752s
epoch 15: {'train_loss': '0.36955'}; time used = 1.1299026012420654s
epoch 20: {'train_loss': '0.22553'}; time used = 1.000756025314331s
epoch 25: {'train_loss': '0.19039'}; time used = 0.9823658466339111s
epoch 30: {'train_loss': '0.15155'}; time used = 0.9647462368011475s
epoch 35: {'train_loss': '0.09072'}; time used = 0.9735689163208008s
epoch 40: {'train_loss': '0.06527'}; time used = 0.9674503803253174s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.577528715133667.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.22257'}; time used = 1.1775996685028076s
epoch 10: {'train_loss': '0.11871'}; time used = 1.0258147716522217s
epoch 15: {'train_loss': '0.06507'}; time used = 1.0976693630218506s
epoch 20: {'train_loss': '0.06154'}; time used = 1.0309860706329346s
epoch 25: {'train_loss': '0.06153'}; time used = 1.1179299354553223s
epoch 30: {'train_loss': '0.07574'}; time used = 1.0025858879089355s
epoch 35: {'train_loss': '0.06866'}; time used = 0.9852960109710693s
epoch 40: {'train_loss': '0.05081'}; time used = 0.9974479675292969s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.273222208023071.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86170'}; time used = 2.250464677810669s
epoch 10: {'train_loss': '2.78649'}; time used = 1.8375067710876465s
epoch 15: {'train_loss': '2.74489'}; time used = 1.7864148616790771s
epoch 20: {'train_loss': '2.73336'}; time used = 1.8675751686096191s
epoch 25: {'train_loss': '2.71100'}; time used = 2.133300304412842s
epoch 30: {'train_loss': '2.67821'}; time used = 2.032553195953369s
epoch 35: {'train_loss': '2.64628'}; time used = 1.7399413585662842s
epoch 40: {'train_loss': '2.60561'}; time used = 1.8531482219696045s
epoch 45: {'train_loss': '2.56312'}; time used = 1.8588299751281738s
epoch 50: {'train_loss': '2.49713'}; time used = 3.360427141189575s
epoch 55: {'train_loss': '2.48419'}; time used = 2.5758657455444336s
epoch 60: {'train_loss': '2.44128'}; time used = 1.5728626251220703s
epoch 65: {'train_loss': '2.35952'}; time used = 2.499626398086548s
epoch 70: {'train_loss': '2.33918'}; time used = 2.3130364418029785s
epoch 75: {'train_loss': '2.30990'}; time used = 1.6607208251953125s
epoch 80: {'train_loss': '2.23624'}; time used = 1.6502244472503662s
epoch 85: {'train_loss': '2.29301'}; time used = 1.640824556350708s
epoch 90: {'train_loss': '2.28056'}; time used = 1.773688554763794s
epoch 95: {'train_loss': '2.21054'}; time used = 1.5481953620910645s
epoch 100: {'train_loss': '2.18560'}; time used = 1.7641115188598633s
epoch 105: {'train_loss': '2.15720'}; time used = 1.5770142078399658s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 44.689701557159424.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5191637630662022, 'samples': 0.5362318840579711, 'weighted': 0.5257284249861133, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.66858'}; time used = 1.8954522609710693s
epoch 10: {'train_loss': '2.56593'}; time used = 1.7560245990753174s
epoch 15: {'train_loss': '2.52626'}; time used = 1.799722671508789s
epoch 20: {'train_loss': '2.47307'}; time used = 1.797727346420288s
epoch 25: {'train_loss': '2.42154'}; time used = 0.9438204765319824s
epoch 30: {'train_loss': '2.34511'}; time used = 0.9436478614807129s
epoch 35: {'train_loss': '2.31748'}; time used = 1.2706489562988281s
epoch 40: {'train_loss': '2.28954'}; time used = 1.2049455642700195s
epoch 45: {'train_loss': '2.26589'}; time used = 1.0938811302185059s
epoch 50: {'train_loss': '2.23006'}; time used = 0.9512169361114502s
epoch 55: {'train_loss': '2.17900'}; time used = 1.1191980838775635s
epoch 60: {'train_loss': '2.14203'}; time used = 1.5471045970916748s
epoch 65: {'train_loss': '2.13349'}; time used = 0.8954408168792725s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.059308767318726.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.26 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.21824'}; time used = 1.876716136932373s
epoch 10: {'train_loss': '0.83156'}; time used = 2.320173740386963s
epoch 15: {'train_loss': '0.18268'}; time used = 3.127997636795044s
epoch 20: {'train_loss': '0.11607'}; time used = 3.2078051567077637s
epoch 25: {'train_loss': '0.00037'}; time used = 2.170970916748047s
epoch 30: {'train_loss': '0.00042'}; time used = 1.884812593460083s
epoch 35: {'train_loss': '0.00000'}; time used = 1.7426447868347168s
epoch 40: {'train_loss': '0.00004'}; time used = 1.8016581535339355s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.439611434936523.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.6373764977927264, 'samples': 0.6376811594202898, 'weighted': 0.6381381518616348, 'accuracy': 0.6376811594202898}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.34707'}; time used = 10.997368574142456s
epoch 10: {'train_loss': '1.33816'}; time used = 7.89348030090332s
epoch 15: {'train_loss': '1.30503'}; time used = 8.898547172546387s
epoch 20: {'train_loss': '1.23685'}; time used = 8.231461524963379s
epoch 25: {'train_loss': '1.14630'}; time used = 7.443807363510132s
epoch 30: {'train_loss': '1.20832'}; time used = 8.049072027206421s
epoch 35: {'train_loss': '1.07752'}; time used = 9.396084547042847s
epoch 40: {'train_loss': '1.14309'}; time used = 8.899926662445068s
epoch 45: {'train_loss': '1.09774'}; time used = 7.324185609817505s
epoch 50: {'train_loss': '1.07384'}; time used = 8.197883367538452s
epoch 55: {'train_loss': '1.20435'}; time used = 7.550382614135742s
epoch 60: {'train_loss': '1.16027'}; time used = 7.791118383407593s
epoch 65: {'train_loss': '1.30775'}; time used = 8.94312596321106s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 137.1303322315216.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.4560712300646163, 'samples': 0.5066666666666667, 'weighted': 0.4475053722324452, 'accuracy': 0.5066666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.93261'}; time used = 1.897493839263916s
epoch 10: {'train_loss': '0.63087'}; time used = 2.114245891571045s
epoch 15: {'train_loss': '0.49064'}; time used = 1.066044807434082s
epoch 20: {'train_loss': '0.38356'}; time used = 0.9948663711547852s
epoch 25: {'train_loss': '0.37600'}; time used = 1.1313109397888184s
epoch 30: {'train_loss': '0.27868'}; time used = 1.2104604244232178s
epoch 35: {'train_loss': '0.28207'}; time used = 1.4699506759643555s
epoch 40: {'train_loss': '0.21365'}; time used = 1.469599723815918s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.703339338302612.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.12647'}; time used = 1.0933623313903809s
epoch 10: {'train_loss': '1.41218'}; time used = 0.9667236804962158s
epoch 15: {'train_loss': '0.67662'}; time used = 0.9679598808288574s
epoch 20: {'train_loss': '0.57554'}; time used = 0.9888291358947754s
epoch 25: {'train_loss': '0.03002'}; time used = 0.9487111568450928s
epoch 30: {'train_loss': '1.40775'}; time used = 1.0746114253997803s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.00902795791626.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.19 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.61304'}; time used = 1.2252180576324463s
epoch 10: {'train_loss': '2.32147'}; time used = 1.1660771369934082s
epoch 15: {'train_loss': '2.03068'}; time used = 1.1835854053497314s
epoch 20: {'train_loss': '1.86913'}; time used = 1.1854627132415771s
epoch 25: {'train_loss': '1.75363'}; time used = 0.9920086860656738s
epoch 30: {'train_loss': '1.62754'}; time used = 1.1968517303466797s
epoch 35: {'train_loss': '1.52439'}; time used = 1.1088106632232666s
epoch 40: {'train_loss': '1.62605'}; time used = 1.0352070331573486s
epoch 45: {'train_loss': '1.68388'}; time used = 1.0463693141937256s
epoch 50: {'train_loss': '1.58861'}; time used = 1.0228874683380127s
epoch 55: {'train_loss': '1.53955'}; time used = 1.1493520736694336s
epoch 60: {'train_loss': '1.47287'}; time used = 1.3005225658416748s
epoch 65: {'train_loss': '1.42168'}; time used = 1.1468617916107178s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.387420415878296.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.24983'}; time used = 1.8384370803833008s
epoch 10: {'train_loss': '1.16800'}; time used = 1.7017183303833008s
epoch 15: {'train_loss': '1.03345'}; time used = 1.777125358581543s
epoch 20: {'train_loss': '0.88791'}; time used = 1.654463768005371s
epoch 25: {'train_loss': '0.64981'}; time used = 1.7204809188842773s
epoch 30: {'train_loss': '0.50414'}; time used = 1.8772492408752441s
epoch 35: {'train_loss': '0.26703'}; time used = 1.8091306686401367s
epoch 40: {'train_loss': '0.14140'}; time used = 1.8850047588348389s
epoch 45: {'train_loss': '0.13064'}; time used = 2.193361520767212s
epoch 50: {'train_loss': '0.07586'}; time used = 1.806757926940918s
epoch 55: {'train_loss': '0.07420'}; time used = 2.0051422119140625s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.976733207702637.
Training classifier using 80.00% nodes...
{'micro': 0.6666666666666666, 'macro': 0.6595151255095473, 'samples': 0.6666666666666666, 'weighted': 0.663090896088107, 'accuracy': 0.6666666666666666}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76219'}; time used = 4.498197793960571s
epoch 10: {'train_loss': '2.72199'}; time used = 4.671604156494141s
epoch 15: {'train_loss': '2.69066'}; time used = 3.919907331466675s
epoch 20: {'train_loss': '2.65363'}; time used = 2.851506471633911s
epoch 25: {'train_loss': '2.57817'}; time used = 2.608478307723999s
epoch 30: {'train_loss': '2.51656'}; time used = 1.8234527111053467s
epoch 35: {'train_loss': '2.45336'}; time used = 2.104963779449463s
epoch 40: {'train_loss': '2.37328'}; time used = 1.655580759048462s
epoch 45: {'train_loss': '2.58237'}; time used = 1.9163050651550293s
epoch 50: {'train_loss': '2.32471'}; time used = 2.0133681297302246s
epoch 55: {'train_loss': '2.33079'}; time used = 1.8268959522247314s
epoch 60: {'train_loss': '2.29777'}; time used = 1.7709059715270996s
epoch 65: {'train_loss': '2.19912'}; time used = 2.0888750553131104s
epoch 70: {'train_loss': '2.13059'}; time used = 1.7146613597869873s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 42.50149059295654.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.06 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.62 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.77907'}; time used = 1.2770590782165527s
epoch 10: {'train_loss': '2.77262'}; time used = 1.0729985237121582s
epoch 15: {'train_loss': '2.77893'}; time used = 0.9347705841064453s
epoch 20: {'train_loss': '2.78020'}; time used = 1.030017375946045s
epoch 25: {'train_loss': '2.77352'}; time used = 1.0083775520324707s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.526264905929565.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.39332'}; time used = 1.1985270977020264s
epoch 10: {'train_loss': '1.40529'}; time used = 1.0675535202026367s
epoch 15: {'train_loss': '1.34709'}; time used = 0.9830441474914551s
epoch 20: {'train_loss': '1.37487'}; time used = 1.006300449371338s
epoch 25: {'train_loss': '1.33916'}; time used = 1.0596914291381836s
epoch 30: {'train_loss': '1.35642'}; time used = 1.0404176712036133s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.47142505645752.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7548387096774194, 'samples': 0.7631578947368421, 'weighted': 0.7619694397283531, 'accuracy': 0.7631578947368421}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.65739'}; time used = 2.1012871265411377s
epoch 10: {'train_loss': '0.22678'}; time used = 1.8568768501281738s
epoch 15: {'train_loss': '0.08220'}; time used = 1.7957162857055664s
epoch 20: {'train_loss': '0.00603'}; time used = 1.1911520957946777s
epoch 25: {'train_loss': '0.00035'}; time used = 1.5110766887664795s
epoch 30: {'train_loss': '0.02178'}; time used = 1.3110308647155762s
epoch 35: {'train_loss': '0.05334'}; time used = 1.3203327655792236s
epoch 40: {'train_loss': '0.02230'}; time used = 1.427905797958374s
epoch 45: {'train_loss': '0.00858'}; time used = 1.1710212230682373s
epoch 50: {'train_loss': '0.00554'}; time used = 1.2345595359802246s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.337541103363037.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.638095238095238, 'samples': 0.7105263157894737, 'weighted': 0.6636591478696743, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.40138'}; time used = 1.8778536319732666s
epoch 10: {'train_loss': '1.23309'}; time used = 1.7903978824615479s
epoch 15: {'train_loss': '1.04362'}; time used = 1.934530258178711s
epoch 20: {'train_loss': '0.73343'}; time used = 1.8662397861480713s
epoch 25: {'train_loss': '0.59798'}; time used = 2.3025386333465576s
epoch 30: {'train_loss': '0.56864'}; time used = 2.344266414642334s
epoch 35: {'train_loss': '0.29303'}; time used = 2.3001790046691895s
epoch 40: {'train_loss': '0.26225'}; time used = 2.350337266921997s
epoch 45: {'train_loss': '0.05281'}; time used = 1.9549896717071533s
epoch 50: {'train_loss': '0.00636'}; time used = 2.181541919708252s
epoch 55: {'train_loss': '0.00775'}; time used = 2.131218194961548s
epoch 60: {'train_loss': '0.00587'}; time used = 1.7920584678649902s
epoch 65: {'train_loss': '0.00573'}; time used = 2.7238364219665527s
epoch 70: {'train_loss': '0.00334'}; time used = 3.7756764888763428s
epoch 75: {'train_loss': '0.00234'}; time used = 3.8794052600860596s
epoch 80: {'train_loss': '0.05620'}; time used = 2.1733579635620117s
epoch 85: {'train_loss': '0.00128'}; time used = 2.3126957416534424s
epoch 90: {'train_loss': '0.03927'}; time used = 1.8549628257751465s
epoch 95: {'train_loss': '0.00453'}; time used = 1.8254694938659668s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 48.4180953502655.
Training classifier using 80.00% nodes...
{'micro': 0.6376811594202898, 'macro': 0.6299077451190731, 'samples': 0.6376811594202898, 'weighted': 0.6337944522696815, 'accuracy': 0.6376811594202898}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.33 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.15426'}; time used = 1.3472120761871338s
epoch 10: {'train_loss': '0.90164'}; time used = 1.277965784072876s
epoch 15: {'train_loss': '0.76142'}; time used = 1.2344324588775635s
epoch 20: {'train_loss': '0.63294'}; time used = 0.9812717437744141s
epoch 25: {'train_loss': '0.58059'}; time used = 1.0200915336608887s
epoch 30: {'train_loss': '0.48360'}; time used = 1.0911097526550293s
epoch 35: {'train_loss': '0.44677'}; time used = 1.1966075897216797s
epoch 40: {'train_loss': '0.39533'}; time used = 1.10050368309021s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.410658597946167.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.525, 'samples': 0.631578947368421, 'weighted': 0.5605263157894737, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 34.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.84533'}; time used = 1.5053749084472656s
epoch 10: {'train_loss': '0.25148'}; time used = 1.1027288436889648s
epoch 15: {'train_loss': '0.18011'}; time used = 1.1032214164733887s
epoch 20: {'train_loss': '0.14431'}; time used = 0.9402811527252197s
epoch 25: {'train_loss': '0.16358'}; time used = 0.9220352172851562s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.346783638000488.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.30816'}; time used = 3.726621627807617s
epoch 10: {'train_loss': '2.81393'}; time used = 3.4507532119750977s
epoch 15: {'train_loss': '2.77647'}; time used = 2.920818328857422s
epoch 20: {'train_loss': '2.79667'}; time used = 2.4311463832855225s
epoch 25: {'train_loss': '2.77061'}; time used = 2.5453298091888428s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.310121536254883.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.45238095238095244, 'samples': 0.5362318840579711, 'weighted': 0.46790890269151136, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.78007'}; time used = 1.9388532638549805s
epoch 10: {'train_loss': '2.75101'}; time used = 1.8704156875610352s
epoch 15: {'train_loss': '2.75145'}; time used = 1.7828319072723389s
epoch 20: {'train_loss': '2.74804'}; time used = 1.7749464511871338s
epoch 25: {'train_loss': '2.73481'}; time used = 1.8528149127960205s
epoch 30: {'train_loss': '2.71553'}; time used = 2.234055757522583s
epoch 35: {'train_loss': '2.69788'}; time used = 3.3039934635162354s
epoch 40: {'train_loss': '2.65294'}; time used = 1.8160955905914307s
epoch 45: {'train_loss': '2.59379'}; time used = 1.909877061843872s
epoch 50: {'train_loss': '2.52995'}; time used = 1.9261994361877441s
epoch 55: {'train_loss': '2.48364'}; time used = 2.046433925628662s
epoch 60: {'train_loss': '2.49626'}; time used = 1.855210304260254s
epoch 65: {'train_loss': '2.44842'}; time used = 2.6604738235473633s
epoch 70: {'train_loss': '2.44061'}; time used = 2.0843048095703125s
epoch 75: {'train_loss': '2.42619'}; time used = 2.0555734634399414s
epoch 80: {'train_loss': '2.40729'}; time used = 2.2137279510498047s
epoch 85: {'train_loss': '2.41716'}; time used = 1.8814697265625s
epoch 90: {'train_loss': '2.41451'}; time used = 1.7281880378723145s
epoch 95: {'train_loss': '2.40876'}; time used = 1.7599544525146484s
epoch 100: {'train_loss': '2.41164'}; time used = 1.7725255489349365s
epoch 105: {'train_loss': '2.40237'}; time used = 2.01497483253479s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 46.10173797607422.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.38268398268398274, 'samples': 0.5507246376811594, 'weighted': 0.40602296254470177, 'accuracy': 0.5507246376811594}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.26 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.55 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.88558'}; time used = 1.2143540382385254s
epoch 10: {'train_loss': '2.80446'}; time used = 1.089975357055664s
epoch 15: {'train_loss': '2.79240'}; time used = 1.0469846725463867s
epoch 20: {'train_loss': '2.78357'}; time used = 1.18292236328125s
epoch 25: {'train_loss': '2.77748'}; time used = 1.136991024017334s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.115555763244629.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.03901'}; time used = 1.8225209712982178s
epoch 10: {'train_loss': '3.01995'}; time used = 1.9332568645477295s
epoch 15: {'train_loss': '2.88130'}; time used = 1.6513104438781738s
epoch 20: {'train_loss': '2.82047'}; time used = 1.5855934619903564s
epoch 25: {'train_loss': '2.78299'}; time used = 1.640791416168213s
epoch 30: {'train_loss': '2.75858'}; time used = 1.5827059745788574s
epoch 35: {'train_loss': '2.73782'}; time used = 1.5362718105316162s
epoch 40: {'train_loss': '2.71889'}; time used = 1.526902675628662s
epoch 45: {'train_loss': '2.68921'}; time used = 1.5480690002441406s
epoch 50: {'train_loss': '2.63912'}; time used = 1.6026630401611328s
epoch 55: {'train_loss': '2.59734'}; time used = 1.9434354305267334s
epoch 60: {'train_loss': '2.54509'}; time used = 1.7556076049804688s
epoch 65: {'train_loss': '2.42566'}; time used = 1.6169462203979492s
epoch 70: {'train_loss': '2.41094'}; time used = 1.763089895248413s
epoch 75: {'train_loss': '2.44290'}; time used = 1.569826364517212s
epoch 80: {'train_loss': '2.35453'}; time used = 1.6908440589904785s
epoch 85: {'train_loss': '2.31165'}; time used = 1.561061143875122s
epoch 90: {'train_loss': '2.22314'}; time used = 1.526019811630249s
epoch 95: {'train_loss': '2.50401'}; time used = 1.5747075080871582s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.74857831001282.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4995164410058027, 'samples': 0.5652173913043478, 'weighted': 0.5126566310655117, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.05641'}; time used = 2.8734850883483887s
epoch 10: {'train_loss': '1.01880'}; time used = 1.7094306945800781s
epoch 15: {'train_loss': '0.97046'}; time used = 1.8075170516967773s
epoch 20: {'train_loss': '0.89693'}; time used = 1.9231481552124023s
epoch 25: {'train_loss': '0.83345'}; time used = 2.004183053970337s
epoch 30: {'train_loss': '0.72495'}; time used = 1.7330169677734375s
epoch 35: {'train_loss': '0.40080'}; time used = 3.057887554168701s
epoch 40: {'train_loss': '0.51798'}; time used = 3.0383846759796143s
epoch 45: {'train_loss': '0.45046'}; time used = 2.988318920135498s
epoch 50: {'train_loss': '0.31886'}; time used = 1.9612712860107422s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.291789531707764.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4145927601809955, 'samples': 0.5652173913043478, 'weighted': 0.43611056462718867, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.64 GiB already allocated; 1.25 GiB free; 26.45 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '3.07461'}; time used = 1.388878345489502s
epoch 10: {'train_loss': '2.89431'}; time used = 1.1772332191467285s
epoch 15: {'train_loss': '2.84607'}; time used = 1.0830879211425781s
epoch 20: {'train_loss': '2.80204'}; time used = 1.0537092685699463s
epoch 25: {'train_loss': '2.73066'}; time used = 1.108158826828003s
epoch 30: {'train_loss': '2.63721'}; time used = 1.0941376686096191s
epoch 35: {'train_loss': '2.48437'}; time used = 1.0802807807922363s
epoch 40: {'train_loss': '2.34637'}; time used = 1.0976197719573975s
epoch 45: {'train_loss': '2.31050'}; time used = 1.0740129947662354s
epoch 50: {'train_loss': '2.28388'}; time used = 1.0921483039855957s
epoch 55: {'train_loss': '2.20867'}; time used = 1.091306209564209s
epoch 60: {'train_loss': '2.17932'}; time used = 1.1735455989837646s
epoch 65: {'train_loss': '2.20191'}; time used = 1.283501148223877s
epoch 70: {'train_loss': '2.26633'}; time used = 1.3699407577514648s
epoch 75: {'train_loss': '2.17061'}; time used = 1.3025038242340088s
epoch 80: {'train_loss': '2.15147'}; time used = 1.2715322971343994s
epoch 85: {'train_loss': '2.17039'}; time used = 1.0804848670959473s
epoch 90: {'train_loss': '2.14618'}; time used = 1.0732440948486328s
epoch 95: {'train_loss': '2.18022'}; time used = 1.2069532871246338s
epoch 100: {'train_loss': '2.14684'}; time used = 1.0871992111206055s
epoch 105: {'train_loss': '2.13595'}; time used = 1.1500563621520996s
epoch 110: {'train_loss': '2.11877'}; time used = 1.0893337726593018s
epoch 115: {'train_loss': '2.11545'}; time used = 1.088029384613037s
epoch 120: {'train_loss': '2.09442'}; time used = 1.083733320236206s
epoch 125: {'train_loss': '2.10974'}; time used = 1.0879764556884766s
epoch 130: {'train_loss': '2.08721'}; time used = 1.0875835418701172s
epoch 135: {'train_loss': '2.09955'}; time used = 1.0683033466339111s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.59330654144287.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6125490196078432, 'samples': 0.6578947368421053, 'weighted': 0.6334778121775028, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.85589'}; time used = 1.5869243144989014s
epoch 10: {'train_loss': '2.79138'}; time used = 1.4619088172912598s
epoch 15: {'train_loss': '2.68002'}; time used = 1.4329607486724854s
epoch 20: {'train_loss': '2.50189'}; time used = 1.6363439559936523s
epoch 25: {'train_loss': '2.30736'}; time used = 1.4722859859466553s
epoch 30: {'train_loss': '2.17472'}; time used = 1.4547979831695557s
epoch 35: {'train_loss': '2.08560'}; time used = 1.9563164710998535s
epoch 40: {'train_loss': '2.06959'}; time used = 2.0259039402008057s
epoch 45: {'train_loss': '2.05204'}; time used = 2.186436176300049s
epoch 50: {'train_loss': '2.12214'}; time used = 2.3474419116973877s
epoch 55: {'train_loss': '2.00792'}; time used = 1.699065923690796s
epoch 60: {'train_loss': '2.02373'}; time used = 1.477184534072876s
epoch 65: {'train_loss': '2.01020'}; time used = 1.3628191947937012s
epoch 70: {'train_loss': '1.96432'}; time used = 1.3302083015441895s
epoch 75: {'train_loss': '1.89417'}; time used = 1.3280770778656006s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.967329263687134.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.6125490196078432, 'samples': 0.6578947368421053, 'weighted': 0.6334778121775028, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.91399'}; time used = 1.1931753158569336s
epoch 10: {'train_loss': '2.84836'}; time used = 1.0247676372528076s
epoch 15: {'train_loss': '2.82685'}; time used = 1.038947343826294s
epoch 20: {'train_loss': '2.80659'}; time used = 1.254457950592041s
epoch 25: {'train_loss': '2.80108'}; time used = 1.1872611045837402s
epoch 30: {'train_loss': '2.79537'}; time used = 1.2201879024505615s
epoch 35: {'train_loss': '2.80156'}; time used = 1.170891284942627s
epoch 40: {'train_loss': '2.79575'}; time used = 1.2474801540374756s
epoch 45: {'train_loss': '2.79629'}; time used = 1.0590128898620605s
epoch 50: {'train_loss': '2.78653'}; time used = 1.1596856117248535s
epoch 55: {'train_loss': '2.78686'}; time used = 1.1782183647155762s
epoch 60: {'train_loss': '2.78937'}; time used = 1.2110891342163086s
epoch 65: {'train_loss': '2.78336'}; time used = 1.0988826751708984s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.63118600845337.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.6041666666666666, 'samples': 0.631578947368421, 'weighted': 0.6206140350877193, 'accuracy': 0.631578947368421}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '3.42267'}; time used = 2.2255797386169434s
epoch 10: {'train_loss': '2.90726'}; time used = 2.000528335571289s
epoch 15: {'train_loss': '2.88139'}; time used = 2.1416351795196533s
epoch 20: {'train_loss': '2.84371'}; time used = 1.9948861598968506s
epoch 25: {'train_loss': '2.79713'}; time used = 2.3465471267700195s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.821746110916138.
Training classifier using 80.00% nodes...
{'micro': 0.6086956521739131, 'macro': 0.5174825174825175, 'samples': 0.6086956521739131, 'weighted': 0.53268470659775, 'accuracy': 0.6086956521739131}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39611'}; time used = 1.3990254402160645s
epoch 10: {'train_loss': '1.40511'}; time used = 1.2505865097045898s
epoch 15: {'train_loss': '1.37842'}; time used = 1.228569746017456s
epoch 20: {'train_loss': '1.38433'}; time used = 1.2014853954315186s
epoch 25: {'train_loss': '1.32854'}; time used = 1.2311630249023438s
epoch 30: {'train_loss': '1.30995'}; time used = 1.3099920749664307s
epoch 35: {'train_loss': '1.25121'}; time used = 1.2069847583770752s
epoch 40: {'train_loss': '1.28437'}; time used = 1.1706275939941406s
epoch 45: {'train_loss': '0.95053'}; time used = 1.2909610271453857s
epoch 50: {'train_loss': '1.02972'}; time used = 1.163761854171753s
epoch 55: {'train_loss': '0.94212'}; time used = 1.2815487384796143s
epoch 60: {'train_loss': '0.90206'}; time used = 1.206150770187378s
epoch 65: {'train_loss': '0.76507'}; time used = 1.223123550415039s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.450358390808105.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6955128205128205, 'samples': 0.7368421052631579, 'weighted': 0.713225371120108, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.17076'}; time used = 2.3066468238830566s
epoch 10: {'train_loss': '0.68088'}; time used = 2.1718013286590576s
epoch 15: {'train_loss': '0.45487'}; time used = 1.8577735424041748s
epoch 20: {'train_loss': '0.32267'}; time used = 2.312282085418701s
epoch 25: {'train_loss': '0.18556'}; time used = 2.6955156326293945s
epoch 30: {'train_loss': '0.13878'}; time used = 2.907348394393921s
epoch 35: {'train_loss': '0.11053'}; time used = 1.8079962730407715s
epoch 40: {'train_loss': '0.10846'}; time used = 1.8246862888336182s
epoch 45: {'train_loss': '0.08990'}; time used = 1.8072519302368164s
epoch 50: {'train_loss': '0.10762'}; time used = 1.806514024734497s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.30330491065979.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5208333333333333, 'samples': 0.5942028985507246, 'weighted': 0.5344202898550725, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.78071'}; time used = 4.970866441726685s
epoch 10: {'train_loss': '2.78421'}; time used = 4.5473833084106445s
epoch 15: {'train_loss': '2.77383'}; time used = 4.499860763549805s
epoch 20: {'train_loss': '2.76977'}; time used = 4.710669040679932s
epoch 25: {'train_loss': '2.76902'}; time used = 4.580738067626953s
epoch 30: {'train_loss': '2.76524'}; time used = 4.730587482452393s
epoch 35: {'train_loss': '2.76088'}; time used = 4.612311124801636s
epoch 40: {'train_loss': '2.75628'}; time used = 4.798985242843628s
epoch 45: {'train_loss': '2.74901'}; time used = 4.742003917694092s
epoch 50: {'train_loss': '2.74592'}; time used = 6.977642059326172s
epoch 55: {'train_loss': '2.74293'}; time used = 5.189189672470093s
epoch 60: {'train_loss': '2.77202'}; time used = 5.122541427612305s
epoch 65: {'train_loss': '2.75436'}; time used = 4.923068284988403s
epoch 70: {'train_loss': '2.75057'}; time used = 4.979637384414673s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 92.2903425693512.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.719747772995696, 'samples': 0.72, 'weighted': 0.7195796216594934, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.56 GiB already allocated; 1.33 GiB free; 24.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.20250'}; time used = 1.7297391891479492s
epoch 10: {'train_loss': '2.77935'}; time used = 1.8159263134002686s
epoch 15: {'train_loss': '2.70933'}; time used = 1.6992883682250977s
epoch 20: {'train_loss': '2.66240'}; time used = 1.6922452449798584s
epoch 25: {'train_loss': '2.62399'}; time used = 1.7423615455627441s
epoch 30: {'train_loss': '2.59575'}; time used = 1.6458823680877686s
epoch 35: {'train_loss': '2.56981'}; time used = 1.672680377960205s
epoch 40: {'train_loss': '2.54797'}; time used = 3.0170466899871826s
epoch 45: {'train_loss': '2.52872'}; time used = 1.7823362350463867s
epoch 50: {'train_loss': '2.48889'}; time used = 1.8055939674377441s
epoch 55: {'train_loss': '2.47205'}; time used = 1.868542194366455s
epoch 60: {'train_loss': '2.44889'}; time used = 1.8400635719299316s
epoch 65: {'train_loss': '2.39565'}; time used = 1.7414186000823975s
epoch 70: {'train_loss': '2.32166'}; time used = 2.4032793045043945s
epoch 75: {'train_loss': '2.30464'}; time used = 3.200382709503174s
epoch 80: {'train_loss': '2.28806'}; time used = 4.0186927318573s
epoch 85: {'train_loss': '2.28732'}; time used = 4.329785346984863s
epoch 90: {'train_loss': '2.28394'}; time used = 4.236603736877441s
epoch 95: {'train_loss': '2.25754'}; time used = 4.1529319286346436s
epoch 100: {'train_loss': '2.20921'}; time used = 3.408237934112549s
epoch 105: {'train_loss': '2.20493'}; time used = 2.699070692062378s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 56.882976770401.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5739833936555248, 'samples': 0.5797101449275363, 'weighted': 0.5775626132005319, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.44 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.88 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.12054'}; time used = 1.1381380558013916s
epoch 10: {'train_loss': '0.96836'}; time used = 1.0135881900787354s
epoch 15: {'train_loss': '0.27984'}; time used = 1.6061201095581055s
epoch 20: {'train_loss': '0.13064'}; time used = 1.720710039138794s
epoch 25: {'train_loss': '0.01692'}; time used = 0.9929337501525879s
epoch 30: {'train_loss': '0.33073'}; time used = 1.0233840942382812s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.85186243057251.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.83233'}; time used = 2.084131956100464s
epoch 10: {'train_loss': '2.75990'}; time used = 1.916398286819458s
epoch 15: {'train_loss': '2.75292'}; time used = 2.0350067615509033s
epoch 20: {'train_loss': '2.73638'}; time used = 2.31173038482666s
epoch 25: {'train_loss': '2.70407'}; time used = 2.09017276763916s
epoch 30: {'train_loss': '2.63242'}; time used = 1.947619915008545s
epoch 35: {'train_loss': '2.58058'}; time used = 1.9528796672821045s
epoch 40: {'train_loss': '2.52791'}; time used = 1.922424554824829s
epoch 45: {'train_loss': '2.50264'}; time used = 1.9175136089324951s
epoch 50: {'train_loss': '2.46652'}; time used = 2.156036138534546s
epoch 55: {'train_loss': '2.46946'}; time used = 2.4619944095611572s
epoch 60: {'train_loss': '2.45595'}; time used = 2.3982956409454346s
epoch 65: {'train_loss': '2.43397'}; time used = 2.4182450771331787s
epoch 70: {'train_loss': '2.41950'}; time used = 2.4152514934539795s
epoch 75: {'train_loss': '2.41967'}; time used = 2.45432186126709s
epoch 80: {'train_loss': '2.38142'}; time used = 2.4870197772979736s
epoch 85: {'train_loss': '2.38229'}; time used = 2.4245965480804443s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.87818169593811.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4719387755102041, 'samples': 0.5652173913043478, 'weighted': 0.4880212954747117, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.84693'}; time used = 2.2301621437072754s
epoch 10: {'train_loss': '2.76552'}; time used = 2.2453060150146484s
epoch 15: {'train_loss': '2.77653'}; time used = 2.3574564456939697s
epoch 20: {'train_loss': '2.76495'}; time used = 2.495464324951172s
epoch 25: {'train_loss': '2.73861'}; time used = 2.673333168029785s
epoch 30: {'train_loss': '2.72295'}; time used = 2.599397659301758s
epoch 35: {'train_loss': '2.71218'}; time used = 3.170753240585327s
epoch 40: {'train_loss': '2.70726'}; time used = 3.5820634365081787s
epoch 45: {'train_loss': '2.69863'}; time used = 3.7831642627716064s
epoch 50: {'train_loss': '2.69548'}; time used = 2.6630561351776123s
epoch 55: {'train_loss': '2.69904'}; time used = 2.2201037406921387s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.857601165771484.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4888888888888888, 'samples': 0.5362318840579711, 'weighted': 0.5001610305958131, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.76 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '0.25011'}; time used = 1.0682103633880615s
epoch 10: {'train_loss': '0.11527'}; time used = 0.9688663482666016s
epoch 15: {'train_loss': '0.06738'}; time used = 0.9476504325866699s
epoch 20: {'train_loss': '0.06190'}; time used = 1.0922415256500244s
epoch 25: {'train_loss': '0.06168'}; time used = 0.9610397815704346s
epoch 30: {'train_loss': '0.07575'}; time used = 0.9512112140655518s
epoch 35: {'train_loss': '0.06864'}; time used = 0.9604799747467041s
epoch 40: {'train_loss': '0.05074'}; time used = 0.9602265357971191s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.651579856872559.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.58 GiB already allocated; 1.31 GiB free; 25.01 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39629'}; time used = 1.2270612716674805s
epoch 10: {'train_loss': '1.38047'}; time used = 1.0721659660339355s
epoch 15: {'train_loss': '1.26667'}; time used = 1.098076581954956s
epoch 20: {'train_loss': '1.26339'}; time used = 1.2674102783203125s
epoch 25: {'train_loss': '1.09779'}; time used = 1.2874958515167236s
epoch 30: {'train_loss': '0.99034'}; time used = 1.1813254356384277s
epoch 35: {'train_loss': '0.96121'}; time used = 1.0754821300506592s
epoch 40: {'train_loss': '0.94946'}; time used = 1.0538959503173828s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.263035774230957.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.36 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.68638'}; time used = 1.160700798034668s
epoch 10: {'train_loss': '2.30409'}; time used = 1.0296285152435303s
epoch 15: {'train_loss': '1.71634'}; time used = 1.0207438468933105s
epoch 20: {'train_loss': '1.50358'}; time used = 1.0509343147277832s
epoch 25: {'train_loss': '1.48431'}; time used = 1.0504264831542969s
epoch 30: {'train_loss': '1.33714'}; time used = 1.1151349544525146s
epoch 35: {'train_loss': '1.27850'}; time used = 1.1000220775604248s
epoch 40: {'train_loss': '1.23985'}; time used = 1.0599050521850586s
epoch 45: {'train_loss': '1.17744'}; time used = 0.9873678684234619s
epoch 50: {'train_loss': '1.03336'}; time used = 1.0009698867797852s
epoch 55: {'train_loss': '1.16005'}; time used = 0.9908215999603271s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.7224862575531.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8637992831541219, 'samples': 0.868421052631579, 'weighted': 0.8677607998490852, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.82 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.94880'}; time used = 1.3751304149627686s
epoch 10: {'train_loss': '2.82326'}; time used = 1.112133264541626s
epoch 15: {'train_loss': '2.80027'}; time used = 1.1718368530273438s
epoch 20: {'train_loss': '2.72728'}; time used = 1.2226009368896484s
epoch 25: {'train_loss': '2.59371'}; time used = 1.1326196193695068s
epoch 30: {'train_loss': '2.40703'}; time used = 1.266728401184082s
epoch 35: {'train_loss': '2.29153'}; time used = 1.2738471031188965s
epoch 40: {'train_loss': '2.22885'}; time used = 1.123927116394043s
epoch 45: {'train_loss': '2.21067'}; time used = 1.1365323066711426s
epoch 50: {'train_loss': '2.18935'}; time used = 1.1321089267730713s
epoch 55: {'train_loss': '2.11961'}; time used = 1.1760814189910889s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.040536403656006.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6840513983371126, 'samples': 0.7105263157894737, 'weighted': 0.6984922624020369, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.77876'}; time used = 1.6957294940948486s
epoch 10: {'train_loss': '2.72905'}; time used = 1.5899524688720703s
epoch 15: {'train_loss': '2.69935'}; time used = 1.6024730205535889s
epoch 20: {'train_loss': '2.68808'}; time used = 1.602503776550293s
epoch 25: {'train_loss': '2.67855'}; time used = 1.642946720123291s
epoch 30: {'train_loss': '2.66873'}; time used = 1.5466279983520508s
epoch 35: {'train_loss': '2.66471'}; time used = 1.654806137084961s
epoch 40: {'train_loss': '2.65922'}; time used = 1.8298614025115967s
epoch 45: {'train_loss': '2.65088'}; time used = 1.7672054767608643s
epoch 50: {'train_loss': '2.63657'}; time used = 1.7592966556549072s
epoch 55: {'train_loss': '2.62911'}; time used = 1.7012488842010498s
epoch 60: {'train_loss': '2.62792'}; time used = 1.7016723155975342s
epoch 65: {'train_loss': '2.60904'}; time used = 1.5799121856689453s
epoch 70: {'train_loss': '2.59411'}; time used = 1.756051778793335s
epoch 75: {'train_loss': '2.58309'}; time used = 1.581451654434204s
epoch 80: {'train_loss': '2.57806'}; time used = 2.561662197113037s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.60048460960388.
Training classifier using 80.00% nodes...
{'micro': 0.4782608695652174, 'macro': 0.4646551724137931, 'samples': 0.4782608695652174, 'weighted': 0.470839580209895, 'accuracy': 0.4782608695652174}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79562'}; time used = 1.8321609497070312s
epoch 10: {'train_loss': '2.78020'}; time used = 1.8774998188018799s
epoch 15: {'train_loss': '2.77403'}; time used = 2.0177438259124756s
epoch 20: {'train_loss': '2.76854'}; time used = 1.9233534336090088s
epoch 25: {'train_loss': '2.76718'}; time used = 1.965679407119751s
epoch 30: {'train_loss': '2.76244'}; time used = 1.9390811920166016s
epoch 35: {'train_loss': '2.75909'}; time used = 1.8448057174682617s
epoch 40: {'train_loss': '2.75784'}; time used = 1.834779977798462s
epoch 45: {'train_loss': '2.75734'}; time used = 1.8145115375518799s
epoch 50: {'train_loss': '2.75243'}; time used = 1.8926002979278564s
epoch 55: {'train_loss': '2.75420'}; time used = 1.8702008724212646s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.449503898620605.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.34724'}; time used = 1.807617425918579s
epoch 10: {'train_loss': '1.25630'}; time used = 1.8168995380401611s
epoch 15: {'train_loss': '1.24238'}; time used = 1.814988374710083s
epoch 20: {'train_loss': '1.13380'}; time used = 1.8268065452575684s
epoch 25: {'train_loss': '0.79507'}; time used = 2.412929058074951s
epoch 30: {'train_loss': '0.90241'}; time used = 4.433888912200928s
epoch 35: {'train_loss': '1.05642'}; time used = 1.8986501693725586s
epoch 40: {'train_loss': '1.10957'}; time used = 1.7275872230529785s
epoch 45: {'train_loss': '0.94722'}; time used = 2.1091995239257812s
epoch 50: {'train_loss': '1.25645'}; time used = 1.8783915042877197s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 26.20608949661255.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5765079365079364, 'samples': 0.5797101449275363, 'weighted': 0.5791764435242696, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.05 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.09353'}; time used = 1.2974295616149902s
epoch 10: {'train_loss': '2.82458'}; time used = 1.067772626876831s
epoch 15: {'train_loss': '2.83091'}; time used = 1.0779218673706055s
epoch 20: {'train_loss': '2.81199'}; time used = 1.2246510982513428s
epoch 25: {'train_loss': '2.79632'}; time used = 1.1625826358795166s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.227591037750244.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.02167'}; time used = 1.7128231525421143s
epoch 10: {'train_loss': '0.86883'}; time used = 1.86472487449646s
epoch 15: {'train_loss': '0.00164'}; time used = 1.8349013328552246s
epoch 20: {'train_loss': '0.00113'}; time used = 1.9709832668304443s
epoch 25: {'train_loss': '0.00099'}; time used = 3.1286122798919678s
epoch 30: {'train_loss': '0.00000'}; time used = 2.933530330657959s
epoch 35: {'train_loss': '0.00000'}; time used = 2.6579530239105225s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.45271944999695.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5706929843381249, 'samples': 0.5797101449275363, 'weighted': 0.5752015646328306, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.38760'}; time used = 1.099027156829834s
epoch 10: {'train_loss': '1.39956'}; time used = 0.9731237888336182s
epoch 15: {'train_loss': '1.31676'}; time used = 1.0702621936798096s
epoch 20: {'train_loss': '1.32178'}; time used = 1.0206935405731201s
epoch 25: {'train_loss': '1.23993'}; time used = 1.0587530136108398s
epoch 30: {'train_loss': '1.23731'}; time used = 1.0141246318817139s
epoch 35: {'train_loss': '1.21615'}; time used = 1.0412280559539795s
epoch 40: {'train_loss': '1.08371'}; time used = 1.072507619857788s
epoch 45: {'train_loss': '0.75009'}; time used = 1.006531000137329s
epoch 50: {'train_loss': '1.04565'}; time used = 0.997664213180542s
epoch 55: {'train_loss': '0.84250'}; time used = 1.0519523620605469s
epoch 60: {'train_loss': '0.74611'}; time used = 0.9859542846679688s
epoch 65: {'train_loss': '0.41015'}; time used = 1.0364265441894531s
epoch 70: {'train_loss': '0.54530'}; time used = 1.0455882549285889s
epoch 75: {'train_loss': '1.08029'}; time used = 1.0100011825561523s
epoch 80: {'train_loss': '1.01271'}; time used = 0.9729573726654053s
epoch 85: {'train_loss': '0.32607'}; time used = 1.051255464553833s
epoch 90: {'train_loss': '0.99723'}; time used = 1.0632257461547852s
epoch 95: {'train_loss': '0.32560'}; time used = 1.0231685638427734s
epoch 100: {'train_loss': '0.33355'}; time used = 0.9812202453613281s
epoch 105: {'train_loss': '0.81148'}; time used = 1.009512186050415s
epoch 110: {'train_loss': '0.36552'}; time used = 1.0036036968231201s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.72657537460327.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.33823'}; time used = 1.6286933422088623s
epoch 10: {'train_loss': '1.40287'}; time used = 1.3571677207946777s
epoch 15: {'train_loss': '1.38673'}; time used = 1.9852240085601807s
epoch 20: {'train_loss': '1.38810'}; time used = 3.472311019897461s
epoch 25: {'train_loss': '1.38096'}; time used = 3.716137170791626s
epoch 30: {'train_loss': '1.36856'}; time used = 3.573228597640991s
epoch 35: {'train_loss': '1.36580'}; time used = 3.3446431159973145s
epoch 40: {'train_loss': '1.33330'}; time used = 3.2784595489501953s
epoch 45: {'train_loss': '1.28328'}; time used = 3.299896240234375s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.03308129310608.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.7076923076923077, 'samples': 0.7368421052631579, 'weighted': 0.7222672064777328, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.84 GiB already allocated; 1.07 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.97059'}; time used = 1.8603923320770264s
epoch 10: {'train_loss': '0.16099'}; time used = 3.162428379058838s
epoch 15: {'train_loss': '0.00000'}; time used = 1.7781846523284912s
epoch 20: {'train_loss': '0.15045'}; time used = 1.6329264640808105s
epoch 25: {'train_loss': '0.00014'}; time used = 2.048377275466919s
epoch 30: {'train_loss': '0.00039'}; time used = 2.276409864425659s
epoch 35: {'train_loss': '0.00039'}; time used = 1.8198418617248535s
epoch 40: {'train_loss': '1.38610'}; time used = 1.8347980976104736s
epoch 45: {'train_loss': '0.00001'}; time used = 1.8565819263458252s
epoch 50: {'train_loss': '0.00000'}; time used = 1.7435736656188965s
epoch 55: {'train_loss': '1.38628'}; time used = 1.6596412658691406s
epoch 60: {'train_loss': '0.00000'}; time used = 2.6986429691314697s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.888331174850464.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5218637992831542, 'samples': 0.5797101449275363, 'weighted': 0.5339151212924004, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.68 GiB already allocated; 1.19 GiB free; 46.30 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.57 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.26 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.36379'}; time used = 2.0435962677001953s
epoch 10: {'train_loss': '2.98142'}; time used = 1.988340139389038s
epoch 15: {'train_loss': '2.88265'}; time used = 2.04447865486145s
epoch 20: {'train_loss': '2.85455'}; time used = 1.9928326606750488s
epoch 25: {'train_loss': '2.82615'}; time used = 2.776811361312866s
epoch 30: {'train_loss': '2.81429'}; time used = 2.062027931213379s
epoch 35: {'train_loss': '2.80618'}; time used = 2.1387712955474854s
epoch 40: {'train_loss': '2.79989'}; time used = 2.1789066791534424s
epoch 45: {'train_loss': '2.80167'}; time used = 2.085468053817749s
epoch 50: {'train_loss': '2.79249'}; time used = 2.1090683937072754s
epoch 55: {'train_loss': '2.79203'}; time used = 2.0287511348724365s
epoch 60: {'train_loss': '2.78476'}; time used = 1.9593193531036377s
epoch 65: {'train_loss': '2.77144'}; time used = 2.6618568897247314s
epoch 70: {'train_loss': '2.76116'}; time used = 2.5242464542388916s
epoch 75: {'train_loss': '2.73755'}; time used = 1.9381685256958008s
epoch 80: {'train_loss': '2.70898'}; time used = 2.016451358795166s
epoch 85: {'train_loss': '2.67832'}; time used = 2.034181594848633s
epoch 90: {'train_loss': '2.65871'}; time used = 1.989790439605713s
epoch 95: {'train_loss': '2.63411'}; time used = 2.0049593448638916s
epoch 100: {'train_loss': '2.58161'}; time used = 2.1236398220062256s
epoch 105: {'train_loss': '2.60065'}; time used = 2.190906047821045s
epoch 110: {'train_loss': '2.61380'}; time used = 2.063587188720703s
epoch 115: {'train_loss': '2.57346'}; time used = 2.058774471282959s
epoch 120: {'train_loss': '2.58234'}; time used = 3.2444076538085938s
epoch 125: {'train_loss': '2.56983'}; time used = 3.695460081100464s
epoch 130: {'train_loss': '2.56873'}; time used = 3.56103515625s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 65.72760820388794.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.491578947368421, 'samples': 0.5942028985507246, 'weighted': 0.5081311975591152, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.76 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.55 GiB already allocated; 1.33 GiB free; 33.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.78190'}; time used = 4.315031051635742s
epoch 10: {'train_loss': '2.78399'}; time used = 4.230442523956299s
epoch 15: {'train_loss': '2.77526'}; time used = 4.94191312789917s
epoch 20: {'train_loss': '2.77260'}; time used = 6.900549411773682s
epoch 25: {'train_loss': '2.77383'}; time used = 4.980443239212036s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.85118222236633.
Training classifier using 80.00% nodes...
{'micro': 0.695, 'macro': 0.6943811217715874, 'samples': 0.695, 'weighted': 0.6941060647811819, 'accuracy': 0.695}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.06 GiB already allocated; 849.44 MiB free; 26.53 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.95457'}; time used = 1.5580320358276367s
epoch 10: {'train_loss': '2.84329'}; time used = 1.5190553665161133s
epoch 15: {'train_loss': '2.81912'}; time used = 1.3927123546600342s
epoch 20: {'train_loss': '2.79155'}; time used = 1.394235372543335s
epoch 25: {'train_loss': '2.79733'}; time used = 1.3628294467926025s
epoch 30: {'train_loss': '2.78843'}; time used = 1.3434624671936035s
epoch 35: {'train_loss': '2.78765'}; time used = 1.3593401908874512s
epoch 40: {'train_loss': '2.78727'}; time used = 1.3355259895324707s
epoch 45: {'train_loss': '2.79055'}; time used = 1.3424921035766602s
epoch 50: {'train_loss': '2.78653'}; time used = 1.3719382286071777s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.690860271453857.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.4176245210727969, 'samples': 0.5789473684210527, 'weighted': 0.4660213752772736, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.25 GiB free; 35.62 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 33.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.65584'}; time used = 1.148723840713501s
epoch 10: {'train_loss': '2.56983'}; time used = 1.0513360500335693s
epoch 15: {'train_loss': '2.31591'}; time used = 1.1955766677856445s
epoch 20: {'train_loss': '2.08621'}; time used = 1.1314945220947266s
epoch 25: {'train_loss': '2.04179'}; time used = 1.164172649383545s
epoch 30: {'train_loss': '1.99757'}; time used = 0.9801194667816162s
epoch 35: {'train_loss': '1.89535'}; time used = 0.9826483726501465s
epoch 40: {'train_loss': '1.89025'}; time used = 1.10837984085083s
epoch 45: {'train_loss': '1.86755'}; time used = 1.2126576900482178s
epoch 50: {'train_loss': '1.84082'}; time used = 0.9998929500579834s
epoch 55: {'train_loss': '1.82583'}; time used = 0.98946213722229s
epoch 60: {'train_loss': '1.81014'}; time used = 1.063981294631958s
epoch 65: {'train_loss': '1.77152'}; time used = 1.0035903453826904s
epoch 70: {'train_loss': '1.78873'}; time used = 0.9982724189758301s
epoch 75: {'train_loss': '1.73814'}; time used = 1.1261084079742432s
epoch 80: {'train_loss': '1.74102'}; time used = 1.015470027923584s
epoch 85: {'train_loss': '1.77275'}; time used = 0.9784836769104004s
epoch 90: {'train_loss': '1.74817'}; time used = 0.9587006568908691s
epoch 95: {'train_loss': '1.73086'}; time used = 1.0266668796539307s
epoch 100: {'train_loss': '1.74624'}; time used = 1.1546077728271484s
epoch 105: {'train_loss': '1.71962'}; time used = 1.351172685623169s
epoch 110: {'train_loss': '1.71728'}; time used = 1.0115480422973633s
epoch 115: {'train_loss': '1.70428'}; time used = 0.9817426204681396s
epoch 120: {'train_loss': '1.68236'}; time used = 1.1029410362243652s
epoch 125: {'train_loss': '1.69988'}; time used = 1.0514700412750244s
epoch 130: {'train_loss': '1.67923'}; time used = 1.0015037059783936s
epoch 135: {'train_loss': '1.74558'}; time used = 0.9531505107879639s
epoch 140: {'train_loss': '1.79614'}; time used = 0.9581232070922852s
epoch 145: {'train_loss': '1.75874'}; time used = 0.9704923629760742s
epoch 150: {'train_loss': '1.71929'}; time used = 0.9484407901763916s
epoch 155: {'train_loss': '1.69258'}; time used = 0.9520168304443359s
epoch 160: {'train_loss': '1.68511'}; time used = 0.9472982883453369s
epoch 165: {'train_loss': '1.72556'}; time used = 1.1013832092285156s
epoch 170: {'train_loss': '1.67165'}; time used = 1.2239973545074463s
epoch 175: {'train_loss': '1.65502'}; time used = 0.995366096496582s
epoch 180: {'train_loss': '1.67367'}; time used = 0.917680025100708s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.829118490219116.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.856386999244142, 'samples': 0.868421052631579, 'weighted': 0.8629510283645622, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.16 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.84257'}; time used = 2.555358648300171s
epoch 10: {'train_loss': '2.76918'}; time used = 2.5972540378570557s
epoch 15: {'train_loss': '2.78108'}; time used = 2.9663310050964355s
epoch 20: {'train_loss': '2.77534'}; time used = 2.6270599365234375s
epoch 25: {'train_loss': '2.75773'}; time used = 2.9396495819091797s
epoch 30: {'train_loss': '2.74691'}; time used = 2.5280191898345947s
epoch 35: {'train_loss': '2.73023'}; time used = 3.796217203140259s
epoch 40: {'train_loss': '2.71945'}; time used = 4.047858715057373s
epoch 45: {'train_loss': '2.71564'}; time used = 3.9888081550598145s
epoch 50: {'train_loss': '2.70235'}; time used = 2.8098435401916504s
epoch 55: {'train_loss': '2.70240'}; time used = 2.8087520599365234s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 38.30460453033447.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5792682926829268, 'samples': 0.5942028985507246, 'weighted': 0.5850123718628489, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39958'}; time used = 1.286423921585083s
epoch 10: {'train_loss': '1.39691'}; time used = 1.077867031097412s
epoch 15: {'train_loss': '1.38470'}; time used = 1.1479098796844482s
epoch 20: {'train_loss': '1.39008'}; time used = 1.1263277530670166s
epoch 25: {'train_loss': '1.38910'}; time used = 1.0610437393188477s
epoch 30: {'train_loss': '1.38569'}; time used = 1.144646406173706s
epoch 35: {'train_loss': '1.39402'}; time used = 1.0798430442810059s
epoch 40: {'train_loss': '1.37468'}; time used = 1.0883066654205322s
epoch 45: {'train_loss': '1.34329'}; time used = 1.0791707038879395s
epoch 50: {'train_loss': '1.40986'}; time used = 1.0709831714630127s
epoch 55: {'train_loss': '1.38003'}; time used = 1.0812370777130127s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.708292722702026.
Training classifier using 80.00% nodes...
{'micro': 0.5789473684210527, 'macro': 0.3666666666666667, 'samples': 0.5789473684210527, 'weighted': 0.4245614035087719, 'accuracy': 0.5789473684210527}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.63 GiB already allocated; 1.26 GiB free; 26.55 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.02308'}; time used = 1.2475569248199463s
epoch 10: {'train_loss': '0.61294'}; time used = 1.0107345581054688s
epoch 15: {'train_loss': '0.30175'}; time used = 1.206742763519287s
epoch 20: {'train_loss': '0.14656'}; time used = 1.0216877460479736s
epoch 25: {'train_loss': '0.08023'}; time used = 1.0279605388641357s
epoch 30: {'train_loss': '0.04313'}; time used = 1.0934090614318848s
epoch 35: {'train_loss': '0.03389'}; time used = 1.1212794780731201s
epoch 40: {'train_loss': '0.02394'}; time used = 1.1001701354980469s
epoch 45: {'train_loss': '0.02215'}; time used = 1.0292308330535889s
epoch 50: {'train_loss': '0.01268'}; time used = 1.0254693031311035s
epoch 55: {'train_loss': '0.00969'}; time used = 1.014784336090088s
epoch 60: {'train_loss': '0.00892'}; time used = 1.087012529373169s
epoch 65: {'train_loss': '0.01232'}; time used = 1.0290272235870361s
epoch 70: {'train_loss': '0.27417'}; time used = 1.0218019485473633s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.947415113449097.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8637992831541219, 'samples': 0.868421052631579, 'weighted': 0.8677607998490852, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.40003'}; time used = 1.2083582878112793s
epoch 10: {'train_loss': '1.39432'}; time used = 1.0760912895202637s
epoch 15: {'train_loss': '1.38000'}; time used = 1.1226797103881836s
epoch 20: {'train_loss': '1.38306'}; time used = 1.1031379699707031s
epoch 25: {'train_loss': '1.35159'}; time used = 1.120617389678955s
epoch 30: {'train_loss': '1.37045'}; time used = 1.1068520545959473s
epoch 35: {'train_loss': '1.36827'}; time used = 1.1594698429107666s
epoch 40: {'train_loss': '1.30055'}; time used = 1.057405710220337s
epoch 45: {'train_loss': '1.10331'}; time used = 1.08372163772583s
epoch 50: {'train_loss': '1.09097'}; time used = 1.1463675498962402s
epoch 55: {'train_loss': '1.16112'}; time used = 1.1672148704528809s
epoch 60: {'train_loss': '0.99404'}; time used = 1.0576343536376953s
epoch 65: {'train_loss': '0.93709'}; time used = 1.0421240329742432s
epoch 70: {'train_loss': '0.95802'}; time used = 1.1355972290039062s
epoch 75: {'train_loss': '0.85989'}; time used = 1.050471544265747s
epoch 80: {'train_loss': '0.76493'}; time used = 1.1594326496124268s
epoch 85: {'train_loss': '0.73636'}; time used = 1.0756244659423828s
epoch 90: {'train_loss': '0.80518'}; time used = 1.399590015411377s
epoch 95: {'train_loss': '0.90581'}; time used = 1.0952200889587402s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.581214427947998.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.672156862745098, 'samples': 0.7105263157894737, 'weighted': 0.6898658410732714, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.73 GiB already allocated; 1.16 GiB free; 34.31 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.26537'}; time used = 1.9750382900238037s
epoch 10: {'train_loss': '1.16720'}; time used = 1.848240852355957s
epoch 15: {'train_loss': '1.01277'}; time used = 2.0770668983459473s
epoch 20: {'train_loss': '0.97289'}; time used = 1.7181780338287354s
epoch 25: {'train_loss': '0.91148'}; time used = 1.7577521800994873s
epoch 30: {'train_loss': '0.84685'}; time used = 1.7880432605743408s
epoch 35: {'train_loss': '0.83079'}; time used = 1.7659330368041992s
epoch 40: {'train_loss': '0.75845'}; time used = 1.6673147678375244s
epoch 45: {'train_loss': '0.56758'}; time used = 1.7926878929138184s
epoch 50: {'train_loss': '0.43026'}; time used = 1.7263216972351074s
epoch 55: {'train_loss': '0.21724'}; time used = 1.925872564315796s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.51731038093567.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4888888888888888, 'samples': 0.5362318840579711, 'weighted': 0.5001610305958131, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.80859'}; time used = 1.803886890411377s
epoch 10: {'train_loss': '2.77691'}; time used = 1.7259464263916016s
epoch 15: {'train_loss': '2.77176'}; time used = 1.802661418914795s
epoch 20: {'train_loss': '2.77655'}; time used = 1.8070762157440186s
epoch 25: {'train_loss': '2.77206'}; time used = 1.8573050498962402s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.396048069000244.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5218637992831542, 'samples': 0.5797101449275363, 'weighted': 0.5339151212924004, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '0.93310'}; time used = 1.2940881252288818s
epoch 10: {'train_loss': '0.63313'}; time used = 1.1966233253479004s
epoch 15: {'train_loss': '0.49203'}; time used = 1.413787841796875s
epoch 20: {'train_loss': '0.38866'}; time used = 1.1813158988952637s
epoch 25: {'train_loss': '0.38806'}; time used = 1.0967555046081543s
epoch 30: {'train_loss': '0.29751'}; time used = 0.9748356342315674s
epoch 35: {'train_loss': '0.31816'}; time used = 1.0295202732086182s
epoch 40: {'train_loss': '0.28106'}; time used = 1.0264892578125s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.556747436523438.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8347826086956521, 'samples': 0.8421052631578947, 'weighted': 0.840274599542334, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.35604'}; time used = 5.371261358261108s
epoch 10: {'train_loss': '1.35545'}; time used = 7.687826633453369s
epoch 15: {'train_loss': '1.33720'}; time used = 5.0813751220703125s
epoch 20: {'train_loss': '1.34158'}; time used = 5.836193561553955s
epoch 25: {'train_loss': '1.32650'}; time used = 5.332247257232666s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 54.14112210273743.
Training classifier using 80.00% nodes...
{'micro': 0.7299999999999999, 'macro': 0.7300000000000001, 'samples': 0.73, 'weighted': 0.73, 'accuracy': 0.73}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.59253'}; time used = 1.168215274810791s
epoch 10: {'train_loss': '1.96645'}; time used = 1.0007984638214111s
epoch 15: {'train_loss': '1.76059'}; time used = 1.0034427642822266s
epoch 20: {'train_loss': '1.62946'}; time used = 0.9576060771942139s
epoch 25: {'train_loss': '2.15821'}; time used = 0.9557986259460449s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.472172021865845.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.20 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.76613'}; time used = 1.2586870193481445s
epoch 10: {'train_loss': '2.39908'}; time used = 0.9508914947509766s
epoch 15: {'train_loss': '2.26610'}; time used = 0.9145092964172363s
epoch 20: {'train_loss': '2.13723'}; time used = 0.877110481262207s
epoch 25: {'train_loss': '2.10015'}; time used = 1.155367374420166s
epoch 30: {'train_loss': '2.04562'}; time used = 1.6887154579162598s
epoch 35: {'train_loss': '1.98778'}; time used = 1.8867528438568115s
epoch 40: {'train_loss': '1.96078'}; time used = 2.1450629234313965s
epoch 45: {'train_loss': '1.94982'}; time used = 1.8083922863006592s
epoch 50: {'train_loss': '1.90840'}; time used = 1.6319339275360107s
epoch 55: {'train_loss': '1.87323'}; time used = 1.2430040836334229s
epoch 60: {'train_loss': '1.84562'}; time used = 0.9433293342590332s
epoch 65: {'train_loss': '1.79910'}; time used = 0.9490780830383301s
epoch 70: {'train_loss': '1.81299'}; time used = 0.8719208240509033s
epoch 75: {'train_loss': '1.77051'}; time used = 0.9047067165374756s
epoch 80: {'train_loss': '1.77697'}; time used = 1.1548190116882324s
epoch 85: {'train_loss': '1.80470'}; time used = 0.9629499912261963s
epoch 90: {'train_loss': '1.78139'}; time used = 1.0011873245239258s
epoch 95: {'train_loss': '1.76862'}; time used = 1.7619097232818604s
epoch 100: {'train_loss': '1.77148'}; time used = 1.0449528694152832s
epoch 105: {'train_loss': '1.73276'}; time used = 0.949207067489624s
epoch 110: {'train_loss': '1.72416'}; time used = 0.8870096206665039s
epoch 115: {'train_loss': '1.71889'}; time used = 0.9060208797454834s
epoch 120: {'train_loss': '1.70031'}; time used = 0.9680097103118896s
epoch 125: {'train_loss': '1.71600'}; time used = 0.8832461833953857s
epoch 130: {'train_loss': '1.68752'}; time used = 0.8775238990783691s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 34.05259037017822.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.64 GiB already allocated; 1.25 GiB free; 26.45 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.78978'}; time used = 1.7572875022888184s
epoch 10: {'train_loss': '2.68236'}; time used = 1.6927955150604248s
epoch 15: {'train_loss': '2.67230'}; time used = 2.679133415222168s
epoch 20: {'train_loss': '2.61988'}; time used = 3.6833460330963135s
epoch 25: {'train_loss': '2.59338'}; time used = 1.7782132625579834s
epoch 30: {'train_loss': '2.55547'}; time used = 1.6805453300476074s
epoch 35: {'train_loss': '2.52429'}; time used = 2.1114449501037598s
epoch 40: {'train_loss': '2.47102'}; time used = 1.7447569370269775s
epoch 45: {'train_loss': '2.40121'}; time used = 1.7360808849334717s
epoch 50: {'train_loss': '2.63545'}; time used = 1.8462097644805908s
epoch 55: {'train_loss': '2.48781'}; time used = 1.7165415287017822s
epoch 60: {'train_loss': '2.47753'}; time used = 1.7824609279632568s
epoch 65: {'train_loss': '2.41611'}; time used = 1.704939603805542s
epoch 70: {'train_loss': '2.36208'}; time used = 2.004607915878296s
epoch 75: {'train_loss': '2.31962'}; time used = 1.7603559494018555s
epoch 80: {'train_loss': '2.30789'}; time used = 1.8235588073730469s
epoch 85: {'train_loss': '2.28124'}; time used = 2.6276659965515137s
epoch 90: {'train_loss': '2.28331'}; time used = 1.6977815628051758s
epoch 95: {'train_loss': '2.23736'}; time used = 1.6908161640167236s
epoch 100: {'train_loss': '2.19517'}; time used = 1.705472469329834s
epoch 105: {'train_loss': '2.20012'}; time used = 1.8046658039093018s
epoch 110: {'train_loss': '2.18934'}; time used = 2.011559009552002s
epoch 115: {'train_loss': '2.17128'}; time used = 1.996347427368164s
epoch 120: {'train_loss': '2.16390'}; time used = 1.9970011711120605s
epoch 125: {'train_loss': '2.13974'}; time used = 1.778414011001587s
epoch 130: {'train_loss': '2.20656'}; time used = 1.6735146045684814s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 53.95280623435974.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.5063131313131313, 'samples': 0.5072463768115942, 'weighted': 0.5078685404772362, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.09089'}; time used = 1.78973388671875s
epoch 10: {'train_loss': '0.03447'}; time used = 1.0892560482025146s
epoch 15: {'train_loss': '0.04624'}; time used = 1.087111234664917s
epoch 20: {'train_loss': '0.00787'}; time used = 1.1462862491607666s
epoch 25: {'train_loss': '0.01046'}; time used = 1.082315444946289s
epoch 30: {'train_loss': '0.00050'}; time used = 1.0698466300964355s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.558117866516113.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35359'}; time used = 1.7342946529388428s
epoch 10: {'train_loss': '1.31214'}; time used = 1.7338860034942627s
epoch 15: {'train_loss': '1.26526'}; time used = 1.6493663787841797s
epoch 20: {'train_loss': '1.42254'}; time used = 2.3485593795776367s
epoch 25: {'train_loss': '1.17244'}; time used = 1.8253064155578613s
epoch 30: {'train_loss': '1.06045'}; time used = 1.6110882759094238s
epoch 35: {'train_loss': '0.90865'}; time used = 1.5999574661254883s
epoch 40: {'train_loss': '0.72617'}; time used = 1.6409859657287598s
epoch 45: {'train_loss': '0.77772'}; time used = 1.6518704891204834s
epoch 50: {'train_loss': '0.76004'}; time used = 1.777118444442749s
epoch 55: {'train_loss': '0.59203'}; time used = 3.4688618183135986s
epoch 60: {'train_loss': '0.78801'}; time used = 1.7609107494354248s
epoch 65: {'train_loss': '0.78480'}; time used = 3.297868251800537s
epoch 70: {'train_loss': '0.44122'}; time used = 3.049536943435669s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.4947075843811.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5295454545454545, 'samples': 0.5652173913043478, 'weighted': 0.5389328063241107, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37314'}; time used = 4.768108129501343s
epoch 10: {'train_loss': '1.30546'}; time used = 4.715007543563843s
epoch 15: {'train_loss': '1.23502'}; time used = 4.391550302505493s
epoch 20: {'train_loss': '1.26545'}; time used = 3.5157315731048584s
epoch 25: {'train_loss': '1.13468'}; time used = 2.040311574935913s
epoch 30: {'train_loss': '1.06352'}; time used = 1.7896502017974854s
epoch 35: {'train_loss': '1.05287'}; time used = 1.7605113983154297s
epoch 40: {'train_loss': '0.96755'}; time used = 1.936288595199585s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.83323287963867.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5492160278745644, 'samples': 0.5652173913043478, 'weighted': 0.5553703984244811, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.82769'}; time used = 1.8031013011932373s
epoch 10: {'train_loss': '2.80081'}; time used = 1.9982821941375732s
epoch 15: {'train_loss': '2.78886'}; time used = 1.6606378555297852s
epoch 20: {'train_loss': '2.77615'}; time used = 1.6724746227264404s
epoch 25: {'train_loss': '2.76911'}; time used = 1.7586257457733154s
epoch 30: {'train_loss': '2.76131'}; time used = 1.7486021518707275s
epoch 35: {'train_loss': '2.75700'}; time used = 1.6550960540771484s
epoch 40: {'train_loss': '2.75166'}; time used = 1.663790225982666s
epoch 45: {'train_loss': '2.74087'}; time used = 1.7995891571044922s
epoch 50: {'train_loss': '2.73913'}; time used = 1.7253050804138184s
epoch 55: {'train_loss': '2.72980'}; time used = 1.7534561157226562s
epoch 60: {'train_loss': '2.70229'}; time used = 1.6088738441467285s
epoch 65: {'train_loss': '2.67838'}; time used = 1.684424638748169s
epoch 70: {'train_loss': '2.68821'}; time used = 1.6476020812988281s
epoch 75: {'train_loss': '2.64095'}; time used = 2.3491573333740234s
epoch 80: {'train_loss': '2.65331'}; time used = 3.1193935871124268s
epoch 85: {'train_loss': '2.65172'}; time used = 3.1119980812072754s
epoch 90: {'train_loss': '2.63297'}; time used = 2.9302549362182617s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.75168800354004.
Training classifier using 80.00% nodes...
{'micro': 0.5072463768115942, 'macro': 0.5021222410865874, 'samples': 0.5072463768115942, 'weighted': 0.5057823380330209, 'accuracy': 0.5072463768115942}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.84406'}; time used = 1.844804048538208s
epoch 10: {'train_loss': '2.72870'}; time used = 3.136875629425049s
epoch 15: {'train_loss': '2.70457'}; time used = 2.9471898078918457s
epoch 20: {'train_loss': '2.68265'}; time used = 2.965925931930542s
epoch 25: {'train_loss': '2.65917'}; time used = 2.4291841983795166s
epoch 30: {'train_loss': '2.63972'}; time used = 1.7077701091766357s
epoch 35: {'train_loss': '2.62867'}; time used = 1.6934151649475098s
epoch 40: {'train_loss': '2.61490'}; time used = 1.7368111610412598s
epoch 45: {'train_loss': '2.60111'}; time used = 1.6341056823730469s
epoch 50: {'train_loss': '2.58115'}; time used = 1.727888822555542s
epoch 55: {'train_loss': '2.58703'}; time used = 1.6839969158172607s
epoch 60: {'train_loss': '2.59556'}; time used = 1.6293816566467285s
epoch 65: {'train_loss': '2.58314'}; time used = 1.7988228797912598s
epoch 70: {'train_loss': '2.56749'}; time used = 1.9877281188964844s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 33.676708698272705.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5218637992831542, 'samples': 0.5797101449275363, 'weighted': 0.5339151212924004, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.81941'}; time used = 1.1915199756622314s
epoch 10: {'train_loss': '2.67200'}; time used = 0.9518945217132568s
epoch 15: {'train_loss': '2.58870'}; time used = 1.082430362701416s
epoch 20: {'train_loss': '2.49256'}; time used = 1.0776479244232178s
epoch 25: {'train_loss': '2.35110'}; time used = 1.3430070877075195s
epoch 30: {'train_loss': '2.19357'}; time used = 1.3439161777496338s
epoch 35: {'train_loss': '2.05813'}; time used = 1.2952172756195068s
epoch 40: {'train_loss': '1.99052'}; time used = 1.2303802967071533s
epoch 45: {'train_loss': '1.86344'}; time used = 1.0671155452728271s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.27842378616333.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.39237'}; time used = 1.209965467453003s
epoch 10: {'train_loss': '1.35231'}; time used = 1.086271047592163s
epoch 15: {'train_loss': '1.19755'}; time used = 1.0649616718292236s
epoch 20: {'train_loss': '1.01299'}; time used = 1.0959501266479492s
epoch 25: {'train_loss': '0.85020'}; time used = 1.0993850231170654s
epoch 30: {'train_loss': '0.68686'}; time used = 1.1110923290252686s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.577021598815918.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.87214'}; time used = 2.0246973037719727s
epoch 10: {'train_loss': '2.78964'}; time used = 2.0596823692321777s
epoch 15: {'train_loss': '2.77614'}; time used = 2.221247911453247s
epoch 20: {'train_loss': '2.77008'}; time used = 1.9997055530548096s
epoch 25: {'train_loss': '2.77151'}; time used = 2.0175302028656006s
epoch 30: {'train_loss': '2.77135'}; time used = 1.9610342979431152s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.9170081615448.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4866071428571428, 'samples': 0.5652173913043478, 'weighted': 0.5011645962732919, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1013.44 MiB free; 19.51 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.33083'}; time used = 3.2177376747131348s
epoch 10: {'train_loss': '1.18693'}; time used = 3.6131081581115723s
epoch 15: {'train_loss': '1.07682'}; time used = 3.4303481578826904s
epoch 20: {'train_loss': '1.07269'}; time used = 2.4150357246398926s
epoch 25: {'train_loss': '0.98356'}; time used = 1.9349515438079834s
epoch 30: {'train_loss': '0.93481'}; time used = 1.7561218738555908s
epoch 35: {'train_loss': '0.93292'}; time used = 1.800135612487793s
epoch 40: {'train_loss': '0.77538'}; time used = 2.5942232608795166s
epoch 45: {'train_loss': '0.73910'}; time used = 1.753760814666748s
epoch 50: {'train_loss': '0.56188'}; time used = 1.829530954360962s
epoch 55: {'train_loss': '0.46030'}; time used = 1.7632777690887451s
epoch 60: {'train_loss': '0.58108'}; time used = 1.748995304107666s
epoch 65: {'train_loss': '0.62322'}; time used = 1.7201991081237793s
epoch 70: {'train_loss': '0.59333'}; time used = 1.7156424522399902s
epoch 75: {'train_loss': '0.27871'}; time used = 1.803429365158081s
epoch 80: {'train_loss': '0.15531'}; time used = 1.7018933296203613s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.036781549453735.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5606960950764007, 'samples': 0.5652173913043478, 'weighted': 0.5639255923820773, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39426'}; time used = 1.083254337310791s
epoch 10: {'train_loss': '1.38112'}; time used = 0.9753634929656982s
epoch 15: {'train_loss': '1.29377'}; time used = 0.965825080871582s
epoch 20: {'train_loss': '1.29119'}; time used = 0.9728710651397705s
epoch 25: {'train_loss': '1.05462'}; time used = 0.9899141788482666s
epoch 30: {'train_loss': '1.20096'}; time used = 0.9841103553771973s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.073604345321655.
Training classifier using 80.00% nodes...
{'micro': 0.5526315789473685, 'macro': 0.4933333333333334, 'samples': 0.5526315789473685, 'weighted': 0.520701754385965, 'accuracy': 0.5526315789473685}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 16.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.79675'}; time used = 1.1081488132476807s
epoch 10: {'train_loss': '2.81502'}; time used = 0.9400472640991211s
epoch 15: {'train_loss': '2.78053'}; time used = 0.9523861408233643s
epoch 20: {'train_loss': '2.77388'}; time used = 0.9722890853881836s
epoch 25: {'train_loss': '2.78190'}; time used = 0.9508097171783447s
epoch 30: {'train_loss': '2.77777'}; time used = 0.9684586524963379s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.083999872207642.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.7989417989417988, 'samples': 0.8157894736842105, 'weighted': 0.808131439710387, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '1.32360'}; time used = 7.227080821990967s
epoch 10: {'train_loss': '1.31825'}; time used = 7.031358480453491s
epoch 15: {'train_loss': '1.27960'}; time used = 7.110151529312134s
epoch 20: {'train_loss': '1.20312'}; time used = 7.0706467628479s
epoch 25: {'train_loss': '1.08980'}; time used = 7.0297582149505615s
epoch 30: {'train_loss': '1.20978'}; time used = 6.996422290802002s
epoch 35: {'train_loss': '1.19837'}; time used = 7.049858331680298s
epoch 40: {'train_loss': '1.13443'}; time used = 7.104934215545654s
epoch 45: {'train_loss': '1.12784'}; time used = 6.979488849639893s
epoch 50: {'train_loss': '1.05885'}; time used = 7.153374671936035s
epoch 55: {'train_loss': '1.27613'}; time used = 8.336314916610718s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 101.6956479549408.
Training classifier using 80.00% nodes...
{'micro': 0.5166666666666667, 'macro': 0.5031087785491111, 'samples': 0.5166666666666667, 'weighted': 0.4986903618184046, 'accuracy': 0.5166666666666667}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35359'}; time used = 1.7948932647705078s
epoch 10: {'train_loss': '1.31214'}; time used = 1.6302249431610107s
epoch 15: {'train_loss': '1.26526'}; time used = 1.7211766242980957s
epoch 20: {'train_loss': '1.42254'}; time used = 1.6801226139068604s
epoch 25: {'train_loss': '1.17244'}; time used = 1.7652804851531982s
epoch 30: {'train_loss': '1.06045'}; time used = 1.733062505722046s
epoch 35: {'train_loss': '0.90865'}; time used = 1.8928484916687012s
epoch 40: {'train_loss': '0.72617'}; time used = 1.8235244750976562s
epoch 45: {'train_loss': '0.77772'}; time used = 1.8839263916015625s
epoch 50: {'train_loss': '0.76004'}; time used = 1.909379482269287s
epoch 55: {'train_loss': '0.59203'}; time used = 1.8290925025939941s
epoch 60: {'train_loss': '0.78801'}; time used = 1.8517255783081055s
epoch 65: {'train_loss': '0.78480'}; time used = 1.8795535564422607s
epoch 70: {'train_loss': '0.44122'}; time used = 1.8380506038665771s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.656867504119873.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5295454545454545, 'samples': 0.5652173913043478, 'weighted': 0.5389328063241107, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.29 GiB free; 34.89 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.21714'}; time used = 1.732332468032837s
epoch 10: {'train_loss': '2.79546'}; time used = 1.7029480934143066s
epoch 15: {'train_loss': '2.72838'}; time used = 1.6217420101165771s
epoch 20: {'train_loss': '2.67240'}; time used = 1.59995698928833s
epoch 25: {'train_loss': '2.62874'}; time used = 1.775733470916748s
epoch 30: {'train_loss': '2.59774'}; time used = 1.634354829788208s
epoch 35: {'train_loss': '2.56790'}; time used = 1.5934045314788818s
epoch 40: {'train_loss': '2.54401'}; time used = 1.5923097133636475s
epoch 45: {'train_loss': '2.52000'}; time used = 1.6170620918273926s
epoch 50: {'train_loss': '2.46658'}; time used = 1.6108319759368896s
epoch 55: {'train_loss': '2.43496'}; time used = 1.603370189666748s
epoch 60: {'train_loss': '2.41563'}; time used = 1.6008975505828857s
epoch 65: {'train_loss': '2.37054'}; time used = 1.6099896430969238s
epoch 70: {'train_loss': '2.30573'}; time used = 1.6067800521850586s
epoch 75: {'train_loss': '2.27263'}; time used = 1.6028659343719482s
epoch 80: {'train_loss': '2.41090'}; time used = 1.8029396533966064s
epoch 85: {'train_loss': '2.29565'}; time used = 1.763869285583496s
epoch 90: {'train_loss': '2.29997'}; time used = 1.6094565391540527s
epoch 95: {'train_loss': '2.26800'}; time used = 1.906874179840088s
epoch 100: {'train_loss': '2.21234'}; time used = 1.9877867698669434s
epoch 105: {'train_loss': '2.21020'}; time used = 1.7889385223388672s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.030590772628784.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5765079365079364, 'samples': 0.5797101449275363, 'weighted': 0.5791764435242696, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 10.35 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.84805'}; time used = 4.2249157428741455s
epoch 10: {'train_loss': '2.77701'}; time used = 4.077054023742676s
epoch 15: {'train_loss': '2.78162'}; time used = 4.251153230667114s
epoch 20: {'train_loss': '2.77760'}; time used = 4.18543553352356s
epoch 25: {'train_loss': '2.77394'}; time used = 4.1884894371032715s
epoch 30: {'train_loss': '2.77525'}; time used = 4.205499172210693s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 32.860981702804565.
Training classifier using 80.00% nodes...
{'micro': 0.68, 'macro': 0.6784242789669379, 'samples': 0.68, 'weighted': 0.6779740729574917, 'accuracy': 0.68}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.03255'}; time used = 1.7750999927520752s
epoch 10: {'train_loss': '0.00697'}; time used = 1.8251523971557617s
epoch 15: {'train_loss': '0.00484'}; time used = 1.7036199569702148s
epoch 20: {'train_loss': '0.00030'}; time used = 1.6756112575531006s
epoch 25: {'train_loss': '0.00009'}; time used = 1.775383472442627s
epoch 30: {'train_loss': '0.00014'}; time used = 1.7573573589324951s
epoch 35: {'train_loss': '0.02936'}; time used = 1.7296690940856934s
epoch 40: {'train_loss': '0.00027'}; time used = 1.6589510440826416s
epoch 45: {'train_loss': '0.00094'}; time used = 1.5902423858642578s
epoch 50: {'train_loss': '0.00311'}; time used = 1.6071033477783203s
epoch 55: {'train_loss': '0.00334'}; time used = 1.6811645030975342s
epoch 60: {'train_loss': '0.03440'}; time used = 1.5950191020965576s
epoch 65: {'train_loss': '0.01470'}; time used = 1.8060309886932373s
epoch 70: {'train_loss': '0.19933'}; time used = 2.091620683670044s
epoch 75: {'train_loss': '0.05422'}; time used = 1.7071568965911865s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.325660228729248.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5101591187270502, 'samples': 0.5797101449275363, 'weighted': 0.5235343160732975, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.66286'}; time used = 1.2124996185302734s
epoch 10: {'train_loss': '2.27200'}; time used = 1.136704683303833s
epoch 15: {'train_loss': '1.73385'}; time used = 1.0169031620025635s
epoch 20: {'train_loss': '1.43474'}; time used = 0.9786972999572754s
epoch 25: {'train_loss': '1.50977'}; time used = 0.9878561496734619s
epoch 30: {'train_loss': '1.90240'}; time used = 0.9775538444519043s
epoch 35: {'train_loss': '1.57394'}; time used = 0.961622953414917s
epoch 40: {'train_loss': '1.44447'}; time used = 0.9568405151367188s
epoch 45: {'train_loss': '1.33610'}; time used = 0.9703712463378906s
epoch 50: {'train_loss': '1.20761'}; time used = 0.9831717014312744s
epoch 55: {'train_loss': '1.16372'}; time used = 0.9694499969482422s
epoch 60: {'train_loss': '1.11117'}; time used = 1.0651535987854004s
epoch 65: {'train_loss': '1.05892'}; time used = 0.9716997146606445s
epoch 70: {'train_loss': '1.02803'}; time used = 1.1188859939575195s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.615319967269897.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6695652173913045, 'samples': 0.6842105263157895, 'weighted': 0.6805491990846683, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.64415'}; time used = 1.2407221794128418s
epoch 10: {'train_loss': '2.53139'}; time used = 1.2599303722381592s
epoch 15: {'train_loss': '2.47509'}; time used = 1.5636229515075684s
epoch 20: {'train_loss': '2.38731'}; time used = 1.8449604511260986s
epoch 25: {'train_loss': '2.34327'}; time used = 1.7615547180175781s
epoch 30: {'train_loss': '2.28567'}; time used = 1.773345708847046s
epoch 35: {'train_loss': '2.25319'}; time used = 2.002779960632324s
epoch 40: {'train_loss': '2.20492'}; time used = 1.1064610481262207s
epoch 45: {'train_loss': '2.17376'}; time used = 0.9636075496673584s
epoch 50: {'train_loss': '2.16284'}; time used = 1.0059731006622314s
epoch 55: {'train_loss': '2.13628'}; time used = 0.9655416011810303s
epoch 60: {'train_loss': '2.11083'}; time used = 1.0534658432006836s
epoch 65: {'train_loss': '2.11282'}; time used = 0.9627659320831299s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.562662601470947.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.27 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.30 GiB free; 26.25 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.35885'}; time used = 1.8469758033752441s
epoch 10: {'train_loss': '1.29221'}; time used = 1.7577004432678223s
epoch 15: {'train_loss': '1.30796'}; time used = 1.768554449081421s
epoch 20: {'train_loss': '1.40529'}; time used = 1.7855706214904785s
epoch 25: {'train_loss': '1.35095'}; time used = 1.8679332733154297s
epoch 30: {'train_loss': '1.31801'}; time used = 1.806063175201416s
epoch 35: {'train_loss': '1.30219'}; time used = 1.8282356262207031s
epoch 40: {'train_loss': '1.27229'}; time used = 1.887915849685669s
epoch 45: {'train_loss': '1.35604'}; time used = 1.8691656589508057s
epoch 50: {'train_loss': '1.21462'}; time used = 2.031080961227417s
epoch 55: {'train_loss': '1.23795'}; time used = 1.8931469917297363s
epoch 60: {'train_loss': '1.27194'}; time used = 1.8628809452056885s
epoch 65: {'train_loss': '1.32857'}; time used = 1.90561842918396s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 28.99627161026001.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.49818181818181817, 'samples': 0.5362318840579711, 'weighted': 0.5081949934123847, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 28.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.02 GiB free; 27.17 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.37767'}; time used = 2.1990702152252197s
epoch 10: {'train_loss': '1.34257'}; time used = 2.1698415279388428s
epoch 15: {'train_loss': '1.36560'}; time used = 2.3075406551361084s
epoch 20: {'train_loss': '1.39597'}; time used = 2.362907886505127s
epoch 25: {'train_loss': '1.30191'}; time used = 2.3781378269195557s
epoch 30: {'train_loss': '1.16056'}; time used = 2.296708583831787s
epoch 35: {'train_loss': '1.07262'}; time used = 2.1759862899780273s
epoch 40: {'train_loss': '1.06764'}; time used = 2.1310293674468994s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.791060209274292.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4145927601809955, 'samples': 0.5652173913043478, 'weighted': 0.43611056462718867, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.38736'}; time used = 1.1486573219299316s
epoch 10: {'train_loss': '1.39736'}; time used = 1.0402288436889648s
epoch 15: {'train_loss': '1.27388'}; time used = 0.9823577404022217s
epoch 20: {'train_loss': '1.44021'}; time used = 0.9584653377532959s
epoch 25: {'train_loss': '0.87064'}; time used = 1.0476930141448975s
epoch 30: {'train_loss': '1.25864'}; time used = 0.9921102523803711s
epoch 35: {'train_loss': '1.37683'}; time used = 1.1304454803466797s
epoch 40: {'train_loss': '1.02265'}; time used = 0.924990177154541s
epoch 45: {'train_loss': '0.89749'}; time used = 1.274522304534912s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.062637567520142.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.35 GiB free; 33.70 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.12898'}; time used = 1.8716866970062256s
epoch 10: {'train_loss': '0.89692'}; time used = 2.1085004806518555s
epoch 15: {'train_loss': '0.56407'}; time used = 1.9814300537109375s
epoch 20: {'train_loss': '0.34944'}; time used = 1.867419719696045s
epoch 25: {'train_loss': '0.19119'}; time used = 2.145003318786621s
epoch 30: {'train_loss': '0.11576'}; time used = 1.6308269500732422s
epoch 35: {'train_loss': '0.04176'}; time used = 1.8746087551116943s
epoch 40: {'train_loss': '0.08083'}; time used = 1.8350770473480225s
epoch 45: {'train_loss': '0.01409'}; time used = 1.6374666690826416s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.318261861801147.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5679785330948122, 'samples': 0.5942028985507246, 'weighted': 0.5756915817583158, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.83 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.39678'}; time used = 1.1184155941009521s
epoch 10: {'train_loss': '1.38447'}; time used = 0.9681534767150879s
epoch 15: {'train_loss': '1.28681'}; time used = 0.9374024868011475s
epoch 20: {'train_loss': '1.34577'}; time used = 0.9773101806640625s
epoch 25: {'train_loss': '1.25756'}; time used = 0.9526674747467041s
epoch 30: {'train_loss': '1.20619'}; time used = 0.9667596817016602s
epoch 35: {'train_loss': '1.29419'}; time used = 1.0011310577392578s
epoch 40: {'train_loss': '1.21670'}; time used = 1.1000750064849854s
epoch 45: {'train_loss': '1.11731'}; time used = 1.0180771350860596s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.659221887588501.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.04 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 252, in main
    res = task.evaluate(model, res, graph)  # evaluate
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/graph_classification.py", line 21, in evaluate
    return self._classify(dataset, res, 0)
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/graph_classification.py", line 34, in _classify
    return clf.train_and_evaluate(dataset, self.train_kwargs()['clf_ratio'], seed=seed)
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/classify.py", line 80, in train_and_evaluate
    self.train(X_train, Y_train, graph.labels()[1])
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/classify.py", line 50, in train
    self.clf.fit(X_train, Y)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/multiclass.py", line 216, in fit
    for i, column in enumerate(columns))
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 921, in __call__
    if self.dispatch_one_batch(iterator):
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 759, in dispatch_one_batch
    self._dispatch(tasks)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 716, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/_parallel_backends.py", line 182, in apply_async
    result = ImmediateResult(func)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/_parallel_backends.py", line 549, in __init__
    self.results = batch()
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 225, in __call__
    for func, args, kwargs in self.items]
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/joblib/parallel.py", line 225, in <listcomp>
    for func, args, kwargs in self.items]
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/multiclass.py", line 80, in _fit_binary
    estimator.fit(X, y)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py", line 2004, in fit
    accept_large_sparse=solver != 'liblinear')
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/utils/validation.py", line 719, in check_X_y
    estimator=estimator)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/utils/validation.py", line 542, in check_array
    allow_nan=force_all_finite == 'allow-nan')
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/utils/validation.py", line 56, in _assert_all_finite
    raise ValueError(msg_err.format(type_err, X.dtype))
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.36509'}; time used = 1.8478374481201172s
epoch 10: {'train_loss': '1.22982'}; time used = 2.0581467151641846s
epoch 15: {'train_loss': '1.12925'}; time used = 1.779728651046753s
epoch 20: {'train_loss': '1.13433'}; time used = 1.785412311553955s
epoch 25: {'train_loss': '1.01162'}; time used = 1.8138911724090576s
epoch 30: {'train_loss': '0.55686'}; time used = 1.7231793403625488s
epoch 35: {'train_loss': '0.67361'}; time used = 1.8052172660827637s
epoch 40: {'train_loss': '0.69172'}; time used = 1.7869246006011963s
epoch 45: {'train_loss': '0.78424'}; time used = 1.7896232604980469s
epoch 50: {'train_loss': '0.61252'}; time used = 1.838852882385254s
epoch 55: {'train_loss': '0.53233'}; time used = 1.7802269458770752s
epoch 60: {'train_loss': '0.56625'}; time used = 1.7718579769134521s
epoch 65: {'train_loss': '0.55060'}; time used = 1.7590930461883545s
epoch 70: {'train_loss': '0.61120'}; time used = 1.7613120079040527s
epoch 75: {'train_loss': '1.37482'}; time used = 1.910470724105835s
epoch 80: {'train_loss': '1.27228'}; time used = 2.698975086212158s
epoch 85: {'train_loss': 'nan'}; time used = 5.266196250915527s
epoch 90: {'train_loss': 'nan'}; time used = 1.8815720081329346s
epoch 95: {'train_loss': 'nan'}; time used = 1.834477186203003s
epoch 100: {'train_loss': 'nan'}; time used = 2.0166409015655518s
epoch 105: {'train_loss': 'nan'}; time used = 1.868483543395996s
epoch 110: {'train_loss': 'nan'}; time used = 1.863539695739746s
epoch 115: {'train_loss': 'nan'}; time used = 1.784595251083374s
epoch 120: {'train_loss': 'nan'}; time used = 5.775669813156128s
epoch 125: {'train_loss': 'nan'}; time used = 6.05173134803772s
epoch 130: {'train_loss': 'nan'}; time used = 5.683100461959839s
epoch 135: {'train_loss': 'nan'}; time used = 6.5949859619140625s
epoch 140: {'train_loss': 'nan'}; time used = 6.403604984283447s
epoch 145: {'train_loss': 'nan'}; time used = 5.423603773117065s
epoch 150: {'train_loss': 'nan'}; time used = 6.147639036178589s
epoch 155: {'train_loss': 'nan'}; time used = 5.35615086555481s
epoch 160: {'train_loss': 'nan'}; time used = 3.001746654510498s
epoch 165: {'train_loss': 'nan'}; time used = 1.7719166278839111s
epoch 170: {'train_loss': 'nan'}; time used = 1.7371492385864258s
epoch 175: {'train_loss': 'nan'}; time used = 2.090167760848999s
epoch 180: {'train_loss': 'nan'}; time used = 1.8632433414459229s
epoch 185: {'train_loss': 'nan'}; time used = 1.7440896034240723s
epoch 190: {'train_loss': 'nan'}; time used = 1.8095221519470215s
epoch 195: {'train_loss': 'nan'}; time used = 1.7452635765075684s
epoch 200: {'train_loss': 'nan'}; time used = 1.8276841640472412s
epoch 205: {'train_loss': 'nan'}; time used = 2.0251762866973877s
epoch 210: {'train_loss': 'nan'}; time used = 1.7701573371887207s
epoch 215: {'train_loss': 'nan'}; time used = 1.8534839153289795s
epoch 220: {'train_loss': 'nan'}; time used = 1.8756451606750488s
epoch 225: {'train_loss': 'nan'}; time used = 1.9217584133148193s
epoch 230: {'train_loss': 'nan'}; time used = 1.8460602760314941s
epoch 235: {'train_loss': 'nan'}; time used = 1.9636712074279785s
epoch 240: {'train_loss': 'nan'}; time used = 1.8130996227264404s
epoch 245: {'train_loss': 'nan'}; time used = 1.8120191097259521s
epoch 250: {'train_loss': 'nan'}; time used = 1.8925468921661377s
epoch 255: {'train_loss': 'nan'}; time used = 1.7663636207580566s
epoch 260: {'train_loss': 'nan'}; time used = 1.8072125911712646s
epoch 265: {'train_loss': 'nan'}; time used = 1.8342127799987793s
epoch 270: {'train_loss': 'nan'}; time used = 1.8353660106658936s
epoch 275: {'train_loss': 'nan'}; time used = 1.8161611557006836s
epoch 280: {'train_loss': 'nan'}; time used = 1.8099298477172852s
epoch 285: {'train_loss': 'nan'}; time used = 1.8797390460968018s
epoch 290: {'train_loss': 'nan'}; time used = 1.8128893375396729s
epoch 295: {'train_loss': 'nan'}; time used = 1.7577524185180664s
epoch 300: {'train_loss': 'nan'}; time used = 1.8955872058868408s
epoch 305: {'train_loss': 'nan'}; time used = 1.8099584579467773s
epoch 310: {'train_loss': 'nan'}; time used = 1.8636810779571533s
epoch 315: {'train_loss': 'nan'}; time used = 1.7795469760894775s
epoch 320: {'train_loss': 'nan'}; time used = 1.8835601806640625s
epoch 325: {'train_loss': 'nan'}; time used = 1.765611171722412s
epoch 330: {'train_loss': 'nan'}; time used = 1.7488605976104736s
epoch 335: {'train_loss': 'nan'}; time used = 1.9660813808441162s
epoch 340: {'train_loss': 'nan'}; time used = 1.8419685363769531s
epoch 345: {'train_loss': 'nan'}; time used = 1.7995305061340332s
epoch 350: {'train_loss': 'nan'}; time used = 1.806532621383667s
epoch 355: {'train_loss': 'nan'}; time used = 1.7964396476745605s
epoch 360: {'train_loss': 'nan'}; time used = 1.788590908050537s
epoch 365: {'train_loss': 'nan'}; time used = 1.8107564449310303s
epoch 370: {'train_loss': 'nan'}; time used = 1.7662887573242188s
epoch 375: {'train_loss': 'nan'}; time used = 1.7858200073242188s
epoch 380: {'train_loss': 'nan'}; time used = 1.916459560394287s
epoch 385: {'train_loss': 'nan'}; time used = 1.8183939456939697s
epoch 390: {'train_loss': 'nan'}; time used = 1.8473374843597412s
epoch 395: {'train_loss': 'nan'}; time used = 1.8021929264068604s
epoch 400: {'train_loss': 'nan'}; time used = 1.8007380962371826s
epoch 405: {'train_loss': 'nan'}; time used = 1.755044937133789s
epoch 410: {'train_loss': 'nan'}; time used = 1.7410283088684082s
epoch 415: {'train_loss': 'nan'}; time used = 1.797187089920044s
epoch 420: {'train_loss': 'nan'}; time used = 1.754033088684082s
epoch 425: {'train_loss': 'nan'}; time used = 1.8298208713531494s
epoch 430: {'train_loss': 'nan'}; time used = 1.817307710647583s
epoch 435: {'train_loss': 'nan'}; time used = 2.200465679168701s
epoch 440: {'train_loss': 'nan'}; time used = 2.4736804962158203s
epoch 445: {'train_loss': 'nan'}; time used = 1.8621151447296143s
epoch 450: {'train_loss': 'nan'}; time used = 1.8871452808380127s
epoch 455: {'train_loss': 'nan'}; time used = 1.9261014461517334s
epoch 460: {'train_loss': 'nan'}; time used = 1.7235095500946045s
epoch 465: {'train_loss': 'nan'}; time used = 3.3276588916778564s
epoch 470: {'train_loss': 'nan'}; time used = 3.6526591777801514s
epoch 475: {'train_loss': 'nan'}; time used = 3.4612197875976562s
epoch 480: {'train_loss': 'nan'}; time used = 2.9295947551727295s
epoch 485: {'train_loss': 'nan'}; time used = 1.9675490856170654s
epoch 490: {'train_loss': 'nan'}; time used = 1.8210556507110596s
epoch 495: {'train_loss': 'nan'}; time used = 1.8373222351074219s
epoch 500: {'train_loss': 'nan'}; time used = 1.771772861480713s
Finished training. Time used = 233.02628135681152.
Training classifier using 80.00% nodes...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.39621'}; time used = 2.5843136310577393s
epoch 10: {'train_loss': '1.36565'}; time used = 2.281548500061035s
epoch 15: {'train_loss': '1.29215'}; time used = 2.245027542114258s
epoch 20: {'train_loss': '1.30354'}; time used = 1.0341765880584717s
epoch 25: {'train_loss': '1.19172'}; time used = 1.0349483489990234s
epoch 30: {'train_loss': '1.01932'}; time used = 1.2929565906524658s
epoch 35: {'train_loss': '1.09721'}; time used = 1.3352015018463135s
epoch 40: {'train_loss': '0.93424'}; time used = 1.0330219268798828s
epoch 45: {'train_loss': '0.79866'}; time used = 1.0596814155578613s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.868627786636353.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '1.35981'}; time used = 2.352921962738037s
epoch 10: {'train_loss': '1.31844'}; time used = 2.268454074859619s
epoch 15: {'train_loss': '1.23525'}; time used = 1.9395666122436523s
epoch 20: {'train_loss': '1.18103'}; time used = 1.5452919006347656s
epoch 25: {'train_loss': '0.91968'}; time used = 0.9881272315979004s
epoch 30: {'train_loss': '0.99601'}; time used = 1.1823523044586182s
epoch 35: {'train_loss': '0.92313'}; time used = 1.1001157760620117s
epoch 40: {'train_loss': '0.84883'}; time used = 1.0750255584716797s
epoch 45: {'train_loss': '0.65276'}; time used = 1.0710923671722412s
epoch 50: {'train_loss': '0.76842'}; time used = 1.0851523876190186s
epoch 55: {'train_loss': '0.57137'}; time used = 1.1000373363494873s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.403337478637695.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.67437'}; time used = 1.1573028564453125s
epoch 10: {'train_loss': '2.47799'}; time used = 1.1641895771026611s
epoch 15: {'train_loss': '2.35911'}; time used = 1.1061477661132812s
epoch 20: {'train_loss': '2.31056'}; time used = 1.1925382614135742s
epoch 25: {'train_loss': '2.24488'}; time used = 1.1756980419158936s
epoch 30: {'train_loss': '2.09311'}; time used = 1.0999414920806885s
epoch 35: {'train_loss': '1.87898'}; time used = 1.0386872291564941s
epoch 40: {'train_loss': '2.57545'}; time used = 1.0499308109283447s
epoch 45: {'train_loss': '2.27934'}; time used = 1.0533440113067627s
epoch 50: {'train_loss': '2.11264'}; time used = 1.0491466522216797s
epoch 55: {'train_loss': '2.05404'}; time used = 1.0728027820587158s
epoch 60: {'train_loss': '1.94955'}; time used = 1.130368709564209s
epoch 65: {'train_loss': '1.84182'}; time used = 1.0476365089416504s
epoch 70: {'train_loss': '1.72341'}; time used = 1.0490436553955078s
epoch 75: {'train_loss': '1.64475'}; time used = 1.0296473503112793s
epoch 80: {'train_loss': '1.64656'}; time used = 1.17063570022583s
epoch 85: {'train_loss': '1.63708'}; time used = 1.079427719116211s
epoch 90: {'train_loss': '1.56191'}; time used = 1.1700530052185059s
epoch 95: {'train_loss': '2.20728'}; time used = 1.2516560554504395s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.054534673690796.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7797101449275363, 'samples': 0.7894736842105263, 'weighted': 0.7870327993897789, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.14 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.77865'}; time used = 2.173696994781494s
epoch 10: {'train_loss': '2.77478'}; time used = 2.0557925701141357s
epoch 15: {'train_loss': '2.77321'}; time used = 2.099208354949951s
epoch 20: {'train_loss': '2.77370'}; time used = 2.1367712020874023s
epoch 25: {'train_loss': '2.77363'}; time used = 2.136416435241699s
epoch 30: {'train_loss': '2.77267'}; time used = 2.0467419624328613s
epoch 35: {'train_loss': '2.77253'}; time used = 2.033144950866699s
epoch 40: {'train_loss': '2.77283'}; time used = 2.0039288997650146s
epoch 45: {'train_loss': '2.77242'}; time used = 2.3639931678771973s
epoch 50: {'train_loss': '2.77284'}; time used = 2.692556142807007s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.116451501846313.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.4189473684210526, 'samples': 0.5362318840579711, 'weighted': 0.4378642257818459, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.36942'}; time used = 3.6424176692962646s
epoch 10: {'train_loss': '1.28932'}; time used = 3.8172974586486816s
epoch 15: {'train_loss': '1.23958'}; time used = 2.9679372310638428s
epoch 20: {'train_loss': '1.27624'}; time used = 1.814253568649292s
epoch 25: {'train_loss': '1.14966'}; time used = 1.903169870376587s
epoch 30: {'train_loss': '1.02838'}; time used = 1.954195261001587s
epoch 35: {'train_loss': '1.06545'}; time used = 1.8059992790222168s
epoch 40: {'train_loss': '0.83107'}; time used = 1.9716243743896484s
epoch 45: {'train_loss': '0.78776'}; time used = 1.7714107036590576s
epoch 50: {'train_loss': '0.63418'}; time used = 3.415628671646118s
epoch 55: {'train_loss': '0.46576'}; time used = 4.1641881465911865s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 40.290284395217896.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5367121507472385, 'samples': 0.5507246376811594, 'weighted': 0.5425506869697055, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.89639'}; time used = 1.2675144672393799s
epoch 10: {'train_loss': '2.81327'}; time used = 1.161034345626831s
epoch 15: {'train_loss': '2.79403'}; time used = 1.1020605564117432s
epoch 20: {'train_loss': '2.78147'}; time used = 1.1015610694885254s
epoch 25: {'train_loss': '2.77577'}; time used = 1.1552186012268066s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.3296799659729.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5947497949138638, 'samples': 0.6578947368421053, 'weighted': 0.6200077716851604, 'accuracy': 0.6578947368421053}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.34701'}; time used = 1.1293127536773682s
epoch 10: {'train_loss': '1.27933'}; time used = 1.0478160381317139s
epoch 15: {'train_loss': '1.16532'}; time used = 1.1186470985412598s
epoch 20: {'train_loss': '1.21130'}; time used = 1.1583759784698486s
epoch 25: {'train_loss': '1.07209'}; time used = 1.1556329727172852s
epoch 30: {'train_loss': '0.89419'}; time used = 0.9582247734069824s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.482728242874146.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6840513983371126, 'samples': 0.7105263157894737, 'weighted': 0.6984922624020369, 'accuracy': 0.7105263157894737}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.04 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.74501'}; time used = 1.272510290145874s
epoch 10: {'train_loss': '2.57902'}; time used = 1.1835498809814453s
epoch 15: {'train_loss': '2.40938'}; time used = 1.1651556491851807s
epoch 20: {'train_loss': '2.11800'}; time used = 1.1680998802185059s
epoch 25: {'train_loss': '2.06361'}; time used = 1.163280725479126s
epoch 30: {'train_loss': '1.94305'}; time used = 1.1715922355651855s
epoch 35: {'train_loss': '1.90913'}; time used = 1.190793514251709s
epoch 40: {'train_loss': '1.86445'}; time used = 1.217851161956787s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.9948890209198.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.05631'}; time used = 2.129333972930908s
epoch 10: {'train_loss': '0.46876'}; time used = 2.261317729949951s
epoch 15: {'train_loss': '0.30834'}; time used = 1.7555198669433594s
epoch 20: {'train_loss': '0.28074'}; time used = 1.7813293933868408s
epoch 25: {'train_loss': '0.30440'}; time used = 1.8766133785247803s
epoch 30: {'train_loss': '0.29153'}; time used = 1.7628860473632812s
epoch 35: {'train_loss': '0.28912'}; time used = 2.7878665924072266s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 18.338507413864136.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.77135'}; time used = 1.0322868824005127s
epoch 10: {'train_loss': '2.56205'}; time used = 1.0606663227081299s
epoch 15: {'train_loss': '2.41932'}; time used = 1.0609679222106934s
epoch 20: {'train_loss': '2.21000'}; time used = 1.0734505653381348s
epoch 25: {'train_loss': '2.12225'}; time used = 1.0512957572937012s
epoch 30: {'train_loss': '2.02714'}; time used = 1.0513148307800293s
epoch 35: {'train_loss': '1.90864'}; time used = 1.0668370723724365s
epoch 40: {'train_loss': '1.87545'}; time used = 1.0560340881347656s
epoch 45: {'train_loss': '1.85802'}; time used = 0.9350602626800537s
epoch 50: {'train_loss': '1.83595'}; time used = 0.9148030281066895s
epoch 55: {'train_loss': '1.82431'}; time used = 0.9231281280517578s
epoch 60: {'train_loss': '1.82372'}; time used = 0.9942831993103027s
epoch 65: {'train_loss': '1.79221'}; time used = 0.9327981472015381s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.34913206100464.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.80220'}; time used = 2.8688368797302246s
epoch 10: {'train_loss': '2.76870'}; time used = 2.7693350315093994s
epoch 15: {'train_loss': '2.76086'}; time used = 2.060288906097412s
epoch 20: {'train_loss': '2.74912'}; time used = 1.716520071029663s
epoch 25: {'train_loss': '2.73605'}; time used = 1.936919927597046s
epoch 30: {'train_loss': '2.72590'}; time used = 1.74904465675354s
epoch 35: {'train_loss': '2.71952'}; time used = 1.7402949333190918s
epoch 40: {'train_loss': '2.71621'}; time used = 1.7816650867462158s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.58631467819214.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5793567374395627, 'samples': 0.5797101449275363, 'weighted': 0.5802402561594965, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 969.44 MiB free; 27.07 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '2.89612'}; time used = 2.2308061122894287s
epoch 10: {'train_loss': '2.82318'}; time used = 1.5582480430603027s
epoch 15: {'train_loss': '2.76793'}; time used = 1.6110424995422363s
epoch 20: {'train_loss': '2.77268'}; time used = 1.6064047813415527s
epoch 25: {'train_loss': '2.75496'}; time used = 1.6648037433624268s
epoch 30: {'train_loss': '2.75112'}; time used = 1.591780185699463s
epoch 35: {'train_loss': '2.74548'}; time used = 1.5915553569793701s
epoch 40: {'train_loss': '2.73779'}; time used = 1.5957882404327393s
epoch 45: {'train_loss': '2.72260'}; time used = 1.5932025909423828s
epoch 50: {'train_loss': '2.71672'}; time used = 1.648815393447876s
epoch 55: {'train_loss': '2.71525'}; time used = 1.581188678741455s
epoch 60: {'train_loss': '2.69979'}; time used = 1.5452592372894287s
epoch 65: {'train_loss': '2.68943'}; time used = 1.5946776866912842s
epoch 70: {'train_loss': '2.69455'}; time used = 1.6057567596435547s
epoch 75: {'train_loss': '2.67961'}; time used = 1.6043565273284912s
epoch 80: {'train_loss': '2.68685'}; time used = 1.6053872108459473s
epoch 85: {'train_loss': '2.68536'}; time used = 1.6309068202972412s
epoch 90: {'train_loss': '2.66982'}; time used = 1.6296815872192383s
epoch 95: {'train_loss': '2.67167'}; time used = 1.6138954162597656s
epoch 100: {'train_loss': '2.67065'}; time used = 1.6055598258972168s
epoch 105: {'train_loss': '2.66221'}; time used = 1.641026496887207s
epoch 110: {'train_loss': '2.66075'}; time used = 1.5516774654388428s
epoch 115: {'train_loss': '2.63977'}; time used = 1.6018767356872559s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 50.413724184036255.
Training classifier using 80.00% nodes...
{'micro': 0.4927536231884058, 'macro': 0.48187084316670237, 'samples': 0.4927536231884058, 'weighted': 0.48731223317755407, 'accuracy': 0.4927536231884058}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.35690'}; time used = 1.9599568843841553s
epoch 10: {'train_loss': '1.30284'}; time used = 1.9936087131500244s
epoch 15: {'train_loss': '1.23644'}; time used = 2.0083723068237305s
epoch 20: {'train_loss': '1.34980'}; time used = 1.865795612335205s
epoch 25: {'train_loss': '1.23967'}; time used = 1.8999173641204834s
epoch 30: {'train_loss': '1.11463'}; time used = 1.7903156280517578s
epoch 35: {'train_loss': '1.27112'}; time used = 1.8268377780914307s
epoch 40: {'train_loss': '1.11200'}; time used = 1.919128179550171s
epoch 45: {'train_loss': '1.28719'}; time used = 3.509127616882324s
epoch 50: {'train_loss': '1.12489'}; time used = 2.3804280757904053s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.512480974197388.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.5988372093023256, 'samples': 0.6231884057971014, 'weighted': 0.6059993259184361, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.02167'}; time used = 1.8716809749603271s
epoch 10: {'train_loss': '0.86883'}; time used = 1.752105951309204s
epoch 15: {'train_loss': '0.00164'}; time used = 1.720609188079834s
epoch 20: {'train_loss': '0.00113'}; time used = 1.695692777633667s
epoch 25: {'train_loss': '0.00099'}; time used = 1.7820160388946533s
epoch 30: {'train_loss': '0.00000'}; time used = 1.6967978477478027s
epoch 35: {'train_loss': '0.00000'}; time used = 1.7460436820983887s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.281489849090576.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5706929843381249, 'samples': 0.5797101449275363, 'weighted': 0.5752015646328306, 'accuracy': 0.5797101449275363}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '2.78011'}; time used = 8.278636693954468s
epoch 10: {'train_loss': '2.78242'}; time used = 7.812739372253418s
epoch 15: {'train_loss': '2.76809'}; time used = 8.597552061080933s
epoch 20: {'train_loss': '2.76115'}; time used = 10.608691215515137s
epoch 25: {'train_loss': '2.75182'}; time used = 7.533454895019531s
epoch 30: {'train_loss': '2.74094'}; time used = 7.702180862426758s
epoch 35: {'train_loss': '2.72421'}; time used = 7.662282466888428s
epoch 40: {'train_loss': '2.71257'}; time used = 8.342028856277466s
epoch 45: {'train_loss': '2.70620'}; time used = 7.902280807495117s
epoch 50: {'train_loss': '2.70325'}; time used = 6.804053544998169s
epoch 55: {'train_loss': '2.70239'}; time used = 7.245906829833984s
epoch 60: {'train_loss': '2.69959'}; time used = 7.755418062210083s
epoch 65: {'train_loss': '2.69782'}; time used = 7.640154838562012s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 129.01979088783264.
Training classifier using 80.00% nodes...
{'micro': 0.48333333333333334, 'macro': 0.4396391064228565, 'samples': 0.48333333333333334, 'weighted': 0.431823067558529, 'accuracy': 0.48333333333333334}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.57 GiB already allocated; 1.32 GiB free; 26.56 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.85316'}; time used = 1.5086297988891602s
epoch 10: {'train_loss': '2.77482'}; time used = 1.3790006637573242s
epoch 15: {'train_loss': '2.77401'}; time used = 1.6881983280181885s
epoch 20: {'train_loss': '2.77107'}; time used = 1.8292450904846191s
epoch 25: {'train_loss': '2.77311'}; time used = 1.3101208209991455s
epoch 30: {'train_loss': '2.77268'}; time used = 1.3269152641296387s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.120228052139282.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.5737179487179487, 'samples': 0.631578947368421, 'weighted': 0.5985155195681512, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.62 GiB already allocated; 1.28 GiB free; 15.77 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.34664'}; time used = 1.2670447826385498s
epoch 10: {'train_loss': '1.42391'}; time used = 1.0689055919647217s
epoch 15: {'train_loss': '0.39618'}; time used = 1.0414252281188965s
epoch 20: {'train_loss': '0.28107'}; time used = 0.9935228824615479s
epoch 25: {'train_loss': '0.03138'}; time used = 0.979562520980835s
epoch 30: {'train_loss': '0.07670'}; time used = 1.0861070156097412s
epoch 35: {'train_loss': '0.02824'}; time used = 1.1802117824554443s
epoch 40: {'train_loss': '0.81826'}; time used = 1.144239902496338s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.156481266021729.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8048422597212033, 'samples': 0.8157894736842105, 'weighted': 0.8121404023632082, 'accuracy': 0.8157894736842105}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '2.91092'}; time used = 1.8966104984283447s
epoch 10: {'train_loss': '2.78920'}; time used = 1.9572265148162842s
epoch 15: {'train_loss': '2.79855'}; time used = 1.7090177536010742s
epoch 20: {'train_loss': '2.78797'}; time used = 1.7052180767059326s
epoch 25: {'train_loss': '2.76779'}; time used = 1.8354871273040771s
epoch 30: {'train_loss': '2.75781'}; time used = 1.8100581169128418s
epoch 35: {'train_loss': '2.75293'}; time used = 1.782060146331787s
epoch 40: {'train_loss': '2.73960'}; time used = 1.84602689743042s
epoch 45: {'train_loss': '2.73014'}; time used = 2.192983627319336s
epoch 50: {'train_loss': '2.71982'}; time used = 1.9561772346496582s
epoch 55: {'train_loss': '2.71713'}; time used = 3.804959297180176s
epoch 60: {'train_loss': '2.70718'}; time used = 2.1675965785980225s
epoch 65: {'train_loss': '2.70377'}; time used = 1.8889105319976807s
epoch 70: {'train_loss': '2.71035'}; time used = 1.762601375579834s
epoch 75: {'train_loss': '2.69026'}; time used = 2.1433680057525635s
epoch 80: {'train_loss': '2.70051'}; time used = 1.9429614543914795s
epoch 85: {'train_loss': '2.70666'}; time used = 1.7622923851013184s
epoch 90: {'train_loss': '2.69025'}; time used = 1.802501916885376s
epoch 95: {'train_loss': '2.68679'}; time used = 1.7175490856170654s
epoch 100: {'train_loss': '2.69574'}; time used = 1.760697603225708s
epoch 105: {'train_loss': '2.68922'}; time used = 1.687941551208496s
epoch 110: {'train_loss': '2.68627'}; time used = 1.7688589096069336s
epoch 115: {'train_loss': '2.66943'}; time used = 2.040088653564453s
epoch 120: {'train_loss': '2.67662'}; time used = 1.7964847087860107s
epoch 125: {'train_loss': '2.67122'}; time used = 1.7326679229736328s
epoch 130: {'train_loss': '2.66772'}; time used = 1.7871971130371094s
epoch 135: {'train_loss': '2.67503'}; time used = 1.7263448238372803s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 57.160704374313354.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5606960950764007, 'samples': 0.5652173913043478, 'weighted': 0.5639255923820773, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.95 GiB already allocated; 973.44 MiB free; 19.50 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.09309'}; time used = 2.274786949157715s
epoch 10: {'train_loss': '2.84954'}; time used = 2.234564781188965s
epoch 15: {'train_loss': '2.77885'}; time used = 2.16481351852417s
epoch 20: {'train_loss': '2.78103'}; time used = 2.223834753036499s
epoch 25: {'train_loss': '2.78165'}; time used = 2.296816110610962s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 16.039281845092773.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5679785330948122, 'samples': 0.5942028985507246, 'weighted': 0.5756915817583158, 'accuracy': 0.5942028985507246}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.36160'}; time used = 1.7553176879882812s
epoch 10: {'train_loss': '1.27947'}; time used = 1.7593238353729248s
epoch 15: {'train_loss': '1.17939'}; time used = 1.7980144023895264s
epoch 20: {'train_loss': '1.14463'}; time used = 1.8403630256652832s
epoch 25: {'train_loss': '1.00863'}; time used = 1.8258039951324463s
epoch 30: {'train_loss': '0.70538'}; time used = 1.7498700618743896s
epoch 35: {'train_loss': '0.92007'}; time used = 1.7375414371490479s
epoch 40: {'train_loss': '0.73394'}; time used = 1.7654383182525635s
epoch 45: {'train_loss': '0.60875'}; time used = 1.740443229675293s
epoch 50: {'train_loss': '0.54452'}; time used = 1.8605759143829346s
epoch 55: {'train_loss': '0.37158'}; time used = 1.6711976528167725s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.415456771850586.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.5282051282051283, 'samples': 0.5362318840579711, 'weighted': 0.5326644370122631, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.44697'}; time used = 1.4602992534637451s
epoch 10: {'train_loss': '0.29863'}; time used = 1.2686169147491455s
epoch 15: {'train_loss': '0.16792'}; time used = 1.1236281394958496s
epoch 20: {'train_loss': '0.04388'}; time used = 1.1149623394012451s
epoch 25: {'train_loss': '0.04982'}; time used = 1.0889089107513428s
epoch 30: {'train_loss': '0.15906'}; time used = 1.1573598384857178s
epoch 35: {'train_loss': '0.13605'}; time used = 1.1680233478546143s
epoch 40: {'train_loss': '0.09594'}; time used = 1.0969915390014648s
epoch 45: {'train_loss': '0.18087'}; time used = 1.097033977508545s
epoch 50: {'train_loss': '0.14118'}; time used = 1.0759572982788086s
epoch 55: {'train_loss': '0.04786'}; time used = 1.0975542068481445s
epoch 60: {'train_loss': '0.06729'}; time used = 1.2060751914978027s
epoch 65: {'train_loss': '0.05379'}; time used = 1.0977540016174316s
epoch 70: {'train_loss': '0.02255'}; time used = 1.1113903522491455s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 20.269609689712524.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7414965986394557, 'samples': 0.7631578947368421, 'weighted': 0.7533118510562119, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.87 GiB already allocated; 1.03 GiB free; 19.45 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.16 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '0.51984'}; time used = 1.5175926685333252s
epoch 10: {'train_loss': '0.23069'}; time used = 1.326890230178833s
epoch 15: {'train_loss': '0.11155'}; time used = 1.285231351852417s
epoch 20: {'train_loss': '0.07026'}; time used = 1.2263009548187256s
epoch 25: {'train_loss': '0.20907'}; time used = 1.4049534797668457s
epoch 30: {'train_loss': '0.27845'}; time used = 1.151695966720581s
epoch 35: {'train_loss': '0.20067'}; time used = 1.0242266654968262s
epoch 40: {'train_loss': '0.07057'}; time used = 1.015564203262329s
epoch 45: {'train_loss': '0.03747'}; time used = 1.026116132736206s
epoch 50: {'train_loss': '0.01677'}; time used = 1.087928295135498s
epoch 55: {'train_loss': '0.01091'}; time used = 1.0529282093048096s
epoch 60: {'train_loss': '0.01071'}; time used = 1.1187365055084229s
epoch 65: {'train_loss': '0.01918'}; time used = 1.060861587524414s
epoch 70: {'train_loss': '0.01852'}; time used = 1.0383317470550537s
epoch 75: {'train_loss': '0.02683'}; time used = 1.0710773468017578s
epoch 80: {'train_loss': '0.00627'}; time used = 1.1718699932098389s
epoch 85: {'train_loss': '0.02909'}; time used = 1.0331737995147705s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.807972192764282.
Training classifier using 80.00% nodes...
{'micro': 0.6578947368421053, 'macro': 0.5947497949138638, 'samples': 0.6578947368421053, 'weighted': 0.6200077716851604, 'accuracy': 0.6578947368421053}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.94 GiB already allocated; 993.44 MiB free; 8.88 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.37449'}; time used = 1.2169463634490967s
epoch 10: {'train_loss': '0.22291'}; time used = 0.960796594619751s
epoch 15: {'train_loss': '0.16345'}; time used = 0.951256513595581s
epoch 20: {'train_loss': '0.15410'}; time used = 0.9398744106292725s
epoch 25: {'train_loss': '0.17146'}; time used = 1.081019401550293s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.214179277420044.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8303571428571428, 'samples': 0.8421052631578947, 'weighted': 0.8374060150375939, 'accuracy': 0.8421052631578947}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.16464'}; time used = 1.6824908256530762s
epoch 10: {'train_loss': '1.06972'}; time used = 1.7583215236663818s
epoch 15: {'train_loss': '0.95769'}; time used = 2.1488635540008545s
epoch 20: {'train_loss': '0.67046'}; time used = 2.7826406955718994s
epoch 25: {'train_loss': '0.44830'}; time used = 2.853344202041626s
epoch 30: {'train_loss': '0.29450'}; time used = 2.9146640300750732s
epoch 35: {'train_loss': '0.17286'}; time used = 1.571171522140503s
epoch 40: {'train_loss': '0.10402'}; time used = 1.6247899532318115s
epoch 45: {'train_loss': '0.07045'}; time used = 1.591806411743164s
epoch 50: {'train_loss': '0.05863'}; time used = 1.727630376815796s
epoch 55: {'train_loss': '0.09491'}; time used = 1.6326675415039062s
epoch 60: {'train_loss': '0.09939'}; time used = 1.7112138271331787s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.035609245300293.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.5095161660169686, 'samples': 0.5507246376811594, 'weighted': 0.5198182839330163, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.16494'}; time used = 2.0867600440979004s
epoch 10: {'train_loss': '0.80699'}; time used = 1.6594250202178955s
epoch 15: {'train_loss': '0.62734'}; time used = 1.0479624271392822s
epoch 20: {'train_loss': '0.57619'}; time used = 1.2567682266235352s
epoch 25: {'train_loss': '0.48933'}; time used = 1.2076892852783203s
epoch 30: {'train_loss': '0.41132'}; time used = 1.105520486831665s
epoch 35: {'train_loss': '0.36890'}; time used = 1.055917501449585s
epoch 40: {'train_loss': '0.33616'}; time used = 1.075592041015625s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.732290983200073.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6161616161616161, 'samples': 0.6842105263157895, 'weighted': 0.6416799574694312, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.37710'}; time used = 1.828629970550537s
epoch 10: {'train_loss': '1.27384'}; time used = 1.7993297576904297s
epoch 15: {'train_loss': '1.20750'}; time used = 1.756066083908081s
epoch 20: {'train_loss': '1.28374'}; time used = 1.721799612045288s
epoch 25: {'train_loss': '1.18489'}; time used = 1.8053197860717773s
epoch 30: {'train_loss': '0.75963'}; time used = 1.8230106830596924s
epoch 35: {'train_loss': '0.80812'}; time used = 1.7790875434875488s
epoch 40: {'train_loss': '0.83028'}; time used = 1.987403154373169s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 19.862048387527466.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.03335'}; time used = 1.8134949207305908s
epoch 10: {'train_loss': '0.98283'}; time used = 1.9594037532806396s
epoch 15: {'train_loss': '0.92309'}; time used = 1.9436454772949219s
epoch 20: {'train_loss': '0.40303'}; time used = 1.7220611572265625s
epoch 25: {'train_loss': '0.38354'}; time used = 2.0855069160461426s
epoch 30: {'train_loss': '0.20702'}; time used = 2.023507833480835s
epoch 35: {'train_loss': '0.25427'}; time used = 2.050044298171997s
epoch 40: {'train_loss': '0.73163'}; time used = 1.6684644222259521s
epoch 45: {'train_loss': '0.28824'}; time used = 1.8127496242523193s
epoch 50: {'train_loss': '0.22824'}; time used = 1.796370267868042s
epoch 55: {'train_loss': '0.72912'}; time used = 1.7275073528289795s
epoch 60: {'train_loss': '0.28007'}; time used = 1.6608514785766602s
epoch 65: {'train_loss': '0.26481'}; time used = 1.8994824886322021s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.49380612373352.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4719387755102041, 'samples': 0.5652173913043478, 'weighted': 0.4880212954747117, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.82722'}; time used = 1.9197347164154053s
epoch 10: {'train_loss': '2.80633'}; time used = 1.9571127891540527s
epoch 15: {'train_loss': '2.77292'}; time used = 1.8384039402008057s
epoch 20: {'train_loss': '2.77816'}; time used = 3.1372060775756836s
epoch 25: {'train_loss': '2.76182'}; time used = 3.306229591369629s
epoch 30: {'train_loss': '2.74023'}; time used = 3.056039810180664s
epoch 35: {'train_loss': '2.72075'}; time used = 2.153916597366333s
epoch 40: {'train_loss': '2.65556'}; time used = 1.9171407222747803s
epoch 45: {'train_loss': '2.60945'}; time used = 1.9058401584625244s
epoch 50: {'train_loss': '2.96715'}; time used = 1.9017541408538818s
epoch 55: {'train_loss': '2.65547'}; time used = 1.9819347858428955s
epoch 60: {'train_loss': '2.60284'}; time used = 1.905014991760254s
epoch 65: {'train_loss': '2.61049'}; time used = 1.9087600708007812s
epoch 70: {'train_loss': '2.57646'}; time used = 1.8995745182037354s
epoch 75: {'train_loss': '2.49736'}; time used = 1.9193270206451416s
epoch 80: {'train_loss': '2.49498'}; time used = 1.974461555480957s
epoch 85: {'train_loss': '2.47065'}; time used = 1.928576946258545s
epoch 90: {'train_loss': '2.49994'}; time used = 2.961304187774658s
epoch 95: {'train_loss': '2.46718'}; time used = 2.1975674629211426s
epoch 100: {'train_loss': '2.43208'}; time used = 1.9008386135101318s
epoch 105: {'train_loss': '2.44401'}; time used = 2.1578636169433594s
epoch 110: {'train_loss': '2.45231'}; time used = 1.9032094478607178s
epoch 115: {'train_loss': '2.41265'}; time used = 1.90744948387146s
epoch 120: {'train_loss': '2.42384'}; time used = 1.868778944015503s
epoch 125: {'train_loss': '2.42406'}; time used = 1.9060373306274414s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 57.10769867897034.
Training classifier using 80.00% nodes...
{'micro': 0.6231884057971014, 'macro': 0.6133620689655173, 'samples': 0.6231884057971014, 'weighted': 0.6178285857071465, 'accuracy': 0.6231884057971014}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.81 GiB already allocated; 1.09 GiB free; 19.47 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.36086'}; time used = 1.9684789180755615s
epoch 10: {'train_loss': '1.29498'}; time used = 1.7780334949493408s
epoch 15: {'train_loss': '1.29638'}; time used = 1.8455276489257812s
epoch 20: {'train_loss': '1.34745'}; time used = 3.575869560241699s
epoch 25: {'train_loss': '1.30072'}; time used = 3.5444791316986084s
epoch 30: {'train_loss': '1.23062'}; time used = 2.526129722595215s
epoch 35: {'train_loss': '1.21524'}; time used = 1.7621314525604248s
epoch 40: {'train_loss': '1.17443'}; time used = 1.6600525379180908s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.401933193206787.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5328820116054158, 'samples': 0.5942028985507246, 'weighted': 0.5451461889944776, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.86 GiB already allocated; 1.05 GiB free; 8.80 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32]
total iter: 500
epoch 5: {'train_loss': '1.35216'}; time used = 7.0677490234375s
epoch 10: {'train_loss': '1.31061'}; time used = 9.085007905960083s
epoch 15: {'train_loss': '1.07222'}; time used = 7.112391948699951s
epoch 20: {'train_loss': '0.70538'}; time used = 6.750389337539673s
epoch 25: {'train_loss': '0.52456'}; time used = 7.060415506362915s
epoch 30: {'train_loss': '0.48519'}; time used = 6.947111129760742s
epoch 35: {'train_loss': '0.21654'}; time used = 7.016306638717651s
epoch 40: {'train_loss': '0.16253'}; time used = 9.213717222213745s
epoch 45: {'train_loss': '0.74839'}; time used = 7.988248586654663s
epoch 50: {'train_loss': '0.35766'}; time used = 6.820998907089233s
epoch 55: {'train_loss': '0.24859'}; time used = 6.694133758544922s
epoch 60: {'train_loss': '0.13607'}; time used = 6.738990783691406s
epoch 65: {'train_loss': '0.25181'}; time used = 6.736696481704712s
epoch 70: {'train_loss': '0.18030'}; time used = 6.7839274406433105s
epoch 75: {'train_loss': '0.12722'}; time used = 6.738603591918945s
epoch 80: {'train_loss': '0.18658'}; time used = 6.581748723983765s
epoch 85: {'train_loss': '0.01917'}; time used = 6.621382713317871s
epoch 90: {'train_loss': '0.26505'}; time used = 6.752492666244507s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 147.08911442756653.
Training classifier using 80.00% nodes...
{'micro': 0.5066666666666667, 'macro': 0.4991362126245848, 'samples': 0.5066666666666667, 'weighted': 0.4954764119601329, 'accuracy': 0.5066666666666667}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 7.29 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.62580'}; time used = 1.2410805225372314s
epoch 10: {'train_loss': '2.44501'}; time used = 1.128509521484375s
epoch 15: {'train_loss': '2.34887'}; time used = 1.0898120403289795s
epoch 20: {'train_loss': '2.28786'}; time used = 0.9470031261444092s
epoch 25: {'train_loss': '2.11246'}; time used = 0.9267010688781738s
epoch 30: {'train_loss': '2.00634'}; time used = 0.9355342388153076s
epoch 35: {'train_loss': '1.88121'}; time used = 1.216245412826538s
epoch 40: {'train_loss': '1.79118'}; time used = 0.9525468349456787s
epoch 45: {'train_loss': '1.69188'}; time used = 0.9616208076477051s
epoch 50: {'train_loss': '1.65815'}; time used = 0.9360828399658203s
epoch 55: {'train_loss': '1.57348'}; time used = 0.9359602928161621s
epoch 60: {'train_loss': '1.54828'}; time used = 0.9947848320007324s
epoch 65: {'train_loss': '1.50768'}; time used = 0.9688477516174316s
epoch 70: {'train_loss': '1.51799'}; time used = 0.9575564861297607s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 17.628147840499878.
Training classifier using 80.00% nodes...
{'micro': 0.7631578947368421, 'macro': 0.7414965986394557, 'samples': 0.7631578947368421, 'weighted': 0.7533118510562119, 'accuracy': 0.7631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.76806'}; time used = 1.056058645248413s
epoch 10: {'train_loss': '2.49435'}; time used = 1.0372488498687744s
epoch 15: {'train_loss': '1.90971'}; time used = 0.9852542877197266s
epoch 20: {'train_loss': '1.78958'}; time used = 0.9437716007232666s
epoch 25: {'train_loss': '1.66222'}; time used = 0.947943925857544s
epoch 30: {'train_loss': '1.59251'}; time used = 0.9475319385528564s
epoch 35: {'train_loss': '1.48152'}; time used = 0.9384899139404297s
epoch 40: {'train_loss': '1.45903'}; time used = 0.9233148097991943s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.038220882415771.
Training classifier using 80.00% nodes...
{'micro': 0.8157894736842104, 'macro': 0.8093189964157707, 'samples': 0.8157894736842105, 'weighted': 0.8148651197887191, 'accuracy': 0.8157894736842105}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.20243'}; time used = 1.7255446910858154s
epoch 10: {'train_loss': '1.15372'}; time used = 1.7569606304168701s
epoch 15: {'train_loss': '1.14734'}; time used = 1.6327311992645264s
epoch 20: {'train_loss': '1.13403'}; time used = 1.7152249813079834s
epoch 25: {'train_loss': '1.02058'}; time used = 3.271923303604126s
epoch 30: {'train_loss': '0.70238'}; time used = 2.9160685539245605s
epoch 35: {'train_loss': '0.47367'}; time used = 3.0084683895111084s
epoch 40: {'train_loss': '0.52081'}; time used = 1.7349779605865479s
epoch 45: {'train_loss': '0.30528'}; time used = 1.734313726425171s
epoch 50: {'train_loss': '0.31959'}; time used = 1.7626724243164062s
epoch 55: {'train_loss': '0.12496'}; time used = 1.837954044342041s
epoch 60: {'train_loss': '0.18056'}; time used = 1.7373547554016113s
epoch 65: {'train_loss': '0.01122'}; time used = 1.7064650058746338s
epoch 70: {'train_loss': '0.09676'}; time used = 1.6470777988433838s
epoch 75: {'train_loss': '0.00572'}; time used = 1.6413941383361816s
epoch 80: {'train_loss': '0.00496'}; time used = 1.6989266872406006s
epoch 85: {'train_loss': '0.00452'}; time used = 1.6598165035247803s
epoch 90: {'train_loss': '0.08871'}; time used = 1.6501805782318115s
epoch 95: {'train_loss': '0.15397'}; time used = 1.6626474857330322s
epoch 100: {'train_loss': '0.04636'}; time used = 1.7819843292236328s
epoch 105: {'train_loss': '0.03044'}; time used = 1.7035441398620605s
epoch 110: {'train_loss': '0.01917'}; time used = 1.6206095218658447s
epoch 115: {'train_loss': '0.02009'}; time used = 1.6484849452972412s
epoch 120: {'train_loss': '0.00994'}; time used = 1.6707499027252197s
epoch 125: {'train_loss': '0.81280'}; time used = 1.6626553535461426s
epoch 130: {'train_loss': '0.00542'}; time used = 1.656017541885376s
epoch 135: {'train_loss': '0.00466'}; time used = 1.7509045600891113s
epoch 140: {'train_loss': '0.00398'}; time used = 1.6348192691802979s
epoch 145: {'train_loss': '0.00357'}; time used = 1.6574227809906006s
epoch 150: {'train_loss': '0.00307'}; time used = 1.7004683017730713s
epoch 155: {'train_loss': '0.00288'}; time used = 1.659688949584961s
epoch 160: {'train_loss': '0.00261'}; time used = 1.7102293968200684s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 62.72858142852783.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5411602843384544, 'samples': 0.5797101449275363, 'weighted': 0.550797749485725, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.98 GiB already allocated; 927.44 MiB free; 26.46 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.91 GiB already allocated; 1005.44 MiB free; 28.86 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.21956'}; time used = 3.1301612854003906s
epoch 10: {'train_loss': '0.84522'}; time used = 2.0816431045532227s
epoch 15: {'train_loss': '0.14057'}; time used = 2.0409295558929443s
epoch 20: {'train_loss': '0.10538'}; time used = 1.9770293235778809s
epoch 25: {'train_loss': '0.00160'}; time used = 2.207190752029419s
epoch 30: {'train_loss': '0.00054'}; time used = 2.1014833450317383s
epoch 35: {'train_loss': '0.36247'}; time used = 2.139425039291382s
epoch 40: {'train_loss': '0.19174'}; time used = 1.8668668270111084s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 22.534578323364258.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.83887'}; time used = 1.0967521667480469s
epoch 10: {'train_loss': '2.78095'}; time used = 0.9810464382171631s
epoch 15: {'train_loss': '2.77338'}; time used = 0.9797475337982178s
epoch 20: {'train_loss': '2.77995'}; time used = 1.017394781112671s
epoch 25: {'train_loss': '2.77583'}; time used = 0.9769320487976074s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 8.509078741073608.
Training classifier using 80.00% nodes...
{'micro': 0.631578947368421, 'macro': 0.525, 'samples': 0.631578947368421, 'weighted': 0.5605263157894737, 'accuracy': 0.631578947368421}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.19 GiB free; 24.69 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.92 GiB already allocated; 1013.44 MiB free; 9.21 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.80722'}; time used = 1.920485258102417s
epoch 10: {'train_loss': '2.77809'}; time used = 1.8655993938446045s
epoch 15: {'train_loss': '2.77193'}; time used = 1.7664761543273926s
epoch 20: {'train_loss': '2.76537'}; time used = 1.8420586585998535s
epoch 25: {'train_loss': '2.76017'}; time used = 2.3082492351531982s
epoch 30: {'train_loss': '2.75837'}; time used = 2.1220688819885254s
epoch 35: {'train_loss': '2.75806'}; time used = 2.2847702503204346s
epoch 40: {'train_loss': '2.76032'}; time used = 2.053039073944092s
epoch 45: {'train_loss': '2.75733'}; time used = 1.8627750873565674s
epoch 50: {'train_loss': '2.75380'}; time used = 1.7965669631958008s
epoch 55: {'train_loss': '2.76148'}; time used = 1.7385926246643066s
epoch 60: {'train_loss': '2.75348'}; time used = 1.6801421642303467s
epoch 65: {'train_loss': '2.74065'}; time used = 1.789957046508789s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 30.739463090896606.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.47826086956521735, 'samples': 0.5362318840579711, 'weighted': 0.4908632640201637, 'accuracy': 0.5362318840579711}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.76 GiB already allocated; 1.15 GiB free; 9.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.52 GiB already allocated; 1.38 GiB free; 14.08 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.96 GiB already allocated; 945.44 MiB free; 28.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.70079'}; time used = 1.283531665802002s
epoch 10: {'train_loss': '2.63747'}; time used = 1.207277774810791s
epoch 15: {'train_loss': '2.58828'}; time used = 1.2295610904693604s
epoch 20: {'train_loss': '2.51112'}; time used = 1.3185029029846191s
epoch 25: {'train_loss': '2.44205'}; time used = 1.427337408065796s
epoch 30: {'train_loss': '2.36548'}; time used = 1.1467082500457764s
epoch 35: {'train_loss': '2.32188'}; time used = 1.157006025314331s
epoch 40: {'train_loss': '2.28037'}; time used = 1.1270949840545654s
epoch 45: {'train_loss': '2.24325'}; time used = 1.1903877258300781s
epoch 50: {'train_loss': '2.21782'}; time used = 1.078500747680664s
epoch 55: {'train_loss': '2.19843'}; time used = 0.9822993278503418s
epoch 60: {'train_loss': '2.15783'}; time used = 1.3159875869750977s
epoch 65: {'train_loss': '2.13337'}; time used = 1.112088680267334s
epoch 70: {'train_loss': '2.15147'}; time used = 1.271286964416504s
epoch 75: {'train_loss': '2.11353'}; time used = 1.159654140472412s
epoch 80: {'train_loss': '2.12686'}; time used = 1.1612675189971924s
epoch 85: {'train_loss': '2.13324'}; time used = 1.1027836799621582s
epoch 90: {'train_loss': '2.09320'}; time used = 1.1190545558929443s
epoch 95: {'train_loss': '2.05682'}; time used = 1.1347548961639404s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 25.85214328765869.
Training classifier using 80.00% nodes...
{'micro': 0.6842105263157895, 'macro': 0.6161616161616161, 'samples': 0.6842105263157895, 'weighted': 0.6416799574694312, 'accuracy': 0.6842105263157895}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32]
total iter: 500
epoch 5: {'train_loss': '1.27717'}; time used = 1.7237639427185059s
epoch 10: {'train_loss': '1.18337'}; time used = 1.6859979629516602s
epoch 15: {'train_loss': '0.98781'}; time used = 1.7021739482879639s
epoch 20: {'train_loss': '0.84072'}; time used = 1.702878713607788s
epoch 25: {'train_loss': '0.77284'}; time used = 1.7652170658111572s
epoch 30: {'train_loss': '0.72078'}; time used = 1.6947720050811768s
epoch 35: {'train_loss': '0.78832'}; time used = 1.6919903755187988s
epoch 40: {'train_loss': '0.63504'}; time used = 1.6939654350280762s
epoch 45: {'train_loss': '0.64450'}; time used = 1.6876897811889648s
epoch 50: {'train_loss': '0.60668'}; time used = 1.6931512355804443s
epoch 55: {'train_loss': '0.64694'}; time used = 1.7928335666656494s
epoch 60: {'train_loss': '0.57898'}; time used = 1.7057547569274902s
epoch 65: {'train_loss': '0.55716'}; time used = 2.3744447231292725s
epoch 70: {'train_loss': '0.49127'}; time used = 2.726372718811035s
epoch 75: {'train_loss': '0.54842'}; time used = 1.7174201011657715s
epoch 80: {'train_loss': '0.49371'}; time used = 1.7565069198608398s
epoch 85: {'train_loss': '0.46192'}; time used = 2.45994234085083s
epoch 90: {'train_loss': '0.55016'}; time used = 1.6962640285491943s
epoch 95: {'train_loss': '0.58105'}; time used = 1.679903507232666s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 37.90203642845154.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.5371198568872988, 'samples': 0.5652173913043478, 'weighted': 0.5453838375981955, 'accuracy': 0.5652173913043478}
/data2/private/hsd/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.87633'}; time used = 2.42787504196167s
epoch 10: {'train_loss': '2.79824'}; time used = 3.038480520248413s
epoch 15: {'train_loss': '2.78754'}; time used = 2.486954927444458s
epoch 20: {'train_loss': '2.77772'}; time used = 2.5131008625030518s
epoch 25: {'train_loss': '2.76955'}; time used = 2.850224256515503s
epoch 30: {'train_loss': '2.75599'}; time used = 2.4493658542633057s
epoch 35: {'train_loss': '2.73796'}; time used = 2.4068307876586914s
epoch 40: {'train_loss': '2.72071'}; time used = 2.2949395179748535s
epoch 45: {'train_loss': '2.68439'}; time used = 2.308687448501587s
epoch 50: {'train_loss': '2.63660'}; time used = 2.3009791374206543s
epoch 55: {'train_loss': '2.60096'}; time used = 2.3884427547454834s
epoch 60: {'train_loss': '2.57744'}; time used = 2.2892985343933105s
epoch 65: {'train_loss': '2.50504'}; time used = 2.307072401046753s
epoch 70: {'train_loss': '2.47451'}; time used = 2.2888526916503906s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 39.268250465393066.
Training classifier using 80.00% nodes...
{'micro': 0.5362318840579711, 'macro': 0.3490566037735849, 'samples': 0.5362318840579711, 'weighted': 0.3743505605687722, 'accuracy': 0.5362318840579711}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.79135'}; time used = 2.2860512733459473s
epoch 10: {'train_loss': '2.77129'}; time used = 2.1975677013397217s
epoch 15: {'train_loss': '2.76856'}; time used = 2.2313337326049805s
epoch 20: {'train_loss': '2.76222'}; time used = 2.2456183433532715s
epoch 25: {'train_loss': '2.75809'}; time used = 3.368058681488037s
epoch 30: {'train_loss': '2.75456'}; time used = 1.6794326305389404s
epoch 35: {'train_loss': '2.74440'}; time used = 1.8167083263397217s
epoch 40: {'train_loss': '2.74455'}; time used = 1.6492054462432861s
epoch 45: {'train_loss': '2.72468'}; time used = 1.8208425045013428s
epoch 50: {'train_loss': '2.69889'}; time used = 1.862790822982788s
epoch 55: {'train_loss': '2.67587'}; time used = 3.128804922103882s
epoch 60: {'train_loss': '2.63799'}; time used = 3.623328924179077s
epoch 65: {'train_loss': '2.63879'}; time used = 3.4484288692474365s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 36.34258460998535.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5765079365079364, 'samples': 0.5797101449275363, 'weighted': 0.5791764435242696, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.33882'}; time used = 2.0503134727478027s
epoch 10: {'train_loss': '1.15506'}; time used = 2.021751880645752s
epoch 15: {'train_loss': '1.00274'}; time used = 2.0572669506073s
epoch 20: {'train_loss': '0.80320'}; time used = 2.134801149368286s
epoch 25: {'train_loss': '0.76712'}; time used = 2.0940587520599365s
epoch 30: {'train_loss': '0.51661'}; time used = 2.184692621231079s
epoch 35: {'train_loss': '0.61394'}; time used = 2.663132905960083s
epoch 40: {'train_loss': '0.53544'}; time used = 2.250296115875244s
epoch 45: {'train_loss': '0.34443'}; time used = 2.23349666595459s
epoch 50: {'train_loss': '0.28452'}; time used = 2.1677815914154053s
epoch 55: {'train_loss': '0.20821'}; time used = 2.2916486263275146s
epoch 60: {'train_loss': '0.02250'}; time used = 2.616049289703369s
epoch 65: {'train_loss': '1.01109'}; time used = 2.2586445808410645s
epoch 70: {'train_loss': '0.81308'}; time used = 2.11238694190979s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 35.64562797546387.
Training classifier using 80.00% nodes...
{'micro': 0.7101449275362319, 'macro': 0.6994773519163764, 'samples': 0.7101449275362319, 'weighted': 0.7035802656163208, 'accuracy': 0.7101449275362319}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.19285'}; time used = 1.0350613594055176s
epoch 10: {'train_loss': '0.84649'}; time used = 0.9310061931610107s
epoch 15: {'train_loss': '0.67418'}; time used = 0.9271018505096436s
epoch 20: {'train_loss': '0.56706'}; time used = 0.913907527923584s
epoch 25: {'train_loss': '0.49009'}; time used = 1.0254039764404297s
epoch 30: {'train_loss': '0.35345'}; time used = 0.9720618724822998s
epoch 35: {'train_loss': '0.32647'}; time used = 1.10239839553833s
epoch 40: {'train_loss': '0.33299'}; time used = 1.122523546218872s
epoch 45: {'train_loss': '0.27156'}; time used = 0.96647047996521s
epoch 50: {'train_loss': '0.28564'}; time used = 1.6718864440917969s
epoch 55: {'train_loss': '0.27093'}; time used = 0.9490499496459961s
epoch 60: {'train_loss': '0.21144'}; time used = 1.0494341850280762s
epoch 65: {'train_loss': '0.22270'}; time used = 0.9594261646270752s
epoch 70: {'train_loss': '0.20588'}; time used = 0.9770619869232178s
epoch 75: {'train_loss': '0.24618'}; time used = 0.9598290920257568s
epoch 80: {'train_loss': '0.21618'}; time used = 0.9493300914764404s
epoch 85: {'train_loss': '0.22021'}; time used = 0.9528837203979492s
epoch 90: {'train_loss': '0.20973'}; time used = 0.9252500534057617s
epoch 95: {'train_loss': '0.28098'}; time used = 0.902747392654419s
epoch 100: {'train_loss': '0.23545'}; time used = 0.9455711841583252s
epoch 105: {'train_loss': '0.22068'}; time used = 1.007317304611206s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 24.224740743637085.
Training classifier using 80.00% nodes...
{'micro': 0.7368421052631579, 'macro': 0.6801346801346801, 'samples': 0.7368421052631579, 'weighted': 0.7013999645578592, 'accuracy': 0.7368421052631579}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.70 GiB already allocated; 1.19 GiB free; 24.67 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 9.00 GiB already allocated; 909.44 MiB free; 27.05 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.37694'}; time used = 2.0251996517181396s
epoch 10: {'train_loss': '1.30536'}; time used = 2.380803108215332s
epoch 15: {'train_loss': '1.20015'}; time used = 2.4830431938171387s
epoch 20: {'train_loss': '1.15275'}; time used = 2.394829034805298s
epoch 25: {'train_loss': '0.89128'}; time used = 1.6286323070526123s
epoch 30: {'train_loss': '1.06963'}; time used = 1.0184893608093262s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 15.229105472564697.
Training classifier using 80.00% nodes...
{'micro': 0.8421052631578947, 'macro': 0.8380681818181819, 'samples': 0.8421052631578947, 'weighted': 0.8421052631578947, 'accuracy': 0.8421052631578947}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.21506'}; time used = 1.566706895828247s
epoch 10: {'train_loss': '0.84309'}; time used = 1.5509793758392334s
epoch 15: {'train_loss': '0.43707'}; time used = 1.5629804134368896s
epoch 20: {'train_loss': '0.20803'}; time used = 1.5452778339385986s
epoch 25: {'train_loss': '0.13390'}; time used = 1.7556653022766113s
epoch 30: {'train_loss': '0.32957'}; time used = 1.600867748260498s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 12.598017930984497.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5321487023614684, 'samples': 0.5797101449275363, 'weighted': 0.5429581211264838, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.86749'}; time used = 1.1421854496002197s
epoch 10: {'train_loss': '2.80523'}; time used = 1.0371477603912354s
epoch 15: {'train_loss': '2.77686'}; time used = 1.0357472896575928s
epoch 20: {'train_loss': '2.77433'}; time used = 1.0421316623687744s
epoch 25: {'train_loss': '2.77947'}; time used = 1.0620677471160889s
epoch 30: {'train_loss': '2.77672'}; time used = 1.0220727920532227s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 10.014750242233276.
Training classifier using 80.00% nodes...
{'micro': 0.8947368421052632, 'macro': 0.889855072463768, 'samples': 0.8947368421052632, 'weighted': 0.8935163996948893, 'accuracy': 0.8947368421052632}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32]
total iter: 500
epoch 5: {'train_loss': '0.65739'}; time used = 1.351276159286499s
epoch 10: {'train_loss': '0.22678'}; time used = 1.0739896297454834s
epoch 15: {'train_loss': '0.08220'}; time used = 1.0949187278747559s
epoch 20: {'train_loss': '0.00603'}; time used = 1.0979125499725342s
epoch 25: {'train_loss': '0.00035'}; time used = 1.1221261024475098s
epoch 30: {'train_loss': '0.02178'}; time used = 1.0760669708251953s
epoch 35: {'train_loss': '0.05334'}; time used = 1.095046043395996s
epoch 40: {'train_loss': '0.02230'}; time used = 1.0850262641906738s
epoch 45: {'train_loss': '0.00858'}; time used = 1.1806306838989258s
epoch 50: {'train_loss': '0.00554'}; time used = 1.1417138576507568s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 14.6463143825531.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.638095238095238, 'samples': 0.7105263157894737, 'weighted': 0.6636591478696743, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '1.39237'}; time used = 1.1357085704803467s
epoch 10: {'train_loss': '1.35231'}; time used = 1.0557844638824463s
epoch 15: {'train_loss': '1.19755'}; time used = 1.0289306640625s
epoch 20: {'train_loss': '1.01299'}; time used = 0.9883191585540771s
epoch 25: {'train_loss': '0.85020'}; time used = 0.9843018054962158s
epoch 30: {'train_loss': '0.68686'}; time used = 1.0695390701293945s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 11.171203374862671.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.62 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.34853'}; time used = 1.8750693798065186s
epoch 10: {'train_loss': '1.28538'}; time used = 1.7844505310058594s
epoch 15: {'train_loss': '1.27638'}; time used = 1.820016860961914s
epoch 20: {'train_loss': '1.36087'}; time used = 1.8853328227996826s
epoch 25: {'train_loss': '1.30529'}; time used = 1.849888563156128s
epoch 30: {'train_loss': '1.22818'}; time used = 1.7780489921569824s
epoch 35: {'train_loss': '1.18620'}; time used = 1.7858340740203857s
epoch 40: {'train_loss': '1.15465'}; time used = 1.772592544555664s
epoch 45: {'train_loss': '1.17411'}; time used = 1.773848533630371s
epoch 50: {'train_loss': '1.07931'}; time used = 1.811089277267456s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 23.91595959663391.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.4645437516724646, 'samples': 0.5797101449275363, 'weighted': 0.4825385006185695, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.78 GiB already allocated; 1.13 GiB free; 7.81 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.15526'}; time used = 1.4736831188201904s
epoch 10: {'train_loss': '0.81061'}; time used = 1.259453535079956s
epoch 15: {'train_loss': '0.63031'}; time used = 1.2634072303771973s
epoch 20: {'train_loss': '0.61123'}; time used = 1.2509334087371826s
epoch 25: {'train_loss': '0.45902'}; time used = 1.2451035976409912s
epoch 30: {'train_loss': '0.31248'}; time used = 1.2469944953918457s
epoch 35: {'train_loss': '0.25182'}; time used = 1.2617127895355225s
epoch 40: {'train_loss': '0.18926'}; time used = 1.2639782428741455s
epoch 45: {'train_loss': '0.26940'}; time used = 1.3251795768737793s
epoch 50: {'train_loss': '0.29943'}; time used = 1.3112525939941406s
epoch 55: {'train_loss': '0.22436'}; time used = 1.346398115158081s
epoch 60: {'train_loss': '0.16177'}; time used = 1.466456413269043s
epoch 65: {'train_loss': '0.20081'}; time used = 1.3991222381591797s
epoch 70: {'train_loss': '0.13730'}; time used = 1.411247730255127s
epoch 75: {'train_loss': '0.13477'}; time used = 1.3990356922149658s
epoch 80: {'train_loss': '0.12200'}; time used = 1.388289451599121s
epoch 85: {'train_loss': '0.08882'}; time used = 1.3978362083435059s
epoch 90: {'train_loss': '0.11326'}; time used = 1.390345573425293s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 27.940038442611694.
Training classifier using 80.00% nodes...
{'micro': 0.7105263157894737, 'macro': 0.6570959803117309, 'samples': 0.7105263157894737, 'weighted': 0.6784681145028281, 'accuracy': 0.7105263157894737}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64]
total iter: 500
epoch 5: {'train_loss': '1.30710'}; time used = 1.8409380912780762s
epoch 10: {'train_loss': '1.17157'}; time used = 1.8295519351959229s
epoch 15: {'train_loss': '1.08234'}; time used = 1.7569711208343506s
epoch 20: {'train_loss': '1.13119'}; time used = 2.0674915313720703s
epoch 25: {'train_loss': '1.02530'}; time used = 2.1135902404785156s
epoch 30: {'train_loss': '0.87370'}; time used = 1.785006046295166s
epoch 35: {'train_loss': '0.88888'}; time used = 1.79069185256958s
epoch 40: {'train_loss': '0.79794'}; time used = 1.7716319561004639s
epoch 45: {'train_loss': '0.78906'}; time used = 1.8301575183868408s
epoch 50: {'train_loss': '0.97411'}; time used = 1.8331289291381836s
epoch 55: {'train_loss': '0.16540'}; time used = 1.7466850280761719s
epoch 60: {'train_loss': '0.28058'}; time used = 1.7421863079071045s
epoch 65: {'train_loss': '0.10337'}; time used = 1.7855618000030518s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 29.30283784866333.
Training classifier using 80.00% nodes...
{'micro': 0.5942028985507246, 'macro': 0.5899830220713073, 'samples': 0.5942028985507246, 'weighted': 0.5929972195566053, 'accuracy': 0.5942028985507246}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.46 GiB (GPU 6; 10.76 GiB total capacity; 8.83 GiB already allocated; 1.07 GiB free; 19.15 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.75 GiB already allocated; 1.14 GiB free; 34.63 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32]
total iter: 500
epoch 5: {'train_loss': '1.25092'}; time used = 1.90687894821167s
epoch 10: {'train_loss': '1.13343'}; time used = 1.8869564533233643s
epoch 15: {'train_loss': '1.07350'}; time used = 1.7929978370666504s
epoch 20: {'train_loss': '0.98287'}; time used = 1.6734576225280762s
epoch 25: {'train_loss': '0.85130'}; time used = 1.7187678813934326s
epoch 30: {'train_loss': '0.70541'}; time used = 1.66115403175354s
epoch 35: {'train_loss': '0.42553'}; time used = 1.6526134014129639s
epoch 40: {'train_loss': '0.23226'}; time used = 1.6439845561981201s
epoch 45: {'train_loss': '0.16946'}; time used = 1.7589936256408691s
epoch 50: {'train_loss': '0.09561'}; time used = 1.6486148834228516s
epoch 55: {'train_loss': '0.12281'}; time used = 1.6949164867401123s
epoch 60: {'train_loss': '0.08862'}; time used = 1.647792100906372s
epoch 65: {'train_loss': '0.06826'}; time used = 1.6481633186340332s
epoch 70: {'train_loss': '0.08598'}; time used = 1.6243479251861572s
epoch 75: {'train_loss': '0.05891'}; time used = 1.6620943546295166s
epoch 80: {'train_loss': '0.11089'}; time used = 1.7171823978424072s
epoch 85: {'train_loss': '0.01545'}; time used = 1.6293447017669678s
epoch 90: {'train_loss': '0.01426'}; time used = 1.6331548690795898s
epoch 95: {'train_loss': '0.04279'}; time used = 1.7414557933807373s
epoch 100: {'train_loss': '0.04283'}; time used = 1.689039945602417s
epoch 105: {'train_loss': '0.04806'}; time used = 1.8683278560638428s
epoch 110: {'train_loss': '0.00881'}; time used = 1.6751773357391357s
epoch 115: {'train_loss': '0.00461'}; time used = 1.6407039165496826s
epoch 120: {'train_loss': '0.01198'}; time used = 1.676252841949463s
epoch 125: {'train_loss': '0.00647'}; time used = 1.6550447940826416s
epoch 130: {'train_loss': '0.00382'}; time used = 1.6773099899291992s
epoch 135: {'train_loss': '0.00853'}; time used = 1.7650532722473145s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 50.25567936897278.
Training classifier using 80.00% nodes...
{'micro': 0.5797101449275363, 'macro': 0.5490196078431372, 'samples': 0.5797101449275363, 'weighted': 0.557544757033248, 'accuracy': 0.5797101449275363}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 23.13 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 32, 32, 32]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '1.01993'}; time used = 2.354140520095825s
epoch 10: {'train_loss': '0.60238'}; time used = 2.286299467086792s
epoch 15: {'train_loss': '0.30277'}; time used = 2.2854299545288086s
epoch 20: {'train_loss': '0.07583'}; time used = 2.2988274097442627s
epoch 25: {'train_loss': '0.00088'}; time used = 2.3571531772613525s
epoch 30: {'train_loss': '0.06293'}; time used = 2.2791428565979004s
epoch 35: {'train_loss': '0.00929'}; time used = 2.246333599090576s
epoch 40: {'train_loss': '0.03483'}; time used = 2.234260320663452s
epoch 45: {'train_loss': '1.01819'}; time used = 2.2304322719573975s
epoch 50: {'train_loss': '0.19948'}; time used = 2.226940870285034s
epoch 55: {'train_loss': '0.07705'}; time used = 2.296367883682251s
epoch 60: {'train_loss': '0.05738'}; time used = 2.2362592220306396s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 31.270946502685547.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4866071428571428, 'samples': 0.5652173913043478, 'weighted': 0.5011645962732919, 'accuracy': 0.5652173913043478}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-BINARY(1000)
Loading IMDB_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
epoch 5: {'train_loss': '2.84974'}; time used = 4.810102939605713s
epoch 10: {'train_loss': '2.77725'}; time used = 4.725227117538452s
epoch 15: {'train_loss': '2.77803'}; time used = 4.942438840866089s
epoch 20: {'train_loss': '2.78451'}; time used = 4.6818177700042725s
epoch 25: {'train_loss': '2.77240'}; time used = 4.781293153762817s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 41.81269979476929.
Training classifier using 80.00% nodes...
{'micro': 0.72, 'macro': 0.71997199719972, 'samples': 0.72, 'weighted': 0.72002800280028, 'accuracy': 0.72}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 168, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.67 GiB already allocated; 1.21 GiB free; 35.30 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 32]
total iter: 500
epoch 5: {'train_loss': '2.70499'}; time used = 1.053816795349121s
epoch 10: {'train_loss': '2.64397'}; time used = 0.9001617431640625s
epoch 15: {'train_loss': '2.59784'}; time used = 0.915062427520752s
epoch 20: {'train_loss': '2.53503'}; time used = 0.9070749282836914s
epoch 25: {'train_loss': '2.45905'}; time used = 0.9001760482788086s
epoch 30: {'train_loss': '2.37269'}; time used = 0.8975276947021484s
epoch 35: {'train_loss': '2.32201'}; time used = 0.8881168365478516s
epoch 40: {'train_loss': '2.27800'}; time used = 0.8751146793365479s
epoch 45: {'train_loss': '2.23662'}; time used = 0.8810825347900391s
epoch 50: {'train_loss': '2.21514'}; time used = 0.8966598510742188s
epoch 55: {'train_loss': '2.20146'}; time used = 0.879399299621582s
epoch 60: {'train_loss': '2.16377'}; time used = 0.9547691345214844s
epoch 65: {'train_loss': '2.13972'}; time used = 0.8982455730438232s
epoch 70: {'train_loss': '2.17111'}; time used = 0.8553018569946289s
epoch 75: {'train_loss': '2.15979'}; time used = 0.8592848777770996s
epoch 80: {'train_loss': '2.13527'}; time used = 0.8774964809417725s
epoch 85: {'train_loss': '2.12093'}; time used = 0.8715384006500244s
epoch 90: {'train_loss': '2.07294'}; time used = 0.879988431930542s
epoch 95: {'train_loss': '2.02795'}; time used = 0.8786907196044922s
epoch 100: {'train_loss': '2.02167'}; time used = 0.9208016395568848s
epoch 105: {'train_loss': '2.03444'}; time used = 0.9585607051849365s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.821346521377563.
Training classifier using 80.00% nodes...
{'micro': 0.7894736842105263, 'macro': 0.7738095238095237, 'samples': 0.7894736842105263, 'weighted': 0.7832080200501252, 'accuracy': 0.7894736842105263}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 37, in forward
    hx = self.embed(x)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 49, in forward
    hx = layer([hx, adj])
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/layers.py", line 48, in __call__
    outputs = super(Layer, self).__call__(inputs, **kwargs)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/layers/graph_attentionc.py", line 103, in forward
    c = torch.nn.functional.softmax(torch.nn.functional.leaky_relu(c, 0.2), dim=0)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/functional.py", line 1231, in softmax
    ret = input.softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.53 GiB already allocated; 1.36 GiB free; 20.85 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'inner', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.16617'}; time used = 1.7603425979614258s
epoch 10: {'train_loss': '2.86024'}; time used = 1.7394733428955078s
epoch 15: {'train_loss': '2.76315'}; time used = 1.7185914516448975s
epoch 20: {'train_loss': '2.75990'}; time used = 1.766730785369873s
epoch 25: {'train_loss': '2.73527'}; time used = 1.7897562980651855s
epoch 30: {'train_loss': '2.68223'}; time used = 1.8016924858093262s
epoch 35: {'train_loss': '2.62458'}; time used = 1.7062795162200928s
epoch 40: {'train_loss': '2.57439'}; time used = 1.7146005630493164s
epoch 45: {'train_loss': '2.52231'}; time used = 1.8432865142822266s
epoch 50: {'train_loss': '2.43258'}; time used = 1.6735222339630127s
epoch 55: {'train_loss': '2.38005'}; time used = 1.7421581745147705s
epoch 60: {'train_loss': '2.31861'}; time used = 1.6563537120819092s
epoch 65: {'train_loss': '2.20207'}; time used = 1.6681323051452637s
epoch 70: {'train_loss': '2.24918'}; time used = 1.6860826015472412s
epoch 75: {'train_loss': '2.09624'}; time used = 1.773116111755371s
epoch 80: {'train_loss': '1.99236'}; time used = 1.7597098350524902s
epoch 85: {'train_loss': '1.99829'}; time used = 1.7047393321990967s
epoch 90: {'train_loss': '2.00962'}; time used = 1.8989336490631104s
epoch 95: {'train_loss': '1.92470'}; time used = 1.723203420639038s
epoch 100: {'train_loss': '1.95421'}; time used = 1.729264497756958s
epoch 105: {'train_loss': '1.89914'}; time used = 1.7500131130218506s
epoch 110: {'train_loss': '1.85241'}; time used = 1.775092363357544s
epoch 115: {'train_loss': '1.84751'}; time used = 1.8175594806671143s
epoch 120: {'train_loss': '1.77726'}; time used = 1.7157504558563232s
epoch 125: {'train_loss': '1.83471'}; time used = 1.7412307262420654s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 47.0457079410553.
Training classifier using 80.00% nodes...
{'micro': 0.4927536231884058, 'macro': 0.4888888888888889, 'samples': 0.4927536231884058, 'weighted': 0.492109500805153, 'accuracy': 0.4927536231884058}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 236, in forward
    self.embeddings = self.train_model(graph, step=i, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 112, in train_model
    output, train_loss, __ = self.evaluate()
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 183, in evaluate
    loss = self.model(bx, bpos, bneg) + self.model(bx_r, bpos_r, bneg_r)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 38, in forward
    hpos = self.embed(pos)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_modelg.py", line 34, in embed
    return self.encoder(x)
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_encoderg.py", line 44, in forward
    adj = x.adj.to_dense().to(getdevice())
RuntimeError: CUDA out of memory. Tried to allocate 1.42 GiB (GPU 6; 10.76 GiB total capacity; 8.59 GiB already allocated; 1.28 GiB free; 43.27 MiB cached)
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'imdb_multi', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gcn', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of IMDB-MULTI(1500)
Loading IMDB_MULTI Dataset from root dir: /data3/private/duyufeng/OpenNE/data/IMDB_MULTI
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [1, 64]
total iter: 500
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'mean', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'dgi', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64]
total iter: 500
epoch 5: {'train_loss': '2.78244'}; time used = 1.0673422813415527s
epoch 10: {'train_loss': '2.67641'}; time used = 0.8893246650695801s
epoch 15: {'train_loss': '2.53617'}; time used = 0.885411262512207s
epoch 20: {'train_loss': '2.35353'}; time used = 0.9025707244873047s
epoch 25: {'train_loss': '2.24056'}; time used = 0.8947815895080566s
epoch 30: {'train_loss': '2.12600'}; time used = 0.8866991996765137s
epoch 35: {'train_loss': '2.04446'}; time used = 0.8944313526153564s
epoch 40: {'train_loss': '2.20147'}; time used = 0.8919270038604736s
epoch 45: {'train_loss': '2.19829'}; time used = 0.9175286293029785s
epoch 50: {'train_loss': '2.05453'}; time used = 0.9128270149230957s
epoch 55: {'train_loss': '1.96463'}; time used = 0.8841540813446045s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.258006811141968.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8606016140865738, 'samples': 0.868421052631579, 'weighted': 0.8658145731165773, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32, 32], 'patience': 3, 'enc': 'gat', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'sum', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 32, 32, 32]
total iter: 500
epoch 5: {'train_loss': '2.89588'}; time used = 2.390937089920044s
epoch 10: {'train_loss': '2.85663'}; time used = 2.347170829772949s
epoch 15: {'train_loss': '2.84477'}; time used = 2.49507737159729s
epoch 20: {'train_loss': '2.81468'}; time used = 2.4115469455718994s
epoch 25: {'train_loss': '2.79247'}; time used = 2.5261754989624023s
epoch 30: {'train_loss': '2.78964'}; time used = 2.4473211765289307s
epoch 35: {'train_loss': '2.79277'}; time used = 2.3407979011535645s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 21.335617303848267.
Training classifier using 80.00% nodes...
{'micro': 0.5507246376811594, 'macro': 0.4763769889840881, 'samples': 0.5507246376811594, 'weighted': 0.49067461373352494, 'accuracy': 0.5507246376811594}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'mutag', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.001, 'early_stopping': 20, 'hiddens': [64, 64], 'patience': 3, 'enc': 'gin', 'dec': 'mlp', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of MUTAG(188)
Loading MUTAG Dataset from root dir: /data3/private/duyufeng/OpenNE/data/MUTAG
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [7, 64, 64, 64]
total iter: 500
epoch 5: {'train_loss': '2.82341'}; time used = 1.3473081588745117s
epoch 10: {'train_loss': '2.77701'}; time used = 1.1543388366699219s
epoch 15: {'train_loss': '2.77431'}; time used = 1.0486481189727783s
epoch 20: {'train_loss': '2.77952'}; time used = 1.0742847919464111s
epoch 25: {'train_loss': '2.77634'}; time used = 1.0638294219970703s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 9.298508882522583.
Training classifier using 80.00% nodes...
{'micro': 0.868421052631579, 'macro': 0.8637992831541219, 'samples': 0.868421052631579, 'weighted': 0.8677607998490852, 'accuracy': 0.868421052631579}
actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'ptc_mr', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 64, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [64], 'patience': 3, 'enc': 'gcn', 'dec': 'inner', 'sampler': 'mvgrl', 'readout': 'mean', 'est': 'jsd', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of PTC_MR(344)
Loading PTC_MR Dataset from root dir: /data3/private/duyufeng/OpenNE/data/PTC_MR
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
Encoder dimensions [18, 64, 64]
total iter: 500
epoch 5: {'train_loss': '3.09899'}; time used = 1.9341270923614502s
epoch 10: {'train_loss': '2.84885'}; time used = 1.8189377784729004s
epoch 15: {'train_loss': '2.77630'}; time used = 1.806267499923706s
epoch 20: {'train_loss': '2.79146'}; time used = 1.8577477931976318s
epoch 25: {'train_loss': '2.78349'}; time used = 1.8419766426086426s
Early stopping condition satisfied. Abort training.
Finished training. Time used = 13.748108386993408.
Training classifier using 80.00% nodes...
{'micro': 0.5652173913043478, 'macro': 0.4362745098039216, 'samples': 0.5652173913043478, 'weighted': 0.4558113100312589, 'accuracy': 0.5652173913043478}
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 266, in <module>
    main(parse_args())
  File "/data3/private/duyufeng/OpenNE/src/openne/__main__.py", line 249, in main
    res = task.train(model, graph)  # train
  File "/data3/private/duyufeng/OpenNE/src/openne/tasks/tasks.py", line 36, in train
    res = model(graph, **self.train_kwargs())
  File "/data2/private/hsd/py36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/models.py", line 221, in forward
    self.build(graph, **kwargs)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 93, in build
    self.preprocess_data(graph)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/ss_gaeg.py", line 231, in preprocess_data
    features = preprocess_features(features, sparse=self.sparse)
  File "/data3/private/duyufeng/OpenNE/src/openne/models/utils.py", line 37, in preprocess_features
    r_mat_inv = torch.diag(r_inv)
RuntimeError: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 2953269746064 bytes. Error code 12 (Cannot allocate memory)

actual args: {'cpu': False, 'devices': [6], 'task': 'graphclassification', 'model': 'ss_gaeg', 'dataset': 'reddit_binary', 'local_dataset': False, 'name': 'SelfDefined', 'weighted': False, 'directed': False, 'clf_ratio': 0.8, '_validate': False, '_no_validate': False, 'dim': 32, 'epochs': 500, 'validation_interval': 5, 'debug_output_interval': 5, 'save': False, 'silent': False, 'sparse': False, 'lr': 0.01, 'early_stopping': 20, 'hiddens': [32], 'patience': 3, 'enc': 'gat', 'dec': 'bilinear', 'sampler': 'dgi', 'readout': 'sum', 'est': 'nce', 'kstep': 4, 'measurement': 'katz', 'table_size': 100000000.0, 'encoder_layer_list': [128], 'nu1': 1e-08, 'nu2': 0.0001, 'decay': False, 'pretrain': False, 'lamb': 0.4}
Adapter of REDDIT-BINARY(2000)
Loading REDDIT_BINARY Dataset from root dir: /data3/private/duyufeng/OpenNE/data/REDDIT_BINARY
Executing task GraphClassification.
Creating test set using 80.0% nodes as training set...finished
Start training...
